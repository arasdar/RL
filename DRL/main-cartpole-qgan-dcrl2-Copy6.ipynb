{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    #states = tf.placeholder(tf.float32, [None, *state_size], name='states')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    rewards = tf.placeholder(tf.float32, [None], name='rewards')\n",
    "    dones = tf.placeholder(tf.float32, [None], name='dones')\n",
    "    rates = tf.placeholder(tf.float32, [None], name='rates') # success rate\n",
    "    return states, actions, next_states, rewards, dones, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('actor', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(actions, state_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=actions, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=state_size)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(states, actions, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=action_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        nl1_fused = tf.concat(axis=1, values=[nl1, actions])\n",
    "        h2 = tf.layers.dense(inputs=nl1_fused, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "                \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(state_size, action_size, hidden_size, gamma,\n",
    "               states, actions, next_states, rewards, dones, rates):\n",
    "    actions_logits = actor(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    aloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                      labels=actions_labels))\n",
    "    ###############################################\n",
    "    next_states_logits = generator(actions=actions_logits, hidden_size=hidden_size, state_size=state_size)\n",
    "    next_states_labels = tf.nn.sigmoid(next_states)\n",
    "    aloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=next_states_logits, \n",
    "                                                                    labels=next_states_labels))\n",
    "    ####################################################\n",
    "    dQs = discriminator(actions=actions_labels, hidden_size=hidden_size, states=states, action_size=action_size)\n",
    "    rates = tf.reshape(rates, shape=[-1, 1])\n",
    "    dloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs, # GAN\n",
    "                                                                   labels=rates)) # 0-1\n",
    "    ####################################################\n",
    "    gQs = discriminator(actions=actions_logits, hidden_size=hidden_size, states=states, action_size=action_size, \n",
    "                        reuse=True)\n",
    "    dloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                    labels=tf.zeros_like(gQs))) # 0-1\n",
    "    aloss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                    labels=tf.ones_like(gQs))) # 0-1\n",
    "    #####################################################\n",
    "    next_actions_logits = actor(states=next_states, hidden_size=hidden_size, action_size=action_size, reuse=True)\n",
    "    nextQs_logits = discriminator(actions=next_actions_logits, hidden_size=hidden_size, states=next_states, \n",
    "                                  action_size=action_size, reuse=True)\n",
    "    nextQs = tf.reshape(nextQs_logits, shape=[-1]) * dones\n",
    "    dQs = tf.reshape(dQs, shape=[-1])\n",
    "    #aloss2 += tf.reduce_mean(tf.square(dQs - nextQs)) # DQN\n",
    "    aloss2 += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs, # GAN\n",
    "                                                                     labels=tf.nn.sigmoid(nextQs))) # 0-1\n",
    "    return actions_logits, aloss, dloss, aloss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(a_loss, a_loss2, d_loss, a_learning_rate, d_learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    a_vars = [var for var in t_vars if var.name.startswith('actor')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        a_opt = tf.train.AdamOptimizer(a_learning_rate).minimize(a_loss, var_list=a_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(d_learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "        a_opt2 = tf.train.AdamOptimizer(a_learning_rate).minimize(a_loss2, var_list=a_vars)\n",
    "    return a_opt, d_opt, a_opt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, a_learning_rate, d_learning_rate, gamma):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.next_states, self.rewards, self.dones, self.rates = model_input(\n",
    "            state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.a_loss, self.d_loss, self.a_loss2 = model_loss(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, gamma=gamma, # model init\n",
    "            states=self.states, actions=self.actions, next_states=self.next_states, #model input \n",
    "            rewards=self.rewards, dones=self.dones, rates=self.rates) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.a_opt, self.d_opt, self.a_opt2 = model_opt(a_loss=self.a_loss, \n",
    "                                                        a_loss2=self.a_loss2, \n",
    "                                                        d_loss=self.d_loss,\n",
    "                                                        a_learning_rate=a_learning_rate,\n",
    "                                                        d_learning_rate=d_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample(buffer, batch_size):\n",
    "#     idx = np.random.choice(np.arange(len(buffer)), size=batch_size, replace=False)\n",
    "#     return [buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size) # data batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 4*2             # number of units in each Q-network hidden layer\n",
    "a_learning_rate = 1e-4         # Q-network learning rate\n",
    "d_learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e3)             # experience mini-batch size: 200/500 a successfull episode size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size,\n",
    "              a_learning_rate=a_learning_rate, d_learning_rate=d_learning_rate, gamma=gamma)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "total_reward = 0\n",
    "num_step = 0\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    rate = -1\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done), rate])\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()\n",
    "        rate = total_reward/500\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.buffer[-1-idx][-1] == -1:\n",
    "                memory.buffer[-1-idx][-1] = rate\n",
    "        total_reward = 0 # reset\n",
    "        num_step = 0 # reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:19.0000 R:19.0000 rate:0.0380 aloss:1.3951 dloss:1.4902 aloss2:1.3826 exploreP:0.9981\n",
      "Episode:1 meanR:18.5000 R:18.0000 rate:0.0360 aloss:1.3859 dloss:1.5004 aloss2:1.3732 exploreP:0.9963\n",
      "Episode:2 meanR:25.6667 R:40.0000 rate:0.0800 aloss:1.3790 dloss:1.4799 aloss2:1.3793 exploreP:0.9924\n",
      "Episode:3 meanR:30.5000 R:45.0000 rate:0.0900 aloss:1.3799 dloss:1.4527 aloss2:1.3882 exploreP:0.9880\n",
      "Episode:4 meanR:28.0000 R:18.0000 rate:0.0360 aloss:1.3738 dloss:1.4460 aloss2:1.3877 exploreP:0.9862\n",
      "Episode:5 meanR:26.0000 R:16.0000 rate:0.0320 aloss:1.3768 dloss:1.4327 aloss2:1.3926 exploreP:0.9847\n",
      "Episode:6 meanR:24.8571 R:18.0000 rate:0.0360 aloss:1.3760 dloss:1.4161 aloss2:1.3997 exploreP:0.9829\n",
      "Episode:7 meanR:25.1250 R:27.0000 rate:0.0540 aloss:1.3735 dloss:1.4103 aloss2:1.3985 exploreP:0.9803\n",
      "Episode:8 meanR:25.1111 R:25.0000 rate:0.0500 aloss:1.3746 dloss:1.3973 aloss2:1.4043 exploreP:0.9779\n",
      "Episode:9 meanR:26.5000 R:39.0000 rate:0.0780 aloss:1.3733 dloss:1.3756 aloss2:1.4139 exploreP:0.9741\n",
      "Episode:10 meanR:27.9091 R:42.0000 rate:0.0840 aloss:1.3782 dloss:1.3783 aloss2:1.4083 exploreP:0.9701\n",
      "Episode:11 meanR:26.6667 R:13.0000 rate:0.0260 aloss:1.3788 dloss:1.3400 aloss2:1.4297 exploreP:0.9688\n",
      "Episode:12 meanR:26.3077 R:22.0000 rate:0.0440 aloss:1.3877 dloss:1.3200 aloss2:1.4397 exploreP:0.9667\n",
      "Episode:13 meanR:25.2857 R:12.0000 rate:0.0240 aloss:1.3719 dloss:1.3195 aloss2:1.4392 exploreP:0.9656\n",
      "Episode:14 meanR:24.8667 R:19.0000 rate:0.0380 aloss:1.3837 dloss:1.3056 aloss2:1.4477 exploreP:0.9638\n",
      "Episode:15 meanR:24.3750 R:17.0000 rate:0.0340 aloss:1.3776 dloss:1.2935 aloss2:1.4547 exploreP:0.9621\n",
      "Episode:16 meanR:24.1176 R:20.0000 rate:0.0400 aloss:1.3849 dloss:1.2715 aloss2:1.4683 exploreP:0.9602\n",
      "Episode:17 meanR:25.2222 R:44.0000 rate:0.0880 aloss:1.3770 dloss:1.2672 aloss2:1.4717 exploreP:0.9561\n",
      "Episode:18 meanR:24.8947 R:19.0000 rate:0.0380 aloss:1.3851 dloss:1.2464 aloss2:1.4830 exploreP:0.9543\n",
      "Episode:19 meanR:25.8500 R:44.0000 rate:0.0880 aloss:1.3926 dloss:1.2018 aloss2:1.5162 exploreP:0.9501\n",
      "Episode:20 meanR:25.7143 R:23.0000 rate:0.0460 aloss:1.3808 dloss:1.2056 aloss2:1.5176 exploreP:0.9480\n",
      "Episode:21 meanR:25.1818 R:14.0000 rate:0.0280 aloss:1.3838 dloss:1.1947 aloss2:1.5234 exploreP:0.9466\n",
      "Episode:22 meanR:24.8696 R:18.0000 rate:0.0360 aloss:1.3915 dloss:1.1582 aloss2:1.5558 exploreP:0.9450\n",
      "Episode:23 meanR:24.7500 R:22.0000 rate:0.0440 aloss:1.3740 dloss:1.1491 aloss2:1.5637 exploreP:0.9429\n",
      "Episode:24 meanR:24.6400 R:22.0000 rate:0.0440 aloss:1.4027 dloss:1.1270 aloss2:1.5812 exploreP:0.9409\n",
      "Episode:25 meanR:24.5000 R:21.0000 rate:0.0420 aloss:1.3844 dloss:1.1384 aloss2:1.5723 exploreP:0.9389\n",
      "Episode:26 meanR:24.4815 R:24.0000 rate:0.0480 aloss:1.4003 dloss:1.1098 aloss2:1.5924 exploreP:0.9367\n",
      "Episode:27 meanR:24.1071 R:14.0000 rate:0.0280 aloss:1.3978 dloss:1.0980 aloss2:1.6114 exploreP:0.9354\n",
      "Episode:28 meanR:24.4138 R:33.0000 rate:0.0660 aloss:1.4095 dloss:1.0935 aloss2:1.6106 exploreP:0.9323\n",
      "Episode:29 meanR:24.5333 R:28.0000 rate:0.0560 aloss:1.3992 dloss:1.0639 aloss2:1.6426 exploreP:0.9298\n",
      "Episode:30 meanR:24.3871 R:20.0000 rate:0.0400 aloss:1.4082 dloss:1.0599 aloss2:1.6557 exploreP:0.9279\n",
      "Episode:31 meanR:24.6250 R:32.0000 rate:0.0640 aloss:1.3892 dloss:1.0557 aloss2:1.6546 exploreP:0.9250\n",
      "Episode:32 meanR:24.5455 R:22.0000 rate:0.0440 aloss:1.4048 dloss:1.0497 aloss2:1.6701 exploreP:0.9230\n",
      "Episode:33 meanR:24.4412 R:21.0000 rate:0.0420 aloss:1.3943 dloss:1.0290 aloss2:1.6826 exploreP:0.9211\n",
      "Episode:34 meanR:24.6286 R:31.0000 rate:0.0620 aloss:1.3914 dloss:1.0142 aloss2:1.7157 exploreP:0.9182\n",
      "Episode:35 meanR:24.1944 R:9.0000 rate:0.0180 aloss:1.3792 dloss:1.0184 aloss2:1.7015 exploreP:0.9174\n",
      "Episode:36 meanR:24.5135 R:36.0000 rate:0.0720 aloss:1.3922 dloss:0.9887 aloss2:1.7253 exploreP:0.9142\n",
      "Episode:37 meanR:24.3947 R:20.0000 rate:0.0400 aloss:1.3993 dloss:0.9501 aloss2:1.7705 exploreP:0.9124\n",
      "Episode:38 meanR:24.2564 R:19.0000 rate:0.0380 aloss:1.3945 dloss:0.9686 aloss2:1.7597 exploreP:0.9106\n",
      "Episode:39 meanR:24.1250 R:19.0000 rate:0.0380 aloss:1.4179 dloss:0.9271 aloss2:1.8222 exploreP:0.9089\n",
      "Episode:40 meanR:23.9268 R:16.0000 rate:0.0320 aloss:1.4247 dloss:0.8964 aloss2:1.8689 exploreP:0.9075\n",
      "Episode:41 meanR:23.7619 R:17.0000 rate:0.0340 aloss:1.4192 dloss:0.8911 aloss2:1.8713 exploreP:0.9060\n",
      "Episode:42 meanR:23.8140 R:26.0000 rate:0.0520 aloss:1.4064 dloss:0.9150 aloss2:1.8406 exploreP:0.9036\n",
      "Episode:43 meanR:23.5455 R:12.0000 rate:0.0240 aloss:1.4252 dloss:0.8524 aloss2:1.9526 exploreP:0.9026\n",
      "Episode:44 meanR:24.3333 R:59.0000 rate:0.1180 aloss:1.4133 dloss:0.8613 aloss2:1.9306 exploreP:0.8973\n",
      "Episode:45 meanR:24.4783 R:31.0000 rate:0.0620 aloss:1.4128 dloss:0.8411 aloss2:2.0121 exploreP:0.8946\n",
      "Episode:46 meanR:24.3617 R:19.0000 rate:0.0380 aloss:1.4048 dloss:0.8576 aloss2:1.9407 exploreP:0.8929\n",
      "Episode:47 meanR:24.1042 R:12.0000 rate:0.0240 aloss:1.4198 dloss:0.7804 aloss2:2.0884 exploreP:0.8918\n",
      "Episode:48 meanR:23.8980 R:14.0000 rate:0.0280 aloss:1.4268 dloss:0.8425 aloss2:2.0021 exploreP:0.8906\n",
      "Episode:49 meanR:24.2000 R:39.0000 rate:0.0780 aloss:1.4230 dloss:0.7925 aloss2:2.0965 exploreP:0.8872\n",
      "Episode:50 meanR:24.0784 R:18.0000 rate:0.0360 aloss:1.4217 dloss:0.8040 aloss2:2.1115 exploreP:0.8856\n",
      "Episode:51 meanR:24.1346 R:27.0000 rate:0.0540 aloss:1.4047 dloss:0.8003 aloss2:2.1159 exploreP:0.8832\n",
      "Episode:52 meanR:23.9811 R:16.0000 rate:0.0320 aloss:1.4128 dloss:0.7578 aloss2:2.1644 exploreP:0.8818\n",
      "Episode:53 meanR:23.7778 R:13.0000 rate:0.0260 aloss:1.4185 dloss:0.7781 aloss2:2.1190 exploreP:0.8807\n",
      "Episode:54 meanR:23.7455 R:22.0000 rate:0.0440 aloss:1.3856 dloss:0.7864 aloss2:2.1174 exploreP:0.8788\n",
      "Episode:55 meanR:23.5357 R:12.0000 rate:0.0240 aloss:1.4125 dloss:0.7130 aloss2:2.2461 exploreP:0.8778\n",
      "Episode:56 meanR:23.4737 R:20.0000 rate:0.0400 aloss:1.3852 dloss:0.7783 aloss2:2.1656 exploreP:0.8760\n",
      "Episode:57 meanR:23.3621 R:17.0000 rate:0.0340 aloss:1.4148 dloss:0.7408 aloss2:2.2106 exploreP:0.8745\n",
      "Episode:58 meanR:23.3390 R:22.0000 rate:0.0440 aloss:1.3965 dloss:0.7536 aloss2:2.1813 exploreP:0.8726\n",
      "Episode:59 meanR:23.2500 R:18.0000 rate:0.0360 aloss:1.4035 dloss:0.7167 aloss2:2.3044 exploreP:0.8711\n",
      "Episode:60 meanR:23.1803 R:19.0000 rate:0.0380 aloss:1.4069 dloss:0.7023 aloss2:2.3377 exploreP:0.8695\n",
      "Episode:61 meanR:23.3710 R:35.0000 rate:0.0700 aloss:1.4052 dloss:0.7103 aloss2:2.3375 exploreP:0.8665\n",
      "Episode:62 meanR:23.2222 R:14.0000 rate:0.0280 aloss:1.4057 dloss:0.7197 aloss2:2.3075 exploreP:0.8653\n",
      "Episode:63 meanR:23.1094 R:16.0000 rate:0.0320 aloss:1.3830 dloss:0.7140 aloss2:2.3051 exploreP:0.8639\n",
      "Episode:64 meanR:22.9385 R:12.0000 rate:0.0240 aloss:1.3965 dloss:0.7188 aloss2:2.2909 exploreP:0.8629\n",
      "Episode:65 meanR:23.0909 R:33.0000 rate:0.0660 aloss:1.3990 dloss:0.6825 aloss2:2.4235 exploreP:0.8601\n",
      "Episode:66 meanR:23.0448 R:20.0000 rate:0.0400 aloss:1.4114 dloss:0.6629 aloss2:2.5035 exploreP:0.8584\n",
      "Episode:67 meanR:23.0441 R:23.0000 rate:0.0460 aloss:1.3873 dloss:0.6837 aloss2:2.4120 exploreP:0.8564\n",
      "Episode:68 meanR:22.9130 R:14.0000 rate:0.0280 aloss:1.3982 dloss:0.6600 aloss2:2.4935 exploreP:0.8552\n",
      "Episode:69 meanR:23.0857 R:35.0000 rate:0.0700 aloss:1.3776 dloss:0.6800 aloss2:2.4808 exploreP:0.8523\n",
      "Episode:70 meanR:22.9718 R:15.0000 rate:0.0300 aloss:1.3818 dloss:0.6720 aloss2:2.4667 exploreP:0.8510\n",
      "Episode:71 meanR:22.7917 R:10.0000 rate:0.0200 aloss:1.3879 dloss:0.6391 aloss2:2.5768 exploreP:0.8502\n",
      "Episode:72 meanR:22.7671 R:21.0000 rate:0.0420 aloss:1.3948 dloss:0.6341 aloss2:2.5721 exploreP:0.8484\n",
      "Episode:73 meanR:22.7703 R:23.0000 rate:0.0460 aloss:1.4015 dloss:0.6536 aloss2:2.5574 exploreP:0.8465\n",
      "Episode:74 meanR:22.9333 R:35.0000 rate:0.0700 aloss:1.4042 dloss:0.6437 aloss2:2.6319 exploreP:0.8436\n",
      "Episode:75 meanR:22.9737 R:26.0000 rate:0.0520 aloss:1.3750 dloss:0.6467 aloss2:2.6351 exploreP:0.8414\n",
      "Episode:76 meanR:23.0909 R:32.0000 rate:0.0640 aloss:1.3778 dloss:0.6342 aloss2:2.6452 exploreP:0.8387\n",
      "Episode:77 meanR:23.0897 R:23.0000 rate:0.0460 aloss:1.3862 dloss:0.6269 aloss2:2.7130 exploreP:0.8368\n",
      "Episode:78 meanR:22.9367 R:11.0000 rate:0.0220 aloss:1.3723 dloss:0.6592 aloss2:2.6323 exploreP:0.8359\n",
      "Episode:79 meanR:22.9000 R:20.0000 rate:0.0400 aloss:1.3761 dloss:0.6333 aloss2:2.6559 exploreP:0.8343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:80 meanR:22.8889 R:22.0000 rate:0.0440 aloss:1.3888 dloss:0.6263 aloss2:2.7216 exploreP:0.8325\n",
      "Episode:81 meanR:22.8780 R:22.0000 rate:0.0440 aloss:1.3872 dloss:0.6187 aloss2:2.7107 exploreP:0.8307\n",
      "Episode:82 meanR:22.9639 R:30.0000 rate:0.0600 aloss:1.3792 dloss:0.6165 aloss2:2.7485 exploreP:0.8282\n",
      "Episode:83 meanR:23.2381 R:46.0000 rate:0.0920 aloss:1.3767 dloss:0.5971 aloss2:2.8003 exploreP:0.8244\n",
      "Episode:84 meanR:23.6588 R:59.0000 rate:0.1180 aloss:1.3848 dloss:0.6054 aloss2:2.8729 exploreP:0.8197\n",
      "Episode:85 meanR:23.7209 R:29.0000 rate:0.0580 aloss:1.3846 dloss:0.6055 aloss2:2.8814 exploreP:0.8173\n",
      "Episode:86 meanR:24.4598 R:88.0000 rate:0.1760 aloss:1.3978 dloss:0.5807 aloss2:2.9769 exploreP:0.8102\n",
      "Episode:87 meanR:24.7727 R:52.0000 rate:0.1040 aloss:1.3905 dloss:0.5571 aloss2:3.0484 exploreP:0.8061\n",
      "Episode:88 meanR:24.6966 R:18.0000 rate:0.0360 aloss:1.3895 dloss:0.5521 aloss2:3.1399 exploreP:0.8047\n",
      "Episode:89 meanR:24.7111 R:26.0000 rate:0.0520 aloss:1.4372 dloss:0.5562 aloss2:3.2105 exploreP:0.8026\n",
      "Episode:90 meanR:24.7143 R:25.0000 rate:0.0500 aloss:1.4071 dloss:0.5442 aloss2:3.0722 exploreP:0.8006\n",
      "Episode:91 meanR:24.6522 R:19.0000 rate:0.0380 aloss:1.4077 dloss:0.5296 aloss2:3.2336 exploreP:0.7991\n",
      "Episode:92 meanR:24.6129 R:21.0000 rate:0.0420 aloss:1.4234 dloss:0.5555 aloss2:3.1807 exploreP:0.7975\n",
      "Episode:93 meanR:24.5957 R:23.0000 rate:0.0460 aloss:1.3878 dloss:0.5418 aloss2:3.2632 exploreP:0.7956\n",
      "Episode:94 meanR:24.7158 R:36.0000 rate:0.0720 aloss:1.3966 dloss:0.5390 aloss2:3.1972 exploreP:0.7928\n",
      "Episode:95 meanR:25.4688 R:97.0000 rate:0.1940 aloss:1.4039 dloss:0.5393 aloss2:3.2697 exploreP:0.7853\n",
      "Episode:96 meanR:25.3608 R:15.0000 rate:0.0300 aloss:1.4523 dloss:0.5424 aloss2:3.4321 exploreP:0.7841\n",
      "Episode:97 meanR:26.0918 R:97.0000 rate:0.1940 aloss:1.4073 dloss:0.5220 aloss2:3.3334 exploreP:0.7766\n",
      "Episode:98 meanR:26.1111 R:28.0000 rate:0.0560 aloss:1.4325 dloss:0.5083 aloss2:3.4366 exploreP:0.7745\n",
      "Episode:99 meanR:26.1000 R:25.0000 rate:0.0500 aloss:1.4031 dloss:0.5314 aloss2:3.4270 exploreP:0.7726\n",
      "Episode:100 meanR:26.2700 R:36.0000 rate:0.0720 aloss:1.3992 dloss:0.5177 aloss2:3.4003 exploreP:0.7698\n",
      "Episode:101 meanR:26.4000 R:31.0000 rate:0.0620 aloss:1.4209 dloss:0.4987 aloss2:3.4197 exploreP:0.7675\n",
      "Episode:102 meanR:26.2600 R:26.0000 rate:0.0520 aloss:1.4154 dloss:0.5021 aloss2:3.5132 exploreP:0.7655\n",
      "Episode:103 meanR:25.9400 R:13.0000 rate:0.0260 aloss:1.4136 dloss:0.5209 aloss2:3.4498 exploreP:0.7645\n",
      "Episode:104 meanR:25.9200 R:16.0000 rate:0.0320 aloss:1.4130 dloss:0.5238 aloss2:3.5239 exploreP:0.7633\n",
      "Episode:105 meanR:26.0700 R:31.0000 rate:0.0620 aloss:1.4482 dloss:0.5131 aloss2:3.5571 exploreP:0.7610\n",
      "Episode:106 meanR:26.3600 R:47.0000 rate:0.0940 aloss:1.4142 dloss:0.5082 aloss2:3.5513 exploreP:0.7575\n",
      "Episode:107 meanR:26.4500 R:36.0000 rate:0.0720 aloss:1.4153 dloss:0.5006 aloss2:3.5501 exploreP:0.7548\n",
      "Episode:108 meanR:26.3600 R:16.0000 rate:0.0320 aloss:1.4120 dloss:0.5328 aloss2:3.5775 exploreP:0.7536\n",
      "Episode:109 meanR:26.3300 R:36.0000 rate:0.0720 aloss:1.4210 dloss:0.4729 aloss2:3.6538 exploreP:0.7509\n",
      "Episode:110 meanR:26.3300 R:42.0000 rate:0.0840 aloss:1.4341 dloss:0.5005 aloss2:3.6549 exploreP:0.7478\n",
      "Episode:111 meanR:26.6000 R:40.0000 rate:0.0800 aloss:1.4030 dloss:0.4977 aloss2:3.6101 exploreP:0.7449\n",
      "Episode:112 meanR:26.7700 R:39.0000 rate:0.0780 aloss:1.4033 dloss:0.4998 aloss2:3.6721 exploreP:0.7420\n",
      "Episode:113 meanR:27.0000 R:35.0000 rate:0.0700 aloss:1.3924 dloss:0.5364 aloss2:3.6523 exploreP:0.7395\n",
      "Episode:114 meanR:27.4700 R:66.0000 rate:0.1320 aloss:1.4086 dloss:0.4961 aloss2:3.7317 exploreP:0.7347\n",
      "Episode:115 meanR:27.6300 R:33.0000 rate:0.0660 aloss:1.4219 dloss:0.5137 aloss2:3.7562 exploreP:0.7323\n",
      "Episode:116 meanR:27.6400 R:21.0000 rate:0.0420 aloss:1.4162 dloss:0.4778 aloss2:3.8235 exploreP:0.7308\n",
      "Episode:117 meanR:27.6300 R:43.0000 rate:0.0860 aloss:1.4151 dloss:0.4795 aloss2:3.7999 exploreP:0.7277\n",
      "Episode:118 meanR:27.7600 R:32.0000 rate:0.0640 aloss:1.4196 dloss:0.5033 aloss2:3.9023 exploreP:0.7254\n",
      "Episode:119 meanR:27.5800 R:26.0000 rate:0.0520 aloss:1.4166 dloss:0.5289 aloss2:4.0438 exploreP:0.7235\n",
      "Episode:120 meanR:27.6100 R:26.0000 rate:0.0520 aloss:1.4182 dloss:0.5078 aloss2:3.9298 exploreP:0.7217\n",
      "Episode:121 meanR:27.7800 R:31.0000 rate:0.0620 aloss:1.4127 dloss:0.5010 aloss2:3.8292 exploreP:0.7195\n",
      "Episode:122 meanR:27.7600 R:16.0000 rate:0.0320 aloss:1.4346 dloss:0.4575 aloss2:3.9675 exploreP:0.7183\n",
      "Episode:123 meanR:27.8900 R:35.0000 rate:0.0700 aloss:1.4045 dloss:0.4947 aloss2:3.9112 exploreP:0.7159\n",
      "Episode:124 meanR:27.8700 R:20.0000 rate:0.0400 aloss:1.3919 dloss:0.4895 aloss2:3.8430 exploreP:0.7144\n",
      "Episode:125 meanR:27.7700 R:11.0000 rate:0.0220 aloss:1.3979 dloss:0.4689 aloss2:3.9448 exploreP:0.7137\n",
      "Episode:126 meanR:28.0200 R:49.0000 rate:0.0980 aloss:1.4014 dloss:0.4867 aloss2:3.9293 exploreP:0.7102\n",
      "Episode:127 meanR:28.1500 R:27.0000 rate:0.0540 aloss:1.4114 dloss:0.4680 aloss2:4.0627 exploreP:0.7083\n",
      "Episode:128 meanR:28.1700 R:35.0000 rate:0.0700 aloss:1.3917 dloss:0.4910 aloss2:4.0009 exploreP:0.7059\n",
      "Episode:129 meanR:28.0600 R:17.0000 rate:0.0340 aloss:1.4164 dloss:0.4796 aloss2:4.0892 exploreP:0.7047\n",
      "Episode:130 meanR:28.1600 R:30.0000 rate:0.0600 aloss:1.4086 dloss:0.5023 aloss2:4.0736 exploreP:0.7026\n",
      "Episode:131 meanR:28.1600 R:32.0000 rate:0.0640 aloss:1.3985 dloss:0.4791 aloss2:4.1074 exploreP:0.7004\n",
      "Episode:132 meanR:28.1000 R:16.0000 rate:0.0320 aloss:1.4106 dloss:0.4853 aloss2:4.1524 exploreP:0.6993\n",
      "Episode:133 meanR:28.2600 R:37.0000 rate:0.0740 aloss:1.3920 dloss:0.4657 aloss2:4.0026 exploreP:0.6968\n",
      "Episode:134 meanR:28.3300 R:38.0000 rate:0.0760 aloss:1.3895 dloss:0.4755 aloss2:3.9632 exploreP:0.6942\n",
      "Episode:135 meanR:28.8200 R:58.0000 rate:0.1160 aloss:1.3924 dloss:0.4945 aloss2:4.0292 exploreP:0.6902\n",
      "Episode:136 meanR:28.6300 R:17.0000 rate:0.0340 aloss:1.3895 dloss:0.5096 aloss2:3.9559 exploreP:0.6891\n",
      "Episode:137 meanR:28.5200 R:9.0000 rate:0.0180 aloss:1.3917 dloss:0.4933 aloss2:4.0687 exploreP:0.6884\n",
      "Episode:138 meanR:28.6500 R:32.0000 rate:0.0640 aloss:1.3937 dloss:0.4981 aloss2:4.0337 exploreP:0.6863\n",
      "Episode:139 meanR:28.7100 R:25.0000 rate:0.0500 aloss:1.3911 dloss:0.4752 aloss2:4.0476 exploreP:0.6846\n",
      "Episode:140 meanR:29.0000 R:45.0000 rate:0.0900 aloss:1.3919 dloss:0.4975 aloss2:4.0378 exploreP:0.6816\n",
      "Episode:141 meanR:29.0100 R:18.0000 rate:0.0360 aloss:1.3879 dloss:0.5060 aloss2:4.0684 exploreP:0.6804\n",
      "Episode:142 meanR:29.0900 R:34.0000 rate:0.0680 aloss:1.3845 dloss:0.4968 aloss2:3.9853 exploreP:0.6781\n",
      "Episode:143 meanR:29.0800 R:11.0000 rate:0.0220 aloss:1.3974 dloss:0.5129 aloss2:4.0595 exploreP:0.6773\n",
      "Episode:144 meanR:28.6500 R:16.0000 rate:0.0320 aloss:1.3838 dloss:0.5093 aloss2:3.9805 exploreP:0.6763\n",
      "Episode:145 meanR:28.6400 R:30.0000 rate:0.0600 aloss:1.4030 dloss:0.4848 aloss2:4.1825 exploreP:0.6743\n",
      "Episode:146 meanR:28.7200 R:27.0000 rate:0.0540 aloss:1.3851 dloss:0.4707 aloss2:4.0758 exploreP:0.6725\n",
      "Episode:147 meanR:28.8600 R:26.0000 rate:0.0520 aloss:1.3814 dloss:0.4853 aloss2:4.0404 exploreP:0.6708\n",
      "Episode:148 meanR:28.9600 R:24.0000 rate:0.0480 aloss:1.4004 dloss:0.4630 aloss2:4.0856 exploreP:0.6692\n",
      "Episode:149 meanR:28.9500 R:38.0000 rate:0.0760 aloss:1.3860 dloss:0.4739 aloss2:3.9961 exploreP:0.6667\n",
      "Episode:150 meanR:28.9200 R:15.0000 rate:0.0300 aloss:1.3787 dloss:0.4912 aloss2:4.0522 exploreP:0.6657\n",
      "Episode:151 meanR:28.8300 R:18.0000 rate:0.0360 aloss:1.3724 dloss:0.4647 aloss2:3.9073 exploreP:0.6645\n",
      "Episode:152 meanR:28.7600 R:9.0000 rate:0.0180 aloss:1.4151 dloss:0.4715 aloss2:4.2373 exploreP:0.6639\n",
      "Episode:153 meanR:29.2700 R:64.0000 rate:0.1280 aloss:1.3895 dloss:0.4730 aloss2:4.1483 exploreP:0.6598\n",
      "Episode:154 meanR:29.4600 R:41.0000 rate:0.0820 aloss:1.3801 dloss:0.4773 aloss2:4.0401 exploreP:0.6571\n",
      "Episode:155 meanR:29.8900 R:55.0000 rate:0.1100 aloss:1.3848 dloss:0.4861 aloss2:4.1696 exploreP:0.6536\n",
      "Episode:156 meanR:29.8200 R:13.0000 rate:0.0260 aloss:1.3858 dloss:0.5034 aloss2:4.0532 exploreP:0.6527\n",
      "Episode:157 meanR:30.1100 R:46.0000 rate:0.0920 aloss:1.3930 dloss:0.4531 aloss2:4.1079 exploreP:0.6498\n",
      "Episode:158 meanR:30.0800 R:19.0000 rate:0.0380 aloss:1.3846 dloss:0.4970 aloss2:4.2113 exploreP:0.6486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:159 meanR:30.2600 R:36.0000 rate:0.0720 aloss:1.3731 dloss:0.5141 aloss2:4.1190 exploreP:0.6463\n",
      "Episode:160 meanR:30.2000 R:13.0000 rate:0.0260 aloss:1.3782 dloss:0.4652 aloss2:4.0551 exploreP:0.6454\n",
      "Episode:161 meanR:30.1500 R:30.0000 rate:0.0600 aloss:1.3802 dloss:0.4691 aloss2:4.0814 exploreP:0.6435\n",
      "Episode:162 meanR:30.3900 R:38.0000 rate:0.0760 aloss:1.3822 dloss:0.4734 aloss2:4.1116 exploreP:0.6411\n",
      "Episode:163 meanR:30.5800 R:35.0000 rate:0.0700 aloss:1.3863 dloss:0.4832 aloss2:4.1550 exploreP:0.6389\n",
      "Episode:164 meanR:31.0000 R:54.0000 rate:0.1080 aloss:1.3772 dloss:0.4832 aloss2:4.1142 exploreP:0.6355\n",
      "Episode:165 meanR:30.8200 R:15.0000 rate:0.0300 aloss:1.3795 dloss:0.4881 aloss2:4.1321 exploreP:0.6346\n",
      "Episode:166 meanR:30.7100 R:9.0000 rate:0.0180 aloss:1.3760 dloss:0.4937 aloss2:4.1166 exploreP:0.6340\n",
      "Episode:167 meanR:30.7000 R:22.0000 rate:0.0440 aloss:1.3734 dloss:0.4692 aloss2:4.0610 exploreP:0.6327\n",
      "Episode:168 meanR:30.7600 R:20.0000 rate:0.0400 aloss:1.3837 dloss:0.4670 aloss2:4.1274 exploreP:0.6314\n",
      "Episode:169 meanR:30.8300 R:42.0000 rate:0.0840 aloss:1.4078 dloss:0.4659 aloss2:4.1148 exploreP:0.6288\n",
      "Episode:170 meanR:31.3100 R:63.0000 rate:0.1260 aloss:1.3815 dloss:0.4713 aloss2:4.1252 exploreP:0.6249\n",
      "Episode:171 meanR:31.5100 R:30.0000 rate:0.0600 aloss:1.3797 dloss:0.4764 aloss2:4.1007 exploreP:0.6231\n",
      "Episode:172 meanR:31.7500 R:45.0000 rate:0.0900 aloss:1.3847 dloss:0.4716 aloss2:4.1424 exploreP:0.6203\n",
      "Episode:173 meanR:32.0000 R:48.0000 rate:0.0960 aloss:1.3804 dloss:0.4744 aloss2:4.1186 exploreP:0.6174\n",
      "Episode:174 meanR:31.9100 R:26.0000 rate:0.0520 aloss:1.3745 dloss:0.4934 aloss2:4.0917 exploreP:0.6158\n",
      "Episode:175 meanR:31.8400 R:19.0000 rate:0.0380 aloss:1.3843 dloss:0.5025 aloss2:4.1623 exploreP:0.6147\n",
      "Episode:176 meanR:31.7200 R:20.0000 rate:0.0400 aloss:1.3684 dloss:0.4822 aloss2:4.0678 exploreP:0.6135\n",
      "Episode:177 meanR:31.8200 R:33.0000 rate:0.0660 aloss:1.3806 dloss:0.4846 aloss2:4.1562 exploreP:0.6115\n",
      "Episode:178 meanR:31.9700 R:26.0000 rate:0.0520 aloss:1.3853 dloss:0.4780 aloss2:4.0975 exploreP:0.6099\n",
      "Episode:179 meanR:32.1300 R:36.0000 rate:0.0720 aloss:1.3766 dloss:0.4625 aloss2:4.1268 exploreP:0.6078\n",
      "Episode:180 meanR:32.3400 R:43.0000 rate:0.0860 aloss:1.3800 dloss:0.4513 aloss2:4.1567 exploreP:0.6052\n",
      "Episode:181 meanR:32.4700 R:35.0000 rate:0.0700 aloss:1.3827 dloss:0.4465 aloss2:4.1101 exploreP:0.6031\n",
      "Episode:182 meanR:32.4700 R:30.0000 rate:0.0600 aloss:1.3769 dloss:0.4673 aloss2:4.1376 exploreP:0.6013\n",
      "Episode:183 meanR:32.6700 R:66.0000 rate:0.1320 aloss:1.3783 dloss:0.4787 aloss2:4.1552 exploreP:0.5975\n",
      "Episode:184 meanR:32.3300 R:25.0000 rate:0.0500 aloss:1.3765 dloss:0.4699 aloss2:4.1640 exploreP:0.5960\n",
      "Episode:185 meanR:32.3800 R:34.0000 rate:0.0680 aloss:1.3908 dloss:0.4772 aloss2:4.2166 exploreP:0.5940\n",
      "Episode:186 meanR:31.8500 R:35.0000 rate:0.0700 aloss:1.3757 dloss:0.4695 aloss2:4.1695 exploreP:0.5920\n",
      "Episode:187 meanR:31.6100 R:28.0000 rate:0.0560 aloss:1.3746 dloss:0.5195 aloss2:4.1333 exploreP:0.5903\n",
      "Episode:188 meanR:31.9600 R:53.0000 rate:0.1060 aloss:1.3811 dloss:0.4953 aloss2:4.0799 exploreP:0.5873\n",
      "Episode:189 meanR:31.9800 R:28.0000 rate:0.0560 aloss:1.3812 dloss:0.4816 aloss2:4.1083 exploreP:0.5857\n",
      "Episode:190 meanR:31.9100 R:18.0000 rate:0.0360 aloss:1.3768 dloss:0.4708 aloss2:4.1440 exploreP:0.5846\n",
      "Episode:191 meanR:32.0500 R:33.0000 rate:0.0660 aloss:1.3848 dloss:0.4512 aloss2:4.1161 exploreP:0.5827\n",
      "Episode:192 meanR:32.1000 R:26.0000 rate:0.0520 aloss:1.3782 dloss:0.4724 aloss2:4.1720 exploreP:0.5812\n",
      "Episode:193 meanR:32.5600 R:69.0000 rate:0.1380 aloss:1.3772 dloss:0.4941 aloss2:4.1588 exploreP:0.5773\n",
      "Episode:194 meanR:32.4500 R:25.0000 rate:0.0500 aloss:1.3819 dloss:0.4644 aloss2:4.1185 exploreP:0.5759\n",
      "Episode:195 meanR:31.8000 R:32.0000 rate:0.0640 aloss:1.3841 dloss:0.4630 aloss2:4.0980 exploreP:0.5741\n",
      "Episode:196 meanR:31.9800 R:33.0000 rate:0.0660 aloss:1.3797 dloss:0.4898 aloss2:4.1795 exploreP:0.5722\n",
      "Episode:197 meanR:31.2400 R:23.0000 rate:0.0460 aloss:1.3848 dloss:0.4795 aloss2:4.0614 exploreP:0.5709\n",
      "Episode:198 meanR:31.2000 R:24.0000 rate:0.0480 aloss:1.3757 dloss:0.4987 aloss2:4.1347 exploreP:0.5696\n",
      "Episode:199 meanR:31.4800 R:53.0000 rate:0.1060 aloss:1.3639 dloss:0.4815 aloss2:4.0661 exploreP:0.5666\n",
      "Episode:200 meanR:31.3600 R:24.0000 rate:0.0480 aloss:1.3699 dloss:0.4531 aloss2:4.0631 exploreP:0.5653\n",
      "Episode:201 meanR:31.4000 R:35.0000 rate:0.0700 aloss:1.3795 dloss:0.4854 aloss2:4.1399 exploreP:0.5634\n",
      "Episode:202 meanR:31.3600 R:22.0000 rate:0.0440 aloss:1.3864 dloss:0.4874 aloss2:4.0957 exploreP:0.5621\n",
      "Episode:203 meanR:31.3900 R:16.0000 rate:0.0320 aloss:1.3686 dloss:0.4996 aloss2:4.1185 exploreP:0.5613\n",
      "Episode:204 meanR:31.5800 R:35.0000 rate:0.0700 aloss:1.3767 dloss:0.4654 aloss2:4.0781 exploreP:0.5593\n",
      "Episode:205 meanR:31.4800 R:21.0000 rate:0.0420 aloss:1.3733 dloss:0.5096 aloss2:4.0709 exploreP:0.5582\n",
      "Episode:206 meanR:31.6100 R:60.0000 rate:0.1200 aloss:1.3786 dloss:0.4680 aloss2:4.1311 exploreP:0.5549\n",
      "Episode:207 meanR:31.7800 R:53.0000 rate:0.1060 aloss:1.3765 dloss:0.4749 aloss2:4.1761 exploreP:0.5520\n",
      "Episode:208 meanR:31.7500 R:13.0000 rate:0.0260 aloss:1.3832 dloss:0.4633 aloss2:4.1005 exploreP:0.5513\n",
      "Episode:209 meanR:31.6000 R:21.0000 rate:0.0420 aloss:1.3820 dloss:0.4725 aloss2:4.1559 exploreP:0.5502\n",
      "Episode:210 meanR:32.0100 R:83.0000 rate:0.1660 aloss:1.3795 dloss:0.4830 aloss2:4.1487 exploreP:0.5457\n",
      "Episode:211 meanR:32.4300 R:82.0000 rate:0.1640 aloss:1.3787 dloss:0.4823 aloss2:4.1015 exploreP:0.5413\n",
      "Episode:212 meanR:32.3900 R:35.0000 rate:0.0700 aloss:1.3745 dloss:0.4740 aloss2:4.1330 exploreP:0.5395\n",
      "Episode:213 meanR:32.9900 R:95.0000 rate:0.1900 aloss:1.3791 dloss:0.4612 aloss2:4.1625 exploreP:0.5345\n",
      "Episode:214 meanR:32.9300 R:60.0000 rate:0.1200 aloss:1.3756 dloss:0.4597 aloss2:4.1572 exploreP:0.5313\n",
      "Episode:215 meanR:33.1500 R:55.0000 rate:0.1100 aloss:1.3791 dloss:0.4950 aloss2:4.1612 exploreP:0.5285\n",
      "Episode:216 meanR:33.5700 R:63.0000 rate:0.1260 aloss:1.3749 dloss:0.4593 aloss2:4.1737 exploreP:0.5252\n",
      "Episode:217 meanR:33.3800 R:24.0000 rate:0.0480 aloss:1.3742 dloss:0.4713 aloss2:4.1141 exploreP:0.5240\n",
      "Episode:218 meanR:33.4900 R:43.0000 rate:0.0860 aloss:1.3785 dloss:0.4823 aloss2:4.1359 exploreP:0.5218\n",
      "Episode:219 meanR:33.4600 R:23.0000 rate:0.0460 aloss:1.3776 dloss:0.4590 aloss2:4.1351 exploreP:0.5206\n",
      "Episode:220 meanR:33.7600 R:56.0000 rate:0.1120 aloss:1.3763 dloss:0.4975 aloss2:4.1188 exploreP:0.5178\n",
      "Episode:221 meanR:34.1600 R:71.0000 rate:0.1420 aloss:1.3878 dloss:0.4758 aloss2:4.0490 exploreP:0.5142\n",
      "Episode:222 meanR:34.6200 R:62.0000 rate:0.1240 aloss:1.3741 dloss:0.4800 aloss2:4.1248 exploreP:0.5110\n",
      "Episode:223 meanR:34.9500 R:68.0000 rate:0.1360 aloss:1.3756 dloss:0.4724 aloss2:4.0901 exploreP:0.5077\n",
      "Episode:224 meanR:35.0900 R:34.0000 rate:0.0680 aloss:1.3808 dloss:0.4651 aloss2:4.1074 exploreP:0.5060\n",
      "Episode:225 meanR:35.5600 R:58.0000 rate:0.1160 aloss:1.3775 dloss:0.4604 aloss2:4.1674 exploreP:0.5031\n",
      "Episode:226 meanR:35.3000 R:23.0000 rate:0.0460 aloss:1.3781 dloss:0.4558 aloss2:4.1223 exploreP:0.5020\n",
      "Episode:227 meanR:35.6500 R:62.0000 rate:0.1240 aloss:1.3819 dloss:0.4880 aloss2:4.1561 exploreP:0.4989\n",
      "Episode:228 meanR:35.8500 R:55.0000 rate:0.1100 aloss:1.3703 dloss:0.4783 aloss2:4.1248 exploreP:0.4962\n",
      "Episode:229 meanR:36.2800 R:60.0000 rate:0.1200 aloss:1.3814 dloss:0.4783 aloss2:4.1421 exploreP:0.4933\n",
      "Episode:230 meanR:36.4100 R:43.0000 rate:0.0860 aloss:1.3858 dloss:0.4694 aloss2:4.1768 exploreP:0.4913\n",
      "Episode:231 meanR:36.9300 R:84.0000 rate:0.1680 aloss:1.3718 dloss:0.4641 aloss2:4.1699 exploreP:0.4872\n",
      "Episode:232 meanR:37.9800 R:121.0000 rate:0.2420 aloss:1.3767 dloss:0.4817 aloss2:4.1419 exploreP:0.4815\n",
      "Episode:233 meanR:39.4800 R:187.0000 rate:0.3740 aloss:1.3763 dloss:0.4782 aloss2:4.1244 exploreP:0.4728\n",
      "Episode:234 meanR:40.2300 R:113.0000 rate:0.2260 aloss:1.3737 dloss:0.4820 aloss2:4.1315 exploreP:0.4676\n",
      "Episode:235 meanR:40.0200 R:37.0000 rate:0.0740 aloss:1.3855 dloss:0.4654 aloss2:4.0895 exploreP:0.4659\n",
      "Episode:236 meanR:40.4500 R:60.0000 rate:0.1200 aloss:1.3751 dloss:0.4707 aloss2:4.1168 exploreP:0.4631\n",
      "Episode:237 meanR:40.6100 R:25.0000 rate:0.0500 aloss:1.3745 dloss:0.4576 aloss2:4.1532 exploreP:0.4620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:238 meanR:41.2100 R:92.0000 rate:0.1840 aloss:1.3795 dloss:0.4601 aloss2:4.1497 exploreP:0.4579\n",
      "Episode:239 meanR:42.6100 R:165.0000 rate:0.3300 aloss:1.3745 dloss:0.4792 aloss2:4.1601 exploreP:0.4505\n",
      "Episode:240 meanR:45.9600 R:380.0000 rate:0.7600 aloss:1.3737 dloss:0.4838 aloss2:4.1215 exploreP:0.4341\n",
      "Episode:241 meanR:47.3500 R:157.0000 rate:0.3140 aloss:1.3747 dloss:0.5299 aloss2:4.0335 exploreP:0.4275\n",
      "Episode:242 meanR:49.1300 R:212.0000 rate:0.4240 aloss:1.3793 dloss:0.4867 aloss2:4.0435 exploreP:0.4188\n",
      "Episode:243 meanR:50.4600 R:144.0000 rate:0.2880 aloss:1.3903 dloss:0.4707 aloss2:4.0773 exploreP:0.4129\n",
      "Episode:244 meanR:50.6100 R:31.0000 rate:0.0620 aloss:1.3764 dloss:0.5502 aloss2:4.0877 exploreP:0.4117\n",
      "Episode:245 meanR:51.4000 R:109.0000 rate:0.2180 aloss:1.3740 dloss:0.4974 aloss2:4.0620 exploreP:0.4073\n",
      "Episode:246 meanR:52.6800 R:155.0000 rate:0.3100 aloss:1.3785 dloss:0.5448 aloss2:4.0047 exploreP:0.4012\n",
      "Episode:247 meanR:52.5900 R:17.0000 rate:0.0340 aloss:1.3950 dloss:0.4549 aloss2:3.9441 exploreP:0.4005\n",
      "Episode:248 meanR:52.5900 R:24.0000 rate:0.0480 aloss:1.3954 dloss:0.5543 aloss2:3.9921 exploreP:0.3996\n",
      "Episode:249 meanR:53.1500 R:94.0000 rate:0.1880 aloss:1.3814 dloss:0.5118 aloss2:3.9904 exploreP:0.3959\n",
      "Episode:250 meanR:55.9100 R:291.0000 rate:0.5820 aloss:1.3841 dloss:0.5245 aloss2:3.9686 exploreP:0.3849\n",
      "Episode:251 meanR:56.0900 R:36.0000 rate:0.0720 aloss:1.4424 dloss:0.5670 aloss2:3.9552 exploreP:0.3835\n",
      "Episode:252 meanR:57.6300 R:163.0000 rate:0.3260 aloss:1.3809 dloss:0.4872 aloss2:3.9590 exploreP:0.3775\n",
      "Episode:253 meanR:58.7300 R:174.0000 rate:0.3480 aloss:1.3857 dloss:0.5187 aloss2:3.9692 exploreP:0.3712\n",
      "Episode:254 meanR:60.2400 R:192.0000 rate:0.3840 aloss:1.3761 dloss:0.5262 aloss2:3.9646 exploreP:0.3643\n",
      "Episode:255 meanR:60.8200 R:113.0000 rate:0.2260 aloss:1.3965 dloss:0.5250 aloss2:3.9264 exploreP:0.3603\n",
      "Episode:256 meanR:60.9400 R:25.0000 rate:0.0500 aloss:1.4418 dloss:0.4663 aloss2:3.9190 exploreP:0.3594\n",
      "Episode:257 meanR:60.9900 R:51.0000 rate:0.1020 aloss:1.4060 dloss:0.5322 aloss2:3.9471 exploreP:0.3577\n",
      "Episode:258 meanR:65.8000 R:500.0000 rate:1.0000 aloss:1.3981 dloss:0.5257 aloss2:3.9683 exploreP:0.3407\n",
      "Episode:259 meanR:67.0900 R:165.0000 rate:0.3300 aloss:1.4230 dloss:0.5067 aloss2:3.9203 exploreP:0.3353\n",
      "Episode:260 meanR:69.1900 R:223.0000 rate:0.4460 aloss:1.4120 dloss:0.5528 aloss2:3.9276 exploreP:0.3281\n",
      "Episode:261 meanR:70.9300 R:204.0000 rate:0.4080 aloss:1.4109 dloss:0.6488 aloss2:3.7961 exploreP:0.3217\n",
      "Episode:262 meanR:72.1800 R:163.0000 rate:0.3260 aloss:1.4355 dloss:0.5870 aloss2:3.7187 exploreP:0.3166\n",
      "Episode:263 meanR:74.4500 R:262.0000 rate:0.5240 aloss:1.4709 dloss:0.5676 aloss2:3.7596 exploreP:0.3087\n",
      "Episode:264 meanR:74.8800 R:97.0000 rate:0.1940 aloss:1.4196 dloss:0.6072 aloss2:3.7526 exploreP:0.3058\n",
      "Episode:265 meanR:77.0600 R:233.0000 rate:0.4660 aloss:1.4406 dloss:0.5820 aloss2:3.7411 exploreP:0.2990\n",
      "Episode:266 meanR:81.9700 R:500.0000 rate:1.0000 aloss:1.4574 dloss:0.5390 aloss2:3.7625 exploreP:0.2849\n",
      "Episode:267 meanR:83.9000 R:215.0000 rate:0.4300 aloss:1.4705 dloss:0.6101 aloss2:3.7904 exploreP:0.2791\n",
      "Episode:268 meanR:85.7900 R:209.0000 rate:0.4180 aloss:1.4888 dloss:0.5597 aloss2:3.7381 exploreP:0.2735\n",
      "Episode:269 meanR:87.5100 R:214.0000 rate:0.4280 aloss:1.4877 dloss:0.5437 aloss2:3.7921 exploreP:0.2679\n",
      "Episode:270 meanR:88.7300 R:185.0000 rate:0.3700 aloss:1.4731 dloss:0.6216 aloss2:3.8176 exploreP:0.2632\n",
      "Episode:271 meanR:90.3600 R:193.0000 rate:0.3860 aloss:1.4856 dloss:0.5967 aloss2:3.7361 exploreP:0.2584\n",
      "Episode:272 meanR:92.8800 R:297.0000 rate:0.5940 aloss:1.4904 dloss:0.5904 aloss2:3.7118 exploreP:0.2511\n",
      "Episode:273 meanR:94.2500 R:185.0000 rate:0.3700 aloss:1.4872 dloss:0.6194 aloss2:3.6857 exploreP:0.2467\n",
      "Episode:274 meanR:96.3100 R:232.0000 rate:0.4640 aloss:1.5023 dloss:0.6207 aloss2:3.6590 exploreP:0.2413\n",
      "Episode:275 meanR:97.9000 R:178.0000 rate:0.3560 aloss:1.5027 dloss:0.5673 aloss2:3.6873 exploreP:0.2372\n",
      "Episode:276 meanR:99.6000 R:190.0000 rate:0.3800 aloss:1.5177 dloss:0.5575 aloss2:3.6992 exploreP:0.2329\n",
      "Episode:277 meanR:101.0500 R:178.0000 rate:0.3560 aloss:1.4922 dloss:0.5636 aloss2:3.7468 exploreP:0.2290\n",
      "Episode:278 meanR:102.1700 R:138.0000 rate:0.2760 aloss:1.5189 dloss:0.5844 aloss2:3.7676 exploreP:0.2260\n",
      "Episode:279 meanR:104.6600 R:285.0000 rate:0.5700 aloss:1.4918 dloss:0.5749 aloss2:3.7389 exploreP:0.2199\n",
      "Episode:280 meanR:105.8500 R:162.0000 rate:0.3240 aloss:1.4912 dloss:0.5549 aloss2:3.7556 exploreP:0.2165\n",
      "Episode:281 meanR:107.4600 R:196.0000 rate:0.3920 aloss:1.4791 dloss:0.6215 aloss2:3.7251 exploreP:0.2125\n",
      "Episode:282 meanR:109.7400 R:258.0000 rate:0.5160 aloss:1.5010 dloss:0.6210 aloss2:3.7057 exploreP:0.2074\n",
      "Episode:283 meanR:111.4600 R:238.0000 rate:0.4760 aloss:1.4743 dloss:0.6315 aloss2:3.6408 exploreP:0.2027\n",
      "Episode:284 meanR:114.4500 R:324.0000 rate:0.6480 aloss:1.4818 dloss:0.6388 aloss2:3.6270 exploreP:0.1966\n",
      "Episode:285 meanR:116.1100 R:200.0000 rate:0.4000 aloss:1.4949 dloss:0.6581 aloss2:3.5910 exploreP:0.1929\n",
      "Episode:286 meanR:117.6100 R:185.0000 rate:0.3700 aloss:1.4996 dloss:0.5938 aloss2:3.5917 exploreP:0.1895\n",
      "Episode:287 meanR:119.7900 R:246.0000 rate:0.4920 aloss:1.4711 dloss:0.6501 aloss2:3.5763 exploreP:0.1852\n",
      "Episode:288 meanR:120.9500 R:169.0000 rate:0.3380 aloss:1.4658 dloss:0.6144 aloss2:3.5564 exploreP:0.1822\n",
      "Episode:289 meanR:123.2800 R:261.0000 rate:0.5220 aloss:1.4592 dloss:0.6140 aloss2:3.5702 exploreP:0.1778\n",
      "Episode:290 meanR:126.3100 R:321.0000 rate:0.6420 aloss:1.4660 dloss:0.6276 aloss2:3.5743 exploreP:0.1725\n",
      "Episode:291 meanR:127.8900 R:191.0000 rate:0.3820 aloss:1.4677 dloss:0.6112 aloss2:3.5810 exploreP:0.1694\n",
      "Episode:292 meanR:129.7400 R:211.0000 rate:0.4220 aloss:1.4514 dloss:0.6352 aloss2:3.5808 exploreP:0.1661\n",
      "Episode:293 meanR:134.0500 R:500.0000 rate:1.0000 aloss:1.4625 dloss:0.6611 aloss2:3.5325 exploreP:0.1585\n",
      "Episode:294 meanR:135.4400 R:164.0000 rate:0.3280 aloss:1.4554 dloss:0.6963 aloss2:3.5098 exploreP:0.1561\n",
      "Episode:295 meanR:136.9600 R:184.0000 rate:0.3680 aloss:1.4412 dloss:0.6625 aloss2:3.4771 exploreP:0.1534\n",
      "Episode:296 meanR:138.6400 R:201.0000 rate:0.4020 aloss:1.4525 dloss:0.6778 aloss2:3.4713 exploreP:0.1505\n",
      "Episode:297 meanR:140.1900 R:178.0000 rate:0.3560 aloss:1.4541 dloss:0.6759 aloss2:3.4364 exploreP:0.1481\n",
      "Episode:298 meanR:142.0200 R:207.0000 rate:0.4140 aloss:1.4678 dloss:0.6580 aloss2:3.4568 exploreP:0.1452\n",
      "Episode:299 meanR:143.6300 R:214.0000 rate:0.4280 aloss:1.4539 dloss:0.6174 aloss2:3.4652 exploreP:0.1424\n",
      "Episode:300 meanR:145.0100 R:162.0000 rate:0.3240 aloss:1.4443 dloss:0.6805 aloss2:3.4808 exploreP:0.1402\n",
      "Episode:301 meanR:146.2700 R:161.0000 rate:0.3220 aloss:1.4348 dloss:0.6742 aloss2:3.4634 exploreP:0.1382\n",
      "Episode:302 meanR:147.9800 R:193.0000 rate:0.3860 aloss:1.4572 dloss:0.6610 aloss2:3.4532 exploreP:0.1357\n",
      "Episode:303 meanR:149.5300 R:171.0000 rate:0.3420 aloss:1.4655 dloss:0.6327 aloss2:3.4582 exploreP:0.1336\n",
      "Episode:304 meanR:150.4800 R:130.0000 rate:0.2600 aloss:1.4645 dloss:0.6595 aloss2:3.4676 exploreP:0.1320\n",
      "Episode:305 meanR:151.7400 R:147.0000 rate:0.2940 aloss:1.4672 dloss:0.5892 aloss2:3.5033 exploreP:0.1302\n",
      "Episode:306 meanR:154.2500 R:311.0000 rate:0.6220 aloss:1.4436 dloss:0.6466 aloss2:3.5147 exploreP:0.1265\n",
      "Episode:307 meanR:155.3200 R:160.0000 rate:0.3200 aloss:1.4541 dloss:0.6161 aloss2:3.5284 exploreP:0.1247\n",
      "Episode:308 meanR:156.7600 R:157.0000 rate:0.3140 aloss:1.4768 dloss:0.7072 aloss2:3.5042 exploreP:0.1229\n",
      "Episode:309 meanR:158.6700 R:212.0000 rate:0.4240 aloss:1.4530 dloss:0.7165 aloss2:3.4455 exploreP:0.1205\n",
      "Episode:310 meanR:160.1700 R:233.0000 rate:0.4660 aloss:1.4690 dloss:0.6670 aloss2:3.4103 exploreP:0.1180\n",
      "Episode:311 meanR:160.7900 R:144.0000 rate:0.2880 aloss:1.4287 dloss:0.6228 aloss2:3.4624 exploreP:0.1164\n",
      "Episode:312 meanR:162.4100 R:197.0000 rate:0.3940 aloss:1.4427 dloss:0.6733 aloss2:3.4728 exploreP:0.1144\n",
      "Episode:313 meanR:162.4700 R:101.0000 rate:0.2020 aloss:1.4471 dloss:0.6714 aloss2:3.4436 exploreP:0.1133\n",
      "Episode:314 meanR:163.2500 R:138.0000 rate:0.2760 aloss:1.4454 dloss:0.6964 aloss2:3.4442 exploreP:0.1119\n",
      "Episode:315 meanR:163.8900 R:119.0000 rate:0.2380 aloss:1.4488 dloss:0.7129 aloss2:3.4207 exploreP:0.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:316 meanR:165.0300 R:177.0000 rate:0.3540 aloss:1.4329 dloss:0.6554 aloss2:3.3973 exploreP:0.1089\n",
      "Episode:317 meanR:168.2900 R:350.0000 rate:0.7000 aloss:1.4265 dloss:0.6814 aloss2:3.4244 exploreP:0.1055\n",
      "Episode:318 meanR:169.4700 R:161.0000 rate:0.3220 aloss:1.4150 dloss:0.7457 aloss2:3.3927 exploreP:0.1040\n",
      "Episode:319 meanR:171.7300 R:249.0000 rate:0.4980 aloss:1.4476 dloss:0.7048 aloss2:3.3418 exploreP:0.1017\n",
      "Episode:320 meanR:173.0300 R:186.0000 rate:0.3720 aloss:1.4373 dloss:0.7762 aloss2:3.3176 exploreP:0.1000\n",
      "Episode:321 meanR:174.8700 R:255.0000 rate:0.5100 aloss:1.4456 dloss:0.6795 aloss2:3.3126 exploreP:0.0977\n",
      "Episode:322 meanR:175.6100 R:136.0000 rate:0.2720 aloss:1.4012 dloss:0.7996 aloss2:3.2957 exploreP:0.0965\n",
      "Episode:323 meanR:176.8300 R:190.0000 rate:0.3800 aloss:1.4135 dloss:0.7427 aloss2:3.2639 exploreP:0.0949\n",
      "Episode:324 meanR:178.8400 R:235.0000 rate:0.4700 aloss:1.4513 dloss:0.6699 aloss2:3.2891 exploreP:0.0929\n",
      "Episode:325 meanR:180.6800 R:242.0000 rate:0.4840 aloss:1.4288 dloss:0.6900 aloss2:3.3178 exploreP:0.0910\n",
      "Episode:326 meanR:181.8700 R:142.0000 rate:0.2840 aloss:1.4352 dloss:0.7129 aloss2:3.3106 exploreP:0.0898\n",
      "Episode:327 meanR:182.8300 R:158.0000 rate:0.3160 aloss:1.4028 dloss:0.7482 aloss2:3.3044 exploreP:0.0886\n",
      "Episode:328 meanR:187.2800 R:500.0000 rate:1.0000 aloss:1.4258 dloss:0.7093 aloss2:3.2854 exploreP:0.0847\n",
      "Episode:329 meanR:189.0200 R:234.0000 rate:0.4680 aloss:1.4312 dloss:0.7271 aloss2:3.2808 exploreP:0.0830\n",
      "Episode:330 meanR:190.3900 R:180.0000 rate:0.3600 aloss:1.4392 dloss:0.6944 aloss2:3.2862 exploreP:0.0817\n",
      "Episode:331 meanR:191.5100 R:196.0000 rate:0.3920 aloss:1.4161 dloss:0.7737 aloss2:3.2868 exploreP:0.0803\n",
      "Episode:332 meanR:191.5300 R:123.0000 rate:0.2460 aloss:1.4218 dloss:0.6825 aloss2:3.2611 exploreP:0.0794\n",
      "Episode:333 meanR:191.8000 R:214.0000 rate:0.4280 aloss:1.4181 dloss:0.7637 aloss2:3.2624 exploreP:0.0780\n",
      "Episode:334 meanR:192.0800 R:141.0000 rate:0.2820 aloss:1.4239 dloss:0.7077 aloss2:3.2330 exploreP:0.0770\n",
      "Episode:335 meanR:195.2900 R:358.0000 rate:0.7160 aloss:1.4359 dloss:0.7366 aloss2:3.2477 exploreP:0.0747\n",
      "Episode:336 meanR:196.8000 R:211.0000 rate:0.4220 aloss:1.4095 dloss:0.7464 aloss2:3.2380 exploreP:0.0733\n",
      "Episode:337 meanR:197.7700 R:122.0000 rate:0.2440 aloss:1.4171 dloss:0.7530 aloss2:3.2293 exploreP:0.0726\n",
      "Episode:338 meanR:198.3600 R:151.0000 rate:0.3020 aloss:1.4547 dloss:0.7885 aloss2:3.2055 exploreP:0.0716\n",
      "Episode:339 meanR:201.7100 R:500.0000 rate:1.0000 aloss:1.4219 dloss:0.7527 aloss2:3.1786 exploreP:0.0686\n",
      "Episode:340 meanR:199.4200 R:151.0000 rate:0.3020 aloss:1.4131 dloss:0.7848 aloss2:3.1693 exploreP:0.0677\n",
      "Episode:341 meanR:199.0800 R:123.0000 rate:0.2460 aloss:1.4153 dloss:0.8655 aloss2:3.1424 exploreP:0.0670\n",
      "Episode:342 meanR:198.4800 R:152.0000 rate:0.3040 aloss:1.4489 dloss:0.7458 aloss2:3.1209 exploreP:0.0662\n",
      "Episode:343 meanR:198.7100 R:167.0000 rate:0.3340 aloss:1.4398 dloss:0.7257 aloss2:3.1467 exploreP:0.0652\n",
      "Episode:344 meanR:200.0400 R:164.0000 rate:0.3280 aloss:1.4272 dloss:0.7598 aloss2:3.1509 exploreP:0.0643\n",
      "Episode:345 meanR:200.5900 R:164.0000 rate:0.3280 aloss:1.3944 dloss:0.8664 aloss2:3.1347 exploreP:0.0635\n",
      "Episode:346 meanR:202.7800 R:374.0000 rate:0.7480 aloss:1.4191 dloss:0.7623 aloss2:3.1100 exploreP:0.0615\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list = [], []\n",
    "# aloss_list, dloss_list, aloss2_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0 # each episode\n",
    "        aloss_batch, dloss_batch, aloss2_batch = [], [], []\n",
    "        state = env.reset() # each episode\n",
    "        num_step = 0 # each episode\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            rate = -1\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done), rate])\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            # Rating the memory\n",
    "            if done is True:\n",
    "                rate = total_reward/500 # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.buffer[-1-idx][-1] == -1: # double-check the landmark/marked indexes\n",
    "                        memory.buffer[-1-idx][-1] = rate # rate the trajectory/data\n",
    "                        \n",
    "            # Training with the maxrated minibatch\n",
    "            batch = memory.buffer\n",
    "            #for idx in range(memory_size// batch_size):\n",
    "            idx = np.random.choice(np.arange(memory_size// batch_size))\n",
    "            states = np.array([each[0] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            actions = np.array([each[1] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            next_states = np.array([each[2] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rewards = np.array([each[3] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            dones = np.array([each[4] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rates = np.array([each[5] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            states = states[rates >= np.max(rates)]\n",
    "            actions = actions[rates >= np.max(rates)]\n",
    "            next_states = next_states[rates >= np.max(rates)]\n",
    "            rewards = rewards[rates >= np.max(rates)]\n",
    "            dones = dones[rates >= np.max(rates)]\n",
    "            rates = rates[rates >= np.max(rates)]\n",
    "            aloss, dloss, _, _ = sess.run([model.a_loss, model.d_loss, model.a_opt, model.d_opt],\n",
    "                                          feed_dict = {model.states: states, \n",
    "                                                       model.actions: actions,\n",
    "                                                       model.next_states: next_states,\n",
    "                                                       model.rewards: rewards,\n",
    "                                                       model.dones: dones,\n",
    "                                                       model.rates: rates})\n",
    "            aloss2, _ = sess.run([model.a_loss2, model.a_opt2], \n",
    "                                 feed_dict = {model.states: states, \n",
    "                                              model.actions: actions,\n",
    "                                              model.next_states: next_states,\n",
    "                                              model.rewards: rewards,\n",
    "                                              model.dones: dones,\n",
    "                                              model.rates: rates})\n",
    "            aloss_batch.append(aloss)\n",
    "            dloss_batch.append(dloss)\n",
    "            aloss2_batch.append(aloss2)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'aloss:{:.4f}'.format(np.mean(aloss_batch)),\n",
    "              'dloss:{:.4f}'.format(np.mean(dloss_batch)),\n",
    "              'aloss2:{:.4f}'.format(np.mean(aloss2_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        # gloss_list.append([ep, np.mean(gloss_batch)])\n",
    "        # dloss_list.append([ep, np.mean(dloss_batch)])\n",
    "        \n",
    "        # Break episode/epoch loop\n",
    "        ## Option 1: Solve the First Version\n",
    "        #The task is episodic, and in order to solve the environment, \n",
    "        #your agent must get an average score of +30 over 100 consecutive episodes.\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(gloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(dloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print('total_reward: {}'.format(total_reward))\n",
    "                break\n",
    "                \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

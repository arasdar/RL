{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    #states = tf.placeholder(tf.float32, [None, *state_size], name='states')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    rewards = tf.placeholder(tf.float32, [None], name='rewards')\n",
    "    dones = tf.placeholder(tf.float32, [None], name='dones')\n",
    "    rates = tf.placeholder(tf.float32, [None], name='rates') # success rate\n",
    "    return states, actions, next_states, rewards, dones, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Act(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('Act', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Env(states, actions, state_size, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('Env', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=action_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        nl1_fused = tf.concat(axis=1, values=[nl1, actions])\n",
    "        h2 = tf.layers.dense(inputs=nl1_fused, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "                \n",
    "        # Output layer\n",
    "        states_logits = tf.layers.dense(inputs=nl2, units=state_size, trainable=False)\n",
    "        Qlogits = tf.layers.dense(inputs=nl2, units=1, trainable=False)\n",
    "        return states_logits, Qlogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(state_size, action_size, hidden_size, gamma,\n",
    "               states, actions, next_states, rewards, dones, rates):\n",
    "    ################################################ a = act(s)\n",
    "    actions_logits = Act(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    aloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                      labels=actions_labels))\n",
    "    ################################################ s', r = env(s, a)\n",
    "    ################################################ s', Q = env(s, a)\n",
    "    ################################################ ~s', ~Q = env(s, ~a)\n",
    "    e_next_states_logits, eQs = Env(actions=actions_labels, states=states, hidden_size=hidden_size, \n",
    "                                    action_size=action_size, state_size=state_size)\n",
    "    a_next_states_logits, aQs = Env(actions=actions_logits, states=states, hidden_size=hidden_size, \n",
    "                                    action_size=action_size, state_size=state_size, reuse=True)\n",
    "    next_states_labels = tf.nn.sigmoid(next_states)\n",
    "    eloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=e_next_states_logits, \n",
    "                                                                   labels=next_states_labels)) # real loss\n",
    "    eloss += -tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=a_next_states_logits, \n",
    "                                                                     labels=next_states_labels)) # maximize loss\n",
    "    aloss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=a_next_states_logits, \n",
    "                                                                    labels=next_states_labels)) # minimize loss\n",
    "    eQs_logits = tf.reshape(eQs, shape=[-1])\n",
    "    aQs_logits = tf.reshape(aQs, shape=[-1])\n",
    "    eloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=eQs_logits, # GAN\n",
    "                                                                    labels=rates)) # 0-1 real\n",
    "#     eloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=aQs_logits, # GAN\n",
    "#                                                                     labels=tf.zeros_like(rates))) # min\n",
    "#     aloss2 += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=aQs_logits, # GAN\n",
    "#                                                                      labels=tf.ones_like(rates))) # max\n",
    "    #################################################### s'', Q' = ~env(s', ~a')\n",
    "    next_actions_logits = Act(states=next_states, hidden_size=hidden_size, action_size=action_size, reuse=True)\n",
    "    _, aQs2 = Env(actions=next_actions_logits, states=next_states, hidden_size=hidden_size, \n",
    "                  action_size=action_size, state_size=state_size, reuse=True)\n",
    "    aQs2_logits = tf.reshape(aQs2, shape=[-1]) * (1-dones)\n",
    "#     eloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=aQs2_logits, # GAN\n",
    "#                                                                     labels=tf.zeros_like(rates))) # min\n",
    "#     aloss2 += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=aQs2_logits, # GAN\n",
    "#                                                                      labels=tf.ones_like(rates))) # max\n",
    "    eloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=(aQs_logits+aQs2_logits)/2, # GAN\n",
    "                                                                    labels=tf.zeros_like(rates))) # min\n",
    "    aloss2 += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=(aQs_logits+aQs2_logits)/2, # GAN\n",
    "                                                                     labels=tf.ones_like(rates))) # max\n",
    "    ###################################################### Q(s,a)= r + Q'(s',a') # max\n",
    "    ###################################################### ~Q(s,~a)= r # min\n",
    "    ###################################################### ~Q(s,~a)= r + Q'(s',a') # max\n",
    "    targetQs = rewards + (gamma * aQs2_logits)\n",
    "    eloss += tf.reduce_mean(tf.square(eQs_logits - targetQs)) # real\n",
    "    eloss += tf.reduce_mean(tf.square(aQs_logits - rewards)) # minimize Q\n",
    "    aloss2 += tf.reduce_mean(tf.square(aQs_logits - targetQs)) # maximize Q\n",
    "    eloss += tf.reduce_mean(targetQs) # minimize Q\n",
    "    aloss2 += -tf.reduce_mean(targetQs) # maxizmie Q\n",
    "    eloss += tf.reduce_mean(eQs_logits) # minimize Q\n",
    "    aloss2 += -tf.reduce_mean(eQs_logits) # maxizmie Q\n",
    "    eloss += tf.reduce_mean((aQs_logits+aQs2_logits)/2) # min\n",
    "    aloss2 += -tf.reduce_mean((aQs_logits+aQs2_logits)/2) # max\n",
    "    return actions_logits, aloss, eloss, aloss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(a_loss, e_loss, a_loss2, a_learning_rate, e_learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    a_vars = [var for var in t_vars if var.name.startswith('Act')]\n",
    "    e_vars = [var for var in t_vars if var.name.startswith('Env')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        a_opt = tf.train.AdamOptimizer(a_learning_rate).minimize(a_loss, var_list=a_vars)\n",
    "        e_opt = tf.train.AdamOptimizer(e_learning_rate).minimize(e_loss, var_list=e_vars)\n",
    "        a_opt2 = tf.train.AdamOptimizer(a_learning_rate).minimize(a_loss2, var_list=a_vars)\n",
    "    return a_opt, e_opt, a_opt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, a_learning_rate, e_learning_rate, gamma):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.next_states, self.rewards, self.dones, self.rates = model_input(\n",
    "            state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.a_loss, self.e_loss, self.a_loss2 = model_loss(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, gamma=gamma, # model init\n",
    "            states=self.states, actions=self.actions, next_states=self.next_states, \n",
    "            rewards=self.rewards, dones=self.dones, rates=self.rates) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.a_opt, self.e_opt, self.a_opt2 = model_opt(a_loss=self.a_loss, \n",
    "                                                        e_loss=self.e_loss,\n",
    "                                                        a_loss2=self.a_loss2, \n",
    "                                                        a_learning_rate=a_learning_rate,\n",
    "                                                        e_learning_rate=e_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size) # data batch\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), size=batch_size, replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 4*2             # number of units in each Q-network hidden layer\n",
    "a_learning_rate = 1e-4         # Q-network learning rate\n",
    "e_learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e3)             # experience mini-batch size\n",
    "gamma=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size, gamma=gamma,\n",
    "              a_learning_rate=a_learning_rate, e_learning_rate=e_learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "total_reward = 0\n",
    "num_step = 0\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    rate = -1\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done), rate])\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        rate = total_reward/500\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.buffer[-1-idx][-1] == -1:\n",
    "                memory.buffer[-1-idx][-1] = rate\n",
    "        state = env.reset()\n",
    "        total_reward = 0 # reset\n",
    "        num_step = 0 # reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:20.0000 R:20.0000 rate:0.0400 aloss:0.7002 eloss:4.3245 aloss2:2.1319 exploreP:0.9980\n",
      "Episode:1 meanR:19.0000 R:18.0000 rate:0.0360 aloss:0.6982 eloss:4.2298 aloss2:2.2813 exploreP:0.9962\n",
      "Episode:2 meanR:21.3333 R:26.0000 rate:0.0520 aloss:0.6998 eloss:4.2404 aloss2:2.2709 exploreP:0.9937\n",
      "Episode:3 meanR:20.0000 R:16.0000 rate:0.0320 aloss:0.6963 eloss:4.2152 aloss2:2.3142 exploreP:0.9921\n",
      "Episode:4 meanR:20.2000 R:21.0000 rate:0.0420 aloss:0.6949 eloss:4.1910 aloss2:2.3700 exploreP:0.9901\n",
      "Episode:5 meanR:18.8333 R:12.0000 rate:0.0240 aloss:0.6974 eloss:4.1858 aloss2:2.3647 exploreP:0.9889\n",
      "Episode:6 meanR:17.8571 R:12.0000 rate:0.0240 aloss:0.6924 eloss:4.1757 aloss2:2.3931 exploreP:0.9877\n",
      "Episode:7 meanR:17.8750 R:18.0000 rate:0.0360 aloss:0.6935 eloss:4.1896 aloss2:2.3623 exploreP:0.9859\n",
      "Episode:8 meanR:17.3333 R:13.0000 rate:0.0260 aloss:0.6978 eloss:4.1411 aloss2:2.4381 exploreP:0.9847\n",
      "Episode:9 meanR:19.1000 R:35.0000 rate:0.0700 aloss:0.6937 eloss:4.1232 aloss2:2.5113 exploreP:0.9813\n",
      "Episode:10 meanR:21.6364 R:47.0000 rate:0.0940 aloss:0.6915 eloss:4.1017 aloss2:2.5529 exploreP:0.9767\n",
      "Episode:11 meanR:21.4167 R:19.0000 rate:0.0380 aloss:0.6946 eloss:4.0369 aloss2:2.7354 exploreP:0.9749\n",
      "Episode:12 meanR:22.1538 R:31.0000 rate:0.0620 aloss:0.6903 eloss:4.0409 aloss2:2.6864 exploreP:0.9719\n",
      "Episode:13 meanR:23.6429 R:43.0000 rate:0.0860 aloss:0.6943 eloss:4.0028 aloss2:2.8237 exploreP:0.9678\n",
      "Episode:14 meanR:23.8667 R:27.0000 rate:0.0540 aloss:0.6923 eloss:3.9843 aloss2:2.8831 exploreP:0.9652\n",
      "Episode:15 meanR:23.5000 R:18.0000 rate:0.0360 aloss:0.6839 eloss:3.9826 aloss2:2.9013 exploreP:0.9635\n",
      "Episode:16 meanR:23.1765 R:18.0000 rate:0.0360 aloss:0.6915 eloss:3.9569 aloss2:2.9748 exploreP:0.9618\n",
      "Episode:17 meanR:23.4444 R:28.0000 rate:0.0560 aloss:0.6918 eloss:3.9721 aloss2:2.8747 exploreP:0.9591\n",
      "Episode:18 meanR:24.1053 R:36.0000 rate:0.0720 aloss:0.6860 eloss:3.9614 aloss2:2.9752 exploreP:0.9557\n",
      "Episode:19 meanR:25.3500 R:49.0000 rate:0.0980 aloss:0.6862 eloss:3.9410 aloss2:3.0697 exploreP:0.9511\n",
      "Episode:20 meanR:25.5238 R:29.0000 rate:0.0580 aloss:0.6837 eloss:3.9343 aloss2:3.0491 exploreP:0.9483\n",
      "Episode:21 meanR:25.8636 R:33.0000 rate:0.0660 aloss:0.6824 eloss:3.9178 aloss2:3.1619 exploreP:0.9452\n",
      "Episode:22 meanR:25.4783 R:17.0000 rate:0.0340 aloss:0.6872 eloss:3.9032 aloss2:3.1994 exploreP:0.9437\n",
      "Episode:23 meanR:24.9583 R:13.0000 rate:0.0260 aloss:0.6844 eloss:3.9067 aloss2:3.2110 exploreP:0.9424\n",
      "Episode:24 meanR:24.6400 R:17.0000 rate:0.0340 aloss:0.6822 eloss:3.9041 aloss2:3.1450 exploreP:0.9409\n",
      "Episode:25 meanR:24.5769 R:23.0000 rate:0.0460 aloss:0.6857 eloss:3.8934 aloss2:3.2458 exploreP:0.9387\n",
      "Episode:26 meanR:24.4815 R:22.0000 rate:0.0440 aloss:0.6820 eloss:3.8975 aloss2:3.2290 exploreP:0.9367\n",
      "Episode:27 meanR:24.3214 R:20.0000 rate:0.0400 aloss:0.6825 eloss:3.9055 aloss2:3.2415 exploreP:0.9348\n",
      "Episode:28 meanR:24.4483 R:28.0000 rate:0.0560 aloss:0.6808 eloss:3.8848 aloss2:3.2612 exploreP:0.9322\n",
      "Episode:29 meanR:24.0333 R:12.0000 rate:0.0240 aloss:0.6855 eloss:3.8933 aloss2:3.3910 exploreP:0.9311\n",
      "Episode:30 meanR:23.6774 R:13.0000 rate:0.0260 aloss:0.6835 eloss:3.8692 aloss2:3.4050 exploreP:0.9299\n",
      "Episode:31 meanR:23.3438 R:13.0000 rate:0.0260 aloss:0.6794 eloss:3.8715 aloss2:3.3333 exploreP:0.9287\n",
      "Episode:32 meanR:24.0909 R:48.0000 rate:0.0960 aloss:0.6847 eloss:3.8709 aloss2:3.3937 exploreP:0.9243\n",
      "Episode:33 meanR:24.0588 R:23.0000 rate:0.0460 aloss:0.6770 eloss:3.8767 aloss2:3.3329 exploreP:0.9222\n",
      "Episode:34 meanR:24.0286 R:23.0000 rate:0.0460 aloss:0.6861 eloss:3.9148 aloss2:3.5492 exploreP:0.9201\n",
      "Episode:35 meanR:23.8333 R:17.0000 rate:0.0340 aloss:0.6866 eloss:3.8495 aloss2:3.4409 exploreP:0.9186\n",
      "Episode:36 meanR:25.1081 R:71.0000 rate:0.1420 aloss:0.6851 eloss:3.8572 aloss2:3.4728 exploreP:0.9122\n",
      "Episode:37 meanR:25.2632 R:31.0000 rate:0.0620 aloss:0.6815 eloss:3.8593 aloss2:3.4318 exploreP:0.9094\n",
      "Episode:38 meanR:24.9487 R:13.0000 rate:0.0260 aloss:0.6786 eloss:3.8755 aloss2:3.4773 exploreP:0.9082\n",
      "Episode:39 meanR:24.8750 R:22.0000 rate:0.0440 aloss:0.6860 eloss:3.8462 aloss2:3.5688 exploreP:0.9062\n",
      "Episode:40 meanR:24.6341 R:15.0000 rate:0.0300 aloss:0.6903 eloss:3.8471 aloss2:3.6149 exploreP:0.9049\n",
      "Episode:41 meanR:24.4524 R:17.0000 rate:0.0340 aloss:0.6819 eloss:3.8734 aloss2:3.5946 exploreP:0.9034\n",
      "Episode:42 meanR:24.1163 R:10.0000 rate:0.0200 aloss:0.6753 eloss:3.8274 aloss2:3.5191 exploreP:0.9025\n",
      "Episode:43 meanR:24.0000 R:19.0000 rate:0.0380 aloss:0.6851 eloss:3.9050 aloss2:3.6346 exploreP:0.9008\n",
      "Episode:44 meanR:24.8000 R:60.0000 rate:0.1200 aloss:0.6799 eloss:3.8314 aloss2:3.5550 exploreP:0.8955\n",
      "Episode:45 meanR:25.5652 R:60.0000 rate:0.1200 aloss:0.6821 eloss:3.8389 aloss2:3.6670 exploreP:0.8902\n",
      "Episode:46 meanR:25.6596 R:30.0000 rate:0.0600 aloss:0.6775 eloss:3.8275 aloss2:3.6745 exploreP:0.8875\n",
      "Episode:47 meanR:25.4583 R:16.0000 rate:0.0320 aloss:0.6892 eloss:3.8315 aloss2:3.7433 exploreP:0.8861\n",
      "Episode:48 meanR:25.2245 R:14.0000 rate:0.0280 aloss:0.6832 eloss:3.8437 aloss2:3.6133 exploreP:0.8849\n",
      "Episode:49 meanR:25.0400 R:16.0000 rate:0.0320 aloss:0.6725 eloss:3.8199 aloss2:3.5294 exploreP:0.8835\n",
      "Episode:50 meanR:24.8627 R:16.0000 rate:0.0320 aloss:0.6834 eloss:3.8215 aloss2:3.6622 exploreP:0.8821\n",
      "Episode:51 meanR:24.6923 R:16.0000 rate:0.0320 aloss:0.6903 eloss:3.8226 aloss2:3.8049 exploreP:0.8807\n",
      "Episode:52 meanR:24.3962 R:9.0000 rate:0.0180 aloss:0.6873 eloss:3.8141 aloss2:3.6779 exploreP:0.8799\n",
      "Episode:53 meanR:24.1667 R:12.0000 rate:0.0240 aloss:0.6774 eloss:3.8501 aloss2:3.6680 exploreP:0.8789\n",
      "Episode:54 meanR:24.1091 R:21.0000 rate:0.0420 aloss:0.6802 eloss:3.8215 aloss2:3.6572 exploreP:0.8771\n",
      "Episode:55 meanR:24.1964 R:29.0000 rate:0.0580 aloss:0.6759 eloss:3.8176 aloss2:3.6533 exploreP:0.8745\n",
      "Episode:56 meanR:24.1930 R:24.0000 rate:0.0480 aloss:0.6744 eloss:3.8008 aloss2:3.6784 exploreP:0.8725\n",
      "Episode:57 meanR:24.1552 R:22.0000 rate:0.0440 aloss:0.6791 eloss:3.8127 aloss2:3.6851 exploreP:0.8706\n",
      "Episode:58 meanR:24.1525 R:24.0000 rate:0.0480 aloss:0.6860 eloss:3.8039 aloss2:3.8083 exploreP:0.8685\n",
      "Episode:59 meanR:24.0167 R:16.0000 rate:0.0320 aloss:0.6765 eloss:3.8072 aloss2:3.7009 exploreP:0.8671\n",
      "Episode:60 meanR:23.8852 R:16.0000 rate:0.0320 aloss:0.6845 eloss:3.8243 aloss2:3.8121 exploreP:0.8658\n",
      "Episode:61 meanR:24.0323 R:33.0000 rate:0.0660 aloss:0.6843 eloss:3.7966 aloss2:3.8218 exploreP:0.8630\n",
      "Episode:62 meanR:24.0794 R:27.0000 rate:0.0540 aloss:0.6816 eloss:3.8035 aloss2:3.7878 exploreP:0.8607\n",
      "Episode:63 meanR:24.0469 R:22.0000 rate:0.0440 aloss:0.6746 eloss:3.8091 aloss2:3.7455 exploreP:0.8588\n",
      "Episode:64 meanR:23.9692 R:19.0000 rate:0.0380 aloss:0.6887 eloss:3.8150 aloss2:3.8378 exploreP:0.8572\n",
      "Episode:65 meanR:24.2273 R:41.0000 rate:0.0820 aloss:0.6746 eloss:3.8182 aloss2:3.8003 exploreP:0.8537\n",
      "Episode:66 meanR:24.0896 R:15.0000 rate:0.0300 aloss:0.6735 eloss:3.7885 aloss2:3.7798 exploreP:0.8524\n",
      "Episode:67 meanR:23.9412 R:14.0000 rate:0.0280 aloss:0.6740 eloss:3.7939 aloss2:3.6737 exploreP:0.8513\n",
      "Episode:68 meanR:24.0000 R:28.0000 rate:0.0560 aloss:0.6816 eloss:3.7887 aloss2:3.7701 exploreP:0.8489\n",
      "Episode:69 meanR:23.9429 R:20.0000 rate:0.0400 aloss:0.6755 eloss:3.7946 aloss2:3.7258 exploreP:0.8472\n",
      "Episode:70 meanR:24.1127 R:36.0000 rate:0.0720 aloss:0.6823 eloss:3.7916 aloss2:3.8079 exploreP:0.8442\n",
      "Episode:71 meanR:24.4722 R:50.0000 rate:0.1000 aloss:0.6847 eloss:3.7965 aloss2:3.8365 exploreP:0.8401\n",
      "Episode:72 meanR:24.6849 R:40.0000 rate:0.0800 aloss:0.6846 eloss:3.7822 aloss2:3.8421 exploreP:0.8368\n",
      "Episode:73 meanR:24.9189 R:42.0000 rate:0.0840 aloss:0.6893 eloss:3.7857 aloss2:3.8733 exploreP:0.8333\n",
      "Episode:74 meanR:25.2933 R:53.0000 rate:0.1060 aloss:0.6893 eloss:3.7784 aloss2:3.8366 exploreP:0.8289\n",
      "Episode:75 meanR:25.4474 R:37.0000 rate:0.0740 aloss:0.6796 eloss:3.7780 aloss2:3.8158 exploreP:0.8259\n",
      "Episode:76 meanR:25.3377 R:17.0000 rate:0.0340 aloss:0.6859 eloss:3.7704 aloss2:3.8429 exploreP:0.8245\n",
      "Episode:77 meanR:25.2179 R:16.0000 rate:0.0320 aloss:0.6792 eloss:3.7696 aloss2:3.8045 exploreP:0.8232\n",
      "Episode:78 meanR:25.1139 R:17.0000 rate:0.0340 aloss:0.6737 eloss:3.7734 aloss2:3.8008 exploreP:0.8218\n",
      "Episode:79 meanR:25.0875 R:23.0000 rate:0.0460 aloss:0.6986 eloss:3.7658 aloss2:3.9102 exploreP:0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:80 meanR:25.0247 R:20.0000 rate:0.0400 aloss:0.6837 eloss:3.8232 aloss2:3.9466 exploreP:0.8184\n",
      "Episode:81 meanR:25.3659 R:53.0000 rate:0.1060 aloss:0.6788 eloss:3.7743 aloss2:3.7820 exploreP:0.8141\n",
      "Episode:82 meanR:25.1807 R:10.0000 rate:0.0200 aloss:0.6826 eloss:3.7672 aloss2:3.9091 exploreP:0.8133\n",
      "Episode:83 meanR:25.1071 R:19.0000 rate:0.0380 aloss:0.6777 eloss:3.7668 aloss2:3.8231 exploreP:0.8118\n",
      "Episode:84 meanR:25.0000 R:16.0000 rate:0.0320 aloss:0.7000 eloss:3.7956 aloss2:3.8544 exploreP:0.8105\n",
      "Episode:85 meanR:25.1860 R:41.0000 rate:0.0820 aloss:0.6838 eloss:3.7731 aloss2:3.8896 exploreP:0.8072\n",
      "Episode:86 meanR:25.1724 R:24.0000 rate:0.0480 aloss:0.6992 eloss:3.8384 aloss2:3.9398 exploreP:0.8053\n",
      "Episode:87 meanR:25.0000 R:10.0000 rate:0.0200 aloss:0.7007 eloss:3.7668 aloss2:3.8308 exploreP:0.8045\n",
      "Episode:88 meanR:25.0112 R:26.0000 rate:0.0520 aloss:0.6868 eloss:3.7648 aloss2:3.8131 exploreP:0.8024\n",
      "Episode:89 meanR:25.1111 R:34.0000 rate:0.0680 aloss:0.6934 eloss:3.7681 aloss2:3.8709 exploreP:0.7997\n",
      "Episode:90 meanR:25.1429 R:28.0000 rate:0.0560 aloss:0.6876 eloss:3.7880 aloss2:3.8486 exploreP:0.7975\n",
      "Episode:91 meanR:25.1630 R:27.0000 rate:0.0540 aloss:0.6826 eloss:3.7656 aloss2:3.8059 exploreP:0.7954\n",
      "Episode:92 meanR:25.5699 R:63.0000 rate:0.1260 aloss:0.6806 eloss:3.7627 aloss2:3.8524 exploreP:0.7905\n",
      "Episode:93 meanR:25.5213 R:21.0000 rate:0.0420 aloss:0.6909 eloss:3.7551 aloss2:3.9000 exploreP:0.7888\n",
      "Episode:94 meanR:25.6000 R:33.0000 rate:0.0660 aloss:0.7001 eloss:3.7571 aloss2:3.9315 exploreP:0.7863\n",
      "Episode:95 meanR:25.9583 R:60.0000 rate:0.1200 aloss:0.6866 eloss:3.7660 aloss2:3.8894 exploreP:0.7816\n",
      "Episode:96 meanR:26.1649 R:46.0000 rate:0.0920 aloss:0.6964 eloss:3.7607 aloss2:3.9312 exploreP:0.7781\n",
      "Episode:97 meanR:26.1020 R:20.0000 rate:0.0400 aloss:0.6943 eloss:3.7786 aloss2:3.7992 exploreP:0.7766\n",
      "Episode:98 meanR:26.2323 R:39.0000 rate:0.0780 aloss:0.6922 eloss:3.7573 aloss2:3.8772 exploreP:0.7736\n",
      "Episode:99 meanR:26.1600 R:19.0000 rate:0.0380 aloss:0.6860 eloss:3.7673 aloss2:3.8513 exploreP:0.7721\n",
      "Episode:100 meanR:26.1200 R:16.0000 rate:0.0320 aloss:0.6634 eloss:3.7575 aloss2:3.8327 exploreP:0.7709\n",
      "Episode:101 meanR:26.3000 R:36.0000 rate:0.0720 aloss:0.6710 eloss:3.7611 aloss2:3.8570 exploreP:0.7682\n",
      "Episode:102 meanR:26.2400 R:20.0000 rate:0.0400 aloss:0.7046 eloss:3.7604 aloss2:3.9688 exploreP:0.7667\n",
      "Episode:103 meanR:26.5200 R:44.0000 rate:0.0880 aloss:0.6957 eloss:3.7648 aloss2:3.8875 exploreP:0.7633\n",
      "Episode:104 meanR:27.2500 R:94.0000 rate:0.1880 aloss:0.6992 eloss:3.7590 aloss2:3.9148 exploreP:0.7563\n",
      "Episode:105 meanR:27.3900 R:26.0000 rate:0.0520 aloss:0.6877 eloss:3.7560 aloss2:3.8943 exploreP:0.7543\n",
      "Episode:106 meanR:27.8200 R:55.0000 rate:0.1100 aloss:0.7065 eloss:3.7636 aloss2:3.9155 exploreP:0.7503\n",
      "Episode:107 meanR:28.2100 R:57.0000 rate:0.1140 aloss:0.7066 eloss:3.7534 aloss2:3.9049 exploreP:0.7461\n",
      "Episode:108 meanR:28.3800 R:30.0000 rate:0.0600 aloss:0.7017 eloss:3.7525 aloss2:3.9634 exploreP:0.7439\n",
      "Episode:109 meanR:28.2200 R:19.0000 rate:0.0380 aloss:0.6973 eloss:3.7510 aloss2:3.9050 exploreP:0.7425\n",
      "Episode:110 meanR:27.9900 R:24.0000 rate:0.0480 aloss:0.7122 eloss:3.7580 aloss2:3.9255 exploreP:0.7407\n",
      "Episode:111 meanR:28.2000 R:40.0000 rate:0.0800 aloss:0.7103 eloss:3.7645 aloss2:3.9399 exploreP:0.7378\n",
      "Episode:112 meanR:28.1000 R:21.0000 rate:0.0420 aloss:0.7204 eloss:3.7825 aloss2:3.9164 exploreP:0.7363\n",
      "Episode:113 meanR:28.6900 R:102.0000 rate:0.2040 aloss:0.7188 eloss:3.7573 aloss2:3.9120 exploreP:0.7289\n",
      "Episode:114 meanR:29.0200 R:60.0000 rate:0.1200 aloss:0.7181 eloss:3.7619 aloss2:3.9282 exploreP:0.7246\n",
      "Episode:115 meanR:29.3800 R:54.0000 rate:0.1080 aloss:0.6930 eloss:3.7546 aloss2:3.8820 exploreP:0.7207\n",
      "Episode:116 meanR:29.4500 R:25.0000 rate:0.0500 aloss:0.7282 eloss:3.7459 aloss2:3.9311 exploreP:0.7190\n",
      "Episode:117 meanR:29.3000 R:13.0000 rate:0.0260 aloss:0.7302 eloss:3.7505 aloss2:3.9551 exploreP:0.7180\n",
      "Episode:118 meanR:29.4100 R:47.0000 rate:0.0940 aloss:0.7322 eloss:3.7801 aloss2:3.9436 exploreP:0.7147\n",
      "Episode:119 meanR:29.2500 R:33.0000 rate:0.0660 aloss:0.7461 eloss:3.8115 aloss2:3.9602 exploreP:0.7124\n",
      "Episode:120 meanR:29.5300 R:57.0000 rate:0.1140 aloss:0.7106 eloss:3.7516 aloss2:3.8414 exploreP:0.7084\n",
      "Episode:121 meanR:29.8200 R:62.0000 rate:0.1240 aloss:0.7253 eloss:3.7474 aloss2:3.9159 exploreP:0.7041\n",
      "Episode:122 meanR:29.7800 R:13.0000 rate:0.0260 aloss:0.7148 eloss:3.7461 aloss2:3.8609 exploreP:0.7032\n",
      "Episode:123 meanR:29.8000 R:15.0000 rate:0.0300 aloss:0.7113 eloss:3.7563 aloss2:3.9134 exploreP:0.7022\n",
      "Episode:124 meanR:30.1400 R:51.0000 rate:0.1020 aloss:0.7053 eloss:3.7467 aloss2:3.9046 exploreP:0.6986\n",
      "Episode:125 meanR:30.4600 R:55.0000 rate:0.1100 aloss:0.7117 eloss:3.7478 aloss2:3.9085 exploreP:0.6949\n",
      "Episode:126 meanR:30.7200 R:48.0000 rate:0.0960 aloss:0.6956 eloss:3.7784 aloss2:3.9108 exploreP:0.6916\n",
      "Episode:127 meanR:31.8200 R:130.0000 rate:0.2600 aloss:0.7319 eloss:3.7423 aloss2:3.9341 exploreP:0.6828\n",
      "Episode:128 meanR:32.0000 R:46.0000 rate:0.0920 aloss:0.7248 eloss:3.7385 aloss2:3.9321 exploreP:0.6797\n",
      "Episode:129 meanR:32.2700 R:39.0000 rate:0.0780 aloss:0.7751 eloss:3.7828 aloss2:3.9057 exploreP:0.6771\n",
      "Episode:130 meanR:32.7200 R:58.0000 rate:0.1160 aloss:0.7252 eloss:3.7614 aloss2:3.9004 exploreP:0.6732\n",
      "Episode:131 meanR:32.9800 R:39.0000 rate:0.0780 aloss:0.7338 eloss:3.7446 aloss2:3.9146 exploreP:0.6706\n",
      "Episode:132 meanR:32.9200 R:42.0000 rate:0.0840 aloss:0.7177 eloss:3.7465 aloss2:3.9128 exploreP:0.6679\n",
      "Episode:133 meanR:32.9300 R:24.0000 rate:0.0480 aloss:0.7324 eloss:3.7470 aloss2:3.9427 exploreP:0.6663\n",
      "Episode:134 meanR:33.0400 R:34.0000 rate:0.0680 aloss:0.7372 eloss:3.7507 aloss2:3.9407 exploreP:0.6641\n",
      "Episode:135 meanR:33.3300 R:46.0000 rate:0.0920 aloss:0.7293 eloss:3.7534 aloss2:3.9189 exploreP:0.6611\n",
      "Episode:136 meanR:33.2900 R:67.0000 rate:0.1340 aloss:0.7179 eloss:3.7392 aloss2:3.9183 exploreP:0.6567\n",
      "Episode:137 meanR:33.1200 R:14.0000 rate:0.0280 aloss:0.7243 eloss:3.7440 aloss2:3.9546 exploreP:0.6558\n",
      "Episode:138 meanR:33.7300 R:74.0000 rate:0.1480 aloss:0.7135 eloss:3.7570 aloss2:3.9367 exploreP:0.6510\n",
      "Episode:139 meanR:34.6100 R:110.0000 rate:0.2200 aloss:0.7175 eloss:3.7479 aloss2:3.9289 exploreP:0.6440\n",
      "Episode:140 meanR:34.5800 R:12.0000 rate:0.0240 aloss:0.7027 eloss:3.7334 aloss2:3.9332 exploreP:0.6433\n",
      "Episode:141 meanR:35.1800 R:77.0000 rate:0.1540 aloss:0.6970 eloss:3.7446 aloss2:3.9122 exploreP:0.6384\n",
      "Episode:142 meanR:35.5500 R:47.0000 rate:0.0940 aloss:0.7302 eloss:3.7602 aloss2:3.9357 exploreP:0.6355\n",
      "Episode:143 meanR:35.6600 R:30.0000 rate:0.0600 aloss:0.7103 eloss:3.7453 aloss2:3.9174 exploreP:0.6336\n",
      "Episode:144 meanR:35.5900 R:53.0000 rate:0.1060 aloss:0.7022 eloss:3.7396 aloss2:3.9432 exploreP:0.6303\n",
      "Episode:145 meanR:35.2400 R:25.0000 rate:0.0500 aloss:0.7174 eloss:3.7511 aloss2:3.9537 exploreP:0.6288\n",
      "Episode:146 meanR:35.1900 R:25.0000 rate:0.0500 aloss:0.6918 eloss:3.7330 aloss2:3.9394 exploreP:0.6272\n",
      "Episode:147 meanR:35.6700 R:64.0000 rate:0.1280 aloss:0.7098 eloss:3.7435 aloss2:3.9253 exploreP:0.6233\n",
      "Episode:148 meanR:35.6900 R:16.0000 rate:0.0320 aloss:0.7176 eloss:3.7486 aloss2:3.9688 exploreP:0.6223\n",
      "Episode:149 meanR:36.3800 R:85.0000 rate:0.1700 aloss:0.7250 eloss:3.7480 aloss2:3.9448 exploreP:0.6171\n",
      "Episode:150 meanR:36.7200 R:50.0000 rate:0.1000 aloss:0.7290 eloss:3.7420 aloss2:3.9449 exploreP:0.6141\n",
      "Episode:151 meanR:37.1100 R:55.0000 rate:0.1100 aloss:0.7229 eloss:3.7770 aloss2:3.9461 exploreP:0.6108\n",
      "Episode:152 meanR:37.2800 R:26.0000 rate:0.0520 aloss:0.7222 eloss:3.7428 aloss2:3.9294 exploreP:0.6092\n",
      "Episode:153 meanR:37.7600 R:60.0000 rate:0.1200 aloss:0.7345 eloss:3.7527 aloss2:3.9193 exploreP:0.6056\n",
      "Episode:154 meanR:38.1000 R:55.0000 rate:0.1100 aloss:0.7470 eloss:3.7483 aloss2:3.9633 exploreP:0.6024\n",
      "Episode:155 meanR:38.0200 R:21.0000 rate:0.0420 aloss:0.7522 eloss:3.7566 aloss2:3.9518 exploreP:0.6011\n",
      "Episode:156 meanR:38.1300 R:35.0000 rate:0.0700 aloss:0.7690 eloss:3.8008 aloss2:3.9266 exploreP:0.5990\n",
      "Episode:157 meanR:38.0200 R:11.0000 rate:0.0220 aloss:0.7402 eloss:3.7533 aloss2:3.8881 exploreP:0.5984\n",
      "Episode:158 meanR:38.0000 R:22.0000 rate:0.0440 aloss:0.7319 eloss:3.7522 aloss2:3.8789 exploreP:0.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:159 meanR:37.9800 R:14.0000 rate:0.0280 aloss:0.7729 eloss:3.7703 aloss2:3.8739 exploreP:0.5963\n",
      "Episode:160 meanR:38.8800 R:106.0000 rate:0.2120 aloss:0.7243 eloss:3.7439 aloss2:3.9212 exploreP:0.5901\n",
      "Episode:161 meanR:38.9200 R:37.0000 rate:0.0740 aloss:0.7172 eloss:3.7370 aloss2:3.9527 exploreP:0.5880\n",
      "Episode:162 meanR:39.0900 R:44.0000 rate:0.0880 aloss:0.7423 eloss:3.7403 aloss2:3.9642 exploreP:0.5854\n",
      "Episode:163 meanR:39.2500 R:38.0000 rate:0.0760 aloss:0.7279 eloss:3.7414 aloss2:3.9404 exploreP:0.5832\n",
      "Episode:164 meanR:39.3400 R:28.0000 rate:0.0560 aloss:0.6991 eloss:3.7414 aloss2:3.9478 exploreP:0.5816\n",
      "Episode:165 meanR:39.2600 R:33.0000 rate:0.0660 aloss:0.7208 eloss:3.7373 aloss2:3.9396 exploreP:0.5798\n",
      "Episode:166 meanR:39.6100 R:50.0000 rate:0.1000 aloss:0.7398 eloss:3.7446 aloss2:3.9521 exploreP:0.5769\n",
      "Episode:167 meanR:39.8200 R:35.0000 rate:0.0700 aloss:0.7164 eloss:3.7612 aloss2:3.9364 exploreP:0.5749\n",
      "Episode:168 meanR:40.0300 R:49.0000 rate:0.0980 aloss:0.7076 eloss:3.7438 aloss2:3.9386 exploreP:0.5722\n",
      "Episode:169 meanR:40.2000 R:37.0000 rate:0.0740 aloss:0.7304 eloss:3.7531 aloss2:3.9511 exploreP:0.5701\n",
      "Episode:170 meanR:40.0600 R:22.0000 rate:0.0440 aloss:0.7458 eloss:3.7622 aloss2:3.9249 exploreP:0.5689\n",
      "Episode:171 meanR:39.7800 R:22.0000 rate:0.0440 aloss:0.7685 eloss:3.7840 aloss2:3.9661 exploreP:0.5676\n",
      "Episode:172 meanR:39.8800 R:50.0000 rate:0.1000 aloss:0.7162 eloss:3.7386 aloss2:3.9157 exploreP:0.5649\n",
      "Episode:173 meanR:39.7300 R:27.0000 rate:0.0540 aloss:0.7426 eloss:3.7552 aloss2:3.9369 exploreP:0.5634\n",
      "Episode:174 meanR:39.5200 R:32.0000 rate:0.0640 aloss:0.7353 eloss:3.7602 aloss2:3.9081 exploreP:0.5616\n",
      "Episode:175 meanR:39.2900 R:14.0000 rate:0.0280 aloss:0.7515 eloss:3.7495 aloss2:3.9558 exploreP:0.5608\n",
      "Episode:176 meanR:39.7200 R:60.0000 rate:0.1200 aloss:0.7623 eloss:3.7614 aloss2:3.9243 exploreP:0.5575\n",
      "Episode:177 meanR:40.0300 R:47.0000 rate:0.0940 aloss:0.7572 eloss:3.7341 aloss2:3.9369 exploreP:0.5550\n",
      "Episode:178 meanR:40.1300 R:27.0000 rate:0.0540 aloss:0.7418 eloss:3.7337 aloss2:3.9722 exploreP:0.5535\n",
      "Episode:179 meanR:40.3900 R:49.0000 rate:0.0980 aloss:0.7388 eloss:3.7652 aloss2:3.9369 exploreP:0.5508\n",
      "Episode:180 meanR:40.5900 R:40.0000 rate:0.0800 aloss:0.7412 eloss:3.7601 aloss2:3.9331 exploreP:0.5487\n",
      "Episode:181 meanR:40.2700 R:21.0000 rate:0.0420 aloss:0.7103 eloss:3.7970 aloss2:3.9197 exploreP:0.5475\n",
      "Episode:182 meanR:40.6700 R:50.0000 rate:0.1000 aloss:0.7454 eloss:3.7403 aloss2:3.9406 exploreP:0.5449\n",
      "Episode:183 meanR:40.9600 R:48.0000 rate:0.0960 aloss:0.7441 eloss:3.7630 aloss2:3.9441 exploreP:0.5423\n",
      "Episode:184 meanR:41.5800 R:78.0000 rate:0.1560 aloss:0.7336 eloss:3.7401 aloss2:3.9417 exploreP:0.5382\n",
      "Episode:185 meanR:41.5900 R:42.0000 rate:0.0840 aloss:0.7317 eloss:3.7495 aloss2:3.9601 exploreP:0.5359\n",
      "Episode:186 meanR:41.7400 R:39.0000 rate:0.0780 aloss:0.7372 eloss:3.7486 aloss2:3.9497 exploreP:0.5339\n",
      "Episode:187 meanR:42.2600 R:62.0000 rate:0.1240 aloss:0.7213 eloss:3.7584 aloss2:3.9519 exploreP:0.5307\n",
      "Episode:188 meanR:42.3600 R:36.0000 rate:0.0720 aloss:0.7162 eloss:3.7665 aloss2:3.9183 exploreP:0.5288\n",
      "Episode:189 meanR:42.2500 R:23.0000 rate:0.0460 aloss:0.7792 eloss:3.7770 aloss2:3.9443 exploreP:0.5276\n",
      "Episode:190 meanR:42.1800 R:21.0000 rate:0.0420 aloss:0.7013 eloss:3.7421 aloss2:3.9337 exploreP:0.5265\n",
      "Episode:191 meanR:42.1900 R:28.0000 rate:0.0560 aloss:0.7227 eloss:3.7365 aloss2:3.9287 exploreP:0.5251\n",
      "Episode:192 meanR:41.8200 R:26.0000 rate:0.0520 aloss:0.7187 eloss:3.7398 aloss2:3.9698 exploreP:0.5237\n",
      "Episode:193 meanR:41.8200 R:21.0000 rate:0.0420 aloss:0.7120 eloss:3.7376 aloss2:3.9286 exploreP:0.5227\n",
      "Episode:194 meanR:41.7200 R:23.0000 rate:0.0460 aloss:0.7232 eloss:3.7708 aloss2:3.9235 exploreP:0.5215\n",
      "Episode:195 meanR:41.5700 R:45.0000 rate:0.0900 aloss:0.7108 eloss:3.7391 aloss2:3.9341 exploreP:0.5192\n",
      "Episode:196 meanR:41.4300 R:32.0000 rate:0.0640 aloss:0.7283 eloss:3.7439 aloss2:3.9430 exploreP:0.5176\n",
      "Episode:197 meanR:41.5800 R:35.0000 rate:0.0700 aloss:0.7023 eloss:3.7421 aloss2:3.9571 exploreP:0.5158\n",
      "Episode:198 meanR:41.7600 R:57.0000 rate:0.1140 aloss:0.7268 eloss:3.7662 aloss2:3.9394 exploreP:0.5129\n",
      "Episode:199 meanR:41.9500 R:38.0000 rate:0.0760 aloss:0.7427 eloss:3.7404 aloss2:3.9382 exploreP:0.5110\n",
      "Episode:200 meanR:42.2200 R:43.0000 rate:0.0860 aloss:0.7467 eloss:3.7518 aloss2:3.9267 exploreP:0.5088\n",
      "Episode:201 meanR:42.0100 R:15.0000 rate:0.0300 aloss:0.8261 eloss:3.8200 aloss2:3.9207 exploreP:0.5081\n",
      "Episode:202 meanR:42.7400 R:93.0000 rate:0.1860 aloss:0.7468 eloss:3.7476 aloss2:3.9389 exploreP:0.5035\n",
      "Episode:203 meanR:42.5300 R:23.0000 rate:0.0460 aloss:0.7182 eloss:3.7529 aloss2:3.9266 exploreP:0.5024\n",
      "Episode:204 meanR:42.2600 R:67.0000 rate:0.1340 aloss:0.7173 eloss:3.7405 aloss2:3.9691 exploreP:0.4991\n",
      "Episode:205 meanR:42.3400 R:34.0000 rate:0.0680 aloss:0.7503 eloss:3.7553 aloss2:3.9862 exploreP:0.4974\n",
      "Episode:206 meanR:42.6200 R:83.0000 rate:0.1660 aloss:0.7527 eloss:3.7472 aloss2:3.9549 exploreP:0.4934\n",
      "Episode:207 meanR:42.3400 R:29.0000 rate:0.0580 aloss:0.7447 eloss:3.7436 aloss2:3.9244 exploreP:0.4920\n",
      "Episode:208 meanR:42.1800 R:14.0000 rate:0.0280 aloss:0.7248 eloss:3.7410 aloss2:3.9711 exploreP:0.4913\n",
      "Episode:209 meanR:42.3600 R:37.0000 rate:0.0740 aloss:0.7505 eloss:3.7633 aloss2:3.9976 exploreP:0.4895\n",
      "Episode:210 meanR:42.6000 R:48.0000 rate:0.0960 aloss:0.7624 eloss:3.7596 aloss2:3.9225 exploreP:0.4872\n",
      "Episode:211 meanR:42.7100 R:51.0000 rate:0.1020 aloss:0.7497 eloss:3.7707 aloss2:3.9147 exploreP:0.4848\n",
      "Episode:212 meanR:43.1000 R:60.0000 rate:0.1200 aloss:0.7472 eloss:3.7504 aloss2:3.9474 exploreP:0.4820\n",
      "Episode:213 meanR:42.7500 R:67.0000 rate:0.1340 aloss:0.7327 eloss:3.7524 aloss2:3.9521 exploreP:0.4788\n",
      "Episode:214 meanR:42.7100 R:56.0000 rate:0.1120 aloss:0.7365 eloss:3.7497 aloss2:3.9421 exploreP:0.4762\n",
      "Episode:215 meanR:42.3800 R:21.0000 rate:0.0420 aloss:0.7343 eloss:3.7388 aloss2:3.9862 exploreP:0.4752\n",
      "Episode:216 meanR:42.5400 R:41.0000 rate:0.0820 aloss:0.7418 eloss:3.7494 aloss2:3.9602 exploreP:0.4733\n",
      "Episode:217 meanR:42.6100 R:20.0000 rate:0.0400 aloss:0.7369 eloss:3.7447 aloss2:3.9508 exploreP:0.4724\n",
      "Episode:218 meanR:42.4600 R:32.0000 rate:0.0640 aloss:0.7250 eloss:3.7483 aloss2:3.9655 exploreP:0.4709\n",
      "Episode:219 meanR:42.4000 R:27.0000 rate:0.0540 aloss:0.7233 eloss:3.7402 aloss2:3.9726 exploreP:0.4697\n",
      "Episode:220 meanR:42.3300 R:50.0000 rate:0.1000 aloss:0.7193 eloss:3.7398 aloss2:3.9813 exploreP:0.4674\n",
      "Episode:221 meanR:42.0700 R:36.0000 rate:0.0720 aloss:0.7355 eloss:3.7461 aloss2:3.9541 exploreP:0.4657\n",
      "Episode:222 meanR:42.1400 R:20.0000 rate:0.0400 aloss:0.7324 eloss:3.7309 aloss2:4.0111 exploreP:0.4648\n",
      "Episode:223 meanR:42.4600 R:47.0000 rate:0.0940 aloss:0.7550 eloss:3.7543 aloss2:3.9430 exploreP:0.4627\n",
      "Episode:224 meanR:42.4600 R:51.0000 rate:0.1020 aloss:0.7592 eloss:3.7732 aloss2:3.9610 exploreP:0.4604\n",
      "Episode:225 meanR:42.3200 R:41.0000 rate:0.0820 aloss:0.7539 eloss:3.7472 aloss2:3.9632 exploreP:0.4585\n",
      "Episode:226 meanR:42.4200 R:58.0000 rate:0.1160 aloss:0.7569 eloss:3.7722 aloss2:3.9357 exploreP:0.4559\n",
      "Episode:227 meanR:41.4500 R:33.0000 rate:0.0660 aloss:0.7298 eloss:3.7907 aloss2:3.9219 exploreP:0.4545\n",
      "Episode:228 meanR:41.2600 R:27.0000 rate:0.0540 aloss:0.7334 eloss:3.7587 aloss2:3.8887 exploreP:0.4533\n",
      "Episode:229 meanR:41.0000 R:13.0000 rate:0.0260 aloss:0.7184 eloss:3.7680 aloss2:3.8758 exploreP:0.4527\n",
      "Episode:230 meanR:40.8800 R:46.0000 rate:0.0920 aloss:0.7787 eloss:3.7470 aloss2:3.9371 exploreP:0.4507\n",
      "Episode:231 meanR:40.8500 R:36.0000 rate:0.0720 aloss:0.7872 eloss:3.7870 aloss2:3.9427 exploreP:0.4491\n",
      "Episode:232 meanR:40.9700 R:54.0000 rate:0.1080 aloss:0.7753 eloss:3.7660 aloss2:3.9153 exploreP:0.4467\n",
      "Episode:233 meanR:41.2600 R:53.0000 rate:0.1060 aloss:0.7598 eloss:3.7550 aloss2:3.9251 exploreP:0.4444\n",
      "Episode:234 meanR:41.4000 R:48.0000 rate:0.0960 aloss:0.7415 eloss:3.7401 aloss2:3.9517 exploreP:0.4423\n",
      "Episode:235 meanR:41.2500 R:31.0000 rate:0.0620 aloss:0.7586 eloss:3.7653 aloss2:3.9556 exploreP:0.4410\n",
      "Episode:236 meanR:40.9100 R:33.0000 rate:0.0660 aloss:0.7232 eloss:3.7600 aloss2:3.9054 exploreP:0.4396\n",
      "Episode:237 meanR:41.2400 R:47.0000 rate:0.0940 aloss:0.7237 eloss:3.7457 aloss2:3.9777 exploreP:0.4376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:238 meanR:40.8900 R:39.0000 rate:0.0780 aloss:0.7435 eloss:3.7641 aloss2:3.9416 exploreP:0.4359\n",
      "Episode:239 meanR:40.4400 R:65.0000 rate:0.1300 aloss:0.7320 eloss:3.7555 aloss2:3.9473 exploreP:0.4331\n",
      "Episode:240 meanR:40.7400 R:42.0000 rate:0.0840 aloss:0.7305 eloss:3.7514 aloss2:3.9580 exploreP:0.4314\n",
      "Episode:241 meanR:40.4200 R:45.0000 rate:0.0900 aloss:0.7241 eloss:3.7444 aloss2:3.9755 exploreP:0.4295\n",
      "Episode:242 meanR:40.6800 R:73.0000 rate:0.1460 aloss:0.7331 eloss:3.7514 aloss2:3.9642 exploreP:0.4264\n",
      "Episode:243 meanR:40.6600 R:28.0000 rate:0.0560 aloss:0.7082 eloss:3.7355 aloss2:3.9728 exploreP:0.4253\n",
      "Episode:244 meanR:40.6300 R:50.0000 rate:0.1000 aloss:0.7334 eloss:3.7682 aloss2:3.9627 exploreP:0.4232\n",
      "Episode:245 meanR:40.8200 R:44.0000 rate:0.0880 aloss:0.7559 eloss:3.7448 aloss2:3.9621 exploreP:0.4214\n",
      "Episode:246 meanR:41.0400 R:47.0000 rate:0.0940 aloss:0.7589 eloss:3.7392 aloss2:3.9771 exploreP:0.4194\n",
      "Episode:247 meanR:40.7900 R:39.0000 rate:0.0780 aloss:0.7605 eloss:3.7779 aloss2:3.9344 exploreP:0.4179\n",
      "Episode:248 meanR:41.0600 R:43.0000 rate:0.0860 aloss:0.7509 eloss:3.7469 aloss2:3.9389 exploreP:0.4161\n",
      "Episode:249 meanR:40.5300 R:32.0000 rate:0.0640 aloss:0.7429 eloss:3.7850 aloss2:3.9345 exploreP:0.4148\n",
      "Episode:250 meanR:40.4600 R:43.0000 rate:0.0860 aloss:0.7636 eloss:3.7672 aloss2:3.9028 exploreP:0.4131\n",
      "Episode:251 meanR:40.4100 R:50.0000 rate:0.1000 aloss:0.7772 eloss:3.8017 aloss2:3.9546 exploreP:0.4111\n",
      "Episode:252 meanR:40.5500 R:40.0000 rate:0.0800 aloss:0.7421 eloss:3.7575 aloss2:3.9105 exploreP:0.4095\n",
      "Episode:253 meanR:40.3100 R:36.0000 rate:0.0720 aloss:0.7497 eloss:3.7514 aloss2:3.9276 exploreP:0.4080\n",
      "Episode:254 meanR:40.2200 R:46.0000 rate:0.0920 aloss:0.7662 eloss:3.7436 aloss2:3.9519 exploreP:0.4062\n",
      "Episode:255 meanR:40.4500 R:44.0000 rate:0.0880 aloss:0.8008 eloss:3.7907 aloss2:3.9657 exploreP:0.4045\n",
      "Episode:256 meanR:40.5300 R:43.0000 rate:0.0860 aloss:0.7458 eloss:3.7536 aloss2:3.8818 exploreP:0.4028\n",
      "Episode:257 meanR:40.8100 R:39.0000 rate:0.0780 aloss:0.7545 eloss:3.7517 aloss2:3.9262 exploreP:0.4012\n",
      "Episode:258 meanR:40.8500 R:26.0000 rate:0.0520 aloss:0.7400 eloss:3.7466 aloss2:3.9580 exploreP:0.4002\n",
      "Episode:259 meanR:41.2000 R:49.0000 rate:0.0980 aloss:0.7339 eloss:3.7460 aloss2:3.9432 exploreP:0.3983\n",
      "Episode:260 meanR:40.5600 R:42.0000 rate:0.0840 aloss:0.7351 eloss:3.7584 aloss2:3.9414 exploreP:0.3967\n",
      "Episode:261 meanR:40.5600 R:37.0000 rate:0.0740 aloss:0.7357 eloss:3.7567 aloss2:3.9417 exploreP:0.3953\n",
      "Episode:262 meanR:40.5500 R:43.0000 rate:0.0860 aloss:0.7465 eloss:3.7419 aloss2:3.9932 exploreP:0.3936\n",
      "Episode:263 meanR:40.4200 R:25.0000 rate:0.0500 aloss:0.7369 eloss:3.7556 aloss2:3.9444 exploreP:0.3926\n",
      "Episode:264 meanR:40.6400 R:50.0000 rate:0.1000 aloss:0.7241 eloss:3.7450 aloss2:3.9714 exploreP:0.3907\n",
      "Episode:265 meanR:40.7400 R:43.0000 rate:0.0860 aloss:0.7347 eloss:3.7395 aloss2:3.9947 exploreP:0.3891\n",
      "Episode:266 meanR:40.6200 R:38.0000 rate:0.0760 aloss:0.7728 eloss:3.7734 aloss2:3.9344 exploreP:0.3877\n",
      "Episode:267 meanR:40.8000 R:53.0000 rate:0.1060 aloss:0.7287 eloss:3.7456 aloss2:3.9658 exploreP:0.3857\n",
      "Episode:268 meanR:40.6200 R:31.0000 rate:0.0620 aloss:0.7482 eloss:3.7531 aloss2:3.9430 exploreP:0.3845\n",
      "Episode:269 meanR:40.6300 R:38.0000 rate:0.0760 aloss:0.7629 eloss:3.7588 aloss2:3.9625 exploreP:0.3831\n",
      "Episode:270 meanR:40.8600 R:45.0000 rate:0.0900 aloss:0.7370 eloss:3.7514 aloss2:3.9633 exploreP:0.3814\n",
      "Episode:271 meanR:40.9900 R:35.0000 rate:0.0700 aloss:0.7217 eloss:3.7604 aloss2:3.9398 exploreP:0.3801\n",
      "Episode:272 meanR:40.8400 R:35.0000 rate:0.0700 aloss:0.7481 eloss:3.7483 aloss2:3.9644 exploreP:0.3788\n",
      "Episode:273 meanR:41.0500 R:48.0000 rate:0.0960 aloss:0.7564 eloss:3.7458 aloss2:3.9648 exploreP:0.3771\n",
      "Episode:274 meanR:41.1900 R:46.0000 rate:0.0920 aloss:0.7419 eloss:3.7535 aloss2:3.9506 exploreP:0.3754\n",
      "Episode:275 meanR:41.4800 R:43.0000 rate:0.0860 aloss:0.7601 eloss:3.7448 aloss2:3.9532 exploreP:0.3738\n",
      "Episode:276 meanR:41.2800 R:40.0000 rate:0.0800 aloss:0.7342 eloss:3.7446 aloss2:3.9759 exploreP:0.3723\n",
      "Episode:277 meanR:41.1500 R:34.0000 rate:0.0680 aloss:0.7635 eloss:3.7426 aloss2:3.9636 exploreP:0.3711\n",
      "Episode:278 meanR:41.2000 R:32.0000 rate:0.0640 aloss:0.7518 eloss:3.7613 aloss2:3.9600 exploreP:0.3700\n",
      "Episode:279 meanR:41.0400 R:33.0000 rate:0.0660 aloss:0.7660 eloss:3.7466 aloss2:3.9583 exploreP:0.3688\n",
      "Episode:280 meanR:40.9900 R:35.0000 rate:0.0700 aloss:0.8018 eloss:3.7793 aloss2:3.9532 exploreP:0.3675\n",
      "Episode:281 meanR:41.3800 R:60.0000 rate:0.1200 aloss:0.7663 eloss:3.7551 aloss2:3.9426 exploreP:0.3654\n",
      "Episode:282 meanR:41.4800 R:60.0000 rate:0.1200 aloss:0.7330 eloss:3.7453 aloss2:3.9605 exploreP:0.3633\n",
      "Episode:283 meanR:41.2300 R:23.0000 rate:0.0460 aloss:0.7362 eloss:3.7621 aloss2:3.9121 exploreP:0.3624\n",
      "Episode:284 meanR:40.9900 R:54.0000 rate:0.1080 aloss:0.7419 eloss:3.7403 aloss2:3.9740 exploreP:0.3606\n",
      "Episode:285 meanR:40.9900 R:42.0000 rate:0.0840 aloss:0.7314 eloss:3.7664 aloss2:3.9690 exploreP:0.3591\n",
      "Episode:286 meanR:41.0100 R:41.0000 rate:0.0820 aloss:0.7515 eloss:3.7642 aloss2:3.9322 exploreP:0.3577\n",
      "Episode:287 meanR:40.9600 R:57.0000 rate:0.1140 aloss:0.7137 eloss:3.7535 aloss2:3.9502 exploreP:0.3557\n",
      "Episode:288 meanR:40.7600 R:16.0000 rate:0.0320 aloss:0.7709 eloss:3.7761 aloss2:3.9049 exploreP:0.3551\n",
      "Episode:289 meanR:40.9400 R:41.0000 rate:0.0820 aloss:0.7359 eloss:3.7455 aloss2:3.9426 exploreP:0.3537\n",
      "Episode:290 meanR:41.2300 R:50.0000 rate:0.1000 aloss:0.7537 eloss:3.7573 aloss2:3.9422 exploreP:0.3520\n",
      "Episode:291 meanR:41.3900 R:44.0000 rate:0.0880 aloss:0.7202 eloss:3.7414 aloss2:3.9795 exploreP:0.3505\n",
      "Episode:292 meanR:41.7300 R:60.0000 rate:0.1200 aloss:0.7282 eloss:3.7545 aloss2:3.9517 exploreP:0.3485\n",
      "Episode:293 meanR:41.8800 R:36.0000 rate:0.0720 aloss:0.7220 eloss:3.7442 aloss2:3.9678 exploreP:0.3472\n",
      "Episode:294 meanR:42.1400 R:49.0000 rate:0.0980 aloss:0.7298 eloss:3.7434 aloss2:3.9649 exploreP:0.3456\n",
      "Episode:295 meanR:42.2800 R:59.0000 rate:0.1180 aloss:0.7372 eloss:3.7486 aloss2:3.9512 exploreP:0.3436\n",
      "Episode:296 meanR:42.3800 R:42.0000 rate:0.0840 aloss:0.7326 eloss:3.7504 aloss2:3.9598 exploreP:0.3422\n",
      "Episode:297 meanR:42.3000 R:27.0000 rate:0.0540 aloss:0.7732 eloss:3.7541 aloss2:3.9616 exploreP:0.3413\n",
      "Episode:298 meanR:42.1600 R:43.0000 rate:0.0860 aloss:0.7360 eloss:3.7600 aloss2:3.9423 exploreP:0.3399\n",
      "Episode:299 meanR:42.1900 R:41.0000 rate:0.0820 aloss:0.7580 eloss:3.7607 aloss2:3.9532 exploreP:0.3386\n",
      "Episode:300 meanR:42.1300 R:37.0000 rate:0.0740 aloss:0.7453 eloss:3.7480 aloss2:3.9637 exploreP:0.3373\n",
      "Episode:301 meanR:42.5800 R:60.0000 rate:0.1200 aloss:0.7449 eloss:3.7415 aloss2:3.9776 exploreP:0.3354\n",
      "Episode:302 meanR:41.9800 R:33.0000 rate:0.0660 aloss:0.7479 eloss:3.7577 aloss2:3.9359 exploreP:0.3343\n",
      "Episode:303 meanR:42.2000 R:45.0000 rate:0.0900 aloss:0.7926 eloss:3.7746 aloss2:3.9599 exploreP:0.3329\n",
      "Episode:304 meanR:41.9400 R:41.0000 rate:0.0820 aloss:0.7442 eloss:3.7473 aloss2:3.9574 exploreP:0.3315\n",
      "Episode:305 meanR:42.0500 R:45.0000 rate:0.0900 aloss:0.7777 eloss:3.7775 aloss2:3.9260 exploreP:0.3301\n",
      "Episode:306 meanR:41.7200 R:50.0000 rate:0.1000 aloss:0.7607 eloss:3.7702 aloss2:3.9263 exploreP:0.3285\n",
      "Episode:307 meanR:42.0400 R:61.0000 rate:0.1220 aloss:0.7359 eloss:3.7384 aloss2:3.9422 exploreP:0.3266\n",
      "Episode:308 meanR:43.1500 R:125.0000 rate:0.2500 aloss:0.7370 eloss:3.7485 aloss2:3.9363 exploreP:0.3226\n",
      "Episode:309 meanR:43.2500 R:47.0000 rate:0.0940 aloss:0.7253 eloss:3.7376 aloss2:3.9739 exploreP:0.3212\n",
      "Episode:310 meanR:43.2700 R:50.0000 rate:0.1000 aloss:0.7429 eloss:3.7474 aloss2:3.9511 exploreP:0.3196\n",
      "Episode:311 meanR:43.1500 R:39.0000 rate:0.0780 aloss:0.7284 eloss:3.7475 aloss2:3.9557 exploreP:0.3184\n",
      "Episode:312 meanR:42.9700 R:42.0000 rate:0.0840 aloss:0.7495 eloss:3.7450 aloss2:3.9558 exploreP:0.3171\n",
      "Episode:313 meanR:42.8100 R:51.0000 rate:0.1020 aloss:0.7271 eloss:3.7478 aloss2:3.9495 exploreP:0.3155\n",
      "Episode:314 meanR:42.7600 R:51.0000 rate:0.1020 aloss:0.7357 eloss:3.7376 aloss2:3.9626 exploreP:0.3140\n",
      "Episode:315 meanR:43.0800 R:53.0000 rate:0.1060 aloss:0.7390 eloss:3.7433 aloss2:3.9563 exploreP:0.3124\n",
      "Episode:316 meanR:43.0200 R:35.0000 rate:0.0700 aloss:0.7790 eloss:3.7586 aloss2:3.9317 exploreP:0.3113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:317 meanR:43.1800 R:36.0000 rate:0.0720 aloss:0.7955 eloss:3.7585 aloss2:3.9370 exploreP:0.3102\n",
      "Episode:318 meanR:43.1900 R:33.0000 rate:0.0660 aloss:0.7571 eloss:3.7619 aloss2:3.9296 exploreP:0.3093\n",
      "Episode:319 meanR:43.4600 R:54.0000 rate:0.1080 aloss:0.7403 eloss:3.7487 aloss2:3.9465 exploreP:0.3076\n",
      "Episode:320 meanR:43.4100 R:45.0000 rate:0.0900 aloss:0.7599 eloss:3.7552 aloss2:3.9338 exploreP:0.3063\n",
      "Episode:321 meanR:43.5100 R:46.0000 rate:0.0920 aloss:0.7729 eloss:3.7568 aloss2:3.9562 exploreP:0.3049\n",
      "Episode:322 meanR:43.8500 R:54.0000 rate:0.1080 aloss:0.7368 eloss:3.7465 aloss2:3.9325 exploreP:0.3034\n",
      "Episode:323 meanR:43.7200 R:34.0000 rate:0.0680 aloss:0.7443 eloss:3.7416 aloss2:3.9489 exploreP:0.3024\n",
      "Episode:324 meanR:43.5300 R:32.0000 rate:0.0640 aloss:0.7349 eloss:3.7466 aloss2:3.9504 exploreP:0.3014\n",
      "Episode:325 meanR:43.9200 R:80.0000 rate:0.1600 aloss:0.7405 eloss:3.7487 aloss2:3.9468 exploreP:0.2991\n",
      "Episode:326 meanR:43.7200 R:38.0000 rate:0.0760 aloss:0.7463 eloss:3.7645 aloss2:3.9174 exploreP:0.2980\n",
      "Episode:327 meanR:43.7600 R:37.0000 rate:0.0740 aloss:0.7100 eloss:3.7480 aloss2:3.9722 exploreP:0.2969\n",
      "Episode:328 meanR:43.8200 R:33.0000 rate:0.0660 aloss:0.7518 eloss:3.7535 aloss2:3.9525 exploreP:0.2960\n",
      "Episode:329 meanR:44.1200 R:43.0000 rate:0.0860 aloss:0.7004 eloss:3.7502 aloss2:3.9488 exploreP:0.2948\n",
      "Episode:330 meanR:44.1500 R:49.0000 rate:0.0980 aloss:0.6988 eloss:3.7594 aloss2:3.9391 exploreP:0.2934\n",
      "Episode:331 meanR:44.2100 R:42.0000 rate:0.0840 aloss:0.7331 eloss:3.7640 aloss2:3.9317 exploreP:0.2922\n",
      "Episode:332 meanR:44.0300 R:36.0000 rate:0.0720 aloss:0.7369 eloss:3.7558 aloss2:3.9327 exploreP:0.2912\n",
      "Episode:333 meanR:43.9000 R:40.0000 rate:0.0800 aloss:0.7545 eloss:3.7479 aloss2:3.9242 exploreP:0.2901\n",
      "Episode:334 meanR:43.9000 R:48.0000 rate:0.0960 aloss:0.7358 eloss:3.7370 aloss2:3.9505 exploreP:0.2887\n",
      "Episode:335 meanR:44.1700 R:58.0000 rate:0.1160 aloss:0.7217 eloss:3.7637 aloss2:3.9344 exploreP:0.2871\n",
      "Episode:336 meanR:44.2600 R:42.0000 rate:0.0840 aloss:0.7482 eloss:3.7515 aloss2:3.9177 exploreP:0.2859\n",
      "Episode:337 meanR:44.2400 R:45.0000 rate:0.0900 aloss:0.7222 eloss:3.7471 aloss2:3.9345 exploreP:0.2847\n",
      "Episode:338 meanR:44.2700 R:42.0000 rate:0.0840 aloss:0.7287 eloss:3.7417 aloss2:3.9420 exploreP:0.2836\n",
      "Episode:339 meanR:43.9800 R:36.0000 rate:0.0720 aloss:0.7658 eloss:3.7449 aloss2:3.9391 exploreP:0.2826\n",
      "Episode:340 meanR:43.8800 R:32.0000 rate:0.0640 aloss:0.8081 eloss:3.7519 aloss2:3.9344 exploreP:0.2817\n",
      "Episode:341 meanR:43.9700 R:54.0000 rate:0.1080 aloss:0.7567 eloss:3.7385 aloss2:3.9496 exploreP:0.2802\n",
      "Episode:342 meanR:43.5700 R:33.0000 rate:0.0660 aloss:0.7268 eloss:3.7386 aloss2:3.9390 exploreP:0.2793\n",
      "Episode:343 meanR:43.8600 R:57.0000 rate:0.1140 aloss:0.7581 eloss:3.7571 aloss2:3.9310 exploreP:0.2778\n",
      "Episode:344 meanR:43.9200 R:56.0000 rate:0.1120 aloss:0.7397 eloss:3.7385 aloss2:3.9609 exploreP:0.2763\n",
      "Episode:345 meanR:43.9800 R:50.0000 rate:0.1000 aloss:0.7603 eloss:3.7550 aloss2:3.9438 exploreP:0.2750\n",
      "Episode:346 meanR:43.9500 R:44.0000 rate:0.0880 aloss:0.7605 eloss:3.7571 aloss2:3.9149 exploreP:0.2738\n",
      "Episode:347 meanR:44.1800 R:62.0000 rate:0.1240 aloss:0.7369 eloss:3.7440 aloss2:3.9453 exploreP:0.2722\n",
      "Episode:348 meanR:44.2300 R:48.0000 rate:0.0960 aloss:0.7228 eloss:3.7357 aloss2:3.9501 exploreP:0.2709\n",
      "Episode:349 meanR:44.4200 R:51.0000 rate:0.1020 aloss:0.7366 eloss:3.7521 aloss2:3.9394 exploreP:0.2696\n",
      "Episode:350 meanR:44.5300 R:54.0000 rate:0.1080 aloss:0.7302 eloss:3.7399 aloss2:3.9536 exploreP:0.2682\n",
      "Episode:351 meanR:44.5100 R:48.0000 rate:0.0960 aloss:0.7213 eloss:3.7379 aloss2:3.9532 exploreP:0.2670\n",
      "Episode:352 meanR:44.5100 R:40.0000 rate:0.0800 aloss:0.7295 eloss:3.7449 aloss2:3.9433 exploreP:0.2660\n",
      "Episode:353 meanR:44.6000 R:45.0000 rate:0.0900 aloss:0.7263 eloss:3.7383 aloss2:3.9455 exploreP:0.2648\n",
      "Episode:354 meanR:44.4600 R:32.0000 rate:0.0640 aloss:0.7322 eloss:3.7474 aloss2:3.9422 exploreP:0.2640\n",
      "Episode:355 meanR:44.4000 R:38.0000 rate:0.0760 aloss:0.7379 eloss:3.7479 aloss2:3.9400 exploreP:0.2630\n",
      "Episode:356 meanR:44.7300 R:76.0000 rate:0.1520 aloss:0.7596 eloss:3.7490 aloss2:3.9552 exploreP:0.2611\n",
      "Episode:357 meanR:44.7400 R:40.0000 rate:0.0800 aloss:0.7253 eloss:3.7353 aloss2:3.9459 exploreP:0.2601\n",
      "Episode:358 meanR:45.0100 R:53.0000 rate:0.1060 aloss:0.7240 eloss:3.7365 aloss2:3.9471 exploreP:0.2588\n",
      "Episode:359 meanR:45.1600 R:64.0000 rate:0.1280 aloss:0.7443 eloss:3.7721 aloss2:3.9247 exploreP:0.2572\n",
      "Episode:360 meanR:45.2100 R:47.0000 rate:0.0940 aloss:0.7528 eloss:3.7394 aloss2:3.9181 exploreP:0.2560\n",
      "Episode:361 meanR:45.1900 R:35.0000 rate:0.0700 aloss:0.7245 eloss:3.7359 aloss2:3.9232 exploreP:0.2552\n",
      "Episode:362 meanR:45.2700 R:51.0000 rate:0.1020 aloss:0.7290 eloss:3.7676 aloss2:3.9048 exploreP:0.2539\n",
      "Episode:363 meanR:45.3800 R:36.0000 rate:0.0720 aloss:0.7419 eloss:3.7401 aloss2:3.9223 exploreP:0.2531\n",
      "Episode:364 meanR:45.3200 R:44.0000 rate:0.0880 aloss:0.7406 eloss:3.7533 aloss2:3.9133 exploreP:0.2520\n",
      "Episode:365 meanR:45.3300 R:44.0000 rate:0.0880 aloss:0.7308 eloss:3.7348 aloss2:3.9337 exploreP:0.2509\n",
      "Episode:366 meanR:45.6000 R:65.0000 rate:0.1300 aloss:0.7641 eloss:3.7654 aloss2:3.9346 exploreP:0.2494\n",
      "Episode:367 meanR:45.4100 R:34.0000 rate:0.0680 aloss:0.7081 eloss:3.7308 aloss2:3.9042 exploreP:0.2486\n",
      "Episode:368 meanR:45.4600 R:36.0000 rate:0.0720 aloss:0.7465 eloss:3.7520 aloss2:3.9142 exploreP:0.2477\n",
      "Episode:369 meanR:45.4200 R:34.0000 rate:0.0680 aloss:0.7073 eloss:3.7277 aloss2:3.9215 exploreP:0.2469\n",
      "Episode:370 meanR:45.4000 R:43.0000 rate:0.0860 aloss:0.7105 eloss:3.7400 aloss2:3.9336 exploreP:0.2459\n",
      "Episode:371 meanR:45.6700 R:62.0000 rate:0.1240 aloss:0.7220 eloss:3.7331 aloss2:3.9233 exploreP:0.2444\n",
      "Episode:372 meanR:45.9400 R:62.0000 rate:0.1240 aloss:0.7444 eloss:3.7728 aloss2:3.9069 exploreP:0.2430\n",
      "Episode:373 meanR:45.9900 R:53.0000 rate:0.1060 aloss:0.7167 eloss:3.7314 aloss2:3.9317 exploreP:0.2417\n",
      "Episode:374 meanR:45.9600 R:43.0000 rate:0.0860 aloss:0.7185 eloss:3.7423 aloss2:3.9315 exploreP:0.2407\n",
      "Episode:375 meanR:45.9300 R:40.0000 rate:0.0800 aloss:0.7171 eloss:3.7365 aloss2:3.9242 exploreP:0.2398\n",
      "Episode:376 meanR:46.0700 R:54.0000 rate:0.1080 aloss:0.7353 eloss:3.7404 aloss2:3.9326 exploreP:0.2386\n",
      "Episode:377 meanR:46.1800 R:45.0000 rate:0.0900 aloss:0.7306 eloss:3.7392 aloss2:3.9510 exploreP:0.2376\n",
      "Episode:378 meanR:46.3000 R:44.0000 rate:0.0880 aloss:0.7161 eloss:3.7320 aloss2:3.9581 exploreP:0.2366\n",
      "Episode:379 meanR:46.5700 R:60.0000 rate:0.1200 aloss:0.7203 eloss:3.7369 aloss2:3.9445 exploreP:0.2352\n",
      "Episode:380 meanR:46.5000 R:28.0000 rate:0.0560 aloss:0.7190 eloss:3.7251 aloss2:3.9626 exploreP:0.2346\n",
      "Episode:381 meanR:46.5600 R:66.0000 rate:0.1320 aloss:0.7237 eloss:3.7261 aloss2:3.9522 exploreP:0.2331\n",
      "Episode:382 meanR:46.4200 R:46.0000 rate:0.0920 aloss:0.7467 eloss:3.7439 aloss2:3.9328 exploreP:0.2321\n",
      "Episode:383 meanR:46.5500 R:36.0000 rate:0.0720 aloss:0.7403 eloss:3.7350 aloss2:3.9426 exploreP:0.2313\n",
      "Episode:384 meanR:46.6100 R:60.0000 rate:0.1200 aloss:0.7122 eloss:3.7366 aloss2:3.9302 exploreP:0.2300\n",
      "Episode:385 meanR:46.6600 R:47.0000 rate:0.0940 aloss:0.7486 eloss:3.7465 aloss2:3.9234 exploreP:0.2289\n",
      "Episode:386 meanR:46.7400 R:49.0000 rate:0.0980 aloss:0.7361 eloss:3.7311 aloss2:3.9496 exploreP:0.2278\n",
      "Episode:387 meanR:46.6900 R:52.0000 rate:0.1040 aloss:0.7524 eloss:3.7477 aloss2:3.9305 exploreP:0.2267\n",
      "Episode:388 meanR:46.9700 R:44.0000 rate:0.0880 aloss:0.7563 eloss:3.7427 aloss2:3.9502 exploreP:0.2258\n",
      "Episode:389 meanR:47.0900 R:53.0000 rate:0.1060 aloss:0.7226 eloss:3.7335 aloss2:3.9274 exploreP:0.2246\n",
      "Episode:390 meanR:47.2000 R:61.0000 rate:0.1220 aloss:0.7094 eloss:3.7464 aloss2:3.9101 exploreP:0.2233\n",
      "Episode:391 meanR:47.2300 R:47.0000 rate:0.0940 aloss:0.7159 eloss:3.7334 aloss2:3.9369 exploreP:0.2223\n",
      "Episode:392 meanR:46.9600 R:33.0000 rate:0.0660 aloss:0.7606 eloss:3.7383 aloss2:3.9314 exploreP:0.2216\n",
      "Episode:393 meanR:47.0700 R:47.0000 rate:0.0940 aloss:0.7193 eloss:3.7563 aloss2:3.9150 exploreP:0.2206\n",
      "Episode:394 meanR:46.9100 R:33.0000 rate:0.0660 aloss:0.7113 eloss:3.7232 aloss2:3.9491 exploreP:0.2199\n",
      "Episode:395 meanR:46.8400 R:52.0000 rate:0.1040 aloss:0.7295 eloss:3.7311 aloss2:3.9350 exploreP:0.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:396 meanR:46.8200 R:40.0000 rate:0.0800 aloss:0.7107 eloss:3.7679 aloss2:3.9366 exploreP:0.2180\n",
      "Episode:397 meanR:46.9900 R:44.0000 rate:0.0880 aloss:0.7155 eloss:3.7303 aloss2:3.9109 exploreP:0.2171\n",
      "Episode:398 meanR:46.8800 R:32.0000 rate:0.0640 aloss:0.7382 eloss:3.7305 aloss2:3.9256 exploreP:0.2164\n",
      "Episode:399 meanR:46.8500 R:38.0000 rate:0.0760 aloss:0.7346 eloss:3.7351 aloss2:3.9334 exploreP:0.2157\n",
      "Episode:400 meanR:46.8600 R:38.0000 rate:0.0760 aloss:0.7315 eloss:3.7732 aloss2:3.9332 exploreP:0.2149\n",
      "Episode:401 meanR:46.6600 R:40.0000 rate:0.0800 aloss:0.7166 eloss:3.7272 aloss2:3.9092 exploreP:0.2141\n",
      "Episode:402 meanR:46.8400 R:51.0000 rate:0.1020 aloss:0.7179 eloss:3.7222 aloss2:3.9268 exploreP:0.2130\n",
      "Episode:403 meanR:46.7700 R:38.0000 rate:0.0760 aloss:0.7666 eloss:3.7355 aloss2:3.9293 exploreP:0.2123\n",
      "Episode:404 meanR:46.9000 R:54.0000 rate:0.1080 aloss:0.7046 eloss:3.7270 aloss2:3.9294 exploreP:0.2112\n",
      "Episode:405 meanR:46.7500 R:30.0000 rate:0.0600 aloss:0.7515 eloss:3.7755 aloss2:3.9030 exploreP:0.2106\n",
      "Episode:406 meanR:46.5700 R:32.0000 rate:0.0640 aloss:0.7361 eloss:3.7254 aloss2:3.9264 exploreP:0.2099\n",
      "Episode:407 meanR:46.5000 R:54.0000 rate:0.1080 aloss:0.7098 eloss:3.7323 aloss2:3.9150 exploreP:0.2088\n",
      "Episode:408 meanR:45.5900 R:34.0000 rate:0.0680 aloss:0.7288 eloss:3.7637 aloss2:3.9026 exploreP:0.2082\n",
      "Episode:409 meanR:45.5400 R:42.0000 rate:0.0840 aloss:0.7331 eloss:3.7339 aloss2:3.9149 exploreP:0.2073\n",
      "Episode:410 meanR:45.5900 R:55.0000 rate:0.1100 aloss:0.7290 eloss:3.7322 aloss2:3.9096 exploreP:0.2063\n",
      "Episode:411 meanR:45.4800 R:28.0000 rate:0.0560 aloss:0.7107 eloss:3.7277 aloss2:3.9185 exploreP:0.2057\n",
      "Episode:412 meanR:46.1100 R:105.0000 rate:0.2100 aloss:0.7146 eloss:3.7286 aloss2:3.9225 exploreP:0.2037\n",
      "Episode:413 meanR:46.1000 R:50.0000 rate:0.1000 aloss:0.7379 eloss:3.7305 aloss2:3.9405 exploreP:0.2027\n",
      "Episode:414 meanR:46.1800 R:59.0000 rate:0.1180 aloss:0.7078 eloss:3.7532 aloss2:3.9338 exploreP:0.2016\n",
      "Episode:415 meanR:46.2100 R:56.0000 rate:0.1120 aloss:0.6975 eloss:3.7373 aloss2:3.9134 exploreP:0.2005\n",
      "Episode:416 meanR:46.4300 R:57.0000 rate:0.1140 aloss:0.7190 eloss:3.7243 aloss2:3.9328 exploreP:0.1994\n",
      "Episode:417 meanR:46.5200 R:45.0000 rate:0.0900 aloss:0.7065 eloss:3.7538 aloss2:3.9437 exploreP:0.1986\n",
      "Episode:418 meanR:46.6200 R:43.0000 rate:0.0860 aloss:0.7033 eloss:3.7174 aloss2:3.9292 exploreP:0.1977\n",
      "Episode:419 meanR:46.3800 R:30.0000 rate:0.0600 aloss:0.7227 eloss:3.7278 aloss2:3.9232 exploreP:0.1972\n",
      "Episode:420 meanR:46.3100 R:38.0000 rate:0.0760 aloss:0.6993 eloss:3.7266 aloss2:3.9310 exploreP:0.1965\n",
      "Episode:421 meanR:46.2900 R:44.0000 rate:0.0880 aloss:0.6924 eloss:3.7569 aloss2:3.9005 exploreP:0.1957\n",
      "Episode:422 meanR:46.4200 R:67.0000 rate:0.1340 aloss:0.7133 eloss:3.7289 aloss2:3.9197 exploreP:0.1944\n",
      "Episode:423 meanR:46.7200 R:64.0000 rate:0.1280 aloss:0.7103 eloss:3.7267 aloss2:3.9254 exploreP:0.1932\n",
      "Episode:424 meanR:46.8900 R:49.0000 rate:0.0980 aloss:0.7230 eloss:3.7232 aloss2:3.9412 exploreP:0.1923\n",
      "Episode:425 meanR:46.3900 R:30.0000 rate:0.0600 aloss:0.7407 eloss:3.7284 aloss2:3.9327 exploreP:0.1918\n",
      "Episode:426 meanR:46.5000 R:49.0000 rate:0.0980 aloss:0.7217 eloss:3.7295 aloss2:3.9365 exploreP:0.1909\n",
      "Episode:427 meanR:46.5100 R:38.0000 rate:0.0760 aloss:0.7152 eloss:3.7199 aloss2:3.9275 exploreP:0.1902\n",
      "Episode:428 meanR:46.6300 R:45.0000 rate:0.0900 aloss:0.6997 eloss:3.7400 aloss2:3.9190 exploreP:0.1894\n",
      "Episode:429 meanR:46.6800 R:48.0000 rate:0.0960 aloss:0.7293 eloss:3.7265 aloss2:3.9221 exploreP:0.1886\n",
      "Episode:430 meanR:46.7300 R:54.0000 rate:0.1080 aloss:0.7074 eloss:3.7286 aloss2:3.9345 exploreP:0.1876\n",
      "Episode:431 meanR:46.7700 R:46.0000 rate:0.0920 aloss:0.7283 eloss:3.7477 aloss2:3.9090 exploreP:0.1868\n",
      "Episode:432 meanR:46.8300 R:42.0000 rate:0.0840 aloss:0.7452 eloss:3.7340 aloss2:3.8901 exploreP:0.1860\n",
      "Episode:433 meanR:47.1300 R:70.0000 rate:0.1400 aloss:0.7170 eloss:3.7609 aloss2:3.8818 exploreP:0.1848\n",
      "Episode:434 meanR:47.2200 R:57.0000 rate:0.1140 aloss:0.7247 eloss:3.7298 aloss2:3.9035 exploreP:0.1838\n",
      "Episode:435 meanR:47.2000 R:56.0000 rate:0.1120 aloss:0.7024 eloss:3.7509 aloss2:3.9007 exploreP:0.1828\n",
      "Episode:436 meanR:47.1300 R:35.0000 rate:0.0700 aloss:0.7172 eloss:3.7119 aloss2:3.9262 exploreP:0.1822\n",
      "Episode:437 meanR:47.1900 R:51.0000 rate:0.1020 aloss:0.7003 eloss:3.7197 aloss2:3.9237 exploreP:0.1814\n",
      "Episode:438 meanR:47.4600 R:69.0000 rate:0.1380 aloss:0.7080 eloss:3.7246 aloss2:3.9357 exploreP:0.1802\n",
      "Episode:439 meanR:47.5500 R:45.0000 rate:0.0900 aloss:0.7176 eloss:3.7268 aloss2:3.9260 exploreP:0.1794\n",
      "Episode:440 meanR:47.6500 R:42.0000 rate:0.0840 aloss:0.6726 eloss:3.7215 aloss2:3.9262 exploreP:0.1787\n",
      "Episode:441 meanR:47.4300 R:32.0000 rate:0.0640 aloss:0.6984 eloss:3.7307 aloss2:3.9287 exploreP:0.1782\n",
      "Episode:442 meanR:47.5000 R:40.0000 rate:0.0800 aloss:0.6981 eloss:3.7125 aloss2:3.9391 exploreP:0.1775\n",
      "Episode:443 meanR:47.3500 R:42.0000 rate:0.0840 aloss:0.6931 eloss:3.7131 aloss2:3.9473 exploreP:0.1768\n",
      "Episode:444 meanR:47.4800 R:69.0000 rate:0.1380 aloss:0.7133 eloss:3.7303 aloss2:3.9269 exploreP:0.1757\n",
      "Episode:445 meanR:47.4600 R:48.0000 rate:0.0960 aloss:0.7025 eloss:3.7307 aloss2:3.9363 exploreP:0.1749\n",
      "Episode:446 meanR:47.3600 R:34.0000 rate:0.0680 aloss:0.7017 eloss:3.7253 aloss2:3.9125 exploreP:0.1743\n",
      "Episode:447 meanR:47.2900 R:55.0000 rate:0.1100 aloss:0.6948 eloss:3.7186 aloss2:3.9119 exploreP:0.1734\n",
      "Episode:448 meanR:47.2600 R:45.0000 rate:0.0900 aloss:0.7096 eloss:3.7392 aloss2:3.9238 exploreP:0.1727\n",
      "Episode:449 meanR:47.0800 R:33.0000 rate:0.0660 aloss:0.7247 eloss:3.7247 aloss2:3.9292 exploreP:0.1721\n",
      "Episode:450 meanR:47.0200 R:48.0000 rate:0.0960 aloss:0.7028 eloss:3.7264 aloss2:3.9098 exploreP:0.1714\n",
      "Episode:451 meanR:47.3100 R:77.0000 rate:0.1540 aloss:0.6936 eloss:3.7223 aloss2:3.9215 exploreP:0.1701\n",
      "Episode:452 meanR:47.2500 R:34.0000 rate:0.0680 aloss:0.6847 eloss:3.7295 aloss2:3.9271 exploreP:0.1696\n",
      "Episode:453 meanR:47.2000 R:40.0000 rate:0.0800 aloss:0.6959 eloss:3.7228 aloss2:3.9138 exploreP:0.1689\n",
      "Episode:454 meanR:47.1700 R:29.0000 rate:0.0580 aloss:0.6937 eloss:3.7318 aloss2:3.9027 exploreP:0.1685\n",
      "Episode:455 meanR:47.2200 R:43.0000 rate:0.0860 aloss:0.7022 eloss:3.7152 aloss2:3.9388 exploreP:0.1678\n",
      "Episode:456 meanR:46.9600 R:50.0000 rate:0.1000 aloss:0.7073 eloss:3.7218 aloss2:3.9471 exploreP:0.1670\n",
      "Episode:457 meanR:46.9300 R:37.0000 rate:0.0740 aloss:0.6843 eloss:3.7150 aloss2:3.9387 exploreP:0.1664\n",
      "Episode:458 meanR:47.0100 R:61.0000 rate:0.1220 aloss:0.6946 eloss:3.7206 aloss2:3.9350 exploreP:0.1655\n",
      "Episode:459 meanR:46.7500 R:38.0000 rate:0.0760 aloss:0.6967 eloss:3.7159 aloss2:3.9364 exploreP:0.1649\n",
      "Episode:460 meanR:46.7500 R:47.0000 rate:0.0940 aloss:0.6944 eloss:3.7225 aloss2:3.9277 exploreP:0.1642\n",
      "Episode:461 meanR:48.2400 R:184.0000 rate:0.3680 aloss:0.6945 eloss:3.7216 aloss2:3.9397 exploreP:0.1614\n",
      "Episode:462 meanR:48.4200 R:69.0000 rate:0.1380 aloss:0.6935 eloss:3.7191 aloss2:3.9302 exploreP:0.1603\n",
      "Episode:463 meanR:48.6600 R:60.0000 rate:0.1200 aloss:0.6900 eloss:3.7174 aloss2:3.9365 exploreP:0.1594\n",
      "Episode:464 meanR:48.6000 R:38.0000 rate:0.0760 aloss:0.6937 eloss:3.7110 aloss2:3.9387 exploreP:0.1588\n",
      "Episode:465 meanR:48.8400 R:68.0000 rate:0.1360 aloss:0.7068 eloss:3.7246 aloss2:3.9319 exploreP:0.1578\n",
      "Episode:466 meanR:48.7600 R:57.0000 rate:0.1140 aloss:0.6877 eloss:3.7251 aloss2:3.9250 exploreP:0.1570\n",
      "Episode:467 meanR:48.8300 R:41.0000 rate:0.0820 aloss:0.7018 eloss:3.7136 aloss2:3.9244 exploreP:0.1564\n",
      "Episode:468 meanR:49.1200 R:65.0000 rate:0.1300 aloss:0.7097 eloss:3.7339 aloss2:3.9176 exploreP:0.1554\n",
      "Episode:469 meanR:51.0400 R:226.0000 rate:0.4520 aloss:0.7037 eloss:3.7223 aloss2:3.9099 exploreP:0.1522\n",
      "Episode:470 meanR:51.0400 R:43.0000 rate:0.0860 aloss:0.6901 eloss:3.7363 aloss2:3.9121 exploreP:0.1516\n",
      "Episode:471 meanR:50.9500 R:53.0000 rate:0.1060 aloss:0.6966 eloss:3.7148 aloss2:3.9184 exploreP:0.1508\n",
      "Episode:472 meanR:51.7000 R:137.0000 rate:0.2740 aloss:0.6759 eloss:3.7160 aloss2:3.9343 exploreP:0.1489\n",
      "Episode:473 meanR:51.9500 R:78.0000 rate:0.1560 aloss:0.6936 eloss:3.7178 aloss2:3.9383 exploreP:0.1478\n",
      "Episode:474 meanR:52.0100 R:49.0000 rate:0.0980 aloss:0.6910 eloss:3.7233 aloss2:3.9267 exploreP:0.1472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:475 meanR:52.5600 R:95.0000 rate:0.1900 aloss:0.6777 eloss:3.7234 aloss2:3.9279 exploreP:0.1459\n",
      "Episode:476 meanR:52.5800 R:56.0000 rate:0.1120 aloss:0.6868 eloss:3.7129 aloss2:3.9460 exploreP:0.1451\n",
      "Episode:477 meanR:52.8400 R:71.0000 rate:0.1420 aloss:0.6846 eloss:3.7213 aloss2:3.9376 exploreP:0.1442\n",
      "Episode:478 meanR:53.4300 R:103.0000 rate:0.2060 aloss:0.6864 eloss:3.7104 aloss2:3.9256 exploreP:0.1428\n",
      "Episode:479 meanR:53.5100 R:68.0000 rate:0.1360 aloss:0.7009 eloss:3.7248 aloss2:3.9291 exploreP:0.1419\n",
      "Episode:480 meanR:53.8900 R:66.0000 rate:0.1320 aloss:0.6791 eloss:3.7172 aloss2:3.9315 exploreP:0.1410\n",
      "Episode:481 meanR:54.0300 R:80.0000 rate:0.1600 aloss:0.6987 eloss:3.7281 aloss2:3.9398 exploreP:0.1400\n",
      "Episode:482 meanR:54.0100 R:44.0000 rate:0.0880 aloss:0.6881 eloss:3.7081 aloss2:3.9220 exploreP:0.1394\n",
      "Episode:483 meanR:54.1900 R:54.0000 rate:0.1080 aloss:0.7002 eloss:3.7328 aloss2:3.9089 exploreP:0.1387\n",
      "Episode:484 meanR:54.3500 R:76.0000 rate:0.1520 aloss:0.6905 eloss:3.7158 aloss2:3.9196 exploreP:0.1377\n",
      "Episode:485 meanR:55.2800 R:140.0000 rate:0.2800 aloss:0.6806 eloss:3.7181 aloss2:3.9322 exploreP:0.1360\n",
      "Episode:486 meanR:55.4600 R:67.0000 rate:0.1340 aloss:0.6924 eloss:3.7078 aloss2:3.9414 exploreP:0.1351\n",
      "Episode:487 meanR:55.3900 R:45.0000 rate:0.0900 aloss:0.6733 eloss:3.7174 aloss2:3.9278 exploreP:0.1345\n",
      "Episode:488 meanR:55.4200 R:47.0000 rate:0.0940 aloss:0.6907 eloss:3.7259 aloss2:3.9239 exploreP:0.1340\n",
      "Episode:489 meanR:55.3200 R:43.0000 rate:0.0860 aloss:0.6666 eloss:3.7135 aloss2:3.9279 exploreP:0.1334\n",
      "Episode:490 meanR:55.3900 R:68.0000 rate:0.1360 aloss:0.6997 eloss:3.7201 aloss2:3.9469 exploreP:0.1326\n",
      "Episode:491 meanR:55.4700 R:55.0000 rate:0.1100 aloss:0.6948 eloss:3.7107 aloss2:3.9398 exploreP:0.1319\n",
      "Episode:492 meanR:55.5100 R:37.0000 rate:0.0740 aloss:0.6832 eloss:3.7050 aloss2:3.9398 exploreP:0.1315\n",
      "Episode:493 meanR:55.8100 R:77.0000 rate:0.1540 aloss:0.6828 eloss:3.7207 aloss2:3.9370 exploreP:0.1305\n",
      "Episode:494 meanR:56.9100 R:143.0000 rate:0.2860 aloss:0.6851 eloss:3.7138 aloss2:3.9397 exploreP:0.1288\n",
      "Episode:495 meanR:56.9900 R:60.0000 rate:0.1200 aloss:0.6828 eloss:3.7309 aloss2:3.9200 exploreP:0.1281\n",
      "Episode:496 meanR:57.0700 R:48.0000 rate:0.0960 aloss:0.6831 eloss:3.7120 aloss2:3.9215 exploreP:0.1276\n",
      "Episode:497 meanR:57.2800 R:65.0000 rate:0.1300 aloss:0.6854 eloss:3.7176 aloss2:3.9302 exploreP:0.1268\n",
      "Episode:498 meanR:57.5800 R:62.0000 rate:0.1240 aloss:0.6838 eloss:3.7080 aloss2:3.9513 exploreP:0.1261\n",
      "Episode:499 meanR:57.9300 R:73.0000 rate:0.1460 aloss:0.6850 eloss:3.7076 aloss2:3.9501 exploreP:0.1252\n",
      "Episode:500 meanR:58.1900 R:64.0000 rate:0.1280 aloss:0.6714 eloss:3.7173 aloss2:3.9498 exploreP:0.1245\n",
      "Episode:501 meanR:58.6700 R:88.0000 rate:0.1760 aloss:0.6794 eloss:3.7127 aloss2:3.9620 exploreP:0.1235\n",
      "Episode:502 meanR:58.7300 R:57.0000 rate:0.1140 aloss:0.6654 eloss:3.7161 aloss2:3.9375 exploreP:0.1228\n",
      "Episode:503 meanR:58.9300 R:58.0000 rate:0.1160 aloss:0.6654 eloss:3.7119 aloss2:3.9523 exploreP:0.1222\n",
      "Episode:504 meanR:59.0300 R:64.0000 rate:0.1280 aloss:0.7044 eloss:3.7043 aloss2:3.9719 exploreP:0.1215\n",
      "Episode:505 meanR:59.2800 R:55.0000 rate:0.1100 aloss:0.6854 eloss:3.7060 aloss2:3.9773 exploreP:0.1209\n",
      "Episode:506 meanR:59.3600 R:40.0000 rate:0.0800 aloss:0.6646 eloss:3.7321 aloss2:3.9194 exploreP:0.1204\n",
      "Episode:507 meanR:59.5000 R:68.0000 rate:0.1360 aloss:0.6984 eloss:3.7334 aloss2:3.9349 exploreP:0.1197\n",
      "Episode:508 meanR:59.6500 R:49.0000 rate:0.0980 aloss:0.6874 eloss:3.7144 aloss2:3.9250 exploreP:0.1191\n",
      "Episode:509 meanR:60.0300 R:80.0000 rate:0.1600 aloss:0.6783 eloss:3.7124 aloss2:3.9274 exploreP:0.1183\n",
      "Episode:510 meanR:60.8800 R:140.0000 rate:0.2800 aloss:0.6731 eloss:3.7199 aloss2:3.9270 exploreP:0.1168\n",
      "Episode:511 meanR:61.0000 R:40.0000 rate:0.0800 aloss:0.6636 eloss:3.7491 aloss2:3.9055 exploreP:0.1163\n",
      "Episode:512 meanR:60.5500 R:60.0000 rate:0.1200 aloss:0.6798 eloss:3.7084 aloss2:3.9617 exploreP:0.1157\n",
      "Episode:513 meanR:60.9900 R:94.0000 rate:0.1880 aloss:0.6919 eloss:3.6994 aloss2:3.9766 exploreP:0.1147\n",
      "Episode:514 meanR:62.4200 R:202.0000 rate:0.4040 aloss:0.6827 eloss:3.7077 aloss2:3.9660 exploreP:0.1126\n",
      "Episode:515 meanR:62.5400 R:68.0000 rate:0.1360 aloss:0.6887 eloss:3.7049 aloss2:3.9696 exploreP:0.1119\n",
      "Episode:516 meanR:62.8200 R:85.0000 rate:0.1700 aloss:0.6840 eloss:3.7106 aloss2:3.9629 exploreP:0.1111\n",
      "Episode:517 meanR:63.4400 R:107.0000 rate:0.2140 aloss:0.6825 eloss:3.7137 aloss2:3.9581 exploreP:0.1100\n",
      "Episode:518 meanR:64.0200 R:101.0000 rate:0.2020 aloss:0.6786 eloss:3.7010 aloss2:3.9597 exploreP:0.1090\n",
      "Episode:519 meanR:64.6200 R:90.0000 rate:0.1800 aloss:0.6843 eloss:3.7034 aloss2:3.9768 exploreP:0.1081\n",
      "Episode:520 meanR:64.9700 R:73.0000 rate:0.1460 aloss:0.7111 eloss:3.7132 aloss2:3.9785 exploreP:0.1074\n",
      "Episode:521 meanR:64.9500 R:42.0000 rate:0.0840 aloss:0.7078 eloss:3.7114 aloss2:3.9588 exploreP:0.1070\n",
      "Episode:522 meanR:64.9400 R:66.0000 rate:0.1320 aloss:0.6731 eloss:3.7081 aloss2:3.9583 exploreP:0.1063\n",
      "Episode:523 meanR:64.9000 R:60.0000 rate:0.1200 aloss:0.6806 eloss:3.7137 aloss2:3.9805 exploreP:0.1058\n",
      "Episode:524 meanR:65.3000 R:89.0000 rate:0.1780 aloss:0.6845 eloss:3.7072 aloss2:3.9735 exploreP:0.1049\n",
      "Episode:525 meanR:66.0200 R:102.0000 rate:0.2040 aloss:0.6629 eloss:3.7181 aloss2:3.9708 exploreP:0.1039\n",
      "Episode:526 meanR:66.2200 R:69.0000 rate:0.1380 aloss:0.6710 eloss:3.7069 aloss2:3.9686 exploreP:0.1033\n",
      "Episode:527 meanR:66.4100 R:57.0000 rate:0.1140 aloss:0.6805 eloss:3.7080 aloss2:3.9726 exploreP:0.1028\n",
      "Episode:528 meanR:66.5600 R:60.0000 rate:0.1200 aloss:0.6796 eloss:3.7039 aloss2:3.9910 exploreP:0.1022\n",
      "Episode:529 meanR:67.1500 R:107.0000 rate:0.2140 aloss:0.6853 eloss:3.7106 aloss2:3.9775 exploreP:0.1012\n",
      "Episode:530 meanR:67.9000 R:129.0000 rate:0.2580 aloss:0.6746 eloss:3.6990 aloss2:3.9822 exploreP:0.1001\n",
      "Episode:531 meanR:68.3100 R:87.0000 rate:0.1740 aloss:0.6726 eloss:3.7037 aloss2:3.9745 exploreP:0.0993\n",
      "Episode:532 meanR:69.1100 R:122.0000 rate:0.2440 aloss:0.6774 eloss:3.7193 aloss2:3.9692 exploreP:0.0982\n",
      "Episode:533 meanR:69.8000 R:139.0000 rate:0.2780 aloss:0.6936 eloss:3.7247 aloss2:3.9549 exploreP:0.0970\n",
      "Episode:534 meanR:69.9700 R:74.0000 rate:0.1480 aloss:0.6855 eloss:3.7079 aloss2:3.9602 exploreP:0.0963\n",
      "Episode:535 meanR:70.0800 R:67.0000 rate:0.1340 aloss:0.6886 eloss:3.6986 aloss2:3.9866 exploreP:0.0958\n",
      "Episode:536 meanR:71.1200 R:139.0000 rate:0.2780 aloss:0.6658 eloss:3.7120 aloss2:3.9773 exploreP:0.0946\n",
      "Episode:537 meanR:71.8200 R:121.0000 rate:0.2420 aloss:0.6817 eloss:3.6986 aloss2:4.0059 exploreP:0.0936\n",
      "Episode:538 meanR:71.8200 R:69.0000 rate:0.1380 aloss:0.6799 eloss:3.7164 aloss2:3.9880 exploreP:0.0930\n",
      "Episode:539 meanR:72.0400 R:67.0000 rate:0.1340 aloss:0.6856 eloss:3.7055 aloss2:3.9948 exploreP:0.0924\n",
      "Episode:540 meanR:72.6300 R:101.0000 rate:0.2020 aloss:0.6919 eloss:3.6974 aloss2:4.0031 exploreP:0.0916\n",
      "Episode:541 meanR:73.5200 R:121.0000 rate:0.2420 aloss:0.6882 eloss:3.7085 aloss2:3.9900 exploreP:0.0906\n",
      "Episode:542 meanR:74.2000 R:108.0000 rate:0.2160 aloss:0.6889 eloss:3.7200 aloss2:3.9950 exploreP:0.0898\n",
      "Episode:543 meanR:75.3500 R:157.0000 rate:0.3140 aloss:0.6810 eloss:3.7087 aloss2:3.9581 exploreP:0.0885\n",
      "Episode:544 meanR:75.7500 R:109.0000 rate:0.2180 aloss:0.6853 eloss:3.7021 aloss2:3.9965 exploreP:0.0877\n",
      "Episode:545 meanR:76.1900 R:92.0000 rate:0.1840 aloss:0.6828 eloss:3.7055 aloss2:3.9880 exploreP:0.0870\n",
      "Episode:546 meanR:76.3300 R:48.0000 rate:0.0960 aloss:0.6931 eloss:3.7012 aloss2:3.9951 exploreP:0.0866\n",
      "Episode:547 meanR:76.1900 R:41.0000 rate:0.0820 aloss:0.6778 eloss:3.6958 aloss2:4.0023 exploreP:0.0863\n",
      "Episode:548 meanR:76.7400 R:100.0000 rate:0.2000 aloss:0.6756 eloss:3.7135 aloss2:3.9804 exploreP:0.0855\n",
      "Episode:549 meanR:77.5700 R:116.0000 rate:0.2320 aloss:0.6703 eloss:3.7184 aloss2:3.9457 exploreP:0.0846\n",
      "Episode:550 meanR:78.3000 R:121.0000 rate:0.2420 aloss:0.6726 eloss:3.7066 aloss2:3.9740 exploreP:0.0837\n",
      "Episode:551 meanR:78.9600 R:143.0000 rate:0.2860 aloss:0.6705 eloss:3.7037 aloss2:3.9950 exploreP:0.0827\n",
      "Episode:552 meanR:79.7400 R:112.0000 rate:0.2240 aloss:0.6644 eloss:3.7195 aloss2:3.9995 exploreP:0.0819\n",
      "Episode:553 meanR:80.7500 R:141.0000 rate:0.2820 aloss:0.6829 eloss:3.6964 aloss2:4.0070 exploreP:0.0809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:554 meanR:81.5800 R:112.0000 rate:0.2240 aloss:0.6767 eloss:3.7012 aloss2:4.0338 exploreP:0.0801\n",
      "Episode:555 meanR:82.7300 R:158.0000 rate:0.3160 aloss:0.6796 eloss:3.6995 aloss2:4.0236 exploreP:0.0790\n",
      "Episode:556 meanR:83.3400 R:111.0000 rate:0.2220 aloss:0.6756 eloss:3.6954 aloss2:4.0360 exploreP:0.0782\n",
      "Episode:557 meanR:84.0900 R:112.0000 rate:0.2240 aloss:0.6817 eloss:3.7045 aloss2:4.0311 exploreP:0.0775\n",
      "Episode:558 meanR:83.9000 R:42.0000 rate:0.0840 aloss:0.6651 eloss:3.6909 aloss2:4.0272 exploreP:0.0772\n",
      "Episode:559 meanR:84.6700 R:115.0000 rate:0.2300 aloss:0.6595 eloss:3.6948 aloss2:4.0371 exploreP:0.0764\n",
      "Episode:560 meanR:85.4000 R:120.0000 rate:0.2400 aloss:0.6753 eloss:3.6975 aloss2:4.0393 exploreP:0.0756\n",
      "Episode:561 meanR:84.8300 R:127.0000 rate:0.2540 aloss:0.6771 eloss:3.6883 aloss2:4.0418 exploreP:0.0748\n",
      "Episode:562 meanR:85.0600 R:92.0000 rate:0.1840 aloss:0.6706 eloss:3.7126 aloss2:4.0241 exploreP:0.0742\n",
      "Episode:563 meanR:86.0000 R:154.0000 rate:0.3080 aloss:0.6651 eloss:3.7004 aloss2:4.0459 exploreP:0.0732\n",
      "Episode:564 meanR:87.0100 R:139.0000 rate:0.2780 aloss:0.6826 eloss:3.6829 aloss2:4.0572 exploreP:0.0724\n",
      "Episode:565 meanR:88.1500 R:182.0000 rate:0.3640 aloss:0.6634 eloss:3.7100 aloss2:4.0369 exploreP:0.0712\n",
      "Episode:566 meanR:88.8600 R:128.0000 rate:0.2560 aloss:0.6644 eloss:3.6888 aloss2:4.0648 exploreP:0.0704\n",
      "Episode:567 meanR:89.2500 R:80.0000 rate:0.1600 aloss:0.6615 eloss:3.7076 aloss2:4.0454 exploreP:0.0700\n",
      "Episode:568 meanR:89.5300 R:93.0000 rate:0.1860 aloss:0.6871 eloss:3.6877 aloss2:4.0628 exploreP:0.0694\n",
      "Episode:569 meanR:88.7500 R:148.0000 rate:0.2960 aloss:0.6635 eloss:3.6821 aloss2:4.0470 exploreP:0.0685\n",
      "Episode:570 meanR:89.7900 R:147.0000 rate:0.2940 aloss:0.6766 eloss:3.6811 aloss2:4.0771 exploreP:0.0677\n",
      "Episode:571 meanR:90.8300 R:157.0000 rate:0.3140 aloss:0.6628 eloss:3.6914 aloss2:4.0809 exploreP:0.0668\n",
      "Episode:572 meanR:90.9700 R:151.0000 rate:0.3020 aloss:0.6694 eloss:3.6908 aloss2:4.0753 exploreP:0.0659\n",
      "Episode:573 meanR:91.5900 R:140.0000 rate:0.2800 aloss:0.6599 eloss:3.6906 aloss2:4.0763 exploreP:0.0652\n",
      "Episode:574 meanR:92.6600 R:156.0000 rate:0.3120 aloss:0.6639 eloss:3.6902 aloss2:4.0837 exploreP:0.0643\n",
      "Episode:575 meanR:93.5700 R:186.0000 rate:0.3720 aloss:0.6643 eloss:3.7006 aloss2:4.0697 exploreP:0.0633\n",
      "Episode:576 meanR:94.9500 R:194.0000 rate:0.3880 aloss:0.6611 eloss:3.6914 aloss2:4.0711 exploreP:0.0623\n",
      "Episode:577 meanR:95.6500 R:141.0000 rate:0.2820 aloss:0.6639 eloss:3.6916 aloss2:4.0774 exploreP:0.0615\n",
      "Episode:578 meanR:96.0000 R:138.0000 rate:0.2760 aloss:0.6751 eloss:3.6862 aloss2:4.0894 exploreP:0.0608\n",
      "Episode:579 meanR:96.7200 R:140.0000 rate:0.2800 aloss:0.6666 eloss:3.6802 aloss2:4.1136 exploreP:0.0601\n",
      "Episode:580 meanR:97.5700 R:151.0000 rate:0.3020 aloss:0.6706 eloss:3.6831 aloss2:4.1099 exploreP:0.0594\n",
      "Episode:581 meanR:98.6100 R:184.0000 rate:0.3680 aloss:0.6708 eloss:3.6877 aloss2:4.0930 exploreP:0.0585\n",
      "Episode:582 meanR:99.2600 R:109.0000 rate:0.2180 aloss:0.6827 eloss:3.6819 aloss2:4.1100 exploreP:0.0580\n",
      "Episode:583 meanR:100.2000 R:148.0000 rate:0.2960 aloss:0.6512 eloss:3.7071 aloss2:4.0998 exploreP:0.0573\n",
      "Episode:584 meanR:101.1300 R:169.0000 rate:0.3380 aloss:0.6503 eloss:3.6878 aloss2:4.0965 exploreP:0.0565\n",
      "Episode:585 meanR:101.6100 R:188.0000 rate:0.3760 aloss:0.6632 eloss:3.6943 aloss2:4.1105 exploreP:0.0556\n",
      "Episode:586 meanR:101.6600 R:72.0000 rate:0.1440 aloss:0.6560 eloss:3.6944 aloss2:4.0790 exploreP:0.0553\n",
      "Episode:587 meanR:101.7700 R:56.0000 rate:0.1120 aloss:0.6558 eloss:3.6914 aloss2:4.1010 exploreP:0.0550\n",
      "Episode:588 meanR:102.8100 R:151.0000 rate:0.3020 aloss:0.6550 eloss:3.6893 aloss2:4.0840 exploreP:0.0543\n",
      "Episode:589 meanR:103.8800 R:150.0000 rate:0.3000 aloss:0.6609 eloss:3.6769 aloss2:4.1188 exploreP:0.0537\n",
      "Episode:590 meanR:104.8900 R:169.0000 rate:0.3380 aloss:0.6725 eloss:3.6783 aloss2:4.1255 exploreP:0.0529\n",
      "Episode:591 meanR:105.8700 R:153.0000 rate:0.3060 aloss:0.6433 eloss:3.6836 aloss2:4.1195 exploreP:0.0523\n",
      "Episode:592 meanR:106.8300 R:133.0000 rate:0.2660 aloss:0.6556 eloss:3.6903 aloss2:4.1167 exploreP:0.0517\n",
      "Episode:593 meanR:107.6100 R:155.0000 rate:0.3100 aloss:0.6678 eloss:3.7035 aloss2:4.1080 exploreP:0.0511\n",
      "Episode:594 meanR:107.6900 R:151.0000 rate:0.3020 aloss:0.6527 eloss:3.6872 aloss2:4.0924 exploreP:0.0505\n",
      "Episode:595 meanR:108.3100 R:122.0000 rate:0.2440 aloss:0.6591 eloss:3.7007 aloss2:4.1296 exploreP:0.0500\n",
      "Episode:596 meanR:108.4100 R:58.0000 rate:0.1160 aloss:0.6890 eloss:3.6666 aloss2:4.1235 exploreP:0.0498\n",
      "Episode:597 meanR:109.1100 R:135.0000 rate:0.2700 aloss:0.6606 eloss:3.6754 aloss2:4.1337 exploreP:0.0492\n",
      "Episode:598 meanR:110.0700 R:158.0000 rate:0.3160 aloss:0.6673 eloss:3.7004 aloss2:4.1292 exploreP:0.0486\n",
      "Episode:599 meanR:109.9000 R:56.0000 rate:0.1120 aloss:0.6622 eloss:3.6756 aloss2:4.1372 exploreP:0.0484\n",
      "Episode:600 meanR:110.8500 R:159.0000 rate:0.3180 aloss:0.6596 eloss:3.6854 aloss2:4.1421 exploreP:0.0478\n",
      "Episode:601 meanR:111.5500 R:158.0000 rate:0.3160 aloss:0.6515 eloss:3.6952 aloss2:4.1356 exploreP:0.0472\n",
      "Episode:602 meanR:112.6000 R:162.0000 rate:0.3240 aloss:0.6448 eloss:3.6990 aloss2:4.1075 exploreP:0.0466\n",
      "Episode:603 meanR:113.5000 R:148.0000 rate:0.2960 aloss:0.6613 eloss:3.6705 aloss2:4.1675 exploreP:0.0461\n",
      "Episode:604 meanR:114.1800 R:132.0000 rate:0.2640 aloss:0.6671 eloss:3.6698 aloss2:4.1673 exploreP:0.0456\n",
      "Episode:605 meanR:115.0700 R:144.0000 rate:0.2880 aloss:0.6809 eloss:3.6832 aloss2:4.1473 exploreP:0.0451\n",
      "Episode:606 meanR:116.6300 R:196.0000 rate:0.3920 aloss:0.6532 eloss:3.6740 aloss2:4.1532 exploreP:0.0444\n",
      "Episode:607 meanR:117.7200 R:177.0000 rate:0.3540 aloss:0.6541 eloss:3.6674 aloss2:4.1837 exploreP:0.0438\n",
      "Episode:608 meanR:118.6400 R:141.0000 rate:0.2820 aloss:0.6684 eloss:3.6736 aloss2:4.1763 exploreP:0.0433\n",
      "Episode:609 meanR:119.7900 R:195.0000 rate:0.3900 aloss:0.6533 eloss:3.6817 aloss2:4.1625 exploreP:0.0427\n",
      "Episode:610 meanR:119.9200 R:153.0000 rate:0.3060 aloss:0.6559 eloss:3.6718 aloss2:4.1885 exploreP:0.0422\n",
      "Episode:611 meanR:121.1400 R:162.0000 rate:0.3240 aloss:0.6684 eloss:3.6720 aloss2:4.1795 exploreP:0.0417\n",
      "Episode:612 meanR:122.3400 R:180.0000 rate:0.3600 aloss:0.6620 eloss:3.6708 aloss2:4.2030 exploreP:0.0411\n",
      "Episode:613 meanR:122.9700 R:157.0000 rate:0.3140 aloss:0.6512 eloss:3.6730 aloss2:4.1939 exploreP:0.0406\n",
      "Episode:614 meanR:122.5400 R:159.0000 rate:0.3180 aloss:0.6491 eloss:3.6795 aloss2:4.1983 exploreP:0.0401\n",
      "Episode:615 meanR:123.2700 R:141.0000 rate:0.2820 aloss:0.6541 eloss:3.6790 aloss2:4.1840 exploreP:0.0397\n",
      "Episode:616 meanR:123.8700 R:145.0000 rate:0.2900 aloss:0.6610 eloss:3.6920 aloss2:4.1547 exploreP:0.0393\n",
      "Episode:617 meanR:124.4000 R:160.0000 rate:0.3200 aloss:0.6557 eloss:3.6701 aloss2:4.1748 exploreP:0.0388\n",
      "Episode:618 meanR:125.1300 R:174.0000 rate:0.3480 aloss:0.6551 eloss:3.6827 aloss2:4.1989 exploreP:0.0383\n",
      "Episode:619 meanR:126.1100 R:188.0000 rate:0.3760 aloss:0.6554 eloss:3.6738 aloss2:4.2258 exploreP:0.0378\n",
      "Episode:620 meanR:127.1200 R:174.0000 rate:0.3480 aloss:0.6540 eloss:3.6636 aloss2:4.2222 exploreP:0.0373\n",
      "Episode:621 meanR:128.2900 R:159.0000 rate:0.3180 aloss:0.6386 eloss:3.6713 aloss2:4.2204 exploreP:0.0369\n",
      "Episode:622 meanR:129.2400 R:161.0000 rate:0.3220 aloss:0.6567 eloss:3.6894 aloss2:4.1963 exploreP:0.0365\n",
      "Episode:623 meanR:130.0300 R:139.0000 rate:0.2780 aloss:0.6562 eloss:3.6743 aloss2:4.1967 exploreP:0.0361\n",
      "Episode:624 meanR:130.6200 R:148.0000 rate:0.2960 aloss:0.6462 eloss:3.6744 aloss2:4.2195 exploreP:0.0357\n",
      "Episode:625 meanR:131.4800 R:188.0000 rate:0.3760 aloss:0.6578 eloss:3.6675 aloss2:4.2373 exploreP:0.0352\n",
      "Episode:626 meanR:132.4400 R:165.0000 rate:0.3300 aloss:0.6382 eloss:3.6895 aloss2:4.1954 exploreP:0.0348\n",
      "Episode:627 meanR:133.1800 R:131.0000 rate:0.2620 aloss:0.6571 eloss:3.6529 aloss2:4.2308 exploreP:0.0345\n",
      "Episode:628 meanR:133.7800 R:120.0000 rate:0.2400 aloss:0.6279 eloss:3.6830 aloss2:4.2161 exploreP:0.0342\n",
      "Episode:629 meanR:134.0100 R:130.0000 rate:0.2600 aloss:0.6465 eloss:3.6725 aloss2:4.2402 exploreP:0.0339\n",
      "Episode:630 meanR:134.0200 R:130.0000 rate:0.2600 aloss:0.6608 eloss:3.6657 aloss2:4.2284 exploreP:0.0336\n",
      "Episode:631 meanR:134.5500 R:140.0000 rate:0.2800 aloss:0.6468 eloss:3.6662 aloss2:4.2600 exploreP:0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:632 meanR:134.5900 R:126.0000 rate:0.2520 aloss:0.6548 eloss:3.6768 aloss2:4.2703 exploreP:0.0330\n",
      "Episode:633 meanR:135.1500 R:195.0000 rate:0.3900 aloss:0.6374 eloss:3.6831 aloss2:4.2281 exploreP:0.0325\n",
      "Episode:634 meanR:135.7000 R:129.0000 rate:0.2580 aloss:0.6477 eloss:3.6723 aloss2:4.2127 exploreP:0.0322\n",
      "Episode:635 meanR:136.6000 R:157.0000 rate:0.3140 aloss:0.6403 eloss:3.6705 aloss2:4.2378 exploreP:0.0319\n",
      "Episode:636 meanR:136.8400 R:163.0000 rate:0.3260 aloss:0.6494 eloss:3.6741 aloss2:4.2609 exploreP:0.0315\n",
      "Episode:637 meanR:137.4900 R:186.0000 rate:0.3720 aloss:0.6539 eloss:3.6702 aloss2:4.2753 exploreP:0.0311\n",
      "Episode:638 meanR:137.9100 R:111.0000 rate:0.2220 aloss:0.6245 eloss:3.6778 aloss2:4.2573 exploreP:0.0309\n",
      "Episode:639 meanR:138.6200 R:138.0000 rate:0.2760 aloss:0.6669 eloss:3.6647 aloss2:4.2866 exploreP:0.0306\n",
      "Episode:640 meanR:139.0300 R:142.0000 rate:0.2840 aloss:0.6550 eloss:3.6567 aloss2:4.2816 exploreP:0.0303\n",
      "Episode:641 meanR:138.9700 R:115.0000 rate:0.2300 aloss:0.6204 eloss:3.6808 aloss2:4.2281 exploreP:0.0301\n",
      "Episode:642 meanR:138.9700 R:108.0000 rate:0.2160 aloss:0.6515 eloss:3.6536 aloss2:4.2589 exploreP:0.0299\n",
      "Episode:643 meanR:138.7900 R:139.0000 rate:0.2780 aloss:0.6542 eloss:3.6553 aloss2:4.2715 exploreP:0.0296\n",
      "Episode:644 meanR:139.0700 R:137.0000 rate:0.2740 aloss:0.6503 eloss:3.6649 aloss2:4.3045 exploreP:0.0293\n",
      "Episode:645 meanR:139.4300 R:128.0000 rate:0.2560 aloss:0.6207 eloss:3.6795 aloss2:4.2950 exploreP:0.0291\n",
      "Episode:646 meanR:140.1600 R:121.0000 rate:0.2420 aloss:0.6383 eloss:3.6744 aloss2:4.2692 exploreP:0.0289\n",
      "Episode:647 meanR:141.3400 R:159.0000 rate:0.3180 aloss:0.6597 eloss:3.6742 aloss2:4.2920 exploreP:0.0286\n",
      "Episode:648 meanR:141.0200 R:68.0000 rate:0.1360 aloss:0.6384 eloss:3.6593 aloss2:4.2945 exploreP:0.0284\n",
      "Episode:649 meanR:141.1100 R:125.0000 rate:0.2500 aloss:0.6553 eloss:3.6706 aloss2:4.2766 exploreP:0.0282\n",
      "Episode:650 meanR:141.2600 R:136.0000 rate:0.2720 aloss:0.6167 eloss:3.6717 aloss2:4.2834 exploreP:0.0280\n",
      "Episode:651 meanR:141.0900 R:126.0000 rate:0.2520 aloss:0.6324 eloss:3.6782 aloss2:4.2495 exploreP:0.0277\n",
      "Episode:652 meanR:141.0700 R:110.0000 rate:0.2200 aloss:0.6368 eloss:3.6737 aloss2:4.2735 exploreP:0.0275\n",
      "Episode:653 meanR:140.9900 R:133.0000 rate:0.2660 aloss:0.6243 eloss:3.6794 aloss2:4.2705 exploreP:0.0273\n",
      "Episode:654 meanR:141.9200 R:205.0000 rate:0.4100 aloss:0.6358 eloss:3.6710 aloss2:4.2883 exploreP:0.0270\n",
      "Episode:655 meanR:141.6800 R:134.0000 rate:0.2680 aloss:0.6331 eloss:3.6729 aloss2:4.2760 exploreP:0.0267\n",
      "Episode:656 meanR:141.9100 R:134.0000 rate:0.2680 aloss:0.6396 eloss:3.6695 aloss2:4.2885 exploreP:0.0265\n",
      "Episode:657 meanR:142.2100 R:142.0000 rate:0.2840 aloss:0.6372 eloss:3.6588 aloss2:4.3179 exploreP:0.0263\n",
      "Episode:658 meanR:143.2100 R:142.0000 rate:0.2840 aloss:0.6209 eloss:3.6916 aloss2:4.2629 exploreP:0.0260\n",
      "Episode:659 meanR:143.3200 R:126.0000 rate:0.2520 aloss:0.6074 eloss:3.6949 aloss2:4.2326 exploreP:0.0258\n",
      "Episode:660 meanR:143.3600 R:124.0000 rate:0.2480 aloss:0.6210 eloss:3.6713 aloss2:4.3251 exploreP:0.0256\n",
      "Episode:661 meanR:143.8000 R:171.0000 rate:0.3420 aloss:0.6403 eloss:3.6722 aloss2:4.2908 exploreP:0.0254\n",
      "Episode:662 meanR:143.8600 R:98.0000 rate:0.1960 aloss:0.6534 eloss:3.6738 aloss2:4.3121 exploreP:0.0252\n",
      "Episode:663 meanR:144.2000 R:188.0000 rate:0.3760 aloss:0.6302 eloss:3.6697 aloss2:4.2842 exploreP:0.0249\n",
      "Episode:664 meanR:143.9900 R:118.0000 rate:0.2360 aloss:0.6067 eloss:3.6783 aloss2:4.3050 exploreP:0.0248\n",
      "Episode:665 meanR:143.6500 R:148.0000 rate:0.2960 aloss:0.6403 eloss:3.6614 aloss2:4.3245 exploreP:0.0246\n",
      "Episode:666 meanR:143.4600 R:109.0000 rate:0.2180 aloss:0.6321 eloss:3.6874 aloss2:4.3148 exploreP:0.0244\n",
      "Episode:667 meanR:143.9000 R:124.0000 rate:0.2480 aloss:0.6360 eloss:3.6720 aloss2:4.3053 exploreP:0.0242\n",
      "Episode:668 meanR:144.3700 R:140.0000 rate:0.2800 aloss:0.6302 eloss:3.6676 aloss2:4.3029 exploreP:0.0240\n",
      "Episode:669 meanR:144.3900 R:150.0000 rate:0.3000 aloss:0.6393 eloss:3.6686 aloss2:4.3143 exploreP:0.0238\n",
      "Episode:670 meanR:144.1600 R:124.0000 rate:0.2480 aloss:0.6385 eloss:3.6549 aloss2:4.2878 exploreP:0.0236\n",
      "Episode:671 meanR:143.8800 R:129.0000 rate:0.2580 aloss:0.6212 eloss:3.6654 aloss2:4.3131 exploreP:0.0235\n",
      "Episode:672 meanR:143.4400 R:107.0000 rate:0.2140 aloss:0.6069 eloss:3.6672 aloss2:4.3408 exploreP:0.0233\n",
      "Episode:673 meanR:143.3500 R:131.0000 rate:0.2620 aloss:0.6290 eloss:3.6649 aloss2:4.3203 exploreP:0.0232\n",
      "Episode:674 meanR:143.2300 R:144.0000 rate:0.2880 aloss:0.6274 eloss:3.6736 aloss2:4.2985 exploreP:0.0230\n",
      "Episode:675 meanR:142.6900 R:132.0000 rate:0.2640 aloss:0.6257 eloss:3.6694 aloss2:4.3335 exploreP:0.0228\n",
      "Episode:676 meanR:141.9900 R:124.0000 rate:0.2480 aloss:0.6314 eloss:3.6664 aloss2:4.3498 exploreP:0.0226\n",
      "Episode:677 meanR:142.6900 R:211.0000 rate:0.4220 aloss:0.6111 eloss:3.6802 aloss2:4.3262 exploreP:0.0224\n",
      "Episode:678 meanR:142.8800 R:157.0000 rate:0.3140 aloss:0.6204 eloss:3.6644 aloss2:4.3249 exploreP:0.0222\n",
      "Episode:679 meanR:142.6700 R:119.0000 rate:0.2380 aloss:0.6371 eloss:3.6562 aloss2:4.3460 exploreP:0.0220\n",
      "Episode:680 meanR:142.2800 R:112.0000 rate:0.2240 aloss:0.6039 eloss:3.6779 aloss2:4.3136 exploreP:0.0219\n",
      "Episode:681 meanR:142.0000 R:156.0000 rate:0.3120 aloss:0.6225 eloss:3.6739 aloss2:4.3409 exploreP:0.0217\n",
      "Episode:682 meanR:142.2600 R:135.0000 rate:0.2700 aloss:0.6162 eloss:3.6832 aloss2:4.3265 exploreP:0.0216\n",
      "Episode:683 meanR:142.2000 R:142.0000 rate:0.2840 aloss:0.6306 eloss:3.6721 aloss2:4.3328 exploreP:0.0214\n",
      "Episode:684 meanR:141.9500 R:144.0000 rate:0.2880 aloss:0.6249 eloss:3.6739 aloss2:4.3039 exploreP:0.0212\n",
      "Episode:685 meanR:141.3900 R:132.0000 rate:0.2640 aloss:0.6350 eloss:3.6535 aloss2:4.3302 exploreP:0.0211\n",
      "Episode:686 meanR:142.0700 R:140.0000 rate:0.2800 aloss:0.6285 eloss:3.6677 aloss2:4.3384 exploreP:0.0209\n",
      "Episode:687 meanR:142.7100 R:120.0000 rate:0.2400 aloss:0.6164 eloss:3.6778 aloss2:4.3409 exploreP:0.0208\n",
      "Episode:688 meanR:142.4700 R:127.0000 rate:0.2540 aloss:0.6268 eloss:3.6640 aloss2:4.3463 exploreP:0.0207\n",
      "Episode:689 meanR:142.1300 R:116.0000 rate:0.2320 aloss:0.5954 eloss:3.6891 aloss2:4.3067 exploreP:0.0205\n",
      "Episode:690 meanR:141.8100 R:137.0000 rate:0.2740 aloss:0.6101 eloss:3.6808 aloss2:4.3215 exploreP:0.0204\n",
      "Episode:691 meanR:142.1500 R:187.0000 rate:0.3740 aloss:0.6269 eloss:3.6596 aloss2:4.3489 exploreP:0.0202\n",
      "Episode:692 meanR:142.0900 R:127.0000 rate:0.2540 aloss:0.6009 eloss:3.6794 aloss2:4.3070 exploreP:0.0201\n",
      "Episode:693 meanR:141.7000 R:116.0000 rate:0.2320 aloss:0.6141 eloss:3.6727 aloss2:4.3426 exploreP:0.0200\n",
      "Episode:694 meanR:141.6900 R:150.0000 rate:0.3000 aloss:0.6242 eloss:3.6696 aloss2:4.3579 exploreP:0.0198\n",
      "Episode:695 meanR:142.3100 R:184.0000 rate:0.3680 aloss:0.5993 eloss:3.6975 aloss2:4.2975 exploreP:0.0196\n",
      "Episode:696 meanR:142.8800 R:115.0000 rate:0.2300 aloss:0.6117 eloss:3.6800 aloss2:4.3291 exploreP:0.0195\n",
      "Episode:697 meanR:142.9300 R:140.0000 rate:0.2800 aloss:0.5942 eloss:3.6810 aloss2:4.3316 exploreP:0.0194\n",
      "Episode:698 meanR:143.1900 R:184.0000 rate:0.3680 aloss:0.6155 eloss:3.6644 aloss2:4.3486 exploreP:0.0192\n",
      "Episode:699 meanR:144.2500 R:162.0000 rate:0.3240 aloss:0.6210 eloss:3.6624 aloss2:4.3550 exploreP:0.0191\n",
      "Episode:700 meanR:144.2100 R:155.0000 rate:0.3100 aloss:0.6140 eloss:3.6606 aloss2:4.3938 exploreP:0.0189\n",
      "Episode:701 meanR:143.9900 R:136.0000 rate:0.2720 aloss:0.6004 eloss:3.6763 aloss2:4.3517 exploreP:0.0188\n",
      "Episode:702 meanR:144.0400 R:167.0000 rate:0.3340 aloss:0.6019 eloss:3.6855 aloss2:4.3245 exploreP:0.0187\n",
      "Episode:703 meanR:144.0000 R:144.0000 rate:0.2880 aloss:0.6059 eloss:3.6853 aloss2:4.3476 exploreP:0.0185\n",
      "Episode:704 meanR:145.2600 R:258.0000 rate:0.5160 aloss:0.6214 eloss:3.6708 aloss2:4.3427 exploreP:0.0183\n",
      "Episode:705 meanR:145.3400 R:152.0000 rate:0.3040 aloss:0.5926 eloss:3.6841 aloss2:4.3276 exploreP:0.0182\n",
      "Episode:706 meanR:145.2700 R:189.0000 rate:0.3780 aloss:0.6013 eloss:3.6640 aloss2:4.3620 exploreP:0.0180\n",
      "Episode:707 meanR:144.8800 R:138.0000 rate:0.2760 aloss:0.6134 eloss:3.6606 aloss2:4.3809 exploreP:0.0179\n",
      "Episode:708 meanR:146.0500 R:258.0000 rate:0.5160 aloss:0.5998 eloss:3.6840 aloss2:4.3694 exploreP:0.0177\n",
      "Episode:709 meanR:145.8800 R:178.0000 rate:0.3560 aloss:0.6143 eloss:3.6703 aloss2:4.3838 exploreP:0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:710 meanR:146.1900 R:184.0000 rate:0.3680 aloss:0.5926 eloss:3.6726 aloss2:4.3433 exploreP:0.0175\n",
      "Episode:711 meanR:146.0400 R:147.0000 rate:0.2940 aloss:0.6190 eloss:3.6629 aloss2:4.3917 exploreP:0.0174\n",
      "Episode:712 meanR:145.5100 R:127.0000 rate:0.2540 aloss:0.5953 eloss:3.6837 aloss2:4.3905 exploreP:0.0173\n",
      "Episode:713 meanR:145.4000 R:146.0000 rate:0.2920 aloss:0.6195 eloss:3.6737 aloss2:4.3547 exploreP:0.0172\n",
      "Episode:714 meanR:145.5800 R:177.0000 rate:0.3540 aloss:0.5942 eloss:3.6725 aloss2:4.3790 exploreP:0.0170\n",
      "Episode:715 meanR:146.2300 R:206.0000 rate:0.4120 aloss:0.6191 eloss:3.6643 aloss2:4.3744 exploreP:0.0169\n",
      "Episode:716 meanR:146.3700 R:159.0000 rate:0.3180 aloss:0.6065 eloss:3.6696 aloss2:4.3466 exploreP:0.0168\n",
      "Episode:717 meanR:146.3200 R:155.0000 rate:0.3100 aloss:0.6122 eloss:3.6695 aloss2:4.3556 exploreP:0.0167\n",
      "Episode:718 meanR:145.9500 R:137.0000 rate:0.2740 aloss:0.6034 eloss:3.6649 aloss2:4.3783 exploreP:0.0166\n",
      "Episode:719 meanR:145.4000 R:133.0000 rate:0.2660 aloss:0.5878 eloss:3.6877 aloss2:4.3536 exploreP:0.0165\n",
      "Episode:720 meanR:145.3100 R:165.0000 rate:0.3300 aloss:0.6001 eloss:3.6715 aloss2:4.3895 exploreP:0.0164\n",
      "Episode:721 meanR:145.4700 R:175.0000 rate:0.3500 aloss:0.5978 eloss:3.6714 aloss2:4.3902 exploreP:0.0163\n",
      "Episode:722 meanR:145.4900 R:163.0000 rate:0.3260 aloss:0.6163 eloss:3.6668 aloss2:4.3950 exploreP:0.0162\n",
      "Episode:723 meanR:146.6400 R:254.0000 rate:0.5080 aloss:0.5994 eloss:3.6745 aloss2:4.3791 exploreP:0.0160\n",
      "Episode:724 meanR:146.8200 R:166.0000 rate:0.3320 aloss:0.6027 eloss:3.6758 aloss2:4.3628 exploreP:0.0159\n",
      "Episode:725 meanR:146.5000 R:156.0000 rate:0.3120 aloss:0.5971 eloss:3.6703 aloss2:4.3766 exploreP:0.0158\n",
      "Episode:726 meanR:146.3100 R:146.0000 rate:0.2920 aloss:0.6115 eloss:3.6770 aloss2:4.3925 exploreP:0.0157\n",
      "Episode:727 meanR:146.3400 R:134.0000 rate:0.2680 aloss:0.5892 eloss:3.6873 aloss2:4.3895 exploreP:0.0157\n",
      "Episode:728 meanR:146.5200 R:138.0000 rate:0.2760 aloss:0.5883 eloss:3.6898 aloss2:4.3488 exploreP:0.0156\n",
      "Episode:729 meanR:146.9100 R:169.0000 rate:0.3380 aloss:0.5965 eloss:3.6626 aloss2:4.3637 exploreP:0.0155\n",
      "Episode:730 meanR:147.3000 R:169.0000 rate:0.3380 aloss:0.5911 eloss:3.6747 aloss2:4.3827 exploreP:0.0154\n",
      "Episode:731 meanR:147.4700 R:157.0000 rate:0.3140 aloss:0.5985 eloss:3.6849 aloss2:4.3733 exploreP:0.0153\n",
      "Episode:732 meanR:147.8700 R:166.0000 rate:0.3320 aloss:0.5823 eloss:3.6938 aloss2:4.3220 exploreP:0.0152\n",
      "Episode:733 meanR:147.5800 R:166.0000 rate:0.3320 aloss:0.6014 eloss:3.6565 aloss2:4.4065 exploreP:0.0151\n",
      "Episode:734 meanR:147.6400 R:135.0000 rate:0.2700 aloss:0.6299 eloss:3.6478 aloss2:4.4177 exploreP:0.0151\n",
      "Episode:735 meanR:147.6000 R:153.0000 rate:0.3060 aloss:0.5946 eloss:3.6803 aloss2:4.3625 exploreP:0.0150\n",
      "Episode:736 meanR:147.6300 R:166.0000 rate:0.3320 aloss:0.5876 eloss:3.6652 aloss2:4.3828 exploreP:0.0149\n",
      "Episode:737 meanR:147.6500 R:188.0000 rate:0.3760 aloss:0.5882 eloss:3.6805 aloss2:4.3886 exploreP:0.0148\n",
      "Episode:738 meanR:148.1700 R:163.0000 rate:0.3260 aloss:0.5866 eloss:3.6719 aloss2:4.3899 exploreP:0.0147\n",
      "Episode:739 meanR:148.4700 R:168.0000 rate:0.3360 aloss:0.5832 eloss:3.6787 aloss2:4.4132 exploreP:0.0147\n",
      "Episode:740 meanR:148.8600 R:181.0000 rate:0.3620 aloss:0.5862 eloss:3.6817 aloss2:4.4074 exploreP:0.0146\n",
      "Episode:741 meanR:149.3000 R:159.0000 rate:0.3180 aloss:0.6086 eloss:3.6545 aloss2:4.4046 exploreP:0.0145\n",
      "Episode:742 meanR:149.7100 R:149.0000 rate:0.2980 aloss:0.5959 eloss:3.6784 aloss2:4.3867 exploreP:0.0144\n",
      "Episode:743 meanR:149.8400 R:152.0000 rate:0.3040 aloss:0.5784 eloss:3.6883 aloss2:4.3978 exploreP:0.0144\n",
      "Episode:744 meanR:149.7700 R:130.0000 rate:0.2600 aloss:0.5959 eloss:3.6655 aloss2:4.4124 exploreP:0.0143\n",
      "Episode:745 meanR:150.0200 R:153.0000 rate:0.3060 aloss:0.5759 eloss:3.6795 aloss2:4.4069 exploreP:0.0143\n",
      "Episode:746 meanR:150.6000 R:179.0000 rate:0.3580 aloss:0.6084 eloss:3.6664 aloss2:4.4293 exploreP:0.0142\n",
      "Episode:747 meanR:150.7300 R:172.0000 rate:0.3440 aloss:0.5932 eloss:3.6714 aloss2:4.4034 exploreP:0.0141\n",
      "Episode:748 meanR:151.5900 R:154.0000 rate:0.3080 aloss:0.5950 eloss:3.6679 aloss2:4.4157 exploreP:0.0140\n",
      "Episode:749 meanR:151.9500 R:161.0000 rate:0.3220 aloss:0.5827 eloss:3.6820 aloss2:4.4161 exploreP:0.0140\n",
      "Episode:750 meanR:152.5200 R:193.0000 rate:0.3860 aloss:0.5907 eloss:3.6621 aloss2:4.4098 exploreP:0.0139\n",
      "Episode:751 meanR:152.6200 R:136.0000 rate:0.2720 aloss:0.5764 eloss:3.6671 aloss2:4.4251 exploreP:0.0139\n",
      "Episode:752 meanR:153.2600 R:174.0000 rate:0.3480 aloss:0.5984 eloss:3.6666 aloss2:4.4561 exploreP:0.0138\n",
      "Episode:753 meanR:153.7900 R:186.0000 rate:0.3720 aloss:0.5761 eloss:3.7019 aloss2:4.3897 exploreP:0.0137\n",
      "Episode:754 meanR:153.9100 R:217.0000 rate:0.4340 aloss:0.5819 eloss:3.6737 aloss2:4.3963 exploreP:0.0136\n",
      "Episode:755 meanR:154.1300 R:156.0000 rate:0.3120 aloss:0.5762 eloss:3.6722 aloss2:4.4299 exploreP:0.0136\n",
      "Episode:756 meanR:154.6700 R:188.0000 rate:0.3760 aloss:0.5712 eloss:3.6864 aloss2:4.3941 exploreP:0.0135\n",
      "Episode:757 meanR:155.0100 R:176.0000 rate:0.3520 aloss:0.5955 eloss:3.6601 aloss2:4.4409 exploreP:0.0135\n",
      "Episode:758 meanR:155.1000 R:151.0000 rate:0.3020 aloss:0.6015 eloss:3.6835 aloss2:4.4238 exploreP:0.0134\n",
      "Episode:759 meanR:155.0600 R:122.0000 rate:0.2440 aloss:0.5827 eloss:3.6733 aloss2:4.3988 exploreP:0.0134\n",
      "Episode:760 meanR:155.4200 R:160.0000 rate:0.3200 aloss:0.5951 eloss:3.6666 aloss2:4.4295 exploreP:0.0133\n",
      "Episode:761 meanR:156.5600 R:285.0000 rate:0.5700 aloss:0.5856 eloss:3.6686 aloss2:4.4246 exploreP:0.0132\n",
      "Episode:762 meanR:157.4000 R:182.0000 rate:0.3640 aloss:0.5950 eloss:3.6652 aloss2:4.4251 exploreP:0.0132\n",
      "Episode:763 meanR:157.1200 R:160.0000 rate:0.3200 aloss:0.5600 eloss:3.6901 aloss2:4.4093 exploreP:0.0131\n",
      "Episode:764 meanR:157.9900 R:205.0000 rate:0.4100 aloss:0.5745 eloss:3.6749 aloss2:4.4306 exploreP:0.0130\n",
      "Episode:765 meanR:158.4000 R:189.0000 rate:0.3780 aloss:0.5753 eloss:3.6804 aloss2:4.4465 exploreP:0.0130\n",
      "Episode:766 meanR:159.4200 R:211.0000 rate:0.4220 aloss:0.5724 eloss:3.6746 aloss2:4.4349 exploreP:0.0129\n",
      "Episode:767 meanR:159.8300 R:165.0000 rate:0.3300 aloss:0.5669 eloss:3.6882 aloss2:4.4058 exploreP:0.0129\n",
      "Episode:768 meanR:160.0700 R:164.0000 rate:0.3280 aloss:0.5797 eloss:3.6639 aloss2:4.4418 exploreP:0.0128\n",
      "Episode:769 meanR:160.2000 R:163.0000 rate:0.3260 aloss:0.5980 eloss:3.6614 aloss2:4.4359 exploreP:0.0128\n",
      "Episode:770 meanR:160.3200 R:136.0000 rate:0.2720 aloss:0.5557 eloss:3.6762 aloss2:4.4445 exploreP:0.0127\n",
      "Episode:771 meanR:160.7900 R:176.0000 rate:0.3520 aloss:0.5622 eloss:3.6763 aloss2:4.4361 exploreP:0.0127\n",
      "Episode:772 meanR:161.3600 R:164.0000 rate:0.3280 aloss:0.5848 eloss:3.6660 aloss2:4.4119 exploreP:0.0127\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list = [], []\n",
    "aloss_list, eloss_list, aloss2_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes for running average/running mean/window\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        aloss_batch, eloss_batch, aloss2_batch = [], [], []\n",
    "        total_reward = 0\n",
    "        state = env.reset()\n",
    "        num_step = 0\n",
    "        rate = -1\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (env) or Exploit (model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done), rate])\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            # Training with the maxrated minibatch\n",
    "            batch = memory.buffer\n",
    "            #for idx in range(memory_size// batch_size):\n",
    "            while True:\n",
    "                idx = np.random.choice(np.arange(memory_size// batch_size))\n",
    "                states = np.array([each[0] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                actions = np.array([each[1] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                next_states = np.array([each[2] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                rewards = np.array([each[3] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                dones = np.array([each[4] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                rates = np.array([each[5] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                states = states[rates >= np.max(rates)]\n",
    "                actions = actions[rates >= np.max(rates)]\n",
    "                next_states = next_states[rates >= np.max(rates)]\n",
    "                rewards = rewards[rates >= np.max(rates)]\n",
    "                dones = dones[rates >= np.max(rates)]\n",
    "                rates = rates[rates >= np.max(rates)]\n",
    "                if np.count_nonzero(dones) > 0 and len(dones) > 1 and np.max(rates) > 0:\n",
    "                    break\n",
    "            aloss, _ = sess.run([model.a_loss, model.a_opt],\n",
    "                                  feed_dict = {model.states: states, \n",
    "                                               model.actions: actions,\n",
    "                                               model.next_states: next_states,\n",
    "                                               model.rewards: rewards,\n",
    "                                               model.dones: dones,\n",
    "                                               model.rates: rates})\n",
    "            eloss, _ = sess.run([model.e_loss, model.e_opt],\n",
    "                                  feed_dict = {model.states: states, \n",
    "                                               model.actions: actions,\n",
    "                                               model.next_states: next_states,\n",
    "                                               model.rewards: rewards,\n",
    "                                               model.dones: dones,\n",
    "                                               model.rates: rates})\n",
    "            aloss2, _= sess.run([model.a_loss2, model.a_opt2], \n",
    "                                 feed_dict = {model.states: states, \n",
    "                                              model.actions: actions,\n",
    "                                              model.next_states: next_states,\n",
    "                                              model.rewards: rewards,\n",
    "                                              model.dones: dones,\n",
    "                                              model.rates: rates})\n",
    "            # print(len(dones), np.count_nonzero(dones), np.max(rates))\n",
    "            aloss_batch.append(aloss)\n",
    "            eloss_batch.append(eloss)\n",
    "            aloss2_batch.append(aloss2)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        # Rating the latest played episode\n",
    "        rate = total_reward/500 # update rate at the end/ when episode is done\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.buffer[-1-idx][-1] == -1: # double-check the landmark/marked indexes\n",
    "                memory.buffer[-1-idx][-1] = rate # rate the trajectory/data\n",
    "\n",
    "        # Print out\n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'aloss:{:.4f}'.format(np.mean(aloss_batch)),\n",
    "              'eloss:{:.4f}'.format(np.mean(eloss_batch)),\n",
    "              'aloss2:{:.4f}'.format(np.mean(aloss2_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        aloss_list.append([ep, np.mean(aloss_batch)])\n",
    "        eloss_list.append([ep, np.mean(eloss_batch)])\n",
    "        aloss2_list.append([ep, np.mean(aloss2_batch)])\n",
    "        \n",
    "        # Break episode/epoch loop\n",
    "        ## Option 1: Solve the First Version\n",
    "        #The task is episodic, and in order to solve the environment, \n",
    "        #your agent must get an average score of +30 over 100 consecutive episodes.\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(aloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Act losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(eloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Env losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(aloss2_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Act losses 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print('total_reward: {}'.format(total_reward))\n",
    "                break\n",
    "                \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info: [ 0.03367204 -0.18377751 -0.02637949  0.27589704] 0 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02999649  0.01171068 -0.02086155 -0.02498789] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.0302307   0.20712549 -0.0213613  -0.32417918] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.03437321  0.01231411 -0.02784489 -0.03830853] 0 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.03461949  0.20782406 -0.02861106 -0.33964511] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.03877597  0.40334119 -0.03540396 -0.64121127] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.0468428   0.59893833 -0.04822819 -0.94482972] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.05882157  0.7946756  -0.06712478 -1.25226782] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.07471508  0.99059021 -0.09217014 -1.56519781] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.09452688  1.18668501 -0.12347409 -1.88515114] 1 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "        \n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return actions, states, targetQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_outputs(action_size, hidden_size, states, cell, initial_state):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    return actions_logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs):\n",
    "    actions_logits, _ = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                  lstm_size=hidden_size, num_classes=action_size, reuse=True)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "#     loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Qs_logits, \n",
    "#                                                                   labels=tf.nn.sigmoid(targetQs[1:])))\n",
    "    return actions_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.actions, self.states, self.targetQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "        # Output of the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state = model_outputs(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs, \n",
    "            cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_total_reward = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state:', np.array(states).shape[1], \n",
    "#       'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32                # number of samples in the memory/ experience as mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n",
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.03912216,  0.01218385, -0.00347782,  0.04461972]),\n",
       " 1,\n",
       " array([ 0.03936583,  0.2073555 , -0.00258543, -0.24915846]),\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states, rewards, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 meanReward: 13.0000 meanLoss: 1.4376 ExploreP: 0.9987\n",
      "Episode: 1 meanReward: 13.0000 meanLoss: 2.0859 ExploreP: 0.9974\n",
      "Episode: 2 meanReward: 12.3333 meanLoss: 1.8955 ExploreP: 0.9963\n",
      "Episode: 3 meanReward: 13.7500 meanLoss: 7.2121 ExploreP: 0.9946\n",
      "Episode: 4 meanReward: 15.6000 meanLoss: 10.4739 ExploreP: 0.9923\n",
      "Episode: 5 meanReward: 16.6667 meanLoss: 7.0556 ExploreP: 0.9901\n",
      "Episode: 6 meanReward: 22.1429 meanLoss: 2.2025 ExploreP: 0.9848\n",
      "Episode: 7 meanReward: 26.7500 meanLoss: 4.1586 ExploreP: 0.9790\n",
      "Episode: 8 meanReward: 25.3333 meanLoss: 9.7931 ExploreP: 0.9777\n",
      "Episode: 9 meanReward: 24.7000 meanLoss: 17.9609 ExploreP: 0.9758\n",
      "Episode: 10 meanReward: 25.0000 meanLoss: 15.0360 ExploreP: 0.9731\n",
      "Episode: 11 meanReward: 24.5000 meanLoss: 16.6036 ExploreP: 0.9713\n",
      "Episode: 12 meanReward: 24.3077 meanLoss: 19.1308 ExploreP: 0.9692\n",
      "Episode: 13 meanReward: 25.9286 meanLoss: 13.1408 ExploreP: 0.9647\n",
      "Episode: 14 meanReward: 25.3333 meanLoss: 17.2051 ExploreP: 0.9631\n",
      "Episode: 15 meanReward: 24.9375 meanLoss: 27.4406 ExploreP: 0.9613\n",
      "Episode: 16 meanReward: 24.0588 meanLoss: 29.2070 ExploreP: 0.9603\n",
      "Episode: 17 meanReward: 23.7222 meanLoss: 41.7260 ExploreP: 0.9586\n",
      "Episode: 18 meanReward: 23.7368 meanLoss: 30.3269 ExploreP: 0.9563\n",
      "Episode: 19 meanReward: 23.8000 meanLoss: 31.9171 ExploreP: 0.9540\n",
      "Episode: 20 meanReward: 23.6667 meanLoss: 43.9707 ExploreP: 0.9520\n",
      "Episode: 21 meanReward: 23.3636 meanLoss: 32.6032 ExploreP: 0.9504\n",
      "Episode: 22 meanReward: 23.3478 meanLoss: 33.9882 ExploreP: 0.9482\n",
      "Episode: 23 meanReward: 22.9167 meanLoss: 40.9606 ExploreP: 0.9470\n",
      "Episode: 24 meanReward: 22.6000 meanLoss: 30.0629 ExploreP: 0.9456\n",
      "Episode: 25 meanReward: 22.1538 meanLoss: 22.2847 ExploreP: 0.9446\n",
      "Episode: 26 meanReward: 21.7037 meanLoss: 14.5683 ExploreP: 0.9437\n",
      "Episode: 27 meanReward: 21.4643 meanLoss: 28.4668 ExploreP: 0.9423\n",
      "Episode: 28 meanReward: 21.3448 meanLoss: 50.9369 ExploreP: 0.9406\n",
      "Episode: 29 meanReward: 22.5000 meanLoss: 22.2922 ExploreP: 0.9354\n",
      "Episode: 30 meanReward: 22.4516 meanLoss: 30.2491 ExploreP: 0.9334\n",
      "Episode: 31 meanReward: 22.8750 meanLoss: 32.3770 ExploreP: 0.9301\n",
      "Episode: 32 meanReward: 23.0000 meanLoss: 16.3385 ExploreP: 0.9286\n",
      "Episode: 33 meanReward: 22.9375 meanLoss: 19.1325 ExploreP: 0.9275\n",
      "Episode: 34 meanReward: 23.0938 meanLoss: 35.5705 ExploreP: 0.9261\n",
      "Episode: 35 meanReward: 23.8438 meanLoss: 37.2576 ExploreP: 0.9222\n",
      "Episode: 36 meanReward: 23.5312 meanLoss: 31.3650 ExploreP: 0.9211\n",
      "Episode: 37 meanReward: 23.2188 meanLoss: 44.1526 ExploreP: 0.9200\n",
      "Episode: 38 meanReward: 21.9688 meanLoss: 35.4379 ExploreP: 0.9186\n",
      "Episode: 39 meanReward: 20.4688 meanLoss: 33.2499 ExploreP: 0.9176\n",
      "Episode: 40 meanReward: 20.6562 meanLoss: 18.0615 ExploreP: 0.9158\n",
      "Episode: 41 meanReward: 20.7188 meanLoss: 32.5783 ExploreP: 0.9139\n",
      "Episode: 42 meanReward: 20.7500 meanLoss: 14.3658 ExploreP: 0.9113\n",
      "Episode: 43 meanReward: 20.5938 meanLoss: 34.5129 ExploreP: 0.9100\n",
      "Episode: 44 meanReward: 20.5312 meanLoss: 58.0707 ExploreP: 0.9082\n",
      "Episode: 45 meanReward: 20.4062 meanLoss: 27.8592 ExploreP: 0.9044\n",
      "Episode: 46 meanReward: 20.6250 meanLoss: 5.1658 ExploreP: 0.9022\n",
      "Episode: 47 meanReward: 20.4375 meanLoss: 33.6910 ExploreP: 0.9011\n",
      "Episode: 48 meanReward: 20.5312 meanLoss: 34.5637 ExploreP: 0.8999\n",
      "Episode: 49 meanReward: 21.4062 meanLoss: 6.7397 ExploreP: 0.8958\n",
      "Episode: 50 meanReward: 21.2812 meanLoss: 4.0081 ExploreP: 0.8940\n",
      "Episode: 51 meanReward: 20.8750 meanLoss: 33.1436 ExploreP: 0.8930\n",
      "Episode: 52 meanReward: 21.8750 meanLoss: 18.5412 ExploreP: 0.8883\n",
      "Episode: 53 meanReward: 22.3125 meanLoss: 20.6916 ExploreP: 0.8856\n",
      "Episode: 54 meanReward: 22.1562 meanLoss: 42.4600 ExploreP: 0.8840\n",
      "Episode: 55 meanReward: 22.2812 meanLoss: 64.4876 ExploreP: 0.8825\n",
      "Episode: 56 meanReward: 22.4062 meanLoss: 38.0336 ExploreP: 0.8809\n",
      "Episode: 57 meanReward: 23.9062 meanLoss: 3.6300 ExploreP: 0.8758\n",
      "Episode: 58 meanReward: 24.0312 meanLoss: 7.0506 ExploreP: 0.8745\n",
      "Episode: 59 meanReward: 24.1562 meanLoss: 46.2778 ExploreP: 0.8729\n",
      "Episode: 60 meanReward: 24.8125 meanLoss: 45.4641 ExploreP: 0.8695\n",
      "Episode: 61 meanReward: 23.9688 meanLoss: 42.0039 ExploreP: 0.8671\n",
      "Episode: 62 meanReward: 24.7500 meanLoss: 27.7242 ExploreP: 0.8631\n",
      "Episode: 63 meanReward: 24.0625 meanLoss: 19.0428 ExploreP: 0.8619\n",
      "Episode: 64 meanReward: 23.9688 meanLoss: 21.9198 ExploreP: 0.8607\n",
      "Episode: 65 meanReward: 24.1562 meanLoss: 15.1792 ExploreP: 0.8593\n",
      "Episode: 66 meanReward: 24.2188 meanLoss: 4.2509 ExploreP: 0.8578\n",
      "Episode: 67 meanReward: 23.8750 meanLoss: 42.4103 ExploreP: 0.8551\n",
      "Episode: 68 meanReward: 23.7500 meanLoss: 12.1395 ExploreP: 0.8544\n",
      "Episode: 69 meanReward: 23.9062 meanLoss: 47.6503 ExploreP: 0.8529\n",
      "Episode: 70 meanReward: 24.5938 meanLoss: 46.3836 ExploreP: 0.8498\n",
      "Episode: 71 meanReward: 27.4375 meanLoss: 12.0403 ExploreP: 0.8413\n",
      "Episode: 72 meanReward: 27.2188 meanLoss: 14.3445 ExploreP: 0.8402\n",
      "Episode: 73 meanReward: 26.9375 meanLoss: 44.7554 ExploreP: 0.8392\n",
      "Episode: 74 meanReward: 27.0312 meanLoss: 63.8742 ExploreP: 0.8366\n",
      "Episode: 75 meanReward: 27.1875 meanLoss: 37.7662 ExploreP: 0.8350\n",
      "Episode: 76 meanReward: 27.6562 meanLoss: 42.1289 ExploreP: 0.8321\n",
      "Episode: 77 meanReward: 27.6250 meanLoss: 10.6297 ExploreP: 0.8287\n",
      "Episode: 78 meanReward: 28.1562 meanLoss: 3.4712 ExploreP: 0.8253\n",
      "Episode: 79 meanReward: 28.3438 meanLoss: 45.3372 ExploreP: 0.8238\n",
      "Episode: 80 meanReward: 28.7188 meanLoss: 59.3100 ExploreP: 0.8218\n",
      "Episode: 81 meanReward: 27.7500 meanLoss: 56.6949 ExploreP: 0.8205\n",
      "Episode: 82 meanReward: 27.7812 meanLoss: 66.3546 ExploreP: 0.8188\n",
      "Episode: 83 meanReward: 28.6562 meanLoss: 37.9190 ExploreP: 0.8156\n",
      "Episode: 84 meanReward: 28.6875 meanLoss: 20.7245 ExploreP: 0.8113\n",
      "Episode: 85 meanReward: 29.1875 meanLoss: 6.0881 ExploreP: 0.8075\n",
      "Episode: 86 meanReward: 29.3750 meanLoss: 9.8534 ExploreP: 0.8056\n",
      "Episode: 87 meanReward: 29.5625 meanLoss: 38.4952 ExploreP: 0.8038\n",
      "Episode: 88 meanReward: 29.7812 meanLoss: 21.0715 ExploreP: 0.8017\n",
      "Episode: 89 meanReward: 28.7812 meanLoss: 3.9666 ExploreP: 0.7996\n",
      "Episode: 90 meanReward: 30.2188 meanLoss: 1.6255 ExploreP: 0.7949\n",
      "Episode: 91 meanReward: 30.1250 meanLoss: 3.5099 ExploreP: 0.7936\n",
      "Episode: 92 meanReward: 29.3438 meanLoss: 6.6089 ExploreP: 0.7925\n",
      "Episode: 93 meanReward: 29.0312 meanLoss: 15.5174 ExploreP: 0.7910\n",
      "Episode: 94 meanReward: 28.3438 meanLoss: 54.0230 ExploreP: 0.7892\n",
      "Episode: 95 meanReward: 29.1875 meanLoss: 41.7407 ExploreP: 0.7860\n",
      "Episode: 96 meanReward: 29.0938 meanLoss: 11.7022 ExploreP: 0.7851\n",
      "Episode: 97 meanReward: 28.9375 meanLoss: 21.9307 ExploreP: 0.7842\n",
      "Episode: 98 meanReward: 28.9688 meanLoss: 10.3274 ExploreP: 0.7827\n",
      "Episode: 99 meanReward: 28.4375 meanLoss: 52.9495 ExploreP: 0.7816\n",
      "Episode: 100 meanReward: 28.6875 meanLoss: 91.0200 ExploreP: 0.7803\n",
      "Episode: 101 meanReward: 28.5625 meanLoss: 85.8058 ExploreP: 0.7793\n",
      "Episode: 102 meanReward: 27.8750 meanLoss: 80.7520 ExploreP: 0.7782\n",
      "Episode: 103 meanReward: 25.7500 meanLoss: 53.5982 ExploreP: 0.7756\n",
      "Episode: 104 meanReward: 26.8438 meanLoss: 8.0508 ExploreP: 0.7719\n",
      "Episode: 105 meanReward: 27.2188 meanLoss: 39.3901 ExploreP: 0.7701\n",
      "Episode: 106 meanReward: 26.9062 meanLoss: 52.1835 ExploreP: 0.7684\n",
      "Episode: 107 meanReward: 26.6875 meanLoss: 59.7776 ExploreP: 0.7675\n",
      "Episode: 108 meanReward: 27.9375 meanLoss: 20.0294 ExploreP: 0.7618\n",
      "Episode: 109 meanReward: 27.2188 meanLoss: 28.4956 ExploreP: 0.7604\n",
      "Episode: 110 meanReward: 26.4062 meanLoss: 55.2121 ExploreP: 0.7593\n",
      "Episode: 111 meanReward: 26.2500 meanLoss: 37.7551 ExploreP: 0.7582\n",
      "Episode: 112 meanReward: 26.3125 meanLoss: 9.1026 ExploreP: 0.7562\n",
      "Episode: 113 meanReward: 26.2188 meanLoss: 33.5540 ExploreP: 0.7553\n",
      "Episode: 114 meanReward: 26.3438 meanLoss: 49.9942 ExploreP: 0.7535\n",
      "Episode: 115 meanReward: 26.2812 meanLoss: 25.7287 ExploreP: 0.7506\n",
      "Episode: 116 meanReward: 25.9062 meanLoss: 16.5521 ExploreP: 0.7475\n",
      "Episode: 117 meanReward: 25.3438 meanLoss: 3.7913 ExploreP: 0.7454\n",
      "Episode: 118 meanReward: 25.8438 meanLoss: 2.2648 ExploreP: 0.7425\n",
      "Episode: 119 meanReward: 25.6562 meanLoss: 3.1956 ExploreP: 0.7412\n",
      "Episode: 120 meanReward: 25.5625 meanLoss: 4.0024 ExploreP: 0.7395\n",
      "Episode: 121 meanReward: 26.9688 meanLoss: 12.2903 ExploreP: 0.7343\n",
      "Episode: 122 meanReward: 26.6875 meanLoss: 16.8361 ExploreP: 0.7306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 123 meanReward: 27.9375 meanLoss: 1.6444 ExploreP: 0.7266\n",
      "Episode: 124 meanReward: 31.0000 meanLoss: 1.0872 ExploreP: 0.7186\n",
      "Episode: 125 meanReward: 32.0312 meanLoss: 29.3952 ExploreP: 0.7149\n",
      "Episode: 126 meanReward: 32.3438 meanLoss: 41.7736 ExploreP: 0.7125\n",
      "Episode: 127 meanReward: 31.8438 meanLoss: 8.8394 ExploreP: 0.7108\n",
      "Episode: 128 meanReward: 32.2500 meanLoss: 49.0338 ExploreP: 0.7091\n",
      "Episode: 129 meanReward: 34.8125 meanLoss: 22.9686 ExploreP: 0.7026\n",
      "Episode: 130 meanReward: 34.8750 meanLoss: 17.2163 ExploreP: 0.7011\n",
      "Episode: 131 meanReward: 34.8750 meanLoss: 34.7936 ExploreP: 0.7001\n",
      "Episode: 132 meanReward: 34.7812 meanLoss: 8.3001 ExploreP: 0.6992\n",
      "Episode: 133 meanReward: 34.9688 meanLoss: 9.1053 ExploreP: 0.6979\n",
      "Episode: 134 meanReward: 35.6562 meanLoss: 55.0049 ExploreP: 0.6953\n",
      "Episode: 135 meanReward: 35.1250 meanLoss: 11.4377 ExploreP: 0.6942\n",
      "Episode: 136 meanReward: 34.1562 meanLoss: 8.8163 ExploreP: 0.6930\n",
      "Episode: 137 meanReward: 34.5312 meanLoss: 12.8247 ExploreP: 0.6906\n",
      "Episode: 138 meanReward: 36.2188 meanLoss: 26.2595 ExploreP: 0.6854\n",
      "Episode: 139 meanReward: 36.9688 meanLoss: 12.9233 ExploreP: 0.6830\n",
      "Episode: 140 meanReward: 36.0938 meanLoss: 17.7794 ExploreP: 0.6798\n",
      "Episode: 141 meanReward: 36.1250 meanLoss: 68.0739 ExploreP: 0.6785\n",
      "Episode: 142 meanReward: 37.3438 meanLoss: 18.7612 ExploreP: 0.6749\n",
      "Episode: 143 meanReward: 37.3125 meanLoss: 4.6918 ExploreP: 0.6740\n",
      "Episode: 144 meanReward: 37.0312 meanLoss: 7.0902 ExploreP: 0.6728\n",
      "Episode: 145 meanReward: 38.3125 meanLoss: 3.9645 ExploreP: 0.6693\n",
      "Episode: 146 meanReward: 37.9688 meanLoss: 58.3671 ExploreP: 0.6684\n",
      "Episode: 147 meanReward: 37.8750 meanLoss: 34.3938 ExploreP: 0.6661\n",
      "Episode: 148 meanReward: 36.9062 meanLoss: 20.8418 ExploreP: 0.6654\n",
      "Episode: 149 meanReward: 36.6875 meanLoss: 72.3883 ExploreP: 0.6639\n",
      "Episode: 150 meanReward: 36.8438 meanLoss: 31.0626 ExploreP: 0.6610\n",
      "Episode: 151 meanReward: 37.1562 meanLoss: 64.1727 ExploreP: 0.6592\n",
      "Episode: 152 meanReward: 37.0625 meanLoss: 19.6280 ExploreP: 0.6579\n",
      "Episode: 153 meanReward: 36.3125 meanLoss: 40.9207 ExploreP: 0.6548\n",
      "Episode: 154 meanReward: 35.9375 meanLoss: 46.9517 ExploreP: 0.6523\n",
      "Episode: 155 meanReward: 35.5625 meanLoss: 39.8018 ExploreP: 0.6495\n",
      "Episode: 156 meanReward: 33.2812 meanLoss: 39.4287 ExploreP: 0.6470\n",
      "Episode: 157 meanReward: 32.3125 meanLoss: 44.6637 ExploreP: 0.6457\n",
      "Episode: 158 meanReward: 31.6250 meanLoss: 43.9487 ExploreP: 0.6449\n",
      "Episode: 159 meanReward: 31.5938 meanLoss: 13.5661 ExploreP: 0.6434\n",
      "Episode: 160 meanReward: 31.5312 meanLoss: 11.0104 ExploreP: 0.6420\n",
      "Episode: 161 meanReward: 30.5625 meanLoss: 3.9898 ExploreP: 0.6380\n",
      "Episode: 162 meanReward: 30.5312 meanLoss: 3.7822 ExploreP: 0.6368\n",
      "Episode: 163 meanReward: 30.7500 meanLoss: 11.7008 ExploreP: 0.6355\n",
      "Episode: 164 meanReward: 31.2188 meanLoss: 6.5816 ExploreP: 0.6337\n",
      "Episode: 165 meanReward: 31.2500 meanLoss: 55.6843 ExploreP: 0.6324\n",
      "Episode: 166 meanReward: 31.8125 meanLoss: 11.9174 ExploreP: 0.6290\n",
      "Episode: 167 meanReward: 31.6875 meanLoss: 4.2840 ExploreP: 0.6282\n",
      "Episode: 168 meanReward: 31.6250 meanLoss: 6.6457 ExploreP: 0.6273\n",
      "Episode: 169 meanReward: 30.9062 meanLoss: 5.6327 ExploreP: 0.6265\n",
      "Episode: 170 meanReward: 29.0625 meanLoss: 4.6999 ExploreP: 0.6254\n",
      "Episode: 171 meanReward: 30.9062 meanLoss: 10.1179 ExploreP: 0.6196\n",
      "Episode: 172 meanReward: 30.0625 meanLoss: 110.0751 ExploreP: 0.6184\n",
      "Episode: 173 meanReward: 29.8750 meanLoss: 99.2825 ExploreP: 0.6175\n",
      "Episode: 174 meanReward: 28.6250 meanLoss: 124.4735 ExploreP: 0.6167\n",
      "Episode: 175 meanReward: 28.5000 meanLoss: 183.7231 ExploreP: 0.6161\n",
      "Episode: 176 meanReward: 28.3438 meanLoss: 148.9717 ExploreP: 0.6153\n",
      "Episode: 177 meanReward: 27.3750 meanLoss: 79.4346 ExploreP: 0.6140\n",
      "Episode: 178 meanReward: 27.2812 meanLoss: 110.7026 ExploreP: 0.6134\n",
      "Episode: 179 meanReward: 28.2812 meanLoss: 29.9453 ExploreP: 0.6093\n",
      "Episode: 180 meanReward: 28.1875 meanLoss: 64.0582 ExploreP: 0.6088\n",
      "Episode: 181 meanReward: 28.7188 meanLoss: 69.3428 ExploreP: 0.6065\n",
      "Episode: 182 meanReward: 28.3750 meanLoss: 47.2737 ExploreP: 0.6045\n",
      "Episode: 183 meanReward: 28.1250 meanLoss: 93.0869 ExploreP: 0.6034\n",
      "Episode: 184 meanReward: 28.3750 meanLoss: 102.3624 ExploreP: 0.6017\n",
      "Episode: 185 meanReward: 28.6250 meanLoss: 34.2318 ExploreP: 0.5984\n",
      "Episode: 186 meanReward: 28.5000 meanLoss: 34.3130 ExploreP: 0.5963\n",
      "Episode: 187 meanReward: 27.5938 meanLoss: 28.4641 ExploreP: 0.5955\n",
      "Episode: 188 meanReward: 26.8750 meanLoss: 23.8444 ExploreP: 0.5945\n",
      "Episode: 189 meanReward: 26.8125 meanLoss: 9.7561 ExploreP: 0.5934\n",
      "Episode: 190 meanReward: 28.3438 meanLoss: 22.3005 ExploreP: 0.5899\n",
      "Episode: 191 meanReward: 28.4062 meanLoss: 16.1107 ExploreP: 0.5884\n",
      "Episode: 192 meanReward: 28.2188 meanLoss: 59.3229 ExploreP: 0.5874\n",
      "Episode: 193 meanReward: 27.2812 meanLoss: 56.6725 ExploreP: 0.5855\n",
      "Episode: 194 meanReward: 27.6250 meanLoss: 19.5336 ExploreP: 0.5838\n",
      "Episode: 195 meanReward: 29.1250 meanLoss: 3.8317 ExploreP: 0.5798\n",
      "Episode: 196 meanReward: 29.2188 meanLoss: 3.9804 ExploreP: 0.5780\n",
      "Episode: 197 meanReward: 29.6875 meanLoss: 32.1861 ExploreP: 0.5760\n",
      "Episode: 198 meanReward: 30.4688 meanLoss: 20.5293 ExploreP: 0.5715\n",
      "Episode: 199 meanReward: 30.5312 meanLoss: 99.4160 ExploreP: 0.5707\n",
      "Episode: 200 meanReward: 30.4375 meanLoss: 146.8035 ExploreP: 0.5700\n",
      "Episode: 201 meanReward: 30.6250 meanLoss: 62.7234 ExploreP: 0.5689\n",
      "Episode: 202 meanReward: 30.4688 meanLoss: 8.9641 ExploreP: 0.5682\n",
      "Episode: 203 meanReward: 27.8438 meanLoss: 14.4342 ExploreP: 0.5676\n",
      "Episode: 204 meanReward: 27.7188 meanLoss: 16.5555 ExploreP: 0.5667\n",
      "Episode: 205 meanReward: 27.7188 meanLoss: 100.3369 ExploreP: 0.5660\n",
      "Episode: 206 meanReward: 27.7812 meanLoss: 202.0771 ExploreP: 0.5651\n",
      "Episode: 207 meanReward: 28.4688 meanLoss: 114.2644 ExploreP: 0.5634\n",
      "Episode: 208 meanReward: 28.9375 meanLoss: 42.8623 ExploreP: 0.5618\n",
      "Episode: 209 meanReward: 28.8125 meanLoss: 20.5552 ExploreP: 0.5608\n",
      "Episode: 210 meanReward: 29.5312 meanLoss: 21.3773 ExploreP: 0.5589\n",
      "Episode: 211 meanReward: 28.0000 meanLoss: 33.8732 ExploreP: 0.5580\n",
      "Episode: 212 meanReward: 28.4688 meanLoss: 18.4881 ExploreP: 0.5567\n",
      "Episode: 213 meanReward: 27.7812 meanLoss: 104.3785 ExploreP: 0.5558\n",
      "Episode: 214 meanReward: 27.4688 meanLoss: 144.3713 ExploreP: 0.5545\n",
      "Episode: 215 meanReward: 27.5000 meanLoss: 80.0500 ExploreP: 0.5534\n",
      "Episode: 216 meanReward: 27.1562 meanLoss: 71.5482 ExploreP: 0.5525\n",
      "Episode: 217 meanReward: 26.0625 meanLoss: 57.4556 ExploreP: 0.5513\n",
      "Episode: 218 meanReward: 25.4375 meanLoss: 117.5287 ExploreP: 0.5505\n",
      "Episode: 219 meanReward: 25.5625 meanLoss: 118.2706 ExploreP: 0.5495\n",
      "Episode: 220 meanReward: 25.5000 meanLoss: 144.5594 ExploreP: 0.5487\n",
      "Episode: 221 meanReward: 25.4688 meanLoss: 71.1940 ExploreP: 0.5478\n",
      "Episode: 222 meanReward: 24.3125 meanLoss: 154.4650 ExploreP: 0.5465\n",
      "Episode: 223 meanReward: 24.2188 meanLoss: 176.0658 ExploreP: 0.5452\n",
      "Episode: 224 meanReward: 24.4688 meanLoss: 38.7279 ExploreP: 0.5440\n",
      "Episode: 225 meanReward: 27.5625 meanLoss: 12.5491 ExploreP: 0.5369\n",
      "Episode: 226 meanReward: 27.8750 meanLoss: 37.5493 ExploreP: 0.5348\n",
      "Episode: 227 meanReward: 26.2500 meanLoss: 13.5552 ExploreP: 0.5339\n",
      "Episode: 228 meanReward: 29.3750 meanLoss: 15.2206 ExploreP: 0.5270\n",
      "Episode: 229 meanReward: 30.1875 meanLoss: 24.1900 ExploreP: 0.5239\n",
      "Episode: 230 meanReward: 31.4375 meanLoss: 608.7236 ExploreP: 0.5178\n",
      "Episode: 231 meanReward: 34.1562 meanLoss: 800.4732 ExploreP: 0.5126\n",
      "Episode: 232 meanReward: 34.8125 meanLoss: 638.0331 ExploreP: 0.5109\n",
      "Episode: 233 meanReward: 34.9375 meanLoss: 310.1874 ExploreP: 0.5098\n",
      "Episode: 234 meanReward: 36.8125 meanLoss: 35.2657 ExploreP: 0.5062\n",
      "Episode: 235 meanReward: 39.7188 meanLoss: 5.6616 ExploreP: 0.5011\n",
      "Episode: 236 meanReward: 39.8438 meanLoss: 200.3793 ExploreP: 0.5001\n",
      "Episode: 237 meanReward: 44.2500 meanLoss: 30.9461 ExploreP: 0.4926\n",
      "Episode: 238 meanReward: 44.5000 meanLoss: 70.1479 ExploreP: 0.4914\n",
      "Episode: 239 meanReward: 44.8125 meanLoss: 54.8909 ExploreP: 0.4894\n",
      "Episode: 240 meanReward: 46.0938 meanLoss: 20.3577 ExploreP: 0.4861\n",
      "Episode: 241 meanReward: 46.1875 meanLoss: 82.3158 ExploreP: 0.4851\n",
      "Episode: 242 meanReward: 52.7188 meanLoss: 507.7856 ExploreP: 0.4737\n",
      "Episode: 243 meanReward: 52.5938 meanLoss: 1232.8416 ExploreP: 0.4731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 244 meanReward: 53.8438 meanLoss: 95.8031 ExploreP: 0.4702\n",
      "Episode: 245 meanReward: 54.6250 meanLoss: 17.1217 ExploreP: 0.4682\n",
      "Episode: 246 meanReward: 54.7500 meanLoss: 99.3669 ExploreP: 0.4670\n",
      "Episode: 247 meanReward: 56.8438 meanLoss: 32.1049 ExploreP: 0.4630\n",
      "Episode: 248 meanReward: 57.6562 meanLoss: 10.5373 ExploreP: 0.4611\n",
      "Episode: 249 meanReward: 57.9062 meanLoss: 21.3735 ExploreP: 0.4598\n",
      "Episode: 250 meanReward: 58.2500 meanLoss: 112.7230 ExploreP: 0.4586\n",
      "Episode: 251 meanReward: 59.5938 meanLoss: 39.6320 ExploreP: 0.4558\n",
      "Episode: 252 meanReward: 63.4062 meanLoss: 645.6880 ExploreP: 0.4498\n",
      "Episode: 253 meanReward: 66.0312 meanLoss: 1016.1744 ExploreP: 0.4453\n",
      "Episode: 254 meanReward: 69.3750 meanLoss: 125.1309 ExploreP: 0.4397\n",
      "Episode: 255 meanReward: 76.4062 meanLoss: 848.2800 ExploreP: 0.4291\n",
      "Episode: 256 meanReward: 79.2188 meanLoss: 506.2054 ExploreP: 0.4244\n",
      "Episode: 257 meanReward: 79.2188 meanLoss: 109.9089 ExploreP: 0.4190\n",
      "Episode: 258 meanReward: 79.0625 meanLoss: 98.2716 ExploreP: 0.4175\n",
      "Episode: 259 meanReward: 79.4375 meanLoss: 66.5220 ExploreP: 0.4163\n",
      "Episode: 260 meanReward: 79.2188 meanLoss: 26.9701 ExploreP: 0.4113\n",
      "Episode: 261 meanReward: 79.2188 meanLoss: 51.8039 ExploreP: 0.4088\n",
      "Episode: 262 meanReward: 76.0938 meanLoss: 146.6179 ExploreP: 0.4080\n",
      "Episode: 263 meanReward: 73.4375 meanLoss: 149.9800 ExploreP: 0.4073\n",
      "Episode: 264 meanReward: 81.1250 meanLoss: 7.5660 ExploreP: 0.3964\n",
      "Episode: 265 meanReward: 83.5000 meanLoss: 19.0837 ExploreP: 0.3926\n",
      "Episode: 266 meanReward: 81.7812 meanLoss: 193.7758 ExploreP: 0.3920\n",
      "Episode: 267 meanReward: 81.7500 meanLoss: 48.9777 ExploreP: 0.3880\n",
      "Episode: 268 meanReward: 87.4688 meanLoss: 3.5802 ExploreP: 0.3804\n",
      "Episode: 269 meanReward: 88.0625 meanLoss: 10.2774 ExploreP: 0.3741\n",
      "Episode: 270 meanReward: 91.3750 meanLoss: 41.9453 ExploreP: 0.3694\n",
      "Episode: 271 meanReward: 90.8438 meanLoss: 214.4995 ExploreP: 0.3685\n",
      "Episode: 272 meanReward: 89.1875 meanLoss: 122.8426 ExploreP: 0.3679\n",
      "Episode: 273 meanReward: 93.3438 meanLoss: 24.9743 ExploreP: 0.3624\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver() # save the trained model\n",
    "rewards_list, loss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_loss = deque(maxlen=batch_size)\n",
    "    episode_reward = deque(maxlen=batch_size)\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            \n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([initial_state, final_state])\n",
    "            total_reward += reward\n",
    "            initial_state = final_state\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            initial_states = np.array([each[0] for each in rnn_states])\n",
    "            final_states = np.array([each[1] for each in rnn_states])\n",
    "            actions_logits = sess.run(model.actions_logits, \n",
    "                                      feed_dict = {model.states: next_states, \n",
    "                                                   model.initial_state: final_states[0].reshape([1, -1])})\n",
    "            nextQs = np.max(actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (0.99 * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], \n",
    "                               feed_dict = {model.states: states, \n",
    "                                            model.actions: actions,\n",
    "                                            model.targetQs: targetQs,\n",
    "                                            model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode: {}'.format(ep),\n",
    "              'meanReward: {:.4f}'.format(np.mean(episode_reward)),\n",
    "              'meanLoss: {:.4f}'.format(np.mean(loss_batch)),\n",
    "              'ExploreP: {:.4f}'.format(explore_p))\n",
    "        rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        if(np.mean(episode_total_reward) >= 500):\n",
    "            break\n",
    "    \n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average losses')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward:120.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-seq.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action_logits, initial_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                             model.initial_state: initial_state})\n",
    "        action = np.argmax(action_logits)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "print('total_reward:{}'.format(total_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

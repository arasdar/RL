{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN with rated memory replay\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aras/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "state = env.reset()\n",
    "batch = []\n",
    "for _ in range(1000):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action) # take a random action\n",
    "    batch.append([state, action, next_state, reward, float(done)])\n",
    "    #     print('state, action, reward, done, info:', \n",
    "    #           state, action, reward, done, info)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([-0.04614254, -0.01506811, -0.02828059,  0.03514623]),\n",
       "  0,\n",
       "  array([-0.0464439 , -0.20977333, -0.02757766,  0.3187739 ]),\n",
       "  1.0,\n",
       "  0.0],\n",
       " (4,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([each[0] for each in batch])\n",
    "actions = np.array([each[1] for each in batch])\n",
    "next_states = np.array([each[2] for each in batch])\n",
    "rewards = np.array([each[3] for each in batch])\n",
    "dones = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(1000,) (1000, 4) (1000,) (1000,)\n",
      "float64 float64 int64 float64\n",
      "1 0\n",
      "2\n",
      "1.0 1.0\n",
      "2.296781374484523 -2.4668174457845167\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    return states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, actions, targetQs, action_size, hidden_size):\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    #Qs = tf.reduce_max(actions_logits, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs) # model input\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(batch_size, ListArr):\n",
    "    idx = np.random.choice(np.arange(len(ListArr)), \n",
    "                           size=batch_size, \n",
    "                           replace=True)\n",
    "    return [ListArr[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 24*2             # number of units in each Q-network hidden layer\n",
    "learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e2)             # experience mini-batch size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the memory with the pool of random exploration of the env.\n",
    "goal = 500 # env-based, the total reward required for reaching the goal G\n",
    "state = env.reset() # env-based\n",
    "total_reward = 0 # episode R\n",
    "num_step = 0 # episode steps/ length based on number of steps\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample() # exploring the env action space/ random action/ explore\n",
    "    next_state, reward, done, _ = env.step(action) # exploring the env state, reward, and done/end\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done), -1])\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward # R += r\n",
    "    state = next_state # update the state for next episode\n",
    "    if done is True: # end of this episode\n",
    "        state = env.reset() # reset for next episode\n",
    "        rate = total_reward/goal # the actual sucess rate of the played sequence\n",
    "        total_reward = 0 # reset for next episode\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.buffer[-1-idx][5] == -1: # double-check if it is empty and it is not rated!\n",
    "                memory.buffer[-1-idx][5] = rate # rate each SA pair\n",
    "        num_step = 0 # reset for the next episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:21.0000 R:21.0 rate:0.0420 loss:0.9962 exploreP:0.9979\n",
      "Episode:1 meanR:19.5000 R:18.0 rate:0.0360 loss:1.0013 exploreP:0.9961\n",
      "Episode:2 meanR:20.3333 R:22.0 rate:0.0440 loss:1.0146 exploreP:0.9940\n",
      "Episode:3 meanR:20.0000 R:19.0 rate:0.0380 loss:1.0440 exploreP:0.9921\n",
      "Episode:4 meanR:19.6000 R:18.0 rate:0.0360 loss:1.0671 exploreP:0.9903\n",
      "Episode:5 meanR:18.5000 R:13.0 rate:0.0260 loss:1.0828 exploreP:0.9891\n",
      "Episode:6 meanR:18.4286 R:18.0 rate:0.0360 loss:1.0859 exploreP:0.9873\n",
      "Episode:7 meanR:17.7500 R:13.0 rate:0.0260 loss:1.0896 exploreP:0.9860\n",
      "Episode:8 meanR:17.2222 R:13.0 rate:0.0260 loss:1.1062 exploreP:0.9848\n",
      "Episode:9 meanR:17.7000 R:22.0 rate:0.0440 loss:1.1211 exploreP:0.9826\n",
      "Episode:10 meanR:18.8182 R:30.0 rate:0.0600 loss:1.1419 exploreP:0.9797\n",
      "Episode:11 meanR:19.1667 R:23.0 rate:0.0460 loss:1.1798 exploreP:0.9775\n",
      "Episode:12 meanR:18.5385 R:11.0 rate:0.0220 loss:1.2028 exploreP:0.9764\n",
      "Episode:13 meanR:18.5000 R:18.0 rate:0.0360 loss:1.2504 exploreP:0.9747\n",
      "Episode:14 meanR:18.0000 R:11.0 rate:0.0220 loss:1.2754 exploreP:0.9736\n",
      "Episode:15 meanR:18.1875 R:21.0 rate:0.0420 loss:1.3106 exploreP:0.9716\n",
      "Episode:16 meanR:18.3529 R:21.0 rate:0.0420 loss:1.3723 exploreP:0.9696\n",
      "Episode:17 meanR:18.6111 R:23.0 rate:0.0460 loss:1.4396 exploreP:0.9674\n",
      "Episode:18 meanR:18.3684 R:14.0 rate:0.0280 loss:1.4836 exploreP:0.9660\n",
      "Episode:19 meanR:18.6500 R:24.0 rate:0.0480 loss:1.5461 exploreP:0.9638\n",
      "Episode:20 meanR:18.5238 R:16.0 rate:0.0320 loss:1.7270 exploreP:0.9622\n",
      "Episode:21 meanR:18.6364 R:21.0 rate:0.0420 loss:1.8518 exploreP:0.9602\n",
      "Episode:22 meanR:18.4783 R:15.0 rate:0.0300 loss:1.9645 exploreP:0.9588\n",
      "Episode:23 meanR:19.6667 R:47.0 rate:0.0940 loss:2.1804 exploreP:0.9544\n",
      "Episode:24 meanR:20.6800 R:45.0 rate:0.0900 loss:2.7947 exploreP:0.9501\n",
      "Episode:25 meanR:20.5000 R:16.0 rate:0.0320 loss:3.1570 exploreP:0.9486\n",
      "Episode:26 meanR:20.3704 R:17.0 rate:0.0340 loss:3.4344 exploreP:0.9470\n",
      "Episode:27 meanR:20.2857 R:18.0 rate:0.0360 loss:4.0182 exploreP:0.9453\n",
      "Episode:28 meanR:21.5862 R:58.0 rate:0.1160 loss:5.0947 exploreP:0.9399\n",
      "Episode:29 meanR:22.7333 R:56.0 rate:0.1120 loss:6.9886 exploreP:0.9347\n",
      "Episode:30 meanR:22.4194 R:13.0 rate:0.0260 loss:8.3218 exploreP:0.9335\n",
      "Episode:31 meanR:22.3125 R:19.0 rate:0.0380 loss:8.4090 exploreP:0.9318\n",
      "Episode:32 meanR:22.4242 R:26.0 rate:0.0520 loss:9.9855 exploreP:0.9294\n",
      "Episode:33 meanR:22.6765 R:31.0 rate:0.0620 loss:12.1692 exploreP:0.9265\n",
      "Episode:34 meanR:22.7714 R:26.0 rate:0.0520 loss:15.8330 exploreP:0.9242\n",
      "Episode:35 meanR:22.6389 R:18.0 rate:0.0360 loss:14.9764 exploreP:0.9225\n",
      "Episode:36 meanR:22.7297 R:26.0 rate:0.0520 loss:16.3628 exploreP:0.9201\n",
      "Episode:37 meanR:22.9737 R:32.0 rate:0.0640 loss:22.6560 exploreP:0.9172\n",
      "Episode:38 meanR:22.8718 R:19.0 rate:0.0380 loss:25.2182 exploreP:0.9155\n",
      "Episode:39 meanR:23.2750 R:39.0 rate:0.0780 loss:26.2176 exploreP:0.9120\n",
      "Episode:40 meanR:23.3659 R:27.0 rate:0.0540 loss:27.8389 exploreP:0.9096\n",
      "Episode:41 meanR:23.1905 R:16.0 rate:0.0320 loss:31.7772 exploreP:0.9081\n",
      "Episode:42 meanR:23.0233 R:16.0 rate:0.0320 loss:35.5611 exploreP:0.9067\n",
      "Episode:43 meanR:22.8864 R:17.0 rate:0.0340 loss:42.8503 exploreP:0.9052\n",
      "Episode:44 meanR:22.8667 R:22.0 rate:0.0440 loss:40.3227 exploreP:0.9032\n",
      "Episode:45 meanR:22.6739 R:14.0 rate:0.0280 loss:44.6926 exploreP:0.9019\n",
      "Episode:46 meanR:22.5532 R:17.0 rate:0.0340 loss:40.6869 exploreP:0.9004\n",
      "Episode:47 meanR:22.4792 R:19.0 rate:0.0380 loss:46.0049 exploreP:0.8987\n",
      "Episode:48 meanR:22.3061 R:14.0 rate:0.0280 loss:48.8253 exploreP:0.8975\n",
      "Episode:49 meanR:22.1600 R:15.0 rate:0.0300 loss:44.2184 exploreP:0.8962\n",
      "Episode:50 meanR:21.9216 R:10.0 rate:0.0200 loss:58.9475 exploreP:0.8953\n",
      "Episode:51 meanR:21.7885 R:15.0 rate:0.0300 loss:49.9289 exploreP:0.8940\n",
      "Episode:52 meanR:21.5472 R:9.0 rate:0.0180 loss:52.1782 exploreP:0.8932\n",
      "Episode:53 meanR:22.0000 R:46.0 rate:0.0920 loss:51.0254 exploreP:0.8891\n",
      "Episode:54 meanR:22.0364 R:24.0 rate:0.0480 loss:75.1153 exploreP:0.8870\n",
      "Episode:55 meanR:21.9821 R:19.0 rate:0.0380 loss:74.6814 exploreP:0.8853\n",
      "Episode:56 meanR:21.8596 R:15.0 rate:0.0300 loss:85.2098 exploreP:0.8840\n",
      "Episode:57 meanR:21.7931 R:18.0 rate:0.0360 loss:74.1253 exploreP:0.8824\n",
      "Episode:58 meanR:21.7627 R:20.0 rate:0.0400 loss:76.2025 exploreP:0.8807\n",
      "Episode:59 meanR:22.0667 R:40.0 rate:0.0800 loss:87.9673 exploreP:0.8772\n",
      "Episode:60 meanR:22.0820 R:23.0 rate:0.0460 loss:86.8287 exploreP:0.8752\n",
      "Episode:61 meanR:22.0000 R:17.0 rate:0.0340 loss:97.6217 exploreP:0.8738\n",
      "Episode:62 meanR:22.0000 R:22.0 rate:0.0440 loss:89.7884 exploreP:0.8719\n",
      "Episode:63 meanR:21.8438 R:12.0 rate:0.0240 loss:110.9130 exploreP:0.8708\n",
      "Episode:64 meanR:21.7538 R:16.0 rate:0.0320 loss:107.4641 exploreP:0.8695\n",
      "Episode:65 meanR:21.6212 R:13.0 rate:0.0260 loss:81.2443 exploreP:0.8683\n",
      "Episode:66 meanR:21.4925 R:13.0 rate:0.0260 loss:94.1876 exploreP:0.8672\n",
      "Episode:67 meanR:21.4265 R:17.0 rate:0.0340 loss:86.8765 exploreP:0.8658\n",
      "Episode:68 meanR:21.3913 R:19.0 rate:0.0380 loss:99.2649 exploreP:0.8641\n",
      "Episode:69 meanR:21.2143 R:9.0 rate:0.0180 loss:86.7559 exploreP:0.8634\n",
      "Episode:70 meanR:21.0704 R:11.0 rate:0.0220 loss:108.0542 exploreP:0.8624\n",
      "Episode:71 meanR:21.0972 R:23.0 rate:0.0460 loss:111.7077 exploreP:0.8605\n",
      "Episode:72 meanR:21.0000 R:14.0 rate:0.0280 loss:85.9366 exploreP:0.8593\n",
      "Episode:73 meanR:20.9730 R:19.0 rate:0.0380 loss:87.7024 exploreP:0.8577\n",
      "Episode:74 meanR:20.9067 R:16.0 rate:0.0320 loss:79.7452 exploreP:0.8563\n",
      "Episode:75 meanR:20.7632 R:10.0 rate:0.0200 loss:71.0133 exploreP:0.8555\n",
      "Episode:76 meanR:20.8182 R:25.0 rate:0.0500 loss:77.8014 exploreP:0.8534\n",
      "Episode:77 meanR:20.9615 R:32.0 rate:0.0640 loss:103.6700 exploreP:0.8507\n",
      "Episode:78 meanR:20.8481 R:12.0 rate:0.0240 loss:97.3222 exploreP:0.8497\n",
      "Episode:79 meanR:21.1000 R:41.0 rate:0.0820 loss:107.0359 exploreP:0.8462\n",
      "Episode:80 meanR:21.2099 R:30.0 rate:0.0600 loss:94.6939 exploreP:0.8437\n",
      "Episode:81 meanR:21.1220 R:14.0 rate:0.0280 loss:88.2377 exploreP:0.8426\n",
      "Episode:82 meanR:21.3253 R:38.0 rate:0.0760 loss:100.7590 exploreP:0.8394\n",
      "Episode:83 meanR:21.2857 R:18.0 rate:0.0360 loss:102.7963 exploreP:0.8379\n",
      "Episode:84 meanR:21.3412 R:26.0 rate:0.0520 loss:95.0102 exploreP:0.8358\n",
      "Episode:85 meanR:21.1977 R:9.0 rate:0.0180 loss:98.5457 exploreP:0.8350\n",
      "Episode:86 meanR:21.0805 R:11.0 rate:0.0220 loss:101.5067 exploreP:0.8341\n",
      "Episode:87 meanR:20.9545 R:10.0 rate:0.0200 loss:107.6890 exploreP:0.8333\n",
      "Episode:88 meanR:21.3034 R:52.0 rate:0.1040 loss:94.1857 exploreP:0.8290\n",
      "Episode:89 meanR:21.1889 R:11.0 rate:0.0220 loss:121.0690 exploreP:0.8281\n",
      "Episode:90 meanR:21.1319 R:16.0 rate:0.0320 loss:105.1423 exploreP:0.8268\n",
      "Episode:91 meanR:21.2391 R:31.0 rate:0.0620 loss:95.8622 exploreP:0.8243\n",
      "Episode:92 meanR:21.2151 R:19.0 rate:0.0380 loss:81.0509 exploreP:0.8227\n",
      "Episode:93 meanR:21.1383 R:14.0 rate:0.0280 loss:119.0007 exploreP:0.8216\n",
      "Episode:94 meanR:21.1263 R:20.0 rate:0.0400 loss:88.7930 exploreP:0.8200\n",
      "Episode:95 meanR:21.1562 R:24.0 rate:0.0480 loss:95.5804 exploreP:0.8180\n",
      "Episode:96 meanR:21.1443 R:20.0 rate:0.0400 loss:101.2885 exploreP:0.8164\n",
      "Episode:97 meanR:21.0510 R:12.0 rate:0.0240 loss:64.0036 exploreP:0.8155\n",
      "Episode:98 meanR:21.0606 R:22.0 rate:0.0440 loss:75.3933 exploreP:0.8137\n",
      "Episode:99 meanR:21.0800 R:23.0 rate:0.0460 loss:91.7164 exploreP:0.8118\n",
      "Episode:100 meanR:21.0300 R:16.0 rate:0.0320 loss:91.1871 exploreP:0.8106\n",
      "Episode:101 meanR:21.0300 R:18.0 rate:0.0360 loss:64.8765 exploreP:0.8091\n",
      "Episode:102 meanR:21.0100 R:20.0 rate:0.0400 loss:79.3501 exploreP:0.8075\n",
      "Episode:103 meanR:20.9700 R:15.0 rate:0.0300 loss:93.9198 exploreP:0.8063\n",
      "Episode:104 meanR:20.9800 R:19.0 rate:0.0380 loss:77.6110 exploreP:0.8048\n",
      "Episode:105 meanR:21.2000 R:35.0 rate:0.0700 loss:83.6011 exploreP:0.8020\n",
      "Episode:106 meanR:21.2100 R:19.0 rate:0.0380 loss:64.9576 exploreP:0.8005\n",
      "Episode:107 meanR:21.2400 R:16.0 rate:0.0320 loss:61.0939 exploreP:0.7993\n",
      "Episode:108 meanR:21.6000 R:49.0 rate:0.0980 loss:72.0243 exploreP:0.7954\n",
      "Episode:109 meanR:21.5300 R:15.0 rate:0.0300 loss:82.8487 exploreP:0.7942\n",
      "Episode:110 meanR:21.3800 R:15.0 rate:0.0300 loss:58.7219 exploreP:0.7931\n",
      "Episode:111 meanR:21.4500 R:30.0 rate:0.0600 loss:59.8311 exploreP:0.7907\n",
      "Episode:112 meanR:21.5600 R:22.0 rate:0.0440 loss:53.9245 exploreP:0.7890\n",
      "Episode:113 meanR:21.6200 R:24.0 rate:0.0480 loss:62.1826 exploreP:0.7871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:114 meanR:22.0200 R:51.0 rate:0.1020 loss:59.4320 exploreP:0.7832\n",
      "Episode:115 meanR:21.9700 R:16.0 rate:0.0320 loss:62.7774 exploreP:0.7819\n",
      "Episode:116 meanR:21.9400 R:18.0 rate:0.0360 loss:52.6597 exploreP:0.7806\n",
      "Episode:117 meanR:21.8100 R:10.0 rate:0.0200 loss:50.2963 exploreP:0.7798\n",
      "Episode:118 meanR:21.8000 R:13.0 rate:0.0260 loss:48.7943 exploreP:0.7788\n",
      "Episode:119 meanR:21.6800 R:12.0 rate:0.0240 loss:54.8435 exploreP:0.7779\n",
      "Episode:120 meanR:21.6600 R:14.0 rate:0.0280 loss:57.5740 exploreP:0.7768\n",
      "Episode:121 meanR:21.5800 R:13.0 rate:0.0260 loss:55.8540 exploreP:0.7758\n",
      "Episode:122 meanR:21.7000 R:27.0 rate:0.0540 loss:51.2273 exploreP:0.7737\n",
      "Episode:123 meanR:21.4600 R:23.0 rate:0.0460 loss:59.0369 exploreP:0.7720\n",
      "Episode:124 meanR:21.1500 R:14.0 rate:0.0280 loss:45.4805 exploreP:0.7709\n",
      "Episode:125 meanR:21.1100 R:12.0 rate:0.0240 loss:39.5086 exploreP:0.7700\n",
      "Episode:126 meanR:21.1800 R:24.0 rate:0.0480 loss:43.7610 exploreP:0.7682\n",
      "Episode:127 meanR:21.1300 R:13.0 rate:0.0260 loss:46.5792 exploreP:0.7672\n",
      "Episode:128 meanR:20.6800 R:13.0 rate:0.0260 loss:44.6631 exploreP:0.7662\n",
      "Episode:129 meanR:20.2400 R:12.0 rate:0.0240 loss:49.4183 exploreP:0.7653\n",
      "Episode:130 meanR:20.4700 R:36.0 rate:0.0720 loss:41.1863 exploreP:0.7626\n",
      "Episode:131 meanR:20.4100 R:13.0 rate:0.0260 loss:35.0255 exploreP:0.7616\n",
      "Episode:132 meanR:20.2700 R:12.0 rate:0.0240 loss:44.2230 exploreP:0.7607\n",
      "Episode:133 meanR:20.0800 R:12.0 rate:0.0240 loss:35.2723 exploreP:0.7598\n",
      "Episode:134 meanR:20.2100 R:39.0 rate:0.0780 loss:36.8204 exploreP:0.7569\n",
      "Episode:135 meanR:20.2300 R:20.0 rate:0.0400 loss:40.0298 exploreP:0.7554\n",
      "Episode:136 meanR:20.2500 R:28.0 rate:0.0560 loss:35.8689 exploreP:0.7533\n",
      "Episode:137 meanR:20.1800 R:25.0 rate:0.0500 loss:35.2178 exploreP:0.7514\n",
      "Episode:138 meanR:20.2100 R:22.0 rate:0.0440 loss:31.2582 exploreP:0.7498\n",
      "Episode:139 meanR:19.9600 R:14.0 rate:0.0280 loss:27.5663 exploreP:0.7488\n",
      "Episode:140 meanR:19.9400 R:25.0 rate:0.0500 loss:34.5277 exploreP:0.7469\n",
      "Episode:141 meanR:19.9500 R:17.0 rate:0.0340 loss:28.1213 exploreP:0.7457\n",
      "Episode:142 meanR:19.9800 R:19.0 rate:0.0380 loss:31.3271 exploreP:0.7443\n",
      "Episode:143 meanR:20.0300 R:22.0 rate:0.0440 loss:27.0968 exploreP:0.7427\n",
      "Episode:144 meanR:19.9800 R:17.0 rate:0.0340 loss:29.4319 exploreP:0.7414\n",
      "Episode:145 meanR:19.9800 R:14.0 rate:0.0280 loss:27.8761 exploreP:0.7404\n",
      "Episode:146 meanR:20.0000 R:19.0 rate:0.0380 loss:25.6918 exploreP:0.7390\n",
      "Episode:147 meanR:20.0400 R:23.0 rate:0.0460 loss:28.5901 exploreP:0.7373\n",
      "Episode:148 meanR:20.2100 R:31.0 rate:0.0620 loss:26.9402 exploreP:0.7351\n",
      "Episode:149 meanR:20.2600 R:20.0 rate:0.0400 loss:27.0896 exploreP:0.7336\n",
      "Episode:150 meanR:20.2600 R:10.0 rate:0.0200 loss:22.1706 exploreP:0.7329\n",
      "Episode:151 meanR:20.2900 R:18.0 rate:0.0360 loss:22.8635 exploreP:0.7316\n",
      "Episode:152 meanR:20.5600 R:36.0 rate:0.0720 loss:22.6959 exploreP:0.7290\n",
      "Episode:153 meanR:20.2600 R:16.0 rate:0.0320 loss:25.7409 exploreP:0.7279\n",
      "Episode:154 meanR:20.2400 R:22.0 rate:0.0440 loss:26.0762 exploreP:0.7263\n",
      "Episode:155 meanR:20.2600 R:21.0 rate:0.0420 loss:22.8866 exploreP:0.7248\n",
      "Episode:156 meanR:20.5100 R:40.0 rate:0.0800 loss:22.1718 exploreP:0.7219\n",
      "Episode:157 meanR:20.7300 R:40.0 rate:0.0800 loss:21.7516 exploreP:0.7191\n",
      "Episode:158 meanR:20.7500 R:22.0 rate:0.0440 loss:18.9202 exploreP:0.7175\n",
      "Episode:159 meanR:20.5600 R:21.0 rate:0.0420 loss:22.4180 exploreP:0.7161\n",
      "Episode:160 meanR:20.5800 R:25.0 rate:0.0500 loss:19.7204 exploreP:0.7143\n",
      "Episode:161 meanR:20.6800 R:27.0 rate:0.0540 loss:23.0138 exploreP:0.7124\n",
      "Episode:162 meanR:20.5900 R:13.0 rate:0.0260 loss:17.6493 exploreP:0.7115\n",
      "Episode:163 meanR:20.7400 R:27.0 rate:0.0540 loss:17.8063 exploreP:0.7096\n",
      "Episode:164 meanR:20.7500 R:17.0 rate:0.0340 loss:18.4280 exploreP:0.7084\n",
      "Episode:165 meanR:20.7700 R:15.0 rate:0.0300 loss:20.5634 exploreP:0.7074\n",
      "Episode:166 meanR:20.9800 R:34.0 rate:0.0680 loss:15.1232 exploreP:0.7050\n",
      "Episode:167 meanR:21.2200 R:41.0 rate:0.0820 loss:18.7236 exploreP:0.7022\n",
      "Episode:168 meanR:21.5400 R:51.0 rate:0.1020 loss:20.2391 exploreP:0.6986\n",
      "Episode:169 meanR:21.6000 R:15.0 rate:0.0300 loss:18.3080 exploreP:0.6976\n",
      "Episode:170 meanR:21.8300 R:34.0 rate:0.0680 loss:15.9840 exploreP:0.6953\n",
      "Episode:171 meanR:21.7700 R:17.0 rate:0.0340 loss:14.8973 exploreP:0.6941\n",
      "Episode:172 meanR:22.1000 R:47.0 rate:0.0940 loss:18.8359 exploreP:0.6909\n",
      "Episode:173 meanR:22.2400 R:33.0 rate:0.0660 loss:16.7852 exploreP:0.6886\n",
      "Episode:174 meanR:22.7900 R:71.0 rate:0.1420 loss:18.5152 exploreP:0.6838\n",
      "Episode:175 meanR:22.9200 R:23.0 rate:0.0460 loss:16.5888 exploreP:0.6823\n",
      "Episode:176 meanR:22.8800 R:21.0 rate:0.0420 loss:17.7636 exploreP:0.6809\n",
      "Episode:177 meanR:23.0200 R:46.0 rate:0.0920 loss:17.9912 exploreP:0.6778\n",
      "Episode:178 meanR:23.2200 R:32.0 rate:0.0640 loss:17.1962 exploreP:0.6757\n",
      "Episode:179 meanR:23.2000 R:39.0 rate:0.0780 loss:18.6274 exploreP:0.6731\n",
      "Episode:180 meanR:23.3000 R:40.0 rate:0.0800 loss:20.2230 exploreP:0.6704\n",
      "Episode:181 meanR:23.2900 R:13.0 rate:0.0260 loss:14.6371 exploreP:0.6696\n",
      "Episode:182 meanR:23.4200 R:51.0 rate:0.1020 loss:19.7595 exploreP:0.6662\n",
      "Episode:183 meanR:23.6800 R:44.0 rate:0.0880 loss:20.2704 exploreP:0.6633\n",
      "Episode:184 meanR:23.6600 R:24.0 rate:0.0480 loss:21.5348 exploreP:0.6618\n",
      "Episode:185 meanR:23.7100 R:14.0 rate:0.0280 loss:21.1268 exploreP:0.6609\n",
      "Episode:186 meanR:23.9000 R:30.0 rate:0.0600 loss:18.5622 exploreP:0.6589\n",
      "Episode:187 meanR:24.5200 R:72.0 rate:0.1440 loss:18.8924 exploreP:0.6543\n",
      "Episode:188 meanR:24.1600 R:16.0 rate:0.0320 loss:19.0684 exploreP:0.6532\n",
      "Episode:189 meanR:24.5400 R:49.0 rate:0.0980 loss:23.1026 exploreP:0.6501\n",
      "Episode:190 meanR:24.8100 R:43.0 rate:0.0860 loss:24.4808 exploreP:0.6473\n",
      "Episode:191 meanR:24.9800 R:48.0 rate:0.0960 loss:21.1673 exploreP:0.6443\n",
      "Episode:192 meanR:25.4400 R:65.0 rate:0.1300 loss:23.8697 exploreP:0.6402\n",
      "Episode:193 meanR:25.5400 R:24.0 rate:0.0480 loss:19.4076 exploreP:0.6387\n",
      "Episode:194 meanR:26.0600 R:72.0 rate:0.1440 loss:21.8233 exploreP:0.6342\n",
      "Episode:195 meanR:26.5100 R:69.0 rate:0.1380 loss:22.9232 exploreP:0.6299\n",
      "Episode:196 meanR:26.9100 R:60.0 rate:0.1200 loss:21.4017 exploreP:0.6262\n",
      "Episode:197 meanR:27.5000 R:71.0 rate:0.1420 loss:24.1459 exploreP:0.6218\n",
      "Episode:198 meanR:27.7000 R:42.0 rate:0.0840 loss:26.1890 exploreP:0.6192\n",
      "Episode:199 meanR:27.8300 R:36.0 rate:0.0720 loss:23.8087 exploreP:0.6170\n",
      "Episode:200 meanR:28.2700 R:60.0 rate:0.1200 loss:26.7557 exploreP:0.6134\n",
      "Episode:201 meanR:28.4800 R:39.0 rate:0.0780 loss:26.3346 exploreP:0.6111\n",
      "Episode:202 meanR:28.6800 R:40.0 rate:0.0800 loss:25.7434 exploreP:0.6087\n",
      "Episode:203 meanR:28.8300 R:30.0 rate:0.0600 loss:26.2493 exploreP:0.6069\n",
      "Episode:204 meanR:28.8100 R:17.0 rate:0.0340 loss:32.8403 exploreP:0.6059\n",
      "Episode:205 meanR:28.6900 R:23.0 rate:0.0460 loss:27.2456 exploreP:0.6045\n",
      "Episode:206 meanR:29.0700 R:57.0 rate:0.1140 loss:26.9598 exploreP:0.6011\n",
      "Episode:207 meanR:29.5700 R:66.0 rate:0.1320 loss:29.2048 exploreP:0.5972\n",
      "Episode:208 meanR:29.4700 R:39.0 rate:0.0780 loss:33.9666 exploreP:0.5949\n",
      "Episode:209 meanR:29.8500 R:53.0 rate:0.1060 loss:30.9974 exploreP:0.5918\n",
      "Episode:210 meanR:29.8400 R:14.0 rate:0.0280 loss:25.7992 exploreP:0.5910\n",
      "Episode:211 meanR:30.0500 R:51.0 rate:0.1020 loss:32.5732 exploreP:0.5881\n",
      "Episode:212 meanR:30.3900 R:56.0 rate:0.1120 loss:29.0612 exploreP:0.5848\n",
      "Episode:213 meanR:30.4400 R:29.0 rate:0.0580 loss:34.0254 exploreP:0.5832\n",
      "Episode:214 meanR:30.5200 R:59.0 rate:0.1180 loss:34.1145 exploreP:0.5798\n",
      "Episode:215 meanR:31.3800 R:102.0 rate:0.2040 loss:31.3633 exploreP:0.5740\n",
      "Episode:216 meanR:31.8400 R:64.0 rate:0.1280 loss:33.2435 exploreP:0.5704\n",
      "Episode:217 meanR:32.4800 R:74.0 rate:0.1480 loss:34.9437 exploreP:0.5663\n",
      "Episode:218 meanR:33.2300 R:88.0 rate:0.1760 loss:36.1440 exploreP:0.5614\n",
      "Episode:219 meanR:33.6000 R:49.0 rate:0.0980 loss:35.6435 exploreP:0.5587\n",
      "Episode:220 meanR:33.6800 R:22.0 rate:0.0440 loss:35.6451 exploreP:0.5575\n",
      "Episode:221 meanR:33.6700 R:12.0 rate:0.0240 loss:28.5521 exploreP:0.5569\n",
      "Episode:222 meanR:33.8600 R:46.0 rate:0.0920 loss:34.9040 exploreP:0.5544\n",
      "Episode:223 meanR:34.5900 R:96.0 rate:0.1920 loss:38.5421 exploreP:0.5492\n",
      "Episode:224 meanR:34.8800 R:43.0 rate:0.0860 loss:37.2884 exploreP:0.5468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:225 meanR:34.9900 R:23.0 rate:0.0460 loss:32.3538 exploreP:0.5456\n",
      "Episode:226 meanR:35.8900 R:114.0 rate:0.2280 loss:37.9309 exploreP:0.5395\n",
      "Episode:227 meanR:36.1000 R:34.0 rate:0.0680 loss:34.3856 exploreP:0.5377\n",
      "Episode:228 meanR:36.8400 R:87.0 rate:0.1740 loss:39.7266 exploreP:0.5332\n",
      "Episode:229 meanR:37.5400 R:82.0 rate:0.1640 loss:43.1936 exploreP:0.5289\n",
      "Episode:230 meanR:37.6800 R:50.0 rate:0.1000 loss:40.6173 exploreP:0.5263\n",
      "Episode:231 meanR:38.0700 R:52.0 rate:0.1040 loss:39.3081 exploreP:0.5236\n",
      "Episode:232 meanR:38.5300 R:58.0 rate:0.1160 loss:43.0000 exploreP:0.5207\n",
      "Episode:233 meanR:39.1200 R:71.0 rate:0.1420 loss:47.8724 exploreP:0.5170\n",
      "Episode:234 meanR:39.4800 R:75.0 rate:0.1500 loss:47.7616 exploreP:0.5133\n",
      "Episode:235 meanR:39.4100 R:13.0 rate:0.0260 loss:39.9653 exploreP:0.5126\n",
      "Episode:236 meanR:40.9000 R:177.0 rate:0.3540 loss:48.0542 exploreP:0.5038\n",
      "Episode:237 meanR:41.7100 R:106.0 rate:0.2120 loss:47.6660 exploreP:0.4986\n",
      "Episode:238 meanR:42.3200 R:83.0 rate:0.1660 loss:45.7937 exploreP:0.4945\n",
      "Episode:239 meanR:43.6900 R:151.0 rate:0.3020 loss:48.1510 exploreP:0.4873\n",
      "Episode:240 meanR:44.4200 R:98.0 rate:0.1960 loss:50.8036 exploreP:0.4826\n",
      "Episode:241 meanR:44.9200 R:67.0 rate:0.1340 loss:58.6334 exploreP:0.4795\n",
      "Episode:242 meanR:45.5400 R:81.0 rate:0.1620 loss:47.2856 exploreP:0.4757\n",
      "Episode:243 meanR:46.0400 R:72.0 rate:0.1440 loss:57.2530 exploreP:0.4723\n",
      "Episode:244 meanR:46.8000 R:93.0 rate:0.1860 loss:52.1320 exploreP:0.4681\n",
      "Episode:245 meanR:47.1400 R:48.0 rate:0.0960 loss:65.0623 exploreP:0.4659\n",
      "Episode:246 meanR:47.4900 R:54.0 rate:0.1080 loss:57.8913 exploreP:0.4634\n",
      "Episode:247 meanR:47.4200 R:16.0 rate:0.0320 loss:58.2959 exploreP:0.4627\n",
      "Episode:248 meanR:47.2600 R:15.0 rate:0.0300 loss:57.8605 exploreP:0.4620\n",
      "Episode:249 meanR:48.3000 R:124.0 rate:0.2480 loss:57.1886 exploreP:0.4564\n",
      "Episode:250 meanR:49.1300 R:93.0 rate:0.1860 loss:57.7680 exploreP:0.4523\n",
      "Episode:251 meanR:49.7600 R:81.0 rate:0.1620 loss:59.9126 exploreP:0.4487\n",
      "Episode:252 meanR:50.2500 R:85.0 rate:0.1700 loss:61.9357 exploreP:0.4450\n",
      "Episode:253 meanR:51.2100 R:112.0 rate:0.2240 loss:69.4551 exploreP:0.4402\n",
      "Episode:254 meanR:51.7300 R:74.0 rate:0.1480 loss:72.2027 exploreP:0.4370\n",
      "Episode:255 meanR:51.9400 R:42.0 rate:0.0840 loss:57.4075 exploreP:0.4352\n",
      "Episode:256 meanR:52.3600 R:82.0 rate:0.1640 loss:69.3954 exploreP:0.4317\n",
      "Episode:257 meanR:53.1900 R:123.0 rate:0.2460 loss:67.8218 exploreP:0.4266\n",
      "Episode:258 meanR:54.2300 R:126.0 rate:0.2520 loss:70.4779 exploreP:0.4214\n",
      "Episode:259 meanR:54.5300 R:51.0 rate:0.1020 loss:64.4923 exploreP:0.4193\n",
      "Episode:260 meanR:54.9100 R:63.0 rate:0.1260 loss:67.2490 exploreP:0.4167\n",
      "Episode:261 meanR:55.3000 R:66.0 rate:0.1320 loss:79.8060 exploreP:0.4140\n",
      "Episode:262 meanR:56.2700 R:110.0 rate:0.2200 loss:70.6130 exploreP:0.4096\n",
      "Episode:263 meanR:56.6700 R:67.0 rate:0.1340 loss:79.5085 exploreP:0.4069\n",
      "Episode:264 meanR:57.1300 R:63.0 rate:0.1260 loss:89.7177 exploreP:0.4045\n",
      "Episode:265 meanR:57.9600 R:98.0 rate:0.1960 loss:80.3802 exploreP:0.4006\n",
      "Episode:266 meanR:59.1600 R:154.0 rate:0.3080 loss:80.2025 exploreP:0.3946\n",
      "Episode:267 meanR:59.4100 R:66.0 rate:0.1320 loss:75.0929 exploreP:0.3921\n",
      "Episode:268 meanR:60.0700 R:117.0 rate:0.2340 loss:86.3873 exploreP:0.3877\n",
      "Episode:269 meanR:60.8400 R:92.0 rate:0.1840 loss:82.2918 exploreP:0.3842\n",
      "Episode:270 meanR:61.3800 R:88.0 rate:0.1760 loss:91.9041 exploreP:0.3809\n",
      "Episode:271 meanR:62.0200 R:81.0 rate:0.1620 loss:81.4154 exploreP:0.3779\n",
      "Episode:272 meanR:62.4300 R:88.0 rate:0.1760 loss:85.4444 exploreP:0.3747\n",
      "Episode:273 meanR:63.1600 R:106.0 rate:0.2120 loss:88.1503 exploreP:0.3709\n",
      "Episode:274 meanR:62.9800 R:53.0 rate:0.1060 loss:97.3203 exploreP:0.3690\n",
      "Episode:275 meanR:64.3700 R:162.0 rate:0.3240 loss:93.1464 exploreP:0.3632\n",
      "Episode:276 meanR:65.4000 R:124.0 rate:0.2480 loss:92.2583 exploreP:0.3588\n",
      "Episode:277 meanR:65.9800 R:104.0 rate:0.2080 loss:94.1622 exploreP:0.3552\n",
      "Episode:278 meanR:66.5700 R:91.0 rate:0.1820 loss:98.4303 exploreP:0.3521\n",
      "Episode:279 meanR:68.2600 R:208.0 rate:0.4160 loss:99.1175 exploreP:0.3451\n",
      "Episode:280 meanR:68.4200 R:56.0 rate:0.1120 loss:104.4372 exploreP:0.3432\n",
      "Episode:281 meanR:69.1600 R:87.0 rate:0.1740 loss:100.3785 exploreP:0.3403\n",
      "Episode:282 meanR:69.4200 R:77.0 rate:0.1540 loss:102.7294 exploreP:0.3378\n",
      "Episode:283 meanR:70.2100 R:123.0 rate:0.2460 loss:113.8773 exploreP:0.3338\n",
      "Episode:284 meanR:71.0700 R:110.0 rate:0.2200 loss:119.7421 exploreP:0.3302\n",
      "Episode:285 meanR:72.6500 R:172.0 rate:0.3440 loss:112.9927 exploreP:0.3248\n",
      "Episode:286 meanR:73.4100 R:106.0 rate:0.2120 loss:115.2125 exploreP:0.3214\n",
      "Episode:287 meanR:73.9100 R:122.0 rate:0.2440 loss:124.6122 exploreP:0.3177\n",
      "Episode:288 meanR:74.8400 R:109.0 rate:0.2180 loss:118.0713 exploreP:0.3143\n",
      "Episode:289 meanR:75.8000 R:145.0 rate:0.2900 loss:117.8262 exploreP:0.3099\n",
      "Episode:290 meanR:76.6200 R:125.0 rate:0.2500 loss:109.8048 exploreP:0.3062\n",
      "Episode:291 meanR:77.7300 R:159.0 rate:0.3180 loss:122.2437 exploreP:0.3015\n",
      "Episode:292 meanR:78.0800 R:100.0 rate:0.2000 loss:121.2957 exploreP:0.2986\n",
      "Episode:293 meanR:80.2500 R:241.0 rate:0.4820 loss:121.2632 exploreP:0.2918\n",
      "Episode:294 meanR:81.4400 R:191.0 rate:0.3820 loss:141.0159 exploreP:0.2864\n",
      "Episode:295 meanR:82.4300 R:168.0 rate:0.3360 loss:136.9912 exploreP:0.2818\n",
      "Episode:296 meanR:83.9500 R:212.0 rate:0.4240 loss:137.0563 exploreP:0.2761\n",
      "Episode:297 meanR:84.5900 R:135.0 rate:0.2700 loss:146.6290 exploreP:0.2726\n",
      "Episode:298 meanR:85.4400 R:127.0 rate:0.2540 loss:147.3762 exploreP:0.2693\n",
      "Episode:299 meanR:86.1700 R:109.0 rate:0.2180 loss:145.2317 exploreP:0.2664\n",
      "Episode:300 meanR:86.8200 R:125.0 rate:0.2500 loss:137.3261 exploreP:0.2633\n",
      "Episode:301 meanR:87.7600 R:133.0 rate:0.2660 loss:156.7517 exploreP:0.2599\n",
      "Episode:302 meanR:88.5300 R:117.0 rate:0.2340 loss:162.1556 exploreP:0.2570\n",
      "Episode:303 meanR:90.9000 R:267.0 rate:0.5340 loss:165.1958 exploreP:0.2505\n",
      "Episode:304 meanR:92.5300 R:180.0 rate:0.3600 loss:154.6029 exploreP:0.2462\n",
      "Episode:305 meanR:93.3800 R:108.0 rate:0.2160 loss:172.5689 exploreP:0.2437\n",
      "Episode:306 meanR:94.0800 R:127.0 rate:0.2540 loss:172.8628 exploreP:0.2407\n",
      "Episode:307 meanR:95.4000 R:198.0 rate:0.3960 loss:175.4940 exploreP:0.2362\n",
      "Episode:308 meanR:96.3200 R:131.0 rate:0.2620 loss:190.6140 exploreP:0.2333\n",
      "Episode:309 meanR:96.9200 R:113.0 rate:0.2260 loss:167.3205 exploreP:0.2307\n",
      "Episode:310 meanR:98.8100 R:203.0 rate:0.4060 loss:181.2707 exploreP:0.2263\n",
      "Episode:311 meanR:100.1400 R:184.0 rate:0.3680 loss:173.2804 exploreP:0.2224\n",
      "Episode:312 meanR:101.7500 R:217.0 rate:0.4340 loss:207.9964 exploreP:0.2178\n",
      "Episode:313 meanR:103.1100 R:165.0 rate:0.3300 loss:162.5281 exploreP:0.2144\n",
      "Episode:314 meanR:104.7200 R:220.0 rate:0.4400 loss:228.0808 exploreP:0.2100\n",
      "Episode:315 meanR:105.2300 R:153.0 rate:0.3060 loss:187.4026 exploreP:0.2069\n",
      "Episode:316 meanR:106.7300 R:214.0 rate:0.4280 loss:227.2197 exploreP:0.2028\n",
      "Episode:317 meanR:107.2200 R:123.0 rate:0.2460 loss:200.8887 exploreP:0.2004\n",
      "Episode:318 meanR:108.0600 R:172.0 rate:0.3440 loss:202.6022 exploreP:0.1971\n",
      "Episode:319 meanR:110.1700 R:260.0 rate:0.5200 loss:233.4568 exploreP:0.1923\n",
      "Episode:320 meanR:111.2900 R:134.0 rate:0.2680 loss:194.0558 exploreP:0.1899\n",
      "Episode:321 meanR:113.4900 R:232.0 rate:0.4640 loss:240.0188 exploreP:0.1858\n",
      "Episode:322 meanR:116.4600 R:343.0 rate:0.6860 loss:222.6388 exploreP:0.1799\n",
      "Episode:323 meanR:117.8800 R:238.0 rate:0.4760 loss:239.7942 exploreP:0.1759\n",
      "Episode:324 meanR:119.7400 R:229.0 rate:0.4580 loss:212.9639 exploreP:0.1721\n",
      "Episode:325 meanR:122.0500 R:254.0 rate:0.5080 loss:232.4501 exploreP:0.1680\n",
      "Episode:326 meanR:123.7400 R:283.0 rate:0.5660 loss:232.2101 exploreP:0.1636\n",
      "Episode:327 meanR:126.7000 R:330.0 rate:0.6600 loss:258.7982 exploreP:0.1587\n",
      "Episode:328 meanR:127.8300 R:200.0 rate:0.4000 loss:249.0798 exploreP:0.1557\n",
      "Episode:329 meanR:128.7400 R:173.0 rate:0.3460 loss:304.5218 exploreP:0.1532\n",
      "Episode:330 meanR:130.9400 R:270.0 rate:0.5400 loss:279.6517 exploreP:0.1494\n",
      "Episode:331 meanR:132.5900 R:217.0 rate:0.4340 loss:259.2343 exploreP:0.1464\n",
      "Episode:332 meanR:136.8500 R:484.0 rate:0.9680 loss:261.3878 exploreP:0.1400\n",
      "Episode:333 meanR:138.5300 R:239.0 rate:0.4780 loss:251.5699 exploreP:0.1369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:334 meanR:140.5000 R:272.0 rate:0.5440 loss:259.7885 exploreP:0.1335\n",
      "Episode:335 meanR:144.7300 R:436.0 rate:0.8720 loss:270.7763 exploreP:0.1282\n",
      "Episode:336 meanR:146.0600 R:310.0 rate:0.6200 loss:280.6041 exploreP:0.1246\n",
      "Episode:337 meanR:147.6500 R:265.0 rate:0.5300 loss:250.9721 exploreP:0.1216\n",
      "Episode:338 meanR:149.3900 R:257.0 rate:0.5140 loss:219.7869 exploreP:0.1188\n",
      "Episode:339 meanR:150.1300 R:225.0 rate:0.4500 loss:194.1490 exploreP:0.1164\n",
      "Episode:340 meanR:151.4300 R:228.0 rate:0.4560 loss:249.6533 exploreP:0.1140\n",
      "Episode:341 meanR:153.0300 R:227.0 rate:0.4540 loss:263.9418 exploreP:0.1116\n",
      "Episode:342 meanR:154.3400 R:212.0 rate:0.4240 loss:246.4753 exploreP:0.1095\n",
      "Episode:343 meanR:155.8400 R:222.0 rate:0.4440 loss:232.6557 exploreP:0.1073\n",
      "Episode:344 meanR:157.8900 R:298.0 rate:0.5960 loss:256.4047 exploreP:0.1045\n",
      "Episode:345 meanR:159.3900 R:198.0 rate:0.3960 loss:240.8142 exploreP:0.1026\n",
      "Episode:346 meanR:163.1100 R:426.0 rate:0.8520 loss:251.2836 exploreP:0.0987\n",
      "Episode:347 meanR:165.7600 R:281.0 rate:0.5620 loss:207.4258 exploreP:0.0963\n",
      "Episode:348 meanR:168.8400 R:323.0 rate:0.6460 loss:232.3145 exploreP:0.0935\n",
      "Episode:349 meanR:170.0000 R:240.0 rate:0.4800 loss:210.8076 exploreP:0.0916\n",
      "Episode:350 meanR:170.9600 R:189.0 rate:0.3780 loss:220.8609 exploreP:0.0900\n",
      "Episode:351 meanR:173.9500 R:380.0 rate:0.7600 loss:210.6248 exploreP:0.0870\n",
      "Episode:352 meanR:174.9700 R:187.0 rate:0.3740 loss:203.6888 exploreP:0.0856\n",
      "Episode:353 meanR:177.1600 R:331.0 rate:0.6620 loss:212.0615 exploreP:0.0832\n",
      "Episode:354 meanR:178.2200 R:180.0 rate:0.3600 loss:209.8638 exploreP:0.0819\n",
      "Episode:355 meanR:180.5300 R:273.0 rate:0.5460 loss:201.4003 exploreP:0.0799\n",
      "Episode:356 meanR:182.0300 R:232.0 rate:0.4640 loss:209.6184 exploreP:0.0783\n",
      "Episode:357 meanR:182.8700 R:207.0 rate:0.4140 loss:170.7907 exploreP:0.0769\n",
      "Episode:358 meanR:183.4700 R:186.0 rate:0.3720 loss:151.5390 exploreP:0.0757\n",
      "Episode:359 meanR:184.9700 R:201.0 rate:0.4020 loss:189.1109 exploreP:0.0744\n",
      "Episode:360 meanR:186.9600 R:262.0 rate:0.5240 loss:194.7225 exploreP:0.0727\n",
      "Episode:361 meanR:189.4000 R:310.0 rate:0.6200 loss:190.4727 exploreP:0.0708\n",
      "Episode:362 meanR:191.2200 R:292.0 rate:0.5840 loss:182.4124 exploreP:0.0690\n",
      "Episode:363 meanR:193.3100 R:276.0 rate:0.5520 loss:211.8754 exploreP:0.0674\n",
      "Episode:364 meanR:196.5100 R:383.0 rate:0.7660 loss:180.5544 exploreP:0.0653\n",
      "Episode:365 meanR:199.7500 R:422.0 rate:0.8440 loss:151.8941 exploreP:0.0630\n",
      "Episode:366 meanR:200.2300 R:202.0 rate:0.4040 loss:175.5119 exploreP:0.0619\n",
      "Episode:367 meanR:204.5700 R:500.0 rate:1.0000 loss:137.2724 exploreP:0.0594\n",
      "Episode:368 meanR:206.0200 R:262.0 rate:0.5240 loss:164.0766 exploreP:0.0581\n",
      "Episode:369 meanR:208.1700 R:307.0 rate:0.6140 loss:139.2014 exploreP:0.0567\n",
      "Episode:370 meanR:209.8200 R:253.0 rate:0.5060 loss:149.9678 exploreP:0.0555\n",
      "Episode:371 meanR:211.4300 R:242.0 rate:0.4840 loss:127.8935 exploreP:0.0544\n",
      "Episode:372 meanR:214.3300 R:378.0 rate:0.7560 loss:143.8613 exploreP:0.0528\n",
      "Episode:373 meanR:215.9900 R:272.0 rate:0.5440 loss:145.8407 exploreP:0.0516\n",
      "Episode:374 meanR:217.8500 R:239.0 rate:0.4780 loss:122.8000 exploreP:0.0506\n",
      "Episode:375 meanR:218.0600 R:183.0 rate:0.3660 loss:115.8222 exploreP:0.0499\n",
      "Episode:376 meanR:219.6100 R:279.0 rate:0.5580 loss:130.0731 exploreP:0.0488\n",
      "Episode:377 meanR:222.0400 R:347.0 rate:0.6940 loss:141.2762 exploreP:0.0475\n",
      "Episode:378 meanR:224.0700 R:294.0 rate:0.5880 loss:138.8879 exploreP:0.0464\n",
      "Episode:379 meanR:224.9700 R:298.0 rate:0.5960 loss:158.5947 exploreP:0.0453\n",
      "Episode:380 meanR:227.0200 R:261.0 rate:0.5220 loss:167.6012 exploreP:0.0444\n",
      "Episode:381 meanR:229.1200 R:297.0 rate:0.5940 loss:177.4408 exploreP:0.0434\n",
      "Episode:382 meanR:230.8800 R:253.0 rate:0.5060 loss:167.0783 exploreP:0.0426\n",
      "Episode:383 meanR:234.4400 R:479.0 rate:0.9580 loss:222.5964 exploreP:0.0411\n",
      "Episode:384 meanR:237.3200 R:398.0 rate:0.7960 loss:245.9668 exploreP:0.0398\n",
      "Episode:385 meanR:239.8100 R:421.0 rate:0.8420 loss:268.9828 exploreP:0.0386\n",
      "Episode:386 meanR:240.8800 R:213.0 rate:0.4260 loss:323.5582 exploreP:0.0380\n",
      "Episode:387 meanR:243.9800 R:432.0 rate:0.8640 loss:336.7910 exploreP:0.0368\n",
      "Episode:388 meanR:246.6900 R:380.0 rate:0.7600 loss:374.2456 exploreP:0.0358\n",
      "Episode:389 meanR:247.0500 R:181.0 rate:0.3620 loss:432.4906 exploreP:0.0354\n",
      "Episode:390 meanR:248.4700 R:267.0 rate:0.5340 loss:400.5265 exploreP:0.0347\n",
      "Episode:391 meanR:251.8800 R:500.0 rate:1.0000 loss:500.2542 exploreP:0.0335\n",
      "Episode:392 meanR:252.8600 R:198.0 rate:0.3960 loss:607.3195 exploreP:0.0330\n",
      "Episode:393 meanR:254.8600 R:441.0 rate:0.8820 loss:683.2104 exploreP:0.0320\n",
      "Episode:394 meanR:257.0300 R:408.0 rate:0.8160 loss:704.8566 exploreP:0.0312\n",
      "Episode:395 meanR:257.4500 R:210.0 rate:0.4200 loss:751.2028 exploreP:0.0307\n",
      "Episode:396 meanR:257.0200 R:169.0 rate:0.3380 loss:866.0533 exploreP:0.0304\n",
      "Episode:397 meanR:259.2900 R:362.0 rate:0.7240 loss:967.4191 exploreP:0.0296\n",
      "Episode:398 meanR:259.8800 R:186.0 rate:0.3720 loss:951.5267 exploreP:0.0293\n",
      "Episode:399 meanR:261.0500 R:226.0 rate:0.4520 loss:1090.5110 exploreP:0.0288\n",
      "Episode:400 meanR:263.8900 R:409.0 rate:0.8180 loss:1176.7500 exploreP:0.0281\n",
      "Episode:401 meanR:264.1700 R:161.0 rate:0.3220 loss:1336.1846 exploreP:0.0278\n",
      "Episode:402 meanR:265.5500 R:255.0 rate:0.5100 loss:1430.3929 exploreP:0.0274\n",
      "Episode:403 meanR:265.5100 R:263.0 rate:0.5260 loss:1514.7208 exploreP:0.0269\n",
      "Episode:404 meanR:265.1400 R:143.0 rate:0.2860 loss:1583.8330 exploreP:0.0267\n",
      "Episode:405 meanR:265.7700 R:171.0 rate:0.3420 loss:1640.7654 exploreP:0.0264\n",
      "Episode:406 meanR:269.3900 R:489.0 rate:0.9780 loss:1784.3510 exploreP:0.0256\n",
      "Episode:407 meanR:269.8000 R:239.0 rate:0.4780 loss:2417.9460 exploreP:0.0252\n",
      "Episode:408 meanR:271.0800 R:259.0 rate:0.5180 loss:2392.7744 exploreP:0.0248\n",
      "Episode:409 meanR:272.4800 R:253.0 rate:0.5060 loss:2741.9846 exploreP:0.0245\n",
      "Episode:410 meanR:272.6400 R:219.0 rate:0.4380 loss:3235.3601 exploreP:0.0242\n",
      "Episode:411 meanR:273.0900 R:229.0 rate:0.4580 loss:3556.4292 exploreP:0.0238\n",
      "Episode:412 meanR:273.8900 R:297.0 rate:0.5940 loss:3779.9319 exploreP:0.0234\n",
      "Episode:413 meanR:275.6700 R:343.0 rate:0.6860 loss:4301.2158 exploreP:0.0230\n",
      "Episode:414 meanR:275.5100 R:204.0 rate:0.4080 loss:4562.8047 exploreP:0.0227\n",
      "Episode:415 meanR:275.7100 R:173.0 rate:0.3460 loss:4820.0830 exploreP:0.0225\n",
      "Episode:416 meanR:275.3800 R:181.0 rate:0.3620 loss:4921.9937 exploreP:0.0223\n",
      "Episode:417 meanR:276.3200 R:217.0 rate:0.4340 loss:5081.0376 exploreP:0.0220\n",
      "Episode:418 meanR:276.7300 R:213.0 rate:0.4260 loss:5451.4565 exploreP:0.0218\n",
      "Episode:419 meanR:276.0000 R:187.0 rate:0.3740 loss:5409.3242 exploreP:0.0215\n",
      "Episode:420 meanR:276.5900 R:193.0 rate:0.3860 loss:6016.6343 exploreP:0.0213\n",
      "Episode:421 meanR:276.4900 R:222.0 rate:0.4440 loss:6671.0527 exploreP:0.0211\n",
      "Episode:422 meanR:274.8800 R:182.0 rate:0.3640 loss:7163.5454 exploreP:0.0209\n",
      "Episode:423 meanR:276.3600 R:386.0 rate:0.7720 loss:7593.4028 exploreP:0.0205\n",
      "Episode:424 meanR:276.0800 R:201.0 rate:0.4020 loss:8605.0879 exploreP:0.0203\n",
      "Episode:425 meanR:275.6700 R:213.0 rate:0.4260 loss:8547.1465 exploreP:0.0200\n",
      "Episode:426 meanR:274.2300 R:139.0 rate:0.2780 loss:9229.3086 exploreP:0.0199\n",
      "Episode:427 meanR:274.4000 R:347.0 rate:0.6940 loss:9424.4795 exploreP:0.0196\n",
      "Episode:428 meanR:275.7200 R:332.0 rate:0.6640 loss:10597.0107 exploreP:0.0192\n",
      "Episode:429 meanR:275.7200 R:173.0 rate:0.3460 loss:10675.5098 exploreP:0.0191\n",
      "Episode:430 meanR:275.1800 R:216.0 rate:0.4320 loss:11469.0859 exploreP:0.0189\n",
      "Episode:431 meanR:276.2300 R:322.0 rate:0.6440 loss:12232.1191 exploreP:0.0186\n",
      "Episode:432 meanR:273.4700 R:208.0 rate:0.4160 loss:12418.8848 exploreP:0.0184\n",
      "Episode:433 meanR:275.8200 R:474.0 rate:0.9480 loss:13709.9600 exploreP:0.0180\n",
      "Episode:434 meanR:274.6100 R:151.0 rate:0.3020 loss:15058.1924 exploreP:0.0179\n",
      "Episode:435 meanR:275.2500 R:500.0 rate:1.0000 loss:15780.6904 exploreP:0.0175\n",
      "Episode:436 meanR:277.1500 R:500.0 rate:1.0000 loss:17823.9160 exploreP:0.0172\n",
      "Episode:437 meanR:279.5000 R:500.0 rate:1.0000 loss:18792.3203 exploreP:0.0168\n",
      "Episode:438 meanR:281.9300 R:500.0 rate:1.0000 loss:20393.0234 exploreP:0.0165\n",
      "Episode:439 meanR:284.6800 R:500.0 rate:1.0000 loss:22035.6465 exploreP:0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:440 meanR:287.4000 R:500.0 rate:1.0000 loss:24143.0762 exploreP:0.0159\n",
      "Episode:441 meanR:290.1300 R:500.0 rate:1.0000 loss:24528.9004 exploreP:0.0156\n",
      "Episode:442 meanR:293.0100 R:500.0 rate:1.0000 loss:25797.9902 exploreP:0.0153\n",
      "Episode:443 meanR:295.7900 R:500.0 rate:1.0000 loss:26182.4316 exploreP:0.0151\n",
      "Episode:444 meanR:297.8100 R:500.0 rate:1.0000 loss:26326.7754 exploreP:0.0148\n",
      "Episode:445 meanR:300.8300 R:500.0 rate:1.0000 loss:24712.5918 exploreP:0.0146\n",
      "Episode:446 meanR:301.5700 R:500.0 rate:1.0000 loss:25996.3633 exploreP:0.0143\n",
      "Episode:447 meanR:303.7600 R:500.0 rate:1.0000 loss:25987.6445 exploreP:0.0141\n",
      "Episode:448 meanR:305.5300 R:500.0 rate:1.0000 loss:24676.4082 exploreP:0.0139\n",
      "Episode:449 meanR:308.1300 R:500.0 rate:1.0000 loss:24026.1094 exploreP:0.0137\n",
      "Episode:450 meanR:311.2400 R:500.0 rate:1.0000 loss:25059.5195 exploreP:0.0136\n",
      "Episode:451 meanR:312.4400 R:500.0 rate:1.0000 loss:23116.3516 exploreP:0.0134\n",
      "Episode:452 meanR:315.5700 R:500.0 rate:1.0000 loss:21628.9688 exploreP:0.0132\n",
      "Episode:453 meanR:317.2600 R:500.0 rate:1.0000 loss:18249.5527 exploreP:0.0131\n",
      "Episode:454 meanR:320.4600 R:500.0 rate:1.0000 loss:16633.2617 exploreP:0.0129\n",
      "Episode:455 meanR:322.7300 R:500.0 rate:1.0000 loss:16372.2021 exploreP:0.0128\n",
      "Episode:456 meanR:325.4100 R:500.0 rate:1.0000 loss:17312.7285 exploreP:0.0126\n",
      "Episode:457 meanR:328.3400 R:500.0 rate:1.0000 loss:18557.7832 exploreP:0.0125\n",
      "Episode:458 meanR:331.4800 R:500.0 rate:1.0000 loss:18976.7852 exploreP:0.0124\n",
      "Episode:459 meanR:334.4700 R:500.0 rate:1.0000 loss:16788.3711 exploreP:0.0123\n",
      "Episode:460 meanR:336.8500 R:500.0 rate:1.0000 loss:16735.3828 exploreP:0.0122\n",
      "Episode:461 meanR:338.7500 R:500.0 rate:1.0000 loss:18601.8008 exploreP:0.0121\n",
      "Episode:462 meanR:340.8300 R:500.0 rate:1.0000 loss:20856.5273 exploreP:0.0120\n",
      "Episode:463 meanR:343.0700 R:500.0 rate:1.0000 loss:22902.2969 exploreP:0.0119\n",
      "Episode:464 meanR:344.2400 R:500.0 rate:1.0000 loss:25031.9316 exploreP:0.0118\n",
      "Episode:465 meanR:345.0200 R:500.0 rate:1.0000 loss:27933.1074 exploreP:0.0117\n",
      "Episode:466 meanR:346.4200 R:342.0 rate:0.6840 loss:31268.8477 exploreP:0.0116\n",
      "Episode:467 meanR:346.4200 R:500.0 rate:1.0000 loss:33628.8945 exploreP:0.0115\n",
      "Episode:468 meanR:348.8000 R:500.0 rate:1.0000 loss:35137.9609 exploreP:0.0115\n",
      "Episode:469 meanR:350.7300 R:500.0 rate:1.0000 loss:35208.2383 exploreP:0.0114\n",
      "Episode:470 meanR:353.2000 R:500.0 rate:1.0000 loss:36516.4961 exploreP:0.0113\n",
      "Episode:471 meanR:355.7800 R:500.0 rate:1.0000 loss:37483.4922 exploreP:0.0113\n",
      "Episode:472 meanR:357.0000 R:500.0 rate:1.0000 loss:35877.3555 exploreP:0.0112\n",
      "Episode:473 meanR:359.2800 R:500.0 rate:1.0000 loss:33061.1328 exploreP:0.0111\n",
      "Episode:474 meanR:361.8900 R:500.0 rate:1.0000 loss:31916.0605 exploreP:0.0111\n",
      "Episode:475 meanR:365.0600 R:500.0 rate:1.0000 loss:30715.1289 exploreP:0.0110\n",
      "Episode:476 meanR:367.2700 R:500.0 rate:1.0000 loss:33400.3516 exploreP:0.0110\n",
      "Episode:477 meanR:368.8000 R:500.0 rate:1.0000 loss:34101.7656 exploreP:0.0109\n",
      "Episode:478 meanR:370.8600 R:500.0 rate:1.0000 loss:30601.2422 exploreP:0.0109\n",
      "Episode:479 meanR:372.8800 R:500.0 rate:1.0000 loss:27018.5293 exploreP:0.0108\n",
      "Episode:480 meanR:375.2700 R:500.0 rate:1.0000 loss:22740.4434 exploreP:0.0108\n",
      "Episode:481 meanR:377.3000 R:500.0 rate:1.0000 loss:19051.9316 exploreP:0.0108\n",
      "Episode:482 meanR:379.7700 R:500.0 rate:1.0000 loss:18364.1074 exploreP:0.0107\n",
      "Episode:483 meanR:379.9800 R:500.0 rate:1.0000 loss:19381.1367 exploreP:0.0107\n",
      "Episode:484 meanR:380.7600 R:476.0 rate:0.9520 loss:18740.3086 exploreP:0.0107\n",
      "Episode:485 meanR:381.5500 R:500.0 rate:1.0000 loss:18799.9766 exploreP:0.0106\n",
      "Episode:486 meanR:384.4200 R:500.0 rate:1.0000 loss:20855.0840 exploreP:0.0106\n",
      "Episode:487 meanR:385.1000 R:500.0 rate:1.0000 loss:24013.8203 exploreP:0.0106\n",
      "Episode:488 meanR:386.3000 R:500.0 rate:1.0000 loss:25067.1191 exploreP:0.0105\n",
      "Episode:489 meanR:389.4900 R:500.0 rate:1.0000 loss:26894.8848 exploreP:0.0105\n",
      "Episode:490 meanR:391.8200 R:500.0 rate:1.0000 loss:27311.6465 exploreP:0.0105\n",
      "Episode:491 meanR:391.8200 R:500.0 rate:1.0000 loss:26580.6855 exploreP:0.0105\n",
      "Episode:492 meanR:394.8400 R:500.0 rate:1.0000 loss:25653.7637 exploreP:0.0104\n",
      "Episode:493 meanR:395.4300 R:500.0 rate:1.0000 loss:23930.4824 exploreP:0.0104\n",
      "Episode:494 meanR:396.3500 R:500.0 rate:1.0000 loss:24317.6445 exploreP:0.0104\n",
      "Episode:495 meanR:399.2500 R:500.0 rate:1.0000 loss:25087.8203 exploreP:0.0104\n",
      "Episode:496 meanR:402.5600 R:500.0 rate:1.0000 loss:27100.8398 exploreP:0.0104\n",
      "Episode:497 meanR:403.9400 R:500.0 rate:1.0000 loss:28902.1758 exploreP:0.0103\n",
      "Episode:498 meanR:407.0800 R:500.0 rate:1.0000 loss:29994.0078 exploreP:0.0103\n",
      "Episode:499 meanR:409.8200 R:500.0 rate:1.0000 loss:28638.8906 exploreP:0.0103\n",
      "Episode:500 meanR:410.7300 R:500.0 rate:1.0000 loss:26157.2441 exploreP:0.0103\n",
      "Episode:501 meanR:414.1200 R:500.0 rate:1.0000 loss:24478.6074 exploreP:0.0103\n",
      "Episode:502 meanR:416.5700 R:500.0 rate:1.0000 loss:21492.3594 exploreP:0.0103\n",
      "Episode:503 meanR:418.9400 R:500.0 rate:1.0000 loss:17353.0098 exploreP:0.0103\n",
      "Episode:504 meanR:422.5100 R:500.0 rate:1.0000 loss:14379.8223 exploreP:0.0102\n",
      "Episode:505 meanR:425.8000 R:500.0 rate:1.0000 loss:12034.0820 exploreP:0.0102\n",
      "Episode:506 meanR:425.9100 R:500.0 rate:1.0000 loss:10032.6416 exploreP:0.0102\n",
      "Episode:507 meanR:428.5200 R:500.0 rate:1.0000 loss:8141.8066 exploreP:0.0102\n",
      "Episode:508 meanR:430.9300 R:500.0 rate:1.0000 loss:7382.2661 exploreP:0.0102\n",
      "Episode:509 meanR:433.4000 R:500.0 rate:1.0000 loss:6837.8149 exploreP:0.0102\n",
      "Episode:510 meanR:436.2100 R:500.0 rate:1.0000 loss:7161.1958 exploreP:0.0102\n",
      "Episode:511 meanR:438.9200 R:500.0 rate:1.0000 loss:7711.3730 exploreP:0.0102\n",
      "Episode:512 meanR:440.9500 R:500.0 rate:1.0000 loss:8002.6929 exploreP:0.0102\n",
      "Episode:513 meanR:442.5200 R:500.0 rate:1.0000 loss:9056.5664 exploreP:0.0102\n",
      "Episode:514 meanR:445.4800 R:500.0 rate:1.0000 loss:9692.6416 exploreP:0.0101\n",
      "Episode:515 meanR:448.7500 R:500.0 rate:1.0000 loss:9223.9775 exploreP:0.0101\n",
      "Episode:516 meanR:451.9400 R:500.0 rate:1.0000 loss:9483.0742 exploreP:0.0101\n",
      "Episode:517 meanR:454.7700 R:500.0 rate:1.0000 loss:9919.3496 exploreP:0.0101\n",
      "Episode:518 meanR:457.6400 R:500.0 rate:1.0000 loss:9780.4229 exploreP:0.0101\n",
      "Episode:519 meanR:460.7700 R:500.0 rate:1.0000 loss:10509.8584 exploreP:0.0101\n",
      "Episode:520 meanR:463.8400 R:500.0 rate:1.0000 loss:11226.0840 exploreP:0.0101\n",
      "Episode:521 meanR:466.6200 R:500.0 rate:1.0000 loss:11750.6289 exploreP:0.0101\n",
      "Episode:522 meanR:469.8000 R:500.0 rate:1.0000 loss:12287.7520 exploreP:0.0101\n",
      "Episode:523 meanR:470.9400 R:500.0 rate:1.0000 loss:12900.0645 exploreP:0.0101\n",
      "Episode:524 meanR:473.9300 R:500.0 rate:1.0000 loss:14508.5762 exploreP:0.0101\n",
      "Episode:525 meanR:476.8000 R:500.0 rate:1.0000 loss:14464.3662 exploreP:0.0101\n",
      "Episode:526 meanR:480.4100 R:500.0 rate:1.0000 loss:14826.2061 exploreP:0.0101\n",
      "Episode:527 meanR:481.9400 R:500.0 rate:1.0000 loss:15615.2578 exploreP:0.0101\n",
      "Episode:528 meanR:483.6200 R:500.0 rate:1.0000 loss:17289.9824 exploreP:0.0101\n",
      "Episode:529 meanR:486.8900 R:500.0 rate:1.0000 loss:18112.9648 exploreP:0.0101\n",
      "Episode:530 meanR:489.7300 R:500.0 rate:1.0000 loss:19767.6562 exploreP:0.0101\n",
      "Episode:531 meanR:491.5100 R:500.0 rate:1.0000 loss:20736.5742 exploreP:0.0101\n",
      "Episode:532 meanR:494.4300 R:500.0 rate:1.0000 loss:21484.2930 exploreP:0.0101\n",
      "Episode:533 meanR:494.6900 R:500.0 rate:1.0000 loss:22536.1484 exploreP:0.0101\n",
      "Episode:534 meanR:498.1800 R:500.0 rate:1.0000 loss:24748.2871 exploreP:0.0101\n",
      "Episode:535 meanR:498.1800 R:500.0 rate:1.0000 loss:27890.6680 exploreP:0.0101\n",
      "Episode:536 meanR:498.1800 R:500.0 rate:1.0000 loss:28610.4082 exploreP:0.0100\n",
      "Episode:537 meanR:498.1800 R:500.0 rate:1.0000 loss:32355.6113 exploreP:0.0100\n",
      "Episode:538 meanR:498.1800 R:500.0 rate:1.0000 loss:33810.7578 exploreP:0.0100\n",
      "Episode:539 meanR:498.1800 R:500.0 rate:1.0000 loss:35212.7266 exploreP:0.0100\n",
      "Episode:540 meanR:498.1800 R:500.0 rate:1.0000 loss:36706.2461 exploreP:0.0100\n",
      "Episode:541 meanR:498.1800 R:500.0 rate:1.0000 loss:37256.3828 exploreP:0.0100\n",
      "Episode:542 meanR:498.1800 R:500.0 rate:1.0000 loss:38659.8164 exploreP:0.0100\n",
      "Episode:543 meanR:498.1800 R:500.0 rate:1.0000 loss:40278.3281 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:544 meanR:498.1800 R:500.0 rate:1.0000 loss:44379.5742 exploreP:0.0100\n",
      "Episode:545 meanR:498.1800 R:500.0 rate:1.0000 loss:46621.4258 exploreP:0.0100\n",
      "Episode:546 meanR:498.1800 R:500.0 rate:1.0000 loss:44514.2578 exploreP:0.0100\n",
      "Episode:547 meanR:498.1800 R:500.0 rate:1.0000 loss:46095.6016 exploreP:0.0100\n",
      "Episode:548 meanR:498.1800 R:500.0 rate:1.0000 loss:47308.6641 exploreP:0.0100\n",
      "Episode:549 meanR:498.1800 R:500.0 rate:1.0000 loss:49747.6367 exploreP:0.0100\n",
      "Episode:550 meanR:498.1800 R:500.0 rate:1.0000 loss:52775.0391 exploreP:0.0100\n",
      "Episode:551 meanR:498.1800 R:500.0 rate:1.0000 loss:52271.6094 exploreP:0.0100\n",
      "Episode:552 meanR:498.1800 R:500.0 rate:1.0000 loss:56494.8203 exploreP:0.0100\n",
      "Episode:553 meanR:498.1800 R:500.0 rate:1.0000 loss:61410.3672 exploreP:0.0100\n",
      "Episode:554 meanR:498.1800 R:500.0 rate:1.0000 loss:61183.7930 exploreP:0.0100\n",
      "Episode:555 meanR:498.1800 R:500.0 rate:1.0000 loss:59939.3398 exploreP:0.0100\n",
      "Episode:556 meanR:498.1800 R:500.0 rate:1.0000 loss:59376.8789 exploreP:0.0100\n",
      "Episode:557 meanR:498.1800 R:500.0 rate:1.0000 loss:60846.9453 exploreP:0.0100\n",
      "Episode:558 meanR:498.1800 R:500.0 rate:1.0000 loss:58792.9766 exploreP:0.0100\n",
      "Episode:559 meanR:498.1800 R:500.0 rate:1.0000 loss:58908.1758 exploreP:0.0100\n",
      "Episode:560 meanR:498.1800 R:500.0 rate:1.0000 loss:59040.2148 exploreP:0.0100\n",
      "Episode:561 meanR:498.1800 R:500.0 rate:1.0000 loss:57178.8984 exploreP:0.0100\n",
      "Episode:562 meanR:498.1800 R:500.0 rate:1.0000 loss:53360.8828 exploreP:0.0100\n",
      "Episode:563 meanR:498.1800 R:500.0 rate:1.0000 loss:47995.6953 exploreP:0.0100\n",
      "Episode:564 meanR:498.1800 R:500.0 rate:1.0000 loss:44837.8945 exploreP:0.0100\n",
      "Episode:565 meanR:498.1800 R:500.0 rate:1.0000 loss:41161.3906 exploreP:0.0100\n",
      "Episode:566 meanR:499.7600 R:500.0 rate:1.0000 loss:38625.5234 exploreP:0.0100\n",
      "Episode:567 meanR:499.7600 R:500.0 rate:1.0000 loss:33328.2148 exploreP:0.0100\n",
      "Episode:568 meanR:499.7600 R:500.0 rate:1.0000 loss:30421.6992 exploreP:0.0100\n",
      "Episode:569 meanR:499.7600 R:500.0 rate:1.0000 loss:28079.1758 exploreP:0.0100\n",
      "Episode:570 meanR:499.7600 R:500.0 rate:1.0000 loss:26870.2031 exploreP:0.0100\n",
      "Episode:571 meanR:499.7600 R:500.0 rate:1.0000 loss:22471.7324 exploreP:0.0100\n",
      "Episode:572 meanR:499.7600 R:500.0 rate:1.0000 loss:20209.8359 exploreP:0.0100\n",
      "Episode:573 meanR:499.7600 R:500.0 rate:1.0000 loss:18382.2637 exploreP:0.0100\n",
      "Episode:574 meanR:499.7600 R:500.0 rate:1.0000 loss:15070.5781 exploreP:0.0100\n",
      "Episode:575 meanR:499.7600 R:500.0 rate:1.0000 loss:14325.0381 exploreP:0.0100\n",
      "Episode:576 meanR:499.7600 R:500.0 rate:1.0000 loss:11614.1289 exploreP:0.0100\n",
      "Episode:577 meanR:499.7600 R:500.0 rate:1.0000 loss:10494.9316 exploreP:0.0100\n",
      "Episode:578 meanR:499.7600 R:500.0 rate:1.0000 loss:8409.4326 exploreP:0.0100\n",
      "Episode:579 meanR:499.7600 R:500.0 rate:1.0000 loss:7886.6567 exploreP:0.0100\n",
      "Episode:580 meanR:499.7600 R:500.0 rate:1.0000 loss:6544.8433 exploreP:0.0100\n",
      "Episode:581 meanR:499.7600 R:500.0 rate:1.0000 loss:5195.0796 exploreP:0.0100\n",
      "Episode:582 meanR:499.5800 R:482.0 rate:0.9640 loss:4613.6899 exploreP:0.0100\n",
      "Episode:583 meanR:499.3700 R:479.0 rate:0.9580 loss:3446.3320 exploreP:0.0100\n",
      "Episode:584 meanR:499.1700 R:456.0 rate:0.9120 loss:2660.5220 exploreP:0.0100\n",
      "Episode:585 meanR:498.6700 R:450.0 rate:0.9000 loss:2330.0854 exploreP:0.0100\n",
      "Episode:586 meanR:498.4300 R:476.0 rate:0.9520 loss:1586.2332 exploreP:0.0100\n",
      "Episode:587 meanR:498.0400 R:461.0 rate:0.9220 loss:1526.0907 exploreP:0.0100\n",
      "Episode:588 meanR:497.7400 R:470.0 rate:0.9400 loss:1236.0042 exploreP:0.0100\n",
      "Episode:589 meanR:497.1300 R:439.0 rate:0.8780 loss:1338.8380 exploreP:0.0100\n",
      "Episode:590 meanR:496.1100 R:398.0 rate:0.7960 loss:1368.6451 exploreP:0.0100\n",
      "Episode:591 meanR:494.6400 R:353.0 rate:0.7060 loss:1677.4419 exploreP:0.0100\n",
      "Episode:592 meanR:493.1700 R:353.0 rate:0.7060 loss:1682.9890 exploreP:0.0100\n",
      "Episode:593 meanR:491.7300 R:356.0 rate:0.7120 loss:1586.6624 exploreP:0.0100\n",
      "Episode:594 meanR:489.9700 R:324.0 rate:0.6480 loss:1512.3956 exploreP:0.0100\n",
      "Episode:595 meanR:488.3100 R:334.0 rate:0.6680 loss:1601.2672 exploreP:0.0100\n",
      "Episode:596 meanR:486.6000 R:329.0 rate:0.6580 loss:1604.8986 exploreP:0.0100\n",
      "Episode:597 meanR:484.4400 R:284.0 rate:0.5680 loss:1337.8916 exploreP:0.0100\n",
      "Episode:598 meanR:482.4900 R:305.0 rate:0.6100 loss:1940.6718 exploreP:0.0100\n",
      "Episode:599 meanR:480.3200 R:283.0 rate:0.5660 loss:2106.7139 exploreP:0.0100\n",
      "Episode:600 meanR:478.1400 R:282.0 rate:0.5640 loss:1377.0690 exploreP:0.0100\n",
      "Episode:601 meanR:475.8600 R:272.0 rate:0.5440 loss:1491.8901 exploreP:0.0100\n",
      "Episode:602 meanR:473.3900 R:253.0 rate:0.5060 loss:1645.7717 exploreP:0.0100\n",
      "Episode:603 meanR:470.8700 R:248.0 rate:0.4960 loss:1968.0902 exploreP:0.0100\n",
      "Episode:604 meanR:468.2700 R:240.0 rate:0.4800 loss:2143.9060 exploreP:0.0100\n",
      "Episode:605 meanR:465.5400 R:227.0 rate:0.4540 loss:2385.9353 exploreP:0.0100\n",
      "Episode:606 meanR:463.0700 R:253.0 rate:0.5060 loss:2665.2922 exploreP:0.0100\n",
      "Episode:607 meanR:460.6200 R:255.0 rate:0.5100 loss:2390.8394 exploreP:0.0100\n",
      "Episode:608 meanR:458.1200 R:250.0 rate:0.5000 loss:2818.9707 exploreP:0.0100\n",
      "Episode:609 meanR:455.5100 R:239.0 rate:0.4780 loss:2971.6936 exploreP:0.0100\n",
      "Episode:610 meanR:452.9100 R:240.0 rate:0.4800 loss:2913.8982 exploreP:0.0100\n",
      "Episode:611 meanR:450.6400 R:273.0 rate:0.5460 loss:3202.7354 exploreP:0.0100\n",
      "Episode:612 meanR:448.7200 R:308.0 rate:0.6160 loss:3581.8059 exploreP:0.0100\n",
      "Episode:613 meanR:447.9200 R:420.0 rate:0.8400 loss:4671.0908 exploreP:0.0100\n",
      "Episode:614 meanR:446.0800 R:316.0 rate:0.6320 loss:5387.1885 exploreP:0.0100\n",
      "Episode:615 meanR:446.0800 R:500.0 rate:1.0000 loss:5794.8325 exploreP:0.0100\n",
      "Episode:616 meanR:446.0800 R:500.0 rate:1.0000 loss:9875.2344 exploreP:0.0100\n",
      "Episode:617 meanR:446.0800 R:500.0 rate:1.0000 loss:15765.3252 exploreP:0.0100\n",
      "Episode:618 meanR:446.0800 R:500.0 rate:1.0000 loss:20267.8965 exploreP:0.0100\n",
      "Episode:619 meanR:446.0800 R:500.0 rate:1.0000 loss:20012.5332 exploreP:0.0100\n",
      "Episode:620 meanR:441.1900 R:11.0 rate:0.0220 loss:18271.8887 exploreP:0.0100\n",
      "Episode:621 meanR:436.3200 R:13.0 rate:0.0260 loss:30152.3125 exploreP:0.0100\n",
      "Episode:622 meanR:431.4400 R:12.0 rate:0.0240 loss:20849.5156 exploreP:0.0100\n",
      "Episode:623 meanR:426.5500 R:11.0 rate:0.0220 loss:16863.8203 exploreP:0.0100\n",
      "Episode:624 meanR:421.6500 R:10.0 rate:0.0200 loss:16242.6436 exploreP:0.0100\n",
      "Episode:625 meanR:416.7600 R:11.0 rate:0.0220 loss:20456.3418 exploreP:0.0100\n",
      "Episode:626 meanR:411.8900 R:13.0 rate:0.0260 loss:28826.1680 exploreP:0.0100\n",
      "Episode:627 meanR:407.0000 R:11.0 rate:0.0220 loss:21095.0527 exploreP:0.0100\n",
      "Episode:628 meanR:402.1100 R:11.0 rate:0.0220 loss:20421.8457 exploreP:0.0100\n",
      "Episode:629 meanR:397.2200 R:11.0 rate:0.0220 loss:18563.1055 exploreP:0.0100\n",
      "Episode:630 meanR:392.3300 R:11.0 rate:0.0220 loss:38914.9883 exploreP:0.0100\n",
      "Episode:631 meanR:387.4400 R:11.0 rate:0.0220 loss:14542.3818 exploreP:0.0100\n",
      "Episode:632 meanR:382.5500 R:11.0 rate:0.0220 loss:24199.1270 exploreP:0.0100\n",
      "Episode:633 meanR:377.6500 R:10.0 rate:0.0200 loss:26110.6973 exploreP:0.0100\n",
      "Episode:634 meanR:372.7700 R:12.0 rate:0.0240 loss:27226.1035 exploreP:0.0100\n",
      "Episode:635 meanR:367.8800 R:11.0 rate:0.0220 loss:24261.4512 exploreP:0.0100\n",
      "Episode:636 meanR:362.9900 R:11.0 rate:0.0220 loss:31309.1484 exploreP:0.0100\n",
      "Episode:637 meanR:358.1100 R:12.0 rate:0.0240 loss:19332.5762 exploreP:0.0100\n",
      "Episode:638 meanR:353.2300 R:12.0 rate:0.0240 loss:11273.9131 exploreP:0.0100\n",
      "Episode:639 meanR:348.3400 R:11.0 rate:0.0220 loss:23216.9238 exploreP:0.0100\n",
      "Episode:640 meanR:343.4500 R:11.0 rate:0.0220 loss:24745.3066 exploreP:0.0100\n",
      "Episode:641 meanR:338.5700 R:12.0 rate:0.0240 loss:15616.9951 exploreP:0.0100\n",
      "Episode:642 meanR:333.6900 R:12.0 rate:0.0240 loss:32190.2910 exploreP:0.0100\n",
      "Episode:643 meanR:328.8000 R:11.0 rate:0.0220 loss:8192.6094 exploreP:0.0100\n",
      "Episode:644 meanR:323.9200 R:12.0 rate:0.0240 loss:21225.0625 exploreP:0.0100\n",
      "Episode:645 meanR:319.0200 R:10.0 rate:0.0200 loss:16277.4785 exploreP:0.0100\n",
      "Episode:646 meanR:314.1200 R:10.0 rate:0.0200 loss:9668.4053 exploreP:0.0100\n",
      "Episode:647 meanR:309.2300 R:11.0 rate:0.0220 loss:16691.8574 exploreP:0.0100\n",
      "Episode:648 meanR:304.3400 R:11.0 rate:0.0220 loss:13375.3994 exploreP:0.0100\n",
      "Episode:649 meanR:299.4400 R:10.0 rate:0.0200 loss:11358.9688 exploreP:0.0100\n",
      "Episode:650 meanR:294.5400 R:10.0 rate:0.0200 loss:34296.8594 exploreP:0.0100\n",
      "Episode:651 meanR:289.6500 R:11.0 rate:0.0220 loss:14537.2100 exploreP:0.0100\n",
      "Episode:652 meanR:284.7600 R:11.0 rate:0.0220 loss:12787.2061 exploreP:0.0100\n",
      "Episode:653 meanR:279.8800 R:12.0 rate:0.0240 loss:17636.7188 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:654 meanR:275.0000 R:12.0 rate:0.0240 loss:25867.9902 exploreP:0.0100\n",
      "Episode:655 meanR:270.1100 R:11.0 rate:0.0220 loss:26067.6895 exploreP:0.0100\n",
      "Episode:656 meanR:265.2100 R:10.0 rate:0.0200 loss:31709.5156 exploreP:0.0100\n",
      "Episode:657 meanR:260.3300 R:12.0 rate:0.0240 loss:14247.9443 exploreP:0.0100\n",
      "Episode:658 meanR:255.4300 R:10.0 rate:0.0200 loss:16867.4004 exploreP:0.0100\n",
      "Episode:659 meanR:250.5300 R:10.0 rate:0.0200 loss:11118.7324 exploreP:0.0100\n",
      "Episode:660 meanR:245.6500 R:12.0 rate:0.0240 loss:31916.0488 exploreP:0.0100\n",
      "Episode:661 meanR:240.7700 R:12.0 rate:0.0240 loss:18627.4512 exploreP:0.0100\n",
      "Episode:662 meanR:235.8800 R:11.0 rate:0.0220 loss:20050.0801 exploreP:0.0100\n",
      "Episode:663 meanR:230.9900 R:11.0 rate:0.0220 loss:12937.9678 exploreP:0.0100\n",
      "Episode:664 meanR:226.1100 R:12.0 rate:0.0240 loss:26665.9160 exploreP:0.0100\n",
      "Episode:665 meanR:221.2300 R:12.0 rate:0.0240 loss:15218.1982 exploreP:0.0100\n",
      "Episode:666 meanR:216.3500 R:12.0 rate:0.0240 loss:38822.7930 exploreP:0.0100\n",
      "Episode:667 meanR:211.4700 R:12.0 rate:0.0240 loss:27186.2754 exploreP:0.0100\n",
      "Episode:668 meanR:206.5800 R:11.0 rate:0.0220 loss:13319.5459 exploreP:0.0100\n",
      "Episode:669 meanR:201.6800 R:10.0 rate:0.0200 loss:18574.3789 exploreP:0.0100\n",
      "Episode:670 meanR:196.7800 R:10.0 rate:0.0200 loss:16137.3984 exploreP:0.0100\n",
      "Episode:671 meanR:191.8800 R:10.0 rate:0.0200 loss:26767.8809 exploreP:0.0100\n",
      "Episode:672 meanR:187.0100 R:13.0 rate:0.0260 loss:23885.2285 exploreP:0.0100\n",
      "Episode:673 meanR:182.1300 R:12.0 rate:0.0240 loss:27794.1543 exploreP:0.0100\n",
      "Episode:674 meanR:177.2400 R:11.0 rate:0.0220 loss:23904.5137 exploreP:0.0100\n",
      "Episode:675 meanR:172.3500 R:11.0 rate:0.0220 loss:33794.6641 exploreP:0.0100\n",
      "Episode:676 meanR:167.4600 R:11.0 rate:0.0220 loss:13977.8975 exploreP:0.0100\n",
      "Episode:677 meanR:162.5700 R:11.0 rate:0.0220 loss:22105.9316 exploreP:0.0100\n",
      "Episode:678 meanR:157.6900 R:12.0 rate:0.0240 loss:27500.3184 exploreP:0.0100\n",
      "Episode:679 meanR:152.7800 R:9.0 rate:0.0180 loss:12608.7188 exploreP:0.0100\n",
      "Episode:680 meanR:147.8800 R:10.0 rate:0.0200 loss:32880.5273 exploreP:0.0100\n",
      "Episode:681 meanR:143.0000 R:12.0 rate:0.0240 loss:25168.8926 exploreP:0.0100\n",
      "Episode:682 meanR:138.2900 R:11.0 rate:0.0220 loss:21016.5781 exploreP:0.0100\n",
      "Episode:683 meanR:133.6200 R:12.0 rate:0.0240 loss:12130.2002 exploreP:0.0100\n",
      "Episode:684 meanR:129.1700 R:11.0 rate:0.0220 loss:70584.5781 exploreP:0.0100\n",
      "Episode:685 meanR:124.7800 R:11.0 rate:0.0220 loss:35418.9570 exploreP:0.0100\n",
      "Episode:686 meanR:120.1300 R:11.0 rate:0.0220 loss:27485.8945 exploreP:0.0100\n",
      "Episode:687 meanR:115.6200 R:10.0 rate:0.0200 loss:32865.5078 exploreP:0.0100\n",
      "Episode:688 meanR:111.0300 R:11.0 rate:0.0220 loss:39484.4102 exploreP:0.0100\n",
      "Episode:689 meanR:106.7400 R:10.0 rate:0.0200 loss:18367.5352 exploreP:0.0100\n",
      "Episode:690 meanR:102.8800 R:12.0 rate:0.0240 loss:41021.0977 exploreP:0.0100\n",
      "Episode:691 meanR:99.4700 R:12.0 rate:0.0240 loss:33157.1133 exploreP:0.0100\n",
      "Episode:692 meanR:96.0500 R:11.0 rate:0.0220 loss:23487.1074 exploreP:0.0100\n",
      "Episode:693 meanR:92.6000 R:11.0 rate:0.0220 loss:28344.6172 exploreP:0.0100\n",
      "Episode:694 meanR:89.4800 R:12.0 rate:0.0240 loss:17968.3574 exploreP:0.0100\n",
      "Episode:695 meanR:86.2400 R:10.0 rate:0.0200 loss:24828.4043 exploreP:0.0100\n",
      "Episode:696 meanR:83.0600 R:11.0 rate:0.0220 loss:18785.9219 exploreP:0.0100\n",
      "Episode:697 meanR:80.3300 R:11.0 rate:0.0220 loss:34704.6953 exploreP:0.0100\n",
      "Episode:698 meanR:77.4000 R:12.0 rate:0.0240 loss:28835.6699 exploreP:0.0100\n",
      "Episode:699 meanR:74.6900 R:12.0 rate:0.0240 loss:27943.6172 exploreP:0.0100\n",
      "Episode:700 meanR:72.0100 R:14.0 rate:0.0280 loss:43661.0625 exploreP:0.0100\n",
      "Episode:701 meanR:69.3900 R:10.0 rate:0.0200 loss:32434.6035 exploreP:0.0100\n",
      "Episode:702 meanR:66.9700 R:11.0 rate:0.0220 loss:56980.4414 exploreP:0.0100\n",
      "Episode:703 meanR:64.6200 R:13.0 rate:0.0260 loss:22552.6562 exploreP:0.0100\n",
      "Episode:704 meanR:62.3300 R:11.0 rate:0.0220 loss:23632.4316 exploreP:0.0100\n",
      "Episode:705 meanR:60.1800 R:12.0 rate:0.0240 loss:35652.3047 exploreP:0.0100\n",
      "Episode:706 meanR:57.7700 R:12.0 rate:0.0240 loss:48114.7344 exploreP:0.0100\n",
      "Episode:707 meanR:55.3300 R:11.0 rate:0.0220 loss:51365.1094 exploreP:0.0100\n",
      "Episode:708 meanR:52.9500 R:12.0 rate:0.0240 loss:44539.4727 exploreP:0.0100\n",
      "Episode:709 meanR:50.6700 R:11.0 rate:0.0220 loss:17333.7363 exploreP:0.0100\n",
      "Episode:710 meanR:48.4000 R:13.0 rate:0.0260 loss:68000.7109 exploreP:0.0100\n",
      "Episode:711 meanR:45.7900 R:12.0 rate:0.0240 loss:35750.3281 exploreP:0.0100\n",
      "Episode:712 meanR:42.8100 R:10.0 rate:0.0200 loss:35459.2422 exploreP:0.0100\n",
      "Episode:713 meanR:38.7200 R:11.0 rate:0.0220 loss:37951.3906 exploreP:0.0100\n",
      "Episode:714 meanR:35.6600 R:10.0 rate:0.0200 loss:51235.7930 exploreP:0.0100\n",
      "Episode:715 meanR:30.7700 R:11.0 rate:0.0220 loss:44284.3750 exploreP:0.0100\n",
      "Episode:716 meanR:25.8900 R:12.0 rate:0.0240 loss:32824.0742 exploreP:0.0100\n",
      "Episode:717 meanR:20.9900 R:10.0 rate:0.0200 loss:43715.3516 exploreP:0.0100\n",
      "Episode:718 meanR:16.1000 R:11.0 rate:0.0220 loss:28207.8203 exploreP:0.0100\n",
      "Episode:719 meanR:11.2100 R:11.0 rate:0.0220 loss:27599.5254 exploreP:0.0100\n",
      "Episode:720 meanR:11.2200 R:12.0 rate:0.0240 loss:26648.1875 exploreP:0.0100\n",
      "Episode:721 meanR:11.2000 R:11.0 rate:0.0220 loss:54517.7227 exploreP:0.0100\n",
      "Episode:722 meanR:11.2000 R:12.0 rate:0.0240 loss:35753.8320 exploreP:0.0100\n",
      "Episode:723 meanR:11.2200 R:13.0 rate:0.0260 loss:26845.7480 exploreP:0.0100\n",
      "Episode:724 meanR:11.2600 R:14.0 rate:0.0280 loss:42026.4766 exploreP:0.0100\n",
      "Episode:725 meanR:11.2800 R:13.0 rate:0.0260 loss:32681.1367 exploreP:0.0100\n",
      "Episode:726 meanR:11.2700 R:12.0 rate:0.0240 loss:47052.9219 exploreP:0.0100\n",
      "Episode:727 meanR:11.2800 R:12.0 rate:0.0240 loss:42929.6992 exploreP:0.0100\n",
      "Episode:728 meanR:11.2700 R:10.0 rate:0.0200 loss:58169.1367 exploreP:0.0100\n",
      "Episode:729 meanR:11.2800 R:12.0 rate:0.0240 loss:48127.4180 exploreP:0.0100\n",
      "Episode:730 meanR:11.2800 R:11.0 rate:0.0220 loss:54103.6484 exploreP:0.0100\n",
      "Episode:731 meanR:11.3000 R:13.0 rate:0.0260 loss:81488.0469 exploreP:0.0100\n",
      "Episode:732 meanR:11.3000 R:11.0 rate:0.0220 loss:52932.6523 exploreP:0.0100\n",
      "Episode:733 meanR:11.3200 R:12.0 rate:0.0240 loss:37010.4180 exploreP:0.0100\n",
      "Episode:734 meanR:11.3100 R:11.0 rate:0.0220 loss:26203.7812 exploreP:0.0100\n",
      "Episode:735 meanR:11.3200 R:12.0 rate:0.0240 loss:55042.7656 exploreP:0.0100\n",
      "Episode:736 meanR:11.3300 R:12.0 rate:0.0240 loss:52790.4688 exploreP:0.0100\n",
      "Episode:737 meanR:11.3100 R:10.0 rate:0.0200 loss:46939.5547 exploreP:0.0100\n",
      "Episode:738 meanR:11.3200 R:13.0 rate:0.0260 loss:54976.9297 exploreP:0.0100\n",
      "Episode:739 meanR:11.3300 R:12.0 rate:0.0240 loss:73844.0547 exploreP:0.0100\n",
      "Episode:740 meanR:11.3400 R:12.0 rate:0.0240 loss:73892.1172 exploreP:0.0100\n",
      "Episode:741 meanR:11.3300 R:11.0 rate:0.0220 loss:34023.6250 exploreP:0.0100\n",
      "Episode:742 meanR:11.3200 R:11.0 rate:0.0220 loss:49535.4023 exploreP:0.0100\n",
      "Episode:743 meanR:11.3300 R:12.0 rate:0.0240 loss:65897.2578 exploreP:0.0100\n",
      "Episode:744 meanR:11.3200 R:11.0 rate:0.0220 loss:54246.4492 exploreP:0.0100\n",
      "Episode:745 meanR:11.3100 R:9.0 rate:0.0180 loss:44543.3359 exploreP:0.0100\n",
      "Episode:746 meanR:11.3300 R:12.0 rate:0.0240 loss:46939.7656 exploreP:0.0100\n",
      "Episode:747 meanR:11.3500 R:13.0 rate:0.0260 loss:48957.7656 exploreP:0.0100\n",
      "Episode:748 meanR:11.3600 R:12.0 rate:0.0240 loss:50819.5664 exploreP:0.0100\n",
      "Episode:749 meanR:11.3900 R:13.0 rate:0.0260 loss:34034.3359 exploreP:0.0100\n",
      "Episode:750 meanR:11.4100 R:12.0 rate:0.0240 loss:41063.4805 exploreP:0.0100\n",
      "Episode:751 meanR:11.4100 R:11.0 rate:0.0220 loss:47098.4766 exploreP:0.0100\n",
      "Episode:752 meanR:11.4100 R:11.0 rate:0.0220 loss:50692.0664 exploreP:0.0100\n",
      "Episode:753 meanR:11.4100 R:12.0 rate:0.0240 loss:50228.9531 exploreP:0.0100\n",
      "Episode:754 meanR:11.4100 R:12.0 rate:0.0240 loss:45718.6523 exploreP:0.0100\n",
      "Episode:755 meanR:11.4200 R:12.0 rate:0.0240 loss:59781.1367 exploreP:0.0100\n",
      "Episode:756 meanR:11.4200 R:10.0 rate:0.0200 loss:64852.0000 exploreP:0.0100\n",
      "Episode:757 meanR:11.4100 R:11.0 rate:0.0220 loss:103401.1719 exploreP:0.0100\n",
      "Episode:758 meanR:11.4500 R:14.0 rate:0.0280 loss:59409.3867 exploreP:0.0100\n",
      "Episode:759 meanR:11.4600 R:11.0 rate:0.0220 loss:60576.8594 exploreP:0.0100\n",
      "Episode:760 meanR:11.4700 R:13.0 rate:0.0260 loss:58663.1719 exploreP:0.0100\n",
      "Episode:761 meanR:11.4600 R:11.0 rate:0.0220 loss:48958.2344 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:762 meanR:11.4500 R:10.0 rate:0.0200 loss:48635.5234 exploreP:0.0100\n",
      "Episode:763 meanR:11.4700 R:13.0 rate:0.0260 loss:101441.0781 exploreP:0.0100\n",
      "Episode:764 meanR:11.4600 R:11.0 rate:0.0220 loss:69759.7344 exploreP:0.0100\n",
      "Episode:765 meanR:11.4600 R:12.0 rate:0.0240 loss:60578.1680 exploreP:0.0100\n",
      "Episode:766 meanR:11.4600 R:12.0 rate:0.0240 loss:74046.6094 exploreP:0.0100\n",
      "Episode:767 meanR:11.4500 R:11.0 rate:0.0220 loss:94044.9766 exploreP:0.0100\n",
      "Episode:768 meanR:11.4600 R:12.0 rate:0.0240 loss:84523.3984 exploreP:0.0100\n",
      "Episode:769 meanR:11.4800 R:12.0 rate:0.0240 loss:85182.5703 exploreP:0.0100\n",
      "Episode:770 meanR:11.4900 R:11.0 rate:0.0220 loss:92170.6797 exploreP:0.0100\n",
      "Episode:771 meanR:11.5100 R:12.0 rate:0.0240 loss:87251.7422 exploreP:0.0100\n",
      "Episode:772 meanR:11.4900 R:11.0 rate:0.0220 loss:82212.3203 exploreP:0.0100\n",
      "Episode:773 meanR:11.4800 R:11.0 rate:0.0220 loss:60739.3086 exploreP:0.0100\n",
      "Episode:774 meanR:11.4700 R:10.0 rate:0.0200 loss:88365.8438 exploreP:0.0100\n",
      "Episode:775 meanR:11.4800 R:12.0 rate:0.0240 loss:85983.2422 exploreP:0.0100\n",
      "Episode:776 meanR:11.5000 R:13.0 rate:0.0260 loss:85612.2031 exploreP:0.0100\n",
      "Episode:777 meanR:11.5100 R:12.0 rate:0.0240 loss:97778.3359 exploreP:0.0100\n",
      "Episode:778 meanR:11.4900 R:10.0 rate:0.0200 loss:89797.1562 exploreP:0.0100\n",
      "Episode:779 meanR:11.5100 R:11.0 rate:0.0220 loss:91186.5938 exploreP:0.0100\n",
      "Episode:780 meanR:11.5200 R:11.0 rate:0.0220 loss:89844.5703 exploreP:0.0100\n",
      "Episode:781 meanR:11.5100 R:11.0 rate:0.0220 loss:80793.7734 exploreP:0.0100\n",
      "Episode:782 meanR:11.5000 R:10.0 rate:0.0200 loss:79199.8281 exploreP:0.0100\n",
      "Episode:783 meanR:11.4900 R:11.0 rate:0.0220 loss:95063.9766 exploreP:0.0100\n",
      "Episode:784 meanR:11.5000 R:12.0 rate:0.0240 loss:87967.5547 exploreP:0.0100\n",
      "Episode:785 meanR:11.5000 R:11.0 rate:0.0220 loss:93878.1562 exploreP:0.0100\n",
      "Episode:786 meanR:11.5000 R:11.0 rate:0.0220 loss:80709.7500 exploreP:0.0100\n",
      "Episode:787 meanR:11.5200 R:12.0 rate:0.0240 loss:82637.1172 exploreP:0.0100\n",
      "Episode:788 meanR:11.5300 R:12.0 rate:0.0240 loss:80815.0156 exploreP:0.0100\n",
      "Episode:789 meanR:11.5400 R:11.0 rate:0.0220 loss:73842.0703 exploreP:0.0100\n",
      "Episode:790 meanR:11.5500 R:13.0 rate:0.0260 loss:93727.4844 exploreP:0.0100\n",
      "Episode:791 meanR:11.5500 R:12.0 rate:0.0240 loss:75114.5625 exploreP:0.0100\n",
      "Episode:792 meanR:11.5500 R:11.0 rate:0.0220 loss:119328.3750 exploreP:0.0100\n",
      "Episode:793 meanR:11.5600 R:12.0 rate:0.0240 loss:94680.5391 exploreP:0.0100\n",
      "Episode:794 meanR:11.5800 R:14.0 rate:0.0280 loss:103922.2422 exploreP:0.0100\n",
      "Episode:795 meanR:11.6100 R:13.0 rate:0.0260 loss:72733.2188 exploreP:0.0100\n",
      "Episode:796 meanR:11.6100 R:11.0 rate:0.0220 loss:151019.2500 exploreP:0.0100\n",
      "Episode:797 meanR:11.6100 R:11.0 rate:0.0220 loss:106202.9297 exploreP:0.0100\n",
      "Episode:798 meanR:11.5900 R:10.0 rate:0.0200 loss:99403.8047 exploreP:0.0100\n",
      "Episode:799 meanR:11.5700 R:10.0 rate:0.0200 loss:90875.0938 exploreP:0.0100\n",
      "Episode:800 meanR:11.5400 R:11.0 rate:0.0220 loss:95919.6484 exploreP:0.0100\n",
      "Episode:801 meanR:11.5600 R:12.0 rate:0.0240 loss:95443.1797 exploreP:0.0100\n",
      "Episode:802 meanR:11.5500 R:10.0 rate:0.0200 loss:86197.0156 exploreP:0.0100\n",
      "Episode:803 meanR:11.5300 R:11.0 rate:0.0220 loss:102676.3984 exploreP:0.0100\n",
      "Episode:804 meanR:11.5300 R:11.0 rate:0.0220 loss:101584.4766 exploreP:0.0100\n",
      "Episode:805 meanR:11.5200 R:11.0 rate:0.0220 loss:70867.0938 exploreP:0.0100\n",
      "Episode:806 meanR:11.5200 R:12.0 rate:0.0240 loss:135597.9531 exploreP:0.0100\n",
      "Episode:807 meanR:11.5200 R:11.0 rate:0.0220 loss:113335.7266 exploreP:0.0100\n",
      "Episode:808 meanR:11.5100 R:11.0 rate:0.0220 loss:123980.2969 exploreP:0.0100\n",
      "Episode:809 meanR:11.5200 R:12.0 rate:0.0240 loss:96741.0859 exploreP:0.0100\n",
      "Episode:810 meanR:11.5000 R:11.0 rate:0.0220 loss:98021.8672 exploreP:0.0100\n",
      "Episode:811 meanR:11.4900 R:11.0 rate:0.0220 loss:92821.5703 exploreP:0.0100\n",
      "Episode:812 meanR:11.5000 R:11.0 rate:0.0220 loss:128732.1484 exploreP:0.0100\n",
      "Episode:813 meanR:11.5000 R:11.0 rate:0.0220 loss:98905.5000 exploreP:0.0100\n",
      "Episode:814 meanR:11.5300 R:13.0 rate:0.0260 loss:100901.2422 exploreP:0.0100\n",
      "Episode:815 meanR:11.5300 R:11.0 rate:0.0220 loss:114869.8203 exploreP:0.0100\n",
      "Episode:816 meanR:11.5200 R:11.0 rate:0.0220 loss:131579.4375 exploreP:0.0100\n",
      "Episode:817 meanR:11.5400 R:12.0 rate:0.0240 loss:123650.4062 exploreP:0.0100\n",
      "Episode:818 meanR:11.5500 R:12.0 rate:0.0240 loss:83416.0156 exploreP:0.0100\n",
      "Episode:819 meanR:11.5600 R:12.0 rate:0.0240 loss:127970.5938 exploreP:0.0100\n",
      "Episode:820 meanR:11.5400 R:10.0 rate:0.0200 loss:106064.8984 exploreP:0.0100\n",
      "Episode:821 meanR:11.5500 R:12.0 rate:0.0240 loss:96926.8438 exploreP:0.0100\n",
      "Episode:822 meanR:11.5300 R:10.0 rate:0.0200 loss:100642.3281 exploreP:0.0100\n",
      "Episode:823 meanR:11.5200 R:12.0 rate:0.0240 loss:131945.7344 exploreP:0.0100\n",
      "Episode:824 meanR:11.4800 R:10.0 rate:0.0200 loss:100614.2812 exploreP:0.0100\n",
      "Episode:825 meanR:11.4700 R:12.0 rate:0.0240 loss:128752.9141 exploreP:0.0100\n",
      "Episode:826 meanR:11.4600 R:11.0 rate:0.0220 loss:103447.4922 exploreP:0.0100\n",
      "Episode:827 meanR:11.4400 R:10.0 rate:0.0200 loss:140340.5781 exploreP:0.0100\n",
      "Episode:828 meanR:11.4400 R:10.0 rate:0.0200 loss:112405.8594 exploreP:0.0100\n",
      "Episode:829 meanR:11.4300 R:11.0 rate:0.0220 loss:106810.4531 exploreP:0.0100\n",
      "Episode:830 meanR:11.4300 R:11.0 rate:0.0220 loss:116243.5781 exploreP:0.0100\n",
      "Episode:831 meanR:11.3900 R:9.0 rate:0.0180 loss:122152.0703 exploreP:0.0100\n",
      "Episode:832 meanR:11.3700 R:9.0 rate:0.0180 loss:154950.5000 exploreP:0.0100\n",
      "Episode:833 meanR:11.3500 R:10.0 rate:0.0200 loss:84402.1875 exploreP:0.0100\n",
      "Episode:834 meanR:11.3400 R:10.0 rate:0.0200 loss:122049.6719 exploreP:0.0100\n",
      "Episode:835 meanR:11.3100 R:9.0 rate:0.0180 loss:132428.9219 exploreP:0.0100\n",
      "Episode:836 meanR:11.3100 R:12.0 rate:0.0240 loss:152032.0781 exploreP:0.0100\n",
      "Episode:837 meanR:11.3100 R:10.0 rate:0.0200 loss:98637.6719 exploreP:0.0100\n",
      "Episode:838 meanR:11.2800 R:10.0 rate:0.0200 loss:106861.9609 exploreP:0.0100\n",
      "Episode:839 meanR:11.2800 R:12.0 rate:0.0240 loss:105729.0234 exploreP:0.0100\n",
      "Episode:840 meanR:11.2700 R:11.0 rate:0.0220 loss:108168.6562 exploreP:0.0100\n",
      "Episode:841 meanR:11.2700 R:11.0 rate:0.0220 loss:117571.0312 exploreP:0.0100\n",
      "Episode:842 meanR:11.2700 R:11.0 rate:0.0220 loss:97386.6328 exploreP:0.0100\n",
      "Episode:843 meanR:11.2600 R:11.0 rate:0.0220 loss:119003.2266 exploreP:0.0100\n",
      "Episode:844 meanR:11.2500 R:10.0 rate:0.0200 loss:112055.3750 exploreP:0.0100\n",
      "Episode:845 meanR:11.2700 R:11.0 rate:0.0220 loss:126243.9297 exploreP:0.0100\n",
      "Episode:846 meanR:11.2500 R:10.0 rate:0.0200 loss:148313.1562 exploreP:0.0100\n",
      "Episode:847 meanR:11.2300 R:11.0 rate:0.0220 loss:99994.9688 exploreP:0.0100\n",
      "Episode:848 meanR:11.2200 R:11.0 rate:0.0220 loss:105335.3047 exploreP:0.0100\n",
      "Episode:849 meanR:11.1900 R:10.0 rate:0.0200 loss:126840.3516 exploreP:0.0100\n",
      "Episode:850 meanR:11.1800 R:11.0 rate:0.0220 loss:129084.9297 exploreP:0.0100\n",
      "Episode:851 meanR:11.1700 R:10.0 rate:0.0200 loss:124510.3594 exploreP:0.0100\n",
      "Episode:852 meanR:11.1700 R:11.0 rate:0.0220 loss:149157.8281 exploreP:0.0100\n",
      "Episode:853 meanR:11.1500 R:10.0 rate:0.0200 loss:144510.6562 exploreP:0.0100\n",
      "Episode:854 meanR:11.1300 R:10.0 rate:0.0200 loss:157118.0312 exploreP:0.0100\n",
      "Episode:855 meanR:11.1200 R:11.0 rate:0.0220 loss:136542.8594 exploreP:0.0100\n",
      "Episode:856 meanR:11.1300 R:11.0 rate:0.0220 loss:180250.8438 exploreP:0.0100\n",
      "Episode:857 meanR:11.1100 R:9.0 rate:0.0180 loss:156896.1875 exploreP:0.0100\n",
      "Episode:858 meanR:11.0600 R:9.0 rate:0.0180 loss:114460.5859 exploreP:0.0100\n",
      "Episode:859 meanR:11.0700 R:12.0 rate:0.0240 loss:141961.0781 exploreP:0.0100\n",
      "Episode:860 meanR:11.0400 R:10.0 rate:0.0200 loss:127276.4141 exploreP:0.0100\n",
      "Episode:861 meanR:11.0400 R:11.0 rate:0.0220 loss:113463.2812 exploreP:0.0100\n",
      "Episode:862 meanR:11.0400 R:10.0 rate:0.0200 loss:139785.8438 exploreP:0.0100\n",
      "Episode:863 meanR:11.0100 R:10.0 rate:0.0200 loss:110838.4844 exploreP:0.0100\n",
      "Episode:864 meanR:11.0100 R:11.0 rate:0.0220 loss:174435.8125 exploreP:0.0100\n",
      "Episode:865 meanR:11.0000 R:11.0 rate:0.0220 loss:130665.7734 exploreP:0.0100\n",
      "Episode:866 meanR:10.9700 R:9.0 rate:0.0180 loss:133229.5938 exploreP:0.0100\n",
      "Episode:867 meanR:10.9700 R:11.0 rate:0.0220 loss:146534.0938 exploreP:0.0100\n",
      "Episode:868 meanR:10.9500 R:10.0 rate:0.0200 loss:156866.0000 exploreP:0.0100\n",
      "Episode:869 meanR:10.9300 R:10.0 rate:0.0200 loss:157673.3906 exploreP:0.0100\n",
      "Episode:870 meanR:10.9400 R:12.0 rate:0.0240 loss:141796.3906 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:871 meanR:10.9200 R:10.0 rate:0.0200 loss:151734.1562 exploreP:0.0100\n",
      "Episode:872 meanR:10.9200 R:11.0 rate:0.0220 loss:126273.9922 exploreP:0.0100\n",
      "Episode:873 meanR:10.9100 R:10.0 rate:0.0200 loss:142991.4062 exploreP:0.0100\n",
      "Episode:874 meanR:10.9200 R:11.0 rate:0.0220 loss:194737.1406 exploreP:0.0100\n",
      "Episode:875 meanR:10.9100 R:11.0 rate:0.0220 loss:180159.7500 exploreP:0.0100\n",
      "Episode:876 meanR:10.8900 R:11.0 rate:0.0220 loss:138286.3281 exploreP:0.0100\n",
      "Episode:877 meanR:10.8800 R:11.0 rate:0.0220 loss:162669.9375 exploreP:0.0100\n",
      "Episode:878 meanR:10.9000 R:12.0 rate:0.0240 loss:156818.8438 exploreP:0.0100\n",
      "Episode:879 meanR:10.9000 R:11.0 rate:0.0220 loss:147933.1406 exploreP:0.0100\n",
      "Episode:880 meanR:10.8900 R:10.0 rate:0.0200 loss:143440.9219 exploreP:0.0100\n",
      "Episode:881 meanR:10.8900 R:11.0 rate:0.0220 loss:154956.6094 exploreP:0.0100\n",
      "Episode:882 meanR:10.9000 R:11.0 rate:0.0220 loss:198233.9844 exploreP:0.0100\n",
      "Episode:883 meanR:10.8900 R:10.0 rate:0.0200 loss:145270.0938 exploreP:0.0100\n",
      "Episode:884 meanR:10.8800 R:11.0 rate:0.0220 loss:189558.0625 exploreP:0.0100\n",
      "Episode:885 meanR:10.8900 R:12.0 rate:0.0240 loss:193847.7031 exploreP:0.0100\n",
      "Episode:886 meanR:10.8900 R:11.0 rate:0.0220 loss:150444.0000 exploreP:0.0100\n",
      "Episode:887 meanR:10.8800 R:11.0 rate:0.0220 loss:210637.7500 exploreP:0.0100\n",
      "Episode:888 meanR:10.8500 R:9.0 rate:0.0180 loss:178722.8125 exploreP:0.0100\n",
      "Episode:889 meanR:10.8500 R:11.0 rate:0.0220 loss:198757.0625 exploreP:0.0100\n",
      "Episode:890 meanR:10.8500 R:13.0 rate:0.0260 loss:173688.0312 exploreP:0.0100\n",
      "Episode:891 meanR:10.8400 R:11.0 rate:0.0220 loss:193094.6094 exploreP:0.0100\n",
      "Episode:892 meanR:10.8600 R:13.0 rate:0.0260 loss:191876.0000 exploreP:0.0100\n",
      "Episode:893 meanR:10.8500 R:11.0 rate:0.0220 loss:219952.8906 exploreP:0.0100\n",
      "Episode:894 meanR:10.8100 R:10.0 rate:0.0200 loss:206283.7656 exploreP:0.0100\n",
      "Episode:895 meanR:10.7700 R:9.0 rate:0.0180 loss:204733.8594 exploreP:0.0100\n",
      "Episode:896 meanR:10.7700 R:11.0 rate:0.0220 loss:267425.5312 exploreP:0.0100\n",
      "Episode:897 meanR:10.7700 R:11.0 rate:0.0220 loss:203558.5938 exploreP:0.0100\n",
      "Episode:898 meanR:10.7600 R:9.0 rate:0.0180 loss:247452.8906 exploreP:0.0100\n",
      "Episode:899 meanR:10.7600 R:10.0 rate:0.0200 loss:221208.7969 exploreP:0.0100\n",
      "Episode:900 meanR:10.7400 R:9.0 rate:0.0180 loss:245848.9219 exploreP:0.0100\n",
      "Episode:901 meanR:10.7300 R:11.0 rate:0.0220 loss:241857.0469 exploreP:0.0100\n",
      "Episode:902 meanR:10.7500 R:12.0 rate:0.0240 loss:266549.9062 exploreP:0.0100\n",
      "Episode:903 meanR:10.7500 R:11.0 rate:0.0220 loss:226405.5938 exploreP:0.0100\n",
      "Episode:904 meanR:10.7500 R:11.0 rate:0.0220 loss:221955.2969 exploreP:0.0100\n",
      "Episode:905 meanR:10.7400 R:10.0 rate:0.0200 loss:170525.1094 exploreP:0.0100\n",
      "Episode:906 meanR:10.7200 R:10.0 rate:0.0200 loss:236318.2969 exploreP:0.0100\n",
      "Episode:907 meanR:10.7100 R:10.0 rate:0.0200 loss:271622.0312 exploreP:0.0100\n",
      "Episode:908 meanR:10.7100 R:11.0 rate:0.0220 loss:209681.4062 exploreP:0.0100\n",
      "Episode:909 meanR:10.7000 R:11.0 rate:0.0220 loss:208486.0469 exploreP:0.0100\n",
      "Episode:910 meanR:10.7000 R:11.0 rate:0.0220 loss:242797.5000 exploreP:0.0100\n",
      "Episode:911 meanR:10.7000 R:11.0 rate:0.0220 loss:233742.1875 exploreP:0.0100\n",
      "Episode:912 meanR:10.6900 R:10.0 rate:0.0200 loss:239286.7969 exploreP:0.0100\n",
      "Episode:913 meanR:10.6800 R:10.0 rate:0.0200 loss:208918.6719 exploreP:0.0100\n",
      "Episode:914 meanR:10.6600 R:11.0 rate:0.0220 loss:256108.1562 exploreP:0.0100\n",
      "Episode:915 meanR:10.6400 R:9.0 rate:0.0180 loss:250691.0781 exploreP:0.0100\n",
      "Episode:916 meanR:10.6200 R:9.0 rate:0.0180 loss:240502.3594 exploreP:0.0100\n",
      "Episode:917 meanR:10.5900 R:9.0 rate:0.0180 loss:277697.6250 exploreP:0.0100\n",
      "Episode:918 meanR:10.5700 R:10.0 rate:0.0200 loss:297371.5625 exploreP:0.0100\n",
      "Episode:919 meanR:10.5400 R:9.0 rate:0.0180 loss:285329.2188 exploreP:0.0100\n",
      "Episode:920 meanR:10.5400 R:10.0 rate:0.0200 loss:213295.4219 exploreP:0.0100\n",
      "Episode:921 meanR:10.5200 R:10.0 rate:0.0200 loss:239867.8438 exploreP:0.0100\n",
      "Episode:922 meanR:10.5000 R:8.0 rate:0.0160 loss:271529.1562 exploreP:0.0100\n",
      "Episode:923 meanR:10.4800 R:10.0 rate:0.0200 loss:224003.2500 exploreP:0.0100\n",
      "Episode:924 meanR:10.4700 R:9.0 rate:0.0180 loss:298635.3125 exploreP:0.0100\n",
      "Episode:925 meanR:10.4400 R:9.0 rate:0.0180 loss:243533.0625 exploreP:0.0100\n",
      "Episode:926 meanR:10.4400 R:11.0 rate:0.0220 loss:249504.0938 exploreP:0.0100\n",
      "Episode:927 meanR:10.4500 R:11.0 rate:0.0220 loss:265557.9062 exploreP:0.0100\n",
      "Episode:928 meanR:10.4300 R:8.0 rate:0.0160 loss:208402.2500 exploreP:0.0100\n",
      "Episode:929 meanR:10.4100 R:9.0 rate:0.0180 loss:223000.1875 exploreP:0.0100\n",
      "Episode:930 meanR:10.4100 R:11.0 rate:0.0220 loss:282374.2188 exploreP:0.0100\n",
      "Episode:931 meanR:10.4200 R:10.0 rate:0.0200 loss:248652.2500 exploreP:0.0100\n",
      "Episode:932 meanR:10.4500 R:12.0 rate:0.0240 loss:265742.0938 exploreP:0.0100\n",
      "Episode:933 meanR:10.4400 R:9.0 rate:0.0180 loss:298387.1562 exploreP:0.0100\n",
      "Episode:934 meanR:10.4400 R:10.0 rate:0.0200 loss:298698.6562 exploreP:0.0100\n",
      "Episode:935 meanR:10.4400 R:9.0 rate:0.0180 loss:292388.3438 exploreP:0.0100\n",
      "Episode:936 meanR:10.4200 R:10.0 rate:0.0200 loss:288273.5938 exploreP:0.0100\n",
      "Episode:937 meanR:10.4300 R:11.0 rate:0.0220 loss:296807.2188 exploreP:0.0100\n",
      "Episode:938 meanR:10.4200 R:9.0 rate:0.0180 loss:288722.6875 exploreP:0.0100\n",
      "Episode:939 meanR:10.4000 R:10.0 rate:0.0200 loss:321330.6875 exploreP:0.0100\n",
      "Episode:940 meanR:10.3900 R:10.0 rate:0.0200 loss:314619.8125 exploreP:0.0100\n",
      "Episode:941 meanR:10.3900 R:11.0 rate:0.0220 loss:311604.8438 exploreP:0.0100\n",
      "Episode:942 meanR:10.3900 R:11.0 rate:0.0220 loss:328617.4062 exploreP:0.0100\n",
      "Episode:943 meanR:10.3800 R:10.0 rate:0.0200 loss:314343.9375 exploreP:0.0100\n",
      "Episode:944 meanR:10.3900 R:11.0 rate:0.0220 loss:286586.4375 exploreP:0.0100\n",
      "Episode:945 meanR:10.3900 R:11.0 rate:0.0220 loss:329164.5625 exploreP:0.0100\n",
      "Episode:946 meanR:10.3800 R:9.0 rate:0.0180 loss:390411.2500 exploreP:0.0100\n",
      "Episode:947 meanR:10.3800 R:11.0 rate:0.0220 loss:351407.4062 exploreP:0.0100\n",
      "Episode:948 meanR:10.3600 R:9.0 rate:0.0180 loss:326494.0625 exploreP:0.0100\n",
      "Episode:949 meanR:10.3500 R:9.0 rate:0.0180 loss:298119.4375 exploreP:0.0100\n",
      "Episode:950 meanR:10.3400 R:10.0 rate:0.0200 loss:294409.6875 exploreP:0.0100\n",
      "Episode:951 meanR:10.3400 R:10.0 rate:0.0200 loss:307058.1250 exploreP:0.0100\n",
      "Episode:952 meanR:10.3200 R:9.0 rate:0.0180 loss:293803.0625 exploreP:0.0100\n",
      "Episode:953 meanR:10.3100 R:9.0 rate:0.0180 loss:312857.2188 exploreP:0.0100\n",
      "Episode:954 meanR:10.3200 R:11.0 rate:0.0220 loss:304622.4688 exploreP:0.0100\n",
      "Episode:955 meanR:10.2900 R:8.0 rate:0.0160 loss:409085.3750 exploreP:0.0100\n",
      "Episode:956 meanR:10.2700 R:9.0 rate:0.0180 loss:410178.7812 exploreP:0.0100\n",
      "Episode:957 meanR:10.2900 R:11.0 rate:0.0220 loss:389766.5000 exploreP:0.0100\n",
      "Episode:958 meanR:10.2900 R:9.0 rate:0.0180 loss:340982.0938 exploreP:0.0100\n",
      "Episode:959 meanR:10.2700 R:10.0 rate:0.0200 loss:309492.2812 exploreP:0.0100\n",
      "Episode:960 meanR:10.2600 R:9.0 rate:0.0180 loss:368061.3750 exploreP:0.0100\n",
      "Episode:961 meanR:10.2500 R:10.0 rate:0.0200 loss:372949.6562 exploreP:0.0100\n",
      "Episode:962 meanR:10.2500 R:10.0 rate:0.0200 loss:344883.6562 exploreP:0.0100\n",
      "Episode:963 meanR:10.2400 R:9.0 rate:0.0180 loss:328582.0000 exploreP:0.0100\n",
      "Episode:964 meanR:10.2200 R:9.0 rate:0.0180 loss:363005.7500 exploreP:0.0100\n",
      "Episode:965 meanR:10.2100 R:10.0 rate:0.0200 loss:403107.1875 exploreP:0.0100\n",
      "Episode:966 meanR:10.2200 R:10.0 rate:0.0200 loss:336642.7500 exploreP:0.0100\n",
      "Episode:967 meanR:10.2100 R:10.0 rate:0.0200 loss:312510.6250 exploreP:0.0100\n",
      "Episode:968 meanR:10.2000 R:9.0 rate:0.0180 loss:323691.1562 exploreP:0.0100\n",
      "Episode:969 meanR:10.2000 R:10.0 rate:0.0200 loss:364369.0625 exploreP:0.0100\n",
      "Episode:970 meanR:10.1700 R:9.0 rate:0.0180 loss:417736.1250 exploreP:0.0100\n",
      "Episode:971 meanR:10.1700 R:10.0 rate:0.0200 loss:305237.5312 exploreP:0.0100\n",
      "Episode:972 meanR:10.1600 R:10.0 rate:0.0200 loss:305468.5312 exploreP:0.0100\n",
      "Episode:973 meanR:10.1500 R:9.0 rate:0.0180 loss:374454.4375 exploreP:0.0100\n",
      "Episode:974 meanR:10.1400 R:10.0 rate:0.0200 loss:441674.0000 exploreP:0.0100\n",
      "Episode:975 meanR:10.1400 R:11.0 rate:0.0220 loss:368289.7812 exploreP:0.0100\n",
      "Episode:976 meanR:10.1100 R:8.0 rate:0.0160 loss:367542.2812 exploreP:0.0100\n",
      "Episode:977 meanR:10.1000 R:10.0 rate:0.0200 loss:359857.1875 exploreP:0.0100\n",
      "Episode:978 meanR:10.0800 R:10.0 rate:0.0200 loss:276011.1875 exploreP:0.0100\n",
      "Episode:979 meanR:10.0600 R:9.0 rate:0.0180 loss:350586.0938 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:980 meanR:10.0500 R:9.0 rate:0.0180 loss:373109.1250 exploreP:0.0100\n",
      "Episode:981 meanR:10.0200 R:8.0 rate:0.0160 loss:429035.3438 exploreP:0.0100\n",
      "Episode:982 meanR:10.0000 R:9.0 rate:0.0180 loss:387235.8438 exploreP:0.0100\n",
      "Episode:983 meanR:10.0000 R:10.0 rate:0.0200 loss:396856.8438 exploreP:0.0100\n",
      "Episode:984 meanR:9.9800 R:9.0 rate:0.0180 loss:472770.2812 exploreP:0.0100\n",
      "Episode:985 meanR:9.9600 R:10.0 rate:0.0200 loss:352976.6250 exploreP:0.0100\n",
      "Episode:986 meanR:9.9400 R:9.0 rate:0.0180 loss:379331.2812 exploreP:0.0100\n",
      "Episode:987 meanR:9.9300 R:10.0 rate:0.0200 loss:445039.0938 exploreP:0.0100\n",
      "Episode:988 meanR:9.9300 R:9.0 rate:0.0180 loss:427728.7188 exploreP:0.0100\n",
      "Episode:989 meanR:9.9100 R:9.0 rate:0.0180 loss:381872.6562 exploreP:0.0100\n",
      "Episode:990 meanR:9.8800 R:10.0 rate:0.0200 loss:317446.4062 exploreP:0.0100\n",
      "Episode:991 meanR:9.8600 R:9.0 rate:0.0180 loss:422335.1562 exploreP:0.0100\n",
      "Episode:992 meanR:9.8100 R:8.0 rate:0.0160 loss:284583.6250 exploreP:0.0100\n",
      "Episode:993 meanR:9.8000 R:10.0 rate:0.0200 loss:307206.4375 exploreP:0.0100\n",
      "Episode:994 meanR:9.7900 R:9.0 rate:0.0180 loss:428998.4375 exploreP:0.0100\n",
      "Episode:995 meanR:9.8100 R:11.0 rate:0.0220 loss:307964.8750 exploreP:0.0100\n",
      "Episode:996 meanR:9.7900 R:9.0 rate:0.0180 loss:346008.2812 exploreP:0.0100\n",
      "Episode:997 meanR:9.7600 R:8.0 rate:0.0160 loss:364106.3438 exploreP:0.0100\n",
      "Episode:998 meanR:9.7600 R:9.0 rate:0.0180 loss:314046.1250 exploreP:0.0100\n",
      "Episode:999 meanR:9.7600 R:10.0 rate:0.0200 loss:362441.7188 exploreP:0.0100\n",
      "Episode:1000 meanR:9.7600 R:9.0 rate:0.0180 loss:378425.5625 exploreP:0.0100\n",
      "Episode:1001 meanR:9.7400 R:9.0 rate:0.0180 loss:352403.1250 exploreP:0.0100\n",
      "Episode:1002 meanR:9.7200 R:10.0 rate:0.0200 loss:423882.9062 exploreP:0.0100\n",
      "Episode:1003 meanR:9.7100 R:10.0 rate:0.0200 loss:373891.5625 exploreP:0.0100\n",
      "Episode:1004 meanR:9.6900 R:9.0 rate:0.0180 loss:279226.6250 exploreP:0.0100\n",
      "Episode:1005 meanR:9.6900 R:10.0 rate:0.0200 loss:401350.5625 exploreP:0.0100\n",
      "Episode:1006 meanR:9.7000 R:11.0 rate:0.0220 loss:372327.9688 exploreP:0.0100\n",
      "Episode:1007 meanR:9.7000 R:10.0 rate:0.0200 loss:307623.0938 exploreP:0.0100\n",
      "Episode:1008 meanR:9.6900 R:10.0 rate:0.0200 loss:389380.3750 exploreP:0.0100\n",
      "Episode:1009 meanR:9.6600 R:8.0 rate:0.0160 loss:362051.4062 exploreP:0.0100\n",
      "Episode:1010 meanR:9.6400 R:9.0 rate:0.0180 loss:377913.6875 exploreP:0.0100\n",
      "Episode:1011 meanR:9.6300 R:10.0 rate:0.0200 loss:393513.4375 exploreP:0.0100\n",
      "Episode:1012 meanR:9.6400 R:11.0 rate:0.0220 loss:313752.8125 exploreP:0.0100\n",
      "Episode:1013 meanR:9.6400 R:10.0 rate:0.0200 loss:381154.6875 exploreP:0.0100\n",
      "Episode:1014 meanR:9.6300 R:10.0 rate:0.0200 loss:363062.7188 exploreP:0.0100\n",
      "Episode:1015 meanR:9.6300 R:9.0 rate:0.0180 loss:409257.9688 exploreP:0.0100\n",
      "Episode:1016 meanR:9.6400 R:10.0 rate:0.0200 loss:282959.6562 exploreP:0.0100\n",
      "Episode:1017 meanR:9.6400 R:9.0 rate:0.0180 loss:313890.4062 exploreP:0.0100\n",
      "Episode:1018 meanR:9.6200 R:8.0 rate:0.0160 loss:360648.6875 exploreP:0.0100\n",
      "Episode:1019 meanR:9.6300 R:10.0 rate:0.0200 loss:355409.9375 exploreP:0.0100\n",
      "Episode:1020 meanR:9.6200 R:9.0 rate:0.0180 loss:312282.0625 exploreP:0.0100\n",
      "Episode:1021 meanR:9.6200 R:10.0 rate:0.0200 loss:396502.5000 exploreP:0.0100\n",
      "Episode:1022 meanR:9.6300 R:9.0 rate:0.0180 loss:323919.0938 exploreP:0.0100\n",
      "Episode:1023 meanR:9.6200 R:9.0 rate:0.0180 loss:405401.4375 exploreP:0.0100\n",
      "Episode:1024 meanR:9.6200 R:9.0 rate:0.0180 loss:271714.0625 exploreP:0.0100\n",
      "Episode:1025 meanR:9.6300 R:10.0 rate:0.0200 loss:283774.6875 exploreP:0.0100\n",
      "Episode:1026 meanR:9.6200 R:10.0 rate:0.0200 loss:301757.3438 exploreP:0.0100\n",
      "Episode:1027 meanR:9.6100 R:10.0 rate:0.0200 loss:424496.5000 exploreP:0.0100\n",
      "Episode:1028 meanR:9.6200 R:9.0 rate:0.0180 loss:257309.9219 exploreP:0.0100\n",
      "Episode:1029 meanR:9.6200 R:9.0 rate:0.0180 loss:312666.0000 exploreP:0.0100\n",
      "Episode:1030 meanR:9.6100 R:10.0 rate:0.0200 loss:282714.1250 exploreP:0.0100\n",
      "Episode:1031 meanR:9.6000 R:9.0 rate:0.0180 loss:397911.1875 exploreP:0.0100\n",
      "Episode:1032 meanR:9.5700 R:9.0 rate:0.0180 loss:381552.6562 exploreP:0.0100\n",
      "Episode:1033 meanR:9.5900 R:11.0 rate:0.0220 loss:313137.0312 exploreP:0.0100\n",
      "Episode:1034 meanR:9.5800 R:9.0 rate:0.0180 loss:341485.5312 exploreP:0.0100\n",
      "Episode:1035 meanR:9.5900 R:10.0 rate:0.0200 loss:269164.2500 exploreP:0.0100\n",
      "Episode:1036 meanR:9.5800 R:9.0 rate:0.0180 loss:302785.7188 exploreP:0.0100\n",
      "Episode:1037 meanR:9.5700 R:10.0 rate:0.0200 loss:290940.2812 exploreP:0.0100\n",
      "Episode:1038 meanR:9.5600 R:8.0 rate:0.0160 loss:355456.8750 exploreP:0.0100\n",
      "Episode:1039 meanR:9.5500 R:9.0 rate:0.0180 loss:344976.2812 exploreP:0.0100\n",
      "Episode:1040 meanR:9.5400 R:9.0 rate:0.0180 loss:324517.9062 exploreP:0.0100\n",
      "Episode:1041 meanR:9.5200 R:9.0 rate:0.0180 loss:297250.3438 exploreP:0.0100\n",
      "Episode:1042 meanR:9.5100 R:10.0 rate:0.0200 loss:227609.7812 exploreP:0.0100\n",
      "Episode:1043 meanR:9.5000 R:9.0 rate:0.0180 loss:250738.3281 exploreP:0.0100\n",
      "Episode:1044 meanR:9.4800 R:9.0 rate:0.0180 loss:300201.3438 exploreP:0.0100\n",
      "Episode:1045 meanR:9.4600 R:9.0 rate:0.0180 loss:232584.9531 exploreP:0.0100\n",
      "Episode:1046 meanR:9.4600 R:9.0 rate:0.0180 loss:271222.5312 exploreP:0.0100\n",
      "Episode:1047 meanR:9.4300 R:8.0 rate:0.0160 loss:264906.8750 exploreP:0.0100\n",
      "Episode:1048 meanR:9.4400 R:10.0 rate:0.0200 loss:202316.3594 exploreP:0.0100\n",
      "Episode:1049 meanR:9.4400 R:9.0 rate:0.0180 loss:286102.8438 exploreP:0.0100\n",
      "Episode:1050 meanR:9.4400 R:10.0 rate:0.0200 loss:336166.8125 exploreP:0.0100\n",
      "Episode:1051 meanR:9.4400 R:10.0 rate:0.0200 loss:307474.7188 exploreP:0.0100\n",
      "Episode:1052 meanR:9.4500 R:10.0 rate:0.0200 loss:259532.7031 exploreP:0.0100\n",
      "Episode:1053 meanR:9.4400 R:8.0 rate:0.0160 loss:286230.6562 exploreP:0.0100\n",
      "Episode:1054 meanR:9.4200 R:9.0 rate:0.0180 loss:273202.8438 exploreP:0.0100\n",
      "Episode:1055 meanR:9.4400 R:10.0 rate:0.0200 loss:186749.1406 exploreP:0.0100\n",
      "Episode:1056 meanR:9.4400 R:9.0 rate:0.0180 loss:218665.2812 exploreP:0.0100\n",
      "Episode:1057 meanR:9.4200 R:9.0 rate:0.0180 loss:226064.9375 exploreP:0.0100\n",
      "Episode:1058 meanR:9.4300 R:10.0 rate:0.0200 loss:209797.2500 exploreP:0.0100\n",
      "Episode:1059 meanR:9.4200 R:9.0 rate:0.0180 loss:257614.3594 exploreP:0.0100\n",
      "Episode:1060 meanR:9.4300 R:10.0 rate:0.0200 loss:252537.9688 exploreP:0.0100\n",
      "Episode:1061 meanR:9.4300 R:10.0 rate:0.0200 loss:245129.5312 exploreP:0.0100\n",
      "Episode:1062 meanR:9.4200 R:9.0 rate:0.0180 loss:158412.1562 exploreP:0.0100\n",
      "Episode:1063 meanR:9.4300 R:10.0 rate:0.0200 loss:259246.8750 exploreP:0.0100\n",
      "Episode:1064 meanR:9.4300 R:9.0 rate:0.0180 loss:200154.0000 exploreP:0.0100\n",
      "Episode:1065 meanR:9.4300 R:10.0 rate:0.0200 loss:208993.8438 exploreP:0.0100\n",
      "Episode:1066 meanR:9.4400 R:11.0 rate:0.0220 loss:181062.1406 exploreP:0.0100\n",
      "Episode:1067 meanR:9.4300 R:9.0 rate:0.0180 loss:186822.7188 exploreP:0.0100\n",
      "Episode:1068 meanR:9.4400 R:10.0 rate:0.0200 loss:158636.1562 exploreP:0.0100\n",
      "Episode:1069 meanR:9.4300 R:9.0 rate:0.0180 loss:245643.8125 exploreP:0.0100\n",
      "Episode:1070 meanR:9.4300 R:9.0 rate:0.0180 loss:201914.8281 exploreP:0.0100\n",
      "Episode:1071 meanR:9.4300 R:10.0 rate:0.0200 loss:225215.6562 exploreP:0.0100\n",
      "Episode:1072 meanR:9.4300 R:10.0 rate:0.0200 loss:160241.5938 exploreP:0.0100\n",
      "Episode:1073 meanR:9.4300 R:9.0 rate:0.0180 loss:167814.7969 exploreP:0.0100\n",
      "Episode:1074 meanR:9.4300 R:10.0 rate:0.0200 loss:179713.0156 exploreP:0.0100\n",
      "Episode:1075 meanR:9.4100 R:9.0 rate:0.0180 loss:145570.4062 exploreP:0.0100\n",
      "Episode:1076 meanR:9.4100 R:8.0 rate:0.0160 loss:187656.5625 exploreP:0.0100\n",
      "Episode:1077 meanR:9.4000 R:9.0 rate:0.0180 loss:188395.0312 exploreP:0.0100\n",
      "Episode:1078 meanR:9.3900 R:9.0 rate:0.0180 loss:162577.9844 exploreP:0.0100\n",
      "Episode:1079 meanR:9.4000 R:10.0 rate:0.0200 loss:122151.6406 exploreP:0.0100\n",
      "Episode:1080 meanR:9.4000 R:9.0 rate:0.0180 loss:180127.7656 exploreP:0.0100\n",
      "Episode:1081 meanR:9.4200 R:10.0 rate:0.0200 loss:172846.8438 exploreP:0.0100\n",
      "Episode:1082 meanR:9.4400 R:11.0 rate:0.0220 loss:202937.1406 exploreP:0.0100\n",
      "Episode:1083 meanR:9.4400 R:10.0 rate:0.0200 loss:191877.4688 exploreP:0.0100\n",
      "Episode:1084 meanR:9.4400 R:9.0 rate:0.0180 loss:213890.1406 exploreP:0.0100\n",
      "Episode:1085 meanR:9.4400 R:10.0 rate:0.0200 loss:138570.0312 exploreP:0.0100\n",
      "Episode:1086 meanR:9.4400 R:9.0 rate:0.0180 loss:194655.2656 exploreP:0.0100\n",
      "Episode:1087 meanR:9.4400 R:10.0 rate:0.0200 loss:223782.8281 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1088 meanR:9.4600 R:11.0 rate:0.0220 loss:149459.2656 exploreP:0.0100\n",
      "Episode:1089 meanR:9.4700 R:10.0 rate:0.0200 loss:123125.8516 exploreP:0.0100\n",
      "Episode:1090 meanR:9.4600 R:9.0 rate:0.0180 loss:187400.9688 exploreP:0.0100\n",
      "Episode:1091 meanR:9.4600 R:9.0 rate:0.0180 loss:117247.0547 exploreP:0.0100\n",
      "Episode:1092 meanR:9.4700 R:9.0 rate:0.0180 loss:85365.8125 exploreP:0.0100\n",
      "Episode:1093 meanR:9.4700 R:10.0 rate:0.0200 loss:124252.8281 exploreP:0.0100\n",
      "Episode:1094 meanR:9.4800 R:10.0 rate:0.0200 loss:109350.2891 exploreP:0.0100\n",
      "Episode:1095 meanR:9.4600 R:9.0 rate:0.0180 loss:140150.3594 exploreP:0.0100\n",
      "Episode:1096 meanR:9.4600 R:9.0 rate:0.0180 loss:209802.0781 exploreP:0.0100\n",
      "Episode:1097 meanR:9.4700 R:9.0 rate:0.0180 loss:138658.1094 exploreP:0.0100\n",
      "Episode:1098 meanR:9.4900 R:11.0 rate:0.0220 loss:101390.9062 exploreP:0.0100\n",
      "Episode:1099 meanR:9.4900 R:10.0 rate:0.0200 loss:83308.6172 exploreP:0.0100\n",
      "Episode:1100 meanR:9.4800 R:8.0 rate:0.0160 loss:85907.2344 exploreP:0.0100\n",
      "Episode:1101 meanR:9.4900 R:10.0 rate:0.0200 loss:144699.1094 exploreP:0.0100\n",
      "Episode:1102 meanR:9.4800 R:9.0 rate:0.0180 loss:77376.5156 exploreP:0.0100\n",
      "Episode:1103 meanR:9.4700 R:9.0 rate:0.0180 loss:68490.0000 exploreP:0.0100\n",
      "Episode:1104 meanR:9.4800 R:10.0 rate:0.0200 loss:159988.0312 exploreP:0.0100\n",
      "Episode:1105 meanR:9.4800 R:10.0 rate:0.0200 loss:82446.6719 exploreP:0.0100\n",
      "Episode:1106 meanR:9.4700 R:10.0 rate:0.0200 loss:36889.4570 exploreP:0.0100\n",
      "Episode:1107 meanR:9.4600 R:9.0 rate:0.0180 loss:132862.9375 exploreP:0.0100\n",
      "Episode:1108 meanR:9.4600 R:10.0 rate:0.0200 loss:94745.5469 exploreP:0.0100\n",
      "Episode:1109 meanR:9.4800 R:10.0 rate:0.0200 loss:42588.3359 exploreP:0.0100\n",
      "Episode:1110 meanR:9.4900 R:10.0 rate:0.0200 loss:79036.3281 exploreP:0.0100\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(1111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "        num_step = 0 # each episode\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done), -1])\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Rating the last played episode\n",
    "            if done is True:\n",
    "                rate = total_reward/ goal # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.buffer[-1-idx][5] == -1: # double-check if it is empty and it is not rated!\n",
    "                        memory.buffer[-1-idx][5] = rate # rate each SA pair\n",
    "                        \n",
    "            # Rating and training the memory\n",
    "            #rates = np.array(memory.buffer)[:, 5]\n",
    "            #rated_mem = np.array(memory.buffer)[rates >= (max(rates)*0.1)]\n",
    "            #rated_mem = np.array(memory.buffer)\n",
    "            #batch = sample(ListArr=rated_mem, batch_size=batch_size)\n",
    "            batch = sample(ListArr=memory.buffer, batch_size=batch_size)\n",
    "            rates = np.array([each[5] for each in batch])\n",
    "            states = np.array([each[0] for each in batch])[rates >= (max(rates)*0.1)]\n",
    "            actions = np.array([each[1] for each in batch])[rates >= (max(rates)*0.1)]\n",
    "            next_states = np.array([each[2] for each in batch])[rates >= (max(rates)*0.1)]\n",
    "            rewards = np.array([each[3] for each in batch])[rates >= (max(rates)*0.1)]\n",
    "            dones = np.array([each[4] for each in batch])[rates >= (max(rates)*0.1)]\n",
    "            #rates = np.array([each[5] for each in batch])\n",
    "            #nextQs_logits = sess.run(model.Qs_logits, feed_dict = {model.states: next_states})\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict = {model.states: next_states})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average losses')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "# Creating a gym env\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# A training graph session\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        # Closing the env\n",
    "        print('total_reward: {}'.format(total_reward))\n",
    "# Close the env at the end\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

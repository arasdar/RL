{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN with rated memory replay\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aras/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "state = env.reset()\n",
    "batch = []\n",
    "for _ in range(1000):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action) # take a random action\n",
    "    batch.append([state, action, next_state, reward, float(done)])\n",
    "    #     print('state, action, reward, done, info:', \n",
    "    #           state, action, reward, done, info)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 0.00545212, -0.00609234, -0.03893244, -0.04982415]),\n",
       "  0,\n",
       "  array([ 0.00533027, -0.20063503, -0.03992892,  0.23032552]),\n",
       "  1.0,\n",
       "  0.0],\n",
       " (4,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([each[0] for each in batch])\n",
    "actions = np.array([each[1] for each in batch])\n",
    "next_states = np.array([each[2] for each in batch])\n",
    "rewards = np.array([each[3] for each in batch])\n",
    "dones = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(1000,) (1000, 4) (1000,) (1000,)\n",
      "float64 float64 int64 float64\n",
      "1 0\n",
      "2\n",
      "1.0 1.0\n",
      "2.2335040889466935 -2.757166976971607\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    return states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, actions, targetQs, action_size, hidden_size):\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    #Qs = tf.reduce_max(actions_logits, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs) # model input\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(batch_size, ListArr):\n",
    "    idx = np.random.choice(np.arange(len(ListArr)), \n",
    "                           size=batch_size, \n",
    "                           replace=True)\n",
    "    return [ListArr[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 24*2             # number of units in each Q-network hidden layer\n",
    "learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e2)             # experience mini-batch size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the memory with the pool of random exploration of the env.\n",
    "goal = 500 # env-based, the total reward required for reaching the goal G\n",
    "state = env.reset() # env-based\n",
    "total_reward = 0 # episode R\n",
    "num_step = 0 # episode steps/ length based on number of steps\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample() # exploring the env action space/ random action/ explore\n",
    "    next_state, reward, done, _ = env.step(action) # exploring the env state, reward, and done/end\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done), -1])\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward # R += r\n",
    "    state = next_state # update the state for next episode\n",
    "    if done is True: # end of this episode\n",
    "        state = env.reset() # reset for next episode\n",
    "        rate = total_reward/goal # the actual sucess rate of the played sequence\n",
    "        total_reward = 0 # reset for next episode\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.buffer[-1-idx][5] == -1: # double-check if it is empty and it is not rated!\n",
    "                memory.buffer[-1-idx][5] = rate # rate each SA pair\n",
    "        num_step = 0 # reset for the next episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dones = np.array(memory.buffer)[:, 4]\n",
    "rates = np.array(memory.buffer)[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones[-27:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.018, 0.018, 0.018, 0.018, 0.036, 0.036, 0.036, 0.036, 0.036,\n",
       "       0.036, 0.036, 0.036, 0.036, 0.036, 0.036, 0.036, 0.036, 0.036,\n",
       "       0.036, 0.036, 0.036, 0.036, -1, -1, -1, -1, -1], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates[-27:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = np.array(memory.buffer)[:, 5]\n",
    "rated_mem = np.array(memory.buffer)[rates >= (max(rates)*0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = np.array(rated_mem)[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.058, 0.058, 0.058, ..., 0.036, 0.036, 0.036], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dones = np.array(memory.buffer)[:, 4]\n",
    "rates = np.array(memory.buffer)[:, 5]\n",
    "rated_mem = np.array(memory.buffer)[rates >= (max(rates)*0.1)]\n",
    "batch = sample(ListArr=rated_mem, batch_size=batch_size)\n",
    "states = np.array([each[0] for each in batch])\n",
    "actions = np.array([each[1] for each in batch])\n",
    "next_states = np.array([each[2] for each in batch])\n",
    "rewards = np.array([each[3] for each in batch])\n",
    "dones = np.array([each[4] for each in batch])\n",
    "rates = np.array([each[5] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4),\n",
       " dtype('float64'),\n",
       " (100,),\n",
       " dtype('int64'),\n",
       " (100, 4),\n",
       " dtype('float64'),\n",
       " (100,),\n",
       " dtype('float64'),\n",
       " (100,),\n",
       " dtype('float64'),\n",
       " (100,),\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape, states.dtype, actions.shape, actions.dtype, next_states.shape, next_states.dtype, \\\n",
    "rewards.shape, rewards.dtype, dones.shape, dones.dtype, rates.shape, rates.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.024, 0.042, 0.086, 0.074, 0.032, 0.026, 0.024, 0.044, 0.06 ,\n",
       "       0.038, 0.108, 0.054, 0.102, 0.108, 0.088, 0.034, 0.062, 0.06 ,\n",
       "       0.034, 0.068, 0.036, 0.098, 0.066, 0.044, 0.032, 0.054, 0.076,\n",
       "       0.046, 0.032, 0.034, 0.034, 0.128, 0.044, 0.106, 0.058, 0.032,\n",
       "       0.096, 0.154, 0.062, 0.036, 0.032, 0.036, 0.034, 0.062, 0.064,\n",
       "       0.034, 0.04 , 0.026, 0.05 , 0.024, 0.032, 0.03 , 0.062, 0.12 ,\n",
       "       0.128, 0.042, 0.06 , 0.034, 0.042, 0.094, 0.048, 0.032, 0.048,\n",
       "       0.082, 0.17 , 0.028, 0.054, 0.05 , 0.052, 0.052, 0.062, 0.034,\n",
       "       0.054, 0.12 , 0.044, 0.046, 0.082, 0.1  , 0.11 , 0.052, 0.108,\n",
       "       0.044, 0.062, 0.058, 0.096, 0.036, 0.058, 0.032, 0.024, 0.03 ,\n",
       "       0.022, 0.11 , 0.036, 0.028, 0.058, 0.06 , 0.024, 0.066, 0.112,\n",
       "       0.036])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:23.0000 R:23.0 rate:0.0460 loss:1.0110 exploreP:0.9977\n",
      "Episode:1 meanR:42.0000 R:61.0 rate:0.1220 loss:1.1627 exploreP:0.9917\n",
      "Episode:2 meanR:32.6667 R:14.0 rate:0.0280 loss:1.2473 exploreP:0.9903\n",
      "Episode:3 meanR:28.2500 R:15.0 rate:0.0300 loss:1.2502 exploreP:0.9889\n",
      "Episode:4 meanR:25.4000 R:14.0 rate:0.0280 loss:1.2772 exploreP:0.9875\n",
      "Episode:5 meanR:24.5000 R:20.0 rate:0.0400 loss:1.3057 exploreP:0.9856\n",
      "Episode:6 meanR:23.4286 R:17.0 rate:0.0340 loss:1.2722 exploreP:0.9839\n",
      "Episode:7 meanR:24.5000 R:32.0 rate:0.0640 loss:1.2694 exploreP:0.9808\n",
      "Episode:8 meanR:24.2222 R:22.0 rate:0.0440 loss:1.2625 exploreP:0.9787\n",
      "Episode:9 meanR:24.1000 R:23.0 rate:0.0460 loss:1.2819 exploreP:0.9764\n",
      "Episode:10 meanR:24.0000 R:23.0 rate:0.0460 loss:1.2919 exploreP:0.9742\n",
      "Episode:11 meanR:23.1667 R:14.0 rate:0.0280 loss:1.3180 exploreP:0.9729\n",
      "Episode:12 meanR:22.6154 R:16.0 rate:0.0320 loss:1.3374 exploreP:0.9713\n",
      "Episode:13 meanR:23.4286 R:34.0 rate:0.0680 loss:1.3706 exploreP:0.9681\n",
      "Episode:14 meanR:23.8667 R:30.0 rate:0.0600 loss:1.4193 exploreP:0.9652\n",
      "Episode:15 meanR:23.2500 R:14.0 rate:0.0280 loss:1.5148 exploreP:0.9638\n",
      "Episode:16 meanR:23.0588 R:20.0 rate:0.0400 loss:1.5515 exploreP:0.9619\n",
      "Episode:17 meanR:23.3333 R:28.0 rate:0.0560 loss:1.6502 exploreP:0.9593\n",
      "Episode:18 meanR:23.7895 R:32.0 rate:0.0640 loss:1.8040 exploreP:0.9562\n",
      "Episode:19 meanR:24.1500 R:31.0 rate:0.0620 loss:1.9517 exploreP:0.9533\n",
      "Episode:20 meanR:24.1429 R:24.0 rate:0.0480 loss:2.1380 exploreP:0.9511\n",
      "Episode:21 meanR:24.2273 R:26.0 rate:0.0520 loss:2.5810 exploreP:0.9486\n",
      "Episode:22 meanR:24.3043 R:26.0 rate:0.0520 loss:2.7018 exploreP:0.9462\n",
      "Episode:23 meanR:23.9167 R:15.0 rate:0.0300 loss:2.7296 exploreP:0.9448\n",
      "Episode:24 meanR:24.0400 R:27.0 rate:0.0540 loss:3.0340 exploreP:0.9423\n",
      "Episode:25 meanR:23.7692 R:17.0 rate:0.0340 loss:3.4841 exploreP:0.9407\n",
      "Episode:26 meanR:24.7407 R:50.0 rate:0.1000 loss:4.0206 exploreP:0.9360\n",
      "Episode:27 meanR:24.3929 R:15.0 rate:0.0300 loss:4.6923 exploreP:0.9346\n",
      "Episode:28 meanR:24.6552 R:32.0 rate:0.0640 loss:4.9550 exploreP:0.9317\n",
      "Episode:29 meanR:24.5000 R:20.0 rate:0.0400 loss:6.0218 exploreP:0.9298\n",
      "Episode:30 meanR:24.7097 R:31.0 rate:0.0620 loss:6.4128 exploreP:0.9270\n",
      "Episode:31 meanR:24.2812 R:11.0 rate:0.0220 loss:7.1361 exploreP:0.9260\n",
      "Episode:32 meanR:24.2727 R:24.0 rate:0.0480 loss:7.1865 exploreP:0.9238\n",
      "Episode:33 meanR:23.9412 R:13.0 rate:0.0260 loss:8.6525 exploreP:0.9226\n",
      "Episode:34 meanR:23.7143 R:16.0 rate:0.0320 loss:8.6707 exploreP:0.9211\n",
      "Episode:35 meanR:24.3611 R:47.0 rate:0.0940 loss:9.6952 exploreP:0.9169\n",
      "Episode:36 meanR:24.8919 R:44.0 rate:0.0880 loss:13.5509 exploreP:0.9129\n",
      "Episode:37 meanR:24.4737 R:9.0 rate:0.0180 loss:10.3944 exploreP:0.9121\n",
      "Episode:38 meanR:24.4103 R:22.0 rate:0.0440 loss:12.3014 exploreP:0.9101\n",
      "Episode:39 meanR:24.2000 R:16.0 rate:0.0320 loss:16.1636 exploreP:0.9087\n",
      "Episode:40 meanR:24.1463 R:22.0 rate:0.0440 loss:16.0562 exploreP:0.9067\n",
      "Episode:41 meanR:23.9524 R:16.0 rate:0.0320 loss:20.9772 exploreP:0.9053\n",
      "Episode:42 meanR:24.0930 R:30.0 rate:0.0600 loss:18.3295 exploreP:0.9026\n",
      "Episode:43 meanR:24.0455 R:22.0 rate:0.0440 loss:20.5877 exploreP:0.9006\n",
      "Episode:44 meanR:24.3556 R:38.0 rate:0.0760 loss:21.1991 exploreP:0.8972\n",
      "Episode:45 meanR:24.1522 R:15.0 rate:0.0300 loss:23.4110 exploreP:0.8959\n",
      "Episode:46 meanR:23.8511 R:10.0 rate:0.0200 loss:27.5909 exploreP:0.8950\n",
      "Episode:47 meanR:23.9375 R:28.0 rate:0.0560 loss:29.0750 exploreP:0.8925\n",
      "Episode:48 meanR:23.7755 R:16.0 rate:0.0320 loss:35.2518 exploreP:0.8911\n",
      "Episode:49 meanR:23.6600 R:18.0 rate:0.0360 loss:30.4985 exploreP:0.8895\n",
      "Episode:50 meanR:23.7255 R:27.0 rate:0.0540 loss:36.4136 exploreP:0.8872\n",
      "Episode:51 meanR:23.5769 R:16.0 rate:0.0320 loss:40.9332 exploreP:0.8858\n",
      "Episode:52 meanR:23.6415 R:27.0 rate:0.0540 loss:45.5854 exploreP:0.8834\n",
      "Episode:53 meanR:23.9259 R:39.0 rate:0.0780 loss:48.2878 exploreP:0.8800\n",
      "Episode:54 meanR:23.8545 R:20.0 rate:0.0400 loss:49.4318 exploreP:0.8783\n",
      "Episode:55 meanR:23.6786 R:14.0 rate:0.0280 loss:53.3390 exploreP:0.8771\n",
      "Episode:56 meanR:23.8596 R:34.0 rate:0.0680 loss:59.4588 exploreP:0.8741\n",
      "Episode:57 meanR:23.7586 R:18.0 rate:0.0360 loss:53.9877 exploreP:0.8726\n",
      "Episode:58 meanR:23.9661 R:36.0 rate:0.0720 loss:68.3222 exploreP:0.8695\n",
      "Episode:59 meanR:23.8667 R:18.0 rate:0.0360 loss:57.3781 exploreP:0.8679\n",
      "Episode:60 meanR:23.7213 R:15.0 rate:0.0300 loss:77.0004 exploreP:0.8666\n",
      "Episode:61 meanR:23.5806 R:15.0 rate:0.0300 loss:67.8236 exploreP:0.8653\n",
      "Episode:62 meanR:23.5079 R:19.0 rate:0.0380 loss:60.5040 exploreP:0.8637\n",
      "Episode:63 meanR:23.3750 R:15.0 rate:0.0300 loss:62.6169 exploreP:0.8624\n",
      "Episode:64 meanR:23.4154 R:26.0 rate:0.0520 loss:57.7290 exploreP:0.8602\n",
      "Episode:65 meanR:23.3788 R:21.0 rate:0.0420 loss:49.7281 exploreP:0.8584\n",
      "Episode:66 meanR:23.3731 R:23.0 rate:0.0460 loss:52.9254 exploreP:0.8565\n",
      "Episode:67 meanR:23.5000 R:32.0 rate:0.0640 loss:63.4683 exploreP:0.8538\n",
      "Episode:68 meanR:23.6812 R:36.0 rate:0.0720 loss:64.6347 exploreP:0.8508\n",
      "Episode:69 meanR:23.5000 R:11.0 rate:0.0220 loss:59.1793 exploreP:0.8498\n",
      "Episode:70 meanR:23.6761 R:36.0 rate:0.0720 loss:63.0609 exploreP:0.8468\n",
      "Episode:71 meanR:23.5694 R:16.0 rate:0.0320 loss:75.8142 exploreP:0.8455\n",
      "Episode:72 meanR:23.3973 R:11.0 rate:0.0220 loss:56.3773 exploreP:0.8446\n",
      "Episode:73 meanR:23.2838 R:15.0 rate:0.0300 loss:66.0529 exploreP:0.8433\n",
      "Episode:74 meanR:23.2133 R:18.0 rate:0.0360 loss:68.3507 exploreP:0.8418\n",
      "Episode:75 meanR:23.0921 R:14.0 rate:0.0280 loss:58.0311 exploreP:0.8406\n",
      "Episode:76 meanR:22.9481 R:12.0 rate:0.0240 loss:47.2381 exploreP:0.8397\n",
      "Episode:77 meanR:23.0769 R:33.0 rate:0.0660 loss:59.8412 exploreP:0.8369\n",
      "Episode:78 meanR:23.0127 R:18.0 rate:0.0360 loss:68.1586 exploreP:0.8354\n",
      "Episode:79 meanR:22.8750 R:12.0 rate:0.0240 loss:64.0477 exploreP:0.8344\n",
      "Episode:80 meanR:22.8148 R:18.0 rate:0.0360 loss:54.8246 exploreP:0.8330\n",
      "Episode:81 meanR:22.7927 R:21.0 rate:0.0420 loss:53.3095 exploreP:0.8312\n",
      "Episode:82 meanR:22.8072 R:24.0 rate:0.0480 loss:46.6147 exploreP:0.8293\n",
      "Episode:83 meanR:22.7500 R:18.0 rate:0.0360 loss:59.9146 exploreP:0.8278\n",
      "Episode:84 meanR:22.7176 R:20.0 rate:0.0400 loss:58.3145 exploreP:0.8262\n",
      "Episode:85 meanR:22.5930 R:12.0 rate:0.0240 loss:57.4043 exploreP:0.8252\n",
      "Episode:86 meanR:22.4598 R:11.0 rate:0.0220 loss:49.5659 exploreP:0.8243\n",
      "Episode:87 meanR:22.6932 R:43.0 rate:0.0860 loss:61.0531 exploreP:0.8208\n",
      "Episode:88 meanR:22.8652 R:38.0 rate:0.0760 loss:50.2047 exploreP:0.8177\n",
      "Episode:89 meanR:22.7778 R:15.0 rate:0.0300 loss:50.4961 exploreP:0.8165\n",
      "Episode:90 meanR:22.7802 R:23.0 rate:0.0460 loss:54.2742 exploreP:0.8146\n",
      "Episode:91 meanR:22.7391 R:19.0 rate:0.0380 loss:46.4831 exploreP:0.8131\n",
      "Episode:92 meanR:22.8817 R:36.0 rate:0.0720 loss:57.4038 exploreP:0.8102\n",
      "Episode:93 meanR:22.7979 R:15.0 rate:0.0300 loss:54.8713 exploreP:0.8090\n",
      "Episode:94 meanR:22.7684 R:20.0 rate:0.0400 loss:49.5170 exploreP:0.8074\n",
      "Episode:95 meanR:22.6771 R:14.0 rate:0.0280 loss:42.2274 exploreP:0.8063\n",
      "Episode:96 meanR:22.5773 R:13.0 rate:0.0260 loss:49.4392 exploreP:0.8053\n",
      "Episode:97 meanR:22.5102 R:16.0 rate:0.0320 loss:48.4099 exploreP:0.8040\n",
      "Episode:98 meanR:22.4141 R:13.0 rate:0.0260 loss:39.0094 exploreP:0.8030\n",
      "Episode:99 meanR:22.3200 R:13.0 rate:0.0260 loss:49.4986 exploreP:0.8020\n",
      "Episode:100 meanR:22.3000 R:21.0 rate:0.0420 loss:38.0285 exploreP:0.8003\n",
      "Episode:101 meanR:21.8200 R:13.0 rate:0.0260 loss:38.5336 exploreP:0.7993\n",
      "Episode:102 meanR:21.8400 R:16.0 rate:0.0320 loss:48.7325 exploreP:0.7980\n",
      "Episode:103 meanR:21.8700 R:18.0 rate:0.0360 loss:41.1053 exploreP:0.7966\n",
      "Episode:104 meanR:21.8300 R:10.0 rate:0.0200 loss:40.3305 exploreP:0.7958\n",
      "Episode:105 meanR:21.9000 R:27.0 rate:0.0540 loss:41.0926 exploreP:0.7937\n",
      "Episode:106 meanR:21.9600 R:23.0 rate:0.0460 loss:41.7778 exploreP:0.7919\n",
      "Episode:107 meanR:21.8100 R:17.0 rate:0.0340 loss:42.9209 exploreP:0.7906\n",
      "Episode:108 meanR:21.7400 R:15.0 rate:0.0300 loss:34.0092 exploreP:0.7894\n",
      "Episode:109 meanR:21.8400 R:33.0 rate:0.0660 loss:36.6872 exploreP:0.7868\n",
      "Episode:110 meanR:21.7900 R:18.0 rate:0.0360 loss:32.1561 exploreP:0.7854\n",
      "Episode:111 meanR:21.8500 R:20.0 rate:0.0400 loss:34.4196 exploreP:0.7839\n",
      "Episode:112 meanR:21.8500 R:16.0 rate:0.0320 loss:35.1042 exploreP:0.7826\n",
      "Episode:113 meanR:21.6800 R:17.0 rate:0.0340 loss:36.8094 exploreP:0.7813\n",
      "Episode:114 meanR:21.4800 R:10.0 rate:0.0200 loss:35.8047 exploreP:0.7806\n",
      "Episode:115 meanR:21.5000 R:16.0 rate:0.0320 loss:30.0199 exploreP:0.7793\n",
      "Episode:116 meanR:21.4400 R:14.0 rate:0.0280 loss:27.4252 exploreP:0.7782\n",
      "Episode:117 meanR:21.3400 R:18.0 rate:0.0360 loss:29.0375 exploreP:0.7769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:118 meanR:21.4300 R:41.0 rate:0.0820 loss:27.0601 exploreP:0.7737\n",
      "Episode:119 meanR:21.3000 R:18.0 rate:0.0360 loss:34.4363 exploreP:0.7723\n",
      "Episode:120 meanR:21.2000 R:14.0 rate:0.0280 loss:25.5840 exploreP:0.7713\n",
      "Episode:121 meanR:21.1700 R:23.0 rate:0.0460 loss:25.6275 exploreP:0.7695\n",
      "Episode:122 meanR:21.0900 R:18.0 rate:0.0360 loss:27.7654 exploreP:0.7682\n",
      "Episode:123 meanR:21.0600 R:12.0 rate:0.0240 loss:20.1883 exploreP:0.7673\n",
      "Episode:124 meanR:20.9500 R:16.0 rate:0.0320 loss:24.3678 exploreP:0.7660\n",
      "Episode:125 meanR:20.8900 R:11.0 rate:0.0220 loss:24.6428 exploreP:0.7652\n",
      "Episode:126 meanR:20.5300 R:14.0 rate:0.0280 loss:25.9233 exploreP:0.7642\n",
      "Episode:127 meanR:20.5700 R:19.0 rate:0.0380 loss:27.7956 exploreP:0.7627\n",
      "Episode:128 meanR:20.5500 R:30.0 rate:0.0600 loss:25.4590 exploreP:0.7605\n",
      "Episode:129 meanR:20.4800 R:13.0 rate:0.0260 loss:27.3558 exploreP:0.7595\n",
      "Episode:130 meanR:20.3300 R:16.0 rate:0.0320 loss:22.1399 exploreP:0.7583\n",
      "Episode:131 meanR:20.7200 R:50.0 rate:0.1000 loss:23.8990 exploreP:0.7546\n",
      "Episode:132 meanR:20.6600 R:18.0 rate:0.0360 loss:21.8986 exploreP:0.7532\n",
      "Episode:133 meanR:20.6900 R:16.0 rate:0.0320 loss:22.7877 exploreP:0.7520\n",
      "Episode:134 meanR:20.6400 R:11.0 rate:0.0220 loss:23.6427 exploreP:0.7512\n",
      "Episode:135 meanR:20.4600 R:29.0 rate:0.0580 loss:20.8966 exploreP:0.7491\n",
      "Episode:136 meanR:20.2400 R:22.0 rate:0.0440 loss:22.4194 exploreP:0.7475\n",
      "Episode:137 meanR:20.2800 R:13.0 rate:0.0260 loss:19.6375 exploreP:0.7465\n",
      "Episode:138 meanR:20.3000 R:24.0 rate:0.0480 loss:22.5953 exploreP:0.7447\n",
      "Episode:139 meanR:20.4800 R:34.0 rate:0.0680 loss:20.9639 exploreP:0.7422\n",
      "Episode:140 meanR:20.6300 R:37.0 rate:0.0740 loss:18.0090 exploreP:0.7395\n",
      "Episode:141 meanR:20.6500 R:18.0 rate:0.0360 loss:16.7658 exploreP:0.7382\n",
      "Episode:142 meanR:20.6700 R:32.0 rate:0.0640 loss:17.6786 exploreP:0.7359\n",
      "Episode:143 meanR:20.6000 R:15.0 rate:0.0300 loss:13.4678 exploreP:0.7348\n",
      "Episode:144 meanR:20.9400 R:72.0 rate:0.1440 loss:17.9556 exploreP:0.7296\n",
      "Episode:145 meanR:20.9200 R:13.0 rate:0.0260 loss:16.4147 exploreP:0.7287\n",
      "Episode:146 meanR:20.9500 R:13.0 rate:0.0260 loss:16.7163 exploreP:0.7277\n",
      "Episode:147 meanR:21.5400 R:87.0 rate:0.1740 loss:16.8703 exploreP:0.7215\n",
      "Episode:148 meanR:21.5000 R:12.0 rate:0.0240 loss:15.0863 exploreP:0.7207\n",
      "Episode:149 meanR:21.4500 R:13.0 rate:0.0260 loss:15.2702 exploreP:0.7197\n",
      "Episode:150 meanR:21.2800 R:10.0 rate:0.0200 loss:18.8846 exploreP:0.7190\n",
      "Episode:151 meanR:21.4300 R:31.0 rate:0.0620 loss:18.2303 exploreP:0.7168\n",
      "Episode:152 meanR:22.1600 R:100.0 rate:0.2000 loss:18.1047 exploreP:0.7098\n",
      "Episode:153 meanR:21.9100 R:14.0 rate:0.0280 loss:18.3901 exploreP:0.7088\n",
      "Episode:154 meanR:21.8800 R:17.0 rate:0.0340 loss:19.1877 exploreP:0.7076\n",
      "Episode:155 meanR:22.1600 R:42.0 rate:0.0840 loss:18.3319 exploreP:0.7047\n",
      "Episode:156 meanR:22.0800 R:26.0 rate:0.0520 loss:18.1168 exploreP:0.7029\n",
      "Episode:157 meanR:22.1400 R:24.0 rate:0.0480 loss:14.0089 exploreP:0.7013\n",
      "Episode:158 meanR:21.9200 R:14.0 rate:0.0280 loss:14.8771 exploreP:0.7003\n",
      "Episode:159 meanR:21.9900 R:25.0 rate:0.0500 loss:17.3570 exploreP:0.6986\n",
      "Episode:160 meanR:22.2000 R:36.0 rate:0.0720 loss:20.3512 exploreP:0.6961\n",
      "Episode:161 meanR:22.3900 R:34.0 rate:0.0680 loss:15.4895 exploreP:0.6938\n",
      "Episode:162 meanR:22.3000 R:10.0 rate:0.0200 loss:16.5713 exploreP:0.6931\n",
      "Episode:163 meanR:22.3800 R:23.0 rate:0.0460 loss:16.5672 exploreP:0.6915\n",
      "Episode:164 meanR:22.3400 R:22.0 rate:0.0440 loss:17.3784 exploreP:0.6900\n",
      "Episode:165 meanR:22.7500 R:62.0 rate:0.1240 loss:17.8020 exploreP:0.6858\n",
      "Episode:166 meanR:22.8100 R:29.0 rate:0.0580 loss:18.0264 exploreP:0.6838\n",
      "Episode:167 meanR:22.8600 R:37.0 rate:0.0740 loss:17.6531 exploreP:0.6814\n",
      "Episode:168 meanR:22.8500 R:35.0 rate:0.0700 loss:16.3473 exploreP:0.6790\n",
      "Episode:169 meanR:23.0400 R:30.0 rate:0.0600 loss:20.9186 exploreP:0.6770\n",
      "Episode:170 meanR:24.0200 R:134.0 rate:0.2680 loss:19.9588 exploreP:0.6681\n",
      "Episode:171 meanR:24.0000 R:14.0 rate:0.0280 loss:18.5405 exploreP:0.6672\n",
      "Episode:172 meanR:24.7500 R:86.0 rate:0.1720 loss:20.2160 exploreP:0.6616\n",
      "Episode:173 meanR:24.8700 R:27.0 rate:0.0540 loss:20.8230 exploreP:0.6598\n",
      "Episode:174 meanR:24.8800 R:19.0 rate:0.0380 loss:24.1817 exploreP:0.6586\n",
      "Episode:175 meanR:24.9900 R:25.0 rate:0.0500 loss:20.2157 exploreP:0.6570\n",
      "Episode:176 meanR:25.2300 R:36.0 rate:0.0720 loss:19.5957 exploreP:0.6546\n",
      "Episode:177 meanR:25.4200 R:52.0 rate:0.1040 loss:20.6277 exploreP:0.6513\n",
      "Episode:178 meanR:25.6600 R:42.0 rate:0.0840 loss:22.3962 exploreP:0.6486\n",
      "Episode:179 meanR:25.7900 R:25.0 rate:0.0500 loss:18.9314 exploreP:0.6470\n",
      "Episode:180 meanR:25.8500 R:24.0 rate:0.0480 loss:25.4407 exploreP:0.6455\n",
      "Episode:181 meanR:26.4600 R:82.0 rate:0.1640 loss:20.5964 exploreP:0.6403\n",
      "Episode:182 meanR:26.5500 R:33.0 rate:0.0660 loss:21.4335 exploreP:0.6382\n",
      "Episode:183 meanR:26.5700 R:20.0 rate:0.0400 loss:22.2686 exploreP:0.6370\n",
      "Episode:184 meanR:26.6300 R:26.0 rate:0.0520 loss:22.4437 exploreP:0.6353\n",
      "Episode:185 meanR:26.8000 R:29.0 rate:0.0580 loss:22.1230 exploreP:0.6335\n",
      "Episode:186 meanR:27.3800 R:69.0 rate:0.1380 loss:25.2721 exploreP:0.6292\n",
      "Episode:187 meanR:27.5700 R:62.0 rate:0.1240 loss:24.8293 exploreP:0.6254\n",
      "Episode:188 meanR:27.4500 R:26.0 rate:0.0520 loss:23.1745 exploreP:0.6238\n",
      "Episode:189 meanR:27.8400 R:54.0 rate:0.1080 loss:23.1569 exploreP:0.6205\n",
      "Episode:190 meanR:28.2500 R:64.0 rate:0.1280 loss:22.9162 exploreP:0.6166\n",
      "Episode:191 meanR:28.8600 R:80.0 rate:0.1600 loss:26.8016 exploreP:0.6118\n",
      "Episode:192 meanR:29.1900 R:69.0 rate:0.1380 loss:26.4123 exploreP:0.6076\n",
      "Episode:193 meanR:29.4200 R:38.0 rate:0.0760 loss:27.8935 exploreP:0.6054\n",
      "Episode:194 meanR:29.5700 R:35.0 rate:0.0700 loss:28.2120 exploreP:0.6033\n",
      "Episode:195 meanR:30.0000 R:57.0 rate:0.1140 loss:25.7122 exploreP:0.5999\n",
      "Episode:196 meanR:30.3700 R:50.0 rate:0.1000 loss:25.7218 exploreP:0.5970\n",
      "Episode:197 meanR:30.6500 R:44.0 rate:0.0880 loss:30.7825 exploreP:0.5944\n",
      "Episode:198 meanR:30.8100 R:29.0 rate:0.0580 loss:28.1902 exploreP:0.5927\n",
      "Episode:199 meanR:30.8000 R:12.0 rate:0.0240 loss:23.9242 exploreP:0.5920\n",
      "Episode:200 meanR:30.8500 R:26.0 rate:0.0520 loss:31.0265 exploreP:0.5905\n",
      "Episode:201 meanR:30.9400 R:22.0 rate:0.0440 loss:27.3268 exploreP:0.5892\n",
      "Episode:202 meanR:31.6100 R:83.0 rate:0.1660 loss:33.0806 exploreP:0.5844\n",
      "Episode:203 meanR:31.8700 R:44.0 rate:0.0880 loss:30.0324 exploreP:0.5819\n",
      "Episode:204 meanR:32.1000 R:33.0 rate:0.0660 loss:29.3118 exploreP:0.5800\n",
      "Episode:205 meanR:32.1800 R:35.0 rate:0.0700 loss:31.7055 exploreP:0.5780\n",
      "Episode:206 meanR:32.6800 R:73.0 rate:0.1460 loss:30.2837 exploreP:0.5739\n",
      "Episode:207 meanR:32.8300 R:32.0 rate:0.0640 loss:28.2982 exploreP:0.5721\n",
      "Episode:208 meanR:33.4400 R:76.0 rate:0.1520 loss:32.4452 exploreP:0.5679\n",
      "Episode:209 meanR:33.7300 R:62.0 rate:0.1240 loss:32.5801 exploreP:0.5644\n",
      "Episode:210 meanR:34.0800 R:53.0 rate:0.1060 loss:34.3758 exploreP:0.5615\n",
      "Episode:211 meanR:34.3500 R:47.0 rate:0.0940 loss:34.0758 exploreP:0.5589\n",
      "Episode:212 meanR:34.8100 R:62.0 rate:0.1240 loss:36.2453 exploreP:0.5555\n",
      "Episode:213 meanR:34.7900 R:15.0 rate:0.0300 loss:34.4300 exploreP:0.5547\n",
      "Episode:214 meanR:35.2400 R:55.0 rate:0.1100 loss:33.7304 exploreP:0.5517\n",
      "Episode:215 meanR:35.6600 R:58.0 rate:0.1160 loss:35.1237 exploreP:0.5486\n",
      "Episode:216 meanR:36.0000 R:48.0 rate:0.0960 loss:37.8249 exploreP:0.5460\n",
      "Episode:217 meanR:36.1900 R:37.0 rate:0.0740 loss:37.1663 exploreP:0.5440\n",
      "Episode:218 meanR:35.9800 R:20.0 rate:0.0400 loss:35.4777 exploreP:0.5429\n",
      "Episode:219 meanR:36.0200 R:22.0 rate:0.0440 loss:39.0678 exploreP:0.5418\n",
      "Episode:220 meanR:36.5100 R:63.0 rate:0.1260 loss:38.6451 exploreP:0.5384\n",
      "Episode:221 meanR:38.0100 R:173.0 rate:0.3460 loss:37.7887 exploreP:0.5294\n",
      "Episode:222 meanR:39.0400 R:121.0 rate:0.2420 loss:39.6808 exploreP:0.5231\n",
      "Episode:223 meanR:39.5700 R:65.0 rate:0.1300 loss:35.8704 exploreP:0.5198\n",
      "Episode:224 meanR:40.0500 R:64.0 rate:0.1280 loss:44.5055 exploreP:0.5165\n",
      "Episode:225 meanR:40.2800 R:34.0 rate:0.0680 loss:49.0671 exploreP:0.5148\n",
      "Episode:226 meanR:41.1300 R:99.0 rate:0.1980 loss:44.2595 exploreP:0.5098\n",
      "Episode:227 meanR:41.2800 R:34.0 rate:0.0680 loss:36.2017 exploreP:0.5082\n",
      "Episode:228 meanR:41.5600 R:58.0 rate:0.1160 loss:49.4259 exploreP:0.5053\n",
      "Episode:229 meanR:41.6300 R:20.0 rate:0.0400 loss:43.0908 exploreP:0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:230 meanR:42.1200 R:65.0 rate:0.1300 loss:44.1791 exploreP:0.5011\n",
      "Episode:231 meanR:41.8100 R:19.0 rate:0.0380 loss:42.8765 exploreP:0.5001\n",
      "Episode:232 meanR:41.9800 R:35.0 rate:0.0700 loss:46.9530 exploreP:0.4984\n",
      "Episode:233 meanR:42.8300 R:101.0 rate:0.2020 loss:44.2722 exploreP:0.4935\n",
      "Episode:234 meanR:43.5100 R:79.0 rate:0.1580 loss:45.7844 exploreP:0.4897\n",
      "Episode:235 meanR:43.9800 R:76.0 rate:0.1520 loss:46.4517 exploreP:0.4861\n",
      "Episode:236 meanR:44.8400 R:108.0 rate:0.2160 loss:47.8824 exploreP:0.4810\n",
      "Episode:237 meanR:45.3300 R:62.0 rate:0.1240 loss:54.4024 exploreP:0.4781\n",
      "Episode:238 meanR:45.7600 R:67.0 rate:0.1340 loss:53.8842 exploreP:0.4749\n",
      "Episode:239 meanR:46.3900 R:97.0 rate:0.1940 loss:48.9768 exploreP:0.4705\n",
      "Episode:240 meanR:46.3500 R:33.0 rate:0.0660 loss:63.7741 exploreP:0.4689\n",
      "Episode:241 meanR:46.3900 R:22.0 rate:0.0440 loss:46.6550 exploreP:0.4679\n",
      "Episode:242 meanR:46.5500 R:48.0 rate:0.0960 loss:57.1289 exploreP:0.4657\n",
      "Episode:243 meanR:46.6600 R:26.0 rate:0.0520 loss:72.7402 exploreP:0.4645\n",
      "Episode:244 meanR:46.7000 R:76.0 rate:0.1520 loss:54.4148 exploreP:0.4611\n",
      "Episode:245 meanR:47.2100 R:64.0 rate:0.1280 loss:57.3006 exploreP:0.4582\n",
      "Episode:246 meanR:47.6900 R:61.0 rate:0.1220 loss:50.8874 exploreP:0.4555\n",
      "Episode:247 meanR:47.5000 R:68.0 rate:0.1360 loss:65.8412 exploreP:0.4525\n",
      "Episode:248 meanR:48.4100 R:103.0 rate:0.2060 loss:59.5922 exploreP:0.4480\n",
      "Episode:249 meanR:49.0700 R:79.0 rate:0.1580 loss:64.0011 exploreP:0.4445\n",
      "Episode:250 meanR:50.1800 R:121.0 rate:0.2420 loss:55.8111 exploreP:0.4393\n",
      "Episode:251 meanR:50.3700 R:50.0 rate:0.1000 loss:63.3801 exploreP:0.4371\n",
      "Episode:252 meanR:50.0300 R:66.0 rate:0.1320 loss:66.0587 exploreP:0.4343\n",
      "Episode:253 meanR:50.5800 R:69.0 rate:0.1380 loss:69.3805 exploreP:0.4314\n",
      "Episode:254 meanR:51.1900 R:78.0 rate:0.1560 loss:69.9165 exploreP:0.4281\n",
      "Episode:255 meanR:51.6100 R:84.0 rate:0.1680 loss:66.0250 exploreP:0.4246\n",
      "Episode:256 meanR:52.4700 R:112.0 rate:0.2240 loss:63.6022 exploreP:0.4200\n",
      "Episode:257 meanR:52.3900 R:16.0 rate:0.0320 loss:49.0376 exploreP:0.4194\n",
      "Episode:258 meanR:53.4900 R:124.0 rate:0.2480 loss:67.0864 exploreP:0.4143\n",
      "Episode:259 meanR:53.8400 R:60.0 rate:0.1200 loss:69.6145 exploreP:0.4119\n",
      "Episode:260 meanR:54.1000 R:62.0 rate:0.1240 loss:62.4244 exploreP:0.4094\n",
      "Episode:261 meanR:54.7700 R:101.0 rate:0.2020 loss:72.4758 exploreP:0.4054\n",
      "Episode:262 meanR:56.0700 R:140.0 rate:0.2800 loss:73.8866 exploreP:0.3999\n",
      "Episode:263 meanR:56.5400 R:70.0 rate:0.1400 loss:77.9017 exploreP:0.3972\n",
      "Episode:264 meanR:57.3800 R:106.0 rate:0.2120 loss:75.7941 exploreP:0.3931\n",
      "Episode:265 meanR:57.9900 R:123.0 rate:0.2460 loss:81.5844 exploreP:0.3884\n",
      "Episode:266 meanR:59.5900 R:189.0 rate:0.3780 loss:82.5085 exploreP:0.3813\n",
      "Episode:267 meanR:60.0500 R:83.0 rate:0.1660 loss:85.1586 exploreP:0.3783\n",
      "Episode:268 meanR:61.1800 R:148.0 rate:0.2960 loss:88.0003 exploreP:0.3729\n",
      "Episode:269 meanR:61.9700 R:109.0 rate:0.2180 loss:86.4112 exploreP:0.3689\n",
      "Episode:270 meanR:61.3200 R:69.0 rate:0.1380 loss:80.8093 exploreP:0.3665\n",
      "Episode:271 meanR:62.0600 R:88.0 rate:0.1760 loss:85.4744 exploreP:0.3633\n",
      "Episode:272 meanR:62.4900 R:129.0 rate:0.2580 loss:92.7380 exploreP:0.3588\n",
      "Episode:273 meanR:63.2800 R:106.0 rate:0.2120 loss:98.9564 exploreP:0.3551\n",
      "Episode:274 meanR:66.8200 R:373.0 rate:0.7460 loss:94.5681 exploreP:0.3425\n",
      "Episode:275 meanR:67.7600 R:119.0 rate:0.2380 loss:102.8500 exploreP:0.3386\n",
      "Episode:276 meanR:68.6400 R:124.0 rate:0.2480 loss:100.5891 exploreP:0.3345\n",
      "Episode:277 meanR:69.2300 R:111.0 rate:0.2220 loss:110.4098 exploreP:0.3309\n",
      "Episode:278 meanR:70.0000 R:119.0 rate:0.2380 loss:117.7220 exploreP:0.3271\n",
      "Episode:279 meanR:71.1200 R:137.0 rate:0.2740 loss:115.5432 exploreP:0.3228\n",
      "Episode:280 meanR:71.9300 R:105.0 rate:0.2100 loss:102.5779 exploreP:0.3195\n",
      "Episode:281 meanR:72.8700 R:176.0 rate:0.3520 loss:120.2736 exploreP:0.3141\n",
      "Episode:282 meanR:73.4200 R:88.0 rate:0.1760 loss:121.7123 exploreP:0.3115\n",
      "Episode:283 meanR:74.6300 R:141.0 rate:0.2820 loss:130.0816 exploreP:0.3073\n",
      "Episode:284 meanR:74.8000 R:43.0 rate:0.0860 loss:133.8936 exploreP:0.3060\n",
      "Episode:285 meanR:75.7900 R:128.0 rate:0.2560 loss:119.0791 exploreP:0.3022\n",
      "Episode:286 meanR:77.6100 R:251.0 rate:0.5020 loss:131.5139 exploreP:0.2950\n",
      "Episode:287 meanR:78.2000 R:121.0 rate:0.2420 loss:137.4312 exploreP:0.2915\n",
      "Episode:288 meanR:79.1400 R:120.0 rate:0.2400 loss:153.1844 exploreP:0.2882\n",
      "Episode:289 meanR:80.1200 R:152.0 rate:0.3040 loss:134.7628 exploreP:0.2840\n",
      "Episode:290 meanR:80.6800 R:120.0 rate:0.2400 loss:139.9299 exploreP:0.2807\n",
      "Episode:291 meanR:80.7900 R:91.0 rate:0.1820 loss:151.0248 exploreP:0.2783\n",
      "Episode:292 meanR:81.4200 R:132.0 rate:0.2640 loss:151.9988 exploreP:0.2748\n",
      "Episode:293 meanR:83.1800 R:214.0 rate:0.4280 loss:160.6327 exploreP:0.2691\n",
      "Episode:294 meanR:84.0400 R:121.0 rate:0.2420 loss:168.4383 exploreP:0.2660\n",
      "Episode:295 meanR:84.7700 R:130.0 rate:0.2600 loss:163.0331 exploreP:0.2627\n",
      "Episode:296 meanR:85.8400 R:157.0 rate:0.3140 loss:168.4521 exploreP:0.2588\n",
      "Episode:297 meanR:86.7600 R:136.0 rate:0.2720 loss:185.3748 exploreP:0.2554\n",
      "Episode:298 meanR:87.6900 R:122.0 rate:0.2440 loss:187.7278 exploreP:0.2525\n",
      "Episode:299 meanR:89.3200 R:175.0 rate:0.3500 loss:175.8558 exploreP:0.2482\n",
      "Episode:300 meanR:90.5700 R:151.0 rate:0.3020 loss:198.0422 exploreP:0.2447\n",
      "Episode:301 meanR:91.4000 R:105.0 rate:0.2100 loss:216.8342 exploreP:0.2422\n",
      "Episode:302 meanR:93.2900 R:272.0 rate:0.5440 loss:196.6378 exploreP:0.2360\n",
      "Episode:303 meanR:94.2000 R:135.0 rate:0.2700 loss:217.8510 exploreP:0.2330\n",
      "Episode:304 meanR:95.0800 R:121.0 rate:0.2420 loss:193.9709 exploreP:0.2303\n",
      "Episode:305 meanR:95.8600 R:113.0 rate:0.2260 loss:212.8038 exploreP:0.2278\n",
      "Episode:306 meanR:96.3100 R:118.0 rate:0.2360 loss:220.2462 exploreP:0.2253\n",
      "Episode:307 meanR:98.0100 R:202.0 rate:0.4040 loss:239.1638 exploreP:0.2209\n",
      "Episode:308 meanR:100.5900 R:334.0 rate:0.6680 loss:237.4612 exploreP:0.2140\n",
      "Episode:309 meanR:101.3300 R:136.0 rate:0.2720 loss:267.9153 exploreP:0.2113\n",
      "Episode:310 meanR:102.4000 R:160.0 rate:0.3200 loss:280.6196 exploreP:0.2081\n",
      "Episode:311 meanR:103.3800 R:145.0 rate:0.2900 loss:263.0841 exploreP:0.2052\n",
      "Episode:312 meanR:103.9700 R:121.0 rate:0.2420 loss:296.3984 exploreP:0.2029\n",
      "Episode:313 meanR:105.5600 R:174.0 rate:0.3480 loss:304.5581 exploreP:0.1995\n",
      "Episode:314 meanR:106.4400 R:143.0 rate:0.2860 loss:290.7922 exploreP:0.1968\n",
      "Episode:315 meanR:107.7000 R:184.0 rate:0.3680 loss:334.2560 exploreP:0.1934\n",
      "Episode:316 meanR:108.4500 R:123.0 rate:0.2460 loss:299.7243 exploreP:0.1912\n",
      "Episode:317 meanR:110.5700 R:249.0 rate:0.4980 loss:333.7031 exploreP:0.1867\n",
      "Episode:318 meanR:112.2800 R:191.0 rate:0.3820 loss:360.3205 exploreP:0.1834\n",
      "Episode:319 meanR:113.8800 R:182.0 rate:0.3640 loss:369.8078 exploreP:0.1803\n",
      "Episode:320 meanR:115.1700 R:192.0 rate:0.3840 loss:364.2266 exploreP:0.1770\n",
      "Episode:321 meanR:115.2100 R:177.0 rate:0.3540 loss:375.6282 exploreP:0.1741\n",
      "Episode:322 meanR:115.4500 R:145.0 rate:0.2900 loss:380.0363 exploreP:0.1717\n",
      "Episode:323 meanR:117.7600 R:296.0 rate:0.5920 loss:391.4442 exploreP:0.1670\n",
      "Episode:324 meanR:118.5000 R:138.0 rate:0.2760 loss:426.2207 exploreP:0.1649\n",
      "Episode:325 meanR:119.5400 R:138.0 rate:0.2760 loss:447.4995 exploreP:0.1628\n",
      "Episode:326 meanR:120.3600 R:181.0 rate:0.3620 loss:464.9487 exploreP:0.1600\n",
      "Episode:327 meanR:121.6800 R:166.0 rate:0.3320 loss:446.3307 exploreP:0.1575\n",
      "Episode:328 meanR:122.6700 R:157.0 rate:0.3140 loss:513.8342 exploreP:0.1552\n",
      "Episode:329 meanR:125.1600 R:269.0 rate:0.5380 loss:523.1420 exploreP:0.1514\n",
      "Episode:330 meanR:126.0800 R:157.0 rate:0.3140 loss:501.9729 exploreP:0.1492\n",
      "Episode:331 meanR:128.5900 R:270.0 rate:0.5400 loss:512.8967 exploreP:0.1455\n",
      "Episode:332 meanR:130.8900 R:265.0 rate:0.5300 loss:563.1585 exploreP:0.1419\n",
      "Episode:333 meanR:131.4500 R:157.0 rate:0.3140 loss:589.1737 exploreP:0.1399\n",
      "Episode:334 meanR:132.6200 R:196.0 rate:0.3920 loss:587.1977 exploreP:0.1374\n",
      "Episode:335 meanR:134.5400 R:268.0 rate:0.5360 loss:614.2894 exploreP:0.1340\n",
      "Episode:336 meanR:136.1100 R:265.0 rate:0.5300 loss:601.8595 exploreP:0.1307\n",
      "Episode:337 meanR:137.2200 R:173.0 rate:0.3460 loss:619.6174 exploreP:0.1287\n",
      "Episode:338 meanR:140.8700 R:432.0 rate:0.8640 loss:696.4343 exploreP:0.1237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:339 meanR:142.0200 R:212.0 rate:0.4240 loss:747.5423 exploreP:0.1213\n",
      "Episode:340 meanR:143.1500 R:146.0 rate:0.2920 loss:730.9006 exploreP:0.1197\n",
      "Episode:341 meanR:145.0100 R:208.0 rate:0.4160 loss:869.4290 exploreP:0.1174\n",
      "Episode:342 meanR:146.8800 R:235.0 rate:0.4700 loss:865.1468 exploreP:0.1149\n",
      "Episode:343 meanR:149.5600 R:294.0 rate:0.5880 loss:860.9126 exploreP:0.1119\n",
      "Episode:344 meanR:150.6800 R:188.0 rate:0.3760 loss:942.5366 exploreP:0.1100\n",
      "Episode:345 meanR:152.2000 R:216.0 rate:0.4320 loss:990.5001 exploreP:0.1078\n",
      "Episode:346 meanR:155.0800 R:349.0 rate:0.6980 loss:920.1990 exploreP:0.1045\n",
      "Episode:347 meanR:156.6200 R:222.0 rate:0.4440 loss:995.1941 exploreP:0.1024\n",
      "Episode:348 meanR:157.3200 R:173.0 rate:0.3460 loss:1145.0999 exploreP:0.1008\n",
      "Episode:349 meanR:159.1500 R:262.0 rate:0.5240 loss:1111.7498 exploreP:0.0985\n",
      "Episode:350 meanR:161.7200 R:378.0 rate:0.7560 loss:1158.4052 exploreP:0.0952\n",
      "Episode:351 meanR:164.5000 R:328.0 rate:0.6560 loss:1362.4403 exploreP:0.0924\n",
      "Episode:352 meanR:165.8600 R:202.0 rate:0.4040 loss:1345.6246 exploreP:0.0908\n",
      "Episode:353 meanR:168.1300 R:296.0 rate:0.5920 loss:1327.1907 exploreP:0.0884\n",
      "Episode:354 meanR:169.6100 R:226.0 rate:0.4520 loss:1554.2906 exploreP:0.0867\n",
      "Episode:355 meanR:172.7700 R:400.0 rate:0.8000 loss:1564.6678 exploreP:0.0837\n",
      "Episode:356 meanR:176.2800 R:463.0 rate:0.9260 loss:1621.4282 exploreP:0.0803\n",
      "Episode:357 meanR:178.5600 R:244.0 rate:0.4880 loss:1654.0229 exploreP:0.0786\n",
      "Episode:358 meanR:180.4000 R:308.0 rate:0.6160 loss:1903.2490 exploreP:0.0766\n",
      "Episode:359 meanR:183.8300 R:403.0 rate:0.8060 loss:1999.3887 exploreP:0.0739\n",
      "Episode:360 meanR:186.9000 R:369.0 rate:0.7380 loss:2072.2065 exploreP:0.0716\n",
      "Episode:361 meanR:190.3700 R:448.0 rate:0.8960 loss:2261.6543 exploreP:0.0689\n",
      "Episode:362 meanR:191.0400 R:207.0 rate:0.4140 loss:2419.4146 exploreP:0.0677\n",
      "Episode:363 meanR:192.8000 R:246.0 rate:0.4920 loss:2400.3994 exploreP:0.0663\n",
      "Episode:364 meanR:193.7900 R:205.0 rate:0.4100 loss:2652.5874 exploreP:0.0652\n",
      "Episode:365 meanR:194.9900 R:243.0 rate:0.4860 loss:3018.4712 exploreP:0.0638\n",
      "Episode:366 meanR:197.8800 R:478.0 rate:0.9560 loss:2842.4216 exploreP:0.0613\n",
      "Episode:367 meanR:199.4300 R:238.0 rate:0.4760 loss:3165.6340 exploreP:0.0601\n",
      "Episode:368 meanR:200.0300 R:208.0 rate:0.4160 loss:3633.5339 exploreP:0.0591\n",
      "Episode:369 meanR:201.5400 R:260.0 rate:0.5200 loss:3552.8860 exploreP:0.0578\n",
      "Episode:370 meanR:202.8600 R:201.0 rate:0.4020 loss:3737.2124 exploreP:0.0569\n",
      "Episode:371 meanR:204.0000 R:202.0 rate:0.4040 loss:3956.3726 exploreP:0.0559\n",
      "Episode:372 meanR:205.3700 R:266.0 rate:0.5320 loss:3900.8398 exploreP:0.0547\n",
      "Episode:373 meanR:207.5500 R:324.0 rate:0.6480 loss:4152.8813 exploreP:0.0533\n",
      "Episode:374 meanR:205.9200 R:210.0 rate:0.4200 loss:4505.3472 exploreP:0.0524\n",
      "Episode:375 meanR:207.2200 R:249.0 rate:0.4980 loss:4396.1255 exploreP:0.0514\n",
      "Episode:376 meanR:210.9800 R:500.0 rate:1.0000 loss:5106.6328 exploreP:0.0494\n",
      "Episode:377 meanR:212.0600 R:219.0 rate:0.4380 loss:4847.3252 exploreP:0.0485\n",
      "Episode:378 meanR:214.9700 R:410.0 rate:0.8200 loss:5419.6245 exploreP:0.0470\n",
      "Episode:379 meanR:216.8600 R:326.0 rate:0.6520 loss:5347.8667 exploreP:0.0458\n",
      "Episode:380 meanR:219.3300 R:352.0 rate:0.7040 loss:6060.8218 exploreP:0.0445\n",
      "Episode:381 meanR:221.2200 R:365.0 rate:0.7300 loss:6068.9927 exploreP:0.0433\n",
      "Episode:382 meanR:222.7100 R:237.0 rate:0.4740 loss:5991.4663 exploreP:0.0425\n",
      "Episode:383 meanR:223.5200 R:222.0 rate:0.4440 loss:7055.2896 exploreP:0.0418\n",
      "Episode:384 meanR:227.7900 R:470.0 rate:0.9400 loss:7267.5322 exploreP:0.0403\n",
      "Episode:385 meanR:229.4600 R:295.0 rate:0.5900 loss:6792.9551 exploreP:0.0395\n",
      "Episode:386 meanR:231.9400 R:499.0 rate:0.9980 loss:7704.5483 exploreP:0.0380\n",
      "Episode:387 meanR:233.6500 R:292.0 rate:0.5840 loss:7327.5513 exploreP:0.0372\n",
      "Episode:388 meanR:235.0100 R:256.0 rate:0.5120 loss:7909.8203 exploreP:0.0365\n",
      "Episode:389 meanR:235.8800 R:239.0 rate:0.4780 loss:8272.8340 exploreP:0.0359\n",
      "Episode:390 meanR:236.7200 R:204.0 rate:0.4080 loss:8538.8135 exploreP:0.0354\n",
      "Episode:391 meanR:238.4200 R:261.0 rate:0.5220 loss:9232.9316 exploreP:0.0347\n",
      "Episode:392 meanR:239.4200 R:232.0 rate:0.4640 loss:9153.9375 exploreP:0.0342\n",
      "Episode:393 meanR:240.4800 R:320.0 rate:0.6400 loss:9497.3848 exploreP:0.0334\n",
      "Episode:394 meanR:241.9100 R:264.0 rate:0.5280 loss:9275.0723 exploreP:0.0328\n",
      "Episode:395 meanR:243.1000 R:249.0 rate:0.4980 loss:9481.0039 exploreP:0.0322\n",
      "Episode:396 meanR:246.1700 R:464.0 rate:0.9280 loss:10502.9355 exploreP:0.0312\n",
      "Episode:397 meanR:249.0900 R:428.0 rate:0.8560 loss:10618.1240 exploreP:0.0303\n",
      "Episode:398 meanR:250.5300 R:266.0 rate:0.5320 loss:10184.5703 exploreP:0.0298\n",
      "Episode:399 meanR:253.7800 R:500.0 rate:1.0000 loss:10938.5781 exploreP:0.0288\n",
      "Episode:400 meanR:257.0600 R:479.0 rate:0.9580 loss:11965.0547 exploreP:0.0280\n",
      "Episode:401 meanR:259.5700 R:356.0 rate:0.7120 loss:12635.7666 exploreP:0.0273\n",
      "Episode:402 meanR:259.7100 R:286.0 rate:0.5720 loss:12219.4541 exploreP:0.0268\n",
      "Episode:403 meanR:261.2000 R:284.0 rate:0.5680 loss:12608.4424 exploreP:0.0264\n",
      "Episode:404 meanR:262.6100 R:262.0 rate:0.5240 loss:13047.8242 exploreP:0.0259\n",
      "Episode:405 meanR:264.6200 R:314.0 rate:0.6280 loss:14193.6875 exploreP:0.0254\n",
      "Episode:406 meanR:267.1200 R:368.0 rate:0.7360 loss:13907.0977 exploreP:0.0249\n",
      "Episode:407 meanR:267.7700 R:267.0 rate:0.5340 loss:15855.8838 exploreP:0.0245\n",
      "Episode:408 meanR:269.1200 R:469.0 rate:0.9380 loss:14524.7422 exploreP:0.0238\n",
      "Episode:409 meanR:270.9200 R:316.0 rate:0.6320 loss:15691.4189 exploreP:0.0234\n",
      "Episode:410 meanR:272.3200 R:300.0 rate:0.6000 loss:14638.1816 exploreP:0.0230\n",
      "Episode:411 meanR:275.8700 R:500.0 rate:1.0000 loss:15696.5557 exploreP:0.0224\n",
      "Episode:412 meanR:278.8100 R:415.0 rate:0.8300 loss:15443.8555 exploreP:0.0219\n",
      "Episode:413 meanR:280.1600 R:309.0 rate:0.6180 loss:17111.2227 exploreP:0.0215\n",
      "Episode:414 meanR:282.5800 R:385.0 rate:0.7700 loss:15792.1875 exploreP:0.0211\n",
      "Episode:415 meanR:283.0600 R:232.0 rate:0.4640 loss:16456.5762 exploreP:0.0208\n",
      "Episode:416 meanR:283.9900 R:216.0 rate:0.4320 loss:18234.5898 exploreP:0.0206\n",
      "Episode:417 meanR:284.1100 R:261.0 rate:0.5220 loss:17796.0547 exploreP:0.0203\n",
      "Episode:418 meanR:287.2000 R:500.0 rate:1.0000 loss:17171.4980 exploreP:0.0198\n",
      "Episode:419 meanR:289.1000 R:372.0 rate:0.7440 loss:17333.2578 exploreP:0.0195\n",
      "Episode:420 meanR:290.3100 R:313.0 rate:0.6260 loss:18124.0488 exploreP:0.0192\n",
      "Episode:421 meanR:291.9700 R:343.0 rate:0.6860 loss:18330.1230 exploreP:0.0189\n",
      "Episode:422 meanR:293.8300 R:331.0 rate:0.6620 loss:19845.8770 exploreP:0.0186\n",
      "Episode:423 meanR:293.0400 R:217.0 rate:0.4340 loss:18459.4629 exploreP:0.0184\n",
      "Episode:424 meanR:296.6600 R:500.0 rate:1.0000 loss:17456.1191 exploreP:0.0180\n",
      "Episode:425 meanR:297.5100 R:223.0 rate:0.4460 loss:18982.1602 exploreP:0.0178\n",
      "Episode:426 meanR:299.4100 R:371.0 rate:0.7420 loss:18668.2422 exploreP:0.0175\n",
      "Episode:427 meanR:300.5800 R:283.0 rate:0.5660 loss:19073.1660 exploreP:0.0173\n",
      "Episode:428 meanR:301.8000 R:279.0 rate:0.5580 loss:18808.3145 exploreP:0.0171\n",
      "Episode:429 meanR:301.3500 R:224.0 rate:0.4480 loss:19261.0488 exploreP:0.0169\n",
      "Episode:430 meanR:302.5000 R:272.0 rate:0.5440 loss:18656.5000 exploreP:0.0168\n",
      "Episode:431 meanR:302.4900 R:269.0 rate:0.5380 loss:18839.7676 exploreP:0.0166\n",
      "Episode:432 meanR:302.2400 R:240.0 rate:0.4800 loss:19260.0918 exploreP:0.0164\n",
      "Episode:433 meanR:303.5000 R:283.0 rate:0.5660 loss:19648.2930 exploreP:0.0162\n",
      "Episode:434 meanR:305.2600 R:372.0 rate:0.7440 loss:18634.5879 exploreP:0.0160\n",
      "Episode:435 meanR:304.9400 R:236.0 rate:0.4720 loss:20071.6543 exploreP:0.0159\n",
      "Episode:436 meanR:304.5200 R:223.0 rate:0.4460 loss:20724.6152 exploreP:0.0157\n",
      "Episode:437 meanR:307.3400 R:455.0 rate:0.9100 loss:19628.9023 exploreP:0.0155\n",
      "Episode:438 meanR:307.3200 R:430.0 rate:0.8600 loss:19057.4355 exploreP:0.0153\n",
      "Episode:439 meanR:309.6200 R:442.0 rate:0.8840 loss:20599.4473 exploreP:0.0150\n",
      "Episode:440 meanR:310.3100 R:215.0 rate:0.4300 loss:19608.7461 exploreP:0.0149\n",
      "Episode:441 meanR:311.3700 R:314.0 rate:0.6280 loss:19916.4590 exploreP:0.0148\n",
      "Episode:442 meanR:312.1500 R:313.0 rate:0.6260 loss:18631.4180 exploreP:0.0146\n",
      "Episode:443 meanR:314.2100 R:500.0 rate:1.0000 loss:19685.8809 exploreP:0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:444 meanR:315.7100 R:338.0 rate:0.6760 loss:17895.2969 exploreP:0.0143\n",
      "Episode:445 meanR:316.2300 R:268.0 rate:0.5360 loss:19739.8730 exploreP:0.0141\n",
      "Episode:446 meanR:316.1100 R:337.0 rate:0.6740 loss:19222.6133 exploreP:0.0140\n",
      "Episode:447 meanR:317.2000 R:331.0 rate:0.6620 loss:18835.5742 exploreP:0.0139\n",
      "Episode:448 meanR:320.2300 R:476.0 rate:0.9520 loss:18272.7266 exploreP:0.0137\n",
      "Episode:449 meanR:321.0700 R:346.0 rate:0.6920 loss:19757.1562 exploreP:0.0136\n",
      "Episode:450 meanR:320.2900 R:300.0 rate:0.6000 loss:17963.0000 exploreP:0.0135\n",
      "Episode:451 meanR:320.3900 R:338.0 rate:0.6760 loss:18500.0020 exploreP:0.0133\n",
      "Episode:452 meanR:320.8400 R:247.0 rate:0.4940 loss:20101.9805 exploreP:0.0133\n",
      "Episode:453 meanR:320.3400 R:246.0 rate:0.4920 loss:18016.3691 exploreP:0.0132\n",
      "Episode:454 meanR:320.6900 R:261.0 rate:0.5220 loss:17823.4023 exploreP:0.0131\n",
      "Episode:455 meanR:319.0800 R:239.0 rate:0.4780 loss:17118.2070 exploreP:0.0130\n",
      "Episode:456 meanR:319.4500 R:500.0 rate:1.0000 loss:19222.3047 exploreP:0.0129\n",
      "Episode:457 meanR:319.2700 R:226.0 rate:0.4520 loss:17501.5527 exploreP:0.0128\n",
      "Episode:458 meanR:319.0900 R:290.0 rate:0.5800 loss:19077.4590 exploreP:0.0127\n",
      "Episode:459 meanR:320.0600 R:500.0 rate:1.0000 loss:17088.2871 exploreP:0.0126\n",
      "Episode:460 meanR:318.2600 R:189.0 rate:0.3780 loss:18386.4453 exploreP:0.0126\n",
      "Episode:461 meanR:316.0100 R:223.0 rate:0.4460 loss:18153.6074 exploreP:0.0125\n",
      "Episode:462 meanR:316.0800 R:214.0 rate:0.4280 loss:17744.0723 exploreP:0.0124\n",
      "Episode:463 meanR:316.7300 R:311.0 rate:0.6220 loss:18632.6445 exploreP:0.0124\n",
      "Episode:464 meanR:317.1400 R:246.0 rate:0.4920 loss:18420.6172 exploreP:0.0123\n",
      "Episode:465 meanR:317.9000 R:319.0 rate:0.6380 loss:18035.7344 exploreP:0.0122\n",
      "Episode:466 meanR:315.4100 R:229.0 rate:0.4580 loss:19485.3457 exploreP:0.0122\n",
      "Episode:467 meanR:314.9500 R:192.0 rate:0.3840 loss:21074.6348 exploreP:0.0121\n",
      "Episode:468 meanR:315.6500 R:278.0 rate:0.5560 loss:19920.2129 exploreP:0.0121\n",
      "Episode:469 meanR:317.1800 R:413.0 rate:0.8260 loss:21390.8516 exploreP:0.0120\n",
      "Episode:470 meanR:317.4900 R:232.0 rate:0.4640 loss:20321.7910 exploreP:0.0120\n",
      "Episode:471 meanR:318.7100 R:324.0 rate:0.6480 loss:22911.8047 exploreP:0.0119\n",
      "Episode:472 meanR:318.8200 R:277.0 rate:0.5540 loss:22423.5391 exploreP:0.0118\n",
      "Episode:473 meanR:318.1500 R:257.0 rate:0.5140 loss:25180.8066 exploreP:0.0118\n",
      "Episode:474 meanR:317.8800 R:183.0 rate:0.3660 loss:24096.0020 exploreP:0.0118\n",
      "Episode:475 meanR:318.3400 R:295.0 rate:0.5900 loss:25112.8613 exploreP:0.0117\n",
      "Episode:476 meanR:315.2800 R:194.0 rate:0.3880 loss:23003.5098 exploreP:0.0117\n",
      "Episode:477 meanR:315.5100 R:242.0 rate:0.4840 loss:27332.0312 exploreP:0.0116\n",
      "Episode:478 meanR:313.4500 R:204.0 rate:0.4080 loss:25958.1367 exploreP:0.0116\n",
      "Episode:479 meanR:312.2800 R:209.0 rate:0.4180 loss:26307.5312 exploreP:0.0116\n",
      "Episode:480 meanR:311.3500 R:259.0 rate:0.5180 loss:28915.9160 exploreP:0.0115\n",
      "Episode:481 meanR:312.7000 R:500.0 rate:1.0000 loss:27233.2324 exploreP:0.0115\n",
      "Episode:482 meanR:312.3700 R:204.0 rate:0.4080 loss:30132.3730 exploreP:0.0114\n",
      "Episode:483 meanR:313.0500 R:290.0 rate:0.5800 loss:25149.4707 exploreP:0.0114\n",
      "Episode:484 meanR:311.2900 R:294.0 rate:0.5880 loss:26535.5312 exploreP:0.0113\n",
      "Episode:485 meanR:312.0100 R:367.0 rate:0.7340 loss:24484.1914 exploreP:0.0113\n",
      "Episode:486 meanR:309.3300 R:231.0 rate:0.4620 loss:25088.1289 exploreP:0.0113\n",
      "Episode:487 meanR:310.3000 R:389.0 rate:0.7780 loss:23931.5938 exploreP:0.0112\n",
      "Episode:488 meanR:310.2200 R:248.0 rate:0.4960 loss:24803.2461 exploreP:0.0112\n",
      "Episode:489 meanR:311.7100 R:388.0 rate:0.7760 loss:25988.6074 exploreP:0.0111\n",
      "Episode:490 meanR:312.0900 R:242.0 rate:0.4840 loss:25169.7363 exploreP:0.0111\n",
      "Episode:491 meanR:311.4700 R:199.0 rate:0.3980 loss:25281.6387 exploreP:0.0111\n",
      "Episode:492 meanR:312.9900 R:384.0 rate:0.7680 loss:25392.5137 exploreP:0.0111\n",
      "Episode:493 meanR:311.8300 R:204.0 rate:0.4080 loss:26658.4844 exploreP:0.0110\n",
      "Episode:494 meanR:311.0700 R:188.0 rate:0.3760 loss:25340.0977 exploreP:0.0110\n",
      "Episode:495 meanR:310.8400 R:226.0 rate:0.4520 loss:28491.7344 exploreP:0.0110\n",
      "Episode:496 meanR:311.2000 R:500.0 rate:1.0000 loss:28917.6816 exploreP:0.0109\n",
      "Episode:497 meanR:308.7900 R:187.0 rate:0.3740 loss:30396.8789 exploreP:0.0109\n",
      "Episode:498 meanR:308.8500 R:272.0 rate:0.5440 loss:32208.2656 exploreP:0.0109\n",
      "Episode:499 meanR:307.9400 R:409.0 rate:0.8180 loss:31359.1445 exploreP:0.0109\n",
      "Episode:500 meanR:306.5800 R:343.0 rate:0.6860 loss:35309.5391 exploreP:0.0108\n",
      "Episode:501 meanR:305.5600 R:254.0 rate:0.5080 loss:37266.1641 exploreP:0.0108\n",
      "Episode:502 meanR:307.5400 R:484.0 rate:0.9680 loss:42540.7852 exploreP:0.0108\n",
      "Episode:503 meanR:306.6500 R:195.0 rate:0.3900 loss:42973.5898 exploreP:0.0108\n",
      "Episode:504 meanR:307.2000 R:317.0 rate:0.6340 loss:49700.9102 exploreP:0.0107\n",
      "Episode:505 meanR:306.6800 R:262.0 rate:0.5240 loss:51697.1602 exploreP:0.0107\n",
      "Episode:506 meanR:304.8400 R:184.0 rate:0.3680 loss:54704.4492 exploreP:0.0107\n",
      "Episode:507 meanR:304.8000 R:263.0 rate:0.5260 loss:63743.8516 exploreP:0.0107\n",
      "Episode:508 meanR:301.9800 R:187.0 rate:0.3740 loss:63675.5938 exploreP:0.0107\n",
      "Episode:509 meanR:300.8000 R:198.0 rate:0.3960 loss:66910.5234 exploreP:0.0107\n",
      "Episode:510 meanR:299.6300 R:183.0 rate:0.3660 loss:67126.5547 exploreP:0.0106\n",
      "Episode:511 meanR:297.1600 R:253.0 rate:0.5060 loss:66706.1484 exploreP:0.0106\n",
      "Episode:512 meanR:295.4300 R:242.0 rate:0.4840 loss:71532.1797 exploreP:0.0106\n",
      "Episode:513 meanR:295.2000 R:286.0 rate:0.5720 loss:75138.8750 exploreP:0.0106\n",
      "Episode:514 meanR:293.2600 R:191.0 rate:0.3820 loss:78594.6875 exploreP:0.0106\n",
      "Episode:515 meanR:293.3500 R:241.0 rate:0.4820 loss:75944.0000 exploreP:0.0106\n",
      "Episode:516 meanR:293.2000 R:201.0 rate:0.4020 loss:74768.5938 exploreP:0.0106\n",
      "Episode:517 meanR:292.5800 R:199.0 rate:0.3980 loss:82075.3359 exploreP:0.0106\n",
      "Episode:518 meanR:289.4000 R:182.0 rate:0.3640 loss:86233.2188 exploreP:0.0105\n",
      "Episode:519 meanR:287.5800 R:190.0 rate:0.3800 loss:79748.3828 exploreP:0.0105\n",
      "Episode:520 meanR:287.4900 R:304.0 rate:0.6080 loss:83963.5234 exploreP:0.0105\n",
      "Episode:521 meanR:285.9100 R:185.0 rate:0.3700 loss:87436.5547 exploreP:0.0105\n",
      "Episode:522 meanR:285.0300 R:243.0 rate:0.4860 loss:88590.7812 exploreP:0.0105\n",
      "Episode:523 meanR:286.7700 R:391.0 rate:0.7820 loss:98384.2578 exploreP:0.0105\n",
      "Episode:524 meanR:283.8800 R:211.0 rate:0.4220 loss:87851.0312 exploreP:0.0105\n",
      "Episode:525 meanR:283.6900 R:204.0 rate:0.4080 loss:96451.9688 exploreP:0.0105\n",
      "Episode:526 meanR:282.2400 R:226.0 rate:0.4520 loss:94483.3047 exploreP:0.0104\n",
      "Episode:527 meanR:282.6800 R:327.0 rate:0.6540 loss:100480.7578 exploreP:0.0104\n",
      "Episode:528 meanR:282.2200 R:233.0 rate:0.4660 loss:100548.1562 exploreP:0.0104\n",
      "Episode:529 meanR:282.8600 R:288.0 rate:0.5760 loss:108217.3047 exploreP:0.0104\n",
      "Episode:530 meanR:282.8800 R:274.0 rate:0.5480 loss:105656.7188 exploreP:0.0104\n",
      "Episode:531 meanR:282.6300 R:244.0 rate:0.4880 loss:106539.1016 exploreP:0.0104\n",
      "Episode:532 meanR:281.8500 R:162.0 rate:0.3240 loss:109451.2578 exploreP:0.0104\n",
      "Episode:533 meanR:281.1400 R:212.0 rate:0.4240 loss:108344.6328 exploreP:0.0104\n",
      "Episode:534 meanR:280.6200 R:320.0 rate:0.6400 loss:123364.2500 exploreP:0.0104\n",
      "Episode:535 meanR:281.9100 R:365.0 rate:0.7300 loss:122669.6406 exploreP:0.0104\n",
      "Episode:536 meanR:281.9900 R:231.0 rate:0.4620 loss:121259.4141 exploreP:0.0103\n",
      "Episode:537 meanR:279.2900 R:185.0 rate:0.3700 loss:131521.8281 exploreP:0.0103\n",
      "Episode:538 meanR:277.2300 R:224.0 rate:0.4480 loss:131524.2031 exploreP:0.0103\n",
      "Episode:539 meanR:275.3000 R:249.0 rate:0.4980 loss:140032.5781 exploreP:0.0103\n",
      "Episode:540 meanR:275.9300 R:278.0 rate:0.5560 loss:151852.2812 exploreP:0.0103\n",
      "Episode:541 meanR:275.0900 R:230.0 rate:0.4600 loss:148842.0469 exploreP:0.0103\n",
      "Episode:542 meanR:273.7200 R:176.0 rate:0.3520 loss:144064.8438 exploreP:0.0103\n",
      "Episode:543 meanR:270.5700 R:185.0 rate:0.3700 loss:167169.1094 exploreP:0.0103\n",
      "Episode:544 meanR:269.0300 R:184.0 rate:0.3680 loss:161909.3125 exploreP:0.0103\n",
      "Episode:545 meanR:268.8700 R:252.0 rate:0.5040 loss:166253.6719 exploreP:0.0103\n",
      "Episode:546 meanR:267.9800 R:248.0 rate:0.4960 loss:171113.7812 exploreP:0.0103\n",
      "Episode:547 meanR:266.1800 R:151.0 rate:0.3020 loss:166741.1094 exploreP:0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:548 meanR:263.2100 R:179.0 rate:0.3580 loss:186634.6875 exploreP:0.0103\n",
      "Episode:549 meanR:261.6400 R:189.0 rate:0.3780 loss:185840.7969 exploreP:0.0103\n",
      "Episode:550 meanR:261.6700 R:303.0 rate:0.6060 loss:189457.1406 exploreP:0.0103\n",
      "Episode:551 meanR:260.3500 R:206.0 rate:0.4120 loss:193226.3906 exploreP:0.0102\n",
      "Episode:552 meanR:260.6600 R:278.0 rate:0.5560 loss:197211.5000 exploreP:0.0102\n",
      "Episode:553 meanR:260.0100 R:181.0 rate:0.3620 loss:204399.2500 exploreP:0.0102\n",
      "Episode:554 meanR:259.0700 R:167.0 rate:0.3340 loss:195664.1406 exploreP:0.0102\n",
      "Episode:555 meanR:258.3500 R:167.0 rate:0.3340 loss:225089.2031 exploreP:0.0102\n",
      "Episode:556 meanR:255.4400 R:209.0 rate:0.4180 loss:220413.6406 exploreP:0.0102\n",
      "Episode:557 meanR:255.0200 R:184.0 rate:0.3680 loss:221385.5625 exploreP:0.0102\n",
      "Episode:558 meanR:254.1500 R:203.0 rate:0.4060 loss:228963.1094 exploreP:0.0102\n",
      "Episode:559 meanR:251.5800 R:243.0 rate:0.4860 loss:227280.6562 exploreP:0.0102\n",
      "Episode:560 meanR:251.1400 R:145.0 rate:0.2900 loss:244414.4062 exploreP:0.0102\n",
      "Episode:561 meanR:251.3300 R:242.0 rate:0.4840 loss:240978.6406 exploreP:0.0102\n",
      "Episode:562 meanR:251.2200 R:203.0 rate:0.4060 loss:250495.6250 exploreP:0.0102\n",
      "Episode:563 meanR:250.4100 R:230.0 rate:0.4600 loss:256394.5781 exploreP:0.0102\n",
      "Episode:564 meanR:250.6400 R:269.0 rate:0.5380 loss:263831.0625 exploreP:0.0102\n",
      "Episode:565 meanR:249.6700 R:222.0 rate:0.4440 loss:284175.3438 exploreP:0.0102\n",
      "Episode:566 meanR:250.4000 R:302.0 rate:0.6040 loss:284590.5312 exploreP:0.0102\n",
      "Episode:567 meanR:250.4600 R:198.0 rate:0.3960 loss:281981.2500 exploreP:0.0102\n",
      "Episode:568 meanR:249.5200 R:184.0 rate:0.3680 loss:280245.8125 exploreP:0.0102\n",
      "Episode:569 meanR:247.2000 R:181.0 rate:0.3620 loss:292858.7812 exploreP:0.0102\n",
      "Episode:570 meanR:246.5200 R:164.0 rate:0.3280 loss:290006.7500 exploreP:0.0102\n",
      "Episode:571 meanR:245.4600 R:218.0 rate:0.4360 loss:301560.9688 exploreP:0.0102\n",
      "Episode:572 meanR:244.8700 R:218.0 rate:0.4360 loss:323392.2500 exploreP:0.0102\n",
      "Episode:573 meanR:244.4400 R:214.0 rate:0.4280 loss:341688.7500 exploreP:0.0102\n",
      "Episode:574 meanR:245.6000 R:299.0 rate:0.5980 loss:361507.0938 exploreP:0.0102\n",
      "Episode:575 meanR:244.8800 R:223.0 rate:0.4460 loss:389624.3125 exploreP:0.0101\n",
      "Episode:576 meanR:244.9700 R:203.0 rate:0.4060 loss:416898.4375 exploreP:0.0101\n",
      "Episode:577 meanR:245.2800 R:273.0 rate:0.5460 loss:438092.7188 exploreP:0.0101\n",
      "Episode:578 meanR:245.2000 R:196.0 rate:0.3920 loss:453125.7500 exploreP:0.0101\n",
      "Episode:579 meanR:245.2800 R:217.0 rate:0.4340 loss:485260.5000 exploreP:0.0101\n",
      "Episode:580 meanR:244.2900 R:160.0 rate:0.3200 loss:534360.6875 exploreP:0.0101\n",
      "Episode:581 meanR:241.4800 R:219.0 rate:0.4380 loss:548295.3750 exploreP:0.0101\n",
      "Episode:582 meanR:242.0000 R:256.0 rate:0.5120 loss:561370.3125 exploreP:0.0101\n",
      "Episode:583 meanR:240.7200 R:162.0 rate:0.3240 loss:610498.0000 exploreP:0.0101\n",
      "Episode:584 meanR:239.9500 R:217.0 rate:0.4340 loss:632850.1875 exploreP:0.0101\n",
      "Episode:585 meanR:238.2700 R:199.0 rate:0.3980 loss:683018.0000 exploreP:0.0101\n",
      "Episode:586 meanR:237.8100 R:185.0 rate:0.3700 loss:714745.9375 exploreP:0.0101\n",
      "Episode:587 meanR:235.9900 R:207.0 rate:0.4140 loss:737663.2500 exploreP:0.0101\n",
      "Episode:588 meanR:235.5700 R:206.0 rate:0.4120 loss:768921.6875 exploreP:0.0101\n",
      "Episode:589 meanR:233.9400 R:225.0 rate:0.4500 loss:856107.0625 exploreP:0.0101\n",
      "Episode:590 meanR:233.4600 R:194.0 rate:0.3880 loss:910929.5000 exploreP:0.0101\n",
      "Episode:591 meanR:233.2400 R:177.0 rate:0.3540 loss:957410.1875 exploreP:0.0101\n",
      "Episode:592 meanR:231.2500 R:185.0 rate:0.3700 loss:1010465.8750 exploreP:0.0101\n",
      "Episode:593 meanR:231.5800 R:237.0 rate:0.4740 loss:1018140.5000 exploreP:0.0101\n",
      "Episode:594 meanR:231.3000 R:160.0 rate:0.3200 loss:1102557.2500 exploreP:0.0101\n",
      "Episode:595 meanR:230.8100 R:177.0 rate:0.3540 loss:1146784.3750 exploreP:0.0101\n",
      "Episode:596 meanR:227.8700 R:206.0 rate:0.4120 loss:1155835.7500 exploreP:0.0101\n",
      "Episode:597 meanR:228.1100 R:211.0 rate:0.4220 loss:1281986.1250 exploreP:0.0101\n",
      "Episode:598 meanR:227.2100 R:182.0 rate:0.3640 loss:1276589.6250 exploreP:0.0101\n",
      "Episode:599 meanR:224.8400 R:172.0 rate:0.3440 loss:1288506.7500 exploreP:0.0101\n",
      "Episode:600 meanR:223.4900 R:208.0 rate:0.4160 loss:1430504.6250 exploreP:0.0101\n",
      "Episode:601 meanR:223.1200 R:217.0 rate:0.4340 loss:1495342.0000 exploreP:0.0101\n",
      "Episode:602 meanR:220.3600 R:208.0 rate:0.4160 loss:1581500.6250 exploreP:0.0101\n",
      "Episode:603 meanR:220.1400 R:173.0 rate:0.3460 loss:1610361.7500 exploreP:0.0101\n",
      "Episode:604 meanR:218.6700 R:170.0 rate:0.3400 loss:1661573.6250 exploreP:0.0101\n",
      "Episode:605 meanR:218.6400 R:259.0 rate:0.5180 loss:1851650.7500 exploreP:0.0101\n",
      "Episode:606 meanR:218.8500 R:205.0 rate:0.4100 loss:1898074.8750 exploreP:0.0101\n",
      "Episode:607 meanR:218.6300 R:241.0 rate:0.4820 loss:2052741.2500 exploreP:0.0101\n",
      "Episode:608 meanR:218.5200 R:176.0 rate:0.3520 loss:2120398.5000 exploreP:0.0101\n",
      "Episode:609 meanR:218.4200 R:188.0 rate:0.3760 loss:2096511.0000 exploreP:0.0101\n",
      "Episode:610 meanR:218.7300 R:214.0 rate:0.4280 loss:2117961.5000 exploreP:0.0101\n",
      "Episode:611 meanR:217.8500 R:165.0 rate:0.3300 loss:2276729.5000 exploreP:0.0101\n",
      "Episode:612 meanR:217.8200 R:239.0 rate:0.4780 loss:2394178.2500 exploreP:0.0101\n",
      "Episode:613 meanR:216.6300 R:167.0 rate:0.3340 loss:2378741.2500 exploreP:0.0101\n",
      "Episode:614 meanR:216.4800 R:176.0 rate:0.3520 loss:2538034.2500 exploreP:0.0101\n",
      "Episode:615 meanR:216.4600 R:239.0 rate:0.4780 loss:2508934.5000 exploreP:0.0101\n",
      "Episode:616 meanR:216.3600 R:191.0 rate:0.3820 loss:2800592.7500 exploreP:0.0101\n",
      "Episode:617 meanR:216.1100 R:174.0 rate:0.3480 loss:2779337.0000 exploreP:0.0101\n",
      "Episode:618 meanR:216.6700 R:238.0 rate:0.4760 loss:2889584.5000 exploreP:0.0101\n",
      "Episode:619 meanR:216.4700 R:170.0 rate:0.3400 loss:2968732.5000 exploreP:0.0101\n",
      "Episode:620 meanR:215.3700 R:194.0 rate:0.3880 loss:3223562.0000 exploreP:0.0101\n",
      "Episode:621 meanR:216.2700 R:275.0 rate:0.5500 loss:3262504.7500 exploreP:0.0101\n",
      "Episode:622 meanR:215.8200 R:198.0 rate:0.3960 loss:3442637.0000 exploreP:0.0101\n",
      "Episode:623 meanR:214.0700 R:216.0 rate:0.4320 loss:3557391.5000 exploreP:0.0101\n",
      "Episode:624 meanR:214.0500 R:209.0 rate:0.4180 loss:3766768.7500 exploreP:0.0101\n",
      "Episode:625 meanR:214.0300 R:202.0 rate:0.4040 loss:3720087.2500 exploreP:0.0101\n",
      "Episode:626 meanR:213.7900 R:202.0 rate:0.4040 loss:4048048.2500 exploreP:0.0101\n",
      "Episode:627 meanR:212.8000 R:228.0 rate:0.4560 loss:4215712.5000 exploreP:0.0101\n",
      "Episode:628 meanR:213.2300 R:276.0 rate:0.5520 loss:4288069.5000 exploreP:0.0101\n",
      "Episode:629 meanR:212.5700 R:222.0 rate:0.4440 loss:4434489.5000 exploreP:0.0100\n",
      "Episode:630 meanR:212.2700 R:244.0 rate:0.4880 loss:4407495.0000 exploreP:0.0100\n",
      "Episode:631 meanR:214.8300 R:500.0 rate:1.0000 loss:4685268.0000 exploreP:0.0100\n",
      "Episode:632 meanR:218.2100 R:500.0 rate:1.0000 loss:4918788.5000 exploreP:0.0100\n",
      "Episode:633 meanR:221.0900 R:500.0 rate:1.0000 loss:5045135.0000 exploreP:0.0100\n",
      "Episode:634 meanR:222.8900 R:500.0 rate:1.0000 loss:5068824.5000 exploreP:0.0100\n",
      "Episode:635 meanR:222.1700 R:293.0 rate:0.5860 loss:5080403.0000 exploreP:0.0100\n",
      "Episode:636 meanR:224.8600 R:500.0 rate:1.0000 loss:5131490.5000 exploreP:0.0100\n",
      "Episode:637 meanR:228.0100 R:500.0 rate:1.0000 loss:5152445.5000 exploreP:0.0100\n",
      "Episode:638 meanR:230.7700 R:500.0 rate:1.0000 loss:5181917.0000 exploreP:0.0100\n",
      "Episode:639 meanR:233.2800 R:500.0 rate:1.0000 loss:5140399.0000 exploreP:0.0100\n",
      "Episode:640 meanR:235.5000 R:500.0 rate:1.0000 loss:5073881.0000 exploreP:0.0100\n",
      "Episode:641 meanR:238.2000 R:500.0 rate:1.0000 loss:5081733.0000 exploreP:0.0100\n",
      "Episode:642 meanR:241.4400 R:500.0 rate:1.0000 loss:5267904.5000 exploreP:0.0100\n",
      "Episode:643 meanR:244.5900 R:500.0 rate:1.0000 loss:5284408.5000 exploreP:0.0100\n",
      "Episode:644 meanR:247.7500 R:500.0 rate:1.0000 loss:5388395.5000 exploreP:0.0100\n",
      "Episode:645 meanR:250.2300 R:500.0 rate:1.0000 loss:5510562.0000 exploreP:0.0100\n",
      "Episode:646 meanR:252.7500 R:500.0 rate:1.0000 loss:5518486.0000 exploreP:0.0100\n",
      "Episode:647 meanR:256.2400 R:500.0 rate:1.0000 loss:5690099.5000 exploreP:0.0100\n",
      "Episode:648 meanR:259.4500 R:500.0 rate:1.0000 loss:5797735.5000 exploreP:0.0100\n",
      "Episode:649 meanR:262.5600 R:500.0 rate:1.0000 loss:5845286.5000 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:650 meanR:264.5300 R:500.0 rate:1.0000 loss:6082509.0000 exploreP:0.0100\n",
      "Episode:651 meanR:267.4700 R:500.0 rate:1.0000 loss:6222932.0000 exploreP:0.0100\n",
      "Episode:652 meanR:269.6900 R:500.0 rate:1.0000 loss:6394689.5000 exploreP:0.0100\n",
      "Episode:653 meanR:272.8800 R:500.0 rate:1.0000 loss:6525284.5000 exploreP:0.0100\n",
      "Episode:654 meanR:276.2100 R:500.0 rate:1.0000 loss:6686705.5000 exploreP:0.0100\n",
      "Episode:655 meanR:279.5400 R:500.0 rate:1.0000 loss:6736316.5000 exploreP:0.0100\n",
      "Episode:656 meanR:282.4500 R:500.0 rate:1.0000 loss:6933025.0000 exploreP:0.0100\n",
      "Episode:657 meanR:285.6100 R:500.0 rate:1.0000 loss:7126012.0000 exploreP:0.0100\n",
      "Episode:658 meanR:288.5800 R:500.0 rate:1.0000 loss:7288871.5000 exploreP:0.0100\n",
      "Episode:659 meanR:291.1500 R:500.0 rate:1.0000 loss:7524361.0000 exploreP:0.0100\n",
      "Episode:660 meanR:294.7000 R:500.0 rate:1.0000 loss:7570449.0000 exploreP:0.0100\n",
      "Episode:661 meanR:297.2800 R:500.0 rate:1.0000 loss:7650125.0000 exploreP:0.0100\n",
      "Episode:662 meanR:300.2500 R:500.0 rate:1.0000 loss:7795349.5000 exploreP:0.0100\n",
      "Episode:663 meanR:302.9500 R:500.0 rate:1.0000 loss:7841103.0000 exploreP:0.0100\n",
      "Episode:664 meanR:305.2600 R:500.0 rate:1.0000 loss:8050075.5000 exploreP:0.0100\n",
      "Episode:665 meanR:308.0400 R:500.0 rate:1.0000 loss:8107329.5000 exploreP:0.0100\n",
      "Episode:666 meanR:310.0200 R:500.0 rate:1.0000 loss:8052572.0000 exploreP:0.0100\n",
      "Episode:667 meanR:313.0400 R:500.0 rate:1.0000 loss:8296677.5000 exploreP:0.0100\n",
      "Episode:668 meanR:316.2000 R:500.0 rate:1.0000 loss:8188679.0000 exploreP:0.0100\n",
      "Episode:669 meanR:319.3900 R:500.0 rate:1.0000 loss:8339024.5000 exploreP:0.0100\n",
      "Episode:670 meanR:322.7500 R:500.0 rate:1.0000 loss:8312981.0000 exploreP:0.0100\n",
      "Episode:671 meanR:325.5700 R:500.0 rate:1.0000 loss:8277718.0000 exploreP:0.0100\n",
      "Episode:672 meanR:328.3900 R:500.0 rate:1.0000 loss:8107516.5000 exploreP:0.0100\n",
      "Episode:673 meanR:331.2500 R:500.0 rate:1.0000 loss:8243515.5000 exploreP:0.0100\n",
      "Episode:674 meanR:333.2600 R:500.0 rate:1.0000 loss:8127364.0000 exploreP:0.0100\n",
      "Episode:675 meanR:336.0300 R:500.0 rate:1.0000 loss:8372901.5000 exploreP:0.0100\n",
      "Episode:676 meanR:339.0000 R:500.0 rate:1.0000 loss:8371392.5000 exploreP:0.0100\n",
      "Episode:677 meanR:341.2700 R:500.0 rate:1.0000 loss:8602554.0000 exploreP:0.0100\n",
      "Episode:678 meanR:344.3100 R:500.0 rate:1.0000 loss:8778428.0000 exploreP:0.0100\n",
      "Episode:679 meanR:347.1400 R:500.0 rate:1.0000 loss:8752709.0000 exploreP:0.0100\n",
      "Episode:680 meanR:350.5400 R:500.0 rate:1.0000 loss:8758479.0000 exploreP:0.0100\n",
      "Episode:681 meanR:353.3500 R:500.0 rate:1.0000 loss:8430905.0000 exploreP:0.0100\n",
      "Episode:682 meanR:355.7900 R:500.0 rate:1.0000 loss:8325141.5000 exploreP:0.0100\n",
      "Episode:683 meanR:359.1700 R:500.0 rate:1.0000 loss:8359495.5000 exploreP:0.0100\n",
      "Episode:684 meanR:362.0000 R:500.0 rate:1.0000 loss:8394844.0000 exploreP:0.0100\n",
      "Episode:685 meanR:365.0100 R:500.0 rate:1.0000 loss:8487856.0000 exploreP:0.0100\n",
      "Episode:686 meanR:368.1600 R:500.0 rate:1.0000 loss:8584882.0000 exploreP:0.0100\n",
      "Episode:687 meanR:371.0900 R:500.0 rate:1.0000 loss:8712002.0000 exploreP:0.0100\n",
      "Episode:688 meanR:374.0300 R:500.0 rate:1.0000 loss:9014790.0000 exploreP:0.0100\n",
      "Episode:689 meanR:376.7800 R:500.0 rate:1.0000 loss:9091391.0000 exploreP:0.0100\n",
      "Episode:690 meanR:379.8400 R:500.0 rate:1.0000 loss:9578742.0000 exploreP:0.0100\n",
      "Episode:691 meanR:383.0700 R:500.0 rate:1.0000 loss:9497089.0000 exploreP:0.0100\n",
      "Episode:692 meanR:386.2200 R:500.0 rate:1.0000 loss:9967129.0000 exploreP:0.0100\n",
      "Episode:693 meanR:388.8500 R:500.0 rate:1.0000 loss:10480597.0000 exploreP:0.0100\n",
      "Episode:694 meanR:392.2500 R:500.0 rate:1.0000 loss:11034655.0000 exploreP:0.0100\n",
      "Episode:695 meanR:395.4800 R:500.0 rate:1.0000 loss:11665450.0000 exploreP:0.0100\n",
      "Episode:696 meanR:398.4200 R:500.0 rate:1.0000 loss:12040141.0000 exploreP:0.0100\n",
      "Episode:697 meanR:401.3100 R:500.0 rate:1.0000 loss:12820933.0000 exploreP:0.0100\n",
      "Episode:698 meanR:404.4900 R:500.0 rate:1.0000 loss:12315701.0000 exploreP:0.0100\n",
      "Episode:699 meanR:407.7700 R:500.0 rate:1.0000 loss:12182106.0000 exploreP:0.0100\n",
      "Episode:700 meanR:410.6900 R:500.0 rate:1.0000 loss:12852599.0000 exploreP:0.0100\n",
      "Episode:701 meanR:413.5200 R:500.0 rate:1.0000 loss:13402960.0000 exploreP:0.0100\n",
      "Episode:702 meanR:416.4400 R:500.0 rate:1.0000 loss:13670748.0000 exploreP:0.0100\n",
      "Episode:703 meanR:419.7100 R:500.0 rate:1.0000 loss:14164645.0000 exploreP:0.0100\n",
      "Episode:704 meanR:423.0100 R:500.0 rate:1.0000 loss:13996845.0000 exploreP:0.0100\n",
      "Episode:705 meanR:425.4200 R:500.0 rate:1.0000 loss:14144735.0000 exploreP:0.0100\n",
      "Episode:706 meanR:428.3700 R:500.0 rate:1.0000 loss:13691724.0000 exploreP:0.0100\n",
      "Episode:707 meanR:430.9600 R:500.0 rate:1.0000 loss:13634337.0000 exploreP:0.0100\n",
      "Episode:708 meanR:434.2000 R:500.0 rate:1.0000 loss:13445982.0000 exploreP:0.0100\n",
      "Episode:709 meanR:437.3200 R:500.0 rate:1.0000 loss:13740264.0000 exploreP:0.0100\n",
      "Episode:710 meanR:440.1800 R:500.0 rate:1.0000 loss:13425965.0000 exploreP:0.0100\n",
      "Episode:711 meanR:443.5300 R:500.0 rate:1.0000 loss:13928755.0000 exploreP:0.0100\n",
      "Episode:712 meanR:446.1400 R:500.0 rate:1.0000 loss:13376136.0000 exploreP:0.0100\n",
      "Episode:713 meanR:449.4700 R:500.0 rate:1.0000 loss:12508889.0000 exploreP:0.0100\n",
      "Episode:714 meanR:452.7100 R:500.0 rate:1.0000 loss:12221819.0000 exploreP:0.0100\n",
      "Episode:715 meanR:455.3200 R:500.0 rate:1.0000 loss:13558512.0000 exploreP:0.0100\n",
      "Episode:716 meanR:458.4100 R:500.0 rate:1.0000 loss:14844675.0000 exploreP:0.0100\n",
      "Episode:717 meanR:461.6700 R:500.0 rate:1.0000 loss:16067735.0000 exploreP:0.0100\n",
      "Episode:718 meanR:464.2900 R:500.0 rate:1.0000 loss:17478378.0000 exploreP:0.0100\n",
      "Episode:719 meanR:467.5900 R:500.0 rate:1.0000 loss:19897670.0000 exploreP:0.0100\n",
      "Episode:720 meanR:470.0900 R:444.0 rate:0.8880 loss:19702744.0000 exploreP:0.0100\n",
      "Episode:721 meanR:470.3100 R:297.0 rate:0.5940 loss:19977988.0000 exploreP:0.0100\n",
      "Episode:722 meanR:471.6600 R:333.0 rate:0.6660 loss:19830104.0000 exploreP:0.0100\n",
      "Episode:723 meanR:470.7600 R:126.0 rate:0.2520 loss:20053414.0000 exploreP:0.0100\n",
      "Episode:724 meanR:470.8000 R:213.0 rate:0.4260 loss:19520300.0000 exploreP:0.0100\n",
      "Episode:725 meanR:469.5000 R:72.0 rate:0.1440 loss:19902630.0000 exploreP:0.0100\n",
      "Episode:726 meanR:469.9500 R:247.0 rate:0.4940 loss:19267174.0000 exploreP:0.0100\n",
      "Episode:727 meanR:468.5600 R:89.0 rate:0.1780 loss:16756647.0000 exploreP:0.0100\n",
      "Episode:728 meanR:466.2500 R:45.0 rate:0.0900 loss:16896688.0000 exploreP:0.0100\n",
      "Episode:729 meanR:467.1900 R:316.0 rate:0.6320 loss:16273962.0000 exploreP:0.0100\n",
      "Episode:730 meanR:466.3100 R:156.0 rate:0.3120 loss:15015821.0000 exploreP:0.0100\n",
      "Episode:731 meanR:461.4300 R:12.0 rate:0.0240 loss:17380850.0000 exploreP:0.0100\n",
      "Episode:732 meanR:456.7300 R:30.0 rate:0.0600 loss:15078887.0000 exploreP:0.0100\n",
      "Episode:733 meanR:452.2200 R:49.0 rate:0.0980 loss:14968456.0000 exploreP:0.0100\n",
      "Episode:734 meanR:451.8500 R:463.0 rate:0.9260 loss:13523565.0000 exploreP:0.0100\n",
      "Episode:735 meanR:449.9300 R:101.0 rate:0.2020 loss:12604763.0000 exploreP:0.0100\n",
      "Episode:736 meanR:446.6200 R:169.0 rate:0.3380 loss:11793335.0000 exploreP:0.0100\n",
      "Episode:737 meanR:446.6200 R:500.0 rate:1.0000 loss:11489262.0000 exploreP:0.0100\n",
      "Episode:738 meanR:442.8900 R:127.0 rate:0.2540 loss:10933112.0000 exploreP:0.0100\n",
      "Episode:739 meanR:438.3900 R:50.0 rate:0.1000 loss:10535980.0000 exploreP:0.0100\n",
      "Episode:740 meanR:433.8400 R:45.0 rate:0.0900 loss:10172331.0000 exploreP:0.0100\n",
      "Episode:741 meanR:430.6400 R:180.0 rate:0.3600 loss:10107929.0000 exploreP:0.0100\n",
      "Episode:742 meanR:430.6400 R:500.0 rate:1.0000 loss:9014708.0000 exploreP:0.0100\n",
      "Episode:743 meanR:426.2900 R:65.0 rate:0.1300 loss:8296006.0000 exploreP:0.0100\n",
      "Episode:744 meanR:424.2900 R:300.0 rate:0.6000 loss:8514613.0000 exploreP:0.0100\n",
      "Episode:745 meanR:424.2900 R:500.0 rate:1.0000 loss:7991316.0000 exploreP:0.0100\n",
      "Episode:746 meanR:424.2900 R:500.0 rate:1.0000 loss:7322415.0000 exploreP:0.0100\n",
      "Episode:747 meanR:424.2900 R:500.0 rate:1.0000 loss:7470317.5000 exploreP:0.0100\n",
      "Episode:748 meanR:424.2900 R:500.0 rate:1.0000 loss:7325160.0000 exploreP:0.0100\n",
      "Episode:749 meanR:424.2900 R:500.0 rate:1.0000 loss:7110772.0000 exploreP:0.0100\n",
      "Episode:750 meanR:424.2900 R:500.0 rate:1.0000 loss:6955611.0000 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:751 meanR:424.2900 R:500.0 rate:1.0000 loss:6659279.5000 exploreP:0.0100\n",
      "Episode:752 meanR:424.2900 R:500.0 rate:1.0000 loss:6340424.0000 exploreP:0.0100\n",
      "Episode:753 meanR:424.2900 R:500.0 rate:1.0000 loss:6118768.5000 exploreP:0.0100\n",
      "Episode:754 meanR:424.2900 R:500.0 rate:1.0000 loss:6132458.5000 exploreP:0.0100\n",
      "Episode:755 meanR:424.2900 R:500.0 rate:1.0000 loss:5978562.0000 exploreP:0.0100\n",
      "Episode:756 meanR:424.2900 R:500.0 rate:1.0000 loss:6022868.0000 exploreP:0.0100\n",
      "Episode:757 meanR:424.2900 R:500.0 rate:1.0000 loss:5808436.0000 exploreP:0.0100\n",
      "Episode:758 meanR:424.2900 R:500.0 rate:1.0000 loss:5827917.5000 exploreP:0.0100\n",
      "Episode:759 meanR:424.2900 R:500.0 rate:1.0000 loss:6214890.5000 exploreP:0.0100\n",
      "Episode:760 meanR:424.2900 R:500.0 rate:1.0000 loss:7201981.0000 exploreP:0.0100\n",
      "Episode:761 meanR:423.8600 R:457.0 rate:0.9140 loss:6277306.5000 exploreP:0.0100\n",
      "Episode:762 meanR:422.8600 R:400.0 rate:0.8000 loss:6209166.5000 exploreP:0.0100\n",
      "Episode:763 meanR:421.8800 R:402.0 rate:0.8040 loss:5941722.0000 exploreP:0.0100\n",
      "Episode:764 meanR:420.0500 R:317.0 rate:0.6340 loss:5751164.0000 exploreP:0.0100\n",
      "Episode:765 meanR:418.3000 R:325.0 rate:0.6500 loss:5916142.0000 exploreP:0.0100\n",
      "Episode:766 meanR:416.1600 R:286.0 rate:0.5720 loss:5742509.0000 exploreP:0.0100\n",
      "Episode:767 meanR:413.6400 R:248.0 rate:0.4960 loss:5669001.5000 exploreP:0.0100\n",
      "Episode:768 meanR:411.1700 R:253.0 rate:0.5060 loss:5475324.0000 exploreP:0.0100\n",
      "Episode:769 meanR:408.5400 R:237.0 rate:0.4740 loss:5220414.5000 exploreP:0.0100\n",
      "Episode:770 meanR:405.9400 R:240.0 rate:0.4800 loss:5360686.5000 exploreP:0.0100\n",
      "Episode:771 meanR:403.6000 R:266.0 rate:0.5320 loss:5408001.5000 exploreP:0.0100\n",
      "Episode:772 meanR:400.9700 R:237.0 rate:0.4740 loss:5394543.5000 exploreP:0.0100\n",
      "Episode:773 meanR:398.2200 R:225.0 rate:0.4500 loss:5165275.5000 exploreP:0.0100\n",
      "Episode:774 meanR:395.6600 R:244.0 rate:0.4880 loss:5138680.0000 exploreP:0.0100\n",
      "Episode:775 meanR:392.9100 R:225.0 rate:0.4500 loss:4960433.0000 exploreP:0.0100\n",
      "Episode:776 meanR:390.1800 R:227.0 rate:0.4540 loss:5412831.5000 exploreP:0.0100\n",
      "Episode:777 meanR:387.3400 R:216.0 rate:0.4320 loss:5151597.0000 exploreP:0.0100\n",
      "Episode:778 meanR:384.6400 R:230.0 rate:0.4600 loss:5195531.0000 exploreP:0.0100\n",
      "Episode:779 meanR:381.8800 R:224.0 rate:0.4480 loss:5239244.5000 exploreP:0.0100\n",
      "Episode:780 meanR:379.2000 R:232.0 rate:0.4640 loss:5576827.0000 exploreP:0.0100\n",
      "Episode:781 meanR:376.1100 R:191.0 rate:0.3820 loss:5123896.5000 exploreP:0.0100\n",
      "Episode:782 meanR:373.2300 R:212.0 rate:0.4240 loss:4974441.0000 exploreP:0.0100\n",
      "Episode:783 meanR:370.2500 R:202.0 rate:0.4040 loss:5454797.5000 exploreP:0.0100\n",
      "Episode:784 meanR:367.1300 R:188.0 rate:0.3760 loss:5345526.0000 exploreP:0.0100\n",
      "Episode:785 meanR:363.9300 R:180.0 rate:0.3600 loss:5136047.0000 exploreP:0.0100\n",
      "Episode:786 meanR:360.7900 R:186.0 rate:0.3720 loss:5133985.0000 exploreP:0.0100\n",
      "Episode:787 meanR:357.8700 R:208.0 rate:0.4160 loss:5235527.0000 exploreP:0.0100\n",
      "Episode:788 meanR:354.7300 R:186.0 rate:0.3720 loss:5331840.5000 exploreP:0.0100\n",
      "Episode:789 meanR:351.4100 R:168.0 rate:0.3360 loss:5200570.0000 exploreP:0.0100\n",
      "Episode:790 meanR:348.1500 R:174.0 rate:0.3480 loss:5330486.0000 exploreP:0.0100\n",
      "Episode:791 meanR:344.7300 R:158.0 rate:0.3160 loss:5319847.0000 exploreP:0.0100\n",
      "Episode:792 meanR:341.5100 R:178.0 rate:0.3560 loss:4895643.5000 exploreP:0.0100\n",
      "Episode:793 meanR:338.2800 R:177.0 rate:0.3540 loss:4995622.5000 exploreP:0.0100\n",
      "Episode:794 meanR:334.9800 R:170.0 rate:0.3400 loss:4897408.0000 exploreP:0.0100\n",
      "Episode:795 meanR:331.5500 R:157.0 rate:0.3140 loss:5531967.0000 exploreP:0.0100\n",
      "Episode:796 meanR:328.1800 R:163.0 rate:0.3260 loss:5354482.0000 exploreP:0.0100\n",
      "Episode:797 meanR:324.7900 R:161.0 rate:0.3220 loss:5238119.5000 exploreP:0.0100\n",
      "Episode:798 meanR:321.4700 R:168.0 rate:0.3360 loss:5044091.5000 exploreP:0.0100\n",
      "Episode:799 meanR:318.1200 R:165.0 rate:0.3300 loss:4993239.0000 exploreP:0.0100\n",
      "Episode:800 meanR:314.7900 R:167.0 rate:0.3340 loss:5169680.0000 exploreP:0.0100\n",
      "Episode:801 meanR:311.7000 R:191.0 rate:0.3820 loss:5236997.0000 exploreP:0.0100\n",
      "Episode:802 meanR:308.5900 R:189.0 rate:0.3780 loss:5154552.0000 exploreP:0.0100\n",
      "Episode:803 meanR:305.2700 R:168.0 rate:0.3360 loss:5185932.0000 exploreP:0.0100\n",
      "Episode:804 meanR:302.0000 R:173.0 rate:0.3460 loss:5057641.0000 exploreP:0.0100\n",
      "Episode:805 meanR:298.6400 R:164.0 rate:0.3280 loss:5264854.5000 exploreP:0.0100\n",
      "Episode:806 meanR:295.3100 R:167.0 rate:0.3340 loss:5051402.0000 exploreP:0.0100\n",
      "Episode:807 meanR:291.9700 R:166.0 rate:0.3320 loss:5417401.5000 exploreP:0.0100\n",
      "Episode:808 meanR:288.7900 R:182.0 rate:0.3640 loss:5403466.0000 exploreP:0.0100\n",
      "Episode:809 meanR:285.6500 R:186.0 rate:0.3720 loss:5481607.0000 exploreP:0.0100\n",
      "Episode:810 meanR:282.6000 R:195.0 rate:0.3900 loss:5129115.5000 exploreP:0.0100\n",
      "Episode:811 meanR:279.4600 R:186.0 rate:0.3720 loss:4954280.0000 exploreP:0.0100\n",
      "Episode:812 meanR:276.5100 R:205.0 rate:0.4100 loss:5308810.5000 exploreP:0.0100\n",
      "Episode:813 meanR:273.3500 R:184.0 rate:0.3680 loss:5070201.5000 exploreP:0.0100\n",
      "Episode:814 meanR:270.0800 R:173.0 rate:0.3460 loss:5318553.0000 exploreP:0.0100\n",
      "Episode:815 meanR:267.0000 R:192.0 rate:0.3840 loss:5316186.5000 exploreP:0.0100\n",
      "Episode:816 meanR:263.9100 R:191.0 rate:0.3820 loss:5036107.5000 exploreP:0.0100\n",
      "Episode:817 meanR:260.9300 R:202.0 rate:0.4040 loss:5025229.5000 exploreP:0.0100\n",
      "Episode:818 meanR:257.9800 R:205.0 rate:0.4100 loss:5002267.5000 exploreP:0.0100\n",
      "Episode:819 meanR:254.9400 R:196.0 rate:0.3920 loss:4971889.0000 exploreP:0.0100\n",
      "Episode:820 meanR:252.2000 R:170.0 rate:0.3400 loss:5283513.0000 exploreP:0.0100\n",
      "Episode:821 meanR:251.1000 R:187.0 rate:0.3740 loss:5050646.5000 exploreP:0.0100\n",
      "Episode:822 meanR:249.7300 R:196.0 rate:0.3920 loss:5098994.0000 exploreP:0.0100\n",
      "Episode:823 meanR:250.3000 R:183.0 rate:0.3660 loss:4837759.0000 exploreP:0.0100\n",
      "Episode:824 meanR:250.1300 R:196.0 rate:0.3920 loss:5251807.5000 exploreP:0.0100\n",
      "Episode:825 meanR:251.5000 R:209.0 rate:0.4180 loss:4851512.5000 exploreP:0.0100\n",
      "Episode:826 meanR:251.2600 R:223.0 rate:0.4460 loss:5044803.0000 exploreP:0.0100\n",
      "Episode:827 meanR:252.9600 R:259.0 rate:0.5180 loss:5051355.5000 exploreP:0.0100\n",
      "Episode:828 meanR:255.2200 R:271.0 rate:0.5420 loss:4712625.5000 exploreP:0.0100\n",
      "Episode:829 meanR:254.1400 R:208.0 rate:0.4160 loss:4767483.0000 exploreP:0.0100\n",
      "Episode:830 meanR:255.3500 R:277.0 rate:0.5540 loss:4820158.5000 exploreP:0.0100\n",
      "Episode:831 meanR:258.0300 R:280.0 rate:0.5600 loss:4830954.0000 exploreP:0.0100\n",
      "Episode:832 meanR:260.3200 R:259.0 rate:0.5180 loss:4923540.0000 exploreP:0.0100\n",
      "Episode:833 meanR:262.8200 R:299.0 rate:0.5980 loss:4532273.5000 exploreP:0.0100\n",
      "Episode:834 meanR:260.6200 R:243.0 rate:0.4860 loss:4887244.5000 exploreP:0.0100\n",
      "Episode:835 meanR:262.0500 R:244.0 rate:0.4880 loss:4736478.5000 exploreP:0.0100\n",
      "Episode:836 meanR:262.9700 R:261.0 rate:0.5220 loss:4657641.5000 exploreP:0.0100\n",
      "Episode:837 meanR:259.8900 R:192.0 rate:0.3840 loss:4870892.0000 exploreP:0.0100\n",
      "Episode:838 meanR:260.7800 R:216.0 rate:0.4320 loss:4607390.0000 exploreP:0.0100\n",
      "Episode:839 meanR:263.0800 R:280.0 rate:0.5600 loss:4472749.5000 exploreP:0.0100\n",
      "Episode:840 meanR:265.6900 R:306.0 rate:0.6120 loss:4636527.5000 exploreP:0.0100\n",
      "Episode:841 meanR:266.6700 R:278.0 rate:0.5560 loss:4721143.0000 exploreP:0.0100\n",
      "Episode:842 meanR:264.6100 R:294.0 rate:0.5880 loss:4615048.5000 exploreP:0.0100\n",
      "Episode:843 meanR:267.3900 R:343.0 rate:0.6860 loss:4724067.5000 exploreP:0.0100\n",
      "Episode:844 meanR:266.3000 R:191.0 rate:0.3820 loss:4573704.5000 exploreP:0.0100\n",
      "Episode:845 meanR:263.9300 R:263.0 rate:0.5260 loss:4602313.5000 exploreP:0.0100\n",
      "Episode:846 meanR:261.6100 R:268.0 rate:0.5360 loss:4344624.0000 exploreP:0.0100\n",
      "Episode:847 meanR:261.2500 R:464.0 rate:0.9280 loss:4476048.5000 exploreP:0.0100\n",
      "Episode:848 meanR:259.0500 R:280.0 rate:0.5600 loss:4326253.0000 exploreP:0.0100\n",
      "Episode:849 meanR:257.1200 R:307.0 rate:0.6140 loss:4413893.5000 exploreP:0.0100\n",
      "Episode:850 meanR:254.4600 R:234.0 rate:0.4680 loss:4528101.0000 exploreP:0.0100\n",
      "Episode:851 meanR:254.4600 R:500.0 rate:1.0000 loss:4317082.5000 exploreP:0.0100\n",
      "Episode:852 meanR:252.9300 R:347.0 rate:0.6940 loss:4314534.0000 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:853 meanR:250.8600 R:293.0 rate:0.5860 loss:4057803.5000 exploreP:0.0100\n",
      "Episode:854 meanR:248.5200 R:266.0 rate:0.5320 loss:4056832.0000 exploreP:0.0100\n",
      "Episode:855 meanR:243.6200 R:10.0 rate:0.0200 loss:3273521.0000 exploreP:0.0100\n",
      "Episode:856 meanR:238.7200 R:10.0 rate:0.0200 loss:4143142.0000 exploreP:0.0100\n",
      "Episode:857 meanR:233.8100 R:9.0 rate:0.0180 loss:4718422.5000 exploreP:0.0100\n",
      "Episode:858 meanR:228.8900 R:8.0 rate:0.0160 loss:3756004.0000 exploreP:0.0100\n",
      "Episode:859 meanR:223.9800 R:9.0 rate:0.0180 loss:4080178.2500 exploreP:0.0100\n",
      "Episode:860 meanR:219.0600 R:8.0 rate:0.0160 loss:3006525.0000 exploreP:0.0100\n",
      "Episode:861 meanR:214.5900 R:10.0 rate:0.0200 loss:3628790.0000 exploreP:0.0100\n",
      "Episode:862 meanR:210.6800 R:9.0 rate:0.0180 loss:4621986.5000 exploreP:0.0100\n",
      "Episode:863 meanR:206.7500 R:9.0 rate:0.0180 loss:4062647.5000 exploreP:0.0100\n",
      "Episode:864 meanR:203.6700 R:9.0 rate:0.0180 loss:4122968.5000 exploreP:0.0100\n",
      "Episode:865 meanR:200.5300 R:11.0 rate:0.0220 loss:4766539.5000 exploreP:0.0100\n",
      "Episode:866 meanR:197.7600 R:9.0 rate:0.0180 loss:4429755.0000 exploreP:0.0100\n",
      "Episode:867 meanR:195.3700 R:9.0 rate:0.0180 loss:2848228.7500 exploreP:0.0100\n",
      "Episode:868 meanR:192.9400 R:10.0 rate:0.0200 loss:3245791.7500 exploreP:0.0100\n",
      "Episode:869 meanR:190.6800 R:11.0 rate:0.0220 loss:3746270.5000 exploreP:0.0100\n",
      "Episode:870 meanR:188.3700 R:9.0 rate:0.0180 loss:4157575.5000 exploreP:0.0100\n",
      "Episode:871 meanR:185.8100 R:10.0 rate:0.0200 loss:3110556.7500 exploreP:0.0100\n",
      "Episode:872 meanR:183.5400 R:10.0 rate:0.0200 loss:3922267.2500 exploreP:0.0100\n",
      "Episode:873 meanR:181.3900 R:10.0 rate:0.0200 loss:3487440.7500 exploreP:0.0100\n",
      "Episode:874 meanR:179.0300 R:8.0 rate:0.0160 loss:3637769.7500 exploreP:0.0100\n",
      "Episode:875 meanR:176.8800 R:10.0 rate:0.0200 loss:4052984.7500 exploreP:0.0100\n",
      "Episode:876 meanR:174.7000 R:9.0 rate:0.0180 loss:4143761.7500 exploreP:0.0100\n",
      "Episode:877 meanR:172.6500 R:11.0 rate:0.0220 loss:3457019.7500 exploreP:0.0100\n",
      "Episode:878 meanR:170.4300 R:8.0 rate:0.0160 loss:4009200.5000 exploreP:0.0100\n",
      "Episode:879 meanR:168.2800 R:9.0 rate:0.0180 loss:4004452.5000 exploreP:0.0100\n",
      "Episode:880 meanR:166.0500 R:9.0 rate:0.0180 loss:3810406.7500 exploreP:0.0100\n",
      "Episode:881 meanR:164.2400 R:10.0 rate:0.0200 loss:3674419.5000 exploreP:0.0100\n",
      "Episode:882 meanR:162.2200 R:10.0 rate:0.0200 loss:3245851.5000 exploreP:0.0100\n",
      "Episode:883 meanR:160.2800 R:8.0 rate:0.0160 loss:2468773.7500 exploreP:0.0100\n",
      "Episode:884 meanR:158.5000 R:10.0 rate:0.0200 loss:3065802.5000 exploreP:0.0100\n",
      "Episode:885 meanR:156.8000 R:10.0 rate:0.0200 loss:2062512.6250 exploreP:0.0100\n",
      "Episode:886 meanR:155.0400 R:10.0 rate:0.0200 loss:2984932.5000 exploreP:0.0100\n",
      "Episode:887 meanR:153.0600 R:10.0 rate:0.0200 loss:2455401.5000 exploreP:0.0100\n",
      "Episode:888 meanR:151.2900 R:9.0 rate:0.0180 loss:3517700.2500 exploreP:0.0100\n",
      "Episode:889 meanR:149.6900 R:8.0 rate:0.0160 loss:3388759.0000 exploreP:0.0100\n",
      "Episode:890 meanR:148.0400 R:9.0 rate:0.0180 loss:3262005.0000 exploreP:0.0100\n",
      "Episode:891 meanR:146.5600 R:10.0 rate:0.0200 loss:3770070.5000 exploreP:0.0100\n",
      "Episode:892 meanR:144.9000 R:12.0 rate:0.0240 loss:3827871.0000 exploreP:0.0100\n",
      "Episode:893 meanR:143.2200 R:9.0 rate:0.0180 loss:3305114.0000 exploreP:0.0100\n",
      "Episode:894 meanR:141.6100 R:9.0 rate:0.0180 loss:3429633.0000 exploreP:0.0100\n",
      "Episode:895 meanR:140.1400 R:10.0 rate:0.0200 loss:2848298.5000 exploreP:0.0100\n",
      "Episode:896 meanR:138.6100 R:10.0 rate:0.0200 loss:3871106.7500 exploreP:0.0100\n",
      "Episode:897 meanR:137.1000 R:10.0 rate:0.0200 loss:3178163.2500 exploreP:0.0100\n",
      "Episode:898 meanR:135.5100 R:9.0 rate:0.0180 loss:4159599.5000 exploreP:0.0100\n",
      "Episode:899 meanR:133.9600 R:10.0 rate:0.0200 loss:3033854.5000 exploreP:0.0100\n",
      "Episode:900 meanR:132.3800 R:9.0 rate:0.0180 loss:3471483.5000 exploreP:0.0100\n",
      "Episode:901 meanR:130.5600 R:9.0 rate:0.0180 loss:2605261.0000 exploreP:0.0100\n",
      "Episode:902 meanR:128.7700 R:10.0 rate:0.0200 loss:3247586.5000 exploreP:0.0100\n",
      "Episode:903 meanR:127.1900 R:10.0 rate:0.0200 loss:3568103.5000 exploreP:0.0100\n",
      "Episode:904 meanR:125.5700 R:11.0 rate:0.0220 loss:3597080.0000 exploreP:0.0100\n",
      "Episode:905 meanR:124.0400 R:11.0 rate:0.0220 loss:3146246.2500 exploreP:0.0100\n",
      "Episode:906 meanR:122.4800 R:11.0 rate:0.0220 loss:2422769.2500 exploreP:0.0100\n",
      "Episode:907 meanR:120.9200 R:10.0 rate:0.0200 loss:3858468.0000 exploreP:0.0100\n",
      "Episode:908 meanR:119.2000 R:10.0 rate:0.0200 loss:3701558.5000 exploreP:0.0100\n",
      "Episode:909 meanR:117.4500 R:11.0 rate:0.0220 loss:3970198.5000 exploreP:0.0100\n",
      "Episode:910 meanR:115.6000 R:10.0 rate:0.0200 loss:3074462.2500 exploreP:0.0100\n",
      "Episode:911 meanR:114.0100 R:27.0 rate:0.0540 loss:3607140.7500 exploreP:0.0100\n",
      "Episode:912 meanR:112.0600 R:10.0 rate:0.0200 loss:3771474.0000 exploreP:0.0100\n",
      "Episode:913 meanR:110.3400 R:12.0 rate:0.0240 loss:3304223.7500 exploreP:0.0100\n",
      "Episode:914 meanR:108.7200 R:11.0 rate:0.0220 loss:4245856.0000 exploreP:0.0100\n",
      "Episode:915 meanR:106.9100 R:11.0 rate:0.0220 loss:3145784.2500 exploreP:0.0100\n",
      "Episode:916 meanR:105.2700 R:27.0 rate:0.0540 loss:2563485.2500 exploreP:0.0100\n",
      "Episode:917 meanR:103.3700 R:12.0 rate:0.0240 loss:3171224.2500 exploreP:0.0100\n",
      "Episode:918 meanR:101.5800 R:26.0 rate:0.0520 loss:3558173.0000 exploreP:0.0100\n",
      "Episode:919 meanR:99.8800 R:26.0 rate:0.0520 loss:2888248.5000 exploreP:0.0100\n",
      "Episode:920 meanR:98.3000 R:12.0 rate:0.0240 loss:3468143.7500 exploreP:0.0100\n",
      "Episode:921 meanR:101.4300 R:500.0 rate:1.0000 loss:3399829.5000 exploreP:0.0100\n",
      "Episode:922 meanR:99.5900 R:12.0 rate:0.0240 loss:3490726.2500 exploreP:0.0100\n",
      "Episode:923 meanR:97.8700 R:11.0 rate:0.0220 loss:2953202.2500 exploreP:0.0100\n",
      "Episode:924 meanR:96.0200 R:11.0 rate:0.0220 loss:2460712.2500 exploreP:0.0100\n",
      "Episode:925 meanR:94.0600 R:13.0 rate:0.0260 loss:2935502.5000 exploreP:0.0100\n",
      "Episode:926 meanR:91.9600 R:13.0 rate:0.0260 loss:3665093.7500 exploreP:0.0100\n",
      "Episode:927 meanR:89.4800 R:11.0 rate:0.0220 loss:3205095.0000 exploreP:0.0100\n",
      "Episode:928 meanR:86.8800 R:11.0 rate:0.0220 loss:2608705.7500 exploreP:0.0100\n",
      "Episode:929 meanR:84.9100 R:11.0 rate:0.0220 loss:3599581.0000 exploreP:0.0100\n",
      "Episode:930 meanR:82.2700 R:13.0 rate:0.0260 loss:3787021.2500 exploreP:0.0100\n",
      "Episode:931 meanR:79.5800 R:11.0 rate:0.0220 loss:3654852.0000 exploreP:0.0100\n",
      "Episode:932 meanR:77.1000 R:11.0 rate:0.0220 loss:2691490.2500 exploreP:0.0100\n",
      "Episode:933 meanR:74.2100 R:10.0 rate:0.0200 loss:3746191.5000 exploreP:0.0100\n",
      "Episode:934 meanR:71.9000 R:12.0 rate:0.0240 loss:3286314.2500 exploreP:0.0100\n",
      "Episode:935 meanR:69.5700 R:11.0 rate:0.0220 loss:3558373.0000 exploreP:0.0100\n",
      "Episode:936 meanR:67.0700 R:11.0 rate:0.0220 loss:4321675.0000 exploreP:0.0100\n",
      "Episode:937 meanR:65.2700 R:12.0 rate:0.0240 loss:3435479.0000 exploreP:0.0100\n",
      "Episode:938 meanR:63.2200 R:11.0 rate:0.0220 loss:3655169.0000 exploreP:0.0100\n",
      "Episode:939 meanR:60.5400 R:12.0 rate:0.0240 loss:3766324.7500 exploreP:0.0100\n",
      "Episode:940 meanR:57.5900 R:11.0 rate:0.0220 loss:3323074.2500 exploreP:0.0100\n",
      "Episode:941 meanR:54.9100 R:10.0 rate:0.0200 loss:2938865.7500 exploreP:0.0100\n",
      "Episode:942 meanR:52.0800 R:11.0 rate:0.0220 loss:2445342.0000 exploreP:0.0100\n",
      "Episode:943 meanR:48.7500 R:10.0 rate:0.0200 loss:3198154.5000 exploreP:0.0100\n",
      "Episode:944 meanR:46.9500 R:11.0 rate:0.0220 loss:3158481.7500 exploreP:0.0100\n",
      "Episode:945 meanR:44.4400 R:12.0 rate:0.0240 loss:3365024.2500 exploreP:0.0100\n",
      "Episode:946 meanR:41.8900 R:13.0 rate:0.0260 loss:3904435.7500 exploreP:0.0100\n",
      "Episode:947 meanR:37.3600 R:11.0 rate:0.0220 loss:2919903.7500 exploreP:0.0100\n",
      "Episode:948 meanR:34.6800 R:12.0 rate:0.0240 loss:3307658.0000 exploreP:0.0100\n",
      "Episode:949 meanR:31.7200 R:11.0 rate:0.0220 loss:3863494.2500 exploreP:0.0100\n",
      "Episode:950 meanR:29.4900 R:11.0 rate:0.0220 loss:3004604.5000 exploreP:0.0100\n",
      "Episode:951 meanR:24.6000 R:11.0 rate:0.0220 loss:3262140.2500 exploreP:0.0100\n",
      "Episode:952 meanR:21.2400 R:11.0 rate:0.0220 loss:2799399.7500 exploreP:0.0100\n",
      "Episode:953 meanR:18.4200 R:11.0 rate:0.0220 loss:3440938.2500 exploreP:0.0100\n",
      "Episode:954 meanR:15.8700 R:11.0 rate:0.0220 loss:3367515.7500 exploreP:0.0100\n",
      "Episode:955 meanR:15.8800 R:11.0 rate:0.0220 loss:3375184.7500 exploreP:0.0100\n",
      "Episode:956 meanR:15.9100 R:13.0 rate:0.0260 loss:3771283.7500 exploreP:0.0100\n",
      "Episode:957 meanR:15.9300 R:11.0 rate:0.0220 loss:3902995.2500 exploreP:0.0100\n",
      "Episode:958 meanR:15.9800 R:13.0 rate:0.0260 loss:3450826.5000 exploreP:0.0100\n",
      "Episode:959 meanR:16.0200 R:13.0 rate:0.0260 loss:2693654.2500 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:960 meanR:16.0600 R:12.0 rate:0.0240 loss:3401676.7500 exploreP:0.0100\n",
      "Episode:961 meanR:16.0900 R:13.0 rate:0.0260 loss:2809505.2500 exploreP:0.0100\n",
      "Episode:962 meanR:16.1300 R:13.0 rate:0.0260 loss:3028194.2500 exploreP:0.0100\n",
      "Episode:963 meanR:16.1600 R:12.0 rate:0.0240 loss:2997828.2500 exploreP:0.0100\n",
      "Episode:964 meanR:16.1800 R:11.0 rate:0.0220 loss:3762845.7500 exploreP:0.0100\n",
      "Episode:965 meanR:16.1900 R:12.0 rate:0.0240 loss:3419491.2500 exploreP:0.0100\n",
      "Episode:966 meanR:16.2200 R:12.0 rate:0.0240 loss:2885849.7500 exploreP:0.0100\n",
      "Episode:967 meanR:16.2600 R:13.0 rate:0.0260 loss:3195573.2500 exploreP:0.0100\n",
      "Episode:968 meanR:16.2700 R:11.0 rate:0.0220 loss:2297481.7500 exploreP:0.0100\n",
      "Episode:969 meanR:16.2900 R:13.0 rate:0.0260 loss:3548245.0000 exploreP:0.0100\n",
      "Episode:970 meanR:16.3200 R:12.0 rate:0.0240 loss:3141756.7500 exploreP:0.0100\n",
      "Episode:971 meanR:16.3500 R:13.0 rate:0.0260 loss:3180931.0000 exploreP:0.0100\n",
      "Episode:972 meanR:16.3600 R:11.0 rate:0.0220 loss:3153650.2500 exploreP:0.0100\n",
      "Episode:973 meanR:16.3800 R:12.0 rate:0.0240 loss:3023139.7500 exploreP:0.0100\n",
      "Episode:974 meanR:16.4300 R:13.0 rate:0.0260 loss:3323658.7500 exploreP:0.0100\n",
      "Episode:975 meanR:16.4600 R:13.0 rate:0.0260 loss:2479716.5000 exploreP:0.0100\n",
      "Episode:976 meanR:16.4900 R:12.0 rate:0.0240 loss:2859246.7500 exploreP:0.0100\n",
      "Episode:977 meanR:16.5100 R:13.0 rate:0.0260 loss:2356272.7500 exploreP:0.0100\n",
      "Episode:978 meanR:16.5600 R:13.0 rate:0.0260 loss:2845915.0000 exploreP:0.0100\n",
      "Episode:979 meanR:16.6000 R:13.0 rate:0.0260 loss:2739252.5000 exploreP:0.0100\n",
      "Episode:980 meanR:16.6000 R:9.0 rate:0.0180 loss:2889160.5000 exploreP:0.0100\n",
      "Episode:981 meanR:16.6300 R:13.0 rate:0.0260 loss:2197890.5000 exploreP:0.0100\n",
      "Episode:982 meanR:16.6500 R:12.0 rate:0.0240 loss:3452968.0000 exploreP:0.0100\n",
      "Episode:983 meanR:16.6900 R:12.0 rate:0.0240 loss:3015564.2500 exploreP:0.0100\n",
      "Episode:984 meanR:16.7200 R:13.0 rate:0.0260 loss:2950987.0000 exploreP:0.0100\n",
      "Episode:985 meanR:16.7500 R:13.0 rate:0.0260 loss:3800872.2500 exploreP:0.0100\n",
      "Episode:986 meanR:16.7800 R:13.0 rate:0.0260 loss:2783996.2500 exploreP:0.0100\n",
      "Episode:987 meanR:16.8100 R:13.0 rate:0.0260 loss:2221269.0000 exploreP:0.0100\n",
      "Episode:988 meanR:16.8600 R:14.0 rate:0.0280 loss:3811329.2500 exploreP:0.0100\n",
      "Episode:989 meanR:16.8900 R:11.0 rate:0.0220 loss:3066188.2500 exploreP:0.0100\n",
      "Episode:990 meanR:16.9100 R:11.0 rate:0.0220 loss:2007581.8750 exploreP:0.0100\n",
      "Episode:991 meanR:16.9200 R:11.0 rate:0.0220 loss:3046680.7500 exploreP:0.0100\n",
      "Episode:992 meanR:16.9200 R:12.0 rate:0.0240 loss:2513265.7500 exploreP:0.0100\n",
      "Episode:993 meanR:16.9600 R:13.0 rate:0.0260 loss:2973182.2500 exploreP:0.0100\n",
      "Episode:994 meanR:17.0000 R:13.0 rate:0.0260 loss:2786501.2500 exploreP:0.0100\n",
      "Episode:995 meanR:17.0300 R:13.0 rate:0.0260 loss:2681533.5000 exploreP:0.0100\n",
      "Episode:996 meanR:17.0700 R:14.0 rate:0.0280 loss:2937010.7500 exploreP:0.0100\n",
      "Episode:997 meanR:17.1000 R:13.0 rate:0.0260 loss:2307081.0000 exploreP:0.0100\n",
      "Episode:998 meanR:17.1200 R:11.0 rate:0.0220 loss:3694855.7500 exploreP:0.0100\n",
      "Episode:999 meanR:17.1400 R:12.0 rate:0.0240 loss:3119582.7500 exploreP:0.0100\n",
      "Episode:1000 meanR:17.1700 R:12.0 rate:0.0240 loss:3019354.0000 exploreP:0.0100\n",
      "Episode:1001 meanR:17.2200 R:14.0 rate:0.0280 loss:3112839.5000 exploreP:0.0100\n",
      "Episode:1002 meanR:17.2400 R:12.0 rate:0.0240 loss:2361037.0000 exploreP:0.0100\n",
      "Episode:1003 meanR:17.2600 R:12.0 rate:0.0240 loss:2705503.7500 exploreP:0.0100\n",
      "Episode:1004 meanR:17.3000 R:15.0 rate:0.0300 loss:2402757.7500 exploreP:0.0100\n",
      "Episode:1005 meanR:17.3300 R:14.0 rate:0.0280 loss:2795909.7500 exploreP:0.0100\n",
      "Episode:1006 meanR:17.3600 R:14.0 rate:0.0280 loss:3367367.5000 exploreP:0.0100\n",
      "Episode:1007 meanR:17.3900 R:13.0 rate:0.0260 loss:2302837.5000 exploreP:0.0100\n",
      "Episode:1008 meanR:17.4100 R:12.0 rate:0.0240 loss:2787228.2500 exploreP:0.0100\n",
      "Episode:1009 meanR:17.4200 R:12.0 rate:0.0240 loss:3512348.2500 exploreP:0.0100\n",
      "Episode:1010 meanR:17.4400 R:12.0 rate:0.0240 loss:3518814.7500 exploreP:0.0100\n",
      "Episode:1011 meanR:17.3100 R:14.0 rate:0.0280 loss:3154332.7500 exploreP:0.0100\n",
      "Episode:1012 meanR:17.3500 R:14.0 rate:0.0280 loss:2659306.5000 exploreP:0.0100\n",
      "Episode:1013 meanR:17.3700 R:14.0 rate:0.0280 loss:3175886.2500 exploreP:0.0100\n",
      "Episode:1014 meanR:17.4000 R:14.0 rate:0.0280 loss:3259930.7500 exploreP:0.0100\n",
      "Episode:1015 meanR:17.4400 R:15.0 rate:0.0300 loss:3198715.5000 exploreP:0.0100\n",
      "Episode:1016 meanR:17.3300 R:16.0 rate:0.0320 loss:3262472.0000 exploreP:0.0100\n",
      "Episode:1017 meanR:17.3700 R:16.0 rate:0.0320 loss:3228735.0000 exploreP:0.0100\n",
      "Episode:1018 meanR:17.2500 R:14.0 rate:0.0280 loss:2479577.5000 exploreP:0.0100\n",
      "Episode:1019 meanR:17.1500 R:16.0 rate:0.0320 loss:3282675.0000 exploreP:0.0100\n",
      "Episode:1020 meanR:17.1600 R:13.0 rate:0.0260 loss:2765491.7500 exploreP:0.0100\n",
      "Episode:1021 meanR:12.3100 R:15.0 rate:0.0300 loss:2949373.5000 exploreP:0.0100\n",
      "Episode:1022 meanR:12.3300 R:14.0 rate:0.0280 loss:2287434.2500 exploreP:0.0100\n",
      "Episode:1023 meanR:12.3600 R:14.0 rate:0.0280 loss:3330231.5000 exploreP:0.0100\n",
      "Episode:1024 meanR:12.4000 R:15.0 rate:0.0300 loss:3383022.2500 exploreP:0.0100\n",
      "Episode:1025 meanR:12.4300 R:16.0 rate:0.0320 loss:2481545.5000 exploreP:0.0100\n",
      "Episode:1026 meanR:12.4700 R:17.0 rate:0.0340 loss:3144183.2500 exploreP:0.0100\n",
      "Episode:1027 meanR:12.5200 R:16.0 rate:0.0320 loss:3087551.0000 exploreP:0.0100\n",
      "Episode:1028 meanR:12.6200 R:21.0 rate:0.0420 loss:3378443.0000 exploreP:0.0100\n",
      "Episode:1029 meanR:12.7000 R:19.0 rate:0.0380 loss:3034980.2500 exploreP:0.0100\n",
      "Episode:1030 meanR:12.7500 R:18.0 rate:0.0360 loss:2600754.7500 exploreP:0.0100\n",
      "Episode:1031 meanR:12.8600 R:22.0 rate:0.0440 loss:2533879.0000 exploreP:0.0100\n",
      "Episode:1032 meanR:13.0000 R:25.0 rate:0.0500 loss:2709033.2500 exploreP:0.0100\n",
      "Episode:1033 meanR:13.1900 R:29.0 rate:0.0580 loss:2697269.5000 exploreP:0.0100\n",
      "Episode:1034 meanR:13.3400 R:27.0 rate:0.0540 loss:3123184.5000 exploreP:0.0100\n",
      "Episode:1035 meanR:14.3000 R:107.0 rate:0.2140 loss:2557915.0000 exploreP:0.0100\n",
      "Episode:1036 meanR:15.3500 R:116.0 rate:0.2320 loss:2914095.2500 exploreP:0.0100\n",
      "Episode:1037 meanR:16.4100 R:118.0 rate:0.2360 loss:2746781.0000 exploreP:0.0100\n",
      "Episode:1038 meanR:17.6300 R:133.0 rate:0.2660 loss:3062143.0000 exploreP:0.0100\n",
      "Episode:1039 meanR:18.9500 R:144.0 rate:0.2880 loss:2808449.5000 exploreP:0.0100\n",
      "Episode:1040 meanR:20.4700 R:163.0 rate:0.3260 loss:2961784.0000 exploreP:0.0100\n",
      "Episode:1041 meanR:22.1600 R:179.0 rate:0.3580 loss:2899507.2500 exploreP:0.0100\n",
      "Episode:1042 meanR:24.0500 R:200.0 rate:0.4000 loss:2856871.2500 exploreP:0.0100\n",
      "Episode:1043 meanR:25.7900 R:184.0 rate:0.3680 loss:3006623.7500 exploreP:0.0100\n",
      "Episode:1044 meanR:28.0500 R:237.0 rate:0.4740 loss:3083096.5000 exploreP:0.0100\n",
      "Episode:1045 meanR:30.9500 R:302.0 rate:0.6040 loss:3141637.7500 exploreP:0.0100\n",
      "Episode:1046 meanR:34.8300 R:401.0 rate:0.8020 loss:3188689.0000 exploreP:0.0100\n",
      "Episode:1047 meanR:37.7700 R:305.0 rate:0.6100 loss:3146670.2500 exploreP:0.0100\n",
      "Episode:1048 meanR:41.0300 R:338.0 rate:0.6760 loss:3341556.0000 exploreP:0.0100\n",
      "Episode:1049 meanR:45.9200 R:500.0 rate:1.0000 loss:3269501.5000 exploreP:0.0100\n",
      "Episode:1050 meanR:50.8100 R:500.0 rate:1.0000 loss:3097647.5000 exploreP:0.0100\n",
      "Episode:1051 meanR:55.7000 R:500.0 rate:1.0000 loss:3188933.5000 exploreP:0.0100\n",
      "Episode:1052 meanR:60.5900 R:500.0 rate:1.0000 loss:3202309.0000 exploreP:0.0100\n",
      "Episode:1053 meanR:65.4800 R:500.0 rate:1.0000 loss:3149658.5000 exploreP:0.0100\n",
      "Episode:1054 meanR:70.3700 R:500.0 rate:1.0000 loss:3093525.5000 exploreP:0.0100\n",
      "Episode:1055 meanR:75.2600 R:500.0 rate:1.0000 loss:3221518.7500 exploreP:0.0100\n",
      "Episode:1056 meanR:80.1300 R:500.0 rate:1.0000 loss:3141059.5000 exploreP:0.0100\n",
      "Episode:1057 meanR:85.0200 R:500.0 rate:1.0000 loss:3047247.7500 exploreP:0.0100\n",
      "Episode:1058 meanR:89.8900 R:500.0 rate:1.0000 loss:2936498.7500 exploreP:0.0100\n",
      "Episode:1059 meanR:94.7600 R:500.0 rate:1.0000 loss:2977852.0000 exploreP:0.0100\n",
      "Episode:1060 meanR:99.6400 R:500.0 rate:1.0000 loss:2800667.2500 exploreP:0.0100\n",
      "Episode:1061 meanR:104.5100 R:500.0 rate:1.0000 loss:2779503.0000 exploreP:0.0100\n",
      "Episode:1062 meanR:109.3800 R:500.0 rate:1.0000 loss:2706969.0000 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1063 meanR:114.2600 R:500.0 rate:1.0000 loss:2448441.7500 exploreP:0.0100\n",
      "Episode:1064 meanR:118.1400 R:399.0 rate:0.7980 loss:2411065.5000 exploreP:0.0100\n",
      "Episode:1065 meanR:123.0200 R:500.0 rate:1.0000 loss:2368356.2500 exploreP:0.0100\n",
      "Episode:1066 meanR:125.3800 R:248.0 rate:0.4960 loss:2411209.2500 exploreP:0.0100\n",
      "Episode:1067 meanR:130.2500 R:500.0 rate:1.0000 loss:2299520.0000 exploreP:0.0100\n",
      "Episode:1068 meanR:135.1400 R:500.0 rate:1.0000 loss:2153444.2500 exploreP:0.0100\n",
      "Episode:1069 meanR:139.3200 R:431.0 rate:0.8620 loss:2053801.2500 exploreP:0.0100\n",
      "Episode:1070 meanR:142.4100 R:321.0 rate:0.6420 loss:2084761.1250 exploreP:0.0100\n",
      "Episode:1071 meanR:147.2800 R:500.0 rate:1.0000 loss:2067261.2500 exploreP:0.0100\n",
      "Episode:1072 meanR:150.2700 R:310.0 rate:0.6200 loss:1988757.8750 exploreP:0.0100\n",
      "Episode:1073 meanR:153.4300 R:328.0 rate:0.6560 loss:1916743.0000 exploreP:0.0100\n",
      "Episode:1074 meanR:157.1000 R:380.0 rate:0.7600 loss:1829566.6250 exploreP:0.0100\n",
      "Episode:1075 meanR:159.1600 R:219.0 rate:0.4380 loss:1796721.8750 exploreP:0.0100\n",
      "Episode:1076 meanR:161.0600 R:202.0 rate:0.4040 loss:1763545.6250 exploreP:0.0100\n",
      "Episode:1077 meanR:163.0600 R:213.0 rate:0.4260 loss:1816118.3750 exploreP:0.0100\n",
      "Episode:1078 meanR:164.9000 R:197.0 rate:0.3940 loss:1834575.1250 exploreP:0.0100\n",
      "Episode:1079 meanR:169.2300 R:446.0 rate:0.8920 loss:1631101.8750 exploreP:0.0100\n",
      "Episode:1080 meanR:171.1800 R:204.0 rate:0.4080 loss:1723624.1250 exploreP:0.0100\n",
      "Episode:1081 meanR:173.0800 R:203.0 rate:0.4060 loss:1604411.0000 exploreP:0.0100\n",
      "Episode:1082 meanR:175.9100 R:295.0 rate:0.5900 loss:1641636.6250 exploreP:0.0100\n",
      "Episode:1083 meanR:178.3500 R:256.0 rate:0.5120 loss:1659258.2500 exploreP:0.0100\n",
      "Episode:1084 meanR:181.1400 R:292.0 rate:0.5840 loss:1578043.5000 exploreP:0.0100\n",
      "Episode:1085 meanR:184.4200 R:341.0 rate:0.6820 loss:1534274.5000 exploreP:0.0100\n",
      "Episode:1086 meanR:186.6600 R:237.0 rate:0.4740 loss:1388389.5000 exploreP:0.0100\n",
      "Episode:1087 meanR:190.1900 R:366.0 rate:0.7320 loss:1415785.1250 exploreP:0.0100\n",
      "Episode:1088 meanR:192.1300 R:208.0 rate:0.4160 loss:1352935.1250 exploreP:0.0100\n",
      "Episode:1089 meanR:194.6200 R:260.0 rate:0.5200 loss:1220394.1250 exploreP:0.0100\n",
      "Episode:1090 meanR:197.3900 R:288.0 rate:0.5760 loss:1112019.3750 exploreP:0.0100\n",
      "Episode:1091 meanR:199.9200 R:264.0 rate:0.5280 loss:996189.1875 exploreP:0.0100\n",
      "Episode:1092 meanR:202.3400 R:254.0 rate:0.5080 loss:934503.4375 exploreP:0.0100\n",
      "Episode:1093 meanR:205.3600 R:315.0 rate:0.6300 loss:776380.2500 exploreP:0.0100\n",
      "Episode:1094 meanR:209.6900 R:446.0 rate:0.8920 loss:808541.5625 exploreP:0.0100\n",
      "Episode:1095 meanR:212.1300 R:257.0 rate:0.5140 loss:787010.1250 exploreP:0.0100\n",
      "Episode:1096 meanR:216.9900 R:500.0 rate:1.0000 loss:712803.6875 exploreP:0.0100\n",
      "Episode:1097 meanR:219.1800 R:232.0 rate:0.4640 loss:635680.6875 exploreP:0.0100\n",
      "Episode:1098 meanR:222.0400 R:297.0 rate:0.5940 loss:561107.9375 exploreP:0.0100\n",
      "Episode:1099 meanR:226.9200 R:500.0 rate:1.0000 loss:526815.0625 exploreP:0.0100\n",
      "Episode:1100 meanR:231.8000 R:500.0 rate:1.0000 loss:468783.5625 exploreP:0.0100\n",
      "Episode:1101 meanR:236.6600 R:500.0 rate:1.0000 loss:426499.4062 exploreP:0.0100\n",
      "Episode:1102 meanR:240.6400 R:410.0 rate:0.8200 loss:405267.3438 exploreP:0.0100\n",
      "Episode:1103 meanR:243.7800 R:326.0 rate:0.6520 loss:388988.2188 exploreP:0.0100\n",
      "Episode:1104 meanR:247.2000 R:357.0 rate:0.7140 loss:346210.0938 exploreP:0.0100\n",
      "Episode:1105 meanR:252.0600 R:500.0 rate:1.0000 loss:325302.8438 exploreP:0.0100\n",
      "Episode:1106 meanR:256.9200 R:500.0 rate:1.0000 loss:298963.7500 exploreP:0.0100\n",
      "Episode:1107 meanR:261.7900 R:500.0 rate:1.0000 loss:284386.6875 exploreP:0.0100\n",
      "Episode:1108 meanR:266.6700 R:500.0 rate:1.0000 loss:255009.3750 exploreP:0.0100\n",
      "Episode:1109 meanR:271.5500 R:500.0 rate:1.0000 loss:247620.4375 exploreP:0.0100\n",
      "Episode:1110 meanR:276.4300 R:500.0 rate:1.0000 loss:239076.2812 exploreP:0.0100\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(1111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "        num_step = 0 # each episode\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done), -1])\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Rating the last played episode\n",
    "            if done is True:\n",
    "                rate = total_reward/ goal # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.buffer[-1-idx][5] == -1: # double-check if it is empty and it is not rated!\n",
    "                        memory.buffer[-1-idx][5] = rate # rate each SA pair\n",
    "                        \n",
    "            # Rating and training the memory\n",
    "            #rates = np.array(memory.buffer)[:, 5]\n",
    "            #rated_mem = np.array(memory.buffer)[rates >= (max(rates)*0.1)]\n",
    "            #rated_mem = np.array(memory.buffer)\n",
    "            #batch = sample(ListArr=rated_mem, batch_size=batch_size)\n",
    "            batch = sample(ListArr=memory.buffer, batch_size=batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            #rates = np.array([each[5] for each in batch])\n",
    "            #nextQs_logits = sess.run(model.Qs_logits, feed_dict = {model.states: next_states})\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict = {model.states: next_states})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average losses')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJztvXucZGdZ7/t91lp16+rp29wyV2YymUkIkAvOJpGgm8glgGC8C4pkK4oewxG87LMBj0d0H/f2IFu2HJEjShTcSAQFjBAJAQMISshEQsiVTDIzmfv0zPT0ra5rref8sdaqru6u7q6+VFdV9/P9fOrTVW+tqnrq0u9vPZf3eUVVMQzDMIxmcdptgGEYhtFdmHAYhmEYi8KEwzAMw1gUJhyGYRjGojDhMAzDMBaFCYdhGIaxKEw4DMMwjEVhwmEYhmEsChMOwzAMY1F47TagFWzatEn37NnTbjMMwzC6igcffPC8qm5e6Lg1KRx79uzh0KFD7TbDMAyjqxCRY80cZ6EqwzAMY1GYcBiGYRiLwoTDMAzDWBQmHIZhGMaiMOEwDMMwFoUJh2EYhrEoTDgMwzCMRWHCYXQtYRgyNjbWbjMMY92xJhcAGuuDc+fOMTo6SiqVIpfLtdscw1g3tMzjEJFdInKfiDwmIo+KyNvi8XeLyEkReSi+vKbuMe8UkcMi8qSI3FI3/qp47LCIvKNVNhvdRbVaBSLPo9M4fvw4zz77bLvNMIyW0EqPwwd+Q1X/XUQ2AA+KyL3xfe9T1ffWHywiVwOvB54HbAe+KCIH4rs/ALwCOAE8ICJ3qepjLbTd6AJUFQARabMlsykUCu02wTBaRsuEQ1VPA6fj6+Mi8jiwY56H3Arcqapl4IiIHAZeFN93WFWfARCRO+NjTTgMoDOFwzDWMquSHBeRPcD1wP3x0FtF5GERuUNEBuOxHcDxuoediMfmGjfWOYnH0cmUy+V2m2AYK07LhUNEeoG/B96uqmPAB4F9wHVEHsn/WKHXeYuIHBKRQ8PDwyvxlEaHkwhHJwuI5TmMtUhLhUNEUkSi8TFV/RSAqp5V1UBVQ+DPmQpHnQR21T18Zzw21/g0VPVDqnpQVQ9u3rxgO3ljDdANwtGJiXvDWC6trKoS4MPA46r6R3Xj2+oO+xHgkfj6XcDrRSQjInuB/cA3gQeA/SKyV0TSRAn0u1plt9F9dLJwGMZapJVVVTcBPwt8R0QeisfeBbxBRK4DFDgK/BKAqj4qIp8gSnr7wO2qGgCIyFuBewAXuENVH22h3UaX0A0eh2GsRVpZVfU1oFG5y93zPOb3gd9vMH73fI8z1iedKhyJPa7rEgQBQRDgum6brTKMlcNajhhdS6cLh+d5nB4t8b4vPE6h4rfZKsNYOazliGGsMIlwpFIpPn7/s3z5ZEhPLsuvvPSKNltmGCuDeRxG19LpHofjejw9PIFDyP3PXGyzVeubMAw5evSoratZIUw4jK6lU4UjKcG9WAwo+yGuKKdHi222an1TKBQol8ucP3++3aasCUw4jK6lU4UjsedSKUCB5wxlOTlS7Dg7DWOpmHAYXU+nTcg1j2PSJ0S4akueyUrAWMkS5MbawITD6Eo6TSzqSWy7WKgQ4HDFph4ATl2ycFU7qFarHf176UZMOIyupJMngsS2sZJPoMKeoQxgwtEOfN/nmWeesdzGCmPCYXQl3SAck5UQcV0GstHivwuTlXaatS7x/Sg8WKnYZ7+SmHAYxgqT5DgKlYB0KkVPShCUSwWbvIy1gQmH0ZXUexyd5n0k9kyUA7KZNBnPYYc3wUih2mbLDGNlMOEwupJOE4t6Eo9johKQS6cQEfozjnkcxprBhMMwVpggCACYrARks1FiPJ9xGS2ax2GsDUw4jK6k0z0O13UpVENymTS5XA4vnWWiHLTbNMNYEUw4jK6kk3McQRDgOA7lakjGc3Fdl56UMFm2BYDG2sCEwzBWmGT/jbIfkEk5iAhZzzHhMNYMJhxGV9JpXkY9YRhGHocfkvEcHMchl3KYMOEw1ggmHEZX0snCoaqISCwcLiJCzjPhMNYOJhxGV9LJOY7E46jEHoeIkE27Fqoy1gwmHIaxwkyFqqIch+M45DyhGihl3yqrjO7HhMPoSjrNy6hnWqjKjTyOjOcAyqSV5BprABMOoyvpZOEIw5BAQRUyqagcN5tycVALVxlrAhMOw1hBVBVVxQ8jYUuqqhLhsAS5sRYw4TC6kk5Njie2VKN2VWQ8xzwOY81hwmEYK0hNOILE43Bjj8Mxj8NYM5hwGF1JJ3kZ9cwSjriqKuu5iCXHjTWCCYdhrCCJcFSCKFZVW8eRchCwUJWxJjDhMLqeTvI+Znoc6ZpwuIhYqMpYG5hwGF1JJ4lFIyp1OY5EOMA8DmNtYMJhGCvIXKEq1xHSrsNExYTD6H5aJhwisktE7hORx0TkURF5Wzw+JCL3ishT8d/BeFxE5P0iclhEHhaRF9Y9123x8U+JyG2tstnoPkSk3SZMoyYc/nSPAyBv/araTqf9XrqVVnocPvAbqno1cCNwu4hcDbwD+JKq7ge+FN8GeDWwP768BfggREID/A5wA/Ai4HcSsTHWLx2/jqOuqiqZrHrSjlVVGWuClgmHqp5W1X+Pr48DjwM7gFuBj8SHfQT44fj6rcBHNeIbwICIbANuAe5V1YuqOgLcC7yqVXYb3UWnnUHOFaoC6Em5lhw31gSrkuMQkT3A9cD9wFZVPR3fdQbYGl/fARyve9iJeGyu8Zmv8RYROSQih4aHh1fUfqPz6CQvo55GoSqIBC6ftl0AjbVBy4VDRHqBvwferqpj9fdp9F+2IjOAqn5IVQ+q6sHNmzevxFMaXUCneRwJ5djjSLmRfSJCznIcxhqhpcIhIiki0fiYqn4qHj4bh6CI/56Lx08Cu+oevjMem2vcMDqOxONImhymvehfTEQsVGWsGVpZVSXAh4HHVfWP6u66C0gqo24D/qFu/E1xddWNwGgc0roHeKWIDMZJ8VfGY4aBiHRU2Gpmcjzl1gmHJceNNYLXwue+CfhZ4Dsi8lA89i7gD4BPiMibgWPAT8b33Q28BjgMFICfA1DViyLyX4EH4uN+T1UvttBuowtIJuhOC1XN9DjqhSOXcpksF9tmm2GsFC0TDlX9GjDXf/XLGhyvwO1zPNcdwB0rZ51htBY/UBwB15nKcWQ8oVg1j8PofmzluNGVdLrHUQkVz5369xKJVo77oeLHiXPD6FZMOIyup5NyHAnVQEnPFA4vErmyb8JhdDcmHEZX06keRxCEtVJcmPI4AEoWrjK6HBMOoyvpRC8D6leOMytUFTfIpWQeh9HlmHAYXU2neRwJ1TCcHaoyj8NYI5hwGF1LJ4pGrRx3RqgKIBVXWJlwGN2OCYfRlXRqd9yEaoNQVbKKvFS1UJXR3bRyAaBhtJyTIwV8FXbubLclEfXdcVOzchxxVZV5HEaXY8JhdC0iwts/8W1UhQeuv6rd5kxjZqgqynFYOa6xNrBQldGVdGJ4Cup6VYXM8jg8y3G0nfHxcc6cOdNuM7oeEw6ja6klxzssRy4icahquseR3C75JhztZHR0tN0mdD0mHMaaoNwhk/FUd9wGOY6ax2GhKqO7MeEwupKpUJUgwGih2k5zpiEi+IHOIxydIXKGsVRMOIw1QadskDTd45gjVGUex6rRqbmwbmdB4RCR94hIn4ikRORLIjIsIm9cDeMMYz5EJN53WClUOucsPslxzG45IoCax2F0Pc14HK+M9wp/LXAUuAL4z600yjAWYuaZZKfsczG1cnx2d1wRIeM6lhw3up5mhCNZ6/GDwCdV1UoSjI4gCJXY5eg4j6NRqAogkxLKFqoyupxmFgB+VkSeAIrA/yYim4FSa80yjIVJtmcFKHRgjmNmqAog57kdUwFmGEtlQY9DVd8BvBg4qKpVov3Ab221YYYxH6oaeRwxnedxzA5VAaRdoeJbwtbobppJjvcAvwJ8MB7aDhxspVGG0QyBKkq0/q/QYTmOuUJVac+halvHGl1OMzmOvwQqRF4HwEng/26ZRYbRJPXzb7HSGaEqmMpxNApVpV014TC6nmaEY5+qvgeoAqhqgY5r8mCsNzo1VKWqqCrVBgsAAYbCcSrW5NDocpoRjoqI5IjrV0RkH1BuqVWG0QRBXUlusYOEI9GztDv7/Mp1ojUehtHNNFNV9TvA54FdIvIx4CbgP7XSKMNoBj/oPI8DpgStUajKc4WCCYfR5SwoHKp6r4j8O3AjUYjqbap6vuWWGcY8qOo0j6NThENVSSJRSRt1gDCMBlOOQzWwqqrVwlqOtIZmqqpuAkqq+jlgAHiXiDyn5ZYZxgJEJ+7R5FzooOR4kntJtoqFKeFwHSw53gGYoCyPZnIcHwQKInIt8OvA08BHW2qVYTRBEE5NwJ3kcSQ5jvrkeD6fB8D1PEuOG11PM8LhayTPtwIfUNUPABtaa5ZhzE9UVTV1u1OS4xBtGwvTQ1We55HNZnFSaUuOG11PM8nxcRF5J/BG4PtFxAFSrTXLMBYmCQllPYdyh0zGUe4lul4fqoKpPTksVGV0O814HD9FVH77ZlU9A+wE/nChB4nIHSJyTkQeqRt7t4icFJGH4str6u57p4gcFpEnReSWuvFXxWOHReQdi3p3xprGj+PU2ZRDtYPCP0kPLc+ZLRyeA1VrOdJ2LMexPJryOIA/VtVARA4AVwEfb+JxfwX8CbPzIe9T1ffWD4jI1cDrgecRtTT5YvxaAB8AXgGcAB4QkbtU9bEmXt9Yw9QvAMx4DsUOOYuPqqqSctzZ6zhSrkM16JzdCg1jKTTjcXwVyIjIDuALwM8SicK8qOpXgYtN2nErcKeqllX1CHAYeFF8Oayqz6hqBbgTa7BoxPhh1Ksq47nTOuW2m1pVldvI47AFgO3kxEiB+544124zup5mhEPiNiM/Cvypqv4E8PxlvOZbReThOJQ1GI/tAI7XHXMiHptr3FjnzPQ4OqVSqT7H0cjj8CzH0VZ+77OP87H7n62VRxtLoynhEJHvBX4G+NwiHteIDwL7gOuA08D/WOLzzEJE3iIih0Tk0PDw8Eo9rdHB1IQj5XbUZJx4P6m5PI4OEbn1wMxcRhh/N7bv+/JoRgDeDrwT+LSqPioilwP3LeXFVPWsqgaqGgJ/ThSKgqjj7q66Q3fGY3ONN3ruD6nqQVU9uHnz5qWYZ3QZ9VVVnSIc9Z5Qag6PI1SmNWg0VoeRQqV2faJDNv7qVprZyOkrqvpDwAdEpDfON/zqUl5MRLbV3fwRIKm4ugt4vYhkRGQvsB/4JvAAsF9E9opImiiBftdSXttYW9QnoSOPo3Mm4mAejyMZ6hShW08cPjdRuz5pwrEsFqyqEpEXEFVGDUU3ZRh4k6o+usDjPg68FNgkIieImiW+VESuI+q0exT4JYDYk/kE8BjgA7erahA/z1uBewAXuGOh1zXWD9NyHEFnTATTqqoalOOm4kWBlSAkm3JX3b71TH2xwmTFKtuWQzPluH8G/Lqq3gcgIi8lCjO9eL4HqeobGgx/eJ7jfx/4/QbjdwN3N2Gnsc5InIxMB4WqAJItxRuGquLJq5PWnawb6r6OybJ9/suhmRxHPhENAFX9MpBvmUWG0QSqWmurnvEctEPyBpHHEXfCbRiqimavTgqtrRfqixImy5V5jjQWohmP4xkR+W3gr+PbbwSeaZ1JhtEcSUgom4rP4oMQ12l/+CdxfuYqxwWssqoNlOs+8/PjJhzLoRmP4+eBzcCn4svmeMww2srMhXadsLBOVanOswAwGeoEW9cb9WI9PF5qoyXdTzMbOY0AS6qiMoxWoar4qniudFzeIGn37jVaxyFJqKozbF1PJMLhucI58ziWxZzCISL/SLzPeCPiEl3DaBtBoLji1EJCnZA3qG/33jg5bsLRLgpVHxEY6EkxXjLhWA7zeRzvnec+w2g7fqi4ruB02Fl8dYGV49A5tq4nhsfKbOrNkPEcWzm+TOYUDlX9ymoaYhiLIVkv4TlSO7PvhLzB9JXjDXIckiTH2+8drQfqW46cGy+zpS9DoRxQrHbOxl/dyFJ7ThlG2wnCOMfhTFVVdQJ+qIhQK72tx4uLvjpB5NYbE2Wfvkwq9jhMOJaDCYfRtfhhlONIJmi/Q3Ic1UBJObP/tabWcWjHJPLXE+VqQDblkHLFhGOZNC0cItLTSkMMYzEkIaHI4+iMUFUSFvFDbZgYByzH0UaK1ZBs2iWdci1UtUwWFA4RebGIPAY8Ed++VkT+tOWWGcYC+KHiOnUJ5w45iw/CcFYpLsTJcddBaL/IrTeqQUgQKtmUS9p1KFVMOJZDMx7H+4BbgAsAqvpt4PtbaZRhNENNODqkHDfxOKrh7MR4gmctR9pCEprKpVzSnkPFN+FYDk2FqlT1+Iwh+9SNtpL0qvIcB7fTkuNB41BVlONwAO0YW9cLSfltNuWScR0LVS2TZnpVHReRFwMqIingbcDjrTXLMBYmiFeOux2W4whCbehxROs4oiat1qtqdUmEOu06pON1HKqKSONclDE/zXgcvwzcTrTX90mibV9vb6VRhtEMfhDideCiukqctG+E63aWd7ReSEKDrgMpzyFUbfuJRjfTTK+q80T7jRtGxxAtAIS0Jx3TxqPmcQThnOW4KUcsOd4G/Lr+YZlYvEuVkIzX/m7K3UgzOwC+v8HwKHBIVf9h5U0yjObwQ6VH3I5LOFdDSHlzeBy1dRydYet6IQiSXRmFtBdVthWrAf2k2mtYl9JMqCpLFJ56Kr5cA+wE3iwi/7OFthnGvPgz1nF0isfhB+GsbWMh8jicOLTWblvXC/VrawBcJ8pxAJYgXwbNJMevAW6q2wP8g8C/AC8BvtNC2wxjTqKqqjBeOR7vx9EhCedqqLP24gBqidiUa8Kx2gS1feCn9kkp2lqOJdOMxzEI9NbdzgNDsZCUW2KVYTSBH4LrUtscqd0tR6Y8jrmT4xCt8Sh3iMitF+pzHOlUlNcwj2PpNONxvAd4SES+TFRJ+P3AfxORPPDFFtpmGHOS7O3tOc5UqCrsjMnYD5X8PB5H2kJVq44f1uU44t+L9ataOs1UVX1YRO4GXhQPvUtVT8XX/3PLLDOMOZiKW0cTQdKqvFM8juocCwAT0p5jwrHKTIWqHFzXKtuWS7NNDkvAaWAEuEJErOWI0TbqJ2jXcXAcQaT9yfGExBOayfQch1VVrSbJSYVb34bfwoVLpply3F8gWi2+E3gIuBH4N+AHWmuaYTSmvlImySWkHKftk/FUjiNaZDYXKVfsbHeVqdaFqqIootbCV8biacbjeBvwH4BjqnozcD1wqaVWGUYTRMIR/YQ9V/A7ZDKuhiGpBps41TwOx7Gz3VUmiH8bniO130yneKjdSDPCUVLVEoCIZFT1CeDK1pplGHMzPVQVjaXc9ucNpuwK5+xVBdHiQPM4Vpf65LgrnbVgtBtppqrqhIgMAJ8B7hWREeBYa80yjLmpX2iXtPZIuVILR7QbP6BhOa5VVa0+9WIOUTnu1I6R9h0slWaqqn4kvvpuEbkP6Ac+31KrDGMeVDXaAVCnOuN6jtP2iWBqP47GHofnRf9uaQfK1nJkVSlWAtKeU9v4S6BjTjS6kXmFQ0Rc4FFVvQpAVb+yKlYZxgLUQg/xBJ3yOqdSaa5yXNeNFp6lXRi3HMeqMlnxyaejz9/tsB0ju5F5cxzx6vAnRWT3KtljGAuiqoSholCLV0dVVZ3hcfjz7Mfhui5pJ2y7reuNQiUgN0M4/A5ZMNqNNNty5FER+ZKI3JVcFnqQiNwhIudE5JG6sSERuVdEnor/DsbjIiLvF5HDIvKwiLyw7jG3xcc/JSK3LeVNGmsLVSUIQZlqqR5VVbXf41BVqoE23HMcks2cnI7pq7VemCz75DNRgMXtsG7K3UgzyfHfXuJz/xXwJ8BH68beAXxJVf9ARN4R3/4vwKuB/fHlBuCDwA0iMgT8DnAQUOBBEblLVUeWaJOxBlBVfJ0qr4TOqaoKNfqhNirHTfCsyeGqU6yGDPVELdRrOQ77DpbMgh5HnNc4CqTi6w8A/97E474KXJwxfCvwkfj6R4Afrhv/qEZ8AxgQkW3ALcC9qnoxFot7gVct+K6MNc2Ux0GtM67nOh2R7IzCHzLnAkCptVVvv63riaof1Nqpi0SdBjrBQ+1WFhQOEflF4O+AP4uHdhCV5i6Frap6Or5+Btha95zH6447EY/NNW6sc4J4gvZcQVVJOe1fAJgIGkx5Qo1IuY6t41hlykFYEw6w1vbLpZkcx+3ATcAYgKo+BWxZ7gtrlElcMckXkbeIyCEROTQ8PLxST2t0IPUex9Q6jvaHqiDyOBSmTVIzSdk6jlWn4s8Ujva3qOlmmhGOsqpWkhsi4rH0Cf9sHIIi/nsuHj8J7Ko7bmc8Ntf4LFT1Q6p6UFUPbt68eYnmGd1AJBzRBB1XuMZ5g/b3qpryOOYJVblipaCrTMWfvr+454hVVS2DZoTjKyLyLiAnIq8APgn84xJf7y4gqYy6DfiHuvE3xdVVNwKjcUjrHuCVIjIYV2C9Mh4z1jHRXhwKSC3HkXKdjpgIEkGbr626Z00OV5Wk0q2+RDrjObYD4DJopqrqHcCbibaJ/SXgbuAvFnqQiHwceCmwSUROEFVH/QHwCRF5M1Hbkp+MD78beA1wGCgAPwegqhdF5L8SJeQBfk9VZybcjXVGdGYfreOYqqoSqm1ejV0vaI3WcSR4cSdfVa21ITFaQyIaEIlFQm/GY6Lst8usrqcZ4fhhooqnP1/ME6vqG+a462UNjlWiXEqj57kDuGMxr22sfUKdvnI8qqpq/1l8WFvR3lgQRIRUPH9VAyXtmXC0msS7q/cC8xmX8ZIJx1JpJlT1OuC7IvLXIvLaOMdhGG1DVfEDjRYAJh6H0/4FgMnZbRSqmsfjsLbeq0o53iK2Pjm+IesxVqq2y6Sup5l1HD8HXEGU23gD8LSILBiqMoxWkYSqgGk5jnZPxNECQI3tmSfHUVu5bMKxGhRj4ehJT53z9mZS5nEsg6a8B1Wtisg/EVVT5YjCV7/QSsMMYy6izrhxjsONbnsdUl7ph817HJYgXx0mypFwJE0OAXozLmNF8ziWSjMLAF8tIn8FPAX8GFFi/LIW22UY8zKVHI8mg5Tb/vLKpEwYZN5y3KQdifWrWh0KcRK8JzN1njyUT3OxUGn7otFupRmP403A3wK/pKrlFttjGAsyFaoSkrB1yu2M7ViTeWi+pHeynKATPKT1wGQlEo56j2NjbxpVOD9R4bL+bLtM61qayXG8QVU/k4iGiLxERD7QetMMozFR2Ws4LSTkdcAOgPV2zeVxUHef5ThWh2S9Rq7O49jUmwHg7FipLTZ1O03lOETkeuCngZ8AjgCfaqVRhjEfUyu04/USYdR6pBPCDkGQJMfnb3IIFqpaLZLPOV0n5r2x92FrOZbGnMIhIgeIqqjeAJwnCleJqt68SrYZRkOSclyIE81hNFGHGuU+3HkaDLbcrtoCwPlXjoN5HKuFHyoI1Gt5Iuwm3ktjPo/jCeBfgNeq6mEAEfm1VbHKMBYg2To25Qgh0ydj13HneWRrmbkwsRFToSrLcbSaRMxTjkxbpZ+s6Sj71nZkKcyX4/hR4DRwn4j8uYi8DLBlrkbbScpxIdprHKbWTfih4vs+hw8fplxemVqO8fFxisViU3YlJ7BzeRwWqlp9qkE4K3Q4JRz2HSyFOYUjToi/HrgKuA94O7BFRD4oIq9cLQMNYyZTIaGps/dkYqj6IadOnSIIAkZGlr9RZBhGz3f8+PGFD4YpQZvX47BQ1WpSDZTAzUwbS0qiTTiWRjNVVZOq+jeq+jqitubfItru1TDaQv2Zvec6tQWAANUwbMo7WMxr1f9d6NhkRft8wpHkYGwB4OpQDULK3oZpY+ZxLI9melXVUNWReN+LWY0KDWO1SMpeXUdqk3ByBrnS/aqaEYx6giaaHKYtOb6q+DN2/4M64ahajmMpLEo4DKNT8MPpeYRUBzQOrPeE0k14HCYcq0M11FnCkfx2zOtbGiYcRteRlOPWT85TVVUd4nHMUxJcs7XN+4esF/wgnLYXB0xtOVyumnAsBRMOo+tIkuMz95AGpvWrWolNkhYjHNO79s792sl9ZTvbbSmVSoVKpUI1mL5tLIDjCGnXsRzHErG9NYyuo1ab7zo1cZiqqlLSbbTNDyNPaC7Rqm9y2Am9tdYyR44cAeINs3Kzz5HTnmMl0UvEPA6jK5m5h3RydaV3AVyKxzFXYjzBchyrS6HisyHnMTQ0VBtTVTKeYwsAl4gJh9F1JEnoacnxOGbd7qqqxBOaD9sBcHUpVEL6syk2b97MgQMHauMZ8ziWjAmH0XVM5Tim4tapFShxLRQKnD9/fnl26fy7/wEkd1es5UjLUVUmyz59udSs+9Ke5TiWigmH0XXUhKNugm50Fr/Y5Pjx48e5cOHCrNdajF3BAh6HiMRrOdq/1e16oBKEBKHSn4syX/W/iYznWqhqiZhwGF2HqlKdMUHXelW1MFS1kIgkgrZQjkNVSbliYZJVoFiJPuMN2el1QKpKJmWhqqViwmF0JTMb17VqAeBiPQ4/nL/dSELKM49jNUjKszOp2R2TrRx36ZhwGF1H5HFEk29CLcexArsAziUWzXocqXl2/6svHzbhaD1JM8z6NT/Jd5BJmXAsFRMOo+tQVXx/xsrxWlXV1EQwMjJCtVpd0vMvdH1Ou8KpVu/zkXYdKrZyvOVM7cg42+PIeK6FqpaICYfRdUxVVdWV43qNQ1VLaa2+HOGoNFil3Oi4tIWqVoXahl8z8k6qGoeqgmljpZLtQd4MJhxG16GqVMJw2srxRENWolfVYtdu1D+uGuisvkj1TIWqxIRjFUhyHKkG38nMUNW5c+c4duwYlUpl1ezrVkw4jK7E96dXVSXluH4Lk+PNeRyzO7E2IuVaRc9qkISq6sOatRzHjAWAyT4u4Qp3H1iLmHAYXUfkcdCwHHelPY5FC4c/v8eRHJdyHWvp3UKS78qfY2OtJFxY73Ekj1mJ5phrHRMOo+tI1nFkGnTHrQTLX9C1nKqqarhwjgOwBYAtJvmuprbynS0GGc/FqRZnhaZMOBamLcIhIkdF5Dsi8pCIHIqjMaIwAAAgAElEQVTHhkTkXhF5Kv47GI+LiLxfRA6LyMMi8sJ22Gx0BqpayyXUTwbeCuwAmEwYw8PDFAqF2ustxrZydfZuc41eI0qOW1VVq6h5HLE4p+YIVfWGExw7dmzaY5aa41pPtNPjuFlVr1PVg/HtdwBfUtX9wJfi2wCvBvbHl7cAH1x1S42OIfmnrvjhjO64gsjKLACcmJjg+PHj015v5vW5bJvpCc11nCXHW0vN40h2ZGzwnaRcIQiVIPZSTTiap5NCVbcCH4mvfwT44brxj2rEN4ABEdnWDgON9pP0g/IVcnWrgaN9LpYX/mkUomhWOBJPqOxbcrzdjI6O8vTTTwN1VVUNchyZpE1NODVmNEe7hEOBL4jIgyLylnhsq6qejq+fAbbG13cAx+seeyIem4aIvEVEDonIoeHh4VbZbbSZMAwpByEK5NLTcwmeKysSqpqLhYQDoOzrvDmOWjmuZ8nxVjExMVG77s+xlW+xWMStTAKQ/GTM42iedu0A+BJVPSkiW4B7ReSJ+jtVVUVkUd+eqn4I+BDAwYMH7Ztfo6gqlWqIqpBLu7WJOKlU8oOAlfhZ1z9v/WvPZ1dU7bXwOo5k8ZmFqlpPMEfLkXK5DLFw+KFSqVRqZbgmHAvTFo9DVU/Gf88BnwZeBJxNQlDx33Px4SeBXXUP3xmPGeuQqOQ19jhmNK5LubKsXlX1Hkcj4ZiPMAzxQ0VpHE+vp5bjsJYjLSfZnrd+HYfv+8BUpVWpUq1tM2s0x6oLh4jkRWRDch14JfAIcBdwW3zYbcA/xNfvAt4UV1fdCIzWhbSMdUaURwhQhJ6ZoSrHWbEFgAvlOxrdVw0UVWlq5bi1HFkdJisByOy26lDfUXn692oex8K0I1S1Ffh0/A/kAX+jqp8XkQeAT4jIm4FjwE/Gx98NvAY4DBSAn1t9k41OIQxDKnGOIzvT4/BkWSWu84lFECpfe+oc117usq0/19AuPwhRpGEL7/rXUFVSjliOYxWYKFfpSbu1zgL1eLb3+5JZdeFQ1WeAaxuMXwBe1mBcgdtXwTSjC0jWSkQex/Sfb8pxqNY1rfvumXGOHZ7grT+4ZdGvUx+qmij7/ME/Pc6jIy7X7TvH3/zijQ3tqgYhIZBpZj8Oy3GsChMlnw2ZxtNcOhb4pLrt7FiZLzx2hl959Rby+fyq2diNdFI5rmEsSBiGlP2AEJmV46ivqpos+7znnif5i68d4fHTY009d73H8Zdfe5rX/dG9AHzp8XOcGS0jAg8dv1RLuM60qxpq7HE01+TQynFbz3jZJz9DOHp7ewEYyEXjlwpR6/0Hj13kK08Oc+ehZ1fXyC7EhMPoKoIgoOxHHkfvjLh1ynWoxpUxD58YrY1/+/ileZ9TVRkeHq5V1ZwdK/OVJ4e5dP4clWrA0+cm2L2xh9985QEKlYDh8XLD5/DjEFp6Ho+jfiOnUGkoQsbySD7jUJVjFwrsGOyZdn8iHEM9GQAuFqLvc7wUJc3Hiovfw2W9YcJhdBVhGFKsRB5H74wzSc918APl/ESZD39tqkrmqXMTM59mGuPj41y8eLFWbfNbn/5O7b6TI5OMlqoM5dNs7o0mmjNjs/dsCMMwSo4v4HEkJM6Shatax4WJCsVKwNWX75o2nghLLu2Q9hwuTVb55pGL3PvYWQDOT9ieHAthwmF0FUEQUIw9jpmVMilH8IOA87FHsH0gy9a+DCOTze+vMHMiPzo8xlgpoC/rsak3DcCZ0QWEo4kFgOlaU0YTjlZxdrzMuTDP/p3Tc1zJdyAiDPWkuFio8M9PnKvd/9SZcausWgATDqOrCMOQUjXEc2aXvea1QKZ0gWI1SpC/+SWXk894jJWaDz0cOR81N/xPL96D4wgPnxhhtBTQm/UY7ImE6vzE3KGqkPnXcdSHqmBqnYGx8lyIv6ddQ9NDVUFdB+WBfJpDR0c4fG6CjOfw/B19nLhU5PjF4qra2m2YcBhdRRAElHwln/EQkWnVT1kt4Qca1e4D+YxLb9plLI5dN8PZsWjCuGrbBl64e4CvPnGOQJW+XIaeeJvB0QYx8MjjiMtxm+pVtXL7hxiNmSj7gDCUT08bT3IcMH0R6Q9cv58funY7AA+fnD8vtt4x4TC6ijAMKfg6K78B4DoOgSqFSiQUPWmPfDa1qGTn8EQZxxEGe9Ls29yLaiQGfbkMnhO14m70fNHKcQBpzuOI1xBYZVXrKFYCUp4za72P53ls3x4JxI9cP9X27gU7B9g11MNleZeP/+szq2prt2HCYXQVYRhSqIQNVwJ7ogRBtO5CBHIph3zarVXLNMOR4Um29WVxHWHXUI6kQHcgnyEIAgZ6UrXyzZl2VWLvoSe18PIoL/Y4LMfROibLPn3ZVMP7EgHfPpDj/3vj9/D2Vxzg5udeRsp1ePkVvZw48SyXFpEbW2+YcBhdRRAEFKrhLI+jUqngOkKgIccvFNjWn0VEGMh5nJ8oN5XsvDhZ4cmzE1yzqx+AXXEZpwL9+TRBENCfS3GpOHtCUVXKsQj0ZJpIjtuq5ZYzWQ7oyzUn4rf8h+fS0xN939fuHCAMlc8/+GSrTexaTDiMriIMw0g4ZngcqornCEEIZ8bK7Iwn/Y29Gcp+2DAvkZBM5t89O04YKjfu2wRQWzimCJf190QeRy49Z46jFDctzKfnnqxqwhGX7Jaqy9/q1mhMobKwx5GQzWZrY3s35dmQ9Tj0tG3PMBcmHEZXEQQBk5XZHgdEuwD6YUih4pOPz/oHM9FP/NSlhWvzj48UUdfjubu31sYu68ugCgP5LEEQ0JebO1RV9kNEINvEOo4kgV6qmsfRKiYr0ffViPn2XnFE2DXUw6lLhVaZ1vW0az8Ow1g0YRiiqow3yHGoapQcD5VCJaj1scqnIi/gUmF6eKlYLHLhwgV27NhRC2ONFioM9aRwnamJ/7dfezXZnl5c1yUMQwZyHo+dmsvjiLyN+Sal5L6sZx5Hq0g+40LZ57ImPY76Cj2Ajfk0R05Ots7ILsc8DqNrSIRjrBTM8jhGRkZwnSiurUqt5XouPvufWZJ75swZJicnqVSmBGWsNDu0kUm5bMilcN3o+fqzLpcahKpUlZIfzGr1PpOacMSVPkUTjhUn6QBQqEQLNxux0G6Pg/k0I5PVZVW9BUHAqVOnuHRp7ZX2mnAYXUOyarzkK1s2ZIG6s8tCAS/2OAB6UolwRH+jmv4pnNir8H2fQiEKSYyXfPqy3qxEev3ZaH/Wo1AJZk0oYRhSrGrTwpGLPY5ixYRjpSkUCoSqFKtBw+o7aOxx1JOcQMz0VBfDuXPnGB8f5+zZs0t+jk7FhMPoGsIwZLRQIUTY0peZdb9bt690kjxP8g0T8erxSqXCqVOnasedOXOG0dFRytWoeeFgPt1wUkmEpj+u0pmZIA/DkPFyQH/P9MVmM5nayCn6ax7HypKIfiEW5IHenobHLSQcG7IeInBxicLh+z5jY1FX5qeHJxZstNltmHAYXYPv+4wWqoQ4NY+jnnrheP6ByxkcHCTruYDWPI6zZ88yPj4e7TnNVFjj609foFQN+L79G9m4cSODg4P09fUB0z2O5Ax2dEZJrqoyWvQZ6mkcU09InieTbFvaRuGYmJigWl1bnWBrwlEOUKL1N0shKq5QLi5xLcfRo0cBuP/ICP/97if46T//N86Nr53miSYcRtfg+z6XilWCOTwOp+6sce+WflzXxXOFrOfM8hDqzzCDUPnbB45zWX+GvUM5XNdly5YttbyG4zg1j6MvO7fHcanoM5hv1uNob6iqWCxy8uRJTp9eW7swJ8IxGXcP6G+yqmrm7d6MhxCt7QnDcFourBmCIEBV+fS3T5NLuZQrVT556MSinqOTMeEwuoZqtcqlYuRxbO2b7XEkrUbe8KJdZFJubTLYs7GHJ89Ob62e7L0BcOjYRYJQed72/lorCpjeRTW53heX+daX5Kpq5HGUfIYWCFUlAuRK1K+qHaEqVeXs2bOMFKp89fGTs/I/3czMUNVSynEhWv8jRPt5nD17liNHjtS802ZwXZfjI0WeHIGfOLiT79nq8JXvrp11IVaOa3QNk5OTjFaEnrRbq6qqnwBe/tytDOTS/MBVW6ZN9tfvGuRzj5whbLBp0kTZ55OHTrC1L8O7Xn8z6bp2IckkVJ/jCAsjQLTZU0LS4LBQDZv2OFSVbMpti3AUCgUmCkXe8/knGB4vc9czAXf+0k04zvyTaTdQ8zjKPiHStMcxk1zKJe06vO+ex9if2cVzNvYwMTHBwMBA07Y8dKZCSdK8+KodnBwt84nvjhKEOi2k2q2Yx2F0BapKtVrlzETI9oFcbbx+Ati8IcOrX3DZNE8B4Npd/YyVfI5cmF6X//XD53n7nQ9xqVDl51+yl9SMfTSSSchxnNpzDWRdcimXw3WbQ4VhyETZR2FWJ9aZ1AtHLuWueo5jdHSUEydO8OUnh3li1OXaXf08dOwC9zx6ZlXtaBXJd3ZxssK5sJetDUKasLBwAPzAlZvZIGX+292PM1n2+aN/eoRvPTuy4ON83ycIAr5zepLn7+hn28Z+dg9mKVZ8jl5YG2tDTDiMrsD3fVSVZ0fL7NmYr407TuOfcP1kv3swh0vIkZNT28OWqwF/+fWjALxo7xD7NvfOeo7k2PpJRkS4YksvT50bn3bceMkn1Kir7nzUtjUNQ3JptxZSWS1GRkYoVgM+8vA4B/dt4fabr2DHBodPPrg24u+JcJy8VGRjXw8Dc3wfzQjHz9ywm815lyBUPn7oFPd85wRvuuObTC4Q2hsfjzaCevRsgWt29uN5HruHenAJefTU2OLfVAdiwmF0BdVqNRKOkTJ7N02VWM5KavbOFoDBnhTbnTFOnzlDqVRCVfnAl58G4NUvuIzbXvychs9V73Gk01MT0P7NPdM8DlVlouSjDfZ+mEkSQks8jtVMjpfLZcrlMo9cVIaL8LZXPpdsJsPL9g/x1e8Or4lcRyL25yemn2AsBRH4v15zgElN84WnRtnR5zFRqvKXXz8y7+NGR0e5VIELZeGaHQO4rsu2/hwZFx49NbosmzoFEw6jK/B9n4uFKgUfnlM3IdRP9n19fWzfvp39+/dPy3EMxCWy46UqQai89wtP8tipMXrSLj/2wp1s37qFK6+8ctZrbty4kXQ6XeuaunHjRgD2DTicHi0xHG9RG1VUVVGEzRsWLv90HCcSjvTq5jgmJ6MwyT1PjrF7qIcX7h7EdV2u39WHHyr3P3Nh1WxpFbVQ1URlWkhzJs14HEEQsDmfwvE8yurxv998BS/fP8gdXz86Z1dj3/cpl8scHYvuf0HscXiusH9zD4+Zx2EYq0e1WuX0aIkAh8s3Nw5V9fT0TEtk11Z751IgUUuRrz51nifPTLBzqId3/eBza8/diEwmw969e2tluUNDQwDs64smp7u+HS0kDMOQ8xNlQqJ9zhdCRKJQ1SrnOMbGxpisKF9/5iK3XrcdEcF1XZ7T75FNOfzLU+dXzZZWoaqEqlwqVrmsf+Hvohk+9os38f43vojtAzle+/xNXJys8K9PNxbZRJyfGK7Qk3Y5sHVD7fdz5ZY8j50aWxP7mZtwGF1BqVTi6fNFHMfhmp1TlS31Z44z8x3JfcXCJNv7szx49CIfu/8YAL/1mqu4rC9qpd3f39+UDY7j4Hkee4Zy3LS7hz/78mHOT5QJgoDz42U2bciS8eZvOZLYVQtVrZJwVKtVyuUy9z87Rqhw63VR2bHruqRchxt35fnGGvE4TowUGQnSXLl1w4o8556t/bzy+dvJZDIcGBAGM/DZb59qeGy5XMZxHB46FSXGXUdqwrF/c54Lk5VpFXndigmH0fGoKoVCgcfOlbl6W9+0BofzCUfC+fPn2be5lzNjZTKuw+037yPlOuzbt48DBw7UQlHNsGvXLkSEN13Xj1e+xM//1QOMF8ucGi1y+Za+pp4jEY5s2qVQXh3hSFbK3/tMgedt7+OKLdGkumlTtPfI9TvyPHFmnPMT3T2pqSonR4oUNM01O+c/Idi5c2dtUp9JKpWadX3btm14jnDLFb3848OnOHWpOOtxYRgSqvDYqTGu2xWd4IhIfMIRhTHXQp7DhMPoeMrlMqWKz0OnC7xo79C0+5rxOACuvCyaKN/04udw/e5BNm7ciOctfhlTOp1my5Yt7NmY5+3/cTfHTp3lnX//bY6cL3DVtuY9F1VlsCfFyDKa6C2GUqnEufEy3zo5UfM2INp/O5vNct22SDy/+Fh3N+SLKtyqhLBgvimfz7Nv3z72798/674knwVTv6tMJkM+n+fW52+kR8v81qcenvW4IAg4fqlEJQi5ts4zzmQy7OiL+l+thcoqEw6j4ykWizx5Zpxx3+E/Htg87b56sZirKgrghr1D/L9vvpkb9kYTQv3EsFgGBwc5cOAA1+0e5FdvuoxnTg4T4HDzlVuaenyS49iYz3CpWMVfhe1jy+Uy3zw2BiK87trt0+7LZrNs63XZM5Tj09862XJbWkkYhoyVfFKu23Czr5nU58QANm/ezKZNm2onFTNPRvr6+hjqSXHb9YMceurErHUdYRjy8MkxRODGy6dOcjzPI+3Ano158zgMYzWYmJjg0PEx0qnULI/DcZxaM8KZ/+S5XI5cLqqsERGu2ze7nchSERG2b9/OS67YxK+9/Are+L17uemK5sQoCVVt7E2jCiMNdhRcSYIgYGJyknu/e5Eb9g6xrX96tVE2m0VVef0LL+P+Ixe574lzLbWnlSQex0BPZknf8dDQEBs3bqz9lurLsCHyUnp6enjplZvZmg3507isOyEIAh589hLX7OhnY++Ux+M4DmEYcu3Ofh48dqnrE+Rd03JERF4F/DHgAn+hqn/QZpNWBVWd9Q8QBMG0BW6LJQxDqtUqI6NjjBR9xotVKuoQKlQrJYJqlVQmC6oEKuR7suBXqFbKbBwaIJvy6OvJks+myKU9KpUK6fTsduQrwejoKKfPj/KFw+P86PdcUdsAqZ6tW7fS19c365/cdV12797NxYsXa/ft27dvxf5pe3t72bNnD3CUmzdtavr9O46D7/tsjieWs2Olpsp4l8q5c+c4dOQiz4wq73/d3ln39/b2kkql+L7tyucGld+96xGet+PFDTsQdzphGHL0fIHdm7Yt63my2Sx9fX21HFCCiLBr1y7S6bPc8tzNfODfz3L/Mxe44fLopOHSRJHHz07yxpuvmPa4ZAfJG/YO8ZmHTvH08EQtz9SNdIVwiIgLfAB4BXACeEBE7lLVx9pr2dIIw5AwDBERJiYLHB++xKVilbPDFxktVBgtBRTKFVKpVFQNUw2oBTPEAY1u5fsG2b5xA5f1ZRnckKMnnSLlCoFfZWSixPClcUYmq1wYHeNS0edS0WdsskilGjBaqjJRWv6CLxHIeC5pzyGdcnG9NPmU0J/P0JtNk3Yg5UIm38dAPsdlAz1szXvk3JBKEFLwId/Tw9CGHDsGcnjulNegqpw/f57/9cApJjTDL37f5Q1tcByHfH7uxV5JGS2wpLzGfGQyGQ4cOLCoxyShqsvj1epPD0/w/B3N5UcWS7lc5sS5i9z50Hm2b+zjFVdvnXWM67rs3LmTc+fO8Qs3bOW9X3yaH/3Dz3LDVTt5xQt2sTErDPak2LF5kFy6s6eMS5Nljl8q8bM3NBc2nAsRYdu2ucXH8zxuuXoLnzt6hl//xLe5+23fRz4lHDpygYq6vPy5018/ScLfuHcQgHsePWvCsQq8CDisqs8AiMidwK1AxwhHGIYUKz7jpSoThQrjxTKTFZ+xQonJss/YZImJQpFCJWBsYoILExWGJ8pcnKw2bL7nuYIfKClPyLjOrAZ0qlConK/teDcfCvRkM/TlMvTnM2zo9biiJ83QhixDOY/B/g305tI4QOD7KIqIE9vhUChXCUPw/QplP6RUDSiHQqkaUCyWKBVLlCVFqVKhUqlSLlc4fXGcQtmnFChhEOAH87e0CBC8VJr924e4cscQezf14hfH+frjJ/nisz6/+ZoXsGfT8lYCt4rFeloiQqVSoT9fZsircNf9T3Dq1Omox5EqIS5BGBKq4odKGIQEGn03IRCGGt3WeBvabIaelEBQpeQLJT+gXKlSqob4lSLPjpQ4E/Ty4Z+7Zs4Ge+l0mh07dlCpVPj9WzN8/pHTHPruUb75yFQoRgEvlSbfk2XH0AZ2DmSRapHJss+lks9EsVL7PSqCl82zqTdFb8bFQyn5IeVKhUqgZD0hl82Ry3hsyPewpb+H3oxHLuWQ8lyqVZ+qH+CHipLsKe+Sz6UZzOcYyGfo70nRm/GmnWwcGR4nRGrFEK3CdV0yKZffvWU3v/q3D/P2j/wLL9rdx32Pn2XHxj5eMONEIKnMqoyc5lW74eP//C2+8Z2ncAQcQhxx4kWriuO40RYB4uBKiAOIGyXW3Tgn47kS52cEhyjnII6L68D2Tf38/Euf29L33y3CsQM4Xnf7BHDDSr9IEAQcOxbV+Z8eLfGHn3+CIG6ZHS0smlpgpAph9Ism1JBQaSgAM3EdYUPWY0NvL3u39HDjQA/bNw3Ql4YtQwNcNphnU28Gl5BMJlOrwKlvVRGGIb7v4/sBx8+Pcn7SZ6xQpuKHVFURcRnozTGYT7N9qJeN+Uxt/4fVIAkFqWotLDM5WeDiZIlTF8Y5PTJBoapksxn68znKpRIj45McPn2Bw2cv8bnjUSdbBYpuL7/5g9fwC3N4G91IEjYbHbnAy/fk+NdnzvD4sbO4TP1+AgTPiSYKxMF1iCcUcMTBdRTPAVQpVwMKlRBHlIznkEp5ZD0hk/JIeSmeu38Hf/KyA1x12fzlwiLC3r172bmzyg3XXMnZ4Qs8dvwchTDFhO8wMj7BpfEioxOTnL50kS8fL+HjkslkGMp59GfTeK4HAk5QoViZ5NkzPpOVgGoIWc8lm3JIOULV9ylVL1KsBvjB0kKHCoQIac8lm3LxHGGyVEbdFNftbL6L7VLo6enBdV0uywb88g2bufOB4xx+9jS4Hu/6yefNOpnI5/Ns3bqV0dFR3vx9+/nEoeNcnCgRIIQIQRCiQKCA+qAhQRi9xyAE0aB20hCqEoTRHKQaogp+PBehys7NrRcO6YYkjYj8OPAqVf2F+PbPAjeo6lvrjnkL8BaA3bt3f08iAIshDMPa/sAXJytRE7xY5UUERwTHiTYMcuIx14n/kV2HXNojn0nRk0mRz6boyXj0ZtP05VJs3NBDXy5FxnPmXG9gRFu7jk8WOTNeAdfjiq19TS2q6zaCIIhDlspEJSSVcnGIWm6nXBfXkaY8meREor7FSnKC0YqcU0IYhpEXMMc6iMS2+WwIgoAgCCiUqpwdKzBRDihVA6p+SDrtkXJdPCd+P7EHNlGsMFooMV6sMlGsUKj4TJarFCoBfhAShMr3P38Ptx7c04J3PZtkj46KHzBZqtKTy5DPzL8LZCtRVXzfn7YOZTGIyIOqenDB47pEOL4XeLeq3hLffieAqv73RscfPHhQDx06tIoWGoZhdD/NCke3nPo+AOwXkb0ikgZeD9zVZpsMwzDWJV2R41BVX0TeCtxDVI57h6o+2mazDMMw1iVdIRwAqno3cHe77TAMw1jvdEuoyjAMw+gQTDgMwzCMRWHCYRiGYSwKEw7DMAxjUZhwGIZhGIuiKxYALhYRGQYWv3R8ik1A92/AvDzW+2ew3t8/2GcA6+8zeI6qbl7ooDUpHMtFRA41s3pyLbPeP4P1/v7BPgOwz2AuLFRlGIZhLAoTDsMwDGNRmHA05kPtNqADWO+fwXp//2CfAdhn0BDLcRiGYRiLwjwOwzAMY1GYcNQhIq8SkSdF5LCIvKPd9rQKEdklIveJyGMi8qiIvC0eHxKRe0XkqfjvYDwuIvL++HN5WERe2N53sHKIiCsi3xKRz8a394rI/fF7/du4jT8ikolvH47v39NOu1cKERkQkb8TkSdE5HER+d719jsQkV+L/w8eEZGPi0h2vf0OFosJR4yIuMAHgFcDVwNvEJGr22tVy/CB31DVq4Ebgdvj9/oO4Euquh/4Unwbos9kf3x5C/DB1Te5ZbwNeLzu9v8DvE9VrwBGgDfH428GRuLx98XHrQX+GPi8ql4FXEv0Wayb34GI7AB+FTioqs8n2rbh9ay/38Hi0Lo9tdfzBfhe4J662+8E3tluu1bpvf8D8ArgSWBbPLYNeDK+/mfAG+qOrx3XzRdgJ9HE+APAZwEhWuzlzfxNEO0F873xdS8+Ttr9Hpb5/vuBIzPfx3r6HQA7gOPAUPy9fha4ZT39DpZyMY9jiuQHlHAiHlvTxK729cD9wFZVPR3fdQbYGl9fq5/N/wT+DyCMb28ELqmqH9+uf5+1zyC+fzQ+vpvZCwwDfxmH6/5CRPKso9+Bqp4E3gs8C5wm+l4fZH39DhaNCcc6RkR6gb8H3q6qY/X3aXRKtWZL7kTktcA5VX2w3ba0EQ94IfBBVb0emGQqLAWsi9/BIHArkYhuB/LAq9pqVBdgwjHFSWBX3e2d8diaRERSRKLxMVX9VDx8VkS2xfdvA87F42vxs7kJ+CEROQrcSRSu+mNgQESSnTHr32ftM4jv7wcurKbBLeAEcEJV749v/x2RkKyn38HLgSOqOqyqVeBTRL+N9fQ7WDQmHFM8AOyPqynSRAmyu9psU0sQEQE+DDyuqn9Ud9ddwG3x9duIch/J+JviqpobgdG6UEZXoqrvVNWdqrqH6Lv+Z1X9GeA+4Mfjw2Z+Bsln8+Px8V19Jq6qZ4DjInJlPPQy4DHW0e+AKER1o4j0xP8XyWewbn4HS6LdSZZOugCvAb4LPA38VrvtaeH7fAlR+OFh4KH48hqiWO2XgKeALwJD8fFCVHH2NPAdogqUtr+PFfw8Xgp8Nr5+OfBN4DDwSSATj2fj24fj+y9vt90r9N6vAw7Fv4XPAIPr7XcA/C7wBPAI8NdAZr39DhZ7sZXjhmEYxqKwUJVhGIaxKEw4DMMwjEVhwmEYhmn3t54AAAIvSURBVGEsChMOwzAMY1GYcBiGYRiLwoTDMJpARAIReajuMm/3ZBH5ZRF50wq87lER2bTc5zGMlcTKcQ2jCURkQlV72/C6R4nWS5xf7dc2jLkwj8MwlkHsEbxHRL4jIt8UkSvi8XeLyG/G13813vvkYRG5Mx4bEpHPxGPfEJFr4vGNIvKFeH+IvyBadJe81hvj13hIRP4s3grAMFYdEw7DaI7cjFDVT9XdN6qqLwD+hKjj7kzeAVyvqtcAvxyP/S7wrXjsXcBH4/HfAb6mqs8DPg3sBhCR5wI/BdykqtcBAfAzK/sWDaM5vIUPMQwDKMYTdiM+Xvf3fQ3ufxj4mIh8hqitB0RtX34MQFX/OfY0+oDvB340Hv+ciIzEx78M+B7ggailEjmmmg8axqpiwmEYy0fnuJ7wg0SC8Drgt0TkBUt4DQE+oqrvXMJjDWNFsVCVYSyfn6r7+2/1d4iIA+xS1fuA/0LUhrsX+BfiUJOIvBQ4r9GeKF8FfjoefzVR00GImg7+uIhsie8bEpHntPA9GcacmMdhGM2RE5GH6m5/XlWTktxBEXkYKANvmPE4F/hfItJP5DW8X1Uvici7gTvixxWYatX9u8DHReRR4F+J2n6jqo+JyP8JfCEWoypwO3Bspd+oYSyEleMaxjKwclljPWKhKsMwDGNRmMdhGIZhLArzOAzDMIxFYcJhGIZhLAoTDsMwDGNRmHAYhmEYi8KEwzAMw1gUJhyGYRjGovj/ActGFlJ3MpNLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "# Creating a gym env\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# A training graph session\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        # Closing the env\n",
    "        print('total_reward: {}'.format(total_reward))\n",
    "# Close the env at the end\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN with rated memory replay\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aras/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "state = env.reset()\n",
    "batch = []\n",
    "for _ in range(1000):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action) # take a random action\n",
    "    batch.append([state, action, next_state, reward, float(done)])\n",
    "    #     print('state, action, reward, done, info:', \n",
    "    #           state, action, reward, done, info)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 0.03627577, -0.02392764,  0.00057116,  0.02286505]),\n",
       "  0,\n",
       "  array([ 0.03579721, -0.21905778,  0.00102846,  0.31572813]),\n",
       "  1.0,\n",
       "  0.0],\n",
       " (4,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([each[0] for each in batch])\n",
    "actions = np.array([each[1] for each in batch])\n",
    "next_states = np.array([each[2] for each in batch])\n",
    "rewards = np.array([each[3] for each in batch])\n",
    "dones = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(1000,) (1000, 4) (1000,) (1000,)\n",
      "float64 float64 int64 float64\n",
      "1 0\n",
      "2\n",
      "1.0 1.0\n",
      "2.5268027337982506 -2.79364965838285\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    return states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, actions, targetQs, action_size, hidden_size):\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    #Qs = tf.reduce_max(actions_logits, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs) # model input\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(batch_size, ListArr):\n",
    "    idx = np.random.choice(np.arange(len(ListArr)), \n",
    "                           size=batch_size, \n",
    "                           replace=True)\n",
    "    return [ListArr[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 24*2             # number of units in each Q-network hidden layer\n",
    "learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e2)             # experience mini-batch size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the memory with the pool of random exploration of the env.\n",
    "goal = 500 # env-based, the total reward required for reaching the goal G\n",
    "state = env.reset() # env-based\n",
    "total_reward = 0 # episode R\n",
    "num_step = 0 # episode steps/ length based on number of steps\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample() # exploring the env action space/ random action/ explore\n",
    "    next_state, reward, done, _ = env.step(action) # exploring the env state, reward, and done/end\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done), -1])\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward # R += r\n",
    "    state = next_state # update the state for next episode\n",
    "    if done is True: # end of this episode\n",
    "        state = env.reset() # reset for next episode\n",
    "        rate = total_reward/goal # the actual sucess rate of the played sequence\n",
    "        total_reward = 0 # reset for next episode\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.buffer[-1-idx][5] == -1: # double-check if it is empty and it is not rated!\n",
    "                memory.buffer[-1-idx][5] = rate # rate each SA pair\n",
    "        num_step = 0 # reset for the next episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = np.array(memory.buffer)[:, 5]\n",
    "rated_mem = np.array(memory.buffer)[rates >= (max(rates)*0.1)]\n",
    "batch = sample(ListArr=rated_mem, batch_size=batch_size)\n",
    "states = np.array([each[0] for each in batch])\n",
    "actions = np.array([each[1] for each in batch])\n",
    "next_states = np.array([each[2] for each in batch])\n",
    "rewards = np.array([each[3] for each in batch])\n",
    "dones = np.array([each[4] for each in batch])\n",
    "# rates = np.array([each[5] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4),\n",
       " dtype('float64'),\n",
       " (100,),\n",
       " dtype('int64'),\n",
       " (100, 4),\n",
       " dtype('float64'),\n",
       " (100,),\n",
       " dtype('float64'),\n",
       " (100,),\n",
       " dtype('float64'),\n",
       " (100000,),\n",
       " dtype('O'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape, states.dtype, actions.shape, actions.dtype, next_states.shape, next_states.dtype, \\\n",
    "rewards.shape, rewards.dtype, dones.shape, dones.dtype, rates.shape, rates.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.056, 0.056, 0.056, ..., -1, -1, -1], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:20.0000 R:20.0 rate:0.0400 loss:1.0746 exploreP:0.9980\n",
      "Episode:1 meanR:31.5000 R:43.0 rate:0.0860 loss:1.1906 exploreP:0.9938\n",
      "Episode:2 meanR:34.3333 R:40.0 rate:0.0800 loss:1.3368 exploreP:0.9899\n",
      "Episode:3 meanR:36.7500 R:44.0 rate:0.0880 loss:1.4294 exploreP:0.9856\n",
      "Episode:4 meanR:32.2000 R:14.0 rate:0.0280 loss:1.4962 exploreP:0.9842\n",
      "Episode:5 meanR:31.3333 R:27.0 rate:0.0540 loss:1.5345 exploreP:0.9816\n",
      "Episode:6 meanR:29.1429 R:16.0 rate:0.0320 loss:1.5397 exploreP:0.9800\n",
      "Episode:7 meanR:28.5000 R:24.0 rate:0.0480 loss:1.5052 exploreP:0.9777\n",
      "Episode:8 meanR:26.5556 R:11.0 rate:0.0220 loss:1.4323 exploreP:0.9766\n",
      "Episode:9 meanR:27.7000 R:38.0 rate:0.0760 loss:1.4882 exploreP:0.9730\n",
      "Episode:10 meanR:27.0909 R:21.0 rate:0.0420 loss:1.4894 exploreP:0.9709\n",
      "Episode:11 meanR:26.2500 R:17.0 rate:0.0340 loss:1.4619 exploreP:0.9693\n",
      "Episode:12 meanR:25.3846 R:15.0 rate:0.0300 loss:1.5265 exploreP:0.9679\n",
      "Episode:13 meanR:24.6429 R:15.0 rate:0.0300 loss:1.5823 exploreP:0.9664\n",
      "Episode:14 meanR:23.8667 R:13.0 rate:0.0260 loss:1.6175 exploreP:0.9652\n",
      "Episode:15 meanR:23.6875 R:21.0 rate:0.0420 loss:1.6015 exploreP:0.9632\n",
      "Episode:16 meanR:23.2941 R:17.0 rate:0.0340 loss:1.5886 exploreP:0.9616\n",
      "Episode:17 meanR:24.3889 R:43.0 rate:0.0860 loss:1.7543 exploreP:0.9575\n",
      "Episode:18 meanR:24.0526 R:18.0 rate:0.0360 loss:1.8228 exploreP:0.9558\n",
      "Episode:19 meanR:24.0000 R:23.0 rate:0.0460 loss:1.8455 exploreP:0.9536\n",
      "Episode:20 meanR:25.4762 R:55.0 rate:0.1100 loss:2.0863 exploreP:0.9484\n",
      "Episode:21 meanR:25.0000 R:15.0 rate:0.0300 loss:2.2459 exploreP:0.9470\n",
      "Episode:22 meanR:25.0435 R:26.0 rate:0.0520 loss:2.5499 exploreP:0.9446\n",
      "Episode:23 meanR:25.0833 R:26.0 rate:0.0520 loss:2.8692 exploreP:0.9422\n",
      "Episode:24 meanR:24.7600 R:17.0 rate:0.0340 loss:2.6841 exploreP:0.9406\n",
      "Episode:25 meanR:25.8846 R:54.0 rate:0.1080 loss:3.2965 exploreP:0.9356\n",
      "Episode:26 meanR:25.4815 R:15.0 rate:0.0300 loss:4.1481 exploreP:0.9342\n",
      "Episode:27 meanR:25.3214 R:21.0 rate:0.0420 loss:4.0325 exploreP:0.9322\n",
      "Episode:28 meanR:24.9655 R:15.0 rate:0.0300 loss:3.9072 exploreP:0.9309\n",
      "Episode:29 meanR:24.9000 R:23.0 rate:0.0460 loss:4.2552 exploreP:0.9287\n",
      "Episode:30 meanR:24.5806 R:15.0 rate:0.0300 loss:4.4827 exploreP:0.9274\n",
      "Episode:31 meanR:24.8750 R:34.0 rate:0.0680 loss:4.7990 exploreP:0.9243\n",
      "Episode:32 meanR:24.3939 R:9.0 rate:0.0180 loss:6.8961 exploreP:0.9234\n",
      "Episode:33 meanR:24.0000 R:11.0 rate:0.0220 loss:6.7267 exploreP:0.9224\n",
      "Episode:34 meanR:23.6571 R:12.0 rate:0.0240 loss:8.6157 exploreP:0.9213\n",
      "Episode:35 meanR:23.6389 R:23.0 rate:0.0460 loss:6.8182 exploreP:0.9192\n",
      "Episode:36 meanR:23.3784 R:14.0 rate:0.0280 loss:8.2338 exploreP:0.9180\n",
      "Episode:37 meanR:23.2105 R:17.0 rate:0.0340 loss:8.6412 exploreP:0.9164\n",
      "Episode:38 meanR:23.0000 R:15.0 rate:0.0300 loss:8.5495 exploreP:0.9151\n",
      "Episode:39 meanR:23.1500 R:29.0 rate:0.0580 loss:9.7798 exploreP:0.9124\n",
      "Episode:40 meanR:24.6585 R:85.0 rate:0.1700 loss:13.1010 exploreP:0.9048\n",
      "Episode:41 meanR:24.8333 R:32.0 rate:0.0640 loss:16.4969 exploreP:0.9019\n",
      "Episode:42 meanR:24.7442 R:21.0 rate:0.0420 loss:19.3232 exploreP:0.9001\n",
      "Episode:43 meanR:24.4773 R:13.0 rate:0.0260 loss:22.7962 exploreP:0.8989\n",
      "Episode:44 meanR:24.2889 R:16.0 rate:0.0320 loss:23.2796 exploreP:0.8975\n",
      "Episode:45 meanR:24.6087 R:39.0 rate:0.0780 loss:21.1137 exploreP:0.8940\n",
      "Episode:46 meanR:24.3830 R:14.0 rate:0.0280 loss:25.4837 exploreP:0.8928\n",
      "Episode:47 meanR:24.1250 R:12.0 rate:0.0240 loss:32.1404 exploreP:0.8917\n",
      "Episode:48 meanR:24.0816 R:22.0 rate:0.0440 loss:25.1412 exploreP:0.8898\n",
      "Episode:49 meanR:23.9000 R:15.0 rate:0.0300 loss:33.1137 exploreP:0.8885\n",
      "Episode:50 meanR:23.6863 R:13.0 rate:0.0260 loss:30.2663 exploreP:0.8873\n",
      "Episode:51 meanR:23.6923 R:24.0 rate:0.0480 loss:32.3930 exploreP:0.8852\n",
      "Episode:52 meanR:23.6038 R:19.0 rate:0.0380 loss:39.9005 exploreP:0.8836\n",
      "Episode:53 meanR:23.4074 R:13.0 rate:0.0260 loss:44.7265 exploreP:0.8824\n",
      "Episode:54 meanR:23.4182 R:24.0 rate:0.0480 loss:36.5524 exploreP:0.8804\n",
      "Episode:55 meanR:23.5357 R:30.0 rate:0.0600 loss:45.2954 exploreP:0.8778\n",
      "Episode:56 meanR:23.3684 R:14.0 rate:0.0280 loss:51.5925 exploreP:0.8765\n",
      "Episode:57 meanR:23.5000 R:31.0 rate:0.0620 loss:49.8783 exploreP:0.8739\n",
      "Episode:58 meanR:23.5085 R:24.0 rate:0.0480 loss:52.3302 exploreP:0.8718\n",
      "Episode:59 meanR:23.4333 R:19.0 rate:0.0380 loss:45.6791 exploreP:0.8701\n",
      "Episode:60 meanR:23.2787 R:14.0 rate:0.0280 loss:52.3671 exploreP:0.8689\n",
      "Episode:61 meanR:23.5000 R:37.0 rate:0.0740 loss:76.2946 exploreP:0.8658\n",
      "Episode:62 meanR:23.3651 R:15.0 rate:0.0300 loss:72.1929 exploreP:0.8645\n",
      "Episode:63 meanR:23.2031 R:13.0 rate:0.0260 loss:66.0654 exploreP:0.8634\n",
      "Episode:64 meanR:23.0308 R:12.0 rate:0.0240 loss:96.2853 exploreP:0.8624\n",
      "Episode:65 meanR:22.9394 R:17.0 rate:0.0340 loss:76.1057 exploreP:0.8609\n",
      "Episode:66 meanR:22.7761 R:12.0 rate:0.0240 loss:51.2414 exploreP:0.8599\n",
      "Episode:67 meanR:22.7206 R:19.0 rate:0.0380 loss:62.9801 exploreP:0.8583\n",
      "Episode:68 meanR:23.0290 R:44.0 rate:0.0880 loss:85.7014 exploreP:0.8546\n",
      "Episode:69 meanR:23.1714 R:33.0 rate:0.0660 loss:103.6956 exploreP:0.8518\n",
      "Episode:70 meanR:23.1408 R:21.0 rate:0.0420 loss:92.3390 exploreP:0.8500\n",
      "Episode:71 meanR:22.9861 R:12.0 rate:0.0240 loss:104.9927 exploreP:0.8490\n",
      "Episode:72 meanR:22.9726 R:22.0 rate:0.0440 loss:93.6886 exploreP:0.8472\n",
      "Episode:73 meanR:22.8919 R:17.0 rate:0.0340 loss:119.8134 exploreP:0.8457\n",
      "Episode:74 meanR:23.2133 R:47.0 rate:0.0940 loss:71.7308 exploreP:0.8418\n",
      "Episode:75 meanR:23.2763 R:28.0 rate:0.0560 loss:106.2436 exploreP:0.8395\n",
      "Episode:76 meanR:23.1558 R:14.0 rate:0.0280 loss:78.3546 exploreP:0.8383\n",
      "Episode:77 meanR:23.4615 R:47.0 rate:0.0940 loss:105.7314 exploreP:0.8344\n",
      "Episode:78 meanR:23.3291 R:13.0 rate:0.0260 loss:118.1217 exploreP:0.8334\n",
      "Episode:79 meanR:23.3250 R:23.0 rate:0.0460 loss:107.2394 exploreP:0.8315\n",
      "Episode:80 meanR:23.2222 R:15.0 rate:0.0300 loss:83.3700 exploreP:0.8302\n",
      "Episode:81 meanR:23.1220 R:15.0 rate:0.0300 loss:116.7234 exploreP:0.8290\n",
      "Episode:82 meanR:23.2410 R:33.0 rate:0.0660 loss:115.3578 exploreP:0.8263\n",
      "Episode:83 meanR:23.1310 R:14.0 rate:0.0280 loss:147.8470 exploreP:0.8252\n",
      "Episode:84 meanR:23.0588 R:17.0 rate:0.0340 loss:111.7546 exploreP:0.8238\n",
      "Episode:85 meanR:22.9651 R:15.0 rate:0.0300 loss:99.0573 exploreP:0.8226\n",
      "Episode:86 meanR:22.9540 R:22.0 rate:0.0440 loss:109.0148 exploreP:0.8208\n",
      "Episode:87 meanR:22.8636 R:15.0 rate:0.0300 loss:111.7896 exploreP:0.8196\n",
      "Episode:88 meanR:22.7640 R:14.0 rate:0.0280 loss:100.5021 exploreP:0.8184\n",
      "Episode:89 meanR:22.6778 R:15.0 rate:0.0300 loss:97.4392 exploreP:0.8172\n",
      "Episode:90 meanR:22.5824 R:14.0 rate:0.0280 loss:96.4480 exploreP:0.8161\n",
      "Episode:91 meanR:22.4457 R:10.0 rate:0.0200 loss:86.7274 exploreP:0.8153\n",
      "Episode:92 meanR:22.4409 R:22.0 rate:0.0440 loss:95.2911 exploreP:0.8135\n",
      "Episode:93 meanR:22.3191 R:11.0 rate:0.0220 loss:79.1739 exploreP:0.8126\n",
      "Episode:94 meanR:22.1895 R:10.0 rate:0.0200 loss:63.1654 exploreP:0.8118\n",
      "Episode:95 meanR:22.0833 R:12.0 rate:0.0240 loss:71.1743 exploreP:0.8109\n",
      "Episode:96 meanR:22.3196 R:45.0 rate:0.0900 loss:96.3070 exploreP:0.8073\n",
      "Episode:97 meanR:22.2143 R:12.0 rate:0.0240 loss:108.1043 exploreP:0.8063\n",
      "Episode:98 meanR:22.3434 R:35.0 rate:0.0700 loss:76.9304 exploreP:0.8035\n",
      "Episode:99 meanR:22.3100 R:19.0 rate:0.0380 loss:105.1907 exploreP:0.8020\n",
      "Episode:100 meanR:22.2500 R:14.0 rate:0.0280 loss:83.4063 exploreP:0.8009\n",
      "Episode:101 meanR:22.4500 R:63.0 rate:0.1260 loss:79.5593 exploreP:0.7960\n",
      "Episode:102 meanR:22.3100 R:26.0 rate:0.0520 loss:49.4367 exploreP:0.7939\n",
      "Episode:103 meanR:22.0800 R:21.0 rate:0.0420 loss:52.8837 exploreP:0.7923\n",
      "Episode:104 meanR:22.1100 R:17.0 rate:0.0340 loss:41.0887 exploreP:0.7909\n",
      "Episode:105 meanR:22.0200 R:18.0 rate:0.0360 loss:57.6222 exploreP:0.7895\n",
      "Episode:106 meanR:21.9800 R:12.0 rate:0.0240 loss:74.6110 exploreP:0.7886\n",
      "Episode:107 meanR:22.0300 R:29.0 rate:0.0580 loss:61.3435 exploreP:0.7864\n",
      "Episode:108 meanR:22.2200 R:30.0 rate:0.0600 loss:56.3884 exploreP:0.7840\n",
      "Episode:109 meanR:21.9400 R:10.0 rate:0.0200 loss:57.2045 exploreP:0.7833\n",
      "Episode:110 meanR:22.0600 R:33.0 rate:0.0660 loss:54.6617 exploreP:0.7807\n",
      "Episode:111 meanR:22.0200 R:13.0 rate:0.0260 loss:34.2374 exploreP:0.7797\n",
      "Episode:112 meanR:22.0100 R:14.0 rate:0.0280 loss:38.6154 exploreP:0.7786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:113 meanR:22.0000 R:14.0 rate:0.0280 loss:71.0945 exploreP:0.7776\n",
      "Episode:114 meanR:21.9700 R:10.0 rate:0.0200 loss:39.3250 exploreP:0.7768\n",
      "Episode:115 meanR:21.9100 R:15.0 rate:0.0300 loss:43.5094 exploreP:0.7756\n",
      "Episode:116 meanR:21.9000 R:16.0 rate:0.0320 loss:44.7160 exploreP:0.7744\n",
      "Episode:117 meanR:21.6500 R:18.0 rate:0.0360 loss:48.6355 exploreP:0.7730\n",
      "Episode:118 meanR:21.5800 R:11.0 rate:0.0220 loss:48.1457 exploreP:0.7722\n",
      "Episode:119 meanR:21.6900 R:34.0 rate:0.0680 loss:42.8742 exploreP:0.7696\n",
      "Episode:120 meanR:21.3000 R:16.0 rate:0.0320 loss:57.6774 exploreP:0.7684\n",
      "Episode:121 meanR:21.2700 R:12.0 rate:0.0240 loss:41.3575 exploreP:0.7675\n",
      "Episode:122 meanR:21.1400 R:13.0 rate:0.0260 loss:58.4111 exploreP:0.7665\n",
      "Episode:123 meanR:21.1400 R:26.0 rate:0.0520 loss:60.1071 exploreP:0.7645\n",
      "Episode:124 meanR:21.1200 R:15.0 rate:0.0300 loss:39.1479 exploreP:0.7634\n",
      "Episode:125 meanR:20.7600 R:18.0 rate:0.0360 loss:41.8508 exploreP:0.7621\n",
      "Episode:126 meanR:20.7400 R:13.0 rate:0.0260 loss:45.7844 exploreP:0.7611\n",
      "Episode:127 meanR:20.6500 R:12.0 rate:0.0240 loss:53.4837 exploreP:0.7602\n",
      "Episode:128 meanR:20.7100 R:21.0 rate:0.0420 loss:30.9809 exploreP:0.7586\n",
      "Episode:129 meanR:20.9500 R:47.0 rate:0.0940 loss:47.4764 exploreP:0.7551\n",
      "Episode:130 meanR:20.8900 R:9.0 rate:0.0180 loss:23.5327 exploreP:0.7544\n",
      "Episode:131 meanR:20.7400 R:19.0 rate:0.0380 loss:39.3271 exploreP:0.7530\n",
      "Episode:132 meanR:20.9300 R:28.0 rate:0.0560 loss:50.3506 exploreP:0.7509\n",
      "Episode:133 meanR:21.1800 R:36.0 rate:0.0720 loss:42.9156 exploreP:0.7483\n",
      "Episode:134 meanR:21.2100 R:15.0 rate:0.0300 loss:33.9892 exploreP:0.7472\n",
      "Episode:135 meanR:21.2900 R:31.0 rate:0.0620 loss:36.6773 exploreP:0.7449\n",
      "Episode:136 meanR:21.3900 R:24.0 rate:0.0480 loss:35.8855 exploreP:0.7431\n",
      "Episode:137 meanR:21.3900 R:17.0 rate:0.0340 loss:40.6572 exploreP:0.7419\n",
      "Episode:138 meanR:21.3500 R:11.0 rate:0.0220 loss:30.0941 exploreP:0.7411\n",
      "Episode:139 meanR:21.5400 R:48.0 rate:0.0960 loss:41.0503 exploreP:0.7376\n",
      "Episode:140 meanR:20.9500 R:26.0 rate:0.0520 loss:36.1993 exploreP:0.7357\n",
      "Episode:141 meanR:20.9600 R:33.0 rate:0.0660 loss:33.0858 exploreP:0.7333\n",
      "Episode:142 meanR:20.9300 R:18.0 rate:0.0360 loss:27.7476 exploreP:0.7320\n",
      "Episode:143 meanR:20.9200 R:12.0 rate:0.0240 loss:40.4330 exploreP:0.7311\n",
      "Episode:144 meanR:21.2400 R:48.0 rate:0.0960 loss:32.9330 exploreP:0.7277\n",
      "Episode:145 meanR:21.0800 R:23.0 rate:0.0460 loss:38.8713 exploreP:0.7260\n",
      "Episode:146 meanR:21.1600 R:22.0 rate:0.0440 loss:32.8257 exploreP:0.7244\n",
      "Episode:147 meanR:21.2900 R:25.0 rate:0.0500 loss:27.3456 exploreP:0.7227\n",
      "Episode:148 meanR:21.2300 R:16.0 rate:0.0320 loss:31.2701 exploreP:0.7215\n",
      "Episode:149 meanR:21.2100 R:13.0 rate:0.0260 loss:32.2074 exploreP:0.7206\n",
      "Episode:150 meanR:21.3800 R:30.0 rate:0.0600 loss:31.3801 exploreP:0.7185\n",
      "Episode:151 meanR:21.2800 R:14.0 rate:0.0280 loss:22.5207 exploreP:0.7175\n",
      "Episode:152 meanR:21.2600 R:17.0 rate:0.0340 loss:29.7873 exploreP:0.7163\n",
      "Episode:153 meanR:21.3900 R:26.0 rate:0.0520 loss:24.7638 exploreP:0.7144\n",
      "Episode:154 meanR:21.4100 R:26.0 rate:0.0520 loss:34.3498 exploreP:0.7126\n",
      "Episode:155 meanR:21.4000 R:29.0 rate:0.0580 loss:26.1851 exploreP:0.7106\n",
      "Episode:156 meanR:21.6900 R:43.0 rate:0.0860 loss:25.1240 exploreP:0.7076\n",
      "Episode:157 meanR:21.4900 R:11.0 rate:0.0220 loss:28.0452 exploreP:0.7068\n",
      "Episode:158 meanR:21.4200 R:17.0 rate:0.0340 loss:30.0988 exploreP:0.7056\n",
      "Episode:159 meanR:21.3900 R:16.0 rate:0.0320 loss:34.0371 exploreP:0.7045\n",
      "Episode:160 meanR:22.1100 R:86.0 rate:0.1720 loss:29.4215 exploreP:0.6986\n",
      "Episode:161 meanR:21.9300 R:19.0 rate:0.0380 loss:26.2220 exploreP:0.6973\n",
      "Episode:162 meanR:22.0600 R:28.0 rate:0.0560 loss:29.4888 exploreP:0.6953\n",
      "Episode:163 meanR:22.2100 R:28.0 rate:0.0560 loss:27.0634 exploreP:0.6934\n",
      "Episode:164 meanR:22.3100 R:22.0 rate:0.0440 loss:31.5347 exploreP:0.6919\n",
      "Episode:165 meanR:22.6500 R:51.0 rate:0.1020 loss:22.3080 exploreP:0.6884\n",
      "Episode:166 meanR:22.7500 R:22.0 rate:0.0440 loss:27.7824 exploreP:0.6870\n",
      "Episode:167 meanR:23.0300 R:47.0 rate:0.0940 loss:23.4172 exploreP:0.6838\n",
      "Episode:168 meanR:22.7000 R:11.0 rate:0.0220 loss:22.3699 exploreP:0.6830\n",
      "Episode:169 meanR:22.5100 R:14.0 rate:0.0280 loss:20.7494 exploreP:0.6821\n",
      "Episode:170 meanR:22.7500 R:45.0 rate:0.0900 loss:27.0874 exploreP:0.6791\n",
      "Episode:171 meanR:22.7900 R:16.0 rate:0.0320 loss:23.6213 exploreP:0.6780\n",
      "Episode:172 meanR:22.8100 R:24.0 rate:0.0480 loss:21.6535 exploreP:0.6764\n",
      "Episode:173 meanR:22.8500 R:21.0 rate:0.0420 loss:29.5533 exploreP:0.6750\n",
      "Episode:174 meanR:23.0600 R:68.0 rate:0.1360 loss:28.9203 exploreP:0.6705\n",
      "Episode:175 meanR:23.0600 R:28.0 rate:0.0560 loss:24.2069 exploreP:0.6687\n",
      "Episode:176 meanR:23.1800 R:26.0 rate:0.0520 loss:26.2494 exploreP:0.6669\n",
      "Episode:177 meanR:23.0400 R:33.0 rate:0.0660 loss:23.1194 exploreP:0.6648\n",
      "Episode:178 meanR:23.2800 R:37.0 rate:0.0740 loss:26.0759 exploreP:0.6624\n",
      "Episode:179 meanR:23.5400 R:49.0 rate:0.0980 loss:22.7195 exploreP:0.6592\n",
      "Episode:180 meanR:23.5900 R:20.0 rate:0.0400 loss:27.7144 exploreP:0.6579\n",
      "Episode:181 meanR:24.2600 R:82.0 rate:0.1640 loss:25.0927 exploreP:0.6526\n",
      "Episode:182 meanR:24.5800 R:65.0 rate:0.1300 loss:23.6204 exploreP:0.6484\n",
      "Episode:183 meanR:24.6900 R:25.0 rate:0.0500 loss:22.5916 exploreP:0.6468\n",
      "Episode:184 meanR:24.7400 R:22.0 rate:0.0440 loss:24.0270 exploreP:0.6454\n",
      "Episode:185 meanR:25.0000 R:41.0 rate:0.0820 loss:24.3768 exploreP:0.6428\n",
      "Episode:186 meanR:25.3500 R:57.0 rate:0.1140 loss:25.0979 exploreP:0.6392\n",
      "Episode:187 meanR:25.9300 R:73.0 rate:0.1460 loss:26.9806 exploreP:0.6347\n",
      "Episode:188 meanR:26.2900 R:50.0 rate:0.1000 loss:24.2325 exploreP:0.6315\n",
      "Episode:189 meanR:26.4900 R:35.0 rate:0.0700 loss:29.8802 exploreP:0.6294\n",
      "Episode:190 meanR:26.7300 R:38.0 rate:0.0760 loss:25.0263 exploreP:0.6270\n",
      "Episode:191 meanR:27.1500 R:52.0 rate:0.1040 loss:30.4537 exploreP:0.6238\n",
      "Episode:192 meanR:27.3200 R:39.0 rate:0.0780 loss:25.8142 exploreP:0.6214\n",
      "Episode:193 meanR:27.4900 R:28.0 rate:0.0560 loss:24.5336 exploreP:0.6197\n",
      "Episode:194 meanR:27.8100 R:42.0 rate:0.0840 loss:29.2401 exploreP:0.6172\n",
      "Episode:195 meanR:28.1000 R:41.0 rate:0.0820 loss:24.9818 exploreP:0.6147\n",
      "Episode:196 meanR:28.1200 R:47.0 rate:0.0940 loss:28.1287 exploreP:0.6118\n",
      "Episode:197 meanR:28.3300 R:33.0 rate:0.0660 loss:27.9306 exploreP:0.6099\n",
      "Episode:198 meanR:28.3400 R:36.0 rate:0.0720 loss:31.8381 exploreP:0.6077\n",
      "Episode:199 meanR:28.4500 R:30.0 rate:0.0600 loss:31.5095 exploreP:0.6059\n",
      "Episode:200 meanR:28.7600 R:45.0 rate:0.0900 loss:29.1508 exploreP:0.6032\n",
      "Episode:201 meanR:28.6800 R:55.0 rate:0.1100 loss:26.6356 exploreP:0.6000\n",
      "Episode:202 meanR:28.6700 R:25.0 rate:0.0500 loss:28.9577 exploreP:0.5985\n",
      "Episode:203 meanR:29.2700 R:81.0 rate:0.1620 loss:29.7794 exploreP:0.5938\n",
      "Episode:204 meanR:29.3900 R:29.0 rate:0.0580 loss:24.5655 exploreP:0.5921\n",
      "Episode:205 meanR:30.0000 R:79.0 rate:0.1580 loss:29.5265 exploreP:0.5875\n",
      "Episode:206 meanR:30.1100 R:23.0 rate:0.0460 loss:30.9428 exploreP:0.5862\n",
      "Episode:207 meanR:30.0300 R:21.0 rate:0.0420 loss:30.3871 exploreP:0.5850\n",
      "Episode:208 meanR:30.4000 R:67.0 rate:0.1340 loss:30.2566 exploreP:0.5811\n",
      "Episode:209 meanR:30.6500 R:35.0 rate:0.0700 loss:26.1318 exploreP:0.5791\n",
      "Episode:210 meanR:30.7500 R:43.0 rate:0.0860 loss:35.7422 exploreP:0.5767\n",
      "Episode:211 meanR:31.2000 R:58.0 rate:0.1160 loss:36.5527 exploreP:0.5734\n",
      "Episode:212 meanR:31.6700 R:61.0 rate:0.1220 loss:32.5874 exploreP:0.5700\n",
      "Episode:213 meanR:31.9800 R:45.0 rate:0.0900 loss:31.4897 exploreP:0.5675\n",
      "Episode:214 meanR:32.4600 R:58.0 rate:0.1160 loss:30.6928 exploreP:0.5642\n",
      "Episode:215 meanR:32.4500 R:14.0 rate:0.0280 loss:42.7668 exploreP:0.5635\n",
      "Episode:216 meanR:32.6300 R:34.0 rate:0.0680 loss:42.8289 exploreP:0.5616\n",
      "Episode:217 meanR:32.6900 R:24.0 rate:0.0480 loss:41.2273 exploreP:0.5603\n",
      "Episode:218 meanR:33.3300 R:75.0 rate:0.1500 loss:28.1127 exploreP:0.5562\n",
      "Episode:219 meanR:33.6600 R:67.0 rate:0.1340 loss:34.5860 exploreP:0.5525\n",
      "Episode:220 meanR:34.5000 R:100.0 rate:0.2000 loss:37.0494 exploreP:0.5471\n",
      "Episode:221 meanR:35.3500 R:97.0 rate:0.1940 loss:38.9163 exploreP:0.5419\n",
      "Episode:222 meanR:35.3900 R:17.0 rate:0.0340 loss:39.9501 exploreP:0.5410\n",
      "Episode:223 meanR:36.6300 R:150.0 rate:0.3000 loss:42.5714 exploreP:0.5331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:224 meanR:37.2000 R:72.0 rate:0.1440 loss:37.8748 exploreP:0.5294\n",
      "Episode:225 meanR:37.5700 R:55.0 rate:0.1100 loss:34.9659 exploreP:0.5265\n",
      "Episode:226 meanR:38.1800 R:74.0 rate:0.1480 loss:41.2187 exploreP:0.5227\n",
      "Episode:227 meanR:38.4500 R:39.0 rate:0.0780 loss:35.7512 exploreP:0.5207\n",
      "Episode:228 meanR:38.7700 R:53.0 rate:0.1060 loss:39.9025 exploreP:0.5180\n",
      "Episode:229 meanR:38.9000 R:60.0 rate:0.1200 loss:43.9062 exploreP:0.5150\n",
      "Episode:230 meanR:39.2200 R:41.0 rate:0.0820 loss:43.6881 exploreP:0.5129\n",
      "Episode:231 meanR:39.6100 R:58.0 rate:0.1160 loss:42.7890 exploreP:0.5100\n",
      "Episode:232 meanR:39.6300 R:30.0 rate:0.0600 loss:42.6608 exploreP:0.5085\n",
      "Episode:233 meanR:40.3500 R:108.0 rate:0.2160 loss:46.4939 exploreP:0.5031\n",
      "Episode:234 meanR:40.6200 R:42.0 rate:0.0840 loss:42.6616 exploreP:0.5011\n",
      "Episode:235 meanR:41.6700 R:136.0 rate:0.2720 loss:46.0250 exploreP:0.4944\n",
      "Episode:236 meanR:41.9800 R:55.0 rate:0.1100 loss:53.7461 exploreP:0.4918\n",
      "Episode:237 meanR:42.4600 R:65.0 rate:0.1300 loss:54.4948 exploreP:0.4887\n",
      "Episode:238 meanR:43.5000 R:115.0 rate:0.2300 loss:48.8673 exploreP:0.4832\n",
      "Episode:239 meanR:43.4100 R:39.0 rate:0.0780 loss:45.0281 exploreP:0.4814\n",
      "Episode:240 meanR:43.5300 R:38.0 rate:0.0760 loss:67.5751 exploreP:0.4796\n",
      "Episode:241 meanR:44.1900 R:99.0 rate:0.1980 loss:53.5296 exploreP:0.4749\n",
      "Episode:242 meanR:44.3400 R:33.0 rate:0.0660 loss:54.1954 exploreP:0.4734\n",
      "Episode:243 meanR:45.3100 R:109.0 rate:0.2180 loss:54.7754 exploreP:0.4684\n",
      "Episode:244 meanR:45.2600 R:43.0 rate:0.0860 loss:56.3778 exploreP:0.4664\n",
      "Episode:245 meanR:46.1800 R:115.0 rate:0.2300 loss:54.2126 exploreP:0.4612\n",
      "Episode:246 meanR:46.2300 R:27.0 rate:0.0540 loss:60.5932 exploreP:0.4600\n",
      "Episode:247 meanR:46.9100 R:93.0 rate:0.1860 loss:49.7800 exploreP:0.4558\n",
      "Episode:248 meanR:47.3900 R:64.0 rate:0.1280 loss:56.9961 exploreP:0.4530\n",
      "Episode:249 meanR:48.1800 R:92.0 rate:0.1840 loss:60.1148 exploreP:0.4489\n",
      "Episode:250 meanR:48.8600 R:98.0 rate:0.1960 loss:61.1189 exploreP:0.4446\n",
      "Episode:251 meanR:50.7700 R:205.0 rate:0.4100 loss:63.6303 exploreP:0.4358\n",
      "Episode:252 meanR:51.5600 R:96.0 rate:0.1920 loss:51.4829 exploreP:0.4317\n",
      "Episode:253 meanR:52.4500 R:115.0 rate:0.2300 loss:52.6561 exploreP:0.4269\n",
      "Episode:254 meanR:52.5500 R:36.0 rate:0.0720 loss:62.5545 exploreP:0.4254\n",
      "Episode:255 meanR:53.8800 R:162.0 rate:0.3240 loss:66.6012 exploreP:0.4188\n",
      "Episode:256 meanR:53.6800 R:23.0 rate:0.0460 loss:64.0935 exploreP:0.4178\n",
      "Episode:257 meanR:54.9100 R:134.0 rate:0.2680 loss:63.7159 exploreP:0.4124\n",
      "Episode:258 meanR:55.8100 R:107.0 rate:0.2140 loss:71.1920 exploreP:0.4081\n",
      "Episode:259 meanR:57.5000 R:185.0 rate:0.3700 loss:70.6328 exploreP:0.4008\n",
      "Episode:260 meanR:57.3300 R:69.0 rate:0.1380 loss:68.2204 exploreP:0.3981\n",
      "Episode:261 meanR:58.2000 R:106.0 rate:0.2120 loss:81.2986 exploreP:0.3940\n",
      "Episode:262 meanR:58.4100 R:49.0 rate:0.0980 loss:70.0604 exploreP:0.3921\n",
      "Episode:263 meanR:59.1600 R:103.0 rate:0.2060 loss:72.3132 exploreP:0.3882\n",
      "Episode:264 meanR:59.7200 R:78.0 rate:0.1560 loss:71.0523 exploreP:0.3853\n",
      "Episode:265 meanR:60.4300 R:122.0 rate:0.2440 loss:89.6481 exploreP:0.3807\n",
      "Episode:266 meanR:61.7600 R:155.0 rate:0.3100 loss:74.3124 exploreP:0.3750\n",
      "Episode:267 meanR:62.6900 R:140.0 rate:0.2800 loss:82.1371 exploreP:0.3700\n",
      "Episode:268 meanR:63.7000 R:112.0 rate:0.2240 loss:85.2244 exploreP:0.3660\n",
      "Episode:269 meanR:64.5800 R:102.0 rate:0.2040 loss:79.0220 exploreP:0.3623\n",
      "Episode:270 meanR:66.0300 R:190.0 rate:0.3800 loss:86.9873 exploreP:0.3557\n",
      "Episode:271 meanR:66.3900 R:52.0 rate:0.1040 loss:100.0537 exploreP:0.3539\n",
      "Episode:272 meanR:66.7700 R:62.0 rate:0.1240 loss:80.3952 exploreP:0.3518\n",
      "Episode:273 meanR:67.5200 R:96.0 rate:0.1920 loss:78.4338 exploreP:0.3485\n",
      "Episode:274 meanR:67.7900 R:95.0 rate:0.1900 loss:88.3839 exploreP:0.3453\n",
      "Episode:275 meanR:69.0500 R:154.0 rate:0.3080 loss:92.2876 exploreP:0.3402\n",
      "Episode:276 meanR:70.1000 R:131.0 rate:0.2620 loss:89.6382 exploreP:0.3359\n",
      "Episode:277 meanR:71.0700 R:130.0 rate:0.2600 loss:92.8536 exploreP:0.3317\n",
      "Episode:278 meanR:72.2300 R:153.0 rate:0.3060 loss:86.4225 exploreP:0.3268\n",
      "Episode:279 meanR:73.1100 R:137.0 rate:0.2740 loss:95.7642 exploreP:0.3225\n",
      "Episode:280 meanR:74.3900 R:148.0 rate:0.2960 loss:89.7425 exploreP:0.3179\n",
      "Episode:281 meanR:74.6200 R:105.0 rate:0.2100 loss:99.8483 exploreP:0.3147\n",
      "Episode:282 meanR:75.4400 R:147.0 rate:0.2940 loss:86.1350 exploreP:0.3102\n",
      "Episode:283 meanR:77.1200 R:193.0 rate:0.3860 loss:99.8131 exploreP:0.3045\n",
      "Episode:284 meanR:78.9200 R:202.0 rate:0.4040 loss:101.6789 exploreP:0.2986\n",
      "Episode:285 meanR:80.1800 R:167.0 rate:0.3340 loss:105.3270 exploreP:0.2938\n",
      "Episode:286 meanR:80.8500 R:124.0 rate:0.2480 loss:93.9581 exploreP:0.2903\n",
      "Episode:287 meanR:83.0600 R:294.0 rate:0.5880 loss:95.4063 exploreP:0.2822\n",
      "Episode:288 meanR:84.1700 R:161.0 rate:0.3220 loss:79.6641 exploreP:0.2779\n",
      "Episode:289 meanR:85.5600 R:174.0 rate:0.3480 loss:87.2015 exploreP:0.2733\n",
      "Episode:290 meanR:85.8600 R:68.0 rate:0.1360 loss:74.3381 exploreP:0.2715\n",
      "Episode:291 meanR:87.7500 R:241.0 rate:0.4820 loss:82.8886 exploreP:0.2652\n",
      "Episode:292 meanR:89.1900 R:183.0 rate:0.3660 loss:73.1345 exploreP:0.2606\n",
      "Episode:293 meanR:90.6700 R:176.0 rate:0.3520 loss:76.0251 exploreP:0.2562\n",
      "Episode:294 meanR:93.6200 R:337.0 rate:0.6740 loss:76.1742 exploreP:0.2481\n",
      "Episode:295 meanR:95.8500 R:264.0 rate:0.5280 loss:65.3360 exploreP:0.2419\n",
      "Episode:296 meanR:98.7600 R:338.0 rate:0.6760 loss:68.0003 exploreP:0.2342\n",
      "Episode:297 meanR:100.6300 R:220.0 rate:0.4400 loss:69.3338 exploreP:0.2293\n",
      "Episode:298 meanR:102.4800 R:221.0 rate:0.4420 loss:75.0674 exploreP:0.2245\n",
      "Episode:299 meanR:104.4600 R:228.0 rate:0.4560 loss:73.7976 exploreP:0.2197\n",
      "Episode:300 meanR:108.2300 R:422.0 rate:0.8440 loss:65.0782 exploreP:0.2110\n",
      "Episode:301 meanR:109.7300 R:205.0 rate:0.4100 loss:64.8607 exploreP:0.2069\n",
      "Episode:302 meanR:111.8300 R:235.0 rate:0.4700 loss:58.8999 exploreP:0.2023\n",
      "Episode:303 meanR:112.8600 R:184.0 rate:0.3680 loss:51.9946 exploreP:0.1988\n",
      "Episode:304 meanR:115.0200 R:245.0 rate:0.4900 loss:50.5449 exploreP:0.1943\n",
      "Episode:305 meanR:117.0300 R:280.0 rate:0.5600 loss:49.1600 exploreP:0.1892\n",
      "Episode:306 meanR:119.4600 R:266.0 rate:0.5320 loss:48.4715 exploreP:0.1845\n",
      "Episode:307 meanR:121.5600 R:231.0 rate:0.4620 loss:50.5441 exploreP:0.1805\n",
      "Episode:308 meanR:122.8900 R:200.0 rate:0.4000 loss:48.3129 exploreP:0.1771\n",
      "Episode:309 meanR:125.9400 R:340.0 rate:0.6800 loss:45.7900 exploreP:0.1715\n",
      "Episode:310 meanR:127.5400 R:203.0 rate:0.4060 loss:53.9793 exploreP:0.1683\n",
      "Episode:311 meanR:131.9600 R:500.0 rate:1.0000 loss:45.9047 exploreP:0.1606\n",
      "Episode:312 meanR:133.3900 R:204.0 rate:0.4080 loss:39.6180 exploreP:0.1575\n",
      "Episode:313 meanR:135.2500 R:231.0 rate:0.4620 loss:39.4759 exploreP:0.1542\n",
      "Episode:314 meanR:138.7000 R:403.0 rate:0.8060 loss:33.8203 exploreP:0.1485\n",
      "Episode:315 meanR:140.6000 R:204.0 rate:0.4080 loss:39.0397 exploreP:0.1457\n",
      "Episode:316 meanR:142.3600 R:210.0 rate:0.4200 loss:34.1486 exploreP:0.1428\n",
      "Episode:317 meanR:144.5400 R:242.0 rate:0.4840 loss:33.3661 exploreP:0.1397\n",
      "Episode:318 meanR:147.8400 R:405.0 rate:0.8100 loss:36.8809 exploreP:0.1345\n",
      "Episode:319 meanR:150.5500 R:338.0 rate:0.6760 loss:34.6738 exploreP:0.1304\n",
      "Episode:320 meanR:152.6600 R:311.0 rate:0.6220 loss:31.2140 exploreP:0.1267\n",
      "Episode:321 meanR:154.0500 R:236.0 rate:0.4720 loss:26.1872 exploreP:0.1240\n",
      "Episode:322 meanR:156.6800 R:280.0 rate:0.5600 loss:28.3752 exploreP:0.1208\n",
      "Episode:323 meanR:158.8500 R:367.0 rate:0.7340 loss:26.5005 exploreP:0.1168\n",
      "Episode:324 meanR:160.6900 R:256.0 rate:0.5120 loss:20.4104 exploreP:0.1141\n",
      "Episode:325 meanR:165.1400 R:500.0 rate:1.0000 loss:26.2004 exploreP:0.1091\n",
      "Episode:326 meanR:166.7100 R:231.0 rate:0.4620 loss:25.3019 exploreP:0.1068\n",
      "Episode:327 meanR:171.3200 R:500.0 rate:1.0000 loss:20.6121 exploreP:0.1021\n",
      "Episode:328 meanR:175.7900 R:500.0 rate:1.0000 loss:23.2954 exploreP:0.0976\n",
      "Episode:329 meanR:180.1900 R:500.0 rate:1.0000 loss:23.1234 exploreP:0.0933\n",
      "Episode:330 meanR:183.8900 R:411.0 rate:0.8220 loss:23.5090 exploreP:0.0900\n",
      "Episode:331 meanR:188.1100 R:480.0 rate:0.9600 loss:21.6014 exploreP:0.0862\n",
      "Episode:332 meanR:192.6800 R:487.0 rate:0.9740 loss:23.7511 exploreP:0.0826\n",
      "Episode:333 meanR:196.6000 R:500.0 rate:1.0000 loss:22.9125 exploreP:0.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:334 meanR:200.8700 R:469.0 rate:0.9380 loss:22.7159 exploreP:0.0759\n",
      "Episode:335 meanR:203.4100 R:390.0 rate:0.7800 loss:18.6878 exploreP:0.0734\n",
      "Episode:336 meanR:207.2400 R:438.0 rate:0.8760 loss:22.2125 exploreP:0.0706\n",
      "Episode:337 meanR:210.3300 R:374.0 rate:0.7480 loss:24.5704 exploreP:0.0684\n",
      "Episode:338 meanR:212.5800 R:340.0 rate:0.6800 loss:23.7972 exploreP:0.0665\n",
      "Episode:339 meanR:215.5600 R:337.0 rate:0.6740 loss:24.2481 exploreP:0.0646\n",
      "Episode:340 meanR:218.6400 R:346.0 rate:0.6920 loss:21.0750 exploreP:0.0627\n",
      "Episode:341 meanR:220.7800 R:313.0 rate:0.6260 loss:25.7669 exploreP:0.0611\n",
      "Episode:342 meanR:223.9800 R:353.0 rate:0.7060 loss:22.0307 exploreP:0.0593\n",
      "Episode:343 meanR:226.2700 R:338.0 rate:0.6760 loss:24.5316 exploreP:0.0577\n",
      "Episode:344 meanR:229.4500 R:361.0 rate:0.7220 loss:24.3913 exploreP:0.0560\n",
      "Episode:345 meanR:231.6600 R:336.0 rate:0.6720 loss:22.0253 exploreP:0.0545\n",
      "Episode:346 meanR:234.2100 R:282.0 rate:0.5640 loss:25.3014 exploreP:0.0533\n",
      "Episode:347 meanR:236.8400 R:356.0 rate:0.7120 loss:24.5168 exploreP:0.0517\n",
      "Episode:348 meanR:239.3800 R:318.0 rate:0.6360 loss:25.2664 exploreP:0.0504\n",
      "Episode:349 meanR:242.2900 R:383.0 rate:0.7660 loss:20.6699 exploreP:0.0489\n",
      "Episode:350 meanR:244.8900 R:358.0 rate:0.7160 loss:23.4013 exploreP:0.0475\n",
      "Episode:351 meanR:246.1300 R:329.0 rate:0.6580 loss:18.7807 exploreP:0.0463\n",
      "Episode:352 meanR:248.4700 R:330.0 rate:0.6600 loss:18.1632 exploreP:0.0452\n",
      "Episode:353 meanR:250.7800 R:346.0 rate:0.6920 loss:18.2657 exploreP:0.0440\n",
      "Episode:354 meanR:253.3100 R:289.0 rate:0.5780 loss:13.2383 exploreP:0.0430\n",
      "Episode:355 meanR:254.6600 R:297.0 rate:0.5940 loss:15.6227 exploreP:0.0420\n",
      "Episode:356 meanR:257.4700 R:304.0 rate:0.6080 loss:17.7957 exploreP:0.0411\n",
      "Episode:357 meanR:259.5500 R:342.0 rate:0.6840 loss:14.2973 exploreP:0.0400\n",
      "Episode:358 meanR:261.4700 R:299.0 rate:0.5980 loss:15.4986 exploreP:0.0391\n",
      "Episode:359 meanR:262.8300 R:321.0 rate:0.6420 loss:11.9242 exploreP:0.0382\n",
      "Episode:360 meanR:266.1400 R:400.0 rate:0.8000 loss:13.2916 exploreP:0.0371\n",
      "Episode:361 meanR:268.9500 R:387.0 rate:0.7740 loss:11.1336 exploreP:0.0361\n",
      "Episode:362 meanR:271.6900 R:323.0 rate:0.6460 loss:9.0861 exploreP:0.0353\n",
      "Episode:363 meanR:273.7500 R:309.0 rate:0.6180 loss:11.6739 exploreP:0.0345\n",
      "Episode:364 meanR:276.1200 R:315.0 rate:0.6300 loss:11.6877 exploreP:0.0337\n",
      "Episode:365 meanR:278.5000 R:360.0 rate:0.7200 loss:9.6888 exploreP:0.0329\n",
      "Episode:366 meanR:280.3300 R:338.0 rate:0.6760 loss:9.0909 exploreP:0.0321\n",
      "Episode:367 meanR:281.8700 R:294.0 rate:0.5880 loss:8.3677 exploreP:0.0315\n",
      "Episode:368 meanR:283.5600 R:281.0 rate:0.5620 loss:10.7216 exploreP:0.0309\n",
      "Episode:369 meanR:286.3600 R:382.0 rate:0.7640 loss:8.2921 exploreP:0.0301\n",
      "Episode:370 meanR:287.3600 R:290.0 rate:0.5800 loss:7.8099 exploreP:0.0295\n",
      "Episode:371 meanR:289.6800 R:284.0 rate:0.5680 loss:7.6600 exploreP:0.0290\n",
      "Episode:372 meanR:292.8200 R:376.0 rate:0.7520 loss:8.7561 exploreP:0.0283\n",
      "Episode:373 meanR:295.4100 R:355.0 rate:0.7100 loss:10.1269 exploreP:0.0276\n",
      "Episode:374 meanR:297.0400 R:258.0 rate:0.5160 loss:9.9788 exploreP:0.0272\n",
      "Episode:375 meanR:298.5100 R:301.0 rate:0.6020 loss:7.1643 exploreP:0.0267\n",
      "Episode:376 meanR:302.2000 R:500.0 rate:1.0000 loss:7.7820 exploreP:0.0259\n",
      "Episode:377 meanR:304.3000 R:340.0 rate:0.6800 loss:7.6816 exploreP:0.0253\n",
      "Episode:378 meanR:305.9400 R:317.0 rate:0.6340 loss:7.7410 exploreP:0.0249\n",
      "Episode:379 meanR:307.9100 R:334.0 rate:0.6680 loss:8.3238 exploreP:0.0244\n",
      "Episode:380 meanR:309.4800 R:305.0 rate:0.6100 loss:4.9266 exploreP:0.0239\n",
      "Episode:381 meanR:311.6300 R:320.0 rate:0.6400 loss:6.5640 exploreP:0.0235\n",
      "Episode:382 meanR:312.8200 R:266.0 rate:0.5320 loss:7.0317 exploreP:0.0231\n",
      "Episode:383 meanR:315.2900 R:440.0 rate:0.8800 loss:5.8748 exploreP:0.0226\n",
      "Episode:384 meanR:315.8100 R:254.0 rate:0.5080 loss:6.3400 exploreP:0.0223\n",
      "Episode:385 meanR:317.6000 R:346.0 rate:0.6920 loss:6.2053 exploreP:0.0219\n",
      "Episode:386 meanR:318.9700 R:261.0 rate:0.5220 loss:6.6130 exploreP:0.0215\n",
      "Episode:387 meanR:319.5100 R:348.0 rate:0.6960 loss:6.3941 exploreP:0.0212\n",
      "Episode:388 meanR:320.6800 R:278.0 rate:0.5560 loss:6.0272 exploreP:0.0208\n",
      "Episode:389 meanR:323.8300 R:489.0 rate:0.9780 loss:6.4301 exploreP:0.0203\n",
      "Episode:390 meanR:325.8800 R:273.0 rate:0.5460 loss:5.1292 exploreP:0.0200\n",
      "Episode:391 meanR:328.4700 R:500.0 rate:1.0000 loss:5.6906 exploreP:0.0196\n",
      "Episode:392 meanR:330.7100 R:407.0 rate:0.8140 loss:5.6587 exploreP:0.0192\n",
      "Episode:393 meanR:331.7300 R:278.0 rate:0.5560 loss:6.6226 exploreP:0.0189\n",
      "Episode:394 meanR:333.3600 R:500.0 rate:1.0000 loss:5.2859 exploreP:0.0185\n",
      "Episode:395 meanR:333.5100 R:279.0 rate:0.5580 loss:7.1273 exploreP:0.0183\n",
      "Episode:396 meanR:332.8700 R:274.0 rate:0.5480 loss:4.8932 exploreP:0.0180\n",
      "Episode:397 meanR:333.2700 R:260.0 rate:0.5200 loss:6.1884 exploreP:0.0178\n",
      "Episode:398 meanR:334.0600 R:300.0 rate:0.6000 loss:5.2366 exploreP:0.0176\n",
      "Episode:399 meanR:336.7800 R:500.0 rate:1.0000 loss:5.3751 exploreP:0.0172\n",
      "Episode:400 meanR:337.5600 R:500.0 rate:1.0000 loss:5.3589 exploreP:0.0169\n",
      "Episode:401 meanR:338.5800 R:307.0 rate:0.6140 loss:7.6463 exploreP:0.0167\n",
      "Episode:402 meanR:340.1100 R:388.0 rate:0.7760 loss:5.4121 exploreP:0.0164\n",
      "Episode:403 meanR:343.0900 R:482.0 rate:0.9640 loss:5.7735 exploreP:0.0161\n",
      "Episode:404 meanR:343.8600 R:322.0 rate:0.6440 loss:5.7746 exploreP:0.0159\n",
      "Episode:405 meanR:343.9900 R:293.0 rate:0.5860 loss:5.4781 exploreP:0.0157\n",
      "Episode:406 meanR:346.3300 R:500.0 rate:1.0000 loss:5.5245 exploreP:0.0155\n",
      "Episode:407 meanR:348.0200 R:400.0 rate:0.8000 loss:5.8404 exploreP:0.0153\n",
      "Episode:408 meanR:349.5500 R:353.0 rate:0.7060 loss:5.3106 exploreP:0.0151\n",
      "Episode:409 meanR:351.1500 R:500.0 rate:1.0000 loss:5.0850 exploreP:0.0148\n",
      "Episode:410 meanR:351.8300 R:271.0 rate:0.5420 loss:4.5024 exploreP:0.0147\n",
      "Episode:411 meanR:349.6000 R:277.0 rate:0.5540 loss:8.4510 exploreP:0.0146\n",
      "Episode:412 meanR:350.5000 R:294.0 rate:0.5880 loss:5.8481 exploreP:0.0144\n",
      "Episode:413 meanR:351.5200 R:333.0 rate:0.6660 loss:6.5394 exploreP:0.0143\n",
      "Episode:414 meanR:350.6000 R:311.0 rate:0.6220 loss:4.4857 exploreP:0.0142\n",
      "Episode:415 meanR:353.5600 R:500.0 rate:1.0000 loss:4.5342 exploreP:0.0140\n",
      "Episode:416 meanR:356.4600 R:500.0 rate:1.0000 loss:6.9889 exploreP:0.0138\n",
      "Episode:417 meanR:356.8400 R:280.0 rate:0.5600 loss:6.1980 exploreP:0.0137\n",
      "Episode:418 meanR:356.2300 R:344.0 rate:0.6880 loss:5.8382 exploreP:0.0135\n",
      "Episode:419 meanR:356.8900 R:404.0 rate:0.8080 loss:5.3707 exploreP:0.0134\n",
      "Episode:420 meanR:357.6800 R:390.0 rate:0.7800 loss:4.8302 exploreP:0.0133\n",
      "Episode:421 meanR:358.7900 R:347.0 rate:0.6940 loss:3.7803 exploreP:0.0132\n",
      "Episode:422 meanR:360.9900 R:500.0 rate:1.0000 loss:5.8628 exploreP:0.0130\n",
      "Episode:423 meanR:360.0700 R:275.0 rate:0.5500 loss:4.3669 exploreP:0.0129\n",
      "Episode:424 meanR:362.5100 R:500.0 rate:1.0000 loss:5.1914 exploreP:0.0128\n",
      "Episode:425 meanR:360.4200 R:291.0 rate:0.5820 loss:4.8235 exploreP:0.0127\n",
      "Episode:426 meanR:363.1100 R:500.0 rate:1.0000 loss:6.2190 exploreP:0.0126\n",
      "Episode:427 meanR:361.4200 R:331.0 rate:0.6620 loss:6.4468 exploreP:0.0125\n",
      "Episode:428 meanR:361.4200 R:500.0 rate:1.0000 loss:4.4998 exploreP:0.0124\n",
      "Episode:429 meanR:360.9500 R:453.0 rate:0.9060 loss:5.2322 exploreP:0.0123\n",
      "Episode:430 meanR:359.8800 R:304.0 rate:0.6080 loss:3.7180 exploreP:0.0122\n",
      "Episode:431 meanR:359.5900 R:451.0 rate:0.9020 loss:4.6008 exploreP:0.0121\n",
      "Episode:432 meanR:357.6000 R:288.0 rate:0.5760 loss:5.9446 exploreP:0.0120\n",
      "Episode:433 meanR:357.5100 R:491.0 rate:0.9820 loss:4.0052 exploreP:0.0119\n",
      "Episode:434 meanR:356.1000 R:328.0 rate:0.6560 loss:3.5569 exploreP:0.0119\n",
      "Episode:435 meanR:357.2000 R:500.0 rate:1.0000 loss:4.8914 exploreP:0.0118\n",
      "Episode:436 meanR:357.8200 R:500.0 rate:1.0000 loss:5.0440 exploreP:0.0117\n",
      "Episode:437 meanR:358.7100 R:463.0 rate:0.9260 loss:5.7914 exploreP:0.0116\n",
      "Episode:438 meanR:358.1800 R:287.0 rate:0.5740 loss:5.3229 exploreP:0.0116\n",
      "Episode:439 meanR:357.5200 R:271.0 rate:0.5420 loss:5.2987 exploreP:0.0115\n",
      "Episode:440 meanR:356.7600 R:270.0 rate:0.5400 loss:5.7328 exploreP:0.0115\n",
      "Episode:441 meanR:357.2900 R:366.0 rate:0.7320 loss:5.9340 exploreP:0.0114\n",
      "Episode:442 meanR:358.7600 R:500.0 rate:1.0000 loss:5.9345 exploreP:0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:443 meanR:358.0700 R:269.0 rate:0.5380 loss:3.9018 exploreP:0.0113\n",
      "Episode:444 meanR:357.3500 R:289.0 rate:0.5780 loss:5.3490 exploreP:0.0113\n",
      "Episode:445 meanR:358.9900 R:500.0 rate:1.0000 loss:3.5359 exploreP:0.0112\n",
      "Episode:446 meanR:359.1600 R:299.0 rate:0.5980 loss:5.5375 exploreP:0.0112\n",
      "Episode:447 meanR:359.2800 R:368.0 rate:0.7360 loss:5.8241 exploreP:0.0111\n",
      "Episode:448 meanR:359.5700 R:347.0 rate:0.6940 loss:5.6850 exploreP:0.0111\n",
      "Episode:449 meanR:360.0900 R:435.0 rate:0.8700 loss:4.8842 exploreP:0.0111\n",
      "Episode:450 meanR:359.6100 R:310.0 rate:0.6200 loss:4.9554 exploreP:0.0110\n",
      "Episode:451 meanR:361.3200 R:500.0 rate:1.0000 loss:4.3705 exploreP:0.0110\n",
      "Episode:452 meanR:361.7000 R:368.0 rate:0.7360 loss:3.4490 exploreP:0.0109\n",
      "Episode:453 meanR:361.1800 R:294.0 rate:0.5880 loss:4.6133 exploreP:0.0109\n",
      "Episode:454 meanR:361.5200 R:323.0 rate:0.6460 loss:3.6791 exploreP:0.0109\n",
      "Episode:455 meanR:362.7200 R:417.0 rate:0.8340 loss:4.4685 exploreP:0.0109\n",
      "Episode:456 meanR:362.0200 R:234.0 rate:0.4680 loss:3.0553 exploreP:0.0108\n",
      "Episode:457 meanR:362.2600 R:366.0 rate:0.7320 loss:4.6408 exploreP:0.0108\n",
      "Episode:458 meanR:362.6300 R:336.0 rate:0.6720 loss:4.6310 exploreP:0.0108\n",
      "Episode:459 meanR:364.4200 R:500.0 rate:1.0000 loss:4.1047 exploreP:0.0107\n",
      "Episode:460 meanR:364.9800 R:456.0 rate:0.9120 loss:4.8727 exploreP:0.0107\n",
      "Episode:461 meanR:365.5400 R:443.0 rate:0.8860 loss:4.7665 exploreP:0.0107\n",
      "Episode:462 meanR:367.0900 R:478.0 rate:0.9560 loss:4.6157 exploreP:0.0106\n",
      "Episode:463 meanR:366.5200 R:252.0 rate:0.5040 loss:5.8731 exploreP:0.0106\n",
      "Episode:464 meanR:366.3000 R:293.0 rate:0.5860 loss:4.0420 exploreP:0.0106\n",
      "Episode:465 meanR:367.7000 R:500.0 rate:1.0000 loss:4.3433 exploreP:0.0106\n",
      "Episode:466 meanR:368.3100 R:399.0 rate:0.7980 loss:4.1972 exploreP:0.0106\n",
      "Episode:467 meanR:370.3700 R:500.0 rate:1.0000 loss:4.3380 exploreP:0.0105\n",
      "Episode:468 meanR:372.4500 R:489.0 rate:0.9780 loss:4.7592 exploreP:0.0105\n",
      "Episode:469 meanR:373.6300 R:500.0 rate:1.0000 loss:4.9180 exploreP:0.0105\n",
      "Episode:470 meanR:374.1500 R:342.0 rate:0.6840 loss:2.7876 exploreP:0.0105\n",
      "Episode:471 meanR:374.8000 R:349.0 rate:0.6980 loss:2.8729 exploreP:0.0104\n",
      "Episode:472 meanR:374.4100 R:337.0 rate:0.6740 loss:4.0234 exploreP:0.0104\n",
      "Episode:473 meanR:374.0500 R:319.0 rate:0.6380 loss:3.2151 exploreP:0.0104\n",
      "Episode:474 meanR:375.3500 R:388.0 rate:0.7760 loss:3.2691 exploreP:0.0104\n",
      "Episode:475 meanR:376.1000 R:376.0 rate:0.7520 loss:5.3252 exploreP:0.0104\n",
      "Episode:476 meanR:373.4800 R:238.0 rate:0.4760 loss:4.0911 exploreP:0.0104\n",
      "Episode:477 meanR:374.4800 R:440.0 rate:0.8800 loss:3.7400 exploreP:0.0104\n",
      "Episode:478 meanR:374.2900 R:298.0 rate:0.5960 loss:5.4268 exploreP:0.0104\n",
      "Episode:479 meanR:374.5000 R:355.0 rate:0.7100 loss:4.1462 exploreP:0.0103\n",
      "Episode:480 meanR:373.9300 R:248.0 rate:0.4960 loss:5.5790 exploreP:0.0103\n",
      "Episode:481 meanR:374.0000 R:327.0 rate:0.6540 loss:3.7419 exploreP:0.0103\n",
      "Episode:482 meanR:373.7200 R:238.0 rate:0.4760 loss:2.7156 exploreP:0.0103\n",
      "Episode:483 meanR:371.7400 R:242.0 rate:0.4840 loss:4.4036 exploreP:0.0103\n",
      "Episode:484 meanR:372.0400 R:284.0 rate:0.5680 loss:5.5827 exploreP:0.0103\n",
      "Episode:485 meanR:371.9500 R:337.0 rate:0.6740 loss:4.3367 exploreP:0.0103\n",
      "Episode:486 meanR:373.5600 R:422.0 rate:0.8440 loss:4.1636 exploreP:0.0103\n",
      "Episode:487 meanR:373.3500 R:327.0 rate:0.6540 loss:4.1528 exploreP:0.0103\n",
      "Episode:488 meanR:374.1300 R:356.0 rate:0.7120 loss:4.3139 exploreP:0.0103\n",
      "Episode:489 meanR:372.2600 R:302.0 rate:0.6040 loss:4.4501 exploreP:0.0102\n",
      "Episode:490 meanR:373.2500 R:372.0 rate:0.7440 loss:3.9832 exploreP:0.0102\n",
      "Episode:491 meanR:372.9300 R:468.0 rate:0.9360 loss:2.9410 exploreP:0.0102\n",
      "Episode:492 meanR:373.8600 R:500.0 rate:1.0000 loss:3.5393 exploreP:0.0102\n",
      "Episode:493 meanR:374.1600 R:308.0 rate:0.6160 loss:3.9290 exploreP:0.0102\n",
      "Episode:494 meanR:373.3800 R:422.0 rate:0.8440 loss:3.1151 exploreP:0.0102\n",
      "Episode:495 meanR:374.9800 R:439.0 rate:0.8780 loss:3.5548 exploreP:0.0102\n",
      "Episode:496 meanR:375.3500 R:311.0 rate:0.6220 loss:4.4948 exploreP:0.0102\n",
      "Episode:497 meanR:375.8600 R:311.0 rate:0.6220 loss:5.1216 exploreP:0.0102\n",
      "Episode:498 meanR:375.5500 R:269.0 rate:0.5380 loss:3.1167 exploreP:0.0102\n",
      "Episode:499 meanR:373.6800 R:313.0 rate:0.6260 loss:2.9715 exploreP:0.0102\n",
      "Episode:500 meanR:372.6800 R:400.0 rate:0.8000 loss:3.0035 exploreP:0.0102\n",
      "Episode:501 meanR:373.6900 R:408.0 rate:0.8160 loss:2.3585 exploreP:0.0102\n",
      "Episode:502 meanR:373.1100 R:330.0 rate:0.6600 loss:3.8269 exploreP:0.0102\n",
      "Episode:503 meanR:371.4800 R:319.0 rate:0.6380 loss:3.5887 exploreP:0.0101\n",
      "Episode:504 meanR:373.2600 R:500.0 rate:1.0000 loss:3.3485 exploreP:0.0101\n",
      "Episode:505 meanR:374.0600 R:373.0 rate:0.7460 loss:2.6920 exploreP:0.0101\n",
      "Episode:506 meanR:371.6900 R:263.0 rate:0.5260 loss:2.8867 exploreP:0.0101\n",
      "Episode:507 meanR:371.6400 R:395.0 rate:0.7900 loss:3.2089 exploreP:0.0101\n",
      "Episode:508 meanR:371.5300 R:342.0 rate:0.6840 loss:3.2177 exploreP:0.0101\n",
      "Episode:509 meanR:371.5200 R:499.0 rate:0.9980 loss:3.5119 exploreP:0.0101\n",
      "Episode:510 meanR:373.5600 R:475.0 rate:0.9500 loss:3.3442 exploreP:0.0101\n",
      "Episode:511 meanR:375.6200 R:483.0 rate:0.9660 loss:3.7328 exploreP:0.0101\n",
      "Episode:512 meanR:376.1700 R:349.0 rate:0.6980 loss:2.9252 exploreP:0.0101\n",
      "Episode:513 meanR:376.2700 R:343.0 rate:0.6860 loss:3.2533 exploreP:0.0101\n",
      "Episode:514 meanR:377.8000 R:464.0 rate:0.9280 loss:3.4446 exploreP:0.0101\n",
      "Episode:515 meanR:375.9000 R:310.0 rate:0.6200 loss:3.4921 exploreP:0.0101\n",
      "Episode:516 meanR:373.8100 R:291.0 rate:0.5820 loss:4.0677 exploreP:0.0101\n",
      "Episode:517 meanR:374.3700 R:336.0 rate:0.6720 loss:3.2512 exploreP:0.0101\n",
      "Episode:518 meanR:374.4600 R:353.0 rate:0.7060 loss:3.2682 exploreP:0.0101\n",
      "Episode:519 meanR:375.4200 R:500.0 rate:1.0000 loss:2.5643 exploreP:0.0101\n",
      "Episode:520 meanR:375.0000 R:348.0 rate:0.6960 loss:2.4313 exploreP:0.0101\n",
      "Episode:521 meanR:375.4600 R:393.0 rate:0.7860 loss:3.6034 exploreP:0.0101\n",
      "Episode:522 meanR:375.1300 R:467.0 rate:0.9340 loss:3.0561 exploreP:0.0101\n",
      "Episode:523 meanR:375.9600 R:358.0 rate:0.7160 loss:4.4890 exploreP:0.0101\n",
      "Episode:524 meanR:375.9600 R:500.0 rate:1.0000 loss:4.2295 exploreP:0.0101\n",
      "Episode:525 meanR:377.5600 R:451.0 rate:0.9020 loss:2.7095 exploreP:0.0101\n",
      "Episode:526 meanR:377.5600 R:500.0 rate:1.0000 loss:2.0266 exploreP:0.0101\n",
      "Episode:527 meanR:379.2500 R:500.0 rate:1.0000 loss:3.2161 exploreP:0.0101\n",
      "Episode:528 meanR:379.2500 R:500.0 rate:1.0000 loss:3.5780 exploreP:0.0101\n",
      "Episode:529 meanR:379.7200 R:500.0 rate:1.0000 loss:3.2656 exploreP:0.0101\n",
      "Episode:530 meanR:381.6800 R:500.0 rate:1.0000 loss:3.1299 exploreP:0.0100\n",
      "Episode:531 meanR:380.3200 R:315.0 rate:0.6300 loss:3.8766 exploreP:0.0100\n",
      "Episode:532 meanR:381.3200 R:388.0 rate:0.7760 loss:2.4559 exploreP:0.0100\n",
      "Episode:533 meanR:379.0200 R:261.0 rate:0.5220 loss:3.4444 exploreP:0.0100\n",
      "Episode:534 meanR:378.9100 R:317.0 rate:0.6340 loss:3.2900 exploreP:0.0100\n",
      "Episode:535 meanR:378.6100 R:470.0 rate:0.9400 loss:3.2811 exploreP:0.0100\n",
      "Episode:536 meanR:377.0700 R:346.0 rate:0.6920 loss:3.4503 exploreP:0.0100\n",
      "Episode:537 meanR:377.4400 R:500.0 rate:1.0000 loss:3.4176 exploreP:0.0100\n",
      "Episode:538 meanR:379.1400 R:457.0 rate:0.9140 loss:3.4783 exploreP:0.0100\n",
      "Episode:539 meanR:379.8800 R:345.0 rate:0.6900 loss:3.6036 exploreP:0.0100\n",
      "Episode:540 meanR:380.2500 R:307.0 rate:0.6140 loss:3.7194 exploreP:0.0100\n",
      "Episode:541 meanR:379.5000 R:291.0 rate:0.5820 loss:2.9909 exploreP:0.0100\n",
      "Episode:542 meanR:377.5300 R:303.0 rate:0.6060 loss:4.1159 exploreP:0.0100\n",
      "Episode:543 meanR:377.7600 R:292.0 rate:0.5840 loss:3.0522 exploreP:0.0100\n",
      "Episode:544 meanR:378.0900 R:322.0 rate:0.6440 loss:3.3853 exploreP:0.0100\n",
      "Episode:545 meanR:375.7200 R:263.0 rate:0.5260 loss:2.3423 exploreP:0.0100\n",
      "Episode:546 meanR:375.9700 R:324.0 rate:0.6480 loss:4.4010 exploreP:0.0100\n",
      "Episode:547 meanR:375.6000 R:331.0 rate:0.6620 loss:2.7795 exploreP:0.0100\n",
      "Episode:548 meanR:374.7500 R:262.0 rate:0.5240 loss:5.3802 exploreP:0.0100\n",
      "Episode:549 meanR:374.2100 R:381.0 rate:0.7620 loss:4.1636 exploreP:0.0100\n",
      "Episode:550 meanR:374.8300 R:372.0 rate:0.7440 loss:2.7450 exploreP:0.0100\n",
      "Episode:551 meanR:372.3500 R:252.0 rate:0.5040 loss:4.0151 exploreP:0.0100\n",
      "Episode:552 meanR:372.8000 R:413.0 rate:0.8260 loss:3.4548 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:553 meanR:374.8600 R:500.0 rate:1.0000 loss:3.9036 exploreP:0.0100\n",
      "Episode:554 meanR:376.5700 R:494.0 rate:0.9880 loss:3.0027 exploreP:0.0100\n",
      "Episode:555 meanR:376.0000 R:360.0 rate:0.7200 loss:3.6204 exploreP:0.0100\n",
      "Episode:556 meanR:376.9900 R:333.0 rate:0.6660 loss:3.3993 exploreP:0.0100\n",
      "Episode:557 meanR:378.3300 R:500.0 rate:1.0000 loss:3.0046 exploreP:0.0100\n",
      "Episode:558 meanR:379.9700 R:500.0 rate:1.0000 loss:2.9419 exploreP:0.0100\n",
      "Episode:559 meanR:378.6300 R:366.0 rate:0.7320 loss:2.9142 exploreP:0.0100\n",
      "Episode:560 meanR:376.8500 R:278.0 rate:0.5560 loss:2.8469 exploreP:0.0100\n",
      "Episode:561 meanR:376.9900 R:457.0 rate:0.9140 loss:3.2923 exploreP:0.0100\n",
      "Episode:562 meanR:376.2700 R:406.0 rate:0.8120 loss:2.5615 exploreP:0.0100\n",
      "Episode:563 meanR:376.2700 R:252.0 rate:0.5040 loss:4.4205 exploreP:0.0100\n",
      "Episode:564 meanR:376.4000 R:306.0 rate:0.6120 loss:2.9456 exploreP:0.0100\n",
      "Episode:565 meanR:374.4000 R:300.0 rate:0.6000 loss:1.7660 exploreP:0.0100\n",
      "Episode:566 meanR:375.3700 R:496.0 rate:0.9920 loss:3.4091 exploreP:0.0100\n",
      "Episode:567 meanR:373.7100 R:334.0 rate:0.6680 loss:4.1103 exploreP:0.0100\n",
      "Episode:568 meanR:371.3000 R:248.0 rate:0.4960 loss:2.7334 exploreP:0.0100\n",
      "Episode:569 meanR:370.2600 R:396.0 rate:0.7920 loss:2.6655 exploreP:0.0100\n",
      "Episode:570 meanR:368.5400 R:170.0 rate:0.3400 loss:2.6575 exploreP:0.0100\n",
      "Episode:571 meanR:367.5100 R:246.0 rate:0.4920 loss:3.3439 exploreP:0.0100\n",
      "Episode:572 meanR:366.4300 R:229.0 rate:0.4580 loss:2.3152 exploreP:0.0100\n",
      "Episode:573 meanR:366.5800 R:334.0 rate:0.6680 loss:4.6400 exploreP:0.0100\n",
      "Episode:574 meanR:366.0100 R:331.0 rate:0.6620 loss:2.3239 exploreP:0.0100\n",
      "Episode:575 meanR:364.1700 R:192.0 rate:0.3840 loss:2.9673 exploreP:0.0100\n",
      "Episode:576 meanR:364.8200 R:303.0 rate:0.6060 loss:1.5818 exploreP:0.0100\n",
      "Episode:577 meanR:362.6900 R:227.0 rate:0.4540 loss:2.8703 exploreP:0.0100\n",
      "Episode:578 meanR:360.4800 R:77.0 rate:0.1540 loss:2.3949 exploreP:0.0100\n",
      "Episode:579 meanR:357.6500 R:72.0 rate:0.1440 loss:1.2249 exploreP:0.0100\n",
      "Episode:580 meanR:355.8500 R:68.0 rate:0.1360 loss:4.0395 exploreP:0.0100\n",
      "Episode:581 meanR:353.1200 R:54.0 rate:0.1080 loss:2.2288 exploreP:0.0100\n",
      "Episode:582 meanR:351.2500 R:51.0 rate:0.1020 loss:5.8132 exploreP:0.0100\n",
      "Episode:583 meanR:349.6100 R:78.0 rate:0.1560 loss:1.6473 exploreP:0.0100\n",
      "Episode:584 meanR:347.6000 R:83.0 rate:0.1660 loss:4.2460 exploreP:0.0100\n",
      "Episode:585 meanR:345.3300 R:110.0 rate:0.2200 loss:2.1439 exploreP:0.0100\n",
      "Episode:586 meanR:342.3200 R:121.0 rate:0.2420 loss:3.6891 exploreP:0.0100\n",
      "Episode:587 meanR:340.0400 R:99.0 rate:0.1980 loss:2.5496 exploreP:0.0100\n",
      "Episode:588 meanR:338.0600 R:158.0 rate:0.3160 loss:2.7080 exploreP:0.0100\n",
      "Episode:589 meanR:339.7200 R:468.0 rate:0.9360 loss:3.3984 exploreP:0.0100\n",
      "Episode:590 meanR:338.4200 R:242.0 rate:0.4840 loss:2.7891 exploreP:0.0100\n",
      "Episode:591 meanR:336.8600 R:312.0 rate:0.6240 loss:1.0860 exploreP:0.0100\n",
      "Episode:592 meanR:333.2100 R:135.0 rate:0.2700 loss:0.6599 exploreP:0.0100\n",
      "Episode:593 meanR:335.1300 R:500.0 rate:1.0000 loss:2.0943 exploreP:0.0100\n",
      "Episode:594 meanR:335.9100 R:500.0 rate:1.0000 loss:3.5091 exploreP:0.0100\n",
      "Episode:595 meanR:331.6200 R:10.0 rate:0.0200 loss:4.3302 exploreP:0.0100\n",
      "Episode:596 meanR:328.6000 R:9.0 rate:0.0180 loss:36.0264 exploreP:0.0100\n",
      "Episode:597 meanR:325.5800 R:9.0 rate:0.0180 loss:9.2861 exploreP:0.0100\n",
      "Episode:598 meanR:322.9700 R:8.0 rate:0.0160 loss:12.7109 exploreP:0.0100\n",
      "Episode:599 meanR:319.9300 R:9.0 rate:0.0180 loss:21.2302 exploreP:0.0100\n",
      "Episode:600 meanR:316.0200 R:9.0 rate:0.0180 loss:39.1777 exploreP:0.0100\n",
      "Episode:601 meanR:312.0300 R:9.0 rate:0.0180 loss:28.2047 exploreP:0.0100\n",
      "Episode:602 meanR:308.8200 R:9.0 rate:0.0180 loss:16.0261 exploreP:0.0100\n",
      "Episode:603 meanR:305.7100 R:8.0 rate:0.0160 loss:82.0731 exploreP:0.0100\n",
      "Episode:604 meanR:300.8100 R:10.0 rate:0.0200 loss:46.4876 exploreP:0.0100\n",
      "Episode:605 meanR:297.1600 R:8.0 rate:0.0160 loss:29.7332 exploreP:0.0100\n",
      "Episode:606 meanR:294.6300 R:10.0 rate:0.0200 loss:74.9572 exploreP:0.0100\n",
      "Episode:607 meanR:290.7600 R:8.0 rate:0.0160 loss:36.6174 exploreP:0.0100\n",
      "Episode:608 meanR:287.4400 R:10.0 rate:0.0200 loss:55.8258 exploreP:0.0100\n",
      "Episode:609 meanR:282.5600 R:11.0 rate:0.0220 loss:164.7649 exploreP:0.0100\n",
      "Episode:610 meanR:277.8900 R:8.0 rate:0.0160 loss:50.5109 exploreP:0.0100\n",
      "Episode:611 meanR:273.1600 R:10.0 rate:0.0200 loss:124.0041 exploreP:0.0100\n",
      "Episode:612 meanR:269.7600 R:9.0 rate:0.0180 loss:224.9927 exploreP:0.0100\n",
      "Episode:613 meanR:266.4200 R:9.0 rate:0.0180 loss:97.9337 exploreP:0.0100\n",
      "Episode:614 meanR:261.8700 R:9.0 rate:0.0180 loss:73.6413 exploreP:0.0100\n",
      "Episode:615 meanR:258.8600 R:9.0 rate:0.0180 loss:14.8385 exploreP:0.0100\n",
      "Episode:616 meanR:256.0400 R:9.0 rate:0.0180 loss:133.6149 exploreP:0.0100\n",
      "Episode:617 meanR:252.7700 R:9.0 rate:0.0180 loss:382.2247 exploreP:0.0100\n",
      "Episode:618 meanR:249.3400 R:10.0 rate:0.0200 loss:540.9999 exploreP:0.0100\n",
      "Episode:619 meanR:244.4300 R:9.0 rate:0.0180 loss:573.4755 exploreP:0.0100\n",
      "Episode:620 meanR:241.0500 R:10.0 rate:0.0200 loss:121.5214 exploreP:0.0100\n",
      "Episode:621 meanR:237.2200 R:10.0 rate:0.0200 loss:94.9854 exploreP:0.0100\n",
      "Episode:622 meanR:232.6400 R:9.0 rate:0.0180 loss:345.1613 exploreP:0.0100\n",
      "Episode:623 meanR:229.1600 R:10.0 rate:0.0200 loss:259.4396 exploreP:0.0100\n",
      "Episode:624 meanR:224.2500 R:9.0 rate:0.0180 loss:640.8843 exploreP:0.0100\n",
      "Episode:625 meanR:219.8300 R:9.0 rate:0.0180 loss:31.9087 exploreP:0.0100\n",
      "Episode:626 meanR:214.9200 R:9.0 rate:0.0180 loss:625.1661 exploreP:0.0100\n",
      "Episode:627 meanR:210.0100 R:9.0 rate:0.0180 loss:523.7475 exploreP:0.0100\n",
      "Episode:628 meanR:205.1200 R:11.0 rate:0.0220 loss:407.3125 exploreP:0.0100\n",
      "Episode:629 meanR:200.2200 R:10.0 rate:0.0200 loss:814.4398 exploreP:0.0100\n",
      "Episode:630 meanR:195.3000 R:8.0 rate:0.0160 loss:555.2725 exploreP:0.0100\n",
      "Episode:631 meanR:192.2400 R:9.0 rate:0.0180 loss:565.7234 exploreP:0.0100\n",
      "Episode:632 meanR:188.4700 R:11.0 rate:0.0220 loss:498.8765 exploreP:0.0100\n",
      "Episode:633 meanR:185.9600 R:10.0 rate:0.0200 loss:582.9019 exploreP:0.0100\n",
      "Episode:634 meanR:182.8800 R:9.0 rate:0.0180 loss:830.6524 exploreP:0.0100\n",
      "Episode:635 meanR:178.2800 R:10.0 rate:0.0200 loss:1779.0088 exploreP:0.0100\n",
      "Episode:636 meanR:174.9100 R:9.0 rate:0.0180 loss:438.6267 exploreP:0.0100\n",
      "Episode:637 meanR:170.0000 R:9.0 rate:0.0180 loss:1098.0356 exploreP:0.0100\n",
      "Episode:638 meanR:165.5300 R:10.0 rate:0.0200 loss:693.7098 exploreP:0.0100\n",
      "Episode:639 meanR:162.1600 R:8.0 rate:0.0160 loss:336.0984 exploreP:0.0100\n",
      "Episode:640 meanR:159.2000 R:11.0 rate:0.0220 loss:273.1986 exploreP:0.0100\n",
      "Episode:641 meanR:156.3800 R:9.0 rate:0.0180 loss:1819.3837 exploreP:0.0100\n",
      "Episode:642 meanR:153.4400 R:9.0 rate:0.0180 loss:556.5029 exploreP:0.0100\n",
      "Episode:643 meanR:150.6200 R:10.0 rate:0.0200 loss:541.1774 exploreP:0.0100\n",
      "Episode:644 meanR:147.5200 R:12.0 rate:0.0240 loss:1138.0746 exploreP:0.0100\n",
      "Episode:645 meanR:144.9700 R:8.0 rate:0.0160 loss:1028.7404 exploreP:0.0100\n",
      "Episode:646 meanR:141.8300 R:10.0 rate:0.0200 loss:1911.3822 exploreP:0.0100\n",
      "Episode:647 meanR:138.6100 R:9.0 rate:0.0180 loss:2219.2468 exploreP:0.0100\n",
      "Episode:648 meanR:136.0700 R:8.0 rate:0.0160 loss:490.4987 exploreP:0.0100\n",
      "Episode:649 meanR:132.3600 R:10.0 rate:0.0200 loss:173.9432 exploreP:0.0100\n",
      "Episode:650 meanR:128.7300 R:9.0 rate:0.0180 loss:183.3236 exploreP:0.0100\n",
      "Episode:651 meanR:126.3000 R:9.0 rate:0.0180 loss:1562.4064 exploreP:0.0100\n",
      "Episode:652 meanR:122.2700 R:10.0 rate:0.0200 loss:2251.6963 exploreP:0.0100\n",
      "Episode:653 meanR:117.3700 R:10.0 rate:0.0200 loss:2043.7327 exploreP:0.0100\n",
      "Episode:654 meanR:112.5300 R:10.0 rate:0.0200 loss:1320.7279 exploreP:0.0100\n",
      "Episode:655 meanR:109.0300 R:10.0 rate:0.0200 loss:224.0313 exploreP:0.0100\n",
      "Episode:656 meanR:105.7900 R:9.0 rate:0.0180 loss:2948.8928 exploreP:0.0100\n",
      "Episode:657 meanR:100.8900 R:10.0 rate:0.0200 loss:3129.8191 exploreP:0.0100\n",
      "Episode:658 meanR:95.9900 R:10.0 rate:0.0200 loss:1523.8699 exploreP:0.0100\n",
      "Episode:659 meanR:92.4100 R:8.0 rate:0.0160 loss:1956.6952 exploreP:0.0100\n",
      "Episode:660 meanR:89.7300 R:10.0 rate:0.0200 loss:2667.2637 exploreP:0.0100\n",
      "Episode:661 meanR:85.2500 R:9.0 rate:0.0180 loss:2989.4800 exploreP:0.0100\n",
      "Episode:662 meanR:81.2800 R:9.0 rate:0.0180 loss:1508.9330 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:663 meanR:78.8400 R:8.0 rate:0.0160 loss:937.3717 exploreP:0.0100\n",
      "Episode:664 meanR:75.8800 R:10.0 rate:0.0200 loss:4326.5596 exploreP:0.0100\n",
      "Episode:665 meanR:72.9600 R:8.0 rate:0.0160 loss:2266.9880 exploreP:0.0100\n",
      "Episode:666 meanR:68.1000 R:10.0 rate:0.0200 loss:5106.5063 exploreP:0.0100\n",
      "Episode:667 meanR:64.8600 R:10.0 rate:0.0200 loss:3698.2329 exploreP:0.0100\n",
      "Episode:668 meanR:62.4800 R:10.0 rate:0.0200 loss:390.6494 exploreP:0.0100\n",
      "Episode:669 meanR:58.6200 R:10.0 rate:0.0200 loss:4927.5039 exploreP:0.0100\n",
      "Episode:670 meanR:57.0100 R:9.0 rate:0.0180 loss:2770.1675 exploreP:0.0100\n",
      "Episode:671 meanR:54.6400 R:9.0 rate:0.0180 loss:7044.0859 exploreP:0.0100\n",
      "Episode:672 meanR:52.4500 R:10.0 rate:0.0200 loss:3607.1614 exploreP:0.0100\n",
      "Episode:673 meanR:49.2000 R:9.0 rate:0.0180 loss:3831.0161 exploreP:0.0100\n",
      "Episode:674 meanR:45.9900 R:10.0 rate:0.0200 loss:5247.7485 exploreP:0.0100\n",
      "Episode:675 meanR:44.1600 R:9.0 rate:0.0180 loss:2243.1470 exploreP:0.0100\n",
      "Episode:676 meanR:41.2300 R:10.0 rate:0.0200 loss:3639.6516 exploreP:0.0100\n",
      "Episode:677 meanR:39.0400 R:8.0 rate:0.0160 loss:2775.2515 exploreP:0.0100\n",
      "Episode:678 meanR:38.3600 R:9.0 rate:0.0180 loss:4549.9102 exploreP:0.0100\n",
      "Episode:679 meanR:37.7300 R:9.0 rate:0.0180 loss:4163.2368 exploreP:0.0100\n",
      "Episode:680 meanR:37.1400 R:9.0 rate:0.0180 loss:4756.7197 exploreP:0.0100\n",
      "Episode:681 meanR:36.7000 R:10.0 rate:0.0200 loss:3688.0540 exploreP:0.0100\n",
      "Episode:682 meanR:36.2900 R:10.0 rate:0.0200 loss:8150.4946 exploreP:0.0100\n",
      "Episode:683 meanR:35.6000 R:9.0 rate:0.0180 loss:5260.6206 exploreP:0.0100\n",
      "Episode:684 meanR:34.8600 R:9.0 rate:0.0180 loss:4086.9189 exploreP:0.0100\n",
      "Episode:685 meanR:33.8600 R:10.0 rate:0.0200 loss:7200.0781 exploreP:0.0100\n",
      "Episode:686 meanR:32.7400 R:9.0 rate:0.0180 loss:8996.8945 exploreP:0.0100\n",
      "Episode:687 meanR:31.8500 R:10.0 rate:0.0200 loss:2928.0417 exploreP:0.0100\n",
      "Episode:688 meanR:30.3700 R:10.0 rate:0.0200 loss:3004.8040 exploreP:0.0100\n",
      "Episode:689 meanR:25.7800 R:9.0 rate:0.0180 loss:10253.7070 exploreP:0.0100\n",
      "Episode:690 meanR:23.4600 R:10.0 rate:0.0200 loss:9437.2637 exploreP:0.0100\n",
      "Episode:691 meanR:20.4400 R:10.0 rate:0.0200 loss:1717.2699 exploreP:0.0100\n",
      "Episode:692 meanR:19.2000 R:11.0 rate:0.0220 loss:9873.8994 exploreP:0.0100\n",
      "Episode:693 meanR:14.2900 R:9.0 rate:0.0180 loss:646.9693 exploreP:0.0100\n",
      "Episode:694 meanR:9.3800 R:9.0 rate:0.0180 loss:9942.2090 exploreP:0.0100\n",
      "Episode:695 meanR:9.3800 R:10.0 rate:0.0200 loss:9526.0430 exploreP:0.0100\n",
      "Episode:696 meanR:9.3900 R:10.0 rate:0.0200 loss:6344.4214 exploreP:0.0100\n",
      "Episode:697 meanR:9.4100 R:11.0 rate:0.0220 loss:11565.9951 exploreP:0.0100\n",
      "Episode:698 meanR:9.4200 R:9.0 rate:0.0180 loss:7494.4976 exploreP:0.0100\n",
      "Episode:699 meanR:9.4300 R:10.0 rate:0.0200 loss:3365.1040 exploreP:0.0100\n",
      "Episode:700 meanR:9.4500 R:11.0 rate:0.0220 loss:9052.6758 exploreP:0.0100\n",
      "Episode:701 meanR:9.4500 R:9.0 rate:0.0180 loss:811.0551 exploreP:0.0100\n",
      "Episode:702 meanR:9.4600 R:10.0 rate:0.0200 loss:8061.9102 exploreP:0.0100\n",
      "Episode:703 meanR:9.4800 R:10.0 rate:0.0200 loss:10749.4473 exploreP:0.0100\n",
      "Episode:704 meanR:9.4800 R:10.0 rate:0.0200 loss:8365.2559 exploreP:0.0100\n",
      "Episode:705 meanR:9.4900 R:9.0 rate:0.0180 loss:4485.3149 exploreP:0.0100\n",
      "Episode:706 meanR:9.4800 R:9.0 rate:0.0180 loss:16245.4580 exploreP:0.0100\n",
      "Episode:707 meanR:9.5000 R:10.0 rate:0.0200 loss:6463.1060 exploreP:0.0100\n",
      "Episode:708 meanR:9.5000 R:10.0 rate:0.0200 loss:6666.2998 exploreP:0.0100\n",
      "Episode:709 meanR:9.5100 R:12.0 rate:0.0240 loss:7490.3218 exploreP:0.0100\n",
      "Episode:710 meanR:9.5300 R:10.0 rate:0.0200 loss:5288.1118 exploreP:0.0100\n",
      "Episode:711 meanR:9.5300 R:10.0 rate:0.0200 loss:11704.9561 exploreP:0.0100\n",
      "Episode:712 meanR:9.5300 R:9.0 rate:0.0180 loss:1098.3096 exploreP:0.0100\n",
      "Episode:713 meanR:9.5200 R:8.0 rate:0.0160 loss:9239.5625 exploreP:0.0100\n",
      "Episode:714 meanR:9.5100 R:8.0 rate:0.0160 loss:8682.4863 exploreP:0.0100\n",
      "Episode:715 meanR:9.5300 R:11.0 rate:0.0220 loss:5620.0161 exploreP:0.0100\n",
      "Episode:716 meanR:9.5400 R:10.0 rate:0.0200 loss:3237.3784 exploreP:0.0100\n",
      "Episode:717 meanR:9.5300 R:8.0 rate:0.0160 loss:21845.4180 exploreP:0.0100\n",
      "Episode:718 meanR:9.5300 R:10.0 rate:0.0200 loss:28078.8848 exploreP:0.0100\n",
      "Episode:719 meanR:9.5300 R:9.0 rate:0.0180 loss:13606.2793 exploreP:0.0100\n",
      "Episode:720 meanR:9.5300 R:10.0 rate:0.0200 loss:25187.4941 exploreP:0.0100\n",
      "Episode:721 meanR:9.5300 R:10.0 rate:0.0200 loss:13233.4561 exploreP:0.0100\n",
      "Episode:722 meanR:9.5400 R:10.0 rate:0.0200 loss:7169.9048 exploreP:0.0100\n",
      "Episode:723 meanR:9.5400 R:10.0 rate:0.0200 loss:23391.0742 exploreP:0.0100\n",
      "Episode:724 meanR:9.5400 R:9.0 rate:0.0180 loss:9615.8193 exploreP:0.0100\n",
      "Episode:725 meanR:9.5300 R:8.0 rate:0.0160 loss:1493.4395 exploreP:0.0100\n",
      "Episode:726 meanR:9.5400 R:10.0 rate:0.0200 loss:6411.7515 exploreP:0.0100\n",
      "Episode:727 meanR:9.5500 R:10.0 rate:0.0200 loss:7852.0938 exploreP:0.0100\n",
      "Episode:728 meanR:9.5300 R:9.0 rate:0.0180 loss:4102.3398 exploreP:0.0100\n",
      "Episode:729 meanR:9.5200 R:9.0 rate:0.0180 loss:28689.7148 exploreP:0.0100\n",
      "Episode:730 meanR:9.5300 R:9.0 rate:0.0180 loss:26919.9082 exploreP:0.0100\n",
      "Episode:731 meanR:9.5300 R:9.0 rate:0.0180 loss:4461.3901 exploreP:0.0100\n",
      "Episode:732 meanR:9.5200 R:10.0 rate:0.0200 loss:12367.5801 exploreP:0.0100\n",
      "Episode:733 meanR:9.5300 R:11.0 rate:0.0220 loss:19124.0977 exploreP:0.0100\n",
      "Episode:734 meanR:9.5300 R:9.0 rate:0.0180 loss:9985.3877 exploreP:0.0100\n",
      "Episode:735 meanR:9.5300 R:10.0 rate:0.0200 loss:26548.3555 exploreP:0.0100\n",
      "Episode:736 meanR:9.5500 R:11.0 rate:0.0220 loss:11400.1348 exploreP:0.0100\n",
      "Episode:737 meanR:9.5600 R:10.0 rate:0.0200 loss:21564.9648 exploreP:0.0100\n",
      "Episode:738 meanR:9.5500 R:9.0 rate:0.0180 loss:10907.7471 exploreP:0.0100\n",
      "Episode:739 meanR:9.5500 R:8.0 rate:0.0160 loss:22726.9414 exploreP:0.0100\n",
      "Episode:740 meanR:9.5400 R:10.0 rate:0.0200 loss:25465.7227 exploreP:0.0100\n",
      "Episode:741 meanR:9.5400 R:9.0 rate:0.0180 loss:20405.7500 exploreP:0.0100\n",
      "Episode:742 meanR:9.5300 R:8.0 rate:0.0160 loss:6085.1299 exploreP:0.0100\n",
      "Episode:743 meanR:9.5300 R:10.0 rate:0.0200 loss:21148.6211 exploreP:0.0100\n",
      "Episode:744 meanR:9.4900 R:8.0 rate:0.0160 loss:44102.2578 exploreP:0.0100\n",
      "Episode:745 meanR:9.5100 R:10.0 rate:0.0200 loss:2441.2703 exploreP:0.0100\n",
      "Episode:746 meanR:9.4900 R:8.0 rate:0.0160 loss:22560.7109 exploreP:0.0100\n",
      "Episode:747 meanR:9.4900 R:9.0 rate:0.0180 loss:32741.0078 exploreP:0.0100\n",
      "Episode:748 meanR:9.5100 R:10.0 rate:0.0200 loss:28851.0000 exploreP:0.0100\n",
      "Episode:749 meanR:9.4900 R:8.0 rate:0.0160 loss:2622.7134 exploreP:0.0100\n",
      "Episode:750 meanR:9.5000 R:10.0 rate:0.0200 loss:12889.3984 exploreP:0.0100\n",
      "Episode:751 meanR:9.5000 R:9.0 rate:0.0180 loss:36435.7188 exploreP:0.0100\n",
      "Episode:752 meanR:9.5000 R:10.0 rate:0.0200 loss:16998.4355 exploreP:0.0100\n",
      "Episode:753 meanR:9.4900 R:9.0 rate:0.0180 loss:11670.1143 exploreP:0.0100\n",
      "Episode:754 meanR:9.4900 R:10.0 rate:0.0200 loss:14849.9404 exploreP:0.0100\n",
      "Episode:755 meanR:9.4700 R:8.0 rate:0.0160 loss:68581.9062 exploreP:0.0100\n",
      "Episode:756 meanR:9.4600 R:8.0 rate:0.0160 loss:3007.8491 exploreP:0.0100\n",
      "Episode:757 meanR:9.4600 R:10.0 rate:0.0200 loss:50833.6406 exploreP:0.0100\n",
      "Episode:758 meanR:9.4400 R:8.0 rate:0.0160 loss:19045.2246 exploreP:0.0100\n",
      "Episode:759 meanR:9.4600 R:10.0 rate:0.0200 loss:19487.6504 exploreP:0.0100\n",
      "Episode:760 meanR:9.4600 R:10.0 rate:0.0200 loss:37220.0312 exploreP:0.0100\n",
      "Episode:761 meanR:9.4600 R:9.0 rate:0.0180 loss:58899.9453 exploreP:0.0100\n",
      "Episode:762 meanR:9.4700 R:10.0 rate:0.0200 loss:28212.0371 exploreP:0.0100\n",
      "Episode:763 meanR:9.4700 R:8.0 rate:0.0160 loss:9495.4561 exploreP:0.0100\n",
      "Episode:764 meanR:9.4600 R:9.0 rate:0.0180 loss:85254.2812 exploreP:0.0100\n",
      "Episode:765 meanR:9.4700 R:9.0 rate:0.0180 loss:18869.4785 exploreP:0.0100\n",
      "Episode:766 meanR:9.4600 R:9.0 rate:0.0180 loss:49853.6250 exploreP:0.0100\n",
      "Episode:767 meanR:9.4600 R:10.0 rate:0.0200 loss:53055.3867 exploreP:0.0100\n",
      "Episode:768 meanR:9.4500 R:9.0 rate:0.0180 loss:9017.8965 exploreP:0.0100\n",
      "Episode:769 meanR:9.4300 R:8.0 rate:0.0160 loss:32456.7891 exploreP:0.0100\n",
      "Episode:770 meanR:9.4400 R:10.0 rate:0.0200 loss:3755.8679 exploreP:0.0100\n",
      "Episode:771 meanR:9.4400 R:9.0 rate:0.0180 loss:25941.9590 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:772 meanR:9.4500 R:11.0 rate:0.0220 loss:42624.9570 exploreP:0.0100\n",
      "Episode:773 meanR:9.4600 R:10.0 rate:0.0200 loss:4003.9954 exploreP:0.0100\n",
      "Episode:774 meanR:9.4400 R:8.0 rate:0.0160 loss:25279.7930 exploreP:0.0100\n",
      "Episode:775 meanR:9.4600 R:11.0 rate:0.0220 loss:59342.9531 exploreP:0.0100\n",
      "Episode:776 meanR:9.4600 R:10.0 rate:0.0200 loss:83103.8047 exploreP:0.0100\n",
      "Episode:777 meanR:9.4700 R:9.0 rate:0.0180 loss:30432.8965 exploreP:0.0100\n",
      "Episode:778 meanR:9.4700 R:9.0 rate:0.0180 loss:28886.3457 exploreP:0.0100\n",
      "Episode:779 meanR:9.4700 R:9.0 rate:0.0180 loss:44082.1875 exploreP:0.0100\n",
      "Episode:780 meanR:9.4700 R:9.0 rate:0.0180 loss:49083.7656 exploreP:0.0100\n",
      "Episode:781 meanR:9.4600 R:9.0 rate:0.0180 loss:16600.3730 exploreP:0.0100\n",
      "Episode:782 meanR:9.4400 R:8.0 rate:0.0160 loss:28582.4238 exploreP:0.0100\n",
      "Episode:783 meanR:9.4600 R:11.0 rate:0.0220 loss:28024.9570 exploreP:0.0100\n",
      "Episode:784 meanR:9.4700 R:10.0 rate:0.0200 loss:97490.4688 exploreP:0.0100\n",
      "Episode:785 meanR:9.4700 R:10.0 rate:0.0200 loss:13881.2607 exploreP:0.0100\n",
      "Episode:786 meanR:9.4800 R:10.0 rate:0.0200 loss:55456.5625 exploreP:0.0100\n",
      "Episode:787 meanR:9.4800 R:10.0 rate:0.0200 loss:32759.6992 exploreP:0.0100\n",
      "Episode:788 meanR:9.4800 R:10.0 rate:0.0200 loss:47392.5820 exploreP:0.0100\n",
      "Episode:789 meanR:9.4900 R:10.0 rate:0.0200 loss:59419.0820 exploreP:0.0100\n",
      "Episode:790 meanR:9.4800 R:9.0 rate:0.0180 loss:96316.7656 exploreP:0.0100\n",
      "Episode:791 meanR:9.4700 R:9.0 rate:0.0180 loss:93430.5312 exploreP:0.0100\n",
      "Episode:792 meanR:9.4600 R:10.0 rate:0.0200 loss:87748.4766 exploreP:0.0100\n",
      "Episode:793 meanR:9.4700 R:10.0 rate:0.0200 loss:36707.5078 exploreP:0.0100\n",
      "Episode:794 meanR:9.4800 R:10.0 rate:0.0200 loss:124839.1484 exploreP:0.0100\n",
      "Episode:795 meanR:9.4700 R:9.0 rate:0.0180 loss:66304.0312 exploreP:0.0100\n",
      "Episode:796 meanR:9.4600 R:9.0 rate:0.0180 loss:31575.3965 exploreP:0.0100\n",
      "Episode:797 meanR:9.4500 R:10.0 rate:0.0200 loss:31246.9746 exploreP:0.0100\n",
      "Episode:798 meanR:9.4600 R:10.0 rate:0.0200 loss:56336.8555 exploreP:0.0100\n",
      "Episode:799 meanR:9.4400 R:8.0 rate:0.0160 loss:16108.0879 exploreP:0.0100\n",
      "Episode:800 meanR:9.4100 R:8.0 rate:0.0160 loss:26327.5508 exploreP:0.0100\n",
      "Episode:801 meanR:9.4100 R:9.0 rate:0.0180 loss:140438.2188 exploreP:0.0100\n",
      "Episode:802 meanR:9.4100 R:10.0 rate:0.0200 loss:72537.4219 exploreP:0.0100\n",
      "Episode:803 meanR:9.4100 R:10.0 rate:0.0200 loss:108435.0234 exploreP:0.0100\n",
      "Episode:804 meanR:9.4100 R:10.0 rate:0.0200 loss:97153.1016 exploreP:0.0100\n",
      "Episode:805 meanR:9.4300 R:11.0 rate:0.0220 loss:18161.6719 exploreP:0.0100\n",
      "Episode:806 meanR:9.4400 R:10.0 rate:0.0200 loss:97303.3438 exploreP:0.0100\n",
      "Episode:807 meanR:9.4300 R:9.0 rate:0.0180 loss:93269.6562 exploreP:0.0100\n",
      "Episode:808 meanR:9.4200 R:9.0 rate:0.0180 loss:7062.8413 exploreP:0.0100\n",
      "Episode:809 meanR:9.4100 R:11.0 rate:0.0220 loss:111039.8672 exploreP:0.0100\n",
      "Episode:810 meanR:9.4000 R:9.0 rate:0.0180 loss:75002.5703 exploreP:0.0100\n",
      "Episode:811 meanR:9.3900 R:9.0 rate:0.0180 loss:111884.1562 exploreP:0.0100\n",
      "Episode:812 meanR:9.3900 R:9.0 rate:0.0180 loss:42505.7734 exploreP:0.0100\n",
      "Episode:813 meanR:9.4200 R:11.0 rate:0.0220 loss:23355.6797 exploreP:0.0100\n",
      "Episode:814 meanR:9.4400 R:10.0 rate:0.0200 loss:126633.8281 exploreP:0.0100\n",
      "Episode:815 meanR:9.4300 R:10.0 rate:0.0200 loss:91029.9219 exploreP:0.0100\n",
      "Episode:816 meanR:9.4200 R:9.0 rate:0.0180 loss:76763.3281 exploreP:0.0100\n",
      "Episode:817 meanR:9.4300 R:9.0 rate:0.0180 loss:81453.5234 exploreP:0.0100\n",
      "Episode:818 meanR:9.4100 R:8.0 rate:0.0160 loss:103686.4766 exploreP:0.0100\n",
      "Episode:819 meanR:9.4200 R:10.0 rate:0.0200 loss:19896.1172 exploreP:0.0100\n",
      "Episode:820 meanR:9.4200 R:10.0 rate:0.0200 loss:50999.6328 exploreP:0.0100\n",
      "Episode:821 meanR:9.4200 R:10.0 rate:0.0200 loss:83170.4453 exploreP:0.0100\n",
      "Episode:822 meanR:9.4200 R:10.0 rate:0.0200 loss:116200.8984 exploreP:0.0100\n",
      "Episode:823 meanR:9.4000 R:8.0 rate:0.0160 loss:64143.9492 exploreP:0.0100\n",
      "Episode:824 meanR:9.4000 R:9.0 rate:0.0180 loss:65588.2188 exploreP:0.0100\n",
      "Episode:825 meanR:9.4100 R:9.0 rate:0.0180 loss:145074.8125 exploreP:0.0100\n",
      "Episode:826 meanR:9.4100 R:10.0 rate:0.0200 loss:159344.9688 exploreP:0.0100\n",
      "Episode:827 meanR:9.4100 R:10.0 rate:0.0200 loss:124188.7344 exploreP:0.0100\n",
      "Episode:828 meanR:9.4100 R:9.0 rate:0.0180 loss:102495.4609 exploreP:0.0100\n",
      "Episode:829 meanR:9.4200 R:10.0 rate:0.0200 loss:89476.5000 exploreP:0.0100\n",
      "Episode:830 meanR:9.4200 R:9.0 rate:0.0180 loss:89191.7734 exploreP:0.0100\n",
      "Episode:831 meanR:9.4200 R:9.0 rate:0.0180 loss:76921.7891 exploreP:0.0100\n",
      "Episode:832 meanR:9.4200 R:10.0 rate:0.0200 loss:53325.9453 exploreP:0.0100\n",
      "Episode:833 meanR:9.4100 R:10.0 rate:0.0200 loss:82188.4844 exploreP:0.0100\n",
      "Episode:834 meanR:9.4200 R:10.0 rate:0.0200 loss:42390.7148 exploreP:0.0100\n",
      "Episode:835 meanR:9.4200 R:10.0 rate:0.0200 loss:58045.4766 exploreP:0.0100\n",
      "Episode:836 meanR:9.4000 R:9.0 rate:0.0180 loss:113764.7109 exploreP:0.0100\n",
      "Episode:837 meanR:9.3900 R:9.0 rate:0.0180 loss:196823.7344 exploreP:0.0100\n",
      "Episode:838 meanR:9.3900 R:9.0 rate:0.0180 loss:134441.2188 exploreP:0.0100\n",
      "Episode:839 meanR:9.3900 R:8.0 rate:0.0160 loss:246994.6562 exploreP:0.0100\n",
      "Episode:840 meanR:9.3800 R:9.0 rate:0.0180 loss:27291.7539 exploreP:0.0100\n",
      "Episode:841 meanR:9.3800 R:9.0 rate:0.0180 loss:43374.5859 exploreP:0.0100\n",
      "Episode:842 meanR:9.4000 R:10.0 rate:0.0200 loss:99596.4844 exploreP:0.0100\n",
      "Episode:843 meanR:9.3900 R:9.0 rate:0.0180 loss:12476.5469 exploreP:0.0100\n",
      "Episode:844 meanR:9.4200 R:11.0 rate:0.0220 loss:141813.9219 exploreP:0.0100\n",
      "Episode:845 meanR:9.4100 R:9.0 rate:0.0180 loss:25060.4609 exploreP:0.0100\n",
      "Episode:846 meanR:9.4300 R:10.0 rate:0.0200 loss:13166.1592 exploreP:0.0100\n",
      "Episode:847 meanR:9.4300 R:9.0 rate:0.0180 loss:64638.7344 exploreP:0.0100\n",
      "Episode:848 meanR:9.4300 R:10.0 rate:0.0200 loss:181170.5312 exploreP:0.0100\n",
      "Episode:849 meanR:9.4500 R:10.0 rate:0.0200 loss:68958.0859 exploreP:0.0100\n",
      "Episode:850 meanR:9.4500 R:10.0 rate:0.0200 loss:67178.3906 exploreP:0.0100\n",
      "Episode:851 meanR:9.4700 R:11.0 rate:0.0220 loss:66831.1094 exploreP:0.0100\n",
      "Episode:852 meanR:9.4700 R:10.0 rate:0.0200 loss:77706.5234 exploreP:0.0100\n",
      "Episode:853 meanR:9.4800 R:10.0 rate:0.0200 loss:99139.9453 exploreP:0.0100\n",
      "Episode:854 meanR:9.4800 R:10.0 rate:0.0200 loss:182423.0000 exploreP:0.0100\n",
      "Episode:855 meanR:9.5000 R:10.0 rate:0.0200 loss:193752.2969 exploreP:0.0100\n",
      "Episode:856 meanR:9.5100 R:9.0 rate:0.0180 loss:101589.4297 exploreP:0.0100\n",
      "Episode:857 meanR:9.5000 R:9.0 rate:0.0180 loss:232769.6875 exploreP:0.0100\n",
      "Episode:858 meanR:9.5100 R:9.0 rate:0.0180 loss:275066.2812 exploreP:0.0100\n",
      "Episode:859 meanR:9.5000 R:9.0 rate:0.0180 loss:313499.1250 exploreP:0.0100\n",
      "Episode:860 meanR:9.4900 R:9.0 rate:0.0180 loss:17449.2383 exploreP:0.0100\n",
      "Episode:861 meanR:9.4900 R:9.0 rate:0.0180 loss:33842.5234 exploreP:0.0100\n",
      "Episode:862 meanR:9.4800 R:9.0 rate:0.0180 loss:105030.7969 exploreP:0.0100\n",
      "Episode:863 meanR:9.5000 R:10.0 rate:0.0200 loss:152681.7344 exploreP:0.0100\n",
      "Episode:864 meanR:9.5100 R:10.0 rate:0.0200 loss:238620.4219 exploreP:0.0100\n",
      "Episode:865 meanR:9.5100 R:9.0 rate:0.0180 loss:170726.5625 exploreP:0.0100\n",
      "Episode:866 meanR:9.5000 R:8.0 rate:0.0160 loss:303713.9375 exploreP:0.0100\n",
      "Episode:867 meanR:9.4900 R:9.0 rate:0.0180 loss:34932.1094 exploreP:0.0100\n",
      "Episode:868 meanR:9.4900 R:9.0 rate:0.0180 loss:234169.2188 exploreP:0.0100\n",
      "Episode:869 meanR:9.5000 R:9.0 rate:0.0180 loss:137621.0781 exploreP:0.0100\n",
      "Episode:870 meanR:9.5000 R:10.0 rate:0.0200 loss:197514.2500 exploreP:0.0100\n",
      "Episode:871 meanR:9.5100 R:10.0 rate:0.0200 loss:218173.8750 exploreP:0.0100\n",
      "Episode:872 meanR:9.4900 R:9.0 rate:0.0180 loss:105110.8359 exploreP:0.0100\n",
      "Episode:873 meanR:9.4700 R:8.0 rate:0.0160 loss:47213.3828 exploreP:0.0100\n",
      "Episode:874 meanR:9.4900 R:10.0 rate:0.0200 loss:22187.2598 exploreP:0.0100\n",
      "Episode:875 meanR:9.4700 R:9.0 rate:0.0180 loss:21978.2188 exploreP:0.0100\n",
      "Episode:876 meanR:9.4900 R:12.0 rate:0.0240 loss:179970.5625 exploreP:0.0100\n",
      "Episode:877 meanR:9.5000 R:10.0 rate:0.0200 loss:290661.6875 exploreP:0.0100\n",
      "Episode:878 meanR:9.4900 R:8.0 rate:0.0160 loss:250655.5938 exploreP:0.0100\n",
      "Episode:879 meanR:9.4900 R:9.0 rate:0.0180 loss:149733.3438 exploreP:0.0100\n",
      "Episode:880 meanR:9.5100 R:11.0 rate:0.0220 loss:125834.4297 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:881 meanR:9.5200 R:10.0 rate:0.0200 loss:221768.6719 exploreP:0.0100\n",
      "Episode:882 meanR:9.5400 R:10.0 rate:0.0200 loss:280240.6875 exploreP:0.0100\n",
      "Episode:883 meanR:9.5300 R:10.0 rate:0.0200 loss:249761.8750 exploreP:0.0100\n",
      "Episode:884 meanR:9.5100 R:8.0 rate:0.0160 loss:310031.6250 exploreP:0.0100\n",
      "Episode:885 meanR:9.5000 R:9.0 rate:0.0180 loss:45587.8828 exploreP:0.0100\n",
      "Episode:886 meanR:9.5200 R:12.0 rate:0.0240 loss:336548.0312 exploreP:0.0100\n",
      "Episode:887 meanR:9.5000 R:8.0 rate:0.0160 loss:24887.3770 exploreP:0.0100\n",
      "Episode:888 meanR:9.5000 R:10.0 rate:0.0200 loss:49902.1133 exploreP:0.0100\n",
      "Episode:889 meanR:9.5000 R:10.0 rate:0.0200 loss:171722.0625 exploreP:0.0100\n",
      "Episode:890 meanR:9.5100 R:10.0 rate:0.0200 loss:145271.7969 exploreP:0.0100\n",
      "Episode:891 meanR:9.5300 R:11.0 rate:0.0220 loss:450550.1875 exploreP:0.0100\n",
      "Episode:892 meanR:9.5100 R:8.0 rate:0.0160 loss:433695.0625 exploreP:0.0100\n",
      "Episode:893 meanR:9.5100 R:10.0 rate:0.0200 loss:276693.6875 exploreP:0.0100\n",
      "Episode:894 meanR:9.5200 R:11.0 rate:0.0220 loss:116785.7188 exploreP:0.0100\n",
      "Episode:895 meanR:9.5200 R:9.0 rate:0.0180 loss:161231.5469 exploreP:0.0100\n",
      "Episode:896 meanR:9.5300 R:10.0 rate:0.0200 loss:244739.2031 exploreP:0.0100\n",
      "Episode:897 meanR:9.5300 R:10.0 rate:0.0200 loss:300513.5312 exploreP:0.0100\n",
      "Episode:898 meanR:9.5100 R:8.0 rate:0.0160 loss:162559.9844 exploreP:0.0100\n",
      "Episode:899 meanR:9.5200 R:9.0 rate:0.0180 loss:256664.9688 exploreP:0.0100\n",
      "Episode:900 meanR:9.5400 R:10.0 rate:0.0200 loss:130810.1484 exploreP:0.0100\n",
      "Episode:901 meanR:9.5500 R:10.0 rate:0.0200 loss:54788.4609 exploreP:0.0100\n",
      "Episode:902 meanR:9.5400 R:9.0 rate:0.0180 loss:154002.1406 exploreP:0.0100\n",
      "Episode:903 meanR:9.5200 R:8.0 rate:0.0160 loss:341600.3125 exploreP:0.0100\n",
      "Episode:904 meanR:9.5100 R:9.0 rate:0.0180 loss:189707.8281 exploreP:0.0100\n",
      "Episode:905 meanR:9.4900 R:9.0 rate:0.0180 loss:49016.0430 exploreP:0.0100\n",
      "Episode:906 meanR:9.4800 R:9.0 rate:0.0180 loss:155896.8594 exploreP:0.0100\n",
      "Episode:907 meanR:9.4800 R:9.0 rate:0.0180 loss:258967.8594 exploreP:0.0100\n",
      "Episode:908 meanR:9.4800 R:9.0 rate:0.0180 loss:32312.1016 exploreP:0.0100\n",
      "Episode:909 meanR:9.4600 R:9.0 rate:0.0180 loss:537836.8125 exploreP:0.0100\n",
      "Episode:910 meanR:9.4700 R:10.0 rate:0.0200 loss:198574.0938 exploreP:0.0100\n",
      "Episode:911 meanR:9.4800 R:10.0 rate:0.0200 loss:130520.7266 exploreP:0.0100\n",
      "Episode:912 meanR:9.4800 R:9.0 rate:0.0180 loss:34007.7383 exploreP:0.0100\n",
      "Episode:913 meanR:9.4700 R:10.0 rate:0.0200 loss:195378.4844 exploreP:0.0100\n",
      "Episode:914 meanR:9.4800 R:11.0 rate:0.0220 loss:278442.7812 exploreP:0.0100\n",
      "Episode:915 meanR:9.4800 R:10.0 rate:0.0200 loss:168914.4688 exploreP:0.0100\n",
      "Episode:916 meanR:9.4800 R:9.0 rate:0.0180 loss:36675.0000 exploreP:0.0100\n",
      "Episode:917 meanR:9.4700 R:8.0 rate:0.0160 loss:394775.6250 exploreP:0.0100\n",
      "Episode:918 meanR:9.5000 R:11.0 rate:0.0220 loss:222149.2656 exploreP:0.0100\n",
      "Episode:919 meanR:9.5000 R:10.0 rate:0.0200 loss:373671.8438 exploreP:0.0100\n",
      "Episode:920 meanR:9.5000 R:10.0 rate:0.0200 loss:231738.8750 exploreP:0.0100\n",
      "Episode:921 meanR:9.4900 R:9.0 rate:0.0180 loss:246305.5312 exploreP:0.0100\n",
      "Episode:922 meanR:9.4800 R:9.0 rate:0.0180 loss:542984.1875 exploreP:0.0100\n",
      "Episode:923 meanR:9.4900 R:9.0 rate:0.0180 loss:373907.6250 exploreP:0.0100\n",
      "Episode:924 meanR:9.4800 R:8.0 rate:0.0160 loss:546604.5625 exploreP:0.0100\n",
      "Episode:925 meanR:9.4800 R:9.0 rate:0.0180 loss:755554.8125 exploreP:0.0100\n",
      "Episode:926 meanR:9.4600 R:8.0 rate:0.0160 loss:230359.9062 exploreP:0.0100\n",
      "Episode:927 meanR:9.4600 R:10.0 rate:0.0200 loss:176449.4219 exploreP:0.0100\n",
      "Episode:928 meanR:9.4600 R:9.0 rate:0.0180 loss:227272.3125 exploreP:0.0100\n",
      "Episode:929 meanR:9.4600 R:10.0 rate:0.0200 loss:44074.6562 exploreP:0.0100\n",
      "Episode:930 meanR:9.4600 R:9.0 rate:0.0180 loss:489269.0625 exploreP:0.0100\n",
      "Episode:931 meanR:9.4700 R:10.0 rate:0.0200 loss:423245.6875 exploreP:0.0100\n",
      "Episode:932 meanR:9.4600 R:9.0 rate:0.0180 loss:520068.8438 exploreP:0.0100\n",
      "Episode:933 meanR:9.4600 R:10.0 rate:0.0200 loss:370614.8125 exploreP:0.0100\n",
      "Episode:934 meanR:9.4500 R:9.0 rate:0.0180 loss:420295.0625 exploreP:0.0100\n",
      "Episode:935 meanR:9.4400 R:9.0 rate:0.0180 loss:324113.7500 exploreP:0.0100\n",
      "Episode:936 meanR:9.4300 R:8.0 rate:0.0160 loss:510127.6875 exploreP:0.0100\n",
      "Episode:937 meanR:9.4300 R:9.0 rate:0.0180 loss:305360.6562 exploreP:0.0100\n",
      "Episode:938 meanR:9.4400 R:10.0 rate:0.0200 loss:397752.4688 exploreP:0.0100\n",
      "Episode:939 meanR:9.4500 R:9.0 rate:0.0180 loss:245232.4219 exploreP:0.0100\n",
      "Episode:940 meanR:9.4600 R:10.0 rate:0.0200 loss:453581.9375 exploreP:0.0100\n",
      "Episode:941 meanR:9.4700 R:10.0 rate:0.0200 loss:260517.8281 exploreP:0.0100\n",
      "Episode:942 meanR:9.4600 R:9.0 rate:0.0180 loss:414647.4062 exploreP:0.0100\n",
      "Episode:943 meanR:9.4600 R:9.0 rate:0.0180 loss:683097.8125 exploreP:0.0100\n",
      "Episode:944 meanR:9.4500 R:10.0 rate:0.0200 loss:183678.9688 exploreP:0.0100\n",
      "Episode:945 meanR:9.4500 R:9.0 rate:0.0180 loss:307137.8438 exploreP:0.0100\n",
      "Episode:946 meanR:9.4300 R:8.0 rate:0.0160 loss:347466.7500 exploreP:0.0100\n",
      "Episode:947 meanR:9.4300 R:9.0 rate:0.0180 loss:56279.8867 exploreP:0.0100\n",
      "Episode:948 meanR:9.4300 R:10.0 rate:0.0200 loss:257963.5938 exploreP:0.0100\n",
      "Episode:949 meanR:9.4300 R:10.0 rate:0.0200 loss:660180.5625 exploreP:0.0100\n",
      "Episode:950 meanR:9.4200 R:9.0 rate:0.0180 loss:611014.5625 exploreP:0.0100\n",
      "Episode:951 meanR:9.4100 R:10.0 rate:0.0200 loss:280835.5938 exploreP:0.0100\n",
      "Episode:952 meanR:9.4100 R:10.0 rate:0.0200 loss:789161.8750 exploreP:0.0100\n",
      "Episode:953 meanR:9.4000 R:9.0 rate:0.0180 loss:326684.8125 exploreP:0.0100\n",
      "Episode:954 meanR:9.3900 R:9.0 rate:0.0180 loss:296425.8438 exploreP:0.0100\n",
      "Episode:955 meanR:9.3900 R:10.0 rate:0.0200 loss:378319.9062 exploreP:0.0100\n",
      "Episode:956 meanR:9.3900 R:9.0 rate:0.0180 loss:619424.7500 exploreP:0.0100\n",
      "Episode:957 meanR:9.3900 R:9.0 rate:0.0180 loss:640259.1250 exploreP:0.0100\n",
      "Episode:958 meanR:9.4300 R:13.0 rate:0.0260 loss:390859.7188 exploreP:0.0100\n",
      "Episode:959 meanR:9.4300 R:9.0 rate:0.0180 loss:340199.0625 exploreP:0.0100\n",
      "Episode:960 meanR:9.4300 R:9.0 rate:0.0180 loss:884213.8750 exploreP:0.0100\n",
      "Episode:961 meanR:9.4300 R:9.0 rate:0.0180 loss:328037.1250 exploreP:0.0100\n",
      "Episode:962 meanR:9.4400 R:10.0 rate:0.0200 loss:340136.1875 exploreP:0.0100\n",
      "Episode:963 meanR:9.4400 R:10.0 rate:0.0200 loss:361447.9688 exploreP:0.0100\n",
      "Episode:964 meanR:9.4500 R:11.0 rate:0.0220 loss:1093186.2500 exploreP:0.0100\n",
      "Episode:965 meanR:9.4600 R:10.0 rate:0.0200 loss:864307.8125 exploreP:0.0100\n",
      "Episode:966 meanR:9.4800 R:10.0 rate:0.0200 loss:356501.0938 exploreP:0.0100\n",
      "Episode:967 meanR:9.4900 R:10.0 rate:0.0200 loss:591452.8750 exploreP:0.0100\n",
      "Episode:968 meanR:9.4900 R:9.0 rate:0.0180 loss:132928.4688 exploreP:0.0100\n",
      "Episode:969 meanR:9.4900 R:9.0 rate:0.0180 loss:69695.7812 exploreP:0.0100\n",
      "Episode:970 meanR:9.4900 R:10.0 rate:0.0200 loss:363181.4375 exploreP:0.0100\n",
      "Episode:971 meanR:9.4800 R:9.0 rate:0.0180 loss:132133.5938 exploreP:0.0100\n",
      "Episode:972 meanR:9.4800 R:9.0 rate:0.0180 loss:616718.2500 exploreP:0.0100\n",
      "Episode:973 meanR:9.5000 R:10.0 rate:0.0200 loss:668408.8125 exploreP:0.0100\n",
      "Episode:974 meanR:9.4900 R:9.0 rate:0.0180 loss:476174.3438 exploreP:0.0100\n",
      "Episode:975 meanR:9.5000 R:10.0 rate:0.0200 loss:356089.8125 exploreP:0.0100\n",
      "Episode:976 meanR:9.4700 R:9.0 rate:0.0180 loss:1160958.0000 exploreP:0.0100\n",
      "Episode:977 meanR:9.4700 R:10.0 rate:0.0200 loss:422196.3125 exploreP:0.0100\n",
      "Episode:978 meanR:9.4900 R:10.0 rate:0.0200 loss:365373.4062 exploreP:0.0100\n",
      "Episode:979 meanR:9.4800 R:8.0 rate:0.0160 loss:76990.6484 exploreP:0.0100\n",
      "Episode:980 meanR:9.4600 R:9.0 rate:0.0180 loss:425167.0000 exploreP:0.0100\n",
      "Episode:981 meanR:9.4500 R:9.0 rate:0.0180 loss:461709.1562 exploreP:0.0100\n",
      "Episode:982 meanR:9.4300 R:8.0 rate:0.0160 loss:453948.5625 exploreP:0.0100\n",
      "Episode:983 meanR:9.4300 R:10.0 rate:0.0200 loss:782655.5625 exploreP:0.0100\n",
      "Episode:984 meanR:9.4500 R:10.0 rate:0.0200 loss:81563.4922 exploreP:0.0100\n",
      "Episode:985 meanR:9.4600 R:10.0 rate:0.0200 loss:538279.8125 exploreP:0.0100\n",
      "Episode:986 meanR:9.4300 R:9.0 rate:0.0180 loss:1154988.6250 exploreP:0.0100\n",
      "Episode:987 meanR:9.4400 R:9.0 rate:0.0180 loss:487148.7188 exploreP:0.0100\n",
      "Episode:988 meanR:9.4400 R:10.0 rate:0.0200 loss:89615.8906 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:989 meanR:9.4300 R:9.0 rate:0.0180 loss:1193915.1250 exploreP:0.0100\n",
      "Episode:990 meanR:9.4300 R:10.0 rate:0.0200 loss:139064.5625 exploreP:0.0100\n",
      "Episode:991 meanR:9.4100 R:9.0 rate:0.0180 loss:883438.6875 exploreP:0.0100\n",
      "Episode:992 meanR:9.4200 R:9.0 rate:0.0180 loss:1350410.6250 exploreP:0.0100\n",
      "Episode:993 meanR:9.4200 R:10.0 rate:0.0200 loss:748018.0625 exploreP:0.0100\n",
      "Episode:994 meanR:9.4000 R:9.0 rate:0.0180 loss:1574113.1250 exploreP:0.0100\n",
      "Episode:995 meanR:9.4100 R:10.0 rate:0.0200 loss:714938.3750 exploreP:0.0100\n",
      "Episode:996 meanR:9.4100 R:10.0 rate:0.0200 loss:804685.3750 exploreP:0.0100\n",
      "Episode:997 meanR:9.4000 R:9.0 rate:0.0180 loss:468986.3438 exploreP:0.0100\n",
      "Episode:998 meanR:9.4100 R:9.0 rate:0.0180 loss:864189.2500 exploreP:0.0100\n",
      "Episode:999 meanR:9.4000 R:8.0 rate:0.0160 loss:1828215.5000 exploreP:0.0100\n",
      "Episode:1000 meanR:9.4000 R:10.0 rate:0.0200 loss:770214.6250 exploreP:0.0100\n",
      "Episode:1001 meanR:9.4000 R:10.0 rate:0.0200 loss:158502.1406 exploreP:0.0100\n",
      "Episode:1002 meanR:9.4000 R:9.0 rate:0.0180 loss:491269.7812 exploreP:0.0100\n",
      "Episode:1003 meanR:9.4200 R:10.0 rate:0.0200 loss:478505.4062 exploreP:0.0100\n",
      "Episode:1004 meanR:9.4200 R:9.0 rate:0.0180 loss:107867.8594 exploreP:0.0100\n",
      "Episode:1005 meanR:9.4200 R:9.0 rate:0.0180 loss:579947.7500 exploreP:0.0100\n",
      "Episode:1006 meanR:9.4400 R:11.0 rate:0.0220 loss:862794.3750 exploreP:0.0100\n",
      "Episode:1007 meanR:9.4500 R:10.0 rate:0.0200 loss:574902.1875 exploreP:0.0100\n",
      "Episode:1008 meanR:9.4600 R:10.0 rate:0.0200 loss:1804799.0000 exploreP:0.0100\n",
      "Episode:1009 meanR:9.4600 R:9.0 rate:0.0180 loss:1122220.5000 exploreP:0.0100\n",
      "Episode:1010 meanR:9.4600 R:10.0 rate:0.0200 loss:584820.2500 exploreP:0.0100\n",
      "Episode:1011 meanR:9.4600 R:10.0 rate:0.0200 loss:923646.8750 exploreP:0.0100\n",
      "Episode:1012 meanR:9.4700 R:10.0 rate:0.0200 loss:940039.0000 exploreP:0.0100\n",
      "Episode:1013 meanR:9.4700 R:10.0 rate:0.0200 loss:212612.5469 exploreP:0.0100\n",
      "Episode:1014 meanR:9.4600 R:10.0 rate:0.0200 loss:1103542.3750 exploreP:0.0100\n",
      "Episode:1015 meanR:9.4600 R:10.0 rate:0.0200 loss:552578.1250 exploreP:0.0100\n",
      "Episode:1016 meanR:9.4700 R:10.0 rate:0.0200 loss:1167502.6250 exploreP:0.0100\n",
      "Episode:1017 meanR:9.4800 R:9.0 rate:0.0180 loss:2093915.1250 exploreP:0.0100\n",
      "Episode:1018 meanR:9.4600 R:9.0 rate:0.0180 loss:1418764.2500 exploreP:0.0100\n",
      "Episode:1019 meanR:9.4500 R:9.0 rate:0.0180 loss:773299.7500 exploreP:0.0100\n",
      "Episode:1020 meanR:9.4500 R:10.0 rate:0.0200 loss:183907.0312 exploreP:0.0100\n",
      "Episode:1021 meanR:9.4700 R:11.0 rate:0.0220 loss:681303.3125 exploreP:0.0100\n",
      "Episode:1022 meanR:9.4700 R:9.0 rate:0.0180 loss:591420.3125 exploreP:0.0100\n",
      "Episode:1023 meanR:9.4800 R:10.0 rate:0.0200 loss:1135801.7500 exploreP:0.0100\n",
      "Episode:1024 meanR:9.4900 R:9.0 rate:0.0180 loss:670214.2500 exploreP:0.0100\n",
      "Episode:1025 meanR:9.5000 R:10.0 rate:0.0200 loss:284459.1875 exploreP:0.0100\n",
      "Episode:1026 meanR:9.5100 R:9.0 rate:0.0180 loss:1067847.2500 exploreP:0.0100\n",
      "Episode:1027 meanR:9.5000 R:9.0 rate:0.0180 loss:1413891.5000 exploreP:0.0100\n",
      "Episode:1028 meanR:9.5000 R:9.0 rate:0.0180 loss:1080811.8750 exploreP:0.0100\n",
      "Episode:1029 meanR:9.4900 R:9.0 rate:0.0180 loss:198122.7188 exploreP:0.0100\n",
      "Episode:1030 meanR:9.4900 R:9.0 rate:0.0180 loss:128409.0156 exploreP:0.0100\n",
      "Episode:1031 meanR:9.4800 R:9.0 rate:0.0180 loss:1427940.6250 exploreP:0.0100\n",
      "Episode:1032 meanR:9.4900 R:10.0 rate:0.0200 loss:706589.0000 exploreP:0.0100\n",
      "Episode:1033 meanR:9.4900 R:10.0 rate:0.0200 loss:692860.9375 exploreP:0.0100\n",
      "Episode:1034 meanR:9.4900 R:9.0 rate:0.0180 loss:1627891.6250 exploreP:0.0100\n",
      "Episode:1035 meanR:9.4900 R:9.0 rate:0.0180 loss:2339567.0000 exploreP:0.0100\n",
      "Episode:1036 meanR:9.4900 R:8.0 rate:0.0160 loss:224849.8594 exploreP:0.0100\n",
      "Episode:1037 meanR:9.5000 R:10.0 rate:0.0200 loss:1347941.3750 exploreP:0.0100\n",
      "Episode:1038 meanR:9.5000 R:10.0 rate:0.0200 loss:1868434.7500 exploreP:0.0100\n",
      "Episode:1039 meanR:9.5000 R:9.0 rate:0.0180 loss:1534003.1250 exploreP:0.0100\n",
      "Episode:1040 meanR:9.4900 R:9.0 rate:0.0180 loss:2057218.8750 exploreP:0.0100\n",
      "Episode:1041 meanR:9.4800 R:9.0 rate:0.0180 loss:1597598.1250 exploreP:0.0100\n",
      "Episode:1042 meanR:9.4900 R:10.0 rate:0.0200 loss:1126306.2500 exploreP:0.0100\n",
      "Episode:1043 meanR:9.5000 R:10.0 rate:0.0200 loss:781339.8125 exploreP:0.0100\n",
      "Episode:1044 meanR:9.4900 R:9.0 rate:0.0180 loss:1287007.0000 exploreP:0.0100\n",
      "Episode:1045 meanR:9.5000 R:10.0 rate:0.0200 loss:1484442.0000 exploreP:0.0100\n",
      "Episode:1046 meanR:9.5100 R:9.0 rate:0.0180 loss:1526170.3750 exploreP:0.0100\n",
      "Episode:1047 meanR:9.5200 R:10.0 rate:0.0200 loss:708933.6875 exploreP:0.0100\n",
      "Episode:1048 meanR:9.5100 R:9.0 rate:0.0180 loss:2350922.7500 exploreP:0.0100\n",
      "Episode:1049 meanR:9.5000 R:9.0 rate:0.0180 loss:222248.4688 exploreP:0.0100\n",
      "Episode:1050 meanR:9.5100 R:10.0 rate:0.0200 loss:2634078.5000 exploreP:0.0100\n",
      "Episode:1051 meanR:9.5100 R:10.0 rate:0.0200 loss:1471712.5000 exploreP:0.0100\n",
      "Episode:1052 meanR:9.5100 R:10.0 rate:0.0200 loss:2692201.2500 exploreP:0.0100\n",
      "Episode:1053 meanR:9.5100 R:9.0 rate:0.0180 loss:817607.0625 exploreP:0.0100\n",
      "Episode:1054 meanR:9.5200 R:10.0 rate:0.0200 loss:2196377.5000 exploreP:0.0100\n",
      "Episode:1055 meanR:9.5200 R:10.0 rate:0.0200 loss:2528425.2500 exploreP:0.0100\n",
      "Episode:1056 meanR:9.5200 R:9.0 rate:0.0180 loss:1641774.5000 exploreP:0.0100\n",
      "Episode:1057 meanR:9.5100 R:8.0 rate:0.0160 loss:155389.1250 exploreP:0.0100\n",
      "Episode:1058 meanR:9.4800 R:10.0 rate:0.0200 loss:1598902.3750 exploreP:0.0100\n",
      "Episode:1059 meanR:9.4900 R:10.0 rate:0.0200 loss:1598918.2500 exploreP:0.0100\n",
      "Episode:1060 meanR:9.5000 R:10.0 rate:0.0200 loss:2268651.5000 exploreP:0.0100\n",
      "Episode:1061 meanR:9.5000 R:9.0 rate:0.0180 loss:271877.3438 exploreP:0.0100\n",
      "Episode:1062 meanR:9.4900 R:9.0 rate:0.0180 loss:2608401.0000 exploreP:0.0100\n",
      "Episode:1063 meanR:9.4900 R:10.0 rate:0.0200 loss:952997.3750 exploreP:0.0100\n",
      "Episode:1064 meanR:9.4800 R:10.0 rate:0.0200 loss:1332692.6250 exploreP:0.0100\n",
      "Episode:1065 meanR:9.4600 R:8.0 rate:0.0160 loss:2110942.2500 exploreP:0.0100\n",
      "Episode:1066 meanR:9.4600 R:10.0 rate:0.0200 loss:2610387.5000 exploreP:0.0100\n",
      "Episode:1067 meanR:9.4500 R:9.0 rate:0.0180 loss:2540594.5000 exploreP:0.0100\n",
      "Episode:1068 meanR:9.4500 R:9.0 rate:0.0180 loss:164114.3281 exploreP:0.0100\n",
      "Episode:1069 meanR:9.4600 R:10.0 rate:0.0200 loss:2408453.5000 exploreP:0.0100\n",
      "Episode:1070 meanR:9.4600 R:10.0 rate:0.0200 loss:1022049.3125 exploreP:0.0100\n",
      "Episode:1071 meanR:9.4600 R:9.0 rate:0.0180 loss:1690279.1250 exploreP:0.0100\n",
      "Episode:1072 meanR:9.4500 R:8.0 rate:0.0160 loss:2079321.2500 exploreP:0.0100\n",
      "Episode:1073 meanR:9.4500 R:10.0 rate:0.0200 loss:275712.7812 exploreP:0.0100\n",
      "Episode:1074 meanR:9.4700 R:11.0 rate:0.0220 loss:998923.0000 exploreP:0.0100\n",
      "Episode:1075 meanR:9.4700 R:10.0 rate:0.0200 loss:1057017.2500 exploreP:0.0100\n",
      "Episode:1076 meanR:9.4800 R:10.0 rate:0.0200 loss:1517729.3750 exploreP:0.0100\n",
      "Episode:1077 meanR:9.4700 R:9.0 rate:0.0180 loss:1995375.3750 exploreP:0.0100\n",
      "Episode:1078 meanR:9.4700 R:10.0 rate:0.0200 loss:2788672.0000 exploreP:0.0100\n",
      "Episode:1079 meanR:9.4700 R:8.0 rate:0.0160 loss:448142.7500 exploreP:0.0100\n",
      "Episode:1080 meanR:9.4700 R:9.0 rate:0.0180 loss:2854926.0000 exploreP:0.0100\n",
      "Episode:1081 meanR:9.4700 R:9.0 rate:0.0180 loss:1423525.7500 exploreP:0.0100\n",
      "Episode:1082 meanR:9.4800 R:9.0 rate:0.0180 loss:3215420.2500 exploreP:0.0100\n",
      "Episode:1083 meanR:9.4800 R:10.0 rate:0.0200 loss:1095740.3750 exploreP:0.0100\n",
      "Episode:1084 meanR:9.4600 R:8.0 rate:0.0160 loss:1222064.1250 exploreP:0.0100\n",
      "Episode:1085 meanR:9.4600 R:10.0 rate:0.0200 loss:943869.1250 exploreP:0.0100\n",
      "Episode:1086 meanR:9.4700 R:10.0 rate:0.0200 loss:2828212.5000 exploreP:0.0100\n",
      "Episode:1087 meanR:9.4800 R:10.0 rate:0.0200 loss:1119806.1250 exploreP:0.0100\n",
      "Episode:1088 meanR:9.4700 R:9.0 rate:0.0180 loss:1997163.7500 exploreP:0.0100\n",
      "Episode:1089 meanR:9.4800 R:10.0 rate:0.0200 loss:1196932.1250 exploreP:0.0100\n",
      "Episode:1090 meanR:9.4700 R:9.0 rate:0.0180 loss:3308898.5000 exploreP:0.0100\n",
      "Episode:1091 meanR:9.4600 R:8.0 rate:0.0160 loss:223468.6562 exploreP:0.0100\n",
      "Episode:1092 meanR:9.4600 R:9.0 rate:0.0180 loss:2230899.2500 exploreP:0.0100\n",
      "Episode:1093 meanR:9.4700 R:11.0 rate:0.0220 loss:1125063.1250 exploreP:0.0100\n",
      "Episode:1094 meanR:9.4800 R:10.0 rate:0.0200 loss:1113051.2500 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1095 meanR:9.4800 R:10.0 rate:0.0200 loss:2178316.5000 exploreP:0.0100\n",
      "Episode:1096 meanR:9.4700 R:9.0 rate:0.0180 loss:2557980.5000 exploreP:0.0100\n",
      "Episode:1097 meanR:9.4700 R:9.0 rate:0.0180 loss:218890.2188 exploreP:0.0100\n",
      "Episode:1098 meanR:9.4800 R:10.0 rate:0.0200 loss:1191873.8750 exploreP:0.0100\n",
      "Episode:1099 meanR:9.5000 R:10.0 rate:0.0200 loss:2199075.7500 exploreP:0.0100\n",
      "Episode:1100 meanR:9.4800 R:8.0 rate:0.0160 loss:1360139.3750 exploreP:0.0100\n",
      "Episode:1101 meanR:9.4900 R:11.0 rate:0.0220 loss:231706.2969 exploreP:0.0100\n",
      "Episode:1102 meanR:9.4800 R:8.0 rate:0.0160 loss:7528287.0000 exploreP:0.0100\n",
      "Episode:1103 meanR:9.4700 R:9.0 rate:0.0180 loss:2160985.0000 exploreP:0.0100\n",
      "Episode:1104 meanR:9.4700 R:9.0 rate:0.0180 loss:2552109.5000 exploreP:0.0100\n",
      "Episode:1105 meanR:9.4700 R:9.0 rate:0.0180 loss:1596440.2500 exploreP:0.0100\n",
      "Episode:1106 meanR:9.4600 R:10.0 rate:0.0200 loss:1390005.8750 exploreP:0.0100\n",
      "Episode:1107 meanR:9.4600 R:10.0 rate:0.0200 loss:2065690.0000 exploreP:0.0100\n",
      "Episode:1108 meanR:9.4600 R:10.0 rate:0.0200 loss:1765162.7500 exploreP:0.0100\n",
      "Episode:1109 meanR:9.4600 R:9.0 rate:0.0180 loss:1247112.7500 exploreP:0.0100\n",
      "Episode:1110 meanR:9.4600 R:10.0 rate:0.0200 loss:5664204.0000 exploreP:0.0100\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(1111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "        num_step = 0 # each episode\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done), -1])\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Rating the last played episode\n",
    "            if done is True:\n",
    "                rate = total_reward/ goal # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.buffer[-1-idx][5] == -1: # double-check if it is empty and it is not rated!\n",
    "                        memory.buffer[-1-idx][5] = rate # rate each SA pair\n",
    "                        \n",
    "            # Rating and training the memory\n",
    "            allrates = np.array(memory.buffer)[:, 5]\n",
    "            rated_mem = np.array(memory.buffer)[allrates >= (max(allrates)*0.2)]\n",
    "            batch = sample(ListArr=rated_mem, batch_size=batch_size)\n",
    "            #mem = np.array(memory.buffer)\n",
    "            #batch = sample(ListArr=mem, batch_size=batch_size)\n",
    "            #batch = sample(ListArr=memory.buffer, batch_size=batch_size)\n",
    "            #batch = memory.sample(batch_size=batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            #rates = np.array([each[5] for each in batch])\n",
    "            #nextQs_logits = sess.run(model.Qs_logits, feed_dict = {model.states: next_states})\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict = {model.states: next_states})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XPV96P3Pd+acM6PVkixZ3uQFbBazGXCAkB1CwpIEmiZtaNrQlpbmhj5N27Q3kOf2Ie2TpO192pCbV5sUcuGGpHkSaJICl6YEwto0QDBgNhtsGduyZFn7OvvyvX/MEQgjSyNbozOj+b5fr3nNnN85Z+Z7PLK+Or9VVBVjjDHmSKGgAzDGGFOeLEEYY4yZkSUIY4wxM7IEYYwxZkaWIIwxxszIEoQxxpgZlTxBiEhYRJ4Tkfv87Y0i8pSI7BGRO0XE88sj/nanv39DqWMzxhhzdItxB/FZYNe07b8FblbVzcAIcK1ffi0woqqbgJv944wxxgSkpAlCRNYCVwD/098W4CLgh/4hdwBX+a+v9Lfx91/sH2+MMSYATonf/2vAfwUa/O3lwKiqZv3tbmCN/3oNcBBAVbMiMuYfP3i0N29tbdUNGzaUIGxjjFm6nnnmmUFVbZvruJIlCBH5ENCvqs+IyHunimc4VIvYN/19rwOuA1i3bh3bt29fgGiNMaZ6iMiBYo4rZRXTO4CPiMh+4AcUqpa+BjSJyFRiWgsc8l93Ax0A/v5lwPCRb6qqt6rqNlXd1tY2ZwI0xhhzjEqWIFT1RlVdq6obgE8AD6vqJ4FHgI/5h10D3OO/vtffxt//sNpMgsYYE5ggxkF8HvhTEemk0MZwm19+G7DcL/9T4IYAYjPGGOMrdSM1AKr6KPCo//o14LwZjkkCH1+MeIwxxszNRlIbY4yZkSUIY4wxM7IEYYwxZkaWIIw5RuPj40xOTgYdhjElsyiN1MYsNalUit7eXg4Ox4m5y1ju5dh28nqiEQ+AXC7H6OgoLS0t2IwxplJZgjCmCPl8nng8Tn19PapKV1cXP+8c5DtPHCCfLwzXaW3YwTvPOYPrL9rM2PAgo6OjTKSVZY2NNNd5AV+BMfNnCcJULVVlbGyM+vp6HOfN/xUmJyeJRqOvlx84cIB0Ok19Szv7DvXx5KuH+O5zQ2xb18avntFC33iKX+wd5PuPPs/L3UP8yQUt3P1cDw/s2s4ENXz+ym1cfd66IC7TmGNmCcJUpXQ6zb59+zgwFOcnL/USijbykXM3sGVlLYODgzzZOUDPWIa2FW28Z/NyUrEE973Qy8OvPEMmq2QJ8a7TT+Lvf20r6WSc2tpa3rVvHw/vOsx3n9jPZw8cYCTjcsmm5QxOpvjqv+3gki3ttNZHgr50Y4pmCcJUpb6+PsaTGb7+0B5S2TxOaJynXzmAExZCIqSzeZyQkH2phzsfEyJOiPG08o6NLZy1sZ0V7St5/5aVhEJCxC1MVrxx40bek8tR64V5vjfG+849jfdtauKpF3fz+Xte5Ws/282Xrjoj4Cs3pniWIEzVyeVyxONxbnmyn9dStdx53YUw2c/T+4Y4NJYkpQ6XbdtMi47TN5Hi7ud6GEnClz58PuduOHqjczgc5oQTTiASifDRd62gtrYWgJPWtvHBUwf53i+7+O0LN7BpRcOM5xtTbixBmKoTi8V45sAIj++b4AsfPpMz1rWQzTZyyuYTcV339ePy+ZWsicU455TCL33Pm7uh2XVdjlyjpLGxkY+c0c5P9uzjqw/u5hufPHehL8mYkrBxEKaqTExM0NXdww+297BxRRO/ecF6ABzHeVNyAAiFQjQ0NNDQ0FBUcjiauro6mutr+NVT67n/pV72DcaO6xqMWSyWIEzVyOVyHOzu4VuP72PvhHDTR07DCZf+v4CI0NzczPtPaWO9M86tj+8t+WcasxAsQZglYWxsjKGhoaPuz2azdHV18d0nD/DA/jR/esXZXLipddHia2lpoakuwoUntnLvswcYS2QW7bONOVaWIEzFi8ViHD58mBc6D/KPP32Bg8PxN+0fHx/n+Z2v8vUHd/Hg7lF+/6JTufadGxc9zo6ODt61uRXJZfjJi72L/vnGzJc1UpuK193dTWf/JDc/uJtkNs9tTxzky79yJu/ZvJyRsXEefn4fP3j6IEMp+N0PnMN/ee+mQOKMRqNsXrmME5td7tnRYwPnTNmzBGEqWiwWI53Nc8tjewk1tPL581v4wdNdfOXOx/nnlloOjydJZpXW9pXc/vFtbFndGGi8tbW1nL++gdufH2EimaEh6s59kjEBsQRhKlYymaS7u5sHd/WxczLK93/zXNpDk2xsreWBnX08f3CUd56ymgvPOpmLT1mxKA3Sc4lGo5yxsh59boL/7Bzk0tNXBR2SMUdVsgQhIlHgcSDif84PVfUmEfk28B5gzD/0t1V1hxRGH/0P4HIg7pc/W6r4TOVLJBIcGk3wz8+P874tq3nbhhZyuWXUjY7y2ZNPAgqD18pJTU0NJ66opyUCj+22BGHKWynvIFLARao6KSIu8HMR+Xd/35+r6g+POP4yYLP/OB/4pv9szFsMDw9zuK+fWx57DfEa+NJVpwOFhLB8+fKAozu6SCSC64Q5Z00dT+8fDjocY2ZVsntuLZhaTcX1HzrLKVcC3/HPexJoEhH788q8RSKRYGBggMd2D9AzmuCvP3oG7Y3RoMMqiogQjUY5rT1KZ/8kg5OpoEMy5qhKWikrImER2QH0Aw+q6lP+ri+LyAsicrOITE1vuQY4OO30br/syPe8TkS2i8j2gYGBUoZvytTExATxVI5/fbaHjRvWc8mW9qBDmpe6ujo2LY8QJs92u4swZaykCUJVc6q6FVgLnCcipwM3AqcAbwNagM/7h880A9pb7jhU9VZV3aaq29ra2koUuSlnsViMJw/G2J1q4PMfOqPiVmyrra1lfUsdjW6eJ1+zBGHK16J061DVUeBR4FJV7fWrkVLA/wLO8w/rBjqmnbYWOLQY8ZnKkUwmSaVS3LdzkLPXNXHa6mVBhzRvkUgEzw1z7pp6Hn21H9XZal6NCU7JEoSItIlIk/+6Bng/8MpUu4Lfa+kq4CX/lHuBT0nBBcCYqtpwU/MmAwMD7OmP8cpQht+o0IFmU+0Q569vYP9QnM7+yblPMiYApezFtAq4Q0TCFBLRXap6n4g8LCJtFKqUdgCf9o//CYUurp0Uurn+TgljMxVIVUkkEjz82iR10QgfOnN10CEds2g0ypkrawmR54GdfWxutzUiTPkpWYJQ1ReAs2cov+goxytwfaniMZUvmUwynkjz0J4RPnr+Zmq88hrjMB/RaJSmWpd3rshx3wu9fOa9J1ZcW4pZ+oIfWmpMkYaHh3nolQEmcmF+84LKrF6aUlNTA8CFJy6ns3eEF3vG5jjDmMVnCcJUhHw+T9/wKHfvHOOyM1ZX/LKdjuOwdu1azj9xOR3eJHc93RV0SMa8hSUIU/bS6TSdnZ38bGc/oyn4o4s3Bx3SgohGo9S6Yc5c08TDLx8in7feTKa8WIIwZW90dJRsLs8De0a58OTVnLIy2BlZF0o4HKauro6z1zUxMpng+e7RoEMy5k0sQZiyNzExwa7BDJ2THlefvz7ocBbU6tWrOWPNMtxQnv/YMxh0OMa8iSUIU9YymQzZbJb7XxmivTHCe09eWqPnQ6EQy+qibGyOsuOg3UGY8mIJwpS1ZDLJRDLD46+N8bFz15bFmg4LzfM8TllRw3NdIzaq2pSVpfe/zSwpyWSS57vHSWmYy5bo2gme53Hi8ggj8QxdR6ynbUyQLEGYspZMJnmue4JVy2o4LeDlQkslEomwrrmGMHl29U4EHY4xr7MEYcpWPp9nPBZne3eM95/avmRHGnuex6plURxy7B2weZlM+bAEYcrW8PAwL3WPMpwJ8/4KW/NhPjzPI+qGWd3gWoIwZcUShClLqsrExATbu2NEo1HefkL5LiN6vBzHIRwOs7HFY+9ALOhwjHmdJQhTlmKxGIlkisf3T/L+Le14ztL+UfU8j45lHq/1T1pPJlM2lvb/OlOx4vE4u/sm6UuGuPS0lUGHU3Ke57GqwWUilWXA1qk2ZcIShClLsViMHb1xom6Yd21eWoPjZuK6Lm31LoKyf9C6upryYAnClJ10Ok0qleI/9k/yzk1tFb3uQ7E8z6O9IYJDnv2D1g5hyoMlCFN2Jicn6ZtIsX8sx/tOWfp3D1BIEC11HtFQnn1DliBMeSjlmtRREfmliDwvIi+LyF/65RtF5CkR2SMid4qI55dH/O1Of/+GUsVmylssFuPVgSQ5QrzjxNagw1kUnufhhEOsa/LsDsKUjVLeQaSAi1T1LGArcKmIXAD8LXCzqm4GRoBr/eOvBUZUdRNws3+cqTL5fJ5EIsFLh5OsXhZl/fLaoENaFCJCOBxmbZPH/iFrgzDloWQJQgumRv24/kOBi4Af+uV3AFf5r6/0t/H3XyxLdeisOapkMkk+n+fp7kkuOHH5kh09PRPXdVnd4HJgKGZdXU1ZKGkbhIiERWQH0A88COwFRlU16x/SDazxX68BDgL4+8eApTs6yswok8nQM5qgP55b0oPjZuK6LisbPOLpHP0T1tXVBK+kCUJVc6q6FVgLnAecOtNh/vNMfyq+5c8oEblORLaLyPaBgYGFC9aUhWQySWd/jBwhLqjCBNFW5wDKPmuHMGVgUXoxqeoo8ChwAdAkIo6/ay1wyH/dDXQA+PuXAcMzvNetqrpNVbe1tVVHD5dqEovF2DWYZmVjDWuba4IOZ1G5rkt7o3V1NeWjlL2Y2kSkyX9dA7wf2AU8AnzMP+wa4B7/9b3+Nv7+h9UqYqtKJpMhnU6zozfOeRtbqqr9ASAajdJc61ETytu6EKYsOHMfcsxWAXeISJhCIrpLVe8TkZ3AD0TkS8BzwG3+8bcB3xWRTgp3Dp8oYWymDMXjcQYn0/RM5Pm9jS1Bh7PoXNclHBJWN3ocHEkEHY4xpUsQqvoCcPYM5a9RaI84sjwJfLxU8Zjyl0gk2N0fI0OI86owQYRCIcLhMGuWeXYHYcqCjaQ2ZSMej/PqYIrmWo9NbfVBhxOIQk8mh25LEKYMWIIwZSGbzZLJZNjRG2fbhhZCoepqf5jiui4r6hyGYmliqezcJxhTQpYgTFmIx+OMxjO8NpLh/CqsXpriOA6ttYWa34MjdhdhgmUJwpSFRCLBnoEYGcJV2f4wxXVdWus9QuTpsik3TMAsQZiyEI/HeXUgRZ3nsGVVY9DhBMZ1Xdr8ab+tJ5MJmiUIE7hsNks6nebFw3HOWd+ME67eH0vXdanzwjRGQhy0hmoTsOr9n2jKRiKRIJ7OsWswxbb11Vu9BIU2CBFhTaNnCcIEzhKECVwikWDfUJyUhtm2oTnocAIVDof9sRCujYUwgbMEYQIXj8fZO5QiJMLWjqagwwlcYSyEy8GRuE37bQJlCcIEKpfLkUqleLk/yamrGqmLlHL2l8owNRYimckzMGnTfpvgWIIwgUqn0+Tyygu9cc5dX93VS1MKYyHCgHJw2HoymeBYgjCBSqVSdI8kGEtjCcLneR6t9R5h1BqqTaAsQZhApVIpXhuKkyNkCcJXSBARHHKWIEygLEGYQKVSKXYPJGhvjLCmqboWCDoaz/NwwyFW1jvWk8kEyhKECYyqFhqoDyfYtr76Fgg6GsdxCIVCrFnm2XxMJlCWIExgYrEYQ5Mp9o/nOMeql97E8zxWNzjWSG0CZQnCBCYej7N3IEYKh22WIN7E8zxW1IXpHUuQzuaDDsdUKUsQJjCJRILOoRRRN8yW1dU7Qd9MPM+jtdZBVTk0ancRJhhzJggR+aiINPivbxCRu0RkaxHndYjIIyKyS0ReFpHP+uVfFJEeEdnhPy6fds6NItIpIq+KyAeP58JMecvn8/4AuQRnrW3CreIJ+mZSmPZ7alZXa4cwwSjmf+UXVXVCRC4EPgzcCfxTEedlgc+p6qnABcD1IrLF33ezqm71Hz8B8Pd9AjgNuBT4hoiE53k9pkIkk0lSmRw7+5LWvXUGnuf5037nrCeTCUwxCSLnP38I+Iaq/giIzHWSqvaq6rP+6wlgF7BmllOuBH6gqilV3Qd0AucVEZ+pQIlEgn2DMWL5UNVP0DcTz/NoqnWpCdtoahOcYhJEr4j8I/DrwE9ExCvyvNeJyAbgbOApv+gPReQFEbldRKZ+O6wBDk47rZsZEoqIXCci20Vk+8DAwHzCMGUkkUiwdziFEuKcdZYgjhQKhfBclzWNrg2WM4Ep5hf9rwGPAVeo6gjQCtxQ7AeISD3wI+CPVXUc+CZwIrAV6AX+furQGU5/y1SWqnqrqm5T1W1tbW3FhmHKiKqSSCR4ZSDJphX1NNV6QYdUlqbP6mpMEI6aIESkUUQa/WPuBw7525PAfxbz5iLiUkgO31PVHwOoap+q5lQ1D3yLN6qRuoGOaaevBQ7N83pMBUin0+RyOZ7vjXOu3T0cleu6tNfbuhAmOLPdQbwMvOQ/jwBdFKqARvzyWUlhWOxtwC5V/eq08lXTDvuVae91L/AJEYmIyEZgM/DL4i/FVIpEIsHh8SSDCeVca384Ktd1aatzGI2nGU9mgg7HVKGjTr6vqh0AIvIN4H5Vvdff/jDw7iLe+x3AbwEvisgOv+wLwNV+N1kF9gN/4H/eyyJyF7CTQg+o61U195Z3NRUvmUyydyBBlrD1YJqF67q0NUQIM8bB4TinrV4WdEimyhSzOst5qvqZqQ1V/d8ictNcJ6nqz5m5XeEns5zzZeDLRcRkKtjUALmmWpcTWuuCDqdsvTEWotCTyRKEWWzFNFIP+wPk1orIGhH5PIVqJmPmLZfLkU6neWUwxRlrltkEfbNwHIe2+giO5K0nkwlEMQniNyg0Hv+7/+gAri5lUGbpSiaTZHJ5dg8mOX2N/UU8G9d1qY2EWRYR68lkAjFrFZM/kvnPVPX6RYrHLHHJZJKe0QTxfIgzLEHMSkRwHIc1jZ71ZDKBmPUOwm8kttHMZsEkk0m6RtMoliCK4bouqxo9q2IygSimkfpZEfkx8C9AbKpwqleTMfORTCbZN5JmWY3L2mZbQW4uruuyot7h/v0J8nklFLI2G7N4ikkQ7RQSw+XTypTCuAVjipbNZslms7w6kLQG6iI5jkNrrUM6m2NgMkV7YzTokEwVmTNBqOpvLUYgZulLpVJkcnleGUjyWyevCzqcilDo6uoRRukajluCMItqzgQhIhHgtylMw/36T6eqXle6sMxSlEqlODSaJJETa38o0huD5fJ0DcV524aWoEMyVaSYbq7fATZQmO77KQoT7SVLGJNZolKpFAdGkuStgbpojuOwvM7DFVs4yCy+YhLESap6IzCpqrdRWMzn9NKGZZaiVCr1egN1R4s1UBfDcRzccIj2Bpu0zyy+YhLE1CxhoyJyKtAArC9dSGYpyuVypFIp9g6n2LKq0RqoixQOhwmFQqxpjNBtCweZRVZMgrjNX9TnJuCnwG7eWMPBmKKkUilUlT2DKU5e2RB0OBXFcRxW2h2ECUAxvZhu8V8+AljXE3NMUqkUQ7E0Y2ksQcxTYU4ml76JGOlsHs+Z14KOxhyzOX/SRGS3iNwhIr8nIictRlBm6UmlUvSOp8kR4qR2SxDz4bourTVhVOHwmPUPMYunmD9FtgJ3UFgf+h9EZK+I/EtpwzJLTSqVome80Jx1Unt9wNFUFsdxWF7rAEr3qFUzmcVTTIJIARMURlMngEFgvJRBmaVFVUmn0xwYTbOmqYaGqBt0SBXFcRyW+4PlekasodosnmKm2hijsOzo14DfV9X+0oZklppMJkM+n2fvcJqT2m38w3w5jkNzrYcjeXpGLUGYxVPMHcQ1wC+AzwDfEZG/EJH3zHWSiHSIyCMisktEXhaRz/rlLSLyoIjs8Z+b/XIRka+LSKeIvCAi5xzPhZnykU6nyeWVvYNJTrIG6nlzHAcnLLTXu3TbHYRZRHMmCFX9kar+CfA7FBYM+j3ggSLeOwt8TlVPBS4ArheRLcANwEOquhl4yN8GuAzY7D+uA745z2sxZSqTyTA4mSaWg80rLEHMl+sWquRWN7pWxWQWVTG9mO4UkT3ALUAz8Lv+86xUtVdVn/VfTwC7KDR0X0mh0Rv/+Sr/9ZXAd7TgSaBJRFbN83pMGUqn0wxMFtaA2NhaG3Q4FWdqsNzKBs+qmMyiKqYN4mvA06qaPdYPEZENwNkU5nJqV9VeKCQREVnhH7YGODjttG6/rPdYP9eUh0wmQ3+s8OOzfnldwNFUJsdxWFHn0js2autCmEVTTBvEDuDPROSbACKySUQuK/YDRKQe+BHwx6o6W++nmX7idYb3u05EtovI9oGBgWLDMAFKp9P0TWapjxQmnjPz57ourXVhMjmlfyIVdDimShSTIG73j3uXv30I+Eoxby4iLoXk8D1V/bFf3DdVdeQ/T/WK6gY6pp2+1v+sN1HVW1V1m6pua2trKyYMEyBVJZvN0jOeZkNrrc3BdIwcx2F5TRiAHhsLYRZJMQlis6p+BX/SPlWNM/Nf+28ihd8EtwG7VPWr03bdS6FnFP7zPdPKP+X3ZroAGJuqijKVK5PJoKocHM1Y9dJxcF2XlloHQa0nk1k0xbRBpEUkil/dIyIbgXQR570D+C3gRRHZ4Zd9Afgb4C4RuRboAj7u7/sJhWVNO4E4hV5TpsJlMhlyeaVrNMXFZ1kD9bFyXZfldR5hbCyEWTzFJIi/Au4H1orIHcB7gGvnOklVf87R7zQunuF4Ba4vIh5TQTKZDMOxNKm82B3EcXBdl4gbprUmxEGb9tssklkThF9N9DyFv/IvpPAL/89tNLUpViaToX8iRQ5hfYvdQRyrSCQCwLrmCF3DsYCjMdVi1gShqioi96nqubzRVmBM0bLZLIPxHGB3EMcjFArhOA5rGlye7rdGarM4immk/qVNe2GOVWEMRAbPCbGiIRJ0OBUtEomwqiHModEE6Ww+6HBMFSgmQbyTQpJ4VUSeFZHnROTZUgdmloZMJsPh8QwdzTU2uOs4eZ5HW22YvKo1VJtFUUwj9VVzH2LMW02NgTg0nmb98uVBh1PxPM+jrSFCGGX/UIyNrVZlZ0qrmCVH9y5GIGbpyWazhTEQY2nO3GQN1MfLcRxWNEQIk6dryNohTOnZ4ramZDKZDLF0jvFUng7rwXTcXNelMepQ7wkHLEGYRWAJwpRMNptlYCJFjpB1cV0ArusiInQsi3BgyLq6mtKzBGFKpjAGIkmWEOuWW4I4XqFQiHA4zNomjwPDdgdhSu+obRAiMsIMs6lSGCynqtpSsqjMkpDJZBiMZQGho9kSxEJwHIdVDS4P7puwab9Nyc3WSN26aFGYJSmbzXJ4IsOKhgg1XjjocJYE13Vpr3dJZ/McHk+yuqkm6JDMEnbUKiZVzU1/AMuA9mkPY2aVyWToGk2xub0+6FCWDMdxWFFf+Ltu/6C1Q5jSKmbJ0StEZDeF9Rqe8p8fLnVgprLl83nS6TT7hlO2DvUCcl2X9oYIgrJ3YDLocMwSV0wj9ZcpTN39qqp2AB8EHi1lUKbyJZNJhmJpRtPCphV2B7FQXNelqcZhmQd7B+wOwpRWMQkiq6oDQEhERFUfBGxuJjOrTCZD71iSHCE2W4JYMJFIBBHhxOVRu4MwJVfMVBtjIlIH/Bz4joj0AzZTmJlVJpOhezhOlhCb262KaaFMjYXY0OzxRI8lCFNaxdxBXAUkgT+mULXUA3yohDGZJSCRSPDaSIq1zbW01HlBh7NkiAie57G20eXQWJJYKht0SGYJKyZB3Oj3ZMqo6m3++tJ/WurATOXK5/MkEgl29ac4a21T0OEsOYVpvws3//usJ5MpoWISxKUzlF0x10kicruI9IvIS9PKvigiPSKyw39cPm3fjSLS6U8r/sHiwjflKJlMMp5I0zWe46yOZUGHs+R4nkd7vWs9mUzJzTaS+g+ATwMnHbH+QwOwvYj3/jbwD8B3jii/WVX/7ojP2gJ8AjgNWA38TERO8sdfmAoTj8fZPxQnhcOZdgex4CKRCG0NESKSY2+/JQhTOrM1Ut8FPAT8NXDDtPKJYtakVtXHRWRDkXFcCfxAVVPAPhHpBM4DnijyfFNG4vE4+0czIMLpa+wOYqFFIhHccIj1TZ51dTUlNdtI6hFV7VTVjwM1wCX+o+04P/MPReQFvwqq2S9bAxycdky3X/YWInKdiGwXke0DAwPHGYpZaKpKKpVi90CSTW311EeK6Shn5sNxHEKhEBubI1bFZEqqmJHU11O4m1jnP+4Skc8c4+d9EzgR2Ar0An8/9TEzHDvTRIGo6q2quk1Vt7W1HW+uMgstk8mQy+XY2Zew6qUSmerJ1NHk8tpgjGzOep2b0ijmz7s/AM5T1UkAEfkK8AvgG/P9MFXtm3otIt8C7vM3u4GOaYeuBQ7N9/1N8NLpNIOTafrjObZaA3XJRCIRVjcUJu07OJKw5UdNSRTTi0mAzLTtDDP/xT/3G4msmrb5K8BUD6d7gU+ISERENgKbgV8ey2eYYCUSCToHJskQ5tz1NiN8qUQiEVY1eoTIs6dvIuhwzBI1Wy8mR1WzwHeBJ0XkR/6uXwHumOuNReT7wHuBVhHpBm4C3isiWylUH+2ncHeCqr4sIncBO4EscL31YKpM8XicPUNp6iMuJ6+0EdSl4nkeq5ZFccmzp3+SD5wWdERmKZqtiumXwDmq+t9F5BHgXRTuHD6tqk/P9caqevUMxbfNcvyXKUwMaCpULpcjmUzy0uEkZ69vIWyL2ZRMJBIh6oZZ0+jQaV1dTYnMliBe/9/tJ4Q5k4Kpbslkkngqx6tDKT5zdvPcJ5hj5jgO4XCYjc0RSxCmZGZLEG0ictQpNfwpN4x5XTqdZu/AJGkNsW29JYhS8zyPdU0ev9g5acuPmpKYLUGEgXqOsUHaVJ9EIkHnYBwJhdm6zrq4llokEmFNo0Mik6NnNEFHi637bRbWbAmiV1X/atEiMRVNVYnFYuwcSLNlVSO1ng2QK7VCT6YIYfJ09k9agjALbrZurnbnYIqWyWTIZHO82JfgXKteWhRv9GTKsaffurqahTdbgrh40aIwFS+bzdI1HCeegbdtsPEPiyESiVAXcVheE2L/UDwSGrs3AAAUq0lEQVTocMwSNNtcTMOLGYipbKlUij39E2QJsW2D3UEshnA4jOM4dDR5dFmCMCVQzEhqY+YUj8fZM5BkVXMd7Y3RoMOpGq7rsqrB5cCwzepqFp4lCHPcVJV4PM5LfQnr3rrIXNdlZb3DodEkGZu0zywwSxDmuKXTafrGEvTFlXOt/WFROY5Da51LLp/n0Ggi6HDMEmMJwhy3RCLBnv5Jkhrmbdb+sKhc16Wt3iOM0jVs7RBmYVmCMMctHo/TOZigNhrhpBU2Qd9ichyHFf5YiAPWUG0WmCUIc9wSiQQ7+xOcs67ZpntYZK7r0lTjUuNgdxBmwVmCMMclnU4zFkuyeyhtDdQBcF0XEbGurqYkLEGY4zI5OcnegUmS6nKutT8sulAoRDgcZk2jxwG7gzALzBKEOS4TExN0DqchFGZrh03QF4SpsRBdQzFUZ1zK3ZhjYgnCHLOpBYJe7k9z+mqboC8oruvSXu8QS+cYiqWDDscsISVLECJyu4j0i8hL08paRORBEdnjPzf75SIiXxeRThF5QUTOKVVcZuGk02myOeWF3pitPx0gz/NorXXAurqaBVbKO4hvA5ceUXYD8JCqbgYe8rcBLgM2+4/rgG+WMC6zQFKpFF3DMeJZbP6lALmuS1uDh0Oeg5YgzAIqWYJQ1ceBIyf8uxK4w399B3DVtPLvaMGTQJOIrCpVbGZhTI1/yBK2HkwBcl2X1vrCWAjryWQW0mK3QbSrai+A/7zCL18DHJx2XLdfZsrU1PxLrwym6GipYYVN0BcYx3FwwyFWNrjWk8ksqHJppJ5pdNWM3TFE5DoR2S4i2wcGBkocljmadDpNNpvl+d4Eb7P2h0C5rgtAx7KItUGYBbXYCaJvqurIf+73y7uBjmnHrQUOzfQGqnqrqm5T1W1tbW0lDdYcXTKZpG8ixeFYnm02QV+gRATHcVjV6FkbhFlQi50g7gWu8V9fA9wzrfxTfm+mC4CxqaooU56SySQ7ewsLBL1zU2vQ4VQ9x3FY2eByeDxJMpMLOhyzRJSym+v3gSeAk0WkW0SuBf4GuERE9gCX+NsAPwFeAzqBbwGfKVVcZmGkUileOhyno6WWdctrgw6n6jmOQ3u9gyp0j9i032ZhlGxkk6pefZRdb1nrWgvDP68vVSxmYakq8USCHT0x3n3WpqDDMRTWp26pCQPKweE4m1bUBx2SWQLKpZHaVJB4PM6evkmGUsK7Nlv1UjnwPI+2eg+XPAeGbPlRszAsQZh5Gx8f59muUfKOx7tPso4C5cB1XRqiDvWe0DVsVUxmYViCMPOSSqUYGxvjia4Y797cRn3E5l8qB1PTfq9r8qyrq1kwliDMvIyNjbGzd4Ld48KHz1oddDjG5zgOIsKaRo99g5NBh2OWCEsQpmiqSiwW46E9ozTXRbn09JVBh2SmcV2XjqbCYLlsLh90OGYJsARhihaPx+kbneSxfZN8fFsHESccdEhmGs/zWFXvkMkpB62rq1kAliBM0SYmJnh8zxAxXH7jvHVBh2OOEIlEWFEfRlD29ls1kzl+liBMUbLZLIMjY/x09yjv3rzCBseVoWg0yqrGGlxy7B2wBGGOnyUIU5S+vj7ue76Hg5PCH128OehwzAwikQi1kTDtdSFLEGZBWIIwc0qn0+w/PMQPXxrlirPXc66t/VCWXNclFAqxoTnKawM2WM4cP0sQZk7Dw8Pctb2bhET5/KWnBB2OmUWhJ5NndxBmQViCMLOKx+M89epBHtsf59Pv3czKZbYwUDlzXZc1jR4j8QxDk6mgwzEVzhKEOapUKkXXwYN87+ke6hub+P13nxB0SGYOruuysqEwun13n91FmONjCcIc1fDwMI/tHuCZwTBf+NBpRF0b91DuXNelo7mGEHl29o4HHY6pcJYgzIxSqRSHB0b43rODbNvYymU2aroiRKNRltW4rKwLs8sShDlONtOaeQtVpa+vjx/uOERPMsw3P7wFkZmWDTflxvM8AE5pr2XnIUsQ5vjYHYR5E1Wlp6eHJ3f3cveuCa591yZOW70s6LBMkcLhMOFwmBOXR9jTP0E6a3MymWNnCcK8yejoKIcGR/mnX/SwfmUrn/vASUGHZOappqaG9Y2FOZmsu6s5HoEkCBHZLyIvisgOEdnul7WIyIMissd/ttFYiyyXy9HX18e3n+iiJx3l61dvtQn5KlBNTQ1rl7mFhmqrZjLHIcg7iPep6lZV3eZv3wA8pKqbgYf8bbOIDh06xLNdozx6IMWff/AUNq1oCDokcwyi0SgrGqLUO2o9mcxxKacqpiuBO/zXdwBXBRhL1RkfH6d/ZJxvPXWYjatb+e0LNwQdkjlGkUiEcEg4pS1qPZnMcQkqQSjwgIg8IyLX+WXtqtoL4D+vmOlEEblORLaLyPaBgYFFCnfpGx8f559/2U130uXvPn4WTric/nYw8xEOh3Fdl02tEXb2jqOqQYdkKlRQvwXeoarnAJcB14vIu4s9UVVvVdVtqrqtra2tdBFWkcHBQe78xR5+tneSz158Eqeuagw6JHOcIpEIG5sjjMYz7B+yNarNsQkkQajqIf+5H/hX4DygT0RWAfjP/UHEVk2murTe8sDzfP+5fi7ZegKffs+JQYdlFkAkEuGUFbUIys/32J22OTaLniBEpE5EGqZeAx8AXgLuBa7xD7sGuGexY6sm2WyW117bxz/97GXueWmAy87bwt99fKtVLS0RNTU1tNV7bGhyeGz3YNDhmAoVxEjqduBf/ZG5DvD/q+r9IvI0cJeIXAt0AR8PILaqkM/nOdB1kFse2c39e2Nc/e6zuOHSU2y09BISjUYRES7csIy7dw6SzubxHEv+Zn4WPUGo6mvAWTOUDwEXL3Y81SYej7P7wCG+/sDLPNmb5zMfOJPr37fJksMSEw6H8TyPbWvr+d6OYR55tZ8PnmbzaZn5qdo/KXK5HMlkMugwFtXAwADP7erkpruf5/kh+OtPnMcfXrTZksMSVVdXx8nLXTYuC3Pbz/cFHY6pQFWbIHp6ejhw4EDVdAEcHh7m5X093HT/Pvan67n999/DlVvXBB2WKaHW1lbqamv42Kl1PL+vn0dftX4fZn6qNkEkEgmg0Fi7lKkqExMT/McLr/Glf9/DaL6WO//g7ZzV0RR0aKbEQqEQa9eu5ZLTV7OlOc9f/e+XyeZs8j5TvKpMENPvGtLpNPn80ryLyGQyPLdrD//fj5/gvz/YidS38qPPXMgpK22cQ7UIh8Osal/Br25dSe/gKL/YOxR0SKaCVOV6EPn8G39FfeWeZ/mP7iw/+i8X0tYQCTCqhRNPJHng2d089OJBdhwcZUJr+dC2U/n85VtoiLpBh2cWWX19Pds2trHiFz382wu9vPskG2BqilPVCSKTy7O/d5C+YeFv/v0V/v7X3tK5qmKk02m6e/u499n9PLrzMIOxNOGaBq648Cw++fYT6GipDTpEExARoamxnrPX1vP4ngFU1TommKJUdYJoW97CX1xxKj96tofbn+3iw6e3cc7aeobGYyQlysqmOprrvICjnZ2q0jcwwD1P7eaeHb30xZXTOpbzu5dv5tIz1lrfdwMU1qresrKeu/eOsm8wxglt9UGHZCpAVSaIqTaIuro6AD58Vp5nD+zk//neI7Q3RugbT6EKacKcsLKF09scYqkcPRM5Ql6E9a0NrFtex6pltdTURHEkjxsW3JAQccJ4rkNdTYTl9V7J1lNIpdLs6RngsRf38fDOw+wfz3PiutX8v5efxrnrbSkN82au67J5RT0uwzzbNWoJwhSlKhPE1B1EKBSivb0dz/P4bx+CB14+zIEJZdupzWxs8ujpH+LJ1wZ54OUUbqSGtY0O2ViC/zzUx0OZ3KyfoRQSTNRzaa51aarxWFYXpT7qUOM51EQ8WhrrWN/WyLrl9axpqiFMjmQ6S5owiVSGfC7HZCpD98AYh0cm6RsZ5+DgOIfGkgxPpsnllaQ6rFu9gr/+yKlcsqXdqg7MjGpqali1LEpLRHmua4SPnbs26JBMBaj6BAHQ3NxMXV0dZ512yutlU8f9XiyG67pEo1FUlWw2SyaTYWAyRd9onHgiSU6FDEI2B6lMllwuRyyRYmQixlgswVgix2giw6GBIRLpHMlM7vW1ghVQBEHxwkImd/QeVWkc2ptq2djexttOqWNVSwNvP2kVJ1uvJDMH13VxXZfT2mvYcXA06HBMhbAE4fO8t7Y1hEIhGhreWFVNRF7/j7a+tpb1K469KieRTNE7PE5X/xi9Y3H6J9JMZoV6V6h1Q0Q8l1AoTNQLs6qplo62ZaxqqsW1yfTMMaqpqeHk1giP7Zggkc5R49lysmZ2VZkgGhsb3/SLPwg10QgnrG7jhNXW5dAsDs/z2NhSQy4/wQvdo5x/wvKgQzJlrmr/HBURq683VcVxHDavqMcR5T87bQpwM7eqTRDGVBvHcaiNhNm6poFHXrVFhMzcLEEYUyUcp1Cj/IFT23ixZ4yXesYCjsiUu6psgzCmGk0liAtWu5wQifGZW+5nWdRFAVTJKyiKqt+77himKCtlre183nq+Ycwnbpnvu8/rvYv3wXNO4P+67Oz5xTJPliCMqRKO49DS0kImk+Fzl5/GI68UqpkEISSFX5KFR+FXoMD8fmPNI6HMN/eUcjrN+STC+SfN4k9403sX8e++tqX0HW0sQRhTRdraCr3mVq9ezRXnBxyMKXtl1wYhIpeKyKsi0ikiNwQdjzHGVKuyShAiEgb+EbgM2AJcLSJbgo3KGGOqU1klCOA8oFNVX1PVNPAD4MqAYzLGmKpUbgliDXBw2na3X/Y6EblORLaLyPaBAevLbYwxpVJuCWKmtvs3dQNQ1VtVdZuqbptqcDPGGLPwyi1BdAMd07bXAocCisUYY6pauSWIp4HNIrJRRDzgE8C9AcdkjDFVqazGQahqVkT+EPgpEAZuV9WXAw7LGGOqkuixjKcvEyIyABw4xtNbgaU6paVdW2Wya6tMlXht61V1zkbcik4Qx0NEtqvqtqDjKAW7tspk11aZlvK1lVsbhDHGmDJhCcIYY8yMqjlB3Bp0ACVk11aZ7Noq05K9tqptgzDGGDO7ar6DMMYYM4uqTBCVPqW4iHSIyCMisktEXhaRz/rlLSLyoIjs8Z+b/XIRka/71/uCiJwT7BXMTkTCIvKciNznb28Ukaf867rTH0SJiET87U5//4Yg456LiDSJyA9F5BX/u3v7EvrO/sT/WXxJRL4vItFK/d5E5HYR6ReRl6aVzft7EpFr/OP3iMg1QVzL8aq6BLFEphTPAp9T1VOBC4Dr/Wu4AXhIVTcDD/nbULjWzf7jOuCbix/yvHwW2DVt+2+Bm/3rGgGu9cuvBUZUdRNws39cOfsfwP2qegpwFoVrrPjvTETWAH8EbFPV0ykMcv0Elfu9fRu49IiyeX1PItIC3AScT2GW6pumkkpFUdWqegBvB346bftG4Mag4zrOa7oHuAR4FVjll60CXvVf3wJcPe34148rtweF+bceAi4C7qMwgeMg4Bz5/VEYcf92/7XjHydBX8NRrqsR2HdkfEvkO5uahbnF/x7uAz5Yyd8bsAF46Vi/J+Bq4JZp5W86rlIeVXcHQRFTilcS//b8bOApoF1VewH85xX+YZV0zV8D/iuQ97eXA6OqmvW3p8f++nX5+8f848vRCcAA8L/86rP/KSJ1LIHvTFV7gL8DuoBeCt/DMyyN723KfL+nivn+ZlONCWLOKcUrhYjUAz8C/lhVx2c7dIaysrtmEfkQ0K+qz0wvnuFQLWJfuXGAc4BvqurZQIw3qilmUjHX5ledXAlsBFYDdRSqXo5Uid/bXI52LUviGqsxQSyJKcVFxKWQHL6nqj/2i/tEZJW/fxXQ75dXyjW/A/iIiOynsJrgRRTuKJpEZGpiyemxv35d/v5lwPBiBjwP3UC3qj7lb/+QQsKo9O8M4P3APlUdUNUM8GPgQpbG9zZlvt9TJX1/R1WNCaLipxQXEQFuA3ap6len7boXmOotcQ2Ftomp8k/5PS4uAMambpfLiareqKprVXUDhe/lYVX9JPAI8DH/sCOva+p6P+YfX5Z/panqYeCgiJzsF10M7KTCvzNfF3CBiNT6P5tT11bx39s08/2efgp8QESa/TusD/hllSXoRpAgHsDlwG5gL/B/Bx3PMcT/Tgq3qy8AO/zH5RTqcR8C9vjPLf7xQqHn1l7gRQq9TQK/jjmu8b3Aff7rE4BfAp3AvwARvzzqb3f6+08IOu45rmkrsN3/3u4GmpfKdwb8JfAK8BLwXSBSqd8b8H0KbSkZCncC1x7L9wT8rn+NncDvBH1dx/KwkdTGGGNmVI1VTMYYY4pgCcIYY8yMLEEYY4yZkSUIY4wxM7IEYYwxZkaWIIyZRkRyIrJj2mPW2X5F5NMi8qkF+Nz9ItJ6vO9jzEKybq7GTCMik6paH8Dn7qfQh35wsT/bmKOxOwhjiuD/hf+3IvJL/7HJL/+iiPyZ//qPRGSnvy7AD/yyFhG52y97UkTO9MuXi8gD/sR9tzBt7h4R+U3/M3aIyC3+FPXGLDpLEMa8Wc0RVUy/Pm3fuKqeB/wDhTmijnQDcLaqngl82i/7S+A5v+wLwHf88puAn2th4r57gXUAInIq8OvAO1R1K5ADPrmwl2hMcZy5DzGmqiT8X8wz+f6055tn2P8C8D0RuZvCVBpQmBblVwFU9WH/zmEZ8G7go375v4nIiH/8xcC5wNOFaY2o4Y2J4YxZVJYgjCmeHuX1lCso/OL/CPAXInIas0/7PNN7CHCHqt54PIEasxCsismY4v36tOcnpu8QkRDQoaqPUFjwqAmoBx7HryISkfcCg1pYu2N6+WUUJu6DwkRwHxORFf6+FhFZX8JrMuao7A7CmDerEZEd07bvV9Wprq4REXmKwh9WVx9xXhj4Z7/6SCisxTwqIl+ksIrcC0CcN6aM/kvg+yLyLPAYhSmzUdWdIvLfgAf8pJMBrgcOLPSFGjMX6+ZqTBGsG6qpRlbFZIwxZkZ2B2GMMWZGdgdhjDFmRpYgjDHGzMgShDHGmBlZgjDGGDMjSxDGGGNmZAnCGGPMjP4PQykifSd/5HEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average losses')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "# Creating a gym env\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# A training graph session\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        # Closing the env\n",
    "        print('total_reward: {}'.format(total_reward))\n",
    "# Close the env at the end\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

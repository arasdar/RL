{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    #states = tf.placeholder(tf.float32, [None, *state_size], name='states')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    rewards = tf.placeholder(tf.float32, [None], name='rewards')\n",
    "    dones = tf.placeholder(tf.float32, [None], name='dones')\n",
    "    rates = tf.placeholder(tf.float32, [None], name='rates') # success rate\n",
    "    return states, actions, next_states, rewards, dones, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('actor', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(actions, state_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=actions, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=state_size)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(states, actions, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=action_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        nl1_fused = tf.concat(axis=1, values=[nl1, actions])\n",
    "        h2 = tf.layers.dense(inputs=nl1_fused, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "                \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(state_size, action_size, hidden_size, gamma,\n",
    "               states, actions, next_states, rewards, dones, rates):\n",
    "    actions_logits = actor(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    aloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                      labels=actions_labels))\n",
    "    ###############################################\n",
    "    next_states_logits = generator(actions=actions_logits, hidden_size=hidden_size, state_size=state_size)\n",
    "    next_states_labels = tf.nn.sigmoid(next_states)\n",
    "    aloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=next_states_logits, \n",
    "                                                                    labels=next_states_labels))\n",
    "    ####################################################\n",
    "    dQs = discriminator(actions=actions_labels, hidden_size=hidden_size, states=states, action_size=action_size)\n",
    "    rates = tf.reshape(rates, shape=[-1, 1])\n",
    "    dloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs, # GAN\n",
    "                                                                   labels=rates)) # 0-1\n",
    "    ####################################################\n",
    "    gQs = discriminator(actions=actions_logits, hidden_size=hidden_size, states=states, action_size=action_size, \n",
    "                        reuse=True)\n",
    "    dloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                    labels=tf.zeros_like(gQs))) # 0-1\n",
    "    aloss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                    labels=tf.ones_like(gQs))) # 0-1\n",
    "    #####################################################\n",
    "    next_actions_logits = actor(states=next_states, hidden_size=hidden_size, action_size=action_size, reuse=True)\n",
    "    gQs2 = discriminator(actions=next_actions_logits, hidden_size=hidden_size, states=next_states, \n",
    "                         action_size=action_size, reuse=True)\n",
    "    gQs2 = tf.reshape(gQs2, shape=[-1]) * (1-dones)\n",
    "    # dloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs2, # GAN\n",
    "    #                                                                 labels=tf.zeros_like(gQs2))) # 0-1\n",
    "    aloss2 += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs2, # GAN\n",
    "                                                                     labels=tf.ones_like(gQs2))) # 0-1\n",
    "#     ##################################################### repeatable!\n",
    "#     next_states_logits = generator(actions=next_actions_logits, hidden_size=hidden_size, state_size=state_size, \n",
    "#                                    reuse=True)\n",
    "#     next_actions_logits = actor(states=next_states_logits, hidden_size=hidden_size, action_size=action_size, \n",
    "#                                 reuse=True)\n",
    "#     gQs3 = discriminator(actions=next_actions_logits, hidden_size=hidden_size, states=next_states_logits, \n",
    "#                          action_size=action_size, reuse=True)\n",
    "#     dones2 = tf.concat(axis=0, values=[dones[1:], tf.ones(shape=[1])])\n",
    "#     gQs3 = tf.reshape(gQs3, shape=[-1]) * (1-dones2)\n",
    "#     dloss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs3, # GAN\n",
    "#                                                                     labels=tf.zeros_like(gQs3))) # 0-1\n",
    "#     aloss2 += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs3, # GAN\n",
    "#                                                                      labels=tf.ones_like(gQs3))) # 0-1\n",
    "    return actions_logits, aloss, dloss, aloss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(a_loss, a_loss2, d_loss, a_learning_rate, d_learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    a_vars = [var for var in t_vars if var.name.startswith('actor')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        a_opt = tf.train.AdamOptimizer(a_learning_rate).minimize(a_loss, var_list=a_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(d_learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "        a_opt2 = tf.train.AdamOptimizer(a_learning_rate).minimize(a_loss2, var_list=a_vars)\n",
    "    return a_opt, d_opt, a_opt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, a_learning_rate, d_learning_rate, gamma):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.next_states, self.rewards, self.dones, self.rates = model_input(\n",
    "            state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.a_loss, self.d_loss, self.a_loss2 = model_loss(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, gamma=gamma, # model init\n",
    "            states=self.states, actions=self.actions, next_states=self.next_states, #model input \n",
    "            rewards=self.rewards, dones=self.dones, rates=self.rates) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.a_opt, self.d_opt, self.a_opt2 = model_opt(a_loss=self.a_loss, \n",
    "                                                        a_loss2=self.a_loss2, \n",
    "                                                        d_loss=self.d_loss,\n",
    "                                                        a_learning_rate=a_learning_rate,\n",
    "                                                        d_learning_rate=d_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample(buffer, batch_size):\n",
    "#     idx = np.random.choice(np.arange(len(buffer)), size=batch_size, replace=False)\n",
    "#     return [buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size) # data batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 4*2             # number of units in each Q-network hidden layer\n",
    "a_learning_rate = 1e-4         # Q-network learning rate\n",
    "d_learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e3)             # experience mini-batch size: 200/500 a successfull episode size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size,\n",
    "              a_learning_rate=a_learning_rate, d_learning_rate=d_learning_rate, gamma=gamma)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "total_reward = 0\n",
    "num_step = 0\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    rate = -1\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done), rate])\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()\n",
    "        rate = total_reward/500\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.buffer[-1-idx][-1] == -1:\n",
    "                memory.buffer[-1-idx][-1] = rate\n",
    "        total_reward = 0 # reset\n",
    "        num_step = 0 # reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:15.0000 R:15.0000 rate:0.0300 aloss:1.3915 dloss:1.4025 aloss2:1.4267 exploreP:0.9985\n",
      "Episode:1 meanR:16.0000 R:17.0000 rate:0.0340 aloss:1.3881 dloss:1.3881 aloss2:1.4411 exploreP:0.9968\n",
      "Episode:2 meanR:15.0000 R:13.0000 rate:0.0260 aloss:1.3674 dloss:1.3812 aloss2:1.4448 exploreP:0.9956\n",
      "Episode:3 meanR:18.7500 R:30.0000 rate:0.0600 aloss:1.3891 dloss:1.3588 aloss2:1.4688 exploreP:0.9926\n",
      "Episode:4 meanR:20.0000 R:25.0000 rate:0.0500 aloss:1.3801 dloss:1.3535 aloss2:1.4685 exploreP:0.9901\n",
      "Episode:5 meanR:18.8333 R:13.0000 rate:0.0260 aloss:1.3820 dloss:1.3335 aloss2:1.4906 exploreP:0.9889\n",
      "Episode:6 meanR:17.7143 R:11.0000 rate:0.0220 aloss:1.3861 dloss:1.3299 aloss2:1.4929 exploreP:0.9878\n",
      "Episode:7 meanR:18.0000 R:20.0000 rate:0.0400 aloss:1.3779 dloss:1.3291 aloss2:1.4913 exploreP:0.9858\n",
      "Episode:8 meanR:17.4444 R:13.0000 rate:0.0260 aloss:1.3794 dloss:1.3084 aloss2:1.5148 exploreP:0.9846\n",
      "Episode:9 meanR:18.5000 R:28.0000 rate:0.0560 aloss:1.3802 dloss:1.3060 aloss2:1.5089 exploreP:0.9819\n",
      "Episode:10 meanR:17.7273 R:10.0000 rate:0.0200 aloss:1.3701 dloss:1.2964 aloss2:1.5237 exploreP:0.9809\n",
      "Episode:11 meanR:17.7500 R:18.0000 rate:0.0360 aloss:1.3813 dloss:1.2776 aloss2:1.5505 exploreP:0.9791\n",
      "Episode:12 meanR:17.2308 R:11.0000 rate:0.0220 aloss:1.3759 dloss:1.2895 aloss2:1.5232 exploreP:0.9781\n",
      "Episode:13 meanR:16.8571 R:12.0000 rate:0.0240 aloss:1.3851 dloss:1.2925 aloss2:1.5094 exploreP:0.9769\n",
      "Episode:14 meanR:16.4000 R:10.0000 rate:0.0200 aloss:1.3805 dloss:1.2700 aloss2:1.5459 exploreP:0.9759\n",
      "Episode:15 meanR:17.1875 R:29.0000 rate:0.0580 aloss:1.3893 dloss:1.2469 aloss2:1.5808 exploreP:0.9731\n",
      "Episode:16 meanR:18.4706 R:39.0000 rate:0.0780 aloss:1.3841 dloss:1.2425 aloss2:1.5746 exploreP:0.9694\n",
      "Episode:17 meanR:18.7222 R:23.0000 rate:0.0460 aloss:1.3873 dloss:1.2166 aloss2:1.6124 exploreP:0.9672\n",
      "Episode:18 meanR:18.7368 R:19.0000 rate:0.0380 aloss:1.4022 dloss:1.2178 aloss2:1.5988 exploreP:0.9654\n",
      "Episode:19 meanR:18.5500 R:15.0000 rate:0.0300 aloss:1.3881 dloss:1.2149 aloss2:1.6146 exploreP:0.9639\n",
      "Episode:20 meanR:19.2381 R:33.0000 rate:0.0660 aloss:1.3870 dloss:1.1987 aloss2:1.6323 exploreP:0.9608\n",
      "Episode:21 meanR:19.0000 R:14.0000 rate:0.0280 aloss:1.3935 dloss:1.1911 aloss2:1.6420 exploreP:0.9595\n",
      "Episode:22 meanR:18.5217 R:8.0000 rate:0.0160 aloss:1.3743 dloss:1.1844 aloss2:1.6466 exploreP:0.9587\n",
      "Episode:23 meanR:18.4583 R:17.0000 rate:0.0340 aloss:1.4107 dloss:1.1814 aloss2:1.6493 exploreP:0.9571\n",
      "Episode:24 meanR:19.1600 R:36.0000 rate:0.0720 aloss:1.3874 dloss:1.1558 aloss2:1.6932 exploreP:0.9537\n",
      "Episode:25 meanR:20.1538 R:45.0000 rate:0.0900 aloss:1.4105 dloss:1.1448 aloss2:1.6945 exploreP:0.9495\n",
      "Episode:26 meanR:21.6667 R:61.0000 rate:0.1220 aloss:1.4007 dloss:1.1114 aloss2:1.7519 exploreP:0.9437\n",
      "Episode:27 meanR:21.3929 R:14.0000 rate:0.0280 aloss:1.3806 dloss:1.1038 aloss2:1.7540 exploreP:0.9424\n",
      "Episode:28 meanR:21.0345 R:11.0000 rate:0.0220 aloss:1.3902 dloss:1.0749 aloss2:1.8190 exploreP:0.9414\n",
      "Episode:29 meanR:21.0333 R:21.0000 rate:0.0420 aloss:1.3902 dloss:1.0683 aloss2:1.8305 exploreP:0.9395\n",
      "Episode:30 meanR:21.3226 R:30.0000 rate:0.0600 aloss:1.3916 dloss:1.0601 aloss2:1.8413 exploreP:0.9367\n",
      "Episode:31 meanR:21.5625 R:29.0000 rate:0.0580 aloss:1.4072 dloss:1.0323 aloss2:1.8936 exploreP:0.9340\n",
      "Episode:32 meanR:21.6667 R:25.0000 rate:0.0500 aloss:1.4040 dloss:1.0201 aloss2:1.9008 exploreP:0.9317\n",
      "Episode:33 meanR:21.4118 R:13.0000 rate:0.0260 aloss:1.3967 dloss:0.9949 aloss2:1.9721 exploreP:0.9305\n",
      "Episode:34 meanR:21.6286 R:29.0000 rate:0.0580 aloss:1.4407 dloss:0.9867 aloss2:1.9873 exploreP:0.9278\n",
      "Episode:35 meanR:21.6389 R:22.0000 rate:0.0440 aloss:1.4105 dloss:0.9902 aloss2:1.9947 exploreP:0.9258\n",
      "Episode:36 meanR:21.7027 R:24.0000 rate:0.0480 aloss:1.4210 dloss:0.9413 aloss2:2.0997 exploreP:0.9236\n",
      "Episode:37 meanR:21.6842 R:21.0000 rate:0.0420 aloss:1.4176 dloss:0.9186 aloss2:2.1441 exploreP:0.9217\n",
      "Episode:38 meanR:21.4615 R:13.0000 rate:0.0260 aloss:1.4121 dloss:0.9631 aloss2:2.0031 exploreP:0.9205\n",
      "Episode:39 meanR:21.4500 R:21.0000 rate:0.0420 aloss:1.4227 dloss:0.9169 aloss2:2.1913 exploreP:0.9186\n",
      "Episode:40 meanR:21.3171 R:16.0000 rate:0.0320 aloss:1.4493 dloss:0.9176 aloss2:2.1703 exploreP:0.9171\n",
      "Episode:41 meanR:21.6905 R:37.0000 rate:0.0740 aloss:1.3937 dloss:0.9197 aloss2:2.1202 exploreP:0.9138\n",
      "Episode:42 meanR:21.5581 R:16.0000 rate:0.0320 aloss:1.3870 dloss:0.8869 aloss2:2.2296 exploreP:0.9124\n",
      "Episode:43 meanR:21.3409 R:12.0000 rate:0.0240 aloss:1.4220 dloss:0.8628 aloss2:2.3290 exploreP:0.9113\n",
      "Episode:44 meanR:21.5111 R:29.0000 rate:0.0580 aloss:1.4183 dloss:0.8548 aloss2:2.3526 exploreP:0.9087\n",
      "Episode:45 meanR:21.4348 R:18.0000 rate:0.0360 aloss:1.4636 dloss:0.8371 aloss2:2.3751 exploreP:0.9070\n",
      "Episode:46 meanR:21.6383 R:31.0000 rate:0.0620 aloss:1.3947 dloss:0.8548 aloss2:2.3350 exploreP:0.9043\n",
      "Episode:47 meanR:21.8958 R:34.0000 rate:0.0680 aloss:1.4010 dloss:0.8015 aloss2:2.4937 exploreP:0.9012\n",
      "Episode:48 meanR:21.8980 R:22.0000 rate:0.0440 aloss:1.4738 dloss:0.8113 aloss2:2.4891 exploreP:0.8993\n",
      "Episode:49 meanR:21.9400 R:24.0000 rate:0.0480 aloss:1.3611 dloss:0.7984 aloss2:2.5351 exploreP:0.8971\n",
      "Episode:50 meanR:22.5098 R:51.0000 rate:0.1020 aloss:1.4101 dloss:0.7811 aloss2:2.5919 exploreP:0.8926\n",
      "Episode:51 meanR:22.6731 R:31.0000 rate:0.0620 aloss:1.4059 dloss:0.7842 aloss2:2.5461 exploreP:0.8899\n",
      "Episode:52 meanR:22.6981 R:24.0000 rate:0.0480 aloss:1.4058 dloss:0.7580 aloss2:2.6926 exploreP:0.8878\n",
      "Episode:53 meanR:22.7963 R:28.0000 rate:0.0560 aloss:1.3981 dloss:0.7522 aloss2:2.7568 exploreP:0.8853\n",
      "Episode:54 meanR:22.7091 R:18.0000 rate:0.0360 aloss:1.4096 dloss:0.7309 aloss2:2.8077 exploreP:0.8838\n",
      "Episode:55 meanR:22.6964 R:22.0000 rate:0.0440 aloss:1.4039 dloss:0.7306 aloss2:2.8607 exploreP:0.8818\n",
      "Episode:56 meanR:22.7895 R:28.0000 rate:0.0560 aloss:1.4360 dloss:0.6987 aloss2:2.9721 exploreP:0.8794\n",
      "Episode:57 meanR:22.5690 R:10.0000 rate:0.0200 aloss:1.3886 dloss:0.7332 aloss2:2.8501 exploreP:0.8785\n",
      "Episode:58 meanR:22.5763 R:23.0000 rate:0.0460 aloss:1.3899 dloss:0.7117 aloss2:2.9310 exploreP:0.8765\n",
      "Episode:59 meanR:22.4167 R:13.0000 rate:0.0260 aloss:1.3813 dloss:0.7161 aloss2:2.8095 exploreP:0.8754\n",
      "Episode:60 meanR:22.3443 R:18.0000 rate:0.0360 aloss:1.3984 dloss:0.7031 aloss2:3.0868 exploreP:0.8739\n",
      "Episode:61 meanR:22.6774 R:43.0000 rate:0.0860 aloss:1.4058 dloss:0.6884 aloss2:3.0971 exploreP:0.8701\n",
      "Episode:62 meanR:22.6508 R:21.0000 rate:0.0420 aloss:1.3957 dloss:0.6372 aloss2:3.1924 exploreP:0.8683\n",
      "Episode:63 meanR:22.5625 R:17.0000 rate:0.0340 aloss:1.4003 dloss:0.6533 aloss2:3.2394 exploreP:0.8669\n",
      "Episode:64 meanR:22.6000 R:25.0000 rate:0.0500 aloss:1.3915 dloss:0.6829 aloss2:3.0482 exploreP:0.8647\n",
      "Episode:65 meanR:22.5606 R:20.0000 rate:0.0400 aloss:1.4269 dloss:0.6406 aloss2:3.5605 exploreP:0.8630\n",
      "Episode:66 meanR:22.8358 R:41.0000 rate:0.0820 aloss:1.3991 dloss:0.6454 aloss2:3.2820 exploreP:0.8595\n",
      "Episode:67 meanR:25.0735 R:175.0000 rate:0.3500 aloss:1.3863 dloss:0.6381 aloss2:3.3259 exploreP:0.8448\n",
      "Episode:68 meanR:25.1304 R:29.0000 rate:0.0580 aloss:1.3796 dloss:0.6151 aloss2:3.5469 exploreP:0.8424\n",
      "Episode:69 meanR:25.0571 R:20.0000 rate:0.0400 aloss:1.3901 dloss:0.5854 aloss2:3.8121 exploreP:0.8407\n",
      "Episode:70 meanR:25.3944 R:49.0000 rate:0.0980 aloss:1.3806 dloss:0.6216 aloss2:3.4446 exploreP:0.8367\n",
      "Episode:71 meanR:25.2639 R:16.0000 rate:0.0320 aloss:1.3790 dloss:0.5838 aloss2:3.6344 exploreP:0.8353\n",
      "Episode:72 meanR:25.2466 R:24.0000 rate:0.0480 aloss:1.3956 dloss:0.6174 aloss2:3.6564 exploreP:0.8334\n",
      "Episode:73 meanR:25.1622 R:19.0000 rate:0.0380 aloss:1.3882 dloss:0.5677 aloss2:3.7847 exploreP:0.8318\n",
      "Episode:74 meanR:25.3333 R:38.0000 rate:0.0760 aloss:1.3843 dloss:0.5818 aloss2:3.5996 exploreP:0.8287\n",
      "Episode:75 meanR:25.3553 R:27.0000 rate:0.0540 aloss:1.3924 dloss:0.5757 aloss2:3.7942 exploreP:0.8265\n",
      "Episode:76 meanR:25.3896 R:28.0000 rate:0.0560 aloss:1.3812 dloss:0.5644 aloss2:3.8761 exploreP:0.8242\n",
      "Episode:77 meanR:25.2692 R:16.0000 rate:0.0320 aloss:1.3938 dloss:0.5625 aloss2:3.8080 exploreP:0.8229\n",
      "Episode:78 meanR:25.1392 R:15.0000 rate:0.0300 aloss:1.3955 dloss:0.5853 aloss2:3.7308 exploreP:0.8217\n",
      "Episode:79 meanR:25.4500 R:50.0000 rate:0.1000 aloss:1.3941 dloss:0.5578 aloss2:3.8280 exploreP:0.8176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:80 meanR:25.4444 R:25.0000 rate:0.0500 aloss:1.3864 dloss:0.5444 aloss2:3.9876 exploreP:0.8156\n",
      "Episode:81 meanR:25.4756 R:28.0000 rate:0.0560 aloss:1.3894 dloss:0.5582 aloss2:3.9686 exploreP:0.8134\n",
      "Episode:82 meanR:25.4699 R:25.0000 rate:0.0500 aloss:1.4061 dloss:0.5839 aloss2:3.8954 exploreP:0.8114\n",
      "Episode:83 meanR:25.4524 R:24.0000 rate:0.0480 aloss:1.3836 dloss:0.5796 aloss2:4.2632 exploreP:0.8094\n",
      "Episode:84 meanR:25.7882 R:54.0000 rate:0.1080 aloss:1.3879 dloss:0.5657 aloss2:4.3067 exploreP:0.8051\n",
      "Episode:85 meanR:25.6977 R:18.0000 rate:0.0360 aloss:1.4104 dloss:0.5468 aloss2:4.6608 exploreP:0.8037\n",
      "Episode:86 meanR:25.7701 R:32.0000 rate:0.0640 aloss:1.4137 dloss:0.5144 aloss2:4.3068 exploreP:0.8012\n",
      "Episode:87 meanR:25.9773 R:44.0000 rate:0.0880 aloss:1.4173 dloss:0.5582 aloss2:4.6495 exploreP:0.7977\n",
      "Episode:88 meanR:25.8315 R:13.0000 rate:0.0260 aloss:1.4030 dloss:0.5454 aloss2:4.1209 exploreP:0.7967\n",
      "Episode:89 meanR:25.8556 R:28.0000 rate:0.0560 aloss:1.4142 dloss:0.5251 aloss2:4.4771 exploreP:0.7945\n",
      "Episode:90 meanR:26.0879 R:47.0000 rate:0.0940 aloss:1.3881 dloss:0.5300 aloss2:4.3786 exploreP:0.7908\n",
      "Episode:91 meanR:26.0326 R:21.0000 rate:0.0420 aloss:1.4067 dloss:0.5383 aloss2:4.3782 exploreP:0.7892\n",
      "Episode:92 meanR:25.9462 R:18.0000 rate:0.0360 aloss:1.4472 dloss:0.5101 aloss2:4.4691 exploreP:0.7877\n",
      "Episode:93 meanR:26.1489 R:45.0000 rate:0.0900 aloss:1.3914 dloss:0.5191 aloss2:4.7262 exploreP:0.7843\n",
      "Episode:94 meanR:26.1053 R:22.0000 rate:0.0440 aloss:1.4299 dloss:0.4818 aloss2:4.7671 exploreP:0.7826\n",
      "Episode:95 meanR:26.1354 R:29.0000 rate:0.0580 aloss:1.4074 dloss:0.5143 aloss2:4.8724 exploreP:0.7803\n",
      "Episode:96 meanR:26.0825 R:21.0000 rate:0.0420 aloss:1.4476 dloss:0.5155 aloss2:4.6251 exploreP:0.7787\n",
      "Episode:97 meanR:26.2041 R:38.0000 rate:0.0760 aloss:1.4227 dloss:0.5168 aloss2:4.9421 exploreP:0.7758\n",
      "Episode:98 meanR:26.2828 R:34.0000 rate:0.0680 aloss:1.4078 dloss:0.5054 aloss2:4.9099 exploreP:0.7732\n",
      "Episode:99 meanR:26.2800 R:26.0000 rate:0.0520 aloss:1.4530 dloss:0.5027 aloss2:4.9969 exploreP:0.7712\n",
      "Episode:100 meanR:26.2400 R:11.0000 rate:0.0220 aloss:1.4630 dloss:0.5889 aloss2:4.5760 exploreP:0.7704\n",
      "Episode:101 meanR:26.1700 R:10.0000 rate:0.0200 aloss:1.4685 dloss:0.4731 aloss2:5.2975 exploreP:0.7696\n",
      "Episode:102 meanR:26.3200 R:28.0000 rate:0.0560 aloss:1.4002 dloss:0.4761 aloss2:5.1537 exploreP:0.7675\n",
      "Episode:103 meanR:26.1500 R:13.0000 rate:0.0260 aloss:1.4075 dloss:0.4979 aloss2:4.8446 exploreP:0.7665\n",
      "Episode:104 meanR:26.0000 R:10.0000 rate:0.0200 aloss:1.4009 dloss:0.4487 aloss2:4.9894 exploreP:0.7657\n",
      "Episode:105 meanR:26.3000 R:43.0000 rate:0.0860 aloss:1.4286 dloss:0.4853 aloss2:5.0737 exploreP:0.7625\n",
      "Episode:106 meanR:26.4100 R:22.0000 rate:0.0440 aloss:1.4129 dloss:0.4668 aloss2:4.8627 exploreP:0.7608\n",
      "Episode:107 meanR:26.7300 R:52.0000 rate:0.1040 aloss:1.4111 dloss:0.5184 aloss2:5.1565 exploreP:0.7570\n",
      "Episode:108 meanR:27.0000 R:40.0000 rate:0.0800 aloss:1.4047 dloss:0.4837 aloss2:4.9226 exploreP:0.7540\n",
      "Episode:109 meanR:27.0200 R:30.0000 rate:0.0600 aloss:1.3996 dloss:0.4850 aloss2:5.1664 exploreP:0.7517\n",
      "Episode:110 meanR:27.1400 R:22.0000 rate:0.0440 aloss:1.4224 dloss:0.5033 aloss2:5.2834 exploreP:0.7501\n",
      "Episode:111 meanR:27.4900 R:53.0000 rate:0.1060 aloss:1.4603 dloss:0.5156 aloss2:4.9352 exploreP:0.7462\n",
      "Episode:112 meanR:27.6100 R:23.0000 rate:0.0460 aloss:1.4070 dloss:0.5367 aloss2:4.9638 exploreP:0.7445\n",
      "Episode:113 meanR:27.9000 R:41.0000 rate:0.0820 aloss:1.4218 dloss:0.4913 aloss2:4.7758 exploreP:0.7415\n",
      "Episode:114 meanR:28.2500 R:45.0000 rate:0.0900 aloss:1.4481 dloss:0.4937 aloss2:5.0548 exploreP:0.7382\n",
      "Episode:115 meanR:28.2200 R:26.0000 rate:0.0520 aloss:1.4097 dloss:0.4929 aloss2:5.0733 exploreP:0.7363\n",
      "Episode:116 meanR:28.0200 R:19.0000 rate:0.0380 aloss:1.3979 dloss:0.4724 aloss2:5.2861 exploreP:0.7350\n",
      "Episode:117 meanR:28.0100 R:22.0000 rate:0.0440 aloss:1.4266 dloss:0.4874 aloss2:5.2168 exploreP:0.7334\n",
      "Episode:118 meanR:28.2800 R:46.0000 rate:0.0920 aloss:1.4138 dloss:0.5109 aloss2:5.2674 exploreP:0.7300\n",
      "Episode:119 meanR:28.4400 R:31.0000 rate:0.0620 aloss:1.4462 dloss:0.5466 aloss2:5.2520 exploreP:0.7278\n",
      "Episode:120 meanR:28.4400 R:33.0000 rate:0.0660 aloss:1.4325 dloss:0.5289 aloss2:5.0382 exploreP:0.7254\n",
      "Episode:121 meanR:28.6500 R:35.0000 rate:0.0700 aloss:1.4460 dloss:0.4911 aloss2:5.0961 exploreP:0.7229\n",
      "Episode:122 meanR:28.9200 R:35.0000 rate:0.0700 aloss:1.4636 dloss:0.5230 aloss2:5.3777 exploreP:0.7205\n",
      "Episode:123 meanR:28.8500 R:10.0000 rate:0.0200 aloss:1.4213 dloss:0.4990 aloss2:5.3155 exploreP:0.7197\n",
      "Episode:124 meanR:28.6300 R:14.0000 rate:0.0280 aloss:1.4555 dloss:0.4682 aloss2:5.2256 exploreP:0.7188\n",
      "Episode:125 meanR:28.5400 R:36.0000 rate:0.0720 aloss:1.4428 dloss:0.5197 aloss2:5.0541 exploreP:0.7162\n",
      "Episode:126 meanR:28.0900 R:16.0000 rate:0.0320 aloss:1.4619 dloss:0.4568 aloss2:5.2680 exploreP:0.7151\n",
      "Episode:127 meanR:28.2900 R:34.0000 rate:0.0680 aloss:1.4597 dloss:0.4862 aloss2:5.3862 exploreP:0.7127\n",
      "Episode:128 meanR:28.4300 R:25.0000 rate:0.0500 aloss:1.4264 dloss:0.4829 aloss2:5.2430 exploreP:0.7109\n",
      "Episode:129 meanR:28.4100 R:19.0000 rate:0.0380 aloss:1.4287 dloss:0.5186 aloss2:5.3982 exploreP:0.7096\n",
      "Episode:130 meanR:28.3600 R:25.0000 rate:0.0500 aloss:1.4387 dloss:0.4885 aloss2:5.4193 exploreP:0.7079\n",
      "Episode:131 meanR:28.4000 R:33.0000 rate:0.0660 aloss:1.4639 dloss:0.4993 aloss2:5.2444 exploreP:0.7056\n",
      "Episode:132 meanR:28.2600 R:11.0000 rate:0.0220 aloss:1.4940 dloss:0.5191 aloss2:5.2675 exploreP:0.7048\n",
      "Episode:133 meanR:28.4700 R:34.0000 rate:0.0680 aloss:1.4317 dloss:0.5008 aloss2:5.5503 exploreP:0.7024\n",
      "Episode:134 meanR:28.6500 R:47.0000 rate:0.0940 aloss:1.4325 dloss:0.4977 aloss2:5.2524 exploreP:0.6992\n",
      "Episode:135 meanR:28.7900 R:36.0000 rate:0.0720 aloss:1.4570 dloss:0.5026 aloss2:5.4734 exploreP:0.6967\n",
      "Episode:136 meanR:29.6000 R:105.0000 rate:0.2100 aloss:1.4408 dloss:0.4927 aloss2:5.4615 exploreP:0.6895\n",
      "Episode:137 meanR:30.3100 R:92.0000 rate:0.1840 aloss:1.4469 dloss:0.5231 aloss2:5.6708 exploreP:0.6833\n",
      "Episode:138 meanR:30.7600 R:58.0000 rate:0.1160 aloss:1.4703 dloss:0.5058 aloss2:5.5876 exploreP:0.6794\n",
      "Episode:139 meanR:30.9000 R:35.0000 rate:0.0700 aloss:1.4972 dloss:0.4928 aloss2:5.5879 exploreP:0.6771\n",
      "Episode:140 meanR:31.1900 R:45.0000 rate:0.0900 aloss:1.4663 dloss:0.5072 aloss2:5.7316 exploreP:0.6741\n",
      "Episode:141 meanR:31.4100 R:59.0000 rate:0.1180 aloss:1.4162 dloss:0.4774 aloss2:5.5347 exploreP:0.6702\n",
      "Episode:142 meanR:32.3800 R:113.0000 rate:0.2260 aloss:1.4278 dloss:0.4925 aloss2:5.5323 exploreP:0.6628\n",
      "Episode:143 meanR:32.5100 R:25.0000 rate:0.0500 aloss:1.4397 dloss:0.5155 aloss2:5.6510 exploreP:0.6611\n",
      "Episode:144 meanR:32.5400 R:32.0000 rate:0.0640 aloss:1.4048 dloss:0.4614 aloss2:5.5623 exploreP:0.6590\n",
      "Episode:145 meanR:32.7700 R:41.0000 rate:0.0820 aloss:1.4241 dloss:0.4854 aloss2:5.6362 exploreP:0.6564\n",
      "Episode:146 meanR:33.5700 R:111.0000 rate:0.2220 aloss:1.4047 dloss:0.4950 aloss2:5.5604 exploreP:0.6493\n",
      "Episode:147 meanR:33.4800 R:25.0000 rate:0.0500 aloss:1.4049 dloss:0.4913 aloss2:5.7074 exploreP:0.6477\n",
      "Episode:148 meanR:34.1700 R:91.0000 rate:0.1820 aloss:1.3931 dloss:0.4841 aloss2:5.4101 exploreP:0.6419\n",
      "Episode:149 meanR:34.3800 R:45.0000 rate:0.0900 aloss:1.4093 dloss:0.5277 aloss2:5.3491 exploreP:0.6390\n",
      "Episode:150 meanR:34.1500 R:28.0000 rate:0.0560 aloss:1.4061 dloss:0.4719 aloss2:5.5008 exploreP:0.6373\n",
      "Episode:151 meanR:34.1600 R:32.0000 rate:0.0640 aloss:1.3995 dloss:0.5341 aloss2:5.4989 exploreP:0.6353\n",
      "Episode:152 meanR:34.6900 R:77.0000 rate:0.1540 aloss:1.4045 dloss:0.4996 aloss2:5.4019 exploreP:0.6305\n",
      "Episode:153 meanR:35.6300 R:122.0000 rate:0.2440 aloss:1.4076 dloss:0.4966 aloss2:5.4531 exploreP:0.6230\n",
      "Episode:154 meanR:35.7500 R:30.0000 rate:0.0600 aloss:1.3705 dloss:0.5203 aloss2:5.2959 exploreP:0.6211\n",
      "Episode:155 meanR:36.6700 R:114.0000 rate:0.2280 aloss:1.3890 dloss:0.5012 aloss2:5.3858 exploreP:0.6142\n",
      "Episode:156 meanR:36.5400 R:15.0000 rate:0.0300 aloss:1.5101 dloss:0.4404 aloss2:5.1856 exploreP:0.6133\n",
      "Episode:157 meanR:37.4000 R:96.0000 rate:0.1920 aloss:1.3983 dloss:0.4884 aloss2:5.3090 exploreP:0.6075\n",
      "Episode:158 meanR:37.7900 R:62.0000 rate:0.1240 aloss:1.4062 dloss:0.5017 aloss2:5.4425 exploreP:0.6038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:159 meanR:38.1400 R:48.0000 rate:0.0960 aloss:1.3940 dloss:0.4628 aloss2:5.2528 exploreP:0.6010\n",
      "Episode:160 meanR:38.3500 R:39.0000 rate:0.0780 aloss:1.3895 dloss:0.5006 aloss2:5.3597 exploreP:0.5987\n",
      "Episode:161 meanR:38.1100 R:19.0000 rate:0.0380 aloss:1.3927 dloss:0.4843 aloss2:5.3339 exploreP:0.5976\n",
      "Episode:162 meanR:38.0300 R:13.0000 rate:0.0260 aloss:1.4155 dloss:0.5243 aloss2:5.4964 exploreP:0.5968\n",
      "Episode:163 meanR:38.2600 R:40.0000 rate:0.0800 aloss:1.4151 dloss:0.4677 aloss2:5.2074 exploreP:0.5945\n",
      "Episode:164 meanR:38.3300 R:32.0000 rate:0.0640 aloss:1.4124 dloss:0.5362 aloss2:5.4046 exploreP:0.5926\n",
      "Episode:165 meanR:38.3200 R:19.0000 rate:0.0380 aloss:1.4051 dloss:0.4843 aloss2:5.4383 exploreP:0.5915\n",
      "Episode:166 meanR:38.1300 R:22.0000 rate:0.0440 aloss:1.3964 dloss:0.4639 aloss2:5.3232 exploreP:0.5902\n",
      "Episode:167 meanR:36.5700 R:19.0000 rate:0.0380 aloss:1.3827 dloss:0.5293 aloss2:5.2593 exploreP:0.5891\n",
      "Episode:168 meanR:36.8400 R:56.0000 rate:0.1120 aloss:1.4058 dloss:0.4896 aloss2:5.2770 exploreP:0.5859\n",
      "Episode:169 meanR:36.8200 R:18.0000 rate:0.0360 aloss:1.4203 dloss:0.5012 aloss2:5.3521 exploreP:0.5848\n",
      "Episode:170 meanR:36.8500 R:52.0000 rate:0.1040 aloss:1.3989 dloss:0.4968 aloss2:5.5023 exploreP:0.5819\n",
      "Episode:171 meanR:37.5800 R:89.0000 rate:0.1780 aloss:1.3973 dloss:0.4929 aloss2:5.4976 exploreP:0.5768\n",
      "Episode:172 meanR:38.0000 R:66.0000 rate:0.1320 aloss:1.4077 dloss:0.4784 aloss2:5.4244 exploreP:0.5731\n",
      "Episode:173 meanR:38.8600 R:105.0000 rate:0.2100 aloss:1.3994 dloss:0.4830 aloss2:5.4217 exploreP:0.5672\n",
      "Episode:174 meanR:39.2800 R:80.0000 rate:0.1600 aloss:1.4052 dloss:0.4713 aloss2:5.3623 exploreP:0.5627\n",
      "Episode:175 meanR:39.9500 R:94.0000 rate:0.1880 aloss:1.4189 dloss:0.4696 aloss2:5.5091 exploreP:0.5576\n",
      "Episode:176 meanR:40.4700 R:80.0000 rate:0.1600 aloss:1.4008 dloss:0.4863 aloss2:5.5248 exploreP:0.5532\n",
      "Episode:177 meanR:40.5700 R:26.0000 rate:0.0520 aloss:1.4098 dloss:0.5239 aloss2:5.5881 exploreP:0.5518\n",
      "Episode:178 meanR:42.3100 R:189.0000 rate:0.3780 aloss:1.4076 dloss:0.4876 aloss2:5.5322 exploreP:0.5417\n",
      "Episode:179 meanR:42.4300 R:62.0000 rate:0.1240 aloss:1.4001 dloss:0.4793 aloss2:5.5104 exploreP:0.5384\n",
      "Episode:180 meanR:42.3200 R:14.0000 rate:0.0280 aloss:1.3766 dloss:0.4649 aloss2:5.5455 exploreP:0.5376\n",
      "Episode:181 meanR:43.8100 R:177.0000 rate:0.3540 aloss:1.3992 dloss:0.4983 aloss2:5.4746 exploreP:0.5284\n",
      "Episode:182 meanR:44.0600 R:50.0000 rate:0.1000 aloss:1.4468 dloss:0.4840 aloss2:5.3984 exploreP:0.5258\n",
      "Episode:183 meanR:45.7500 R:193.0000 rate:0.3860 aloss:1.3983 dloss:0.5121 aloss2:5.3596 exploreP:0.5159\n",
      "Episode:184 meanR:45.6200 R:41.0000 rate:0.0820 aloss:1.4110 dloss:0.4821 aloss2:5.3026 exploreP:0.5139\n",
      "Episode:185 meanR:46.0300 R:59.0000 rate:0.1180 aloss:1.4065 dloss:0.4694 aloss2:5.3269 exploreP:0.5109\n",
      "Episode:186 meanR:46.2100 R:50.0000 rate:0.1000 aloss:1.4164 dloss:0.5010 aloss2:5.3629 exploreP:0.5084\n",
      "Episode:187 meanR:47.3400 R:157.0000 rate:0.3140 aloss:1.4081 dloss:0.5071 aloss2:5.3471 exploreP:0.5006\n",
      "Episode:188 meanR:47.5100 R:30.0000 rate:0.0600 aloss:1.4065 dloss:0.4640 aloss2:5.2993 exploreP:0.4992\n",
      "Episode:189 meanR:47.9600 R:73.0000 rate:0.1460 aloss:1.4126 dloss:0.4832 aloss2:5.3883 exploreP:0.4956\n",
      "Episode:190 meanR:47.8000 R:31.0000 rate:0.0620 aloss:1.4017 dloss:0.5299 aloss2:5.3599 exploreP:0.4941\n",
      "Episode:191 meanR:48.0300 R:44.0000 rate:0.0880 aloss:1.4125 dloss:0.4895 aloss2:5.3867 exploreP:0.4920\n",
      "Episode:192 meanR:48.4600 R:61.0000 rate:0.1220 aloss:1.3961 dloss:0.4956 aloss2:5.3659 exploreP:0.4890\n",
      "Episode:193 meanR:48.6000 R:59.0000 rate:0.1180 aloss:1.4482 dloss:0.4892 aloss2:5.4307 exploreP:0.4862\n",
      "Episode:194 meanR:48.6600 R:28.0000 rate:0.0560 aloss:1.4057 dloss:0.4837 aloss2:5.4847 exploreP:0.4849\n",
      "Episode:195 meanR:49.2500 R:88.0000 rate:0.1760 aloss:1.3854 dloss:0.4985 aloss2:5.3912 exploreP:0.4807\n",
      "Episode:196 meanR:50.1100 R:107.0000 rate:0.2140 aloss:1.4245 dloss:0.5070 aloss2:5.3724 exploreP:0.4757\n",
      "Episode:197 meanR:51.1900 R:146.0000 rate:0.2920 aloss:1.4028 dloss:0.5120 aloss2:5.3507 exploreP:0.4690\n",
      "Episode:198 meanR:51.3500 R:50.0000 rate:0.1000 aloss:1.4081 dloss:0.4978 aloss2:5.4079 exploreP:0.4667\n",
      "Episode:199 meanR:52.5600 R:147.0000 rate:0.2940 aloss:1.4266 dloss:0.5204 aloss2:5.3301 exploreP:0.4600\n",
      "Episode:200 meanR:53.8600 R:141.0000 rate:0.2820 aloss:1.4230 dloss:0.4906 aloss2:5.3328 exploreP:0.4537\n",
      "Episode:201 meanR:55.2800 R:152.0000 rate:0.3040 aloss:1.4271 dloss:0.4915 aloss2:5.3541 exploreP:0.4470\n",
      "Episode:202 meanR:55.4200 R:42.0000 rate:0.0840 aloss:1.4121 dloss:0.5387 aloss2:5.2562 exploreP:0.4452\n",
      "Episode:203 meanR:55.9600 R:67.0000 rate:0.1340 aloss:1.4227 dloss:0.5194 aloss2:5.2557 exploreP:0.4423\n",
      "Episode:204 meanR:60.8600 R:500.0000 rate:1.0000 aloss:1.4376 dloss:0.5016 aloss2:5.2986 exploreP:0.4212\n",
      "Episode:205 meanR:61.6300 R:120.0000 rate:0.2400 aloss:1.4442 dloss:0.5072 aloss2:5.3351 exploreP:0.4163\n",
      "Episode:206 meanR:62.6200 R:121.0000 rate:0.2420 aloss:1.4478 dloss:0.5029 aloss2:5.3372 exploreP:0.4114\n",
      "Episode:207 meanR:63.2500 R:115.0000 rate:0.2300 aloss:1.4553 dloss:0.5309 aloss2:5.3307 exploreP:0.4068\n",
      "Episode:208 meanR:63.0000 R:15.0000 rate:0.0300 aloss:1.4559 dloss:0.4870 aloss2:5.2437 exploreP:0.4062\n",
      "Episode:209 meanR:63.7800 R:108.0000 rate:0.2160 aloss:1.4367 dloss:0.5036 aloss2:5.3089 exploreP:0.4020\n",
      "Episode:210 meanR:65.3200 R:176.0000 rate:0.3520 aloss:1.4399 dloss:0.5127 aloss2:5.2785 exploreP:0.3951\n",
      "Episode:211 meanR:66.3800 R:159.0000 rate:0.3180 aloss:1.4337 dloss:0.5356 aloss2:5.2337 exploreP:0.3891\n",
      "Episode:212 meanR:71.0100 R:486.0000 rate:0.9720 aloss:1.4610 dloss:0.4980 aloss2:5.2585 exploreP:0.3711\n",
      "Episode:213 meanR:71.8800 R:128.0000 rate:0.2560 aloss:1.4690 dloss:0.5150 aloss2:5.3464 exploreP:0.3665\n",
      "Episode:214 meanR:71.7900 R:36.0000 rate:0.0720 aloss:1.4390 dloss:0.5987 aloss2:5.1466 exploreP:0.3652\n",
      "Episode:215 meanR:72.3300 R:80.0000 rate:0.1600 aloss:1.4386 dloss:0.6322 aloss2:5.1030 exploreP:0.3624\n",
      "Episode:216 meanR:72.3200 R:18.0000 rate:0.0360 aloss:1.4530 dloss:0.6859 aloss2:5.0561 exploreP:0.3617\n",
      "Episode:217 meanR:74.2200 R:212.0000 rate:0.4240 aloss:1.4646 dloss:0.5564 aloss2:5.0167 exploreP:0.3544\n",
      "Episode:218 meanR:76.7000 R:294.0000 rate:0.5880 aloss:1.4596 dloss:0.5796 aloss2:5.0377 exploreP:0.3444\n",
      "Episode:219 meanR:77.4900 R:110.0000 rate:0.2200 aloss:1.4910 dloss:0.5289 aloss2:5.1116 exploreP:0.3407\n",
      "Episode:220 meanR:77.6400 R:48.0000 rate:0.0960 aloss:1.4530 dloss:0.5394 aloss2:5.0898 exploreP:0.3391\n",
      "Episode:221 meanR:78.7900 R:150.0000 rate:0.3000 aloss:1.4669 dloss:0.5430 aloss2:5.1639 exploreP:0.3342\n",
      "Episode:222 meanR:78.9900 R:55.0000 rate:0.1100 aloss:1.4591 dloss:0.5793 aloss2:5.1157 exploreP:0.3325\n",
      "Episode:223 meanR:80.4100 R:152.0000 rate:0.3040 aloss:1.4607 dloss:0.5567 aloss2:5.0015 exploreP:0.3276\n",
      "Episode:224 meanR:81.2800 R:101.0000 rate:0.2020 aloss:1.4611 dloss:0.5192 aloss2:5.0199 exploreP:0.3244\n",
      "Episode:225 meanR:82.7200 R:180.0000 rate:0.3600 aloss:1.4592 dloss:0.5389 aloss2:5.0876 exploreP:0.3188\n",
      "Episode:226 meanR:84.5100 R:195.0000 rate:0.3900 aloss:1.4652 dloss:0.5507 aloss2:5.0337 exploreP:0.3128\n",
      "Episode:227 meanR:89.1700 R:500.0000 rate:1.0000 aloss:1.4674 dloss:0.5507 aloss2:5.0277 exploreP:0.2981\n",
      "Episode:228 meanR:92.8100 R:389.0000 rate:0.7780 aloss:1.4600 dloss:0.6007 aloss2:5.0007 exploreP:0.2871\n",
      "Episode:229 meanR:95.0800 R:246.0000 rate:0.4920 aloss:1.4678 dloss:0.5621 aloss2:4.9908 exploreP:0.2803\n",
      "Episode:230 meanR:96.8400 R:201.0000 rate:0.4020 aloss:1.4666 dloss:0.6059 aloss2:4.9679 exploreP:0.2750\n",
      "Episode:231 meanR:99.0100 R:250.0000 rate:0.5000 aloss:1.4387 dloss:0.5821 aloss2:4.9182 exploreP:0.2684\n",
      "Episode:232 meanR:101.7600 R:286.0000 rate:0.5720 aloss:1.4541 dloss:0.5957 aloss2:4.8654 exploreP:0.2611\n",
      "Episode:233 meanR:102.0500 R:63.0000 rate:0.1260 aloss:1.4540 dloss:0.5609 aloss2:4.8086 exploreP:0.2596\n",
      "Episode:234 meanR:104.0500 R:247.0000 rate:0.4940 aloss:1.4729 dloss:0.5551 aloss2:4.8842 exploreP:0.2535\n",
      "Episode:235 meanR:106.5700 R:288.0000 rate:0.5760 aloss:1.4691 dloss:0.5395 aloss2:4.9614 exploreP:0.2466\n",
      "Episode:236 meanR:108.3000 R:278.0000 rate:0.5560 aloss:1.4676 dloss:0.6054 aloss2:4.9909 exploreP:0.2401\n",
      "Episode:237 meanR:109.5700 R:219.0000 rate:0.4380 aloss:1.4537 dloss:0.5541 aloss2:4.9021 exploreP:0.2351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:238 meanR:111.2900 R:230.0000 rate:0.4600 aloss:1.4576 dloss:0.5909 aloss2:4.9915 exploreP:0.2300\n",
      "Episode:239 meanR:115.9400 R:500.0000 rate:1.0000 aloss:1.4490 dloss:0.5943 aloss2:4.9074 exploreP:0.2192\n",
      "Episode:240 meanR:120.4600 R:497.0000 rate:0.9940 aloss:1.4630 dloss:0.6146 aloss2:4.7713 exploreP:0.2091\n",
      "Episode:241 meanR:120.7300 R:86.0000 rate:0.1720 aloss:1.4740 dloss:0.6001 aloss2:4.8323 exploreP:0.2074\n",
      "Episode:242 meanR:124.3500 R:475.0000 rate:0.9500 aloss:1.4436 dloss:0.6116 aloss2:4.8400 exploreP:0.1982\n",
      "Episode:243 meanR:129.1000 R:500.0000 rate:1.0000 aloss:1.4374 dloss:0.6557 aloss2:4.6456 exploreP:0.1891\n",
      "Episode:244 meanR:131.3300 R:255.0000 rate:0.5100 aloss:1.4479 dloss:0.6588 aloss2:4.6364 exploreP:0.1845\n",
      "Episode:245 meanR:133.8200 R:290.0000 rate:0.5800 aloss:1.4475 dloss:0.6308 aloss2:4.6541 exploreP:0.1796\n",
      "Episode:246 meanR:136.2200 R:351.0000 rate:0.7020 aloss:1.4490 dloss:0.6176 aloss2:4.6354 exploreP:0.1737\n",
      "Episode:247 meanR:139.0300 R:306.0000 rate:0.6120 aloss:1.4370 dloss:0.6045 aloss2:4.6798 exploreP:0.1688\n",
      "Episode:248 meanR:143.1200 R:500.0000 rate:1.0000 aloss:1.4280 dloss:0.6598 aloss2:4.6726 exploreP:0.1610\n",
      "Episode:249 meanR:146.8300 R:416.0000 rate:0.8320 aloss:1.4388 dloss:0.6585 aloss2:4.5604 exploreP:0.1549\n",
      "Episode:250 meanR:151.0800 R:453.0000 rate:0.9060 aloss:1.4299 dloss:0.6469 aloss2:4.6112 exploreP:0.1485\n",
      "Episode:251 meanR:154.3100 R:355.0000 rate:0.7100 aloss:1.4528 dloss:0.6612 aloss2:4.5857 exploreP:0.1436\n",
      "Episode:252 meanR:156.7300 R:319.0000 rate:0.6380 aloss:1.4526 dloss:0.6584 aloss2:4.5129 exploreP:0.1394\n",
      "Episode:253 meanR:157.7600 R:225.0000 rate:0.4500 aloss:1.4404 dloss:0.6842 aloss2:4.4898 exploreP:0.1366\n",
      "Episode:254 meanR:160.7700 R:331.0000 rate:0.6620 aloss:1.4281 dloss:0.7132 aloss2:4.4759 exploreP:0.1324\n",
      "Episode:255 meanR:163.6500 R:402.0000 rate:0.8040 aloss:1.4363 dloss:0.6641 aloss2:4.5092 exploreP:0.1276\n",
      "Episode:256 meanR:168.4000 R:490.0000 rate:0.9800 aloss:1.4395 dloss:0.6925 aloss2:4.4253 exploreP:0.1220\n",
      "Episode:257 meanR:171.0300 R:359.0000 rate:0.7180 aloss:1.4475 dloss:0.6943 aloss2:4.3522 exploreP:0.1180\n",
      "Episode:258 meanR:175.4100 R:500.0000 rate:1.0000 aloss:1.4292 dloss:0.7441 aloss2:4.3345 exploreP:0.1128\n",
      "Episode:259 meanR:177.8400 R:291.0000 rate:0.5820 aloss:1.4300 dloss:0.6834 aloss2:4.3772 exploreP:0.1098\n",
      "Episode:260 meanR:182.4500 R:500.0000 rate:1.0000 aloss:1.4368 dloss:0.7017 aloss2:4.3722 exploreP:0.1050\n",
      "Episode:261 meanR:187.0300 R:477.0000 rate:0.9540 aloss:1.4471 dloss:0.7349 aloss2:4.2806 exploreP:0.1005\n",
      "Episode:262 meanR:188.9900 R:209.0000 rate:0.4180 aloss:1.4491 dloss:0.6937 aloss2:4.2171 exploreP:0.0987\n",
      "Episode:263 meanR:193.5900 R:500.0000 rate:1.0000 aloss:1.4424 dloss:0.7276 aloss2:4.3149 exploreP:0.0943\n",
      "Episode:264 meanR:194.6500 R:138.0000 rate:0.2760 aloss:1.4467 dloss:0.7727 aloss2:4.2772 exploreP:0.0932\n",
      "Episode:265 meanR:196.8600 R:240.0000 rate:0.4800 aloss:1.4432 dloss:0.7079 aloss2:4.2348 exploreP:0.0912\n",
      "Episode:266 meanR:201.6400 R:500.0000 rate:1.0000 aloss:1.4558 dloss:0.6906 aloss2:4.2499 exploreP:0.0872\n",
      "Episode:267 meanR:203.3400 R:189.0000 rate:0.3780 aloss:1.4518 dloss:0.7856 aloss2:4.2984 exploreP:0.0858\n",
      "Episode:268 meanR:204.0100 R:123.0000 rate:0.2460 aloss:1.4466 dloss:0.7224 aloss2:4.2070 exploreP:0.0849\n",
      "Episode:269 meanR:205.2700 R:144.0000 rate:0.2880 aloss:1.4795 dloss:0.7517 aloss2:4.1613 exploreP:0.0838\n",
      "Episode:270 meanR:206.0900 R:134.0000 rate:0.2680 aloss:1.4418 dloss:0.8185 aloss2:4.1305 exploreP:0.0828\n",
      "Episode:271 meanR:206.4900 R:129.0000 rate:0.2580 aloss:1.4626 dloss:0.6969 aloss2:4.1470 exploreP:0.0819\n",
      "Episode:272 meanR:207.0400 R:121.0000 rate:0.2420 aloss:1.4600 dloss:0.7047 aloss2:4.2043 exploreP:0.0810\n",
      "Episode:273 meanR:207.1800 R:119.0000 rate:0.2380 aloss:1.4569 dloss:0.6691 aloss2:4.2747 exploreP:0.0802\n",
      "Episode:274 meanR:207.5500 R:117.0000 rate:0.2340 aloss:1.4512 dloss:0.6606 aloss2:4.2836 exploreP:0.0794\n",
      "Episode:275 meanR:207.8600 R:125.0000 rate:0.2500 aloss:1.4357 dloss:0.8007 aloss2:4.3342 exploreP:0.0785\n",
      "Episode:276 meanR:208.4200 R:136.0000 rate:0.2720 aloss:1.4481 dloss:0.7564 aloss2:4.2671 exploreP:0.0776\n",
      "Episode:277 meanR:213.1600 R:500.0000 rate:1.0000 aloss:1.4394 dloss:0.8007 aloss2:4.0896 exploreP:0.0743\n",
      "Episode:278 meanR:213.4400 R:217.0000 rate:0.4340 aloss:1.4458 dloss:0.7232 aloss2:4.0648 exploreP:0.0729\n",
      "Episode:279 meanR:214.6100 R:179.0000 rate:0.3580 aloss:1.4399 dloss:0.8375 aloss2:4.1355 exploreP:0.0718\n",
      "Episode:280 meanR:215.7700 R:130.0000 rate:0.2600 aloss:1.4378 dloss:0.8165 aloss2:4.0316 exploreP:0.0710\n",
      "Episode:281 meanR:216.7500 R:275.0000 rate:0.5500 aloss:1.4496 dloss:0.7194 aloss2:4.0771 exploreP:0.0693\n",
      "Episode:282 meanR:217.8800 R:163.0000 rate:0.3260 aloss:1.4559 dloss:0.7386 aloss2:4.1234 exploreP:0.0684\n",
      "Episode:283 meanR:217.5300 R:158.0000 rate:0.3160 aloss:1.4432 dloss:0.7980 aloss2:4.0894 exploreP:0.0675\n",
      "Episode:284 meanR:218.3400 R:122.0000 rate:0.2440 aloss:1.4649 dloss:0.7645 aloss2:4.0505 exploreP:0.0668\n",
      "Episode:285 meanR:219.0300 R:128.0000 rate:0.2560 aloss:1.4462 dloss:0.7776 aloss2:4.1132 exploreP:0.0660\n",
      "Episode:286 meanR:219.6900 R:116.0000 rate:0.2320 aloss:1.4285 dloss:0.8314 aloss2:4.0469 exploreP:0.0654\n",
      "Episode:287 meanR:219.3200 R:120.0000 rate:0.2400 aloss:1.4475 dloss:0.7627 aloss2:4.0145 exploreP:0.0647\n",
      "Episode:288 meanR:220.3600 R:134.0000 rate:0.2680 aloss:1.4596 dloss:0.7656 aloss2:4.0056 exploreP:0.0640\n",
      "Episode:289 meanR:220.6400 R:101.0000 rate:0.2020 aloss:1.4493 dloss:0.7345 aloss2:4.0588 exploreP:0.0635\n",
      "Episode:290 meanR:221.5600 R:123.0000 rate:0.2460 aloss:1.4311 dloss:0.8515 aloss2:4.0932 exploreP:0.0628\n",
      "Episode:291 meanR:222.7400 R:162.0000 rate:0.3240 aloss:1.4259 dloss:0.8073 aloss2:4.0022 exploreP:0.0620\n",
      "Episode:292 meanR:223.3800 R:125.0000 rate:0.2500 aloss:1.4561 dloss:0.7481 aloss2:4.0043 exploreP:0.0613\n",
      "Episode:293 meanR:224.0800 R:129.0000 rate:0.2580 aloss:1.4325 dloss:0.7534 aloss2:4.0557 exploreP:0.0607\n",
      "Episode:294 meanR:225.3200 R:152.0000 rate:0.3040 aloss:1.4397 dloss:0.7969 aloss2:4.0238 exploreP:0.0599\n",
      "Episode:295 meanR:225.6800 R:124.0000 rate:0.2480 aloss:1.4472 dloss:0.9034 aloss2:3.9828 exploreP:0.0593\n",
      "Episode:296 meanR:225.8400 R:123.0000 rate:0.2460 aloss:1.4512 dloss:0.8203 aloss2:3.9187 exploreP:0.0587\n",
      "Episode:297 meanR:226.1400 R:176.0000 rate:0.3520 aloss:1.4321 dloss:0.8310 aloss2:3.9104 exploreP:0.0578\n",
      "Episode:298 meanR:228.8700 R:323.0000 rate:0.6460 aloss:1.4464 dloss:0.7577 aloss2:3.9358 exploreP:0.0563\n",
      "Episode:299 meanR:228.5500 R:115.0000 rate:0.2300 aloss:1.4283 dloss:0.7880 aloss2:4.0250 exploreP:0.0558\n",
      "Episode:300 meanR:228.3900 R:125.0000 rate:0.2500 aloss:1.4600 dloss:0.7721 aloss2:4.0175 exploreP:0.0552\n",
      "Episode:301 meanR:228.1300 R:126.0000 rate:0.2520 aloss:1.4348 dloss:0.8663 aloss2:3.9706 exploreP:0.0546\n",
      "Episode:302 meanR:229.1000 R:139.0000 rate:0.2780 aloss:1.4620 dloss:0.7397 aloss2:3.9649 exploreP:0.0540\n",
      "Episode:303 meanR:229.6200 R:119.0000 rate:0.2380 aloss:1.4237 dloss:0.9534 aloss2:3.8887 exploreP:0.0535\n",
      "Episode:304 meanR:225.8900 R:127.0000 rate:0.2540 aloss:1.4227 dloss:0.8514 aloss2:3.8511 exploreP:0.0530\n",
      "Episode:305 meanR:226.0900 R:140.0000 rate:0.2800 aloss:1.4353 dloss:0.8895 aloss2:3.7961 exploreP:0.0524\n",
      "Episode:306 meanR:226.0700 R:119.0000 rate:0.2380 aloss:1.4344 dloss:0.7853 aloss2:3.8543 exploreP:0.0519\n",
      "Episode:307 meanR:226.2100 R:129.0000 rate:0.2580 aloss:1.4294 dloss:0.7900 aloss2:3.9143 exploreP:0.0513\n",
      "Episode:308 meanR:227.5200 R:146.0000 rate:0.2920 aloss:1.4434 dloss:0.8145 aloss2:3.8886 exploreP:0.0507\n",
      "Episode:309 meanR:227.7500 R:131.0000 rate:0.2620 aloss:1.4552 dloss:0.7360 aloss2:3.9061 exploreP:0.0502\n",
      "Episode:310 meanR:228.1200 R:213.0000 rate:0.4260 aloss:1.4413 dloss:0.8358 aloss2:3.9297 exploreP:0.0493\n",
      "Episode:311 meanR:227.7400 R:121.0000 rate:0.2420 aloss:1.4452 dloss:0.7811 aloss2:3.8870 exploreP:0.0489\n",
      "Episode:312 meanR:224.2100 R:133.0000 rate:0.2660 aloss:1.4713 dloss:0.7369 aloss2:3.9123 exploreP:0.0484\n",
      "Episode:313 meanR:224.1300 R:120.0000 rate:0.2400 aloss:1.4483 dloss:0.7307 aloss2:3.9865 exploreP:0.0479\n",
      "Episode:314 meanR:224.9400 R:117.0000 rate:0.2340 aloss:1.4187 dloss:0.8731 aloss2:4.0132 exploreP:0.0475\n",
      "Episode:315 meanR:225.5900 R:145.0000 rate:0.2900 aloss:1.4282 dloss:0.8230 aloss2:3.9253 exploreP:0.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:316 meanR:228.1100 R:270.0000 rate:0.5400 aloss:1.4401 dloss:0.8721 aloss2:3.8864 exploreP:0.0459\n",
      "Episode:317 meanR:227.1400 R:115.0000 rate:0.2300 aloss:1.4602 dloss:0.8019 aloss2:3.8267 exploreP:0.0455\n",
      "Episode:318 meanR:225.3400 R:114.0000 rate:0.2280 aloss:1.4329 dloss:0.7874 aloss2:3.9088 exploreP:0.0451\n",
      "Episode:319 meanR:225.4500 R:121.0000 rate:0.2420 aloss:1.4193 dloss:0.9116 aloss2:3.8725 exploreP:0.0447\n",
      "Episode:320 meanR:226.1900 R:122.0000 rate:0.2440 aloss:1.4496 dloss:0.7305 aloss2:3.8745 exploreP:0.0443\n",
      "Episode:321 meanR:225.8600 R:117.0000 rate:0.2340 aloss:1.4144 dloss:0.8533 aloss2:3.9084 exploreP:0.0439\n",
      "Episode:322 meanR:226.6700 R:136.0000 rate:0.2720 aloss:1.4268 dloss:0.8282 aloss2:3.8622 exploreP:0.0434\n",
      "Episode:323 meanR:228.8500 R:370.0000 rate:0.7400 aloss:1.4443 dloss:0.8032 aloss2:3.8555 exploreP:0.0422\n",
      "Episode:324 meanR:229.0500 R:121.0000 rate:0.2420 aloss:1.4166 dloss:0.8578 aloss2:3.8694 exploreP:0.0418\n",
      "Episode:325 meanR:230.7700 R:352.0000 rate:0.7040 aloss:1.4144 dloss:0.8548 aloss2:3.8398 exploreP:0.0407\n",
      "Episode:326 meanR:231.6200 R:280.0000 rate:0.5600 aloss:1.4514 dloss:0.8030 aloss2:3.8548 exploreP:0.0399\n",
      "Episode:327 meanR:228.2800 R:166.0000 rate:0.3320 aloss:1.4762 dloss:0.7735 aloss2:3.8716 exploreP:0.0394\n",
      "Episode:328 meanR:225.5400 R:115.0000 rate:0.2300 aloss:1.4367 dloss:0.7918 aloss2:3.8992 exploreP:0.0390\n",
      "Episode:329 meanR:224.5000 R:142.0000 rate:0.2840 aloss:1.4381 dloss:0.8805 aloss2:3.9217 exploreP:0.0386\n",
      "Episode:330 meanR:223.6600 R:117.0000 rate:0.2340 aloss:1.4389 dloss:0.8547 aloss2:3.7812 exploreP:0.0383\n",
      "Episode:331 meanR:222.5400 R:138.0000 rate:0.2760 aloss:1.4238 dloss:0.8113 aloss2:3.8495 exploreP:0.0379\n",
      "Episode:332 meanR:221.1400 R:146.0000 rate:0.2920 aloss:1.4209 dloss:0.8750 aloss2:3.8415 exploreP:0.0375\n",
      "Episode:333 meanR:221.8000 R:129.0000 rate:0.2580 aloss:1.4029 dloss:0.9080 aloss2:3.7707 exploreP:0.0372\n",
      "Episode:334 meanR:220.6300 R:130.0000 rate:0.2600 aloss:1.4279 dloss:0.7807 aloss2:3.7953 exploreP:0.0368\n",
      "Episode:335 meanR:218.9700 R:122.0000 rate:0.2440 aloss:1.4139 dloss:0.8621 aloss2:3.7870 exploreP:0.0365\n",
      "Episode:336 meanR:217.5100 R:132.0000 rate:0.2640 aloss:1.4202 dloss:0.8370 aloss2:3.8031 exploreP:0.0361\n",
      "Episode:337 meanR:216.6300 R:131.0000 rate:0.2620 aloss:1.4320 dloss:0.8612 aloss2:3.7880 exploreP:0.0358\n",
      "Episode:338 meanR:216.0000 R:167.0000 rate:0.3340 aloss:1.4370 dloss:0.8211 aloss2:3.7731 exploreP:0.0354\n",
      "Episode:339 meanR:212.4500 R:145.0000 rate:0.2900 aloss:1.4186 dloss:0.8237 aloss2:3.8204 exploreP:0.0350\n",
      "Episode:340 meanR:208.7800 R:130.0000 rate:0.2600 aloss:1.4099 dloss:0.9479 aloss2:3.7411 exploreP:0.0347\n",
      "Episode:341 meanR:209.3100 R:139.0000 rate:0.2780 aloss:1.4636 dloss:0.8014 aloss2:3.7440 exploreP:0.0343\n",
      "Episode:342 meanR:205.9100 R:135.0000 rate:0.2700 aloss:1.4201 dloss:0.8507 aloss2:3.7825 exploreP:0.0340\n",
      "Episode:343 meanR:202.1800 R:127.0000 rate:0.2540 aloss:1.4252 dloss:0.8826 aloss2:3.7928 exploreP:0.0337\n",
      "Episode:344 meanR:201.7300 R:210.0000 rate:0.4200 aloss:1.4258 dloss:0.8193 aloss2:3.7677 exploreP:0.0332\n",
      "Episode:345 meanR:200.1500 R:132.0000 rate:0.2640 aloss:1.4414 dloss:0.8589 aloss2:3.7799 exploreP:0.0329\n",
      "Episode:346 meanR:197.6200 R:98.0000 rate:0.1960 aloss:1.4090 dloss:0.9336 aloss2:3.7670 exploreP:0.0327\n",
      "Episode:347 meanR:197.8100 R:325.0000 rate:0.6500 aloss:1.4118 dloss:0.8678 aloss2:3.7102 exploreP:0.0320\n",
      "Episode:348 meanR:194.4000 R:159.0000 rate:0.3180 aloss:1.4503 dloss:0.7610 aloss2:3.7294 exploreP:0.0316\n",
      "Episode:349 meanR:191.4700 R:123.0000 rate:0.2460 aloss:1.4093 dloss:0.8653 aloss2:3.8101 exploreP:0.0314\n",
      "Episode:350 meanR:188.2500 R:131.0000 rate:0.2620 aloss:1.4074 dloss:0.8650 aloss2:3.7902 exploreP:0.0311\n",
      "Episode:351 meanR:185.8300 R:113.0000 rate:0.2260 aloss:1.4350 dloss:0.7990 aloss2:3.7898 exploreP:0.0308\n",
      "Episode:352 meanR:183.9200 R:128.0000 rate:0.2560 aloss:1.4255 dloss:0.8203 aloss2:3.8423 exploreP:0.0306\n",
      "Episode:353 meanR:183.1700 R:150.0000 rate:0.3000 aloss:1.4029 dloss:0.8555 aloss2:3.7973 exploreP:0.0303\n",
      "Episode:354 meanR:181.5100 R:165.0000 rate:0.3300 aloss:1.4263 dloss:0.8501 aloss2:3.7452 exploreP:0.0299\n",
      "Episode:355 meanR:178.6800 R:119.0000 rate:0.2380 aloss:1.3951 dloss:0.9649 aloss2:3.7653 exploreP:0.0297\n",
      "Episode:356 meanR:175.2500 R:147.0000 rate:0.2940 aloss:1.4104 dloss:0.9310 aloss2:3.6693 exploreP:0.0294\n",
      "Episode:357 meanR:173.2200 R:156.0000 rate:0.3120 aloss:1.3963 dloss:0.8629 aloss2:3.6476 exploreP:0.0291\n",
      "Episode:358 meanR:169.5400 R:132.0000 rate:0.2640 aloss:1.4318 dloss:0.8003 aloss2:3.7263 exploreP:0.0289\n",
      "Episode:359 meanR:168.3300 R:170.0000 rate:0.3400 aloss:1.3972 dloss:0.9015 aloss2:3.7266 exploreP:0.0285\n",
      "Episode:360 meanR:166.9900 R:366.0000 rate:0.7320 aloss:1.4106 dloss:0.8845 aloss2:3.6814 exploreP:0.0279\n",
      "Episode:361 meanR:163.7000 R:148.0000 rate:0.2960 aloss:1.3954 dloss:0.8665 aloss2:3.6392 exploreP:0.0276\n",
      "Episode:362 meanR:162.8600 R:125.0000 rate:0.2500 aloss:1.3863 dloss:0.8808 aloss2:3.6879 exploreP:0.0274\n",
      "Episode:363 meanR:159.5900 R:173.0000 rate:0.3460 aloss:1.3957 dloss:0.8191 aloss2:3.6907 exploreP:0.0271\n",
      "Episode:364 meanR:159.4300 R:122.0000 rate:0.2440 aloss:1.3964 dloss:0.8885 aloss2:3.7035 exploreP:0.0269\n",
      "Episode:365 meanR:158.5000 R:147.0000 rate:0.2940 aloss:1.4025 dloss:0.8092 aloss2:3.7037 exploreP:0.0266\n",
      "Episode:366 meanR:154.7600 R:126.0000 rate:0.2520 aloss:1.4298 dloss:0.8623 aloss2:3.7024 exploreP:0.0264\n",
      "Episode:367 meanR:154.0000 R:113.0000 rate:0.2260 aloss:1.3961 dloss:0.9703 aloss2:3.6749 exploreP:0.0263\n",
      "Episode:368 meanR:153.8400 R:107.0000 rate:0.2140 aloss:1.4074 dloss:0.8536 aloss2:3.6517 exploreP:0.0261\n",
      "Episode:369 meanR:153.7300 R:133.0000 rate:0.2660 aloss:1.3681 dloss:0.8684 aloss2:3.6967 exploreP:0.0259\n",
      "Episode:370 meanR:153.6900 R:130.0000 rate:0.2600 aloss:1.3756 dloss:0.9624 aloss2:3.6549 exploreP:0.0257\n",
      "Episode:371 meanR:153.6900 R:129.0000 rate:0.2580 aloss:1.4133 dloss:0.8529 aloss2:3.6369 exploreP:0.0255\n",
      "Episode:372 meanR:153.9900 R:151.0000 rate:0.3020 aloss:1.3894 dloss:0.8974 aloss2:3.6492 exploreP:0.0252\n",
      "Episode:373 meanR:155.2500 R:245.0000 rate:0.4900 aloss:1.3813 dloss:0.9064 aloss2:3.6331 exploreP:0.0249\n",
      "Episode:374 meanR:157.3900 R:331.0000 rate:0.6620 aloss:1.3869 dloss:0.9118 aloss2:3.5778 exploreP:0.0244\n",
      "Episode:375 meanR:157.6200 R:148.0000 rate:0.2960 aloss:1.3867 dloss:0.9078 aloss2:3.5613 exploreP:0.0242\n",
      "Episode:376 meanR:158.6000 R:234.0000 rate:0.4680 aloss:1.3914 dloss:0.8826 aloss2:3.5663 exploreP:0.0238\n",
      "Episode:377 meanR:155.3500 R:175.0000 rate:0.3500 aloss:1.3712 dloss:0.9360 aloss2:3.5815 exploreP:0.0236\n",
      "Episode:378 meanR:154.7900 R:161.0000 rate:0.3220 aloss:1.3906 dloss:0.8906 aloss2:3.5629 exploreP:0.0234\n",
      "Episode:379 meanR:154.3200 R:132.0000 rate:0.2640 aloss:1.3842 dloss:0.8516 aloss2:3.5657 exploreP:0.0232\n",
      "Episode:380 meanR:154.9200 R:190.0000 rate:0.3800 aloss:1.4169 dloss:0.8998 aloss2:3.6133 exploreP:0.0230\n",
      "Episode:381 meanR:153.8900 R:172.0000 rate:0.3440 aloss:1.3899 dloss:0.8873 aloss2:3.5721 exploreP:0.0227\n",
      "Episode:382 meanR:153.5800 R:132.0000 rate:0.2640 aloss:1.3871 dloss:0.8851 aloss2:3.5891 exploreP:0.0226\n",
      "Episode:383 meanR:153.6200 R:162.0000 rate:0.3240 aloss:1.3824 dloss:0.8899 aloss2:3.6111 exploreP:0.0224\n",
      "Episode:384 meanR:154.9900 R:259.0000 rate:0.5180 aloss:1.4276 dloss:0.8730 aloss2:3.6171 exploreP:0.0220\n",
      "Episode:385 meanR:155.0400 R:133.0000 rate:0.2660 aloss:1.3865 dloss:0.8247 aloss2:3.6667 exploreP:0.0219\n",
      "Episode:386 meanR:155.3500 R:147.0000 rate:0.2940 aloss:1.3752 dloss:0.9060 aloss2:3.6772 exploreP:0.0217\n",
      "Episode:387 meanR:156.4000 R:225.0000 rate:0.4500 aloss:1.3915 dloss:0.9011 aloss2:3.5897 exploreP:0.0215\n",
      "Episode:388 meanR:156.5500 R:149.0000 rate:0.2980 aloss:1.3925 dloss:0.8886 aloss2:3.6299 exploreP:0.0213\n",
      "Episode:389 meanR:158.0800 R:254.0000 rate:0.5080 aloss:1.3811 dloss:0.9310 aloss2:3.5906 exploreP:0.0210\n",
      "Episode:390 meanR:159.1700 R:232.0000 rate:0.4640 aloss:1.4128 dloss:0.8174 aloss2:3.6079 exploreP:0.0208\n",
      "Episode:391 meanR:159.2300 R:168.0000 rate:0.3360 aloss:1.3653 dloss:0.9306 aloss2:3.6680 exploreP:0.0206\n",
      "Episode:392 meanR:159.3200 R:134.0000 rate:0.2680 aloss:1.3953 dloss:0.8397 aloss2:3.6407 exploreP:0.0204\n",
      "Episode:393 meanR:159.3500 R:132.0000 rate:0.2640 aloss:1.3826 dloss:0.9090 aloss2:3.6292 exploreP:0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:394 meanR:160.2800 R:245.0000 rate:0.4900 aloss:1.3975 dloss:0.8762 aloss2:3.6475 exploreP:0.0200\n",
      "Episode:395 meanR:160.5200 R:148.0000 rate:0.2960 aloss:1.3766 dloss:0.9413 aloss2:3.5882 exploreP:0.0199\n",
      "Episode:396 meanR:160.7600 R:147.0000 rate:0.2940 aloss:1.3927 dloss:0.8840 aloss2:3.5800 exploreP:0.0198\n",
      "Episode:397 meanR:161.3200 R:232.0000 rate:0.4640 aloss:1.3752 dloss:0.9504 aloss2:3.5758 exploreP:0.0195\n",
      "Episode:398 meanR:160.5100 R:242.0000 rate:0.4840 aloss:1.3405 dloss:0.9614 aloss2:3.4913 exploreP:0.0193\n",
      "Episode:399 meanR:161.9900 R:263.0000 rate:0.5260 aloss:1.3852 dloss:0.9366 aloss2:3.4536 exploreP:0.0191\n",
      "Episode:400 meanR:163.5800 R:284.0000 rate:0.5680 aloss:1.3498 dloss:0.9329 aloss2:3.4765 exploreP:0.0188\n",
      "Episode:401 meanR:166.1800 R:386.0000 rate:0.7720 aloss:1.3546 dloss:0.9606 aloss2:3.3952 exploreP:0.0185\n",
      "Episode:402 meanR:168.3400 R:355.0000 rate:0.7100 aloss:1.3727 dloss:0.8785 aloss2:3.4927 exploreP:0.0182\n",
      "Episode:403 meanR:168.6300 R:148.0000 rate:0.2960 aloss:1.3849 dloss:0.9223 aloss2:3.5223 exploreP:0.0181\n",
      "Episode:404 meanR:169.9200 R:256.0000 rate:0.5120 aloss:1.3374 dloss:0.9561 aloss2:3.4663 exploreP:0.0179\n",
      "Episode:405 meanR:172.3900 R:387.0000 rate:0.7740 aloss:1.3361 dloss:0.9548 aloss2:3.3992 exploreP:0.0176\n",
      "Episode:406 meanR:173.7900 R:259.0000 rate:0.5180 aloss:1.3679 dloss:0.9154 aloss2:3.4824 exploreP:0.0174\n",
      "Episode:407 meanR:176.3000 R:380.0000 rate:0.7600 aloss:1.3594 dloss:0.9329 aloss2:3.4340 exploreP:0.0171\n",
      "Episode:408 meanR:178.4400 R:360.0000 rate:0.7200 aloss:1.3502 dloss:0.9008 aloss2:3.4784 exploreP:0.0168\n",
      "Episode:409 meanR:180.9100 R:378.0000 rate:0.7560 aloss:1.3554 dloss:0.9280 aloss2:3.4878 exploreP:0.0166\n",
      "Episode:410 meanR:181.4400 R:266.0000 rate:0.5320 aloss:1.3405 dloss:0.9713 aloss2:3.4639 exploreP:0.0164\n",
      "Episode:411 meanR:184.6800 R:445.0000 rate:0.8900 aloss:1.3415 dloss:0.9349 aloss2:3.4516 exploreP:0.0161\n",
      "Episode:412 meanR:186.8900 R:354.0000 rate:0.7080 aloss:1.3626 dloss:0.9508 aloss2:3.4067 exploreP:0.0159\n",
      "Episode:413 meanR:189.2900 R:360.0000 rate:0.7200 aloss:1.3253 dloss:0.9731 aloss2:3.3348 exploreP:0.0157\n",
      "Episode:414 meanR:192.0900 R:397.0000 rate:0.7940 aloss:1.3349 dloss:0.9596 aloss2:3.3867 exploreP:0.0155\n",
      "Episode:415 meanR:194.5000 R:386.0000 rate:0.7720 aloss:1.3424 dloss:0.9597 aloss2:3.3824 exploreP:0.0153\n",
      "Episode:416 meanR:195.5200 R:372.0000 rate:0.7440 aloss:1.3339 dloss:0.9731 aloss2:3.3149 exploreP:0.0151\n",
      "Episode:417 meanR:198.2000 R:383.0000 rate:0.7660 aloss:1.3404 dloss:0.9700 aloss2:3.3610 exploreP:0.0149\n",
      "Episode:418 meanR:200.6500 R:359.0000 rate:0.7180 aloss:1.3459 dloss:0.9460 aloss2:3.3304 exploreP:0.0147\n",
      "Episode:419 meanR:203.3300 R:389.0000 rate:0.7780 aloss:1.3384 dloss:0.9391 aloss2:3.4055 exploreP:0.0145\n",
      "Episode:420 meanR:205.6200 R:351.0000 rate:0.7020 aloss:1.3280 dloss:0.9821 aloss2:3.3298 exploreP:0.0144\n",
      "Episode:421 meanR:208.0700 R:362.0000 rate:0.7240 aloss:1.3276 dloss:0.9654 aloss2:3.3426 exploreP:0.0142\n",
      "Episode:422 meanR:210.6700 R:396.0000 rate:0.7920 aloss:1.3300 dloss:0.9885 aloss2:3.3197 exploreP:0.0141\n",
      "Episode:423 meanR:210.9300 R:396.0000 rate:0.7920 aloss:1.3210 dloss:1.0004 aloss2:3.2489 exploreP:0.0139\n",
      "Episode:424 meanR:213.2600 R:354.0000 rate:0.7080 aloss:1.3381 dloss:0.9493 aloss2:3.2879 exploreP:0.0138\n",
      "Episode:425 meanR:214.7400 R:500.0000 rate:1.0000 aloss:1.3182 dloss:0.9917 aloss2:3.3202 exploreP:0.0136\n",
      "Episode:426 meanR:215.6900 R:375.0000 rate:0.7500 aloss:1.2993 dloss:1.0244 aloss2:3.1664 exploreP:0.0135\n",
      "Episode:427 meanR:218.0200 R:399.0000 rate:0.7980 aloss:1.3286 dloss:0.9602 aloss2:3.2900 exploreP:0.0133\n",
      "Episode:428 meanR:221.8700 R:500.0000 rate:1.0000 aloss:1.3114 dloss:1.0355 aloss2:3.1869 exploreP:0.0132\n",
      "Episode:429 meanR:224.4000 R:395.0000 rate:0.7900 aloss:1.3132 dloss:1.0175 aloss2:3.1733 exploreP:0.0130\n",
      "Episode:430 meanR:227.1500 R:392.0000 rate:0.7840 aloss:1.3177 dloss:1.0297 aloss2:3.1349 exploreP:0.0129\n",
      "Episode:431 meanR:230.1000 R:433.0000 rate:0.8660 aloss:1.3087 dloss:1.0018 aloss2:3.1423 exploreP:0.0128\n",
      "Episode:432 meanR:232.4200 R:378.0000 rate:0.7560 aloss:1.2971 dloss:1.0618 aloss2:3.1227 exploreP:0.0127\n",
      "Episode:433 meanR:234.7900 R:366.0000 rate:0.7320 aloss:1.2994 dloss:1.0474 aloss2:3.0588 exploreP:0.0126\n",
      "Episode:434 meanR:236.9600 R:347.0000 rate:0.6940 aloss:1.3109 dloss:1.0154 aloss2:3.1137 exploreP:0.0125\n",
      "Episode:435 meanR:239.3300 R:359.0000 rate:0.7180 aloss:1.3053 dloss:1.0219 aloss2:3.1000 exploreP:0.0124\n",
      "Episode:436 meanR:241.7800 R:377.0000 rate:0.7540 aloss:1.2836 dloss:1.0616 aloss2:3.0637 exploreP:0.0123\n",
      "Episode:437 meanR:244.1500 R:368.0000 rate:0.7360 aloss:1.3034 dloss:1.0334 aloss2:3.0738 exploreP:0.0122\n",
      "Episode:438 meanR:246.5900 R:411.0000 rate:0.8220 aloss:1.2828 dloss:1.0798 aloss2:3.0058 exploreP:0.0122\n",
      "Episode:439 meanR:249.1900 R:405.0000 rate:0.8100 aloss:1.2991 dloss:1.0035 aloss2:3.0809 exploreP:0.0121\n",
      "Episode:440 meanR:251.4000 R:351.0000 rate:0.7020 aloss:1.3053 dloss:1.0718 aloss2:3.0837 exploreP:0.0120\n",
      "Episode:441 meanR:253.5700 R:356.0000 rate:0.7120 aloss:1.2790 dloss:1.0622 aloss2:3.0173 exploreP:0.0119\n",
      "Episode:442 meanR:256.1000 R:388.0000 rate:0.7760 aloss:1.2852 dloss:1.0487 aloss2:2.9837 exploreP:0.0119\n",
      "Episode:443 meanR:258.9900 R:416.0000 rate:0.8320 aloss:1.2865 dloss:1.0894 aloss2:2.9906 exploreP:0.0118\n",
      "Episode:444 meanR:261.0400 R:415.0000 rate:0.8300 aloss:1.2753 dloss:1.0518 aloss2:2.9559 exploreP:0.0117\n",
      "Episode:445 meanR:263.2900 R:357.0000 rate:0.7140 aloss:1.2862 dloss:1.0611 aloss2:3.0098 exploreP:0.0116\n",
      "Episode:446 meanR:264.0300 R:172.0000 rate:0.3440 aloss:1.2838 dloss:1.0438 aloss2:3.0312 exploreP:0.0116\n",
      "Episode:447 meanR:264.5300 R:375.0000 rate:0.7500 aloss:1.2746 dloss:1.0811 aloss2:2.9592 exploreP:0.0116\n",
      "Episode:448 meanR:267.2400 R:430.0000 rate:0.8600 aloss:1.2784 dloss:1.0517 aloss2:2.9928 exploreP:0.0115\n",
      "Episode:449 meanR:269.6900 R:368.0000 rate:0.7360 aloss:1.2723 dloss:1.0653 aloss2:2.9824 exploreP:0.0114\n",
      "Episode:450 meanR:272.0100 R:363.0000 rate:0.7260 aloss:1.2868 dloss:1.0631 aloss2:3.0076 exploreP:0.0114\n",
      "Episode:451 meanR:275.8100 R:493.0000 rate:0.9860 aloss:1.2729 dloss:1.0800 aloss2:2.9627 exploreP:0.0113\n",
      "Episode:452 meanR:278.2200 R:369.0000 rate:0.7380 aloss:1.2711 dloss:1.0630 aloss2:2.9530 exploreP:0.0113\n",
      "Episode:453 meanR:280.2200 R:350.0000 rate:0.7000 aloss:1.2727 dloss:1.0723 aloss2:2.9555 exploreP:0.0112\n",
      "Episode:454 meanR:282.3600 R:379.0000 rate:0.7580 aloss:1.2732 dloss:1.0863 aloss2:2.9340 exploreP:0.0112\n",
      "Episode:455 meanR:284.9000 R:373.0000 rate:0.7460 aloss:1.2631 dloss:1.0691 aloss2:2.9474 exploreP:0.0111\n",
      "Episode:456 meanR:287.6000 R:417.0000 rate:0.8340 aloss:1.2907 dloss:1.0558 aloss2:2.9881 exploreP:0.0111\n",
      "Episode:457 meanR:289.7200 R:368.0000 rate:0.7360 aloss:1.2608 dloss:1.0967 aloss2:2.9206 exploreP:0.0111\n",
      "Episode:458 meanR:292.4300 R:403.0000 rate:0.8060 aloss:1.2670 dloss:1.0850 aloss2:2.9208 exploreP:0.0110\n",
      "Episode:459 meanR:294.5100 R:378.0000 rate:0.7560 aloss:1.2519 dloss:1.1066 aloss2:2.8808 exploreP:0.0110\n",
      "Episode:460 meanR:294.6000 R:375.0000 rate:0.7500 aloss:1.2520 dloss:1.0822 aloss2:2.8753 exploreP:0.0109\n",
      "Episode:461 meanR:294.7100 R:159.0000 rate:0.3180 aloss:1.2620 dloss:1.0582 aloss2:2.9295 exploreP:0.0109\n",
      "Episode:462 meanR:297.0100 R:355.0000 rate:0.7100 aloss:1.2532 dloss:1.1181 aloss2:2.8731 exploreP:0.0109\n",
      "Episode:463 meanR:299.2300 R:395.0000 rate:0.7900 aloss:1.2471 dloss:1.0861 aloss2:2.8583 exploreP:0.0109\n",
      "Episode:464 meanR:301.9800 R:397.0000 rate:0.7940 aloss:1.2604 dloss:1.0852 aloss2:2.9080 exploreP:0.0108\n",
      "Episode:465 meanR:304.2100 R:370.0000 rate:0.7400 aloss:1.2453 dloss:1.0965 aloss2:2.9016 exploreP:0.0108\n",
      "Episode:466 meanR:306.8000 R:385.0000 rate:0.7700 aloss:1.2645 dloss:1.0638 aloss2:2.8957 exploreP:0.0108\n",
      "Episode:467 meanR:310.0100 R:434.0000 rate:0.8680 aloss:1.2499 dloss:1.0767 aloss2:2.9216 exploreP:0.0107\n",
      "Episode:468 meanR:313.9400 R:500.0000 rate:1.0000 aloss:1.2223 dloss:1.1329 aloss2:2.8158 exploreP:0.0107\n",
      "Episode:469 meanR:316.6200 R:401.0000 rate:0.8020 aloss:1.2376 dloss:1.1224 aloss2:2.8264 exploreP:0.0107\n",
      "Episode:470 meanR:319.9400 R:462.0000 rate:0.9240 aloss:1.2218 dloss:1.1524 aloss2:2.7380 exploreP:0.0106\n",
      "Episode:471 meanR:323.0700 R:442.0000 rate:0.8840 aloss:1.2400 dloss:1.0890 aloss2:2.7967 exploreP:0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:472 meanR:326.5600 R:500.0000 rate:1.0000 aloss:1.2124 dloss:1.1571 aloss2:2.7083 exploreP:0.0106\n",
      "Episode:473 meanR:329.1100 R:500.0000 rate:1.0000 aloss:1.2340 dloss:1.1236 aloss2:2.7471 exploreP:0.0106\n",
      "Episode:474 meanR:329.8500 R:405.0000 rate:0.8100 aloss:1.2287 dloss:1.1406 aloss2:2.7279 exploreP:0.0105\n",
      "Episode:475 meanR:332.7500 R:438.0000 rate:0.8760 aloss:1.2168 dloss:1.1461 aloss2:2.7242 exploreP:0.0105\n",
      "Episode:476 meanR:335.4100 R:500.0000 rate:1.0000 aloss:1.2259 dloss:1.1442 aloss2:2.6641 exploreP:0.0105\n",
      "Episode:477 meanR:338.6600 R:500.0000 rate:1.0000 aloss:1.2096 dloss:1.1460 aloss2:2.6882 exploreP:0.0105\n",
      "Episode:478 meanR:341.6700 R:462.0000 rate:0.9240 aloss:1.2190 dloss:1.1614 aloss2:2.6618 exploreP:0.0104\n",
      "Episode:479 meanR:345.3500 R:500.0000 rate:1.0000 aloss:1.2187 dloss:1.1394 aloss2:2.6591 exploreP:0.0104\n",
      "Episode:480 meanR:348.4500 R:500.0000 rate:1.0000 aloss:1.2317 dloss:1.1318 aloss2:2.7198 exploreP:0.0104\n",
      "Episode:481 meanR:351.7300 R:500.0000 rate:1.0000 aloss:1.2002 dloss:1.1732 aloss2:2.6335 exploreP:0.0104\n",
      "Episode:482 meanR:355.4100 R:500.0000 rate:1.0000 aloss:1.2082 dloss:1.1814 aloss2:2.6062 exploreP:0.0104\n",
      "Episode:483 meanR:358.7900 R:500.0000 rate:1.0000 aloss:1.1900 dloss:1.1795 aloss2:2.5426 exploreP:0.0103\n",
      "Episode:484 meanR:361.2000 R:500.0000 rate:1.0000 aloss:1.2261 dloss:1.1504 aloss2:2.6025 exploreP:0.0103\n",
      "Episode:485 meanR:364.8700 R:500.0000 rate:1.0000 aloss:1.2010 dloss:1.1616 aloss2:2.6096 exploreP:0.0103\n",
      "Episode:486 meanR:368.4000 R:500.0000 rate:1.0000 aloss:1.2153 dloss:1.1526 aloss2:2.6444 exploreP:0.0103\n",
      "Episode:487 meanR:371.1500 R:500.0000 rate:1.0000 aloss:1.2062 dloss:1.1625 aloss2:2.6245 exploreP:0.0103\n",
      "Episode:488 meanR:374.6600 R:500.0000 rate:1.0000 aloss:1.2175 dloss:1.1494 aloss2:2.6418 exploreP:0.0103\n",
      "Episode:489 meanR:377.1200 R:500.0000 rate:1.0000 aloss:1.1910 dloss:1.1756 aloss2:2.5962 exploreP:0.0103\n",
      "Episode:490 meanR:379.8000 R:500.0000 rate:1.0000 aloss:1.2002 dloss:1.1919 aloss2:2.5564 exploreP:0.0102\n",
      "Episode:491 meanR:383.1200 R:500.0000 rate:1.0000 aloss:1.1939 dloss:1.1797 aloss2:2.5348 exploreP:0.0102\n",
      "Episode:492 meanR:386.7800 R:500.0000 rate:1.0000 aloss:1.1962 dloss:1.2021 aloss2:2.4945 exploreP:0.0102\n",
      "Episode:493 meanR:390.4600 R:500.0000 rate:1.0000 aloss:1.1832 dloss:1.1894 aloss2:2.4678 exploreP:0.0102\n",
      "Episode:494 meanR:393.0100 R:500.0000 rate:1.0000 aloss:1.1926 dloss:1.1983 aloss2:2.4986 exploreP:0.0102\n",
      "Episode:495 meanR:396.5300 R:500.0000 rate:1.0000 aloss:1.1840 dloss:1.1973 aloss2:2.4761 exploreP:0.0102\n",
      "Episode:496 meanR:400.0600 R:500.0000 rate:1.0000 aloss:1.1970 dloss:1.1905 aloss2:2.4881 exploreP:0.0102\n",
      "Episode:497 meanR:402.7400 R:500.0000 rate:1.0000 aloss:1.1984 dloss:1.1739 aloss2:2.5390 exploreP:0.0102\n",
      "Episode:498 meanR:405.3200 R:500.0000 rate:1.0000 aloss:1.1767 dloss:1.2308 aloss2:2.4302 exploreP:0.0102\n",
      "Episode:499 meanR:407.6800 R:499.0000 rate:0.9980 aloss:1.1664 dloss:1.2158 aloss2:2.3952 exploreP:0.0102\n",
      "Episode:500 meanR:409.8400 R:500.0000 rate:1.0000 aloss:1.1708 dloss:1.2446 aloss2:2.3313 exploreP:0.0101\n",
      "Episode:501 meanR:410.9800 R:500.0000 rate:1.0000 aloss:1.1720 dloss:1.2155 aloss2:2.3562 exploreP:0.0101\n",
      "Episode:502 meanR:412.4300 R:500.0000 rate:1.0000 aloss:1.1771 dloss:1.2297 aloss2:2.3537 exploreP:0.0101\n",
      "Episode:503 meanR:415.9500 R:500.0000 rate:1.0000 aloss:1.1667 dloss:1.2361 aloss2:2.3399 exploreP:0.0101\n",
      "Episode:504 meanR:418.3900 R:500.0000 rate:1.0000 aloss:1.1801 dloss:1.2217 aloss2:2.3385 exploreP:0.0101\n",
      "Episode:505 meanR:419.5200 R:500.0000 rate:1.0000 aloss:1.1729 dloss:1.2218 aloss2:2.3799 exploreP:0.0101\n",
      "Episode:506 meanR:421.9300 R:500.0000 rate:1.0000 aloss:1.1706 dloss:1.2426 aloss2:2.3368 exploreP:0.0101\n",
      "Episode:507 meanR:423.1300 R:500.0000 rate:1.0000 aloss:1.1803 dloss:1.2131 aloss2:2.3601 exploreP:0.0101\n",
      "Episode:508 meanR:424.5300 R:500.0000 rate:1.0000 aloss:1.1641 dloss:1.2477 aloss2:2.3114 exploreP:0.0101\n",
      "Episode:509 meanR:425.7500 R:500.0000 rate:1.0000 aloss:1.1597 dloss:1.2351 aloss2:2.3045 exploreP:0.0101\n",
      "Episode:510 meanR:428.0900 R:500.0000 rate:1.0000 aloss:1.1646 dloss:1.2552 aloss2:2.2698 exploreP:0.0101\n",
      "Episode:511 meanR:428.6400 R:500.0000 rate:1.0000 aloss:1.1544 dloss:1.2506 aloss2:2.2603 exploreP:0.0101\n",
      "Episode:512 meanR:430.1000 R:500.0000 rate:1.0000 aloss:1.1665 dloss:1.2427 aloss2:2.2781 exploreP:0.0101\n",
      "Episode:513 meanR:431.5000 R:500.0000 rate:1.0000 aloss:1.1457 dloss:1.2488 aloss2:2.2594 exploreP:0.0101\n",
      "Episode:514 meanR:432.5300 R:500.0000 rate:1.0000 aloss:1.1605 dloss:1.2679 aloss2:2.2219 exploreP:0.0101\n",
      "Episode:515 meanR:433.6700 R:500.0000 rate:1.0000 aloss:1.1440 dloss:1.2792 aloss2:2.1774 exploreP:0.0101\n",
      "Episode:516 meanR:434.6800 R:473.0000 rate:0.9460 aloss:1.1517 dloss:1.2879 aloss2:2.1506 exploreP:0.0101\n",
      "Episode:517 meanR:435.8500 R:500.0000 rate:1.0000 aloss:1.1488 dloss:1.2751 aloss2:2.1252 exploreP:0.0101\n",
      "Episode:518 meanR:437.2600 R:500.0000 rate:1.0000 aloss:1.1354 dloss:1.2908 aloss2:2.1202 exploreP:0.0101\n",
      "Episode:519 meanR:438.3700 R:500.0000 rate:1.0000 aloss:1.1384 dloss:1.2767 aloss2:2.1252 exploreP:0.0101\n",
      "Episode:520 meanR:439.8600 R:500.0000 rate:1.0000 aloss:1.1517 dloss:1.2847 aloss2:2.1261 exploreP:0.0101\n",
      "Episode:521 meanR:441.2400 R:500.0000 rate:1.0000 aloss:1.1326 dloss:1.2885 aloss2:2.0823 exploreP:0.0101\n",
      "Episode:522 meanR:442.2800 R:500.0000 rate:1.0000 aloss:1.1280 dloss:1.3172 aloss2:2.0288 exploreP:0.0100\n",
      "Episode:523 meanR:443.3200 R:500.0000 rate:1.0000 aloss:1.1306 dloss:1.2831 aloss2:2.0562 exploreP:0.0100\n",
      "Episode:524 meanR:444.7300 R:495.0000 rate:0.9900 aloss:1.1322 dloss:1.2984 aloss2:2.0803 exploreP:0.0100\n",
      "Episode:525 meanR:444.7300 R:500.0000 rate:1.0000 aloss:1.1222 dloss:1.3029 aloss2:2.0322 exploreP:0.0100\n",
      "Episode:526 meanR:445.9800 R:500.0000 rate:1.0000 aloss:1.1122 dloss:1.3291 aloss2:1.9674 exploreP:0.0100\n",
      "Episode:527 meanR:446.9900 R:500.0000 rate:1.0000 aloss:1.1311 dloss:1.3124 aloss2:1.9662 exploreP:0.0100\n",
      "Episode:528 meanR:446.9900 R:500.0000 rate:1.0000 aloss:1.1283 dloss:1.3177 aloss2:1.9695 exploreP:0.0100\n",
      "Episode:529 meanR:447.6800 R:464.0000 rate:0.9280 aloss:1.1227 dloss:1.3097 aloss2:1.9777 exploreP:0.0100\n",
      "Episode:530 meanR:448.7600 R:500.0000 rate:1.0000 aloss:1.1199 dloss:1.3270 aloss2:1.9595 exploreP:0.0100\n",
      "Episode:531 meanR:449.4300 R:500.0000 rate:1.0000 aloss:1.1079 dloss:1.3120 aloss2:1.9542 exploreP:0.0100\n",
      "Episode:532 meanR:449.8700 R:422.0000 rate:0.8440 aloss:1.1175 dloss:1.3264 aloss2:1.9515 exploreP:0.0100\n",
      "Episode:533 meanR:451.2100 R:500.0000 rate:1.0000 aloss:1.1024 dloss:1.3311 aloss2:1.9038 exploreP:0.0100\n",
      "Episode:534 meanR:452.1300 R:439.0000 rate:0.8780 aloss:1.1099 dloss:1.3225 aloss2:1.9240 exploreP:0.0100\n",
      "Episode:535 meanR:453.5400 R:500.0000 rate:1.0000 aloss:1.1017 dloss:1.3360 aloss2:1.8776 exploreP:0.0100\n",
      "Episode:536 meanR:453.7400 R:397.0000 rate:0.7940 aloss:1.1023 dloss:1.3325 aloss2:1.8797 exploreP:0.0100\n",
      "Episode:537 meanR:454.7500 R:469.0000 rate:0.9380 aloss:1.1023 dloss:1.3378 aloss2:1.8731 exploreP:0.0100\n",
      "Episode:538 meanR:455.6400 R:500.0000 rate:1.0000 aloss:1.0931 dloss:1.3317 aloss2:1.8604 exploreP:0.0100\n",
      "Episode:539 meanR:456.5900 R:500.0000 rate:1.0000 aloss:1.0979 dloss:1.3404 aloss2:1.8385 exploreP:0.0100\n",
      "Episode:540 meanR:457.2300 R:415.0000 rate:0.8300 aloss:1.0975 dloss:1.3297 aloss2:1.8651 exploreP:0.0100\n",
      "Episode:541 meanR:457.5700 R:390.0000 rate:0.7800 aloss:1.0900 dloss:1.3512 aloss2:1.8297 exploreP:0.0100\n",
      "Episode:542 meanR:457.5500 R:386.0000 rate:0.7720 aloss:1.0847 dloss:1.3336 aloss2:1.8250 exploreP:0.0100\n",
      "Episode:543 meanR:458.3900 R:500.0000 rate:1.0000 aloss:1.0940 dloss:1.3415 aloss2:1.8349 exploreP:0.0100\n",
      "Episode:544 meanR:459.2400 R:500.0000 rate:1.0000 aloss:1.0840 dloss:1.3369 aloss2:1.8237 exploreP:0.0100\n",
      "Episode:545 meanR:460.6700 R:500.0000 rate:1.0000 aloss:1.0911 dloss:1.3385 aloss2:1.8457 exploreP:0.0100\n",
      "Episode:546 meanR:463.2600 R:431.0000 rate:0.8620 aloss:1.0857 dloss:1.3402 aloss2:1.8156 exploreP:0.0100\n",
      "Episode:547 meanR:464.5100 R:500.0000 rate:1.0000 aloss:1.0887 dloss:1.3324 aloss2:1.8503 exploreP:0.0100\n",
      "Episode:548 meanR:464.2600 R:405.0000 rate:0.8100 aloss:1.0786 dloss:1.3429 aloss2:1.8088 exploreP:0.0100\n",
      "Episode:549 meanR:465.5800 R:500.0000 rate:1.0000 aloss:1.0864 dloss:1.3396 aloss2:1.8167 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:550 meanR:466.9500 R:500.0000 rate:1.0000 aloss:1.0794 dloss:1.3412 aloss2:1.7942 exploreP:0.0100\n",
      "Episode:551 meanR:466.6300 R:461.0000 rate:0.9220 aloss:1.0809 dloss:1.3280 aloss2:1.8327 exploreP:0.0100\n",
      "Episode:552 meanR:467.9400 R:500.0000 rate:1.0000 aloss:1.0818 dloss:1.3340 aloss2:1.8418 exploreP:0.0100\n",
      "Episode:553 meanR:469.3300 R:489.0000 rate:0.9780 aloss:1.0786 dloss:1.3239 aloss2:1.8868 exploreP:0.0100\n",
      "Episode:554 meanR:469.7600 R:422.0000 rate:0.8440 aloss:1.0766 dloss:1.3440 aloss2:1.8185 exploreP:0.0100\n",
      "Episode:555 meanR:469.8300 R:380.0000 rate:0.7600 aloss:1.0661 dloss:1.3325 aloss2:1.7988 exploreP:0.0100\n",
      "Episode:556 meanR:469.3600 R:370.0000 rate:0.7400 aloss:1.0788 dloss:1.3310 aloss2:1.8504 exploreP:0.0100\n",
      "Episode:557 meanR:470.2700 R:459.0000 rate:0.9180 aloss:1.0734 dloss:1.3341 aloss2:1.8251 exploreP:0.0100\n",
      "Episode:558 meanR:470.1500 R:391.0000 rate:0.7820 aloss:1.0730 dloss:1.3336 aloss2:1.8337 exploreP:0.0100\n",
      "Episode:559 meanR:470.6800 R:431.0000 rate:0.8620 aloss:1.0754 dloss:1.3371 aloss2:1.8113 exploreP:0.0100\n",
      "Episode:560 meanR:471.5200 R:459.0000 rate:0.9180 aloss:1.0686 dloss:1.3233 aloss2:1.8420 exploreP:0.0100\n",
      "Episode:561 meanR:472.7900 R:286.0000 rate:0.5720 aloss:1.0676 dloss:1.3316 aloss2:1.8459 exploreP:0.0100\n",
      "Episode:562 meanR:473.0600 R:382.0000 rate:0.7640 aloss:1.0688 dloss:1.3308 aloss2:1.8338 exploreP:0.0100\n",
      "Episode:563 meanR:472.6000 R:349.0000 rate:0.6980 aloss:1.0667 dloss:1.3180 aloss2:1.8857 exploreP:0.0100\n",
      "Episode:564 meanR:472.5200 R:389.0000 rate:0.7780 aloss:1.0709 dloss:1.3364 aloss2:1.8445 exploreP:0.0100\n",
      "Episode:565 meanR:473.1000 R:428.0000 rate:0.8560 aloss:1.0635 dloss:1.3262 aloss2:1.8186 exploreP:0.0100\n",
      "Episode:566 meanR:473.0700 R:382.0000 rate:0.7640 aloss:1.0695 dloss:1.3235 aloss2:1.8772 exploreP:0.0100\n",
      "Episode:567 meanR:471.6100 R:288.0000 rate:0.5760 aloss:1.0637 dloss:1.3362 aloss2:1.8296 exploreP:0.0100\n",
      "Episode:568 meanR:470.6900 R:408.0000 rate:0.8160 aloss:1.0607 dloss:1.3208 aloss2:1.8311 exploreP:0.0100\n",
      "Episode:569 meanR:470.6400 R:396.0000 rate:0.7920 aloss:1.0623 dloss:1.3260 aloss2:1.8718 exploreP:0.0100\n",
      "Episode:570 meanR:471.0200 R:500.0000 rate:1.0000 aloss:1.0575 dloss:1.3256 aloss2:1.8256 exploreP:0.0100\n",
      "Episode:571 meanR:470.2300 R:363.0000 rate:0.7260 aloss:1.0658 dloss:1.3186 aloss2:1.9019 exploreP:0.0100\n",
      "Episode:572 meanR:469.1100 R:388.0000 rate:0.7760 aloss:1.0648 dloss:1.3271 aloss2:1.8444 exploreP:0.0100\n",
      "Episode:573 meanR:468.4400 R:433.0000 rate:0.8660 aloss:1.0607 dloss:1.3167 aloss2:1.8651 exploreP:0.0100\n",
      "Episode:574 meanR:468.7500 R:436.0000 rate:0.8720 aloss:1.0641 dloss:1.3246 aloss2:1.8667 exploreP:0.0100\n",
      "Episode:575 meanR:468.2500 R:388.0000 rate:0.7760 aloss:1.0644 dloss:1.3175 aloss2:1.8681 exploreP:0.0100\n",
      "Episode:576 meanR:467.0100 R:376.0000 rate:0.7520 aloss:1.0631 dloss:1.3219 aloss2:1.8752 exploreP:0.0100\n",
      "Episode:577 meanR:465.8300 R:382.0000 rate:0.7640 aloss:1.0585 dloss:1.3193 aloss2:1.8534 exploreP:0.0100\n",
      "Episode:578 meanR:465.3700 R:416.0000 rate:0.8320 aloss:1.0595 dloss:1.3169 aloss2:1.8871 exploreP:0.0100\n",
      "Episode:579 meanR:464.3100 R:394.0000 rate:0.7880 aloss:1.0602 dloss:1.3207 aloss2:1.8696 exploreP:0.0100\n",
      "Episode:580 meanR:463.6400 R:433.0000 rate:0.8660 aloss:1.0566 dloss:1.3217 aloss2:1.8343 exploreP:0.0100\n",
      "Episode:581 meanR:462.3800 R:374.0000 rate:0.7480 aloss:1.0607 dloss:1.3190 aloss2:1.8834 exploreP:0.0100\n",
      "Episode:582 meanR:461.1300 R:375.0000 rate:0.7500 aloss:1.0542 dloss:1.3232 aloss2:1.8407 exploreP:0.0100\n",
      "Episode:583 meanR:459.9500 R:382.0000 rate:0.7640 aloss:1.0599 dloss:1.3096 aloss2:1.8893 exploreP:0.0100\n",
      "Episode:584 meanR:459.2000 R:425.0000 rate:0.8500 aloss:1.0586 dloss:1.3189 aloss2:1.8878 exploreP:0.0100\n",
      "Episode:585 meanR:458.8500 R:465.0000 rate:0.9300 aloss:1.0590 dloss:1.3123 aloss2:1.8936 exploreP:0.0100\n",
      "Episode:586 meanR:457.6800 R:383.0000 rate:0.7660 aloss:1.0596 dloss:1.3163 aloss2:1.8939 exploreP:0.0100\n",
      "Episode:587 meanR:456.6400 R:396.0000 rate:0.7920 aloss:1.0573 dloss:1.3146 aloss2:1.8783 exploreP:0.0100\n",
      "Episode:588 meanR:455.2500 R:361.0000 rate:0.7220 aloss:1.0540 dloss:1.3139 aloss2:1.8836 exploreP:0.0100\n",
      "Episode:589 meanR:453.9300 R:368.0000 rate:0.7360 aloss:1.0565 dloss:1.3168 aloss2:1.8747 exploreP:0.0100\n",
      "Episode:590 meanR:453.0200 R:409.0000 rate:0.8180 aloss:1.0528 dloss:1.3190 aloss2:1.8625 exploreP:0.0100\n",
      "Episode:591 meanR:452.4800 R:446.0000 rate:0.8920 aloss:1.0536 dloss:1.3145 aloss2:1.8763 exploreP:0.0100\n",
      "Episode:592 meanR:451.3200 R:384.0000 rate:0.7680 aloss:1.0551 dloss:1.3151 aloss2:1.8551 exploreP:0.0100\n",
      "Episode:593 meanR:450.2600 R:394.0000 rate:0.7880 aloss:1.0555 dloss:1.3115 aloss2:1.8841 exploreP:0.0100\n",
      "Episode:594 meanR:449.0900 R:383.0000 rate:0.7660 aloss:1.0507 dloss:1.3229 aloss2:1.8486 exploreP:0.0100\n",
      "Episode:595 meanR:449.0900 R:500.0000 rate:1.0000 aloss:1.0515 dloss:1.3134 aloss2:1.8438 exploreP:0.0100\n",
      "Episode:596 meanR:447.8000 R:371.0000 rate:0.7420 aloss:1.0526 dloss:1.3199 aloss2:1.8547 exploreP:0.0100\n",
      "Episode:597 meanR:446.3300 R:353.0000 rate:0.7060 aloss:1.0526 dloss:1.3157 aloss2:1.8324 exploreP:0.0100\n",
      "Episode:598 meanR:445.6400 R:431.0000 rate:0.8620 aloss:1.0567 dloss:1.3117 aloss2:1.8684 exploreP:0.0100\n",
      "Episode:599 meanR:444.5400 R:389.0000 rate:0.7780 aloss:1.0530 dloss:1.3214 aloss2:1.8557 exploreP:0.0100\n",
      "Episode:600 meanR:442.3100 R:277.0000 rate:0.5540 aloss:1.0504 dloss:1.3169 aloss2:1.8259 exploreP:0.0100\n",
      "Episode:601 meanR:441.6400 R:433.0000 rate:0.8660 aloss:1.0526 dloss:1.3177 aloss2:1.8413 exploreP:0.0100\n",
      "Episode:602 meanR:440.1200 R:348.0000 rate:0.6960 aloss:1.0518 dloss:1.3177 aloss2:1.8066 exploreP:0.0100\n",
      "Episode:603 meanR:438.6700 R:355.0000 rate:0.7100 aloss:1.0525 dloss:1.3176 aloss2:1.8270 exploreP:0.0100\n",
      "Episode:604 meanR:437.5700 R:390.0000 rate:0.7800 aloss:1.0541 dloss:1.3179 aloss2:1.8264 exploreP:0.0100\n",
      "Episode:605 meanR:436.6300 R:406.0000 rate:0.8120 aloss:1.0474 dloss:1.3146 aloss2:1.8123 exploreP:0.0100\n",
      "Episode:606 meanR:435.4000 R:377.0000 rate:0.7540 aloss:1.0545 dloss:1.3141 aloss2:1.8536 exploreP:0.0100\n",
      "Episode:607 meanR:434.1600 R:376.0000 rate:0.7520 aloss:1.0480 dloss:1.3224 aloss2:1.7974 exploreP:0.0100\n",
      "Episode:608 meanR:432.9100 R:375.0000 rate:0.7500 aloss:1.0457 dloss:1.3189 aloss2:1.7893 exploreP:0.0100\n",
      "Episode:609 meanR:431.0900 R:318.0000 rate:0.6360 aloss:1.0465 dloss:1.3174 aloss2:1.8006 exploreP:0.0100\n",
      "Episode:610 meanR:429.6800 R:359.0000 rate:0.7180 aloss:1.0443 dloss:1.3182 aloss2:1.7843 exploreP:0.0100\n",
      "Episode:611 meanR:428.4800 R:380.0000 rate:0.7600 aloss:1.0478 dloss:1.3154 aloss2:1.8064 exploreP:0.0100\n",
      "Episode:612 meanR:427.1600 R:368.0000 rate:0.7360 aloss:1.0434 dloss:1.3184 aloss2:1.7863 exploreP:0.0100\n",
      "Episode:613 meanR:426.2800 R:412.0000 rate:0.8240 aloss:1.0469 dloss:1.3151 aloss2:1.7940 exploreP:0.0100\n",
      "Episode:614 meanR:424.9500 R:367.0000 rate:0.7340 aloss:1.0502 dloss:1.3125 aloss2:1.8194 exploreP:0.0100\n",
      "Episode:615 meanR:423.5700 R:362.0000 rate:0.7240 aloss:1.0453 dloss:1.3172 aloss2:1.7892 exploreP:0.0100\n",
      "Episode:616 meanR:422.4300 R:359.0000 rate:0.7180 aloss:1.0436 dloss:1.3118 aloss2:1.8033 exploreP:0.0100\n",
      "Episode:617 meanR:421.3300 R:390.0000 rate:0.7800 aloss:1.0445 dloss:1.3156 aloss2:1.7992 exploreP:0.0100\n",
      "Episode:618 meanR:420.0700 R:374.0000 rate:0.7480 aloss:1.0436 dloss:1.3126 aloss2:1.7828 exploreP:0.0100\n",
      "Episode:619 meanR:418.6800 R:361.0000 rate:0.7220 aloss:1.0418 dloss:1.3146 aloss2:1.7676 exploreP:0.0100\n",
      "Episode:620 meanR:417.4500 R:377.0000 rate:0.7540 aloss:1.0427 dloss:1.3140 aloss2:1.7612 exploreP:0.0100\n",
      "Episode:621 meanR:416.9500 R:450.0000 rate:0.9000 aloss:1.0457 dloss:1.3106 aloss2:1.7859 exploreP:0.0100\n",
      "Episode:622 meanR:415.6100 R:366.0000 rate:0.7320 aloss:1.0475 dloss:1.3116 aloss2:1.7922 exploreP:0.0100\n",
      "Episode:623 meanR:414.3200 R:371.0000 rate:0.7420 aloss:1.0417 dloss:1.3095 aloss2:1.7560 exploreP:0.0100\n",
      "Episode:624 meanR:413.2900 R:392.0000 rate:0.7840 aloss:1.0474 dloss:1.3084 aloss2:1.7966 exploreP:0.0100\n",
      "Episode:625 meanR:411.8800 R:359.0000 rate:0.7180 aloss:1.0448 dloss:1.3072 aloss2:1.7763 exploreP:0.0100\n",
      "Episode:626 meanR:410.6100 R:373.0000 rate:0.7460 aloss:1.0442 dloss:1.3073 aloss2:1.7721 exploreP:0.0100\n",
      "Episode:627 meanR:409.7400 R:413.0000 rate:0.8260 aloss:1.0428 dloss:1.3020 aloss2:1.7922 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:628 meanR:408.5500 R:381.0000 rate:0.7620 aloss:1.0419 dloss:1.3009 aloss2:1.7970 exploreP:0.0100\n",
      "Episode:629 meanR:407.5600 R:365.0000 rate:0.7300 aloss:1.0413 dloss:1.3029 aloss2:1.7788 exploreP:0.0100\n",
      "Episode:630 meanR:406.4100 R:385.0000 rate:0.7700 aloss:1.0409 dloss:1.2977 aloss2:1.7792 exploreP:0.0100\n",
      "Episode:631 meanR:405.5900 R:418.0000 rate:0.8360 aloss:1.0413 dloss:1.2982 aloss2:1.7776 exploreP:0.0100\n",
      "Episode:632 meanR:405.1700 R:380.0000 rate:0.7600 aloss:1.0409 dloss:1.2975 aloss2:1.7646 exploreP:0.0100\n",
      "Episode:633 meanR:404.2600 R:409.0000 rate:0.8180 aloss:1.0399 dloss:1.2959 aloss2:1.7677 exploreP:0.0100\n",
      "Episode:634 meanR:404.2400 R:437.0000 rate:0.8740 aloss:1.0393 dloss:1.2932 aloss2:1.7683 exploreP:0.0100\n",
      "Episode:635 meanR:402.5200 R:328.0000 rate:0.6560 aloss:1.0406 dloss:1.2907 aloss2:1.7753 exploreP:0.0100\n",
      "Episode:636 meanR:401.3800 R:283.0000 rate:0.5660 aloss:1.0389 dloss:1.2878 aloss2:1.7792 exploreP:0.0100\n",
      "Episode:637 meanR:400.9100 R:422.0000 rate:0.8440 aloss:1.0399 dloss:1.2887 aloss2:1.7750 exploreP:0.0100\n",
      "Episode:638 meanR:399.1000 R:319.0000 rate:0.6380 aloss:1.0375 dloss:1.2818 aloss2:1.7715 exploreP:0.0100\n",
      "Episode:639 meanR:397.8100 R:371.0000 rate:0.7420 aloss:1.0406 dloss:1.2831 aloss2:1.7932 exploreP:0.0100\n",
      "Episode:640 meanR:396.8500 R:319.0000 rate:0.6380 aloss:1.0410 dloss:1.2804 aloss2:1.7903 exploreP:0.0100\n",
      "Episode:641 meanR:395.6200 R:267.0000 rate:0.5340 aloss:1.0388 dloss:1.2767 aloss2:1.7788 exploreP:0.0100\n",
      "Episode:642 meanR:395.2000 R:344.0000 rate:0.6880 aloss:1.0394 dloss:1.2762 aloss2:1.8034 exploreP:0.0100\n",
      "Episode:643 meanR:393.0200 R:282.0000 rate:0.5640 aloss:1.0398 dloss:1.2735 aloss2:1.8078 exploreP:0.0100\n",
      "Episode:644 meanR:391.4100 R:339.0000 rate:0.6780 aloss:1.0390 dloss:1.2709 aloss2:1.8114 exploreP:0.0100\n",
      "Episode:645 meanR:390.0300 R:362.0000 rate:0.7240 aloss:1.0398 dloss:1.2680 aloss2:1.8075 exploreP:0.0100\n",
      "Episode:646 meanR:389.5000 R:378.0000 rate:0.7560 aloss:1.0408 dloss:1.2659 aloss2:1.8262 exploreP:0.0100\n",
      "Episode:647 meanR:388.0800 R:358.0000 rate:0.7160 aloss:1.0409 dloss:1.2622 aloss2:1.8285 exploreP:0.0100\n",
      "Episode:648 meanR:387.1000 R:307.0000 rate:0.6140 aloss:1.0400 dloss:1.2607 aloss2:1.8158 exploreP:0.0100\n",
      "Episode:649 meanR:386.1800 R:408.0000 rate:0.8160 aloss:1.0417 dloss:1.2575 aloss2:1.8235 exploreP:0.0100\n",
      "Episode:650 meanR:385.1100 R:393.0000 rate:0.7860 aloss:1.0428 dloss:1.2556 aloss2:1.8417 exploreP:0.0100\n",
      "Episode:651 meanR:381.9900 R:149.0000 rate:0.2980 aloss:1.0449 dloss:1.2583 aloss2:1.8460 exploreP:0.0100\n",
      "Episode:652 meanR:380.2400 R:325.0000 rate:0.6500 aloss:1.0446 dloss:1.2547 aloss2:1.8239 exploreP:0.0100\n",
      "Episode:653 meanR:378.2400 R:289.0000 rate:0.5780 aloss:1.0465 dloss:1.2519 aloss2:1.8360 exploreP:0.0100\n",
      "Episode:654 meanR:377.6800 R:366.0000 rate:0.7320 aloss:1.0462 dloss:1.2476 aloss2:1.8786 exploreP:0.0100\n",
      "Episode:655 meanR:377.7000 R:382.0000 rate:0.7640 aloss:1.0447 dloss:1.2452 aloss2:1.8744 exploreP:0.0100\n",
      "Episode:656 meanR:377.2500 R:325.0000 rate:0.6500 aloss:1.0443 dloss:1.2400 aloss2:1.8811 exploreP:0.0100\n",
      "Episode:657 meanR:376.3700 R:371.0000 rate:0.7420 aloss:1.0438 dloss:1.2367 aloss2:1.8943 exploreP:0.0100\n",
      "Episode:658 meanR:376.1600 R:370.0000 rate:0.7400 aloss:1.0446 dloss:1.2350 aloss2:1.8671 exploreP:0.0100\n",
      "Episode:659 meanR:374.3700 R:252.0000 rate:0.5040 aloss:1.0456 dloss:1.2313 aloss2:1.9006 exploreP:0.0100\n",
      "Episode:660 meanR:373.3300 R:355.0000 rate:0.7100 aloss:1.0450 dloss:1.2287 aloss2:1.9127 exploreP:0.0100\n",
      "Episode:661 meanR:374.4100 R:394.0000 rate:0.7880 aloss:1.0460 dloss:1.2290 aloss2:1.9003 exploreP:0.0100\n",
      "Episode:662 meanR:373.3300 R:274.0000 rate:0.5480 aloss:1.0453 dloss:1.2209 aloss2:1.9277 exploreP:0.0100\n",
      "Episode:663 meanR:373.3700 R:353.0000 rate:0.7060 aloss:1.0460 dloss:1.2225 aloss2:1.9376 exploreP:0.0100\n",
      "Episode:664 meanR:371.1000 R:162.0000 rate:0.3240 aloss:1.0471 dloss:1.2223 aloss2:1.8969 exploreP:0.0100\n",
      "Episode:665 meanR:369.3400 R:252.0000 rate:0.5040 aloss:1.0456 dloss:1.2169 aloss2:1.9289 exploreP:0.0100\n",
      "Episode:666 meanR:369.3900 R:387.0000 rate:0.7740 aloss:1.0471 dloss:1.2164 aloss2:1.9498 exploreP:0.0100\n",
      "Episode:667 meanR:369.8900 R:338.0000 rate:0.6760 aloss:1.0485 dloss:1.2158 aloss2:1.9477 exploreP:0.0100\n",
      "Episode:668 meanR:368.4700 R:266.0000 rate:0.5320 aloss:1.0468 dloss:1.2116 aloss2:1.9189 exploreP:0.0100\n",
      "Episode:669 meanR:367.6000 R:309.0000 rate:0.6180 aloss:1.0489 dloss:1.2073 aloss2:1.9848 exploreP:0.0100\n",
      "Episode:670 meanR:365.1200 R:252.0000 rate:0.5040 aloss:1.0493 dloss:1.2085 aloss2:1.9911 exploreP:0.0100\n",
      "Episode:671 meanR:364.0400 R:255.0000 rate:0.5100 aloss:1.0470 dloss:1.2028 aloss2:1.9700 exploreP:0.0100\n",
      "Episode:672 meanR:363.1600 R:300.0000 rate:0.6000 aloss:1.0496 dloss:1.2018 aloss2:1.9945 exploreP:0.0100\n",
      "Episode:673 meanR:361.5100 R:268.0000 rate:0.5360 aloss:1.0503 dloss:1.2000 aloss2:2.0257 exploreP:0.0100\n",
      "Episode:674 meanR:359.9600 R:281.0000 rate:0.5620 aloss:1.0517 dloss:1.1987 aloss2:2.0287 exploreP:0.0100\n",
      "Episode:675 meanR:358.8500 R:277.0000 rate:0.5540 aloss:1.0505 dloss:1.1949 aloss2:2.0041 exploreP:0.0100\n",
      "Episode:676 meanR:357.8200 R:273.0000 rate:0.5460 aloss:1.0544 dloss:1.1935 aloss2:2.0393 exploreP:0.0100\n",
      "Episode:677 meanR:355.7800 R:178.0000 rate:0.3560 aloss:1.0525 dloss:1.1861 aloss2:2.0678 exploreP:0.0100\n",
      "Episode:678 meanR:354.0000 R:238.0000 rate:0.4760 aloss:1.0537 dloss:1.1896 aloss2:2.0808 exploreP:0.0100\n",
      "Episode:679 meanR:353.4200 R:336.0000 rate:0.6720 aloss:1.0518 dloss:1.1853 aloss2:2.0668 exploreP:0.0100\n",
      "Episode:680 meanR:351.5700 R:248.0000 rate:0.4960 aloss:1.0529 dloss:1.1817 aloss2:2.0962 exploreP:0.0100\n",
      "Episode:681 meanR:350.2300 R:240.0000 rate:0.4800 aloss:1.0524 dloss:1.1799 aloss2:2.0856 exploreP:0.0100\n",
      "Episode:682 meanR:349.2300 R:275.0000 rate:0.5500 aloss:1.0530 dloss:1.1757 aloss2:2.0602 exploreP:0.0100\n",
      "Episode:683 meanR:347.9200 R:251.0000 rate:0.5020 aloss:1.0506 dloss:1.1742 aloss2:2.0590 exploreP:0.0100\n",
      "Episode:684 meanR:346.3000 R:263.0000 rate:0.5260 aloss:1.0522 dloss:1.1675 aloss2:2.1341 exploreP:0.0100\n",
      "Episode:685 meanR:344.5400 R:289.0000 rate:0.5780 aloss:1.0519 dloss:1.1687 aloss2:2.1180 exploreP:0.0100\n",
      "Episode:686 meanR:343.7700 R:306.0000 rate:0.6120 aloss:1.0536 dloss:1.1657 aloss2:2.1148 exploreP:0.0100\n",
      "Episode:687 meanR:342.2900 R:248.0000 rate:0.4960 aloss:1.0503 dloss:1.1600 aloss2:2.1407 exploreP:0.0100\n",
      "Episode:688 meanR:342.1900 R:351.0000 rate:0.7020 aloss:1.0514 dloss:1.1568 aloss2:2.1590 exploreP:0.0100\n",
      "Episode:689 meanR:341.1000 R:259.0000 rate:0.5180 aloss:1.0524 dloss:1.1541 aloss2:2.1535 exploreP:0.0100\n",
      "Episode:690 meanR:339.7900 R:278.0000 rate:0.5560 aloss:1.0490 dloss:1.1486 aloss2:2.1261 exploreP:0.0100\n",
      "Episode:691 meanR:338.1400 R:281.0000 rate:0.5620 aloss:1.0509 dloss:1.1454 aloss2:2.2096 exploreP:0.0100\n",
      "Episode:692 meanR:337.6700 R:337.0000 rate:0.6740 aloss:1.0525 dloss:1.1471 aloss2:2.1757 exploreP:0.0100\n",
      "Episode:693 meanR:336.6700 R:294.0000 rate:0.5880 aloss:1.0521 dloss:1.1450 aloss2:2.1721 exploreP:0.0100\n",
      "Episode:694 meanR:336.5700 R:373.0000 rate:0.7460 aloss:1.0487 dloss:1.1386 aloss2:2.2418 exploreP:0.0100\n",
      "Episode:695 meanR:334.1400 R:257.0000 rate:0.5140 aloss:1.0454 dloss:1.1358 aloss2:2.2640 exploreP:0.0100\n",
      "Episode:696 meanR:333.9100 R:348.0000 rate:0.6960 aloss:1.0444 dloss:1.1343 aloss2:2.2423 exploreP:0.0100\n",
      "Episode:697 meanR:333.3800 R:300.0000 rate:0.6000 aloss:1.0447 dloss:1.1296 aloss2:2.2958 exploreP:0.0100\n",
      "Episode:698 meanR:332.5000 R:343.0000 rate:0.6860 aloss:1.0427 dloss:1.1286 aloss2:2.2735 exploreP:0.0100\n",
      "Episode:699 meanR:331.2100 R:260.0000 rate:0.5200 aloss:1.0422 dloss:1.1271 aloss2:2.2632 exploreP:0.0100\n",
      "Episode:700 meanR:331.0800 R:264.0000 rate:0.5280 aloss:1.0417 dloss:1.1259 aloss2:2.3126 exploreP:0.0100\n",
      "Episode:701 meanR:330.2400 R:349.0000 rate:0.6980 aloss:1.0413 dloss:1.1210 aloss2:2.3463 exploreP:0.0100\n",
      "Episode:702 meanR:329.4500 R:269.0000 rate:0.5380 aloss:1.0395 dloss:1.1199 aloss2:2.3258 exploreP:0.0100\n",
      "Episode:703 meanR:328.7500 R:285.0000 rate:0.5700 aloss:1.0396 dloss:1.1164 aloss2:2.3088 exploreP:0.0100\n",
      "Episode:704 meanR:327.7100 R:286.0000 rate:0.5720 aloss:1.0390 dloss:1.1113 aloss2:2.3887 exploreP:0.0100\n",
      "Episode:705 meanR:326.4800 R:283.0000 rate:0.5660 aloss:1.0377 dloss:1.1148 aloss2:2.3367 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:706 meanR:325.5500 R:284.0000 rate:0.5680 aloss:1.0377 dloss:1.1129 aloss2:2.3293 exploreP:0.0100\n",
      "Episode:707 meanR:324.1600 R:237.0000 rate:0.4740 aloss:1.0374 dloss:1.1098 aloss2:2.3193 exploreP:0.0100\n",
      "Episode:708 meanR:323.3600 R:295.0000 rate:0.5900 aloss:1.0365 dloss:1.1124 aloss2:2.3517 exploreP:0.0100\n",
      "Episode:709 meanR:323.0300 R:285.0000 rate:0.5700 aloss:1.0360 dloss:1.1146 aloss2:2.3545 exploreP:0.0100\n",
      "Episode:710 meanR:322.4500 R:301.0000 rate:0.6020 aloss:1.0367 dloss:1.1190 aloss2:2.3394 exploreP:0.0100\n",
      "Episode:711 meanR:321.5100 R:286.0000 rate:0.5720 aloss:1.0351 dloss:1.1159 aloss2:2.4124 exploreP:0.0100\n",
      "Episode:712 meanR:320.6400 R:281.0000 rate:0.5620 aloss:1.0360 dloss:1.1207 aloss2:2.3450 exploreP:0.0100\n",
      "Episode:713 meanR:319.3400 R:282.0000 rate:0.5640 aloss:1.0366 dloss:1.1267 aloss2:2.3306 exploreP:0.0100\n",
      "Episode:714 meanR:317.7500 R:208.0000 rate:0.4160 aloss:1.0354 dloss:1.1263 aloss2:2.3190 exploreP:0.0100\n",
      "Episode:715 meanR:319.1300 R:500.0000 rate:1.0000 aloss:1.0356 dloss:1.1264 aloss2:2.3452 exploreP:0.0100\n",
      "Episode:716 meanR:319.6900 R:415.0000 rate:0.8300 aloss:1.0358 dloss:1.1301 aloss2:2.2995 exploreP:0.0100\n",
      "Episode:717 meanR:319.4700 R:368.0000 rate:0.7360 aloss:1.0362 dloss:1.1311 aloss2:2.3080 exploreP:0.0100\n",
      "Episode:718 meanR:318.9400 R:321.0000 rate:0.6420 aloss:1.0366 dloss:1.1317 aloss2:2.2969 exploreP:0.0100\n",
      "Episode:719 meanR:318.1800 R:285.0000 rate:0.5700 aloss:1.0363 dloss:1.1297 aloss2:2.2896 exploreP:0.0100\n",
      "Episode:720 meanR:316.5400 R:213.0000 rate:0.4260 aloss:1.0348 dloss:1.1251 aloss2:2.3363 exploreP:0.0100\n",
      "Episode:721 meanR:314.7000 R:266.0000 rate:0.5320 aloss:1.0362 dloss:1.1276 aloss2:2.3099 exploreP:0.0100\n",
      "Episode:722 meanR:313.7500 R:271.0000 rate:0.5420 aloss:1.0341 dloss:1.1272 aloss2:2.3071 exploreP:0.0100\n",
      "Episode:723 meanR:313.7800 R:374.0000 rate:0.7480 aloss:1.0356 dloss:1.1255 aloss2:2.2808 exploreP:0.0100\n",
      "Episode:724 meanR:312.9100 R:305.0000 rate:0.6100 aloss:1.0367 dloss:1.1243 aloss2:2.3440 exploreP:0.0100\n",
      "Episode:725 meanR:313.1200 R:380.0000 rate:0.7600 aloss:1.0345 dloss:1.1217 aloss2:2.3556 exploreP:0.0100\n",
      "Episode:726 meanR:312.9300 R:354.0000 rate:0.7080 aloss:1.0316 dloss:1.1160 aloss2:2.3779 exploreP:0.0100\n",
      "Episode:727 meanR:311.7600 R:296.0000 rate:0.5920 aloss:1.0308 dloss:1.1101 aloss2:2.4065 exploreP:0.0100\n",
      "Episode:728 meanR:310.6900 R:274.0000 rate:0.5480 aloss:1.0307 dloss:1.1141 aloss2:2.4122 exploreP:0.0100\n",
      "Episode:729 meanR:309.5100 R:247.0000 rate:0.4940 aloss:1.0316 dloss:1.1125 aloss2:2.3639 exploreP:0.0100\n",
      "Episode:730 meanR:308.3700 R:271.0000 rate:0.5420 aloss:1.0296 dloss:1.1077 aloss2:2.4060 exploreP:0.0100\n",
      "Episode:731 meanR:307.7200 R:353.0000 rate:0.7060 aloss:1.0300 dloss:1.1078 aloss2:2.4366 exploreP:0.0100\n",
      "Episode:732 meanR:306.7700 R:285.0000 rate:0.5700 aloss:1.0306 dloss:1.1082 aloss2:2.4292 exploreP:0.0100\n",
      "Episode:733 meanR:306.2100 R:353.0000 rate:0.7060 aloss:1.0286 dloss:1.1022 aloss2:2.4548 exploreP:0.0100\n",
      "Episode:734 meanR:305.6000 R:376.0000 rate:0.7520 aloss:1.0291 dloss:1.1042 aloss2:2.4240 exploreP:0.0100\n",
      "Episode:735 meanR:303.8100 R:149.0000 rate:0.2980 aloss:1.0273 dloss:1.1006 aloss2:2.5418 exploreP:0.0100\n",
      "Episode:736 meanR:304.5700 R:359.0000 rate:0.7180 aloss:1.0270 dloss:1.0962 aloss2:2.4581 exploreP:0.0100\n",
      "Episode:737 meanR:302.9100 R:256.0000 rate:0.5120 aloss:1.0280 dloss:1.0944 aloss2:2.5266 exploreP:0.0100\n",
      "Episode:738 meanR:301.4400 R:172.0000 rate:0.3440 aloss:1.0275 dloss:1.0914 aloss2:2.4825 exploreP:0.0100\n",
      "Episode:739 meanR:300.6400 R:291.0000 rate:0.5820 aloss:1.0281 dloss:1.0945 aloss2:2.5386 exploreP:0.0100\n",
      "Episode:740 meanR:300.0500 R:260.0000 rate:0.5200 aloss:1.0279 dloss:1.0928 aloss2:2.4804 exploreP:0.0100\n",
      "Episode:741 meanR:299.8300 R:245.0000 rate:0.4900 aloss:1.0280 dloss:1.0931 aloss2:2.5746 exploreP:0.0100\n",
      "Episode:742 meanR:299.3400 R:295.0000 rate:0.5900 aloss:1.0285 dloss:1.0954 aloss2:2.5199 exploreP:0.0100\n",
      "Episode:743 meanR:299.0900 R:257.0000 rate:0.5140 aloss:1.0275 dloss:1.0920 aloss2:2.5530 exploreP:0.0100\n",
      "Episode:744 meanR:298.2000 R:250.0000 rate:0.5000 aloss:1.0289 dloss:1.0882 aloss2:2.5229 exploreP:0.0100\n",
      "Episode:745 meanR:297.4000 R:282.0000 rate:0.5640 aloss:1.0271 dloss:1.0872 aloss2:2.5934 exploreP:0.0100\n",
      "Episode:746 meanR:296.4100 R:279.0000 rate:0.5580 aloss:1.0244 dloss:1.0820 aloss2:2.6371 exploreP:0.0100\n",
      "Episode:747 meanR:295.6000 R:277.0000 rate:0.5540 aloss:1.0253 dloss:1.0798 aloss2:2.6534 exploreP:0.0100\n",
      "Episode:748 meanR:295.9300 R:340.0000 rate:0.6800 aloss:1.0266 dloss:1.0804 aloss2:2.6657 exploreP:0.0100\n",
      "Episode:749 meanR:294.3000 R:245.0000 rate:0.4900 aloss:1.0274 dloss:1.0815 aloss2:2.6130 exploreP:0.0100\n",
      "Episode:750 meanR:293.8900 R:352.0000 rate:0.7040 aloss:1.0220 dloss:1.0757 aloss2:2.6414 exploreP:0.0100\n",
      "Episode:751 meanR:295.1400 R:274.0000 rate:0.5480 aloss:1.0242 dloss:1.0730 aloss2:2.6561 exploreP:0.0100\n",
      "Episode:752 meanR:294.6400 R:275.0000 rate:0.5500 aloss:1.0249 dloss:1.0719 aloss2:2.6909 exploreP:0.0100\n",
      "Episode:753 meanR:294.2800 R:253.0000 rate:0.5060 aloss:1.0207 dloss:1.0697 aloss2:2.6745 exploreP:0.0100\n",
      "Episode:754 meanR:293.0500 R:243.0000 rate:0.4860 aloss:1.0192 dloss:1.0661 aloss2:2.6902 exploreP:0.0100\n",
      "Episode:755 meanR:291.8300 R:260.0000 rate:0.5200 aloss:1.0200 dloss:1.0627 aloss2:2.7527 exploreP:0.0100\n",
      "Episode:756 meanR:291.5200 R:294.0000 rate:0.5880 aloss:1.0248 dloss:1.0635 aloss2:2.6823 exploreP:0.0100\n",
      "Episode:757 meanR:290.5100 R:270.0000 rate:0.5400 aloss:1.0233 dloss:1.0700 aloss2:2.6736 exploreP:0.0100\n",
      "Episode:758 meanR:289.7900 R:298.0000 rate:0.5960 aloss:1.0245 dloss:1.0699 aloss2:2.6663 exploreP:0.0100\n",
      "Episode:759 meanR:290.2000 R:293.0000 rate:0.5860 aloss:1.0255 dloss:1.0729 aloss2:2.6997 exploreP:0.0100\n",
      "Episode:760 meanR:289.0700 R:242.0000 rate:0.4840 aloss:1.0253 dloss:1.0728 aloss2:2.6576 exploreP:0.0100\n",
      "Episode:761 meanR:287.7300 R:260.0000 rate:0.5200 aloss:1.0238 dloss:1.0713 aloss2:2.6867 exploreP:0.0100\n",
      "Episode:762 meanR:287.6100 R:262.0000 rate:0.5240 aloss:1.0241 dloss:1.0670 aloss2:2.6916 exploreP:0.0100\n",
      "Episode:763 meanR:286.9800 R:290.0000 rate:0.5800 aloss:1.0254 dloss:1.0688 aloss2:2.7486 exploreP:0.0100\n",
      "Episode:764 meanR:288.2600 R:290.0000 rate:0.5800 aloss:1.0235 dloss:1.0682 aloss2:2.7458 exploreP:0.0100\n",
      "Episode:765 meanR:288.1500 R:241.0000 rate:0.4820 aloss:1.0214 dloss:1.0617 aloss2:2.7382 exploreP:0.0100\n",
      "Episode:766 meanR:287.7500 R:347.0000 rate:0.6940 aloss:1.0231 dloss:1.0626 aloss2:2.7635 exploreP:0.0100\n",
      "Episode:767 meanR:286.9100 R:254.0000 rate:0.5080 aloss:1.0227 dloss:1.0599 aloss2:2.7999 exploreP:0.0100\n",
      "Episode:768 meanR:287.2700 R:302.0000 rate:0.6040 aloss:1.0218 dloss:1.0620 aloss2:2.8056 exploreP:0.0100\n",
      "Episode:769 meanR:286.8900 R:271.0000 rate:0.5420 aloss:1.0255 dloss:1.0592 aloss2:2.7842 exploreP:0.0100\n",
      "Episode:770 meanR:287.1700 R:280.0000 rate:0.5600 aloss:1.0238 dloss:1.0604 aloss2:2.7984 exploreP:0.0100\n",
      "Episode:771 meanR:287.5600 R:294.0000 rate:0.5880 aloss:1.0227 dloss:1.0585 aloss2:2.7889 exploreP:0.0100\n",
      "Episode:772 meanR:286.3700 R:181.0000 rate:0.3620 aloss:1.0235 dloss:1.0546 aloss2:2.7084 exploreP:0.0100\n",
      "Episode:773 meanR:286.4900 R:280.0000 rate:0.5600 aloss:1.0221 dloss:1.0549 aloss2:2.7830 exploreP:0.0100\n",
      "Episode:774 meanR:286.1000 R:242.0000 rate:0.4840 aloss:1.0238 dloss:1.0528 aloss2:2.8737 exploreP:0.0100\n",
      "Episode:775 meanR:286.0300 R:270.0000 rate:0.5400 aloss:1.0207 dloss:1.0535 aloss2:2.8482 exploreP:0.0100\n",
      "Episode:776 meanR:286.0200 R:272.0000 rate:0.5440 aloss:1.0238 dloss:1.0555 aloss2:2.7973 exploreP:0.0100\n",
      "Episode:777 meanR:286.8700 R:263.0000 rate:0.5260 aloss:1.0218 dloss:1.0490 aloss2:2.9460 exploreP:0.0100\n",
      "Episode:778 meanR:287.1400 R:265.0000 rate:0.5300 aloss:1.0232 dloss:1.0522 aloss2:2.8926 exploreP:0.0100\n",
      "Episode:779 meanR:286.3600 R:258.0000 rate:0.5160 aloss:1.0237 dloss:1.0505 aloss2:2.8543 exploreP:0.0100\n",
      "Episode:780 meanR:286.4900 R:261.0000 rate:0.5220 aloss:1.0215 dloss:1.0479 aloss2:2.7742 exploreP:0.0100\n",
      "Episode:781 meanR:286.6700 R:258.0000 rate:0.5160 aloss:1.0220 dloss:1.0449 aloss2:2.9145 exploreP:0.0100\n",
      "Episode:782 meanR:286.8000 R:288.0000 rate:0.5760 aloss:1.0207 dloss:1.0471 aloss2:2.9617 exploreP:0.0100\n",
      "Episode:783 meanR:286.1800 R:189.0000 rate:0.3780 aloss:1.0199 dloss:1.0479 aloss2:2.9493 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:784 meanR:286.0300 R:248.0000 rate:0.4960 aloss:1.0218 dloss:1.0409 aloss2:2.8902 exploreP:0.0100\n",
      "Episode:785 meanR:285.7300 R:259.0000 rate:0.5180 aloss:1.0217 dloss:1.0442 aloss2:2.9628 exploreP:0.0100\n",
      "Episode:786 meanR:285.0700 R:240.0000 rate:0.4800 aloss:1.0232 dloss:1.0448 aloss2:2.9263 exploreP:0.0100\n",
      "Episode:787 meanR:283.9600 R:137.0000 rate:0.2740 aloss:1.0229 dloss:1.0460 aloss2:2.8988 exploreP:0.0100\n",
      "Episode:788 meanR:283.1300 R:268.0000 rate:0.5360 aloss:1.0217 dloss:1.0409 aloss2:2.9614 exploreP:0.0100\n",
      "Episode:789 meanR:283.3100 R:277.0000 rate:0.5540 aloss:1.0210 dloss:1.0403 aloss2:3.0055 exploreP:0.0100\n",
      "Episode:790 meanR:283.0800 R:255.0000 rate:0.5100 aloss:1.0232 dloss:1.0411 aloss2:2.9571 exploreP:0.0100\n",
      "Episode:791 meanR:282.7600 R:249.0000 rate:0.4980 aloss:1.0210 dloss:1.0436 aloss2:2.9389 exploreP:0.0100\n",
      "Episode:792 meanR:281.8600 R:247.0000 rate:0.4940 aloss:1.0202 dloss:1.0335 aloss2:2.9568 exploreP:0.0100\n",
      "Episode:793 meanR:281.5400 R:262.0000 rate:0.5240 aloss:1.0207 dloss:1.0340 aloss2:3.0456 exploreP:0.0100\n",
      "Episode:794 meanR:280.7800 R:297.0000 rate:0.5940 aloss:1.0200 dloss:1.0355 aloss2:3.0476 exploreP:0.0100\n",
      "Episode:795 meanR:280.9400 R:273.0000 rate:0.5460 aloss:1.0199 dloss:1.0351 aloss2:3.0221 exploreP:0.0100\n",
      "Episode:796 meanR:280.0900 R:263.0000 rate:0.5260 aloss:1.0199 dloss:1.0265 aloss2:3.0764 exploreP:0.0100\n",
      "Episode:797 meanR:279.5100 R:242.0000 rate:0.4840 aloss:1.0201 dloss:1.0331 aloss2:3.0518 exploreP:0.0100\n",
      "Episode:798 meanR:279.0500 R:297.0000 rate:0.5940 aloss:1.0195 dloss:1.0288 aloss2:3.0773 exploreP:0.0100\n",
      "Episode:799 meanR:279.0200 R:257.0000 rate:0.5140 aloss:1.0179 dloss:1.0311 aloss2:3.1245 exploreP:0.0100\n",
      "Episode:800 meanR:279.1600 R:278.0000 rate:0.5560 aloss:1.0171 dloss:1.0238 aloss2:3.1569 exploreP:0.0100\n",
      "Episode:801 meanR:278.2100 R:254.0000 rate:0.5080 aloss:1.0217 dloss:1.0299 aloss2:3.0385 exploreP:0.0100\n",
      "Episode:802 meanR:277.5100 R:199.0000 rate:0.3980 aloss:1.0194 dloss:1.0250 aloss2:3.0771 exploreP:0.0100\n",
      "Episode:803 meanR:277.0900 R:243.0000 rate:0.4860 aloss:1.0176 dloss:1.0241 aloss2:3.1600 exploreP:0.0100\n",
      "Episode:804 meanR:275.6500 R:142.0000 rate:0.2840 aloss:1.0185 dloss:1.0233 aloss2:3.0315 exploreP:0.0100\n",
      "Episode:805 meanR:275.2400 R:242.0000 rate:0.4840 aloss:1.0171 dloss:1.0171 aloss2:3.2151 exploreP:0.0100\n",
      "Episode:806 meanR:275.1700 R:277.0000 rate:0.5540 aloss:1.0186 dloss:1.0165 aloss2:3.2234 exploreP:0.0100\n",
      "Episode:807 meanR:275.4100 R:261.0000 rate:0.5220 aloss:1.0177 dloss:1.0213 aloss2:3.1640 exploreP:0.0100\n",
      "Episode:808 meanR:275.1000 R:264.0000 rate:0.5280 aloss:1.0151 dloss:1.0098 aloss2:3.1987 exploreP:0.0100\n",
      "Episode:809 meanR:274.5200 R:227.0000 rate:0.4540 aloss:1.0175 dloss:1.0134 aloss2:3.2560 exploreP:0.0100\n",
      "Episode:810 meanR:274.4600 R:295.0000 rate:0.5900 aloss:1.0167 dloss:1.0131 aloss2:3.2597 exploreP:0.0100\n",
      "Episode:811 meanR:274.2900 R:269.0000 rate:0.5380 aloss:1.0158 dloss:1.0124 aloss2:3.2059 exploreP:0.0100\n",
      "Episode:812 meanR:273.4800 R:200.0000 rate:0.4000 aloss:1.0156 dloss:1.0076 aloss2:3.2289 exploreP:0.0100\n",
      "Episode:813 meanR:273.1600 R:250.0000 rate:0.5000 aloss:1.0155 dloss:1.0098 aloss2:3.3717 exploreP:0.0100\n",
      "Episode:814 meanR:273.5400 R:246.0000 rate:0.4920 aloss:1.0199 dloss:1.0089 aloss2:3.3155 exploreP:0.0100\n",
      "Episode:815 meanR:271.1100 R:257.0000 rate:0.5140 aloss:1.0152 dloss:1.0089 aloss2:3.3585 exploreP:0.0100\n",
      "Episode:816 meanR:270.3800 R:342.0000 rate:0.6840 aloss:1.0142 dloss:1.0044 aloss2:3.3425 exploreP:0.0100\n",
      "Episode:817 meanR:268.5200 R:182.0000 rate:0.3640 aloss:1.0184 dloss:1.0078 aloss2:3.4177 exploreP:0.0100\n",
      "Episode:818 meanR:268.0000 R:269.0000 rate:0.5380 aloss:1.0143 dloss:0.9975 aloss2:3.4339 exploreP:0.0100\n",
      "Episode:819 meanR:267.7700 R:262.0000 rate:0.5240 aloss:1.0144 dloss:1.0025 aloss2:3.4163 exploreP:0.0100\n",
      "Episode:820 meanR:267.4300 R:179.0000 rate:0.3580 aloss:1.0155 dloss:0.9900 aloss2:3.3426 exploreP:0.0100\n",
      "Episode:821 meanR:267.2800 R:251.0000 rate:0.5020 aloss:1.0134 dloss:0.9928 aloss2:3.3994 exploreP:0.0100\n",
      "Episode:822 meanR:267.0900 R:252.0000 rate:0.5040 aloss:1.0158 dloss:0.9944 aloss2:3.3914 exploreP:0.0100\n",
      "Episode:823 meanR:265.1300 R:178.0000 rate:0.3560 aloss:1.0143 dloss:0.9908 aloss2:3.4930 exploreP:0.0100\n",
      "Episode:824 meanR:264.7700 R:269.0000 rate:0.5380 aloss:1.0168 dloss:0.9945 aloss2:3.4304 exploreP:0.0100\n",
      "Episode:825 meanR:262.7100 R:174.0000 rate:0.3480 aloss:1.0182 dloss:0.9916 aloss2:3.3964 exploreP:0.0100\n",
      "Episode:826 meanR:261.7500 R:258.0000 rate:0.5160 aloss:1.0151 dloss:0.9952 aloss2:3.4711 exploreP:0.0100\n",
      "Episode:827 meanR:261.4800 R:269.0000 rate:0.5380 aloss:1.0173 dloss:0.9928 aloss2:3.4026 exploreP:0.0100\n",
      "Episode:828 meanR:261.4000 R:266.0000 rate:0.5320 aloss:1.0162 dloss:0.9929 aloss2:3.4167 exploreP:0.0100\n",
      "Episode:829 meanR:261.6300 R:270.0000 rate:0.5400 aloss:1.0152 dloss:0.9909 aloss2:3.4921 exploreP:0.0100\n",
      "Episode:830 meanR:261.4000 R:248.0000 rate:0.4960 aloss:1.0163 dloss:0.9949 aloss2:3.5202 exploreP:0.0100\n",
      "Episode:831 meanR:260.3700 R:250.0000 rate:0.5000 aloss:1.0163 dloss:0.9944 aloss2:3.3891 exploreP:0.0100\n",
      "Episode:832 meanR:260.0400 R:252.0000 rate:0.5040 aloss:1.0150 dloss:0.9902 aloss2:3.4477 exploreP:0.0100\n",
      "Episode:833 meanR:259.3200 R:281.0000 rate:0.5620 aloss:1.0143 dloss:0.9908 aloss2:3.4850 exploreP:0.0100\n",
      "Episode:834 meanR:258.2100 R:265.0000 rate:0.5300 aloss:1.0166 dloss:0.9927 aloss2:3.5253 exploreP:0.0100\n",
      "Episode:835 meanR:259.3400 R:262.0000 rate:0.5240 aloss:1.0155 dloss:0.9937 aloss2:3.4831 exploreP:0.0100\n",
      "Episode:836 meanR:258.3100 R:256.0000 rate:0.5120 aloss:1.0166 dloss:0.9912 aloss2:3.4608 exploreP:0.0100\n",
      "Episode:837 meanR:258.3500 R:260.0000 rate:0.5200 aloss:1.0139 dloss:0.9841 aloss2:3.5599 exploreP:0.0100\n",
      "Episode:838 meanR:259.0400 R:241.0000 rate:0.4820 aloss:1.0145 dloss:0.9851 aloss2:3.5032 exploreP:0.0100\n",
      "Episode:839 meanR:257.8600 R:173.0000 rate:0.3460 aloss:1.0157 dloss:0.9899 aloss2:3.5815 exploreP:0.0100\n",
      "Episode:840 meanR:257.8700 R:261.0000 rate:0.5220 aloss:1.0151 dloss:0.9871 aloss2:3.5742 exploreP:0.0100\n",
      "Episode:841 meanR:258.0300 R:261.0000 rate:0.5220 aloss:1.0146 dloss:0.9819 aloss2:3.5257 exploreP:0.0100\n",
      "Episode:842 meanR:256.4900 R:141.0000 rate:0.2820 aloss:1.0164 dloss:0.9874 aloss2:3.5213 exploreP:0.0100\n",
      "Episode:843 meanR:256.7100 R:279.0000 rate:0.5580 aloss:1.0138 dloss:0.9817 aloss2:3.6238 exploreP:0.0100\n",
      "Episode:844 meanR:257.5600 R:335.0000 rate:0.6700 aloss:1.0124 dloss:0.9826 aloss2:3.5885 exploreP:0.0100\n",
      "Episode:845 meanR:257.3800 R:264.0000 rate:0.5280 aloss:1.0133 dloss:0.9768 aloss2:3.6507 exploreP:0.0100\n",
      "Episode:846 meanR:257.2600 R:267.0000 rate:0.5340 aloss:1.0142 dloss:0.9792 aloss2:3.6548 exploreP:0.0100\n",
      "Episode:847 meanR:257.1000 R:261.0000 rate:0.5220 aloss:1.0110 dloss:0.9784 aloss2:3.7328 exploreP:0.0100\n",
      "Episode:848 meanR:256.2900 R:259.0000 rate:0.5180 aloss:1.0129 dloss:0.9788 aloss2:3.6396 exploreP:0.0100\n",
      "Episode:849 meanR:255.1900 R:135.0000 rate:0.2700 aloss:1.0090 dloss:0.9680 aloss2:3.7542 exploreP:0.0100\n",
      "Episode:850 meanR:254.5800 R:291.0000 rate:0.5820 aloss:1.0137 dloss:0.9766 aloss2:3.7556 exploreP:0.0100\n",
      "Episode:851 meanR:253.8200 R:198.0000 rate:0.3960 aloss:1.0103 dloss:0.9723 aloss2:3.7067 exploreP:0.0100\n",
      "Episode:852 meanR:253.5600 R:249.0000 rate:0.4980 aloss:1.0120 dloss:0.9693 aloss2:3.7129 exploreP:0.0100\n",
      "Episode:853 meanR:253.5600 R:253.0000 rate:0.5060 aloss:1.0122 dloss:0.9698 aloss2:3.7570 exploreP:0.0100\n",
      "Episode:854 meanR:253.0300 R:190.0000 rate:0.3800 aloss:1.0126 dloss:0.9711 aloss2:3.9057 exploreP:0.0100\n",
      "Episode:855 meanR:252.2600 R:183.0000 rate:0.3660 aloss:1.0094 dloss:0.9606 aloss2:3.9837 exploreP:0.0100\n",
      "Episode:856 meanR:251.9300 R:261.0000 rate:0.5220 aloss:1.0125 dloss:0.9712 aloss2:3.7806 exploreP:0.0100\n",
      "Episode:857 meanR:251.1400 R:191.0000 rate:0.3820 aloss:1.0122 dloss:0.9705 aloss2:3.7734 exploreP:0.0100\n",
      "Episode:858 meanR:251.0500 R:289.0000 rate:0.5780 aloss:1.0104 dloss:0.9686 aloss2:3.9047 exploreP:0.0100\n",
      "Episode:859 meanR:250.0000 R:188.0000 rate:0.3760 aloss:1.0131 dloss:0.9693 aloss2:3.8335 exploreP:0.0100\n",
      "Episode:860 meanR:250.0400 R:246.0000 rate:0.4920 aloss:1.0108 dloss:0.9701 aloss2:3.8335 exploreP:0.0100\n",
      "Episode:861 meanR:249.8500 R:241.0000 rate:0.4820 aloss:1.0102 dloss:0.9678 aloss2:3.8553 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:862 meanR:249.2100 R:198.0000 rate:0.3960 aloss:1.0121 dloss:0.9629 aloss2:3.8644 exploreP:0.0100\n",
      "Episode:863 meanR:249.1100 R:280.0000 rate:0.5600 aloss:1.0135 dloss:0.9692 aloss2:3.8953 exploreP:0.0100\n",
      "Episode:864 meanR:249.0700 R:286.0000 rate:0.5720 aloss:1.0104 dloss:0.9676 aloss2:3.9143 exploreP:0.0100\n",
      "Episode:865 meanR:248.3200 R:166.0000 rate:0.3320 aloss:1.0105 dloss:0.9651 aloss2:3.9458 exploreP:0.0100\n",
      "Episode:866 meanR:247.3900 R:254.0000 rate:0.5080 aloss:1.0115 dloss:0.9647 aloss2:3.9356 exploreP:0.0100\n",
      "Episode:867 meanR:247.6100 R:276.0000 rate:0.5520 aloss:1.0101 dloss:0.9640 aloss2:3.9546 exploreP:0.0100\n",
      "Episode:868 meanR:247.2900 R:270.0000 rate:0.5400 aloss:1.0084 dloss:0.9594 aloss2:4.0231 exploreP:0.0100\n",
      "Episode:869 meanR:246.5600 R:198.0000 rate:0.3960 aloss:1.0098 dloss:0.9611 aloss2:3.9787 exploreP:0.0100\n",
      "Episode:870 meanR:245.6300 R:187.0000 rate:0.3740 aloss:1.0085 dloss:0.9559 aloss2:4.0764 exploreP:0.0100\n",
      "Episode:871 meanR:245.1400 R:245.0000 rate:0.4900 aloss:1.0100 dloss:0.9593 aloss2:4.0791 exploreP:0.0100\n",
      "Episode:872 meanR:245.9000 R:257.0000 rate:0.5140 aloss:1.0099 dloss:0.9587 aloss2:3.9638 exploreP:0.0100\n",
      "Episode:873 meanR:245.5800 R:248.0000 rate:0.4960 aloss:1.0058 dloss:0.9520 aloss2:4.1382 exploreP:0.0100\n",
      "Episode:874 meanR:244.5100 R:135.0000 rate:0.2700 aloss:1.0109 dloss:0.9603 aloss2:4.0628 exploreP:0.0100\n",
      "Episode:875 meanR:244.5800 R:277.0000 rate:0.5540 aloss:1.0085 dloss:0.9524 aloss2:4.0766 exploreP:0.0100\n",
      "Episode:876 meanR:243.2700 R:141.0000 rate:0.2820 aloss:1.0114 dloss:0.9585 aloss2:4.0736 exploreP:0.0100\n",
      "Episode:877 meanR:243.3000 R:266.0000 rate:0.5320 aloss:1.0083 dloss:0.9520 aloss2:4.0877 exploreP:0.0100\n",
      "Episode:878 meanR:243.4800 R:283.0000 rate:0.5660 aloss:1.0079 dloss:0.9512 aloss2:4.1539 exploreP:0.0100\n",
      "Episode:879 meanR:243.8100 R:291.0000 rate:0.5820 aloss:1.0091 dloss:0.9551 aloss2:4.1152 exploreP:0.0100\n",
      "Episode:880 meanR:243.9500 R:275.0000 rate:0.5500 aloss:1.0062 dloss:0.9502 aloss2:4.2711 exploreP:0.0100\n",
      "Episode:881 meanR:243.9300 R:256.0000 rate:0.5120 aloss:1.0097 dloss:0.9557 aloss2:4.0800 exploreP:0.0100\n",
      "Episode:882 meanR:243.4800 R:243.0000 rate:0.4860 aloss:1.0081 dloss:0.9527 aloss2:4.1856 exploreP:0.0100\n",
      "Episode:883 meanR:244.2900 R:270.0000 rate:0.5400 aloss:1.0074 dloss:0.9523 aloss2:4.1757 exploreP:0.0100\n",
      "Episode:884 meanR:244.3300 R:252.0000 rate:0.5040 aloss:1.0072 dloss:0.9485 aloss2:4.2486 exploreP:0.0100\n",
      "Episode:885 meanR:244.3700 R:263.0000 rate:0.5260 aloss:1.0092 dloss:0.9521 aloss2:4.2211 exploreP:0.0100\n",
      "Episode:886 meanR:244.5600 R:259.0000 rate:0.5180 aloss:1.0107 dloss:0.9548 aloss2:4.1038 exploreP:0.0100\n",
      "Episode:887 meanR:246.7400 R:355.0000 rate:0.7100 aloss:1.0084 dloss:0.9498 aloss2:4.2720 exploreP:0.0100\n",
      "Episode:888 meanR:247.0400 R:298.0000 rate:0.5960 aloss:1.0076 dloss:0.9472 aloss2:4.2559 exploreP:0.0100\n",
      "Episode:889 meanR:246.7100 R:244.0000 rate:0.4880 aloss:1.0087 dloss:0.9505 aloss2:4.2768 exploreP:0.0100\n",
      "Episode:890 meanR:246.8600 R:270.0000 rate:0.5400 aloss:1.0073 dloss:0.9430 aloss2:4.3262 exploreP:0.0100\n",
      "Episode:891 meanR:246.0700 R:170.0000 rate:0.3400 aloss:1.0112 dloss:0.9530 aloss2:4.2866 exploreP:0.0100\n",
      "Episode:892 meanR:246.1500 R:255.0000 rate:0.5100 aloss:1.0075 dloss:0.9437 aloss2:4.2993 exploreP:0.0100\n",
      "Episode:893 meanR:246.0700 R:254.0000 rate:0.5080 aloss:1.0075 dloss:0.9489 aloss2:4.2312 exploreP:0.0100\n",
      "Episode:894 meanR:245.7600 R:266.0000 rate:0.5320 aloss:1.0070 dloss:0.9441 aloss2:4.3439 exploreP:0.0100\n",
      "Episode:895 meanR:245.5400 R:251.0000 rate:0.5020 aloss:1.0057 dloss:0.9418 aloss2:4.4268 exploreP:0.0100\n",
      "Episode:896 meanR:245.2200 R:231.0000 rate:0.4620 aloss:1.0090 dloss:0.9383 aloss2:4.3677 exploreP:0.0100\n",
      "Episode:897 meanR:244.7300 R:193.0000 rate:0.3860 aloss:1.0057 dloss:0.9409 aloss2:4.3371 exploreP:0.0100\n",
      "Episode:898 meanR:244.7900 R:303.0000 rate:0.6060 aloss:1.0042 dloss:0.9348 aloss2:4.4774 exploreP:0.0100\n",
      "Episode:899 meanR:244.8500 R:263.0000 rate:0.5260 aloss:1.0074 dloss:0.9349 aloss2:4.4696 exploreP:0.0100\n",
      "Episode:900 meanR:244.6400 R:257.0000 rate:0.5140 aloss:1.0029 dloss:0.9326 aloss2:4.5318 exploreP:0.0100\n",
      "Episode:901 meanR:246.1000 R:400.0000 rate:0.8000 aloss:1.0050 dloss:0.9338 aloss2:4.5273 exploreP:0.0100\n",
      "Episode:902 meanR:246.8200 R:271.0000 rate:0.5420 aloss:1.0039 dloss:0.9327 aloss2:4.5100 exploreP:0.0100\n",
      "Episode:903 meanR:246.8300 R:244.0000 rate:0.4880 aloss:1.0050 dloss:0.9309 aloss2:4.5857 exploreP:0.0100\n",
      "Episode:904 meanR:248.2700 R:286.0000 rate:0.5720 aloss:1.0041 dloss:0.9327 aloss2:4.5007 exploreP:0.0100\n",
      "Episode:905 meanR:248.8100 R:296.0000 rate:0.5920 aloss:1.0011 dloss:0.9231 aloss2:4.6111 exploreP:0.0100\n",
      "Episode:906 meanR:248.7000 R:266.0000 rate:0.5320 aloss:1.0029 dloss:0.9274 aloss2:4.6514 exploreP:0.0100\n",
      "Episode:907 meanR:248.4700 R:238.0000 rate:0.4760 aloss:1.0040 dloss:0.9249 aloss2:4.6997 exploreP:0.0100\n",
      "Episode:908 meanR:248.7400 R:291.0000 rate:0.5820 aloss:1.0038 dloss:0.9274 aloss2:4.5640 exploreP:0.0100\n",
      "Episode:909 meanR:248.0300 R:156.0000 rate:0.3120 aloss:1.0028 dloss:0.9228 aloss2:4.6106 exploreP:0.0100\n",
      "Episode:910 meanR:247.9500 R:287.0000 rate:0.5740 aloss:1.0021 dloss:0.9222 aloss2:4.6794 exploreP:0.0100\n",
      "Episode:911 meanR:248.1100 R:285.0000 rate:0.5700 aloss:1.0014 dloss:0.9236 aloss2:4.6698 exploreP:0.0100\n",
      "Episode:912 meanR:248.7300 R:262.0000 rate:0.5240 aloss:1.0027 dloss:0.9218 aloss2:4.5793 exploreP:0.0100\n",
      "Episode:913 meanR:248.9800 R:275.0000 rate:0.5500 aloss:0.9995 dloss:0.9159 aloss2:4.7802 exploreP:0.0100\n",
      "Episode:914 meanR:249.3000 R:278.0000 rate:0.5560 aloss:1.0011 dloss:0.9172 aloss2:4.6852 exploreP:0.0100\n",
      "Episode:915 meanR:249.3700 R:264.0000 rate:0.5280 aloss:1.0005 dloss:0.9136 aloss2:4.7543 exploreP:0.0100\n",
      "Episode:916 meanR:248.7600 R:281.0000 rate:0.5620 aloss:1.0020 dloss:0.9161 aloss2:4.6944 exploreP:0.0100\n",
      "Episode:917 meanR:249.6300 R:269.0000 rate:0.5380 aloss:0.9996 dloss:0.9101 aloss2:4.7853 exploreP:0.0100\n",
      "Episode:918 meanR:249.5700 R:263.0000 rate:0.5260 aloss:0.9993 dloss:0.9108 aloss2:4.8096 exploreP:0.0100\n",
      "Episode:919 meanR:249.4800 R:253.0000 rate:0.5060 aloss:0.9999 dloss:0.9148 aloss2:4.7272 exploreP:0.0100\n",
      "Episode:920 meanR:248.9900 R:130.0000 rate:0.2600 aloss:0.9993 dloss:0.9089 aloss2:4.7607 exploreP:0.0100\n",
      "Episode:921 meanR:249.0800 R:260.0000 rate:0.5200 aloss:0.9978 dloss:0.9064 aloss2:4.8502 exploreP:0.0100\n",
      "Episode:922 meanR:249.3100 R:275.0000 rate:0.5500 aloss:1.0005 dloss:0.9118 aloss2:4.7431 exploreP:0.0100\n",
      "Episode:923 meanR:250.3900 R:286.0000 rate:0.5720 aloss:0.9995 dloss:0.9100 aloss2:4.7839 exploreP:0.0100\n",
      "Episode:924 meanR:251.2900 R:359.0000 rate:0.7180 aloss:0.9984 dloss:0.9064 aloss2:4.8100 exploreP:0.0100\n",
      "Episode:925 meanR:252.2100 R:266.0000 rate:0.5320 aloss:0.9988 dloss:0.9030 aloss2:4.8406 exploreP:0.0100\n",
      "Episode:926 meanR:252.2600 R:263.0000 rate:0.5260 aloss:0.9996 dloss:0.9018 aloss2:4.8869 exploreP:0.0100\n",
      "Episode:927 meanR:252.5900 R:302.0000 rate:0.6040 aloss:0.9968 dloss:0.9023 aloss2:4.8604 exploreP:0.0100\n",
      "Episode:928 meanR:251.3600 R:143.0000 rate:0.2860 aloss:0.9971 dloss:0.8976 aloss2:4.9061 exploreP:0.0100\n",
      "Episode:929 meanR:251.2800 R:262.0000 rate:0.5240 aloss:0.9976 dloss:0.8979 aloss2:4.8918 exploreP:0.0100\n",
      "Episode:930 meanR:252.3900 R:359.0000 rate:0.7180 aloss:0.9974 dloss:0.8995 aloss2:4.9176 exploreP:0.0100\n",
      "Episode:931 meanR:252.5900 R:270.0000 rate:0.5400 aloss:0.9978 dloss:0.9015 aloss2:4.9239 exploreP:0.0100\n",
      "Episode:932 meanR:253.7600 R:369.0000 rate:0.7380 aloss:0.9983 dloss:0.8996 aloss2:4.9518 exploreP:0.0100\n",
      "Episode:933 meanR:253.5700 R:262.0000 rate:0.5240 aloss:0.9984 dloss:0.8951 aloss2:5.0298 exploreP:0.0100\n",
      "Episode:934 meanR:253.4200 R:250.0000 rate:0.5000 aloss:0.9980 dloss:0.8987 aloss2:4.8264 exploreP:0.0100\n",
      "Episode:935 meanR:253.5900 R:279.0000 rate:0.5580 aloss:0.9963 dloss:0.8958 aloss2:4.9658 exploreP:0.0100\n",
      "Episode:936 meanR:253.8100 R:278.0000 rate:0.5560 aloss:0.9980 dloss:0.8951 aloss2:4.9164 exploreP:0.0100\n",
      "Episode:937 meanR:255.4000 R:419.0000 rate:0.8380 aloss:0.9971 dloss:0.8927 aloss2:4.9966 exploreP:0.0100\n",
      "Episode:938 meanR:256.5500 R:356.0000 rate:0.7120 aloss:0.9964 dloss:0.8906 aloss2:5.0717 exploreP:0.0100\n",
      "Episode:939 meanR:257.9300 R:311.0000 rate:0.6220 aloss:0.9965 dloss:0.8899 aloss2:4.9641 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:940 meanR:257.8900 R:257.0000 rate:0.5140 aloss:0.9948 dloss:0.8905 aloss2:4.9977 exploreP:0.0100\n",
      "Episode:941 meanR:257.6900 R:241.0000 rate:0.4820 aloss:0.9945 dloss:0.8883 aloss2:5.0452 exploreP:0.0100\n",
      "Episode:942 meanR:258.8500 R:257.0000 rate:0.5140 aloss:0.9989 dloss:0.8881 aloss2:5.1239 exploreP:0.0100\n",
      "Episode:943 meanR:258.7800 R:272.0000 rate:0.5440 aloss:0.9944 dloss:0.8885 aloss2:5.0391 exploreP:0.0100\n",
      "Episode:944 meanR:258.5100 R:308.0000 rate:0.6160 aloss:0.9955 dloss:0.8882 aloss2:5.0977 exploreP:0.0100\n",
      "Episode:945 meanR:258.5100 R:264.0000 rate:0.5280 aloss:0.9951 dloss:0.8861 aloss2:5.1730 exploreP:0.0100\n",
      "Episode:946 meanR:259.6000 R:376.0000 rate:0.7520 aloss:0.9951 dloss:0.8867 aloss2:5.0452 exploreP:0.0100\n",
      "Episode:947 meanR:259.6800 R:269.0000 rate:0.5380 aloss:0.9949 dloss:0.8881 aloss2:5.0698 exploreP:0.0100\n",
      "Episode:948 meanR:259.6500 R:256.0000 rate:0.5120 aloss:0.9938 dloss:0.8867 aloss2:5.1346 exploreP:0.0100\n",
      "Episode:949 meanR:260.6300 R:233.0000 rate:0.4660 aloss:0.9948 dloss:0.8837 aloss2:5.2008 exploreP:0.0100\n",
      "Episode:950 meanR:260.9500 R:323.0000 rate:0.6460 aloss:0.9936 dloss:0.8853 aloss2:5.0900 exploreP:0.0100\n",
      "Episode:951 meanR:261.7200 R:275.0000 rate:0.5500 aloss:0.9949 dloss:0.8882 aloss2:5.1560 exploreP:0.0100\n",
      "Episode:952 meanR:262.0300 R:280.0000 rate:0.5600 aloss:0.9949 dloss:0.8873 aloss2:5.1991 exploreP:0.0100\n",
      "Episode:953 meanR:263.2400 R:374.0000 rate:0.7480 aloss:0.9948 dloss:0.8867 aloss2:5.1864 exploreP:0.0100\n",
      "Episode:954 meanR:264.1000 R:276.0000 rate:0.5520 aloss:0.9949 dloss:0.8888 aloss2:5.2177 exploreP:0.0100\n",
      "Episode:955 meanR:266.4400 R:417.0000 rate:0.8340 aloss:0.9953 dloss:0.8872 aloss2:5.2922 exploreP:0.0100\n",
      "Episode:956 meanR:267.1600 R:333.0000 rate:0.6660 aloss:0.9943 dloss:0.8877 aloss2:5.1997 exploreP:0.0100\n",
      "Episode:957 meanR:267.2600 R:201.0000 rate:0.4020 aloss:0.9945 dloss:0.8883 aloss2:5.1582 exploreP:0.0100\n",
      "Episode:958 meanR:267.2300 R:286.0000 rate:0.5720 aloss:0.9942 dloss:0.8875 aloss2:5.2852 exploreP:0.0100\n",
      "Episode:959 meanR:268.9200 R:357.0000 rate:0.7140 aloss:0.9949 dloss:0.8876 aloss2:5.3423 exploreP:0.0100\n",
      "Episode:960 meanR:269.3200 R:286.0000 rate:0.5720 aloss:0.9943 dloss:0.8851 aloss2:5.2045 exploreP:0.0100\n",
      "Episode:961 meanR:269.3000 R:239.0000 rate:0.4780 aloss:0.9955 dloss:0.8900 aloss2:5.1680 exploreP:0.0100\n",
      "Episode:962 meanR:270.6400 R:332.0000 rate:0.6640 aloss:0.9946 dloss:0.8872 aloss2:5.3048 exploreP:0.0100\n",
      "Episode:963 meanR:269.7000 R:186.0000 rate:0.3720 aloss:0.9955 dloss:0.8888 aloss2:5.1912 exploreP:0.0100\n",
      "Episode:964 meanR:269.7300 R:289.0000 rate:0.5780 aloss:0.9943 dloss:0.8894 aloss2:5.1731 exploreP:0.0100\n",
      "Episode:965 meanR:271.6100 R:354.0000 rate:0.7080 aloss:0.9941 dloss:0.8886 aloss2:5.2974 exploreP:0.0100\n",
      "Episode:966 meanR:272.3500 R:328.0000 rate:0.6560 aloss:0.9951 dloss:0.8897 aloss2:5.3321 exploreP:0.0100\n",
      "Episode:967 meanR:272.5200 R:293.0000 rate:0.5860 aloss:0.9939 dloss:0.8884 aloss2:5.3018 exploreP:0.0100\n",
      "Episode:968 meanR:272.6500 R:283.0000 rate:0.5660 aloss:0.9923 dloss:0.8897 aloss2:5.2996 exploreP:0.0100\n",
      "Episode:969 meanR:273.5300 R:286.0000 rate:0.5720 aloss:0.9958 dloss:0.8915 aloss2:5.2851 exploreP:0.0100\n",
      "Episode:970 meanR:274.8500 R:319.0000 rate:0.6380 aloss:0.9933 dloss:0.8885 aloss2:5.3668 exploreP:0.0100\n",
      "Episode:971 meanR:275.1900 R:279.0000 rate:0.5580 aloss:0.9948 dloss:0.8872 aloss2:5.3014 exploreP:0.0100\n",
      "Episode:972 meanR:275.5300 R:291.0000 rate:0.5820 aloss:0.9930 dloss:0.8887 aloss2:5.4094 exploreP:0.0100\n",
      "Episode:973 meanR:275.6800 R:263.0000 rate:0.5260 aloss:0.9930 dloss:0.8940 aloss2:5.2335 exploreP:0.0100\n",
      "Episode:974 meanR:277.1700 R:284.0000 rate:0.5680 aloss:0.9943 dloss:0.8936 aloss2:5.2837 exploreP:0.0100\n",
      "Episode:975 meanR:277.5900 R:319.0000 rate:0.6380 aloss:0.9945 dloss:0.8936 aloss2:5.3208 exploreP:0.0100\n",
      "Episode:976 meanR:278.9400 R:276.0000 rate:0.5520 aloss:0.9973 dloss:0.8961 aloss2:5.3248 exploreP:0.0100\n",
      "Episode:977 meanR:279.7600 R:348.0000 rate:0.6960 aloss:0.9941 dloss:0.8940 aloss2:5.3535 exploreP:0.0100\n",
      "Episode:978 meanR:279.9900 R:306.0000 rate:0.6120 aloss:0.9938 dloss:0.8933 aloss2:5.3172 exploreP:0.0100\n",
      "Episode:979 meanR:280.2200 R:314.0000 rate:0.6280 aloss:0.9968 dloss:0.8956 aloss2:5.3069 exploreP:0.0100\n",
      "Episode:980 meanR:280.3400 R:287.0000 rate:0.5740 aloss:0.9950 dloss:0.8979 aloss2:5.3043 exploreP:0.0100\n",
      "Episode:981 meanR:281.0300 R:325.0000 rate:0.6500 aloss:0.9944 dloss:0.8985 aloss2:5.2555 exploreP:0.0100\n",
      "Episode:982 meanR:281.3900 R:279.0000 rate:0.5580 aloss:0.9932 dloss:0.8958 aloss2:5.3354 exploreP:0.0100\n",
      "Episode:983 meanR:281.4300 R:274.0000 rate:0.5480 aloss:0.9964 dloss:0.8955 aloss2:5.3129 exploreP:0.0100\n",
      "Episode:984 meanR:281.7300 R:282.0000 rate:0.5640 aloss:0.9930 dloss:0.8961 aloss2:5.3347 exploreP:0.0100\n",
      "Episode:985 meanR:281.9100 R:281.0000 rate:0.5620 aloss:0.9953 dloss:0.8988 aloss2:5.2311 exploreP:0.0100\n",
      "Episode:986 meanR:281.8700 R:255.0000 rate:0.5100 aloss:0.9947 dloss:0.8985 aloss2:5.3329 exploreP:0.0100\n",
      "Episode:987 meanR:282.0700 R:375.0000 rate:0.7500 aloss:0.9954 dloss:0.8955 aloss2:5.3126 exploreP:0.0100\n",
      "Episode:988 meanR:281.8200 R:273.0000 rate:0.5460 aloss:0.9951 dloss:0.8972 aloss2:5.2181 exploreP:0.0100\n",
      "Episode:989 meanR:282.9000 R:352.0000 rate:0.7040 aloss:0.9943 dloss:0.8955 aloss2:5.3544 exploreP:0.0100\n",
      "Episode:990 meanR:283.8200 R:362.0000 rate:0.7240 aloss:0.9979 dloss:0.9019 aloss2:5.2160 exploreP:0.0100\n",
      "Episode:991 meanR:285.9300 R:381.0000 rate:0.7620 aloss:0.9962 dloss:0.8996 aloss2:5.2457 exploreP:0.0100\n",
      "Episode:992 meanR:286.1300 R:275.0000 rate:0.5500 aloss:0.9953 dloss:0.8992 aloss2:5.3390 exploreP:0.0100\n",
      "Episode:993 meanR:286.3500 R:276.0000 rate:0.5520 aloss:0.9971 dloss:0.9023 aloss2:5.1802 exploreP:0.0100\n",
      "Episode:994 meanR:286.5900 R:290.0000 rate:0.5800 aloss:0.9973 dloss:0.8978 aloss2:5.2498 exploreP:0.0100\n",
      "Episode:995 meanR:287.0400 R:296.0000 rate:0.5920 aloss:0.9940 dloss:0.8966 aloss2:5.2645 exploreP:0.0100\n",
      "Episode:996 meanR:287.6700 R:294.0000 rate:0.5880 aloss:0.9966 dloss:0.8959 aloss2:5.2739 exploreP:0.0100\n",
      "Episode:997 meanR:288.7300 R:299.0000 rate:0.5980 aloss:0.9957 dloss:0.8973 aloss2:5.2611 exploreP:0.0100\n",
      "Episode:998 meanR:288.6300 R:293.0000 rate:0.5860 aloss:0.9956 dloss:0.8947 aloss2:5.3410 exploreP:0.0100\n",
      "Episode:999 meanR:289.6000 R:360.0000 rate:0.7200 aloss:0.9958 dloss:0.8944 aloss2:5.3251 exploreP:0.0100\n",
      "Episode:1000 meanR:289.6200 R:259.0000 rate:0.5180 aloss:0.9950 dloss:0.8943 aloss2:5.2208 exploreP:0.0100\n",
      "Episode:1001 meanR:289.4200 R:380.0000 rate:0.7600 aloss:0.9961 dloss:0.8942 aloss2:5.2198 exploreP:0.0100\n",
      "Episode:1002 meanR:290.2800 R:357.0000 rate:0.7140 aloss:0.9940 dloss:0.8911 aloss2:5.3233 exploreP:0.0100\n",
      "Episode:1003 meanR:290.3800 R:254.0000 rate:0.5080 aloss:0.9955 dloss:0.8905 aloss2:5.2615 exploreP:0.0100\n",
      "Episode:1004 meanR:290.2400 R:272.0000 rate:0.5440 aloss:0.9939 dloss:0.8889 aloss2:5.2820 exploreP:0.0100\n",
      "Episode:1005 meanR:290.0600 R:278.0000 rate:0.5560 aloss:0.9960 dloss:0.8889 aloss2:5.3760 exploreP:0.0100\n",
      "Episode:1006 meanR:290.0900 R:269.0000 rate:0.5380 aloss:0.9954 dloss:0.8912 aloss2:5.2875 exploreP:0.0100\n",
      "Episode:1007 meanR:290.4100 R:270.0000 rate:0.5400 aloss:0.9958 dloss:0.8898 aloss2:5.3244 exploreP:0.0100\n",
      "Episode:1008 meanR:290.4800 R:298.0000 rate:0.5960 aloss:0.9953 dloss:0.8883 aloss2:5.2721 exploreP:0.0100\n",
      "Episode:1009 meanR:292.3800 R:346.0000 rate:0.6920 aloss:0.9958 dloss:0.8866 aloss2:5.3786 exploreP:0.0100\n",
      "Episode:1010 meanR:292.3100 R:280.0000 rate:0.5600 aloss:0.9965 dloss:0.8931 aloss2:5.2285 exploreP:0.0100\n",
      "Episode:1011 meanR:292.0500 R:259.0000 rate:0.5180 aloss:0.9972 dloss:0.8916 aloss2:5.2428 exploreP:0.0100\n",
      "Episode:1012 meanR:291.3500 R:192.0000 rate:0.3840 aloss:0.9978 dloss:0.8947 aloss2:5.2961 exploreP:0.0100\n",
      "Episode:1013 meanR:291.1500 R:255.0000 rate:0.5100 aloss:0.9972 dloss:0.8911 aloss2:5.4726 exploreP:0.0100\n",
      "Episode:1014 meanR:291.3300 R:296.0000 rate:0.5920 aloss:0.9952 dloss:0.8882 aloss2:5.4387 exploreP:0.0100\n",
      "Episode:1015 meanR:291.1300 R:244.0000 rate:0.4880 aloss:0.9957 dloss:0.8899 aloss2:5.2231 exploreP:0.0100\n",
      "Episode:1016 meanR:291.0000 R:268.0000 rate:0.5360 aloss:0.9929 dloss:0.8856 aloss2:5.5048 exploreP:0.0100\n",
      "Episode:1017 meanR:291.1500 R:284.0000 rate:0.5680 aloss:0.9957 dloss:0.8863 aloss2:5.3795 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1018 meanR:291.0600 R:254.0000 rate:0.5080 aloss:0.9953 dloss:0.8917 aloss2:5.4235 exploreP:0.0100\n",
      "Episode:1019 meanR:292.2200 R:369.0000 rate:0.7380 aloss:0.9947 dloss:0.8858 aloss2:5.4898 exploreP:0.0100\n",
      "Episode:1020 meanR:293.9200 R:300.0000 rate:0.6000 aloss:0.9961 dloss:0.8891 aloss2:5.3489 exploreP:0.0100\n",
      "Episode:1021 meanR:294.4300 R:311.0000 rate:0.6220 aloss:0.9953 dloss:0.8856 aloss2:5.3863 exploreP:0.0100\n",
      "Episode:1022 meanR:295.2100 R:353.0000 rate:0.7060 aloss:0.9950 dloss:0.8868 aloss2:5.3790 exploreP:0.0100\n",
      "Episode:1023 meanR:295.3100 R:296.0000 rate:0.5920 aloss:0.9957 dloss:0.8867 aloss2:5.4791 exploreP:0.0100\n",
      "Episode:1024 meanR:295.2200 R:350.0000 rate:0.7000 aloss:0.9931 dloss:0.8841 aloss2:5.4359 exploreP:0.0100\n",
      "Episode:1025 meanR:295.9500 R:339.0000 rate:0.6780 aloss:0.9942 dloss:0.8804 aloss2:5.4850 exploreP:0.0100\n",
      "Episode:1026 meanR:297.1500 R:383.0000 rate:0.7660 aloss:0.9934 dloss:0.8767 aloss2:5.6269 exploreP:0.0100\n",
      "Episode:1027 meanR:296.8000 R:267.0000 rate:0.5340 aloss:0.9911 dloss:0.8741 aloss2:5.6693 exploreP:0.0100\n",
      "Episode:1028 meanR:297.3700 R:200.0000 rate:0.4000 aloss:0.9928 dloss:0.8794 aloss2:5.4358 exploreP:0.0100\n",
      "Episode:1029 meanR:297.6100 R:286.0000 rate:0.5720 aloss:0.9926 dloss:0.8734 aloss2:5.6767 exploreP:0.0100\n",
      "Episode:1030 meanR:296.9200 R:290.0000 rate:0.5800 aloss:0.9929 dloss:0.8736 aloss2:5.5094 exploreP:0.0100\n",
      "Episode:1031 meanR:297.3900 R:317.0000 rate:0.6340 aloss:0.9926 dloss:0.8716 aloss2:5.5024 exploreP:0.0100\n",
      "Episode:1032 meanR:297.4900 R:379.0000 rate:0.7580 aloss:0.9916 dloss:0.8705 aloss2:5.5981 exploreP:0.0100\n",
      "Episode:1033 meanR:298.6700 R:380.0000 rate:0.7600 aloss:0.9920 dloss:0.8665 aloss2:5.6686 exploreP:0.0100\n",
      "Episode:1034 meanR:298.7200 R:255.0000 rate:0.5100 aloss:0.9940 dloss:0.8732 aloss2:5.4659 exploreP:0.0100\n",
      "Episode:1035 meanR:298.8300 R:290.0000 rate:0.5800 aloss:0.9911 dloss:0.8704 aloss2:5.6427 exploreP:0.0100\n",
      "Episode:1036 meanR:299.3700 R:332.0000 rate:0.6640 aloss:0.9931 dloss:0.8696 aloss2:5.6891 exploreP:0.0100\n",
      "Episode:1037 meanR:299.0600 R:388.0000 rate:0.7760 aloss:0.9919 dloss:0.8698 aloss2:5.5508 exploreP:0.0100\n",
      "Episode:1038 meanR:298.0700 R:257.0000 rate:0.5140 aloss:0.9916 dloss:0.8687 aloss2:5.6466 exploreP:0.0100\n",
      "Episode:1039 meanR:297.7100 R:275.0000 rate:0.5500 aloss:0.9900 dloss:0.8628 aloss2:5.7699 exploreP:0.0100\n",
      "Episode:1040 meanR:297.9400 R:280.0000 rate:0.5600 aloss:0.9922 dloss:0.8647 aloss2:5.6405 exploreP:0.0100\n",
      "Episode:1041 meanR:298.7000 R:317.0000 rate:0.6340 aloss:0.9911 dloss:0.8618 aloss2:5.7281 exploreP:0.0100\n",
      "Episode:1042 meanR:299.2200 R:309.0000 rate:0.6180 aloss:0.9919 dloss:0.8626 aloss2:5.7869 exploreP:0.0100\n",
      "Episode:1043 meanR:301.0400 R:454.0000 rate:0.9080 aloss:0.9903 dloss:0.8582 aloss2:5.8393 exploreP:0.0100\n",
      "Episode:1044 meanR:301.0500 R:309.0000 rate:0.6180 aloss:0.9906 dloss:0.8593 aloss2:5.7241 exploreP:0.0100\n",
      "Episode:1045 meanR:302.7200 R:431.0000 rate:0.8620 aloss:0.9899 dloss:0.8580 aloss2:5.8170 exploreP:0.0100\n",
      "Episode:1046 meanR:302.6000 R:364.0000 rate:0.7280 aloss:0.9886 dloss:0.8520 aloss2:5.9268 exploreP:0.0100\n",
      "Episode:1047 meanR:303.3100 R:340.0000 rate:0.6800 aloss:0.9893 dloss:0.8504 aloss2:5.8555 exploreP:0.0100\n",
      "Episode:1048 meanR:304.3000 R:355.0000 rate:0.7100 aloss:0.9893 dloss:0.8499 aloss2:5.9712 exploreP:0.0100\n",
      "Episode:1049 meanR:304.8100 R:284.0000 rate:0.5680 aloss:0.9873 dloss:0.8471 aloss2:5.9909 exploreP:0.0100\n",
      "Episode:1050 meanR:304.6600 R:308.0000 rate:0.6160 aloss:0.9881 dloss:0.8457 aloss2:6.0596 exploreP:0.0100\n",
      "Episode:1051 meanR:305.3300 R:342.0000 rate:0.6840 aloss:0.9866 dloss:0.8430 aloss2:6.1826 exploreP:0.0100\n",
      "Episode:1052 meanR:305.3500 R:282.0000 rate:0.5640 aloss:0.9883 dloss:0.8444 aloss2:5.9655 exploreP:0.0100\n",
      "Episode:1053 meanR:304.2400 R:263.0000 rate:0.5260 aloss:0.9860 dloss:0.8394 aloss2:6.0907 exploreP:0.0100\n",
      "Episode:1054 meanR:305.6300 R:415.0000 rate:0.8300 aloss:0.9838 dloss:0.8373 aloss2:6.1735 exploreP:0.0100\n",
      "Episode:1055 meanR:304.5800 R:312.0000 rate:0.6240 aloss:0.9848 dloss:0.8343 aloss2:6.2108 exploreP:0.0100\n",
      "Episode:1056 meanR:304.9900 R:374.0000 rate:0.7480 aloss:0.9858 dloss:0.8329 aloss2:6.2025 exploreP:0.0100\n",
      "Episode:1057 meanR:305.5000 R:252.0000 rate:0.5040 aloss:0.9851 dloss:0.8304 aloss2:6.2997 exploreP:0.0100\n",
      "Episode:1058 meanR:304.6900 R:205.0000 rate:0.4100 aloss:0.9817 dloss:0.8249 aloss2:6.2877 exploreP:0.0100\n",
      "Episode:1059 meanR:304.0900 R:297.0000 rate:0.5940 aloss:0.9857 dloss:0.8305 aloss2:6.1435 exploreP:0.0100\n",
      "Episode:1060 meanR:304.9700 R:374.0000 rate:0.7480 aloss:0.9836 dloss:0.8250 aloss2:6.3226 exploreP:0.0100\n",
      "Episode:1061 meanR:305.5200 R:294.0000 rate:0.5880 aloss:0.9813 dloss:0.8226 aloss2:6.4743 exploreP:0.0100\n",
      "Episode:1062 meanR:305.3500 R:315.0000 rate:0.6300 aloss:0.9831 dloss:0.8206 aloss2:6.3689 exploreP:0.0100\n",
      "Episode:1063 meanR:306.1400 R:265.0000 rate:0.5300 aloss:0.9814 dloss:0.8162 aloss2:6.4657 exploreP:0.0100\n",
      "Episode:1064 meanR:305.8400 R:259.0000 rate:0.5180 aloss:0.9811 dloss:0.8160 aloss2:6.5808 exploreP:0.0100\n",
      "Episode:1065 meanR:305.0400 R:274.0000 rate:0.5480 aloss:0.9785 dloss:0.8152 aloss2:6.5852 exploreP:0.0100\n",
      "Episode:1066 meanR:305.4900 R:373.0000 rate:0.7460 aloss:0.9803 dloss:0.8134 aloss2:6.5820 exploreP:0.0100\n",
      "Episode:1067 meanR:305.3700 R:281.0000 rate:0.5620 aloss:0.9797 dloss:0.8091 aloss2:6.7029 exploreP:0.0100\n",
      "Episode:1068 meanR:306.1500 R:361.0000 rate:0.7220 aloss:0.9788 dloss:0.8071 aloss2:6.7298 exploreP:0.0100\n",
      "Episode:1069 meanR:307.1500 R:386.0000 rate:0.7720 aloss:0.9780 dloss:0.8029 aloss2:6.6182 exploreP:0.0100\n",
      "Episode:1070 meanR:306.9100 R:295.0000 rate:0.5900 aloss:0.9781 dloss:0.7996 aloss2:6.7701 exploreP:0.0100\n",
      "Episode:1071 meanR:307.0100 R:289.0000 rate:0.5780 aloss:0.9740 dloss:0.7946 aloss2:7.0018 exploreP:0.0100\n",
      "Episode:1072 meanR:307.2700 R:317.0000 rate:0.6340 aloss:0.9769 dloss:0.7965 aloss2:6.7123 exploreP:0.0100\n",
      "Episode:1073 meanR:308.6600 R:402.0000 rate:0.8040 aloss:0.9752 dloss:0.7941 aloss2:6.9140 exploreP:0.0100\n",
      "Episode:1074 meanR:309.0800 R:326.0000 rate:0.6520 aloss:0.9774 dloss:0.7956 aloss2:6.9574 exploreP:0.0100\n",
      "Episode:1075 meanR:308.5200 R:263.0000 rate:0.5260 aloss:0.9765 dloss:0.7974 aloss2:6.6943 exploreP:0.0100\n",
      "Episode:1076 meanR:309.4200 R:366.0000 rate:0.7320 aloss:0.9785 dloss:0.8012 aloss2:6.8375 exploreP:0.0100\n",
      "Episode:1077 meanR:310.0900 R:415.0000 rate:0.8300 aloss:0.9758 dloss:0.7999 aloss2:6.8859 exploreP:0.0100\n",
      "Episode:1078 meanR:309.9200 R:289.0000 rate:0.5780 aloss:0.9772 dloss:0.7955 aloss2:6.7876 exploreP:0.0100\n",
      "Episode:1079 meanR:310.4100 R:363.0000 rate:0.7260 aloss:0.9765 dloss:0.7950 aloss2:6.8141 exploreP:0.0100\n",
      "Episode:1080 meanR:311.0100 R:347.0000 rate:0.6940 aloss:0.9767 dloss:0.7949 aloss2:6.8038 exploreP:0.0100\n",
      "Episode:1081 meanR:310.4900 R:273.0000 rate:0.5460 aloss:0.9771 dloss:0.7934 aloss2:6.8069 exploreP:0.0100\n",
      "Episode:1082 meanR:310.7500 R:305.0000 rate:0.6100 aloss:0.9794 dloss:0.7959 aloss2:6.8035 exploreP:0.0100\n",
      "Episode:1083 meanR:311.9200 R:391.0000 rate:0.7820 aloss:0.9765 dloss:0.7916 aloss2:6.8795 exploreP:0.0100\n",
      "Episode:1084 meanR:312.9600 R:386.0000 rate:0.7720 aloss:0.9758 dloss:0.7886 aloss2:6.8306 exploreP:0.0100\n",
      "Episode:1085 meanR:313.7500 R:360.0000 rate:0.7200 aloss:0.9756 dloss:0.7862 aloss2:6.8471 exploreP:0.0100\n",
      "Episode:1086 meanR:313.6600 R:246.0000 rate:0.4920 aloss:0.9736 dloss:0.7802 aloss2:6.8224 exploreP:0.0100\n",
      "Episode:1087 meanR:313.4200 R:351.0000 rate:0.7020 aloss:0.9728 dloss:0.7769 aloss2:6.8683 exploreP:0.0100\n",
      "Episode:1088 meanR:313.8000 R:311.0000 rate:0.6220 aloss:0.9756 dloss:0.7781 aloss2:6.8589 exploreP:0.0100\n",
      "Episode:1089 meanR:313.3700 R:309.0000 rate:0.6180 aloss:0.9734 dloss:0.7786 aloss2:6.9745 exploreP:0.0100\n",
      "Episode:1090 meanR:314.7500 R:500.0000 rate:1.0000 aloss:0.9731 dloss:0.7720 aloss2:7.0077 exploreP:0.0100\n",
      "Episode:1091 meanR:313.0400 R:210.0000 rate:0.4200 aloss:0.9712 dloss:0.7662 aloss2:7.1463 exploreP:0.0100\n",
      "Episode:1092 meanR:313.9200 R:363.0000 rate:0.7260 aloss:0.9703 dloss:0.7689 aloss2:7.0822 exploreP:0.0100\n",
      "Episode:1093 meanR:314.2500 R:309.0000 rate:0.6180 aloss:0.9714 dloss:0.7658 aloss2:6.9975 exploreP:0.0100\n",
      "Episode:1094 meanR:314.0100 R:266.0000 rate:0.5320 aloss:0.9705 dloss:0.7642 aloss2:7.0278 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1095 meanR:314.3700 R:332.0000 rate:0.6640 aloss:0.9695 dloss:0.7646 aloss2:7.1550 exploreP:0.0100\n",
      "Episode:1096 meanR:314.3000 R:287.0000 rate:0.5740 aloss:0.9716 dloss:0.7646 aloss2:7.1050 exploreP:0.0100\n",
      "Episode:1097 meanR:314.7100 R:340.0000 rate:0.6800 aloss:0.9729 dloss:0.7658 aloss2:7.2161 exploreP:0.0100\n",
      "Episode:1098 meanR:314.3400 R:256.0000 rate:0.5120 aloss:0.9693 dloss:0.7599 aloss2:7.2301 exploreP:0.0100\n",
      "Episode:1099 meanR:313.8700 R:313.0000 rate:0.6260 aloss:0.9669 dloss:0.7569 aloss2:7.2252 exploreP:0.0100\n",
      "Episode:1100 meanR:314.0300 R:275.0000 rate:0.5500 aloss:0.9698 dloss:0.7587 aloss2:7.2413 exploreP:0.0100\n",
      "Episode:1101 meanR:312.9400 R:271.0000 rate:0.5420 aloss:0.9705 dloss:0.7611 aloss2:7.1733 exploreP:0.0100\n",
      "Episode:1102 meanR:312.3300 R:296.0000 rate:0.5920 aloss:0.9693 dloss:0.7603 aloss2:7.3453 exploreP:0.0100\n",
      "Episode:1103 meanR:312.3300 R:254.0000 rate:0.5080 aloss:0.9705 dloss:0.7636 aloss2:7.1618 exploreP:0.0100\n",
      "Episode:1104 meanR:312.8300 R:322.0000 rate:0.6440 aloss:0.9703 dloss:0.7624 aloss2:7.3381 exploreP:0.0100\n",
      "Episode:1105 meanR:313.0700 R:302.0000 rate:0.6040 aloss:0.9686 dloss:0.7601 aloss2:7.2901 exploreP:0.0100\n",
      "Episode:1106 meanR:313.6200 R:324.0000 rate:0.6480 aloss:0.9683 dloss:0.7612 aloss2:7.4148 exploreP:0.0100\n",
      "Episode:1107 meanR:313.8100 R:289.0000 rate:0.5780 aloss:0.9706 dloss:0.7627 aloss2:7.3512 exploreP:0.0100\n",
      "Episode:1108 meanR:313.3200 R:249.0000 rate:0.4980 aloss:0.9679 dloss:0.7581 aloss2:7.4061 exploreP:0.0100\n",
      "Episode:1109 meanR:314.0600 R:420.0000 rate:0.8400 aloss:0.9678 dloss:0.7553 aloss2:7.5367 exploreP:0.0100\n",
      "Episode:1110 meanR:314.3400 R:308.0000 rate:0.6160 aloss:0.9702 dloss:0.7581 aloss2:7.4146 exploreP:0.0100\n",
      "Episode:1111 meanR:314.2400 R:249.0000 rate:0.4980 aloss:0.9690 dloss:0.7599 aloss2:7.4087 exploreP:0.0100\n",
      "Episode:1112 meanR:315.2400 R:292.0000 rate:0.5840 aloss:0.9704 dloss:0.7650 aloss2:7.5551 exploreP:0.0100\n",
      "Episode:1113 meanR:316.3400 R:365.0000 rate:0.7300 aloss:0.9695 dloss:0.7618 aloss2:7.5492 exploreP:0.0100\n",
      "Episode:1114 meanR:316.3900 R:301.0000 rate:0.6020 aloss:0.9703 dloss:0.7556 aloss2:7.5566 exploreP:0.0100\n",
      "Episode:1115 meanR:317.5200 R:357.0000 rate:0.7140 aloss:0.9681 dloss:0.7536 aloss2:7.6580 exploreP:0.0100\n",
      "Episode:1116 meanR:317.6500 R:281.0000 rate:0.5620 aloss:0.9681 dloss:0.7554 aloss2:7.6042 exploreP:0.0100\n",
      "Episode:1117 meanR:318.3100 R:350.0000 rate:0.7000 aloss:0.9690 dloss:0.7549 aloss2:7.5446 exploreP:0.0100\n",
      "Episode:1118 meanR:318.9100 R:314.0000 rate:0.6280 aloss:0.9693 dloss:0.7513 aloss2:7.6952 exploreP:0.0100\n",
      "Episode:1119 meanR:318.2700 R:305.0000 rate:0.6100 aloss:0.9664 dloss:0.7498 aloss2:7.6488 exploreP:0.0100\n",
      "Episode:1120 meanR:318.4400 R:317.0000 rate:0.6340 aloss:0.9707 dloss:0.7564 aloss2:7.8348 exploreP:0.0100\n",
      "Episode:1121 meanR:318.4500 R:312.0000 rate:0.6240 aloss:0.9655 dloss:0.7544 aloss2:7.9206 exploreP:0.0100\n",
      "Episode:1122 meanR:317.5600 R:264.0000 rate:0.5280 aloss:0.9683 dloss:0.7562 aloss2:7.8474 exploreP:0.0100\n",
      "Episode:1123 meanR:318.1400 R:354.0000 rate:0.7080 aloss:0.9695 dloss:0.7497 aloss2:7.7703 exploreP:0.0100\n",
      "Episode:1124 meanR:317.3100 R:267.0000 rate:0.5340 aloss:0.9683 dloss:0.7569 aloss2:7.8856 exploreP:0.0100\n",
      "Episode:1125 meanR:316.3600 R:244.0000 rate:0.4880 aloss:0.9681 dloss:0.7529 aloss2:7.8535 exploreP:0.0100\n",
      "Episode:1126 meanR:315.0800 R:255.0000 rate:0.5100 aloss:0.9660 dloss:0.7474 aloss2:7.8411 exploreP:0.0100\n",
      "Episode:1127 meanR:315.9300 R:352.0000 rate:0.7040 aloss:0.9686 dloss:0.7454 aloss2:7.8576 exploreP:0.0100\n",
      "Episode:1128 meanR:316.8900 R:296.0000 rate:0.5920 aloss:0.9644 dloss:0.7524 aloss2:8.0955 exploreP:0.0100\n",
      "Episode:1129 meanR:316.4900 R:246.0000 rate:0.4920 aloss:0.9627 dloss:0.7476 aloss2:7.8760 exploreP:0.0100\n",
      "Episode:1130 meanR:316.0100 R:242.0000 rate:0.4840 aloss:0.9686 dloss:0.7501 aloss2:7.7499 exploreP:0.0100\n",
      "Episode:1131 meanR:315.7400 R:290.0000 rate:0.5800 aloss:0.9668 dloss:0.7471 aloss2:7.8476 exploreP:0.0100\n",
      "Episode:1132 meanR:315.3200 R:337.0000 rate:0.6740 aloss:0.9669 dloss:0.7520 aloss2:7.9990 exploreP:0.0100\n",
      "Episode:1133 meanR:314.6800 R:316.0000 rate:0.6320 aloss:0.9677 dloss:0.7546 aloss2:7.7869 exploreP:0.0100\n",
      "Episode:1134 meanR:314.9000 R:277.0000 rate:0.5540 aloss:0.9677 dloss:0.7485 aloss2:7.9666 exploreP:0.0100\n",
      "Episode:1135 meanR:314.7400 R:274.0000 rate:0.5480 aloss:0.9659 dloss:0.7495 aloss2:8.0333 exploreP:0.0100\n",
      "Episode:1136 meanR:314.0200 R:260.0000 rate:0.5200 aloss:0.9657 dloss:0.7486 aloss2:8.0946 exploreP:0.0100\n",
      "Episode:1137 meanR:313.3300 R:319.0000 rate:0.6380 aloss:0.9703 dloss:0.7531 aloss2:7.8388 exploreP:0.0100\n",
      "Episode:1138 meanR:313.3300 R:257.0000 rate:0.5140 aloss:0.9682 dloss:0.7482 aloss2:7.9397 exploreP:0.0100\n",
      "Episode:1139 meanR:313.6700 R:309.0000 rate:0.6180 aloss:0.9672 dloss:0.7494 aloss2:7.9171 exploreP:0.0100\n",
      "Episode:1140 meanR:313.9100 R:304.0000 rate:0.6080 aloss:0.9675 dloss:0.7504 aloss2:7.8317 exploreP:0.0100\n",
      "Episode:1141 meanR:314.8200 R:408.0000 rate:0.8160 aloss:0.9682 dloss:0.7538 aloss2:7.9082 exploreP:0.0100\n",
      "Episode:1142 meanR:314.9500 R:322.0000 rate:0.6440 aloss:0.9678 dloss:0.7548 aloss2:7.9676 exploreP:0.0100\n",
      "Episode:1143 meanR:313.0800 R:267.0000 rate:0.5340 aloss:0.9673 dloss:0.7410 aloss2:7.7210 exploreP:0.0100\n",
      "Episode:1144 meanR:312.4000 R:241.0000 rate:0.4820 aloss:0.9680 dloss:0.7381 aloss2:7.7283 exploreP:0.0100\n",
      "Episode:1145 meanR:310.0500 R:196.0000 rate:0.3920 aloss:0.9691 dloss:0.7445 aloss2:7.8126 exploreP:0.0100\n",
      "Episode:1146 meanR:309.4900 R:308.0000 rate:0.6160 aloss:0.9663 dloss:0.7479 aloss2:7.9097 exploreP:0.0100\n",
      "Episode:1147 meanR:308.7400 R:265.0000 rate:0.5300 aloss:0.9675 dloss:0.7423 aloss2:7.6941 exploreP:0.0100\n",
      "Episode:1148 meanR:308.3000 R:311.0000 rate:0.6220 aloss:0.9687 dloss:0.7418 aloss2:7.8271 exploreP:0.0100\n",
      "Episode:1149 meanR:307.8800 R:242.0000 rate:0.4840 aloss:0.9677 dloss:0.7457 aloss2:7.8577 exploreP:0.0100\n",
      "Episode:1150 meanR:307.5200 R:272.0000 rate:0.5440 aloss:0.9689 dloss:0.7454 aloss2:8.0193 exploreP:0.0100\n",
      "Episode:1151 meanR:307.7500 R:365.0000 rate:0.7300 aloss:0.9677 dloss:0.7410 aloss2:7.7598 exploreP:0.0100\n",
      "Episode:1152 meanR:307.7600 R:283.0000 rate:0.5660 aloss:0.9664 dloss:0.7485 aloss2:8.0546 exploreP:0.0100\n",
      "Episode:1153 meanR:307.9500 R:282.0000 rate:0.5640 aloss:0.9645 dloss:0.7421 aloss2:8.0171 exploreP:0.0100\n",
      "Episode:1154 meanR:306.7400 R:294.0000 rate:0.5880 aloss:0.9661 dloss:0.7417 aloss2:7.8676 exploreP:0.0100\n",
      "Episode:1155 meanR:307.3300 R:371.0000 rate:0.7420 aloss:0.9675 dloss:0.7421 aloss2:8.0836 exploreP:0.0100\n",
      "Episode:1156 meanR:306.3700 R:278.0000 rate:0.5560 aloss:0.9654 dloss:0.7354 aloss2:7.9260 exploreP:0.0100\n",
      "Episode:1157 meanR:307.7700 R:392.0000 rate:0.7840 aloss:0.9668 dloss:0.7353 aloss2:7.9614 exploreP:0.0100\n",
      "Episode:1158 meanR:309.2800 R:356.0000 rate:0.7120 aloss:0.9662 dloss:0.7362 aloss2:7.9544 exploreP:0.0100\n",
      "Episode:1159 meanR:309.8600 R:355.0000 rate:0.7100 aloss:0.9650 dloss:0.7403 aloss2:8.0895 exploreP:0.0100\n",
      "Episode:1160 meanR:309.9000 R:378.0000 rate:0.7560 aloss:0.9656 dloss:0.7333 aloss2:7.9653 exploreP:0.0100\n",
      "Episode:1161 meanR:309.8400 R:288.0000 rate:0.5760 aloss:0.9670 dloss:0.7337 aloss2:8.0748 exploreP:0.0100\n",
      "Episode:1162 meanR:310.4500 R:376.0000 rate:0.7520 aloss:0.9634 dloss:0.7370 aloss2:8.1272 exploreP:0.0100\n",
      "Episode:1163 meanR:311.4800 R:368.0000 rate:0.7360 aloss:0.9645 dloss:0.7310 aloss2:7.9556 exploreP:0.0100\n",
      "Episode:1164 meanR:311.8300 R:294.0000 rate:0.5880 aloss:0.9640 dloss:0.7294 aloss2:8.1347 exploreP:0.0100\n",
      "Episode:1165 meanR:312.8800 R:379.0000 rate:0.7580 aloss:0.9646 dloss:0.7306 aloss2:8.0668 exploreP:0.0100\n",
      "Episode:1166 meanR:311.7800 R:263.0000 rate:0.5260 aloss:0.9661 dloss:0.7314 aloss2:7.9790 exploreP:0.0100\n",
      "Episode:1167 meanR:311.5200 R:255.0000 rate:0.5100 aloss:0.9666 dloss:0.7333 aloss2:8.0501 exploreP:0.0100\n",
      "Episode:1168 meanR:311.4700 R:356.0000 rate:0.7120 aloss:0.9627 dloss:0.7279 aloss2:8.0710 exploreP:0.0100\n",
      "Episode:1169 meanR:311.2000 R:359.0000 rate:0.7180 aloss:0.9649 dloss:0.7275 aloss2:8.1697 exploreP:0.0100\n",
      "Episode:1170 meanR:311.3700 R:312.0000 rate:0.6240 aloss:0.9646 dloss:0.7254 aloss2:8.1084 exploreP:0.0100\n",
      "Episode:1171 meanR:311.2200 R:274.0000 rate:0.5480 aloss:0.9637 dloss:0.7291 aloss2:8.1347 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1172 meanR:311.3900 R:334.0000 rate:0.6680 aloss:0.9630 dloss:0.7319 aloss2:8.1582 exploreP:0.0100\n",
      "Episode:1173 meanR:310.0300 R:266.0000 rate:0.5320 aloss:0.9646 dloss:0.7313 aloss2:8.1835 exploreP:0.0100\n",
      "Episode:1174 meanR:309.5100 R:274.0000 rate:0.5480 aloss:0.9645 dloss:0.7344 aloss2:8.3279 exploreP:0.0100\n",
      "Episode:1175 meanR:310.7000 R:382.0000 rate:0.7640 aloss:0.9633 dloss:0.7270 aloss2:8.2965 exploreP:0.0100\n",
      "Episode:1176 meanR:310.7500 R:371.0000 rate:0.7420 aloss:0.9647 dloss:0.7256 aloss2:8.1599 exploreP:0.0100\n",
      "Episode:1177 meanR:309.2300 R:263.0000 rate:0.5260 aloss:0.9643 dloss:0.7305 aloss2:8.2854 exploreP:0.0100\n",
      "Episode:1178 meanR:310.1100 R:377.0000 rate:0.7540 aloss:0.9614 dloss:0.7193 aloss2:8.2889 exploreP:0.0100\n",
      "Episode:1179 meanR:308.9300 R:245.0000 rate:0.4900 aloss:0.9650 dloss:0.7257 aloss2:8.4016 exploreP:0.0100\n",
      "Episode:1180 meanR:307.9000 R:244.0000 rate:0.4880 aloss:0.9638 dloss:0.7260 aloss2:8.5095 exploreP:0.0100\n",
      "Episode:1181 meanR:307.8800 R:271.0000 rate:0.5420 aloss:0.9612 dloss:0.7225 aloss2:8.4584 exploreP:0.0100\n",
      "Episode:1182 meanR:307.7500 R:292.0000 rate:0.5840 aloss:0.9614 dloss:0.7204 aloss2:8.4404 exploreP:0.0100\n",
      "Episode:1183 meanR:307.2900 R:345.0000 rate:0.6900 aloss:0.9617 dloss:0.7187 aloss2:8.4809 exploreP:0.0100\n",
      "Episode:1184 meanR:306.1000 R:267.0000 rate:0.5340 aloss:0.9612 dloss:0.7192 aloss2:8.4499 exploreP:0.0100\n",
      "Episode:1185 meanR:305.2100 R:271.0000 rate:0.5420 aloss:0.9588 dloss:0.7079 aloss2:8.4768 exploreP:0.0100\n",
      "Episode:1186 meanR:305.8700 R:312.0000 rate:0.6240 aloss:0.9603 dloss:0.7109 aloss2:8.5239 exploreP:0.0100\n",
      "Episode:1187 meanR:305.0500 R:269.0000 rate:0.5380 aloss:0.9607 dloss:0.7185 aloss2:8.5784 exploreP:0.0100\n",
      "Episode:1188 meanR:304.6600 R:272.0000 rate:0.5440 aloss:0.9582 dloss:0.7109 aloss2:8.6257 exploreP:0.0100\n",
      "Episode:1189 meanR:304.4900 R:292.0000 rate:0.5840 aloss:0.9592 dloss:0.7120 aloss2:8.7589 exploreP:0.0100\n",
      "Episode:1190 meanR:303.0700 R:358.0000 rate:0.7160 aloss:0.9598 dloss:0.7107 aloss2:8.5997 exploreP:0.0100\n",
      "Episode:1191 meanR:303.4100 R:244.0000 rate:0.4880 aloss:0.9608 dloss:0.7165 aloss2:8.6921 exploreP:0.0100\n",
      "Episode:1192 meanR:302.5800 R:280.0000 rate:0.5600 aloss:0.9606 dloss:0.7153 aloss2:8.6846 exploreP:0.0100\n",
      "Episode:1193 meanR:301.8700 R:238.0000 rate:0.4760 aloss:0.9595 dloss:0.7087 aloss2:8.6374 exploreP:0.0100\n",
      "Episode:1194 meanR:302.0600 R:285.0000 rate:0.5700 aloss:0.9602 dloss:0.7124 aloss2:8.7690 exploreP:0.0100\n",
      "Episode:1195 meanR:301.3800 R:264.0000 rate:0.5280 aloss:0.9610 dloss:0.7150 aloss2:8.6817 exploreP:0.0100\n",
      "Episode:1196 meanR:301.3900 R:288.0000 rate:0.5760 aloss:0.9591 dloss:0.7138 aloss2:8.8210 exploreP:0.0100\n",
      "Episode:1197 meanR:300.8300 R:284.0000 rate:0.5680 aloss:0.9594 dloss:0.7074 aloss2:8.8029 exploreP:0.0100\n",
      "Episode:1198 meanR:302.6400 R:437.0000 rate:0.8740 aloss:0.9583 dloss:0.7090 aloss2:8.7921 exploreP:0.0100\n",
      "Episode:1199 meanR:302.9700 R:346.0000 rate:0.6920 aloss:0.9593 dloss:0.7041 aloss2:8.8017 exploreP:0.0100\n",
      "Episode:1200 meanR:303.2900 R:307.0000 rate:0.6140 aloss:0.9577 dloss:0.6966 aloss2:8.7569 exploreP:0.0100\n",
      "Episode:1201 meanR:303.6300 R:305.0000 rate:0.6100 aloss:0.9585 dloss:0.7115 aloss2:8.8954 exploreP:0.0100\n",
      "Episode:1202 meanR:304.3300 R:366.0000 rate:0.7320 aloss:0.9575 dloss:0.7004 aloss2:8.8860 exploreP:0.0100\n",
      "Episode:1203 meanR:304.2700 R:248.0000 rate:0.4960 aloss:0.9605 dloss:0.6995 aloss2:8.8418 exploreP:0.0100\n",
      "Episode:1204 meanR:303.5300 R:248.0000 rate:0.4960 aloss:0.9566 dloss:0.7030 aloss2:8.8956 exploreP:0.0100\n",
      "Episode:1205 meanR:304.3800 R:387.0000 rate:0.7740 aloss:0.9578 dloss:0.7011 aloss2:8.8936 exploreP:0.0100\n",
      "Episode:1206 meanR:304.2500 R:311.0000 rate:0.6220 aloss:0.9587 dloss:0.7004 aloss2:8.9423 exploreP:0.0100\n",
      "Episode:1207 meanR:304.9100 R:355.0000 rate:0.7100 aloss:0.9588 dloss:0.7031 aloss2:9.0836 exploreP:0.0100\n",
      "Episode:1208 meanR:305.9800 R:356.0000 rate:0.7120 aloss:0.9566 dloss:0.6952 aloss2:8.8962 exploreP:0.0100\n",
      "Episode:1209 meanR:306.7500 R:497.0000 rate:0.9940 aloss:0.9590 dloss:0.6956 aloss2:9.0041 exploreP:0.0100\n",
      "Episode:1210 meanR:307.8500 R:418.0000 rate:0.8360 aloss:0.9568 dloss:0.6968 aloss2:8.9835 exploreP:0.0100\n",
      "Episode:1211 meanR:308.6000 R:324.0000 rate:0.6480 aloss:0.9574 dloss:0.6899 aloss2:9.1369 exploreP:0.0100\n",
      "Episode:1212 meanR:309.4300 R:375.0000 rate:0.7500 aloss:0.9569 dloss:0.6941 aloss2:9.1994 exploreP:0.0100\n",
      "Episode:1213 meanR:309.6000 R:382.0000 rate:0.7640 aloss:0.9568 dloss:0.6957 aloss2:9.1420 exploreP:0.0100\n",
      "Episode:1214 meanR:309.1900 R:260.0000 rate:0.5200 aloss:0.9584 dloss:0.6898 aloss2:9.0841 exploreP:0.0100\n",
      "Episode:1215 meanR:308.6200 R:300.0000 rate:0.6000 aloss:0.9561 dloss:0.6920 aloss2:9.2528 exploreP:0.0100\n",
      "Episode:1216 meanR:309.7900 R:398.0000 rate:0.7960 aloss:0.9571 dloss:0.6860 aloss2:9.1049 exploreP:0.0100\n",
      "Episode:1217 meanR:309.9500 R:366.0000 rate:0.7320 aloss:0.9575 dloss:0.6853 aloss2:9.2051 exploreP:0.0100\n",
      "Episode:1218 meanR:311.3700 R:456.0000 rate:0.9120 aloss:0.9576 dloss:0.6895 aloss2:9.1949 exploreP:0.0100\n",
      "Episode:1219 meanR:311.0600 R:274.0000 rate:0.5480 aloss:0.9567 dloss:0.6781 aloss2:9.3037 exploreP:0.0100\n",
      "Episode:1220 meanR:311.6600 R:377.0000 rate:0.7540 aloss:0.9582 dloss:0.6900 aloss2:9.3771 exploreP:0.0100\n",
      "Episode:1221 meanR:312.4800 R:394.0000 rate:0.7880 aloss:0.9565 dloss:0.6848 aloss2:9.2942 exploreP:0.0100\n",
      "Episode:1222 meanR:313.9700 R:413.0000 rate:0.8260 aloss:0.9569 dloss:0.6731 aloss2:9.2977 exploreP:0.0100\n",
      "Episode:1223 meanR:313.8900 R:346.0000 rate:0.6920 aloss:0.9571 dloss:0.6866 aloss2:9.4707 exploreP:0.0100\n",
      "Episode:1224 meanR:315.7700 R:455.0000 rate:0.9100 aloss:0.9558 dloss:0.6842 aloss2:9.4679 exploreP:0.0100\n",
      "Episode:1225 meanR:316.2500 R:292.0000 rate:0.5840 aloss:0.9584 dloss:0.6770 aloss2:9.4340 exploreP:0.0100\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list = [], []\n",
    "# aloss_list, dloss_list, aloss2_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0 # each episode\n",
    "        aloss_batch, dloss_batch, aloss2_batch = [], [], []\n",
    "        state = env.reset() # each episode\n",
    "        num_step = 0 # each episode\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            rate = -1\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done), rate])\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            # Rating the memory\n",
    "            if done is True:\n",
    "                rate = total_reward/500 # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.buffer[-1-idx][-1] == -1: # double-check the landmark/marked indexes\n",
    "                        memory.buffer[-1-idx][-1] = rate # rate the trajectory/data\n",
    "                        \n",
    "            # Training with the maxrated minibatch\n",
    "            batch = memory.buffer\n",
    "            #for idx in range(memory_size// batch_size):\n",
    "            while True:\n",
    "                idx = np.random.choice(np.arange(memory_size// batch_size))\n",
    "                states = np.array([each[0] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                actions = np.array([each[1] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                next_states = np.array([each[2] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                rewards = np.array([each[3] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                dones = np.array([each[4] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                rates = np.array([each[5] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "                states = states[rates >= np.max(rates)]\n",
    "                actions = actions[rates >= np.max(rates)]\n",
    "                next_states = next_states[rates >= np.max(rates)]\n",
    "                rewards = rewards[rates >= np.max(rates)]\n",
    "                dones = dones[rates >= np.max(rates)]\n",
    "                rates = rates[rates >= np.max(rates)]\n",
    "                if np.count_nonzero(dones)==1 and len(dones) >= 1 and np.max(rates) > 0:\n",
    "                    # print('np.count_nonzero(dones)==1 and len(dones) >= 1 and np.max(rates) > 0: ', \n",
    "                    #       np.count_nonzero(dones), len(dones), np.max(rates))\n",
    "                    break\n",
    "            if np.count_nonzero(dones)!=1 and len(dones) < 1 and np.max(rates) <= 0:\n",
    "                print(np.count_nonzero(dones), len(dones), np.max(rates))\n",
    "                break\n",
    "            aloss, _ = sess.run([model.a_loss, model.a_opt],\n",
    "                                feed_dict = {model.states: states, \n",
    "                                            model.actions: actions,\n",
    "                                            model.next_states: next_states,\n",
    "                                            model.rewards: rewards,\n",
    "                                            model.dones: dones,\n",
    "                                            model.rates: rates})\n",
    "            dloss, _ = sess.run([model.d_loss, model.d_opt],\n",
    "                                  feed_dict = {model.states: states, \n",
    "                                               model.actions: actions,\n",
    "                                               model.next_states: next_states,\n",
    "                                               model.rewards: rewards,\n",
    "                                               model.dones: dones,\n",
    "                                               model.rates: rates})\n",
    "            aloss2, _= sess.run([model.a_loss2, model.a_opt2], \n",
    "                                 feed_dict = {model.states: states, \n",
    "                                              model.actions: actions,\n",
    "                                              model.next_states: next_states,\n",
    "                                              model.rewards: rewards,\n",
    "                                              model.dones: dones,\n",
    "                                              model.rates: rates})\n",
    "            # print('dones:', \n",
    "            #       len(dones), np.count_nonzero(dones), \n",
    "            #       len(dones1), np.count_nonzero(dones1), \n",
    "            #       len(dones2), np.count_nonzero(dones2))\n",
    "            aloss_batch.append(aloss)\n",
    "            dloss_batch.append(dloss)\n",
    "            aloss2_batch.append(aloss2)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'aloss:{:.4f}'.format(np.mean(aloss_batch)),\n",
    "              'dloss:{:.4f}'.format(np.mean(dloss_batch)),\n",
    "              'aloss2:{:.4f}'.format(np.mean(aloss2_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        # gloss_list.append([ep, np.mean(gloss_batch)])\n",
    "        # dloss_list.append([ep, np.mean(dloss_batch)])\n",
    "        \n",
    "        # Break episode/epoch loop\n",
    "        ## Option 1: Solve the First Version\n",
    "        #The task is episodic, and in order to solve the environment, \n",
    "        #your agent must get an average score of +30 over 100 consecutive episodes.\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps, arr = np.array(dloss_list).T\n",
    "# smoothed_arr = running_mean(arr, 10)\n",
    "# plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "# plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 481.0\n",
      "total_reward: 481.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print('total_reward: {}'.format(total_reward))\n",
    "                break\n",
    "                \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

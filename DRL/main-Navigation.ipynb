{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# env = UnityEnvironment(file_name=\"/home/arasdar/VisualBanana_Linux/Banana.x86\")\n",
    "env = UnityEnvironment(file_name=\"/home/arasdar/Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "# print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)\n",
    "# print(state.shape, len(env_info.vector_observations), env_info.vector_observations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37,)\n",
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        print(state.shape)\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    #print(state)\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "batch = []\n",
    "while True: # infinite number of steps\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    #print(state, action, reward, done)\n",
    "    batch.append([action, state, reward, done])\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "# print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, array([1.        , 0.        , 0.        , 0.        , 0.35186431,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.37953866,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.11957462,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.43679786,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.7516005 ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.6708644 ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.36187497,\n",
       "         0.        , 0.        ]), 0.0, False], (37,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, array([1.        , 0.        , 0.        , 0.        , 0.35186431,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.37953866,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.11957462,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.43679786,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.7516005 ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.6708644 ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.36187497,\n",
       "        0.        , 0.        ]), 0.0, False]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array([each[0] for each in batch])\n",
    "states = np.array([each[1] for each in batch])\n",
    "rewards = np.array([each[2] for each in batch])\n",
    "dones = np.array([each[3] for each in batch])\n",
    "# infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,) (300, 37) (300,) (300,)\n",
      "float64 float64 int64 bool\n",
      "3 0 4\n",
      "1.0 0.0\n",
      "10.869853973388672 -10.982420921325684\n"
     ]
    }
   ],
   "source": [
    "# print(rewards[:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)), \n",
    "      (np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    reward = tf.placeholder(tf.float32, [], name='reward')\n",
    "    return states, actions, targetQs, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator/Controller: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator/Dopamine: Reward function/planner/naviator/advisor/supervisor/cortical columns\n",
    "def discriminator(states, actions, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Fusion/merge states and actions/ SA/ SM\n",
    "        x_fused = tf.concat(axis=1, values=[states, actions])\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=x_fused, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return rewards logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, actions, targetQs, reward):\n",
    "    # G\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    neg_log_prob_actions = tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                      labels=actions_labels)\n",
    "    rewards = reward * tf.ones_like(targetQs)\n",
    "    #Qs_labels = targetQs[1:]\n",
    "    Qs_labels = rewards[:-1] + (0.99*targetQs[1:])\n",
    "    Qs_labels = tf.concat(axis=0, values=[Qs_labels, tf.zeros([1])])\n",
    "    g_loss = tf.reduce_mean(neg_log_prob_actions * Qs_labels)\n",
    "    #g_loss = tf.reduce_mean(neg_log_prob_actions[:-1] * Qs_labels)\n",
    "    \n",
    "    # D\n",
    "    Qs_logits = discriminator(actions=actions_logits, hidden_size=hidden_size, states=states)\n",
    "    d_lossR = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.reshape(Qs_logits, [-1]),\n",
    "                                                                     labels=rewards))\n",
    "    d_lossQ = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.reshape(Qs_logits, [-1]),\n",
    "                                                                     labels=tf.nn.sigmoid(Qs_labels)))\n",
    "    # d_lossQ = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.reshape(Qs_logits[:-1], [-1]),\n",
    "    #                                                                  labels=tf.nn.sigmoid(Qs_labels)))\n",
    "    d_loss = d_lossR + d_lossQ\n",
    "\n",
    "    return actions_logits, Qs_logits, g_loss, d_loss, d_lossR, d_lossQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizating/training/learning G & D\n",
    "def model_opt(g_loss, d_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param g_loss: Generator loss Tensor for action prediction\n",
    "    :param d_loss: Discriminator loss Tensor for reward prediction for generated/prob/logits action\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, self.reward = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.Qs_logits, self.g_loss, self.d_loss, self.d_lossR, self.d_lossQ = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, # model input\n",
    "            targetQs=self.targetQs, reward=self.reward) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_opt, self.d_opt = model_opt(g_loss=self.g_loss, d_loss=self.d_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size:(300, 37) actions:(300,)\n",
      "action size:4\n"
     ]
    }
   ],
   "source": [
    "print('state size:{}'.format(states.shape), \n",
    "      'actions:{}'.format(actions.shape)) \n",
    "print('action size:{}'.format(np.max(actions) - np.min(actions)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Network parameters\n",
    "state_size = 37              # number of units for the input state/observation -- simulation\n",
    "action_size = 4              # number of units for the output actions -- simulation\n",
    "hidden_size = 37*16          # number of units in each Q-network hidden layer -- simulation\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "\n",
    "while True: # infinite number of steps\n",
    "#for _ in range(batch_size):\n",
    "    state = env_info.vector_observations[0]   # get the next state\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    #memory.buffer.append([action, state, done])\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:-1.0000 rate:-0.0769 gloss:-0.1316 dloss:1.3706 dlossR:0.6773 dlossQ:0.6933\n",
      "Episode:1 meanR:-1.0000 rate:-0.0769 gloss:-0.7123 dloss:1.0514 dlossR:0.4117 dlossQ:0.6397\n",
      "Episode:2 meanR:-0.6667 rate:0.0000 gloss:-2.2430 dloss:0.4708 dlossR:0.1167 dlossQ:0.3541\n",
      "Episode:3 meanR:-0.5000 rate:0.0000 gloss:-1.9378 dloss:0.5582 dlossR:0.1505 dlossQ:0.4077\n",
      "Episode:4 meanR:-0.4000 rate:0.0000 gloss:-2.5756 dloss:0.3596 dlossR:0.0808 dlossQ:0.2788\n",
      "Episode:5 meanR:-0.3333 rate:0.0000 gloss:-3.3259 dloss:0.2474 dlossR:0.0481 dlossQ:0.1993\n",
      "Episode:6 meanR:-0.1429 rate:0.0769 gloss:-3.8222 dloss:0.4762 dlossR:0.2936 dlossQ:0.1826\n",
      "Episode:7 meanR:-0.1250 rate:0.0000 gloss:-4.5931 dloss:0.1158 dlossR:0.0177 dlossQ:0.0981\n",
      "Episode:8 meanR:-0.1111 rate:0.0000 gloss:-5.3130 dloss:0.0846 dlossR:0.0118 dlossQ:0.0728\n",
      "Episode:9 meanR:-0.1000 rate:0.0000 gloss:-6.1249 dloss:0.0456 dlossR:0.0050 dlossQ:0.0406\n",
      "Episode:10 meanR:-0.0909 rate:0.0000 gloss:-6.6945 dloss:0.0358 dlossR:0.0033 dlossQ:0.0325\n",
      "Episode:11 meanR:-0.1667 rate:-0.0769 gloss:-8.2149 dloss:-0.5454 dlossR:-0.5662 dlossQ:0.0208\n",
      "Episode:12 meanR:-0.3077 rate:-0.1538 gloss:-10.4050 dloss:-1.5714 dlossR:-1.5992 dlossQ:0.0278\n",
      "Episode:13 meanR:-0.2143 rate:0.0769 gloss:-11.9323 dloss:0.9012 dlossR:0.8862 dlossQ:0.0149\n",
      "Episode:14 meanR:-0.3333 rate:-0.1538 gloss:-11.0472 dloss:-1.7249 dlossR:-1.7529 dlossQ:0.0280\n",
      "Episode:15 meanR:-0.5000 rate:-0.2308 gloss:-13.8906 dloss:-2.9892 dlossR:-3.0189 dlossQ:0.0298\n",
      "Episode:16 meanR:-0.5882 rate:-0.1538 gloss:-21.7692 dloss:-2.9099 dlossR:-2.9490 dlossQ:0.0391\n",
      "Episode:17 meanR:-0.5556 rate:0.0000 gloss:-17.4218 dloss:0.0229 dlossR:0.0000 dlossQ:0.0229\n",
      "Episode:18 meanR:-0.5263 rate:0.0000 gloss:-13.8277 dloss:0.0233 dlossR:0.0000 dlossQ:0.0233\n",
      "Episode:19 meanR:-0.5500 rate:-0.0769 gloss:-15.8536 dloss:-1.2375 dlossR:-1.2640 dlossQ:0.0265\n",
      "Episode:20 meanR:-0.4286 rate:0.1538 gloss:-18.9708 dloss:2.9898 dlossR:2.9646 dlossQ:0.0252\n",
      "Episode:21 meanR:-0.2727 rate:0.2308 gloss:-17.4323 dloss:3.4119 dlossR:3.3877 dlossQ:0.0242\n",
      "Episode:22 meanR:-0.2609 rate:0.0000 gloss:-17.0381 dloss:0.0246 dlossR:0.0000 dlossQ:0.0246\n",
      "Episode:23 meanR:-0.2500 rate:0.0000 gloss:-17.8989 dloss:0.0232 dlossR:0.0000 dlossQ:0.0232\n",
      "Episode:24 meanR:-0.2400 rate:0.0000 gloss:-19.0687 dloss:0.0285 dlossR:0.0000 dlossQ:0.0285\n",
      "Episode:25 meanR:-0.2308 rate:0.0000 gloss:-19.1527 dloss:0.0229 dlossR:0.0000 dlossQ:0.0229\n",
      "Episode:26 meanR:-0.1852 rate:0.0769 gloss:-11.8851 dloss:1.0346 dlossR:1.0121 dlossQ:0.0225\n",
      "Episode:27 meanR:-0.1429 rate:0.0769 gloss:-14.1593 dloss:1.1088 dlossR:1.0848 dlossQ:0.0240\n",
      "Episode:28 meanR:-0.0345 rate:0.2308 gloss:-14.1260 dloss:3.1897 dlossR:3.1663 dlossQ:0.0234\n",
      "Episode:29 meanR:-0.0667 rate:-0.0769 gloss:-19.1623 dloss:-1.2415 dlossR:-1.2624 dlossQ:0.0208\n",
      "Episode:30 meanR:-0.0645 rate:0.0000 gloss:-15.7446 dloss:0.0507 dlossR:0.0001 dlossQ:0.0506\n",
      "Episode:31 meanR:-0.0625 rate:0.0000 gloss:-17.7766 dloss:0.0530 dlossR:0.0001 dlossQ:0.0528\n",
      "Episode:32 meanR:-0.0909 rate:-0.0769 gloss:-13.8895 dloss:-0.9393 dlossR:-0.9597 dlossQ:0.0204\n",
      "Episode:33 meanR:-0.0882 rate:0.0000 gloss:-14.2558 dloss:0.0210 dlossR:0.0001 dlossQ:0.0209\n",
      "Episode:34 meanR:-0.0857 rate:0.0000 gloss:-14.8550 dloss:0.0239 dlossR:0.0003 dlossQ:0.0236\n",
      "Episode:35 meanR:-0.0556 rate:0.0769 gloss:-13.1438 dloss:0.8846 dlossR:0.8600 dlossQ:0.0246\n",
      "Episode:36 meanR:-0.0270 rate:0.0769 gloss:-6.1040 dloss:0.5173 dlossR:0.4621 dlossQ:0.0552\n",
      "Episode:37 meanR:0.0000 rate:0.0769 gloss:-6.5242 dloss:0.5559 dlossR:0.4869 dlossQ:0.0691\n",
      "Episode:38 meanR:-0.0256 rate:-0.0769 gloss:-11.2782 dloss:-0.6066 dlossR:-0.6769 dlossQ:0.0703\n",
      "Episode:39 meanR:-0.0500 rate:-0.0769 gloss:-8.2761 dloss:-0.3802 dlossR:-0.5366 dlossQ:0.1564\n",
      "Episode:40 meanR:-0.0488 rate:0.0000 gloss:-11.4301 dloss:0.0477 dlossR:0.0040 dlossQ:0.0437\n",
      "Episode:41 meanR:-0.0714 rate:-0.0769 gloss:-10.1572 dloss:-0.5471 dlossR:-0.6764 dlossQ:0.1293\n",
      "Episode:42 meanR:-0.0698 rate:0.0000 gloss:-12.2194 dloss:0.0270 dlossR:0.0018 dlossQ:0.0252\n",
      "Episode:43 meanR:-0.0227 rate:0.1538 gloss:-8.1671 dloss:1.3063 dlossR:1.1780 dlossQ:0.1283\n",
      "Episode:44 meanR:0.0000 rate:0.0769 gloss:-7.9923 dloss:0.7448 dlossR:0.5950 dlossQ:0.1498\n",
      "Episode:45 meanR:0.0000 rate:0.0000 gloss:-13.4250 dloss:0.0296 dlossR:0.0018 dlossQ:0.0278\n",
      "Episode:46 meanR:0.0000 rate:0.0000 gloss:-13.4263 dloss:0.0592 dlossR:0.0056 dlossQ:0.0536\n",
      "Episode:47 meanR:0.0000 rate:0.0000 gloss:-13.3396 dloss:0.0308 dlossR:0.0023 dlossQ:0.0285\n",
      "Episode:48 meanR:0.0000 rate:0.0000 gloss:-13.7990 dloss:0.1232 dlossR:0.0134 dlossQ:0.1098\n",
      "Episode:49 meanR:0.0200 rate:0.0769 gloss:-13.9451 dloss:1.0840 dlossR:0.9581 dlossQ:0.1259\n",
      "Episode:50 meanR:0.0392 rate:0.0769 gloss:-16.7890 dloss:1.2584 dlossR:1.1303 dlossQ:0.1281\n",
      "Episode:51 meanR:0.0385 rate:0.0000 gloss:-13.2290 dloss:0.1986 dlossR:0.0182 dlossQ:0.1804\n",
      "Episode:52 meanR:0.0000 rate:-0.1538 gloss:-10.6106 dloss:-1.1351 dlossR:-1.3276 dlossQ:0.1925\n",
      "Episode:53 meanR:0.0000 rate:0.0000 gloss:-10.4329 dloss:0.0736 dlossR:0.0067 dlossQ:0.0669\n",
      "Episode:54 meanR:0.0000 rate:0.0000 gloss:-8.9987 dloss:0.0877 dlossR:0.0103 dlossQ:0.0774\n",
      "Episode:55 meanR:0.0000 rate:0.0000 gloss:-9.6849 dloss:0.0343 dlossR:0.0034 dlossQ:0.0309\n",
      "Episode:56 meanR:0.0000 rate:0.0000 gloss:-8.1270 dloss:0.1303 dlossR:0.0154 dlossQ:0.1149\n",
      "Episode:57 meanR:0.0000 rate:0.0000 gloss:-7.0086 dloss:0.1145 dlossR:0.0142 dlossQ:0.1003\n",
      "Episode:58 meanR:0.0339 rate:0.1538 gloss:-8.3121 dloss:1.2890 dlossR:1.1039 dlossQ:0.1850\n",
      "Episode:59 meanR:0.0500 rate:0.0769 gloss:-9.1395 dloss:0.7963 dlossR:0.5998 dlossQ:0.1964\n",
      "Episode:60 meanR:0.0656 rate:0.0769 gloss:-7.8667 dloss:0.6927 dlossR:0.5237 dlossQ:0.1690\n",
      "Episode:61 meanR:0.0806 rate:0.0769 gloss:-7.3291 dloss:0.5754 dlossR:0.4762 dlossQ:0.0992\n",
      "Episode:62 meanR:0.0794 rate:0.0000 gloss:-7.3359 dloss:0.2295 dlossR:0.0259 dlossQ:0.2035\n",
      "Episode:63 meanR:0.0781 rate:0.0000 gloss:-5.7605 dloss:0.2008 dlossR:0.0269 dlossQ:0.1738\n",
      "Episode:64 meanR:0.0769 rate:0.0000 gloss:-5.9833 dloss:0.1821 dlossR:0.0297 dlossQ:0.1524\n",
      "Episode:65 meanR:0.0758 rate:0.0000 gloss:-6.2263 dloss:0.2320 dlossR:0.0288 dlossQ:0.2032\n",
      "Episode:66 meanR:0.1045 rate:0.1538 gloss:-7.2959 dloss:1.3560 dlossR:0.9792 dlossQ:0.3768\n",
      "Episode:67 meanR:0.1176 rate:0.0769 gloss:-6.3701 dloss:0.6533 dlossR:0.4372 dlossQ:0.2161\n",
      "Episode:68 meanR:0.1159 rate:0.0000 gloss:-7.9413 dloss:0.0622 dlossR:0.0082 dlossQ:0.0540\n",
      "Episode:69 meanR:0.1000 rate:-0.0769 gloss:-8.0444 dloss:-0.4665 dlossR:-0.4992 dlossQ:0.0328\n",
      "Episode:70 meanR:0.0986 rate:0.0000 gloss:-6.4368 dloss:0.4297 dlossR:0.0505 dlossQ:0.3792\n",
      "Episode:71 meanR:0.0833 rate:-0.0769 gloss:-8.5283 dloss:-0.1335 dlossR:-0.4838 dlossQ:0.3504\n",
      "Episode:72 meanR:0.0959 rate:0.0769 gloss:-7.1701 dloss:0.8818 dlossR:0.4883 dlossQ:0.3935\n",
      "Episode:73 meanR:0.1216 rate:0.1538 gloss:-6.9683 dloss:1.3198 dlossR:0.9184 dlossQ:0.4014\n",
      "Episode:74 meanR:0.1600 rate:0.2308 gloss:-7.0441 dloss:1.7050 dlossR:1.3813 dlossQ:0.3237\n",
      "Episode:75 meanR:0.1579 rate:0.0000 gloss:-8.9643 dloss:0.4275 dlossR:0.0316 dlossQ:0.3959\n",
      "Episode:76 meanR:0.1558 rate:0.0000 gloss:-5.6653 dloss:0.1145 dlossR:0.0178 dlossQ:0.0967\n",
      "Episode:77 meanR:0.1667 rate:0.0769 gloss:-3.9464 dloss:0.5022 dlossR:0.2876 dlossQ:0.2146\n",
      "Episode:78 meanR:0.1646 rate:0.0000 gloss:-5.7374 dloss:0.2292 dlossR:0.0289 dlossQ:0.2003\n",
      "Episode:79 meanR:0.1625 rate:0.0000 gloss:-4.6967 dloss:0.1809 dlossR:0.0308 dlossQ:0.1501\n",
      "Episode:80 meanR:0.1481 rate:-0.0769 gloss:-5.2597 dloss:-0.1318 dlossR:-0.2687 dlossQ:0.1369\n",
      "Episode:81 meanR:0.1220 rate:-0.1538 gloss:-5.3179 dloss:-0.4481 dlossR:-0.5619 dlossQ:0.1138\n",
      "Episode:82 meanR:0.1205 rate:0.0000 gloss:-4.6073 dloss:0.2055 dlossR:0.0349 dlossQ:0.1707\n",
      "Episode:83 meanR:0.1071 rate:-0.0769 gloss:-5.2470 dloss:-0.1301 dlossR:-0.2696 dlossQ:0.1395\n",
      "Episode:84 meanR:0.1059 rate:0.0000 gloss:-5.0647 dloss:0.1500 dlossR:0.0234 dlossQ:0.1266\n",
      "Episode:85 meanR:0.1047 rate:0.0000 gloss:-6.2542 dloss:0.1119 dlossR:0.0157 dlossQ:0.0962\n",
      "Episode:86 meanR:0.1034 rate:0.0000 gloss:-6.6840 dloss:0.4109 dlossR:0.0460 dlossQ:0.3649\n",
      "Episode:87 meanR:0.1136 rate:0.0769 gloss:-4.5774 dloss:0.4923 dlossR:0.3141 dlossQ:0.1783\n",
      "Episode:88 meanR:0.1124 rate:0.0000 gloss:-6.2586 dloss:0.0939 dlossR:0.0120 dlossQ:0.0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:89 meanR:0.1222 rate:0.0769 gloss:-4.9906 dloss:0.5519 dlossR:0.3447 dlossQ:0.2072\n",
      "Episode:90 meanR:0.1099 rate:-0.0769 gloss:-6.2658 dloss:-0.0555 dlossR:-0.3289 dlossQ:0.2734\n",
      "Episode:91 meanR:0.1196 rate:0.0769 gloss:-6.3559 dloss:0.5692 dlossR:0.4113 dlossQ:0.1578\n",
      "Episode:92 meanR:0.1290 rate:0.0769 gloss:-7.2748 dloss:0.6754 dlossR:0.4671 dlossQ:0.2083\n",
      "Episode:93 meanR:0.1170 rate:-0.0769 gloss:-5.8568 dloss:-0.1527 dlossR:-0.3167 dlossQ:0.1640\n",
      "Episode:94 meanR:0.1158 rate:0.0000 gloss:-6.4807 dloss:0.2158 dlossR:0.0274 dlossQ:0.1884\n",
      "Episode:95 meanR:0.1354 rate:0.1538 gloss:-7.1775 dloss:1.0732 dlossR:0.9109 dlossQ:0.1622\n",
      "Episode:96 meanR:0.1546 rate:0.1538 gloss:-5.5053 dloss:0.8447 dlossR:0.7018 dlossQ:0.1429\n",
      "Episode:97 meanR:0.1633 rate:0.0769 gloss:-5.0454 dloss:0.4961 dlossR:0.3340 dlossQ:0.1621\n",
      "Episode:98 meanR:0.1616 rate:0.0000 gloss:-5.5479 dloss:0.1849 dlossR:0.0287 dlossQ:0.1562\n",
      "Episode:99 meanR:0.1700 rate:0.0769 gloss:-5.6715 dloss:0.5481 dlossR:0.3738 dlossQ:0.1743\n",
      "Episode:100 meanR:0.1800 rate:0.0000 gloss:-5.2711 dloss:0.1893 dlossR:0.0328 dlossQ:0.1565\n",
      "Episode:101 meanR:0.1800 rate:-0.0769 gloss:-4.9675 dloss:-0.0601 dlossR:-0.2428 dlossQ:0.1827\n",
      "Episode:102 meanR:0.1500 rate:-0.2308 gloss:-5.6031 dloss:-0.6866 dlossR:-0.8940 dlossQ:0.2074\n",
      "Episode:103 meanR:0.1700 rate:0.1538 gloss:-4.9537 dloss:0.8328 dlossR:0.6449 dlossQ:0.1879\n",
      "Episode:104 meanR:0.1600 rate:-0.0769 gloss:-5.9174 dloss:-0.1635 dlossR:-0.3124 dlossQ:0.1489\n",
      "Episode:105 meanR:0.1200 rate:-0.3077 gloss:-7.4799 dloss:-1.4839 dlossR:-1.6358 dlossQ:0.1519\n",
      "Episode:106 meanR:0.0900 rate:-0.1538 gloss:-6.6328 dloss:-0.6526 dlossR:-0.7311 dlossQ:0.0785\n",
      "Episode:107 meanR:0.0800 rate:-0.0769 gloss:-6.2287 dloss:-0.2677 dlossR:-0.3390 dlossQ:0.0714\n",
      "Episode:108 meanR:0.0800 rate:0.0000 gloss:-7.3162 dloss:0.0712 dlossR:0.0084 dlossQ:0.0628\n",
      "Episode:109 meanR:0.1200 rate:0.3077 gloss:-7.8835 dloss:2.0082 dlossR:1.9472 dlossQ:0.0610\n",
      "Episode:110 meanR:0.1400 rate:0.1538 gloss:-8.5654 dloss:1.0811 dlossR:1.0333 dlossQ:0.0478\n",
      "Episode:111 meanR:0.1500 rate:0.0000 gloss:-11.0195 dloss:0.0471 dlossR:0.0020 dlossQ:0.0450\n",
      "Episode:112 meanR:0.1900 rate:0.1538 gloss:-7.9772 dloss:1.0128 dlossR:0.9726 dlossQ:0.0401\n",
      "Episode:113 meanR:0.1700 rate:-0.0769 gloss:-8.0432 dloss:-0.4207 dlossR:-0.4603 dlossQ:0.0395\n",
      "Episode:114 meanR:0.1800 rate:-0.0769 gloss:-10.5044 dloss:-0.5910 dlossR:-0.6193 dlossQ:0.0283\n",
      "Episode:115 meanR:0.2000 rate:-0.0769 gloss:-9.0115 dloss:-0.4791 dlossR:-0.5220 dlossQ:0.0428\n",
      "Episode:116 meanR:0.2000 rate:-0.1538 gloss:-9.4095 dloss:-1.0403 dlossR:-1.0800 dlossQ:0.0397\n",
      "Episode:117 meanR:0.2000 rate:0.0000 gloss:-9.4749 dloss:0.0582 dlossR:0.0069 dlossQ:0.0513\n",
      "Episode:118 meanR:0.2000 rate:0.0000 gloss:-10.8076 dloss:0.0395 dlossR:0.0039 dlossQ:0.0356\n",
      "Episode:119 meanR:0.2100 rate:0.0000 gloss:-7.5633 dloss:0.0428 dlossR:0.0043 dlossQ:0.0385\n",
      "Episode:120 meanR:0.2000 rate:0.0769 gloss:-8.6196 dloss:0.5734 dlossR:0.5205 dlossQ:0.0529\n",
      "Episode:121 meanR:0.1900 rate:0.1538 gloss:-9.9146 dloss:1.2518 dlossR:1.1899 dlossQ:0.0619\n",
      "Episode:122 meanR:0.1600 rate:-0.2308 gloss:-9.1430 dloss:-1.4992 dlossR:-1.5506 dlossQ:0.0513\n",
      "Episode:123 meanR:0.1700 rate:0.0769 gloss:-8.9289 dloss:0.6230 dlossR:0.5362 dlossQ:0.0869\n",
      "Episode:124 meanR:0.1400 rate:-0.2308 gloss:-8.9491 dloss:-1.4597 dlossR:-1.5103 dlossQ:0.0505\n",
      "Episode:125 meanR:0.1500 rate:0.0769 gloss:-9.5473 dloss:0.6169 dlossR:0.5660 dlossQ:0.0509\n",
      "Episode:126 meanR:0.1500 rate:0.0769 gloss:-10.9023 dloss:0.7056 dlossR:0.6523 dlossQ:0.0533\n",
      "Episode:127 meanR:0.1400 rate:0.0000 gloss:-12.3706 dloss:0.0706 dlossR:0.0031 dlossQ:0.0675\n",
      "Episode:128 meanR:0.1100 rate:0.0000 gloss:-7.7331 dloss:0.0446 dlossR:0.0043 dlossQ:0.0403\n",
      "Episode:129 meanR:0.1300 rate:0.0769 gloss:-8.0948 dloss:0.5092 dlossR:0.4809 dlossQ:0.0283\n",
      "Episode:130 meanR:0.1300 rate:0.0000 gloss:-7.2155 dloss:0.0535 dlossR:0.0062 dlossQ:0.0472\n",
      "Episode:131 meanR:0.1300 rate:0.0000 gloss:-8.9066 dloss:0.0248 dlossR:0.0015 dlossQ:0.0233\n",
      "Episode:132 meanR:0.1400 rate:0.0000 gloss:-11.8597 dloss:0.0310 dlossR:0.0018 dlossQ:0.0291\n",
      "Episode:133 meanR:0.1600 rate:0.1538 gloss:-7.3005 dloss:0.9541 dlossR:0.9184 dlossQ:0.0357\n",
      "Episode:134 meanR:0.1700 rate:0.0769 gloss:-11.3784 dloss:0.7101 dlossR:0.6818 dlossQ:0.0284\n",
      "Episode:135 meanR:0.1700 rate:0.0769 gloss:-8.1184 dloss:0.5181 dlossR:0.4781 dlossQ:0.0400\n",
      "Episode:136 meanR:0.1600 rate:0.0000 gloss:-7.7241 dloss:0.0478 dlossR:0.0048 dlossQ:0.0430\n",
      "Episode:137 meanR:0.1500 rate:0.0000 gloss:-9.5777 dloss:0.0212 dlossR:0.0009 dlossQ:0.0203\n",
      "Episode:138 meanR:0.1600 rate:0.0000 gloss:-8.4932 dloss:0.0319 dlossR:0.0022 dlossQ:0.0297\n",
      "Episode:139 meanR:0.1700 rate:0.0000 gloss:-9.0958 dloss:0.0231 dlossR:0.0014 dlossQ:0.0217\n",
      "Episode:140 meanR:0.1800 rate:0.0769 gloss:-14.2520 dloss:0.8987 dlossR:0.8488 dlossQ:0.0499\n",
      "Episode:141 meanR:0.1900 rate:0.0000 gloss:-10.9004 dloss:0.2289 dlossR:0.0183 dlossQ:0.2105\n",
      "Episode:142 meanR:0.2200 rate:0.2308 gloss:-15.8077 dloss:2.8780 dlossR:2.8439 dlossQ:0.0342\n",
      "Episode:143 meanR:0.1900 rate:-0.0769 gloss:-9.7754 dloss:-0.2846 dlossR:-0.5290 dlossQ:0.2444\n",
      "Episode:144 meanR:0.2000 rate:0.1538 gloss:-8.3745 dloss:1.3643 dlossR:1.0312 dlossQ:0.3331\n",
      "Episode:145 meanR:0.2000 rate:0.0000 gloss:-4.3028 dloss:0.2315 dlossR:0.0442 dlossQ:0.1874\n",
      "Episode:146 meanR:0.2000 rate:0.0000 gloss:-5.2669 dloss:0.1547 dlossR:0.0257 dlossQ:0.1289\n",
      "Episode:147 meanR:0.2000 rate:0.0000 gloss:-5.1567 dloss:0.1371 dlossR:0.0222 dlossQ:0.1149\n",
      "Episode:148 meanR:0.2000 rate:0.0000 gloss:-4.4711 dloss:0.2009 dlossR:0.0360 dlossQ:0.1649\n",
      "Episode:149 meanR:0.1900 rate:0.0000 gloss:-4.7690 dloss:0.1724 dlossR:0.0293 dlossQ:0.1431\n",
      "Episode:150 meanR:0.1800 rate:0.0000 gloss:-3.8954 dloss:0.2662 dlossR:0.0533 dlossQ:0.2130\n",
      "Episode:151 meanR:0.1800 rate:0.0000 gloss:-5.1416 dloss:0.1881 dlossR:0.0287 dlossQ:0.1594\n",
      "Episode:152 meanR:0.2000 rate:0.0000 gloss:-3.6435 dloss:0.3298 dlossR:0.0680 dlossQ:0.2618\n",
      "Episode:153 meanR:0.2000 rate:0.0000 gloss:-5.3800 dloss:0.1558 dlossR:0.0242 dlossQ:0.1316\n",
      "Episode:154 meanR:0.2000 rate:0.0000 gloss:-4.4543 dloss:0.2020 dlossR:0.0370 dlossQ:0.1649\n",
      "Episode:155 meanR:0.2100 rate:0.0769 gloss:-4.3825 dloss:0.5360 dlossR:0.3122 dlossQ:0.2238\n",
      "Episode:156 meanR:0.2100 rate:0.0000 gloss:-3.8575 dloss:0.2854 dlossR:0.0583 dlossQ:0.2271\n",
      "Episode:157 meanR:0.2100 rate:0.0000 gloss:-4.4216 dloss:0.2459 dlossR:0.0446 dlossQ:0.2013\n",
      "Episode:158 meanR:0.1900 rate:0.0000 gloss:-4.2909 dloss:0.2583 dlossR:0.0502 dlossQ:0.2082\n",
      "Episode:159 meanR:0.2100 rate:0.2308 gloss:-3.7895 dloss:1.0058 dlossR:0.7794 dlossQ:0.2263\n",
      "Episode:160 meanR:0.2000 rate:0.0000 gloss:-4.5718 dloss:0.2064 dlossR:0.0355 dlossQ:0.1709\n",
      "Episode:161 meanR:0.1700 rate:-0.1538 gloss:-4.1961 dloss:-0.2352 dlossR:-0.4272 dlossQ:0.1919\n",
      "Episode:162 meanR:0.1900 rate:0.1538 gloss:-4.1893 dloss:0.7408 dlossR:0.5543 dlossQ:0.1865\n",
      "Episode:163 meanR:0.1900 rate:0.0000 gloss:-4.2714 dloss:0.2146 dlossR:0.0394 dlossQ:0.1752\n",
      "Episode:164 meanR:0.2000 rate:0.0769 gloss:-4.5073 dloss:0.4720 dlossR:0.3083 dlossQ:0.1638\n",
      "Episode:165 meanR:0.2100 rate:0.0769 gloss:-5.0273 dloss:0.4522 dlossR:0.3225 dlossQ:0.1297\n",
      "Episode:166 meanR:0.1900 rate:0.0000 gloss:-4.3645 dloss:0.2206 dlossR:0.0400 dlossQ:0.1805\n",
      "Episode:167 meanR:0.1800 rate:0.0000 gloss:-4.3409 dloss:0.2157 dlossR:0.0398 dlossQ:0.1759\n",
      "Episode:168 meanR:0.1700 rate:-0.0769 gloss:-5.4062 dloss:-0.1895 dlossR:-0.2944 dlossQ:0.1049\n",
      "Episode:169 meanR:0.1900 rate:0.0769 gloss:-4.6264 dloss:0.4618 dlossR:0.3082 dlossQ:0.1535\n",
      "Episode:170 meanR:0.1900 rate:0.0000 gloss:-4.3945 dloss:0.2063 dlossR:0.0380 dlossQ:0.1683\n",
      "Episode:171 meanR:0.2000 rate:0.0000 gloss:-4.8671 dloss:0.1711 dlossR:0.0282 dlossQ:0.1429\n",
      "Episode:172 meanR:0.1900 rate:0.0000 gloss:-2.7683 dloss:0.4808 dlossR:0.1198 dlossQ:0.3610\n",
      "Episode:173 meanR:0.1700 rate:0.0000 gloss:-4.9644 dloss:0.1650 dlossR:0.0280 dlossQ:0.1371\n",
      "Episode:174 meanR:0.1200 rate:-0.1538 gloss:-5.0374 dloss:-0.3992 dlossR:-0.5287 dlossQ:0.1294\n",
      "Episode:175 meanR:0.0900 rate:-0.2308 gloss:-5.2695 dloss:-0.7154 dlossR:-0.8351 dlossQ:0.1196\n",
      "Episode:176 meanR:0.0900 rate:0.0000 gloss:-5.3409 dloss:0.1393 dlossR:0.0220 dlossQ:0.1174\n",
      "Episode:177 meanR:0.0900 rate:0.0769 gloss:-5.3825 dloss:0.4554 dlossR:0.3376 dlossQ:0.1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:178 meanR:0.0700 rate:-0.1538 gloss:-6.4764 dloss:-0.6435 dlossR:-0.7165 dlossQ:0.0730\n",
      "Episode:179 meanR:0.0600 rate:-0.0769 gloss:-7.1288 dloss:-0.3462 dlossR:-0.4007 dlossQ:0.0544\n",
      "Episode:180 meanR:0.0800 rate:0.0769 gloss:-7.1074 dloss:0.4845 dlossR:0.4239 dlossQ:0.0607\n",
      "Episode:181 meanR:0.0900 rate:-0.0769 gloss:-6.7778 dloss:-0.3072 dlossR:-0.3726 dlossQ:0.0655\n",
      "Episode:182 meanR:0.1500 rate:0.4615 gloss:-8.5889 dloss:3.2731 dlossR:3.2229 dlossQ:0.0501\n",
      "Episode:183 meanR:0.1500 rate:-0.0769 gloss:-8.1131 dloss:-0.4213 dlossR:-0.4557 dlossQ:0.0344\n",
      "Episode:184 meanR:0.1500 rate:0.0000 gloss:-7.7196 dloss:0.0400 dlossR:0.0038 dlossQ:0.0362\n",
      "Episode:185 meanR:0.1600 rate:0.0769 gloss:-7.7394 dloss:0.4918 dlossR:0.4555 dlossQ:0.0363\n",
      "Episode:186 meanR:0.1600 rate:0.0000 gloss:-7.3096 dloss:0.0436 dlossR:0.0044 dlossQ:0.0392\n",
      "Episode:187 meanR:0.1500 rate:0.0000 gloss:-5.8111 dloss:0.0962 dlossR:0.0138 dlossQ:0.0824\n",
      "Episode:188 meanR:0.1500 rate:0.0000 gloss:-5.0896 dloss:0.1504 dlossR:0.0243 dlossQ:0.1261\n",
      "Episode:189 meanR:0.1400 rate:0.0000 gloss:-6.5442 dloss:0.0701 dlossR:0.0086 dlossQ:0.0614\n",
      "Episode:190 meanR:0.1900 rate:0.3077 gloss:-5.6536 dloss:1.5296 dlossR:1.4261 dlossQ:0.1034\n",
      "Episode:191 meanR:0.1600 rate:-0.1538 gloss:-6.7633 dloss:-0.7020 dlossR:-0.7530 dlossQ:0.0509\n",
      "Episode:192 meanR:0.1900 rate:0.3077 gloss:-5.9182 dloss:1.5803 dlossR:1.4940 dlossQ:0.0863\n",
      "Episode:193 meanR:0.1900 rate:-0.0769 gloss:-4.9667 dloss:-0.1195 dlossR:-0.2511 dlossQ:0.1316\n",
      "Episode:194 meanR:0.1900 rate:0.0000 gloss:-5.0856 dloss:0.1472 dlossR:0.0243 dlossQ:0.1229\n",
      "Episode:195 meanR:0.1800 rate:0.0769 gloss:-5.6130 dloss:0.4321 dlossR:0.3412 dlossQ:0.0909\n",
      "Episode:196 meanR:0.1700 rate:0.0769 gloss:-4.9726 dloss:0.4663 dlossR:0.3219 dlossQ:0.1445\n",
      "Episode:197 meanR:0.1500 rate:-0.0769 gloss:-4.5478 dloss:-0.0229 dlossR:-0.2079 dlossQ:0.1849\n",
      "Episode:198 meanR:0.1300 rate:-0.1538 gloss:-4.9227 dloss:-0.3436 dlossR:-0.5026 dlossQ:0.1590\n",
      "Episode:199 meanR:0.1100 rate:-0.0769 gloss:-4.9941 dloss:-0.0989 dlossR:-0.2470 dlossQ:0.1481\n",
      "Episode:200 meanR:0.0900 rate:-0.1538 gloss:-4.9886 dloss:-0.3524 dlossR:-0.5115 dlossQ:0.1591\n",
      "Episode:201 meanR:0.1000 rate:0.0000 gloss:-4.5377 dloss:0.2320 dlossR:0.0404 dlossQ:0.1916\n",
      "Episode:202 meanR:0.1300 rate:0.0000 gloss:-4.8721 dloss:0.1681 dlossR:0.0282 dlossQ:0.1400\n",
      "Episode:203 meanR:0.1100 rate:0.0000 gloss:-4.2756 dloss:0.3035 dlossR:0.0543 dlossQ:0.2493\n",
      "Episode:204 meanR:0.1100 rate:-0.0769 gloss:-6.2333 dloss:-0.2564 dlossR:-0.3402 dlossQ:0.0838\n",
      "Episode:205 meanR:0.1700 rate:0.1538 gloss:-6.0826 dloss:0.8351 dlossR:0.7384 dlossQ:0.0967\n",
      "Episode:206 meanR:0.1900 rate:0.0000 gloss:-7.2285 dloss:0.0657 dlossR:0.0089 dlossQ:0.0568\n",
      "Episode:207 meanR:0.2000 rate:0.0000 gloss:-6.4967 dloss:0.0825 dlossR:0.0113 dlossQ:0.0712\n",
      "Episode:208 meanR:0.1900 rate:-0.0769 gloss:-7.0446 dloss:-0.3366 dlossR:-0.3901 dlossQ:0.0535\n",
      "Episode:209 meanR:0.1600 rate:0.0769 gloss:-6.1847 dloss:0.4569 dlossR:0.3742 dlossQ:0.0826\n",
      "Episode:210 meanR:0.1400 rate:0.0000 gloss:-6.3935 dloss:0.0804 dlossR:0.0107 dlossQ:0.0697\n",
      "Episode:211 meanR:0.1400 rate:0.0000 gloss:-6.8083 dloss:0.0645 dlossR:0.0078 dlossQ:0.0568\n",
      "Episode:212 meanR:0.1100 rate:-0.0769 gloss:-6.0034 dloss:-0.2381 dlossR:-0.3225 dlossQ:0.0844\n",
      "Episode:213 meanR:0.1100 rate:-0.0769 gloss:-7.0042 dloss:-0.3349 dlossR:-0.3876 dlossQ:0.0528\n",
      "Episode:214 meanR:0.1200 rate:0.0000 gloss:-6.5299 dloss:0.0776 dlossR:0.0097 dlossQ:0.0680\n",
      "Episode:215 meanR:0.1300 rate:0.0000 gloss:-5.5860 dloss:0.1240 dlossR:0.0183 dlossQ:0.1057\n",
      "Episode:216 meanR:0.1500 rate:0.0000 gloss:-7.4028 dloss:0.0455 dlossR:0.0047 dlossQ:0.0408\n",
      "Episode:217 meanR:0.1400 rate:-0.0769 gloss:-8.1018 dloss:-0.4251 dlossR:-0.4548 dlossQ:0.0297\n",
      "Episode:218 meanR:0.1400 rate:0.0000 gloss:-8.0682 dloss:0.0390 dlossR:0.0037 dlossQ:0.0353\n",
      "Episode:219 meanR:0.1400 rate:0.0000 gloss:-8.9044 dloss:0.0304 dlossR:0.0021 dlossQ:0.0283\n",
      "Episode:220 meanR:0.1100 rate:-0.1538 gloss:-8.7823 dloss:-0.9491 dlossR:-0.9780 dlossQ:0.0289\n",
      "Episode:221 meanR:0.1000 rate:0.0769 gloss:-6.2435 dloss:0.4379 dlossR:0.3686 dlossQ:0.0693\n",
      "Episode:222 meanR:0.1300 rate:0.0000 gloss:-7.2618 dloss:0.0458 dlossR:0.0049 dlossQ:0.0409\n",
      "Episode:223 meanR:0.1200 rate:0.0000 gloss:-5.5911 dloss:0.1128 dlossR:0.0171 dlossQ:0.0957\n",
      "Episode:224 meanR:0.1600 rate:0.0769 gloss:-9.2421 dloss:0.5658 dlossR:0.5381 dlossQ:0.0278\n",
      "Episode:225 meanR:0.1600 rate:0.0769 gloss:-8.9434 dloss:0.5446 dlossR:0.5202 dlossQ:0.0244\n",
      "Episode:226 meanR:0.1400 rate:-0.0769 gloss:-9.0064 dloss:-0.4817 dlossR:-0.5080 dlossQ:0.0263\n",
      "Episode:227 meanR:0.1300 rate:-0.0769 gloss:-9.6858 dloss:-0.5232 dlossR:-0.5462 dlossQ:0.0230\n",
      "Episode:228 meanR:0.1300 rate:0.0000 gloss:-10.0977 dloss:0.0229 dlossR:0.0010 dlossQ:0.0218\n",
      "Episode:229 meanR:0.1300 rate:0.0769 gloss:-10.3829 dloss:0.6193 dlossR:0.5991 dlossQ:0.0203\n",
      "Episode:230 meanR:0.1300 rate:0.0000 gloss:-10.5861 dloss:0.0195 dlossR:0.0005 dlossQ:0.0190\n",
      "Episode:231 meanR:0.1200 rate:-0.0769 gloss:-11.2565 dloss:-0.6241 dlossR:-0.6391 dlossQ:0.0149\n",
      "Episode:232 meanR:0.1200 rate:0.0000 gloss:-12.3246 dloss:0.0147 dlossR:0.0003 dlossQ:0.0145\n",
      "Episode:233 meanR:0.1000 rate:0.0000 gloss:-10.1622 dloss:0.0247 dlossR:0.0009 dlossQ:0.0238\n",
      "Episode:234 meanR:0.0800 rate:-0.0769 gloss:-10.5658 dloss:-0.5766 dlossR:-0.5969 dlossQ:0.0203\n",
      "Episode:235 meanR:0.0700 rate:0.0000 gloss:-10.1464 dloss:0.0191 dlossR:0.0007 dlossQ:0.0184\n",
      "Episode:236 meanR:0.0700 rate:0.0000 gloss:-10.4741 dloss:0.0184 dlossR:0.0006 dlossQ:0.0178\n",
      "Episode:237 meanR:0.0500 rate:-0.1538 gloss:-9.7062 dloss:-1.0575 dlossR:-1.0855 dlossQ:0.0280\n",
      "Episode:238 meanR:0.0500 rate:0.0000 gloss:-10.3327 dloss:0.0225 dlossR:0.0009 dlossQ:0.0216\n",
      "Episode:239 meanR:0.0500 rate:0.0000 gloss:-11.5232 dloss:0.0167 dlossR:0.0002 dlossQ:0.0165\n",
      "Episode:240 meanR:0.0400 rate:0.0000 gloss:-12.0421 dloss:0.0178 dlossR:0.0002 dlossQ:0.0176\n",
      "Episode:241 meanR:0.0300 rate:-0.0769 gloss:-13.7055 dloss:-0.7592 dlossR:-0.7780 dlossQ:0.0189\n",
      "Episode:242 meanR:0.0000 rate:0.0000 gloss:-12.7302 dloss:0.0191 dlossR:0.0001 dlossQ:0.0189\n",
      "Episode:243 meanR:0.0100 rate:0.0000 gloss:-14.9558 dloss:0.0163 dlossR:0.0000 dlossQ:0.0163\n",
      "Episode:244 meanR:-0.0200 rate:-0.0769 gloss:-16.4430 dloss:-0.9172 dlossR:-0.9335 dlossQ:0.0164\n",
      "Episode:245 meanR:-0.0100 rate:0.0769 gloss:-12.8842 dloss:0.7587 dlossR:0.7429 dlossQ:0.0158\n",
      "Episode:246 meanR:-0.0100 rate:0.0000 gloss:-11.3810 dloss:0.0199 dlossR:0.0010 dlossQ:0.0189\n",
      "Episode:247 meanR:-0.0100 rate:0.0000 gloss:-14.5037 dloss:0.0168 dlossR:0.0001 dlossQ:0.0168\n",
      "Episode:248 meanR:0.0100 rate:0.1538 gloss:-14.3267 dloss:1.6874 dlossR:1.6704 dlossQ:0.0169\n",
      "Episode:249 meanR:0.0300 rate:0.1538 gloss:-13.7321 dloss:1.6214 dlossR:1.6014 dlossQ:0.0200\n",
      "Episode:250 meanR:0.0300 rate:0.0000 gloss:-13.6192 dloss:0.0216 dlossR:0.0001 dlossQ:0.0215\n",
      "Episode:251 meanR:0.0500 rate:0.1538 gloss:-14.3169 dloss:1.6917 dlossR:1.6779 dlossQ:0.0138\n",
      "Episode:252 meanR:0.0500 rate:0.0000 gloss:-12.7203 dloss:0.0190 dlossR:0.0002 dlossQ:0.0188\n",
      "Episode:253 meanR:0.0500 rate:0.0000 gloss:-13.9276 dloss:0.0234 dlossR:0.0001 dlossQ:0.0232\n",
      "Episode:254 meanR:0.0400 rate:-0.0769 gloss:-9.7149 dloss:-0.5283 dlossR:-0.5506 dlossQ:0.0223\n",
      "Episode:255 meanR:0.0300 rate:0.0000 gloss:-9.9758 dloss:0.0187 dlossR:0.0007 dlossQ:0.0181\n",
      "Episode:256 meanR:0.0200 rate:-0.0769 gloss:-9.4825 dloss:-0.5098 dlossR:-0.5292 dlossQ:0.0194\n",
      "Episode:257 meanR:0.0200 rate:0.0000 gloss:-9.7711 dloss:0.0190 dlossR:0.0007 dlossQ:0.0183\n",
      "Episode:258 meanR:0.0200 rate:0.0000 gloss:-9.2746 dloss:0.0231 dlossR:0.0012 dlossQ:0.0219\n",
      "Episode:259 meanR:-0.0100 rate:0.0000 gloss:-10.5638 dloss:0.0188 dlossR:0.0007 dlossQ:0.0181\n",
      "Episode:260 meanR:-0.0200 rate:-0.0769 gloss:-9.9582 dloss:-0.5275 dlossR:-0.5670 dlossQ:0.0395\n",
      "Episode:261 meanR:0.0100 rate:0.0769 gloss:-9.6893 dloss:0.6159 dlossR:0.5717 dlossQ:0.0442\n",
      "Episode:262 meanR:0.0000 rate:0.0769 gloss:-9.1176 dloss:0.5929 dlossR:0.5395 dlossQ:0.0534\n",
      "Episode:263 meanR:0.0100 rate:0.0769 gloss:-10.3477 dloss:0.6385 dlossR:0.6083 dlossQ:0.0302\n",
      "Episode:264 meanR:0.0000 rate:0.0000 gloss:-8.6996 dloss:0.0791 dlossR:0.0081 dlossQ:0.0710\n",
      "Episode:265 meanR:-0.0100 rate:0.0000 gloss:-8.9814 dloss:0.0522 dlossR:0.0045 dlossQ:0.0477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:266 meanR:-0.0100 rate:0.0000 gloss:-8.6233 dloss:0.0720 dlossR:0.0079 dlossQ:0.0642\n",
      "Episode:267 meanR:-0.0300 rate:-0.1538 gloss:-8.4223 dloss:-0.9064 dlossR:-0.9478 dlossQ:0.0414\n",
      "Episode:268 meanR:-0.0300 rate:-0.0769 gloss:-8.3815 dloss:-0.4108 dlossR:-0.4715 dlossQ:0.0607\n",
      "Episode:269 meanR:-0.0500 rate:-0.0769 gloss:-8.9644 dloss:-0.4479 dlossR:-0.5065 dlossQ:0.0585\n",
      "Episode:270 meanR:-0.0700 rate:-0.1538 gloss:-7.6879 dloss:-0.7971 dlossR:-0.8621 dlossQ:0.0651\n",
      "Episode:271 meanR:-0.0900 rate:-0.1538 gloss:-7.5284 dloss:-0.8080 dlossR:-0.8496 dlossQ:0.0415\n",
      "Episode:272 meanR:-0.0800 rate:0.0769 gloss:-7.6809 dloss:0.5081 dlossR:0.4564 dlossQ:0.0517\n",
      "Episode:273 meanR:-0.0300 rate:0.3846 gloss:-8.8949 dloss:2.7482 dlossR:2.7219 dlossQ:0.0263\n",
      "Episode:274 meanR:-0.0100 rate:0.0000 gloss:-10.6412 dloss:0.0405 dlossR:0.0027 dlossQ:0.0378\n",
      "Episode:275 meanR:0.0200 rate:0.0000 gloss:-11.2298 dloss:0.0571 dlossR:0.0027 dlossQ:0.0544\n",
      "Episode:276 meanR:0.0100 rate:-0.0769 gloss:-14.1845 dloss:-0.7905 dlossR:-0.8104 dlossQ:0.0200\n",
      "Episode:277 meanR:-0.0100 rate:-0.0769 gloss:-13.9078 dloss:-0.7702 dlossR:-0.7934 dlossQ:0.0232\n",
      "Episode:278 meanR:0.0100 rate:0.0000 gloss:-10.5729 dloss:0.0336 dlossR:0.0032 dlossQ:0.0304\n",
      "Episode:279 meanR:0.0100 rate:-0.0769 gloss:-9.3293 dloss:-0.4874 dlossR:-0.5251 dlossQ:0.0377\n",
      "Episode:280 meanR:0.0100 rate:0.0769 gloss:-8.2254 dloss:0.5264 dlossR:0.4842 dlossQ:0.0422\n",
      "Episode:281 meanR:0.0200 rate:0.0000 gloss:-7.6949 dloss:0.0485 dlossR:0.0055 dlossQ:0.0430\n",
      "Episode:282 meanR:-0.0500 rate:-0.0769 gloss:-8.6656 dloss:-0.4583 dlossR:-0.4895 dlossQ:0.0312\n",
      "Episode:283 meanR:-0.0500 rate:-0.0769 gloss:-7.6595 dloss:-0.3928 dlossR:-0.4284 dlossQ:0.0356\n",
      "Episode:284 meanR:-0.0400 rate:0.0769 gloss:-7.1739 dloss:0.4834 dlossR:0.4256 dlossQ:0.0578\n",
      "Episode:285 meanR:-0.0500 rate:0.0000 gloss:-8.5980 dloss:0.0513 dlossR:0.0052 dlossQ:0.0461\n",
      "Episode:286 meanR:-0.0600 rate:-0.0769 gloss:-10.7539 dloss:-0.5829 dlossR:-0.6070 dlossQ:0.0241\n",
      "Episode:287 meanR:-0.0900 rate:-0.2308 gloss:-11.4091 dloss:-1.8569 dlossR:-1.8988 dlossQ:0.0419\n",
      "Episode:288 meanR:-0.0900 rate:0.0000 gloss:-11.5670 dloss:0.0205 dlossR:0.0006 dlossQ:0.0199\n",
      "Episode:289 meanR:-0.0700 rate:0.1538 gloss:-12.1594 dloss:1.4261 dlossR:1.4051 dlossQ:0.0211\n",
      "Episode:290 meanR:-0.1100 rate:0.0000 gloss:-16.8107 dloss:0.0175 dlossR:0.0002 dlossQ:0.0173\n",
      "Episode:291 meanR:-0.0400 rate:0.3846 gloss:-10.6228 dloss:3.2700 dlossR:3.2287 dlossQ:0.0412\n",
      "Episode:292 meanR:-0.0900 rate:-0.0769 gloss:-16.1478 dloss:-0.8687 dlossR:-0.9113 dlossQ:0.0426\n",
      "Episode:293 meanR:-0.0900 rate:-0.0769 gloss:-12.2538 dloss:-0.6703 dlossR:-0.6884 dlossQ:0.0181\n",
      "Episode:294 meanR:-0.0800 rate:0.0769 gloss:-16.8654 dloss:0.9810 dlossR:0.9635 dlossQ:0.0174\n",
      "Episode:295 meanR:-0.1000 rate:-0.0769 gloss:-15.1653 dloss:-0.8368 dlossR:-0.8568 dlossQ:0.0200\n",
      "Episode:296 meanR:-0.1200 rate:-0.0769 gloss:-13.3307 dloss:-0.7163 dlossR:-0.7496 dlossQ:0.0333\n",
      "Episode:297 meanR:-0.1200 rate:-0.0769 gloss:-13.2473 dloss:-0.6992 dlossR:-0.7522 dlossQ:0.0531\n",
      "Episode:298 meanR:-0.0800 rate:0.1538 gloss:-11.5309 dloss:1.4035 dlossR:1.3497 dlossQ:0.0538\n",
      "Episode:299 meanR:-0.0700 rate:0.0000 gloss:-10.0750 dloss:0.1499 dlossR:0.0113 dlossQ:0.1386\n",
      "Episode:300 meanR:-0.0300 rate:0.1538 gloss:-9.0005 dloss:1.2439 dlossR:1.0723 dlossQ:0.1716\n",
      "Episode:301 meanR:-0.0400 rate:-0.0769 gloss:-8.7964 dloss:-0.3712 dlossR:-0.4882 dlossQ:0.1170\n",
      "Episode:302 meanR:-0.0400 rate:0.0000 gloss:-11.8817 dloss:0.6614 dlossR:0.0384 dlossQ:0.6230\n",
      "Episode:303 meanR:-0.0200 rate:0.1538 gloss:-7.7974 dloss:1.2900 dlossR:0.9472 dlossQ:0.3429\n",
      "Episode:304 meanR:0.0000 rate:0.0769 gloss:-6.9439 dloss:0.6233 dlossR:0.4360 dlossQ:0.1873\n",
      "Episode:305 meanR:-0.0100 rate:0.0769 gloss:-6.6619 dloss:0.5871 dlossR:0.4153 dlossQ:0.1718\n",
      "Episode:306 meanR:-0.0300 rate:-0.1538 gloss:-4.9197 dloss:-0.2927 dlossR:-0.4995 dlossQ:0.2068\n",
      "Episode:307 meanR:0.0100 rate:0.3077 gloss:-4.1794 dloss:1.3817 dlossR:1.1333 dlossQ:0.2484\n",
      "Episode:308 meanR:-0.0300 rate:-0.3846 gloss:-4.7165 dloss:-0.9972 dlossR:-1.1872 dlossQ:0.1900\n",
      "Episode:309 meanR:-0.0400 rate:0.0000 gloss:-7.0361 dloss:0.4422 dlossR:0.0646 dlossQ:0.3776\n",
      "Episode:310 meanR:-0.0300 rate:0.0769 gloss:-5.9308 dloss:0.5547 dlossR:0.3765 dlossQ:0.1783\n",
      "Episode:311 meanR:-0.0400 rate:-0.0769 gloss:-6.6204 dloss:-0.2060 dlossR:-0.3501 dlossQ:0.1441\n",
      "Episode:312 meanR:-0.0300 rate:0.0000 gloss:-5.4416 dloss:0.1725 dlossR:0.0271 dlossQ:0.1453\n",
      "Episode:313 meanR:-0.0200 rate:0.0000 gloss:-6.5194 dloss:0.1286 dlossR:0.0181 dlossQ:0.1105\n",
      "Episode:314 meanR:-0.0100 rate:0.0769 gloss:-7.4788 dloss:0.5531 dlossR:0.4479 dlossQ:0.1052\n",
      "Episode:315 meanR:0.0000 rate:0.0769 gloss:-6.0729 dloss:0.4718 dlossR:0.3718 dlossQ:0.1001\n",
      "Episode:316 meanR:0.0000 rate:0.0000 gloss:-5.6815 dloss:0.1174 dlossR:0.0181 dlossQ:0.0993\n",
      "Episode:317 meanR:0.0300 rate:0.1538 gloss:-6.4709 dloss:0.8593 dlossR:0.7757 dlossQ:0.0836\n",
      "Episode:318 meanR:0.1000 rate:0.5385 gloss:-5.8273 dloss:2.7448 dlossR:2.6394 dlossQ:0.1055\n",
      "Episode:319 meanR:0.1200 rate:0.1538 gloss:-7.6109 dloss:0.9580 dlossR:0.9051 dlossQ:0.0529\n",
      "Episode:320 meanR:0.2100 rate:0.5385 gloss:-7.6616 dloss:3.4511 dlossR:3.3735 dlossQ:0.0776\n",
      "Episode:321 meanR:0.2200 rate:0.1538 gloss:-5.9482 dloss:0.9005 dlossR:0.7390 dlossQ:0.1615\n",
      "Episode:322 meanR:0.2700 rate:0.3846 gloss:-5.6754 dloss:2.0193 dlossR:1.8098 dlossQ:0.2095\n",
      "Episode:323 meanR:0.2700 rate:0.0000 gloss:-5.4019 dloss:0.2942 dlossR:0.0559 dlossQ:0.2383\n",
      "Episode:324 meanR:0.3200 rate:0.4615 gloss:-3.7991 dloss:1.9526 dlossR:1.5926 dlossQ:0.3599\n",
      "Episode:325 meanR:0.3200 rate:0.0769 gloss:-4.5028 dloss:0.6475 dlossR:0.3418 dlossQ:0.3056\n",
      "Episode:326 meanR:0.3400 rate:0.0769 gloss:-2.8818 dloss:0.8624 dlossR:0.3656 dlossQ:0.4968\n",
      "Episode:327 meanR:0.4100 rate:0.4615 gloss:-1.1018 dloss:1.5523 dlossR:0.8885 dlossQ:0.6638\n",
      "Episode:328 meanR:0.4300 rate:0.1538 gloss:-0.9612 dloss:1.1620 dlossR:0.5080 dlossQ:0.6540\n",
      "Episode:329 meanR:0.4300 rate:0.0769 gloss:-0.9138 dloss:1.1518 dlossR:0.5008 dlossQ:0.6510\n",
      "Episode:330 meanR:0.4800 rate:0.3846 gloss:-0.0983 dloss:1.4073 dlossR:0.6955 dlossQ:0.7118\n",
      "Episode:331 meanR:0.5200 rate:0.2308 gloss:-0.0676 dloss:1.3386 dlossR:0.6393 dlossQ:0.6993\n",
      "Episode:332 meanR:0.5000 rate:-0.1538 gloss:-0.7005 dloss:1.1449 dlossR:0.4796 dlossQ:0.6653\n",
      "Episode:333 meanR:0.5400 rate:0.3077 gloss:-0.0635 dloss:1.3478 dlossR:0.6445 dlossQ:0.7033\n",
      "Episode:334 meanR:0.5900 rate:0.3077 gloss:-0.1376 dloss:1.3456 dlossR:0.6404 dlossQ:0.7052\n",
      "Episode:335 meanR:0.6100 rate:0.1538 gloss:-0.4281 dloss:1.2463 dlossR:0.5619 dlossQ:0.6843\n",
      "Episode:336 meanR:0.6600 rate:0.3846 gloss:-0.1208 dloss:1.3824 dlossR:0.6700 dlossQ:0.7124\n",
      "Episode:337 meanR:0.7200 rate:0.3077 gloss:-0.3079 dloss:1.3329 dlossR:0.6312 dlossQ:0.7017\n",
      "Episode:338 meanR:0.7400 rate:0.1538 gloss:-0.4889 dloss:1.2356 dlossR:0.5526 dlossQ:0.6830\n",
      "Episode:339 meanR:0.7500 rate:0.0769 gloss:-0.8071 dloss:1.1242 dlossR:0.4672 dlossQ:0.6570\n",
      "Episode:340 meanR:0.7800 rate:0.2308 gloss:-0.5123 dloss:1.2710 dlossR:0.5819 dlossQ:0.6890\n",
      "Episode:341 meanR:0.7800 rate:-0.0769 gloss:-1.0685 dloss:0.9842 dlossR:0.3523 dlossQ:0.6319\n",
      "Episode:342 meanR:0.8300 rate:0.3846 gloss:-0.3983 dloss:1.3925 dlossR:0.6803 dlossQ:0.7122\n",
      "Episode:343 meanR:0.8300 rate:0.0000 gloss:-1.0907 dloss:1.0104 dlossR:0.3785 dlossQ:0.6319\n",
      "Episode:344 meanR:0.8500 rate:0.0769 gloss:-1.0813 dloss:1.0646 dlossR:0.4259 dlossQ:0.6386\n",
      "Episode:345 meanR:0.8800 rate:0.3077 gloss:-0.8385 dloss:1.3114 dlossR:0.6325 dlossQ:0.6789\n",
      "Episode:346 meanR:0.9100 rate:0.2308 gloss:-0.9980 dloss:1.2195 dlossR:0.5592 dlossQ:0.6603\n",
      "Episode:347 meanR:0.9000 rate:-0.0769 gloss:-1.4922 dloss:0.8309 dlossR:0.2421 dlossQ:0.5888\n",
      "Episode:348 meanR:0.8800 rate:0.0000 gloss:-1.2872 dloss:0.9579 dlossR:0.3476 dlossQ:0.6103\n",
      "Episode:349 meanR:0.8600 rate:0.0000 gloss:-1.6563 dloss:0.8428 dlossR:0.2742 dlossQ:0.5686\n",
      "Episode:350 meanR:0.8800 rate:0.1538 gloss:-1.5334 dloss:1.0545 dlossR:0.4593 dlossQ:0.5952\n",
      "Episode:351 meanR:0.8700 rate:0.0769 gloss:-1.8251 dloss:0.9027 dlossR:0.3442 dlossQ:0.5585\n",
      "Episode:352 meanR:0.8900 rate:0.1538 gloss:-1.5681 dloss:1.0579 dlossR:0.4568 dlossQ:0.6011\n",
      "Episode:353 meanR:0.9200 rate:0.2308 gloss:-1.5126 dloss:1.1733 dlossR:0.5571 dlossQ:0.6162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:354 meanR:0.9200 rate:-0.0769 gloss:-2.2822 dloss:0.5966 dlossR:0.0803 dlossQ:0.5163\n",
      "Episode:355 meanR:0.9300 rate:0.0769 gloss:-1.9830 dloss:0.8418 dlossR:0.3271 dlossQ:0.5148\n",
      "Episode:356 meanR:0.9500 rate:0.0769 gloss:-1.5729 dloss:0.9319 dlossR:0.3660 dlossQ:0.5659\n",
      "Episode:357 meanR:0.9500 rate:0.0000 gloss:-2.0637 dloss:0.6932 dlossR:0.2028 dlossQ:0.4905\n",
      "Episode:358 meanR:0.9500 rate:0.0000 gloss:-1.6846 dloss:0.8003 dlossR:0.2617 dlossQ:0.5387\n",
      "Episode:359 meanR:0.9500 rate:0.0000 gloss:-2.2903 dloss:0.6122 dlossR:0.1715 dlossQ:0.4407\n",
      "Episode:360 meanR:0.9700 rate:0.0769 gloss:-1.6090 dloss:0.8975 dlossR:0.3466 dlossQ:0.5509\n",
      "Episode:361 meanR:0.9600 rate:0.0000 gloss:-2.3196 dloss:0.6071 dlossR:0.1685 dlossQ:0.4385\n",
      "Episode:362 meanR:0.9500 rate:0.0000 gloss:-2.4289 dloss:0.5863 dlossR:0.1616 dlossQ:0.4247\n",
      "Episode:363 meanR:0.9300 rate:-0.0769 gloss:-3.1793 dloss:0.2504 dlossR:-0.0693 dlossQ:0.3197\n",
      "Episode:364 meanR:0.9300 rate:0.0000 gloss:-3.9018 dloss:0.2915 dlossR:0.0592 dlossQ:0.2323\n",
      "Episode:365 meanR:0.9400 rate:0.0769 gloss:-4.4543 dloss:0.4876 dlossR:0.2991 dlossQ:0.1885\n",
      "Episode:366 meanR:0.9300 rate:-0.0769 gloss:-5.3084 dloss:-0.1413 dlossR:-0.2689 dlossQ:0.1276\n",
      "Episode:367 meanR:0.9300 rate:-0.1538 gloss:-6.0265 dloss:-0.5541 dlossR:-0.6432 dlossQ:0.0891\n",
      "Episode:368 meanR:0.9400 rate:0.0000 gloss:-5.8706 dloss:0.1087 dlossR:0.0159 dlossQ:0.0928\n",
      "Episode:369 meanR:0.9600 rate:0.0769 gloss:-6.2396 dloss:0.4605 dlossR:0.3712 dlossQ:0.0893\n",
      "Episode:370 meanR:0.9800 rate:0.0000 gloss:-6.0930 dloss:0.1062 dlossR:0.0143 dlossQ:0.0919\n",
      "Episode:371 meanR:1.0000 rate:0.0000 gloss:-6.3492 dloss:0.0839 dlossR:0.0116 dlossQ:0.0723\n",
      "Episode:372 meanR:1.0000 rate:0.0769 gloss:-6.8479 dloss:0.4578 dlossR:0.4024 dlossQ:0.0554\n",
      "Episode:373 meanR:0.9500 rate:0.0000 gloss:-5.5128 dloss:0.1298 dlossR:0.0209 dlossQ:0.1089\n",
      "Episode:374 meanR:0.9700 rate:0.1538 gloss:-6.6195 dloss:0.8489 dlossR:0.7837 dlossQ:0.0652\n",
      "Episode:375 meanR:0.9800 rate:0.0769 gloss:-6.8087 dloss:0.4563 dlossR:0.4002 dlossQ:0.0561\n",
      "Episode:376 meanR:1.0100 rate:0.1538 gloss:-6.7842 dloss:0.8604 dlossR:0.8027 dlossQ:0.0577\n",
      "Episode:377 meanR:1.0200 rate:0.0000 gloss:-6.2231 dloss:0.0964 dlossR:0.0137 dlossQ:0.0826\n",
      "Episode:378 meanR:1.0100 rate:-0.0769 gloss:-6.4472 dloss:-0.2655 dlossR:-0.3446 dlossQ:0.0791\n",
      "Episode:379 meanR:1.0600 rate:0.3077 gloss:-6.2717 dloss:1.6311 dlossR:1.5290 dlossQ:0.1021\n",
      "Episode:380 meanR:1.0600 rate:0.0769 gloss:-7.8182 dloss:0.5269 dlossR:0.4571 dlossQ:0.0698\n",
      "Episode:381 meanR:1.0600 rate:0.0000 gloss:-5.4910 dloss:0.2325 dlossR:0.0356 dlossQ:0.1969\n",
      "Episode:382 meanR:1.1000 rate:0.2308 gloss:-4.7624 dloss:1.0734 dlossR:0.8985 dlossQ:0.1749\n",
      "Episode:383 meanR:1.1300 rate:0.1538 gloss:-4.2962 dloss:0.7629 dlossR:0.5553 dlossQ:0.2076\n",
      "Episode:384 meanR:1.1100 rate:-0.0769 gloss:-4.5485 dloss:-0.0455 dlossR:-0.2115 dlossQ:0.1660\n",
      "Episode:385 meanR:1.1100 rate:0.0000 gloss:-4.0124 dloss:0.2914 dlossR:0.0600 dlossQ:0.2314\n",
      "Episode:386 meanR:1.1200 rate:0.0000 gloss:-3.7479 dloss:0.3402 dlossR:0.0726 dlossQ:0.2676\n",
      "Episode:387 meanR:1.1500 rate:0.0000 gloss:-4.6902 dloss:0.2550 dlossR:0.0513 dlossQ:0.2037\n",
      "Episode:388 meanR:1.1500 rate:0.0000 gloss:-4.2446 dloss:0.3119 dlossR:0.0657 dlossQ:0.2462\n",
      "Episode:389 meanR:1.1300 rate:0.0000 gloss:-4.2561 dloss:0.3166 dlossR:0.0691 dlossQ:0.2475\n",
      "Episode:390 meanR:1.1400 rate:0.0769 gloss:-3.8686 dloss:0.5927 dlossR:0.3054 dlossQ:0.2873\n",
      "Episode:391 meanR:1.1000 rate:0.0769 gloss:-3.7618 dloss:0.6135 dlossR:0.3080 dlossQ:0.3056\n",
      "Episode:392 meanR:1.1200 rate:0.0769 gloss:-3.5493 dloss:0.6701 dlossR:0.3108 dlossQ:0.3593\n",
      "Episode:393 meanR:1.1300 rate:0.0000 gloss:-3.2857 dloss:0.4826 dlossR:0.1147 dlossQ:0.3680\n",
      "Episode:394 meanR:1.1200 rate:0.0000 gloss:-3.9759 dloss:0.4343 dlossR:0.0844 dlossQ:0.3499\n",
      "Episode:395 meanR:1.1200 rate:-0.0769 gloss:-4.0024 dloss:0.1379 dlossR:-0.1437 dlossQ:0.2816\n",
      "Episode:396 meanR:1.1400 rate:0.0769 gloss:-3.0089 dloss:0.6467 dlossR:0.2877 dlossQ:0.3590\n",
      "Episode:397 meanR:1.1400 rate:-0.0769 gloss:-3.4946 dloss:0.1683 dlossR:-0.1068 dlossQ:0.2751\n",
      "Episode:398 meanR:1.1300 rate:0.0769 gloss:-2.9997 dloss:0.6057 dlossR:0.2732 dlossQ:0.3325\n",
      "Episode:399 meanR:1.1300 rate:0.0000 gloss:-3.1864 dloss:0.4139 dlossR:0.0982 dlossQ:0.3157\n",
      "Episode:400 meanR:1.1100 rate:0.0000 gloss:-2.9641 dloss:0.4630 dlossR:0.1172 dlossQ:0.3458\n",
      "Episode:401 meanR:1.1200 rate:0.0000 gloss:-3.7240 dloss:0.3163 dlossR:0.0660 dlossQ:0.2502\n",
      "Episode:402 meanR:1.1400 rate:0.1538 gloss:-3.1185 dloss:0.7986 dlossR:0.4694 dlossQ:0.3292\n",
      "Episode:403 meanR:1.1200 rate:0.0000 gloss:-3.7103 dloss:0.3253 dlossR:0.0716 dlossQ:0.2537\n",
      "Episode:404 meanR:1.1100 rate:0.0000 gloss:-4.1980 dloss:0.2444 dlossR:0.0476 dlossQ:0.1968\n",
      "Episode:405 meanR:1.1100 rate:0.0769 gloss:-3.8403 dloss:0.5147 dlossR:0.2804 dlossQ:0.2344\n",
      "Episode:406 meanR:1.1400 rate:0.0769 gloss:-4.3761 dloss:0.4772 dlossR:0.2941 dlossQ:0.1831\n",
      "Episode:407 meanR:1.1000 rate:0.0000 gloss:-4.4123 dloss:0.2182 dlossR:0.0404 dlossQ:0.1778\n",
      "Episode:408 meanR:1.1500 rate:0.0000 gloss:-4.4016 dloss:0.2246 dlossR:0.0420 dlossQ:0.1826\n",
      "Episode:409 meanR:1.1600 rate:0.0769 gloss:-4.6887 dloss:0.4647 dlossR:0.3040 dlossQ:0.1606\n",
      "Episode:410 meanR:1.1500 rate:0.0000 gloss:-4.5953 dloss:0.2031 dlossR:0.0360 dlossQ:0.1670\n",
      "Episode:411 meanR:1.1700 rate:0.0769 gloss:-4.7959 dloss:0.4576 dlossR:0.3071 dlossQ:0.1505\n",
      "Episode:412 meanR:1.1800 rate:0.0769 gloss:-4.7637 dloss:0.4588 dlossR:0.3060 dlossQ:0.1528\n",
      "Episode:413 meanR:1.1700 rate:-0.0769 gloss:-4.6886 dloss:-0.0683 dlossR:-0.2226 dlossQ:0.1543\n",
      "Episode:414 meanR:1.1400 rate:-0.1538 gloss:-5.3211 dloss:-0.4433 dlossR:-0.5537 dlossQ:0.1104\n",
      "Episode:415 meanR:1.1000 rate:-0.2308 gloss:-5.3040 dloss:-0.7058 dlossR:-0.8206 dlossQ:0.1148\n",
      "Episode:416 meanR:1.1000 rate:0.0000 gloss:-5.3916 dloss:0.1289 dlossR:0.0202 dlossQ:0.1087\n",
      "Episode:417 meanR:1.0700 rate:-0.0769 gloss:-5.2988 dloss:-0.1553 dlossR:-0.2702 dlossQ:0.1149\n",
      "Episode:418 meanR:1.0100 rate:0.0769 gloss:-5.6534 dloss:0.4362 dlossR:0.3411 dlossQ:0.0951\n",
      "Episode:419 meanR:0.9800 rate:-0.0769 gloss:-6.4377 dloss:-0.2817 dlossR:-0.3471 dlossQ:0.0654\n",
      "Episode:420 meanR:0.9000 rate:-0.0769 gloss:-6.7137 dloss:-0.3080 dlossR:-0.3654 dlossQ:0.0574\n",
      "Episode:421 meanR:0.8900 rate:0.0769 gloss:-6.0094 dloss:0.4428 dlossR:0.3586 dlossQ:0.0842\n",
      "Episode:422 meanR:0.8500 rate:0.0769 gloss:-6.4771 dloss:0.4474 dlossR:0.3815 dlossQ:0.0659\n",
      "Episode:423 meanR:0.8600 rate:0.0769 gloss:-7.3868 dloss:0.4743 dlossR:0.4288 dlossQ:0.0455\n",
      "Episode:424 meanR:0.8000 rate:0.0000 gloss:-6.8856 dloss:0.0646 dlossR:0.0078 dlossQ:0.0567\n",
      "Episode:425 meanR:0.7900 rate:0.0000 gloss:-7.2076 dloss:0.0475 dlossR:0.0051 dlossQ:0.0423\n",
      "Episode:426 meanR:0.7800 rate:0.0000 gloss:-7.2715 dloss:0.0551 dlossR:0.0061 dlossQ:0.0490\n",
      "Episode:427 meanR:0.7300 rate:0.0769 gloss:-7.3892 dloss:0.4862 dlossR:0.4300 dlossQ:0.0562\n",
      "Episode:428 meanR:0.7000 rate:-0.0769 gloss:-7.6944 dloss:-0.3798 dlossR:-0.4236 dlossQ:0.0438\n",
      "Episode:429 meanR:0.6800 rate:-0.0769 gloss:-7.8637 dloss:-0.3994 dlossR:-0.4348 dlossQ:0.0355\n",
      "Episode:430 meanR:0.6200 rate:-0.0769 gloss:-7.4443 dloss:-0.3660 dlossR:-0.4091 dlossQ:0.0431\n",
      "Episode:431 meanR:0.5900 rate:0.0000 gloss:-7.2540 dloss:0.0536 dlossR:0.0060 dlossQ:0.0477\n",
      "Episode:432 meanR:0.6000 rate:-0.0769 gloss:-8.3136 dloss:-0.4300 dlossR:-0.4610 dlossQ:0.0310\n",
      "Episode:433 meanR:0.5700 rate:0.0769 gloss:-7.7522 dloss:0.4866 dlossR:0.4478 dlossQ:0.0388\n",
      "Episode:434 meanR:0.5200 rate:-0.0769 gloss:-9.0541 dloss:-0.4765 dlossR:-0.5030 dlossQ:0.0265\n",
      "Episode:435 meanR:0.4900 rate:-0.0769 gloss:-7.4797 dloss:-0.3696 dlossR:-0.4101 dlossQ:0.0405\n",
      "Episode:436 meanR:0.4400 rate:0.0000 gloss:-7.9671 dloss:0.0368 dlossR:0.0036 dlossQ:0.0332\n",
      "Episode:437 meanR:0.3900 rate:-0.0769 gloss:-7.9369 dloss:-0.4068 dlossR:-0.4395 dlossQ:0.0328\n",
      "Episode:438 meanR:0.3700 rate:0.0000 gloss:-8.2265 dloss:0.0304 dlossR:0.0025 dlossQ:0.0280\n",
      "Episode:439 meanR:0.3500 rate:-0.0769 gloss:-8.9620 dloss:-0.4754 dlossR:-0.4998 dlossQ:0.0244\n",
      "Episode:440 meanR:0.3200 rate:0.0000 gloss:-9.6625 dloss:0.0232 dlossR:0.0011 dlossQ:0.0222\n",
      "Episode:441 meanR:0.3300 rate:0.0000 gloss:-11.0306 dloss:0.0188 dlossR:0.0004 dlossQ:0.0184\n",
      "Episode:442 meanR:0.2800 rate:0.0000 gloss:-10.6969 dloss:0.0208 dlossR:0.0013 dlossQ:0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:443 meanR:0.2800 rate:0.0000 gloss:-11.0727 dloss:0.0181 dlossR:0.0005 dlossQ:0.0176\n",
      "Episode:444 meanR:0.2700 rate:0.0000 gloss:-10.1782 dloss:0.0203 dlossR:0.0006 dlossQ:0.0196\n",
      "Episode:445 meanR:0.2300 rate:0.0000 gloss:-12.1951 dloss:0.0157 dlossR:0.0002 dlossQ:0.0155\n",
      "Episode:446 meanR:0.2000 rate:0.0000 gloss:-10.8834 dloss:0.0205 dlossR:0.0004 dlossQ:0.0201\n",
      "Episode:447 meanR:0.2000 rate:-0.0769 gloss:-8.5757 dloss:-0.4512 dlossR:-0.4768 dlossQ:0.0255\n",
      "Episode:448 meanR:0.2100 rate:0.0769 gloss:-9.4893 dloss:0.5648 dlossR:0.5448 dlossQ:0.0200\n",
      "Episode:449 meanR:0.2100 rate:0.0000 gloss:-8.6463 dloss:0.0278 dlossR:0.0019 dlossQ:0.0259\n",
      "Episode:450 meanR:0.1900 rate:0.0000 gloss:-10.5569 dloss:0.0176 dlossR:0.0005 dlossQ:0.0171\n",
      "Episode:451 meanR:0.2000 rate:0.1538 gloss:-11.6203 dloss:1.3519 dlossR:1.3357 dlossQ:0.0162\n",
      "Episode:452 meanR:0.1800 rate:0.0000 gloss:-12.2977 dloss:0.0182 dlossR:0.0001 dlossQ:0.0180\n",
      "Episode:453 meanR:0.1500 rate:0.0000 gloss:-11.4191 dloss:0.0192 dlossR:0.0003 dlossQ:0.0188\n",
      "Episode:454 meanR:0.1500 rate:-0.0769 gloss:-12.9360 dloss:-0.7175 dlossR:-0.7354 dlossQ:0.0178\n",
      "Episode:455 meanR:0.1400 rate:0.0000 gloss:-9.5395 dloss:0.0205 dlossR:0.0010 dlossQ:0.0195\n",
      "Episode:456 meanR:0.1400 rate:0.0769 gloss:-10.8046 dloss:0.6413 dlossR:0.6234 dlossQ:0.0179\n",
      "Episode:457 meanR:0.1400 rate:0.0000 gloss:-11.7683 dloss:0.0229 dlossR:0.0003 dlossQ:0.0226\n",
      "Episode:458 meanR:0.1300 rate:-0.0769 gloss:-11.7316 dloss:-0.6441 dlossR:-0.6621 dlossQ:0.0180\n",
      "Episode:459 meanR:0.1300 rate:0.0000 gloss:-11.2539 dloss:0.0198 dlossR:0.0004 dlossQ:0.0194\n",
      "Episode:460 meanR:0.1200 rate:0.0000 gloss:-11.6452 dloss:0.0161 dlossR:0.0003 dlossQ:0.0158\n",
      "Episode:461 meanR:0.1200 rate:0.0000 gloss:-11.7202 dloss:0.0160 dlossR:0.0002 dlossQ:0.0158\n",
      "Episode:462 meanR:0.1200 rate:0.0000 gloss:-13.8373 dloss:0.0181 dlossR:0.0002 dlossQ:0.0179\n",
      "Episode:463 meanR:0.1400 rate:0.0769 gloss:-12.4722 dloss:0.7353 dlossR:0.7182 dlossQ:0.0172\n",
      "Episode:464 meanR:0.1300 rate:-0.0769 gloss:-10.9117 dloss:-0.5978 dlossR:-0.6147 dlossQ:0.0169\n",
      "Episode:465 meanR:0.1300 rate:0.0769 gloss:-10.3743 dloss:0.6163 dlossR:0.5974 dlossQ:0.0188\n",
      "Episode:466 meanR:0.1400 rate:0.0000 gloss:-10.3795 dloss:0.0193 dlossR:0.0007 dlossQ:0.0186\n",
      "Episode:467 meanR:0.1500 rate:-0.0769 gloss:-10.5653 dloss:-0.5823 dlossR:-0.5998 dlossQ:0.0175\n",
      "Episode:468 meanR:0.1400 rate:-0.0769 gloss:-11.0243 dloss:-0.6071 dlossR:-0.6226 dlossQ:0.0156\n",
      "Episode:469 meanR:0.1200 rate:-0.0769 gloss:-11.0331 dloss:-0.6029 dlossR:-0.6205 dlossQ:0.0176\n",
      "Episode:470 meanR:0.1200 rate:0.0000 gloss:-10.2276 dloss:0.0183 dlossR:0.0006 dlossQ:0.0177\n",
      "Episode:471 meanR:0.1200 rate:0.0000 gloss:-10.3932 dloss:0.0183 dlossR:0.0006 dlossQ:0.0177\n",
      "Episode:472 meanR:0.1100 rate:0.0000 gloss:-12.2835 dloss:0.0153 dlossR:0.0002 dlossQ:0.0152\n",
      "Episode:473 meanR:0.1100 rate:0.0000 gloss:-12.7499 dloss:0.0161 dlossR:0.0001 dlossQ:0.0159\n",
      "Episode:474 meanR:0.0900 rate:0.0000 gloss:-9.0972 dloss:0.0289 dlossR:0.0020 dlossQ:0.0269\n",
      "Episode:475 meanR:0.1000 rate:0.1538 gloss:-9.1568 dloss:1.1067 dlossR:1.0776 dlossQ:0.0291\n",
      "Episode:476 meanR:0.1000 rate:0.1538 gloss:-10.2110 dloss:1.2144 dlossR:1.1933 dlossQ:0.0211\n",
      "Episode:477 meanR:0.1700 rate:0.5385 gloss:-10.4213 dloss:4.4878 dlossR:4.4666 dlossQ:0.0211\n",
      "Episode:478 meanR:0.1800 rate:0.0000 gloss:-10.5185 dloss:0.0276 dlossR:0.0013 dlossQ:0.0263\n",
      "Episode:479 meanR:0.1500 rate:0.0769 gloss:-10.1906 dloss:0.6050 dlossR:0.5837 dlossQ:0.0213\n",
      "Episode:480 meanR:0.1500 rate:0.0769 gloss:-8.3185 dloss:0.5295 dlossR:0.4858 dlossQ:0.0437\n",
      "Episode:481 meanR:0.1500 rate:0.0000 gloss:-7.9669 dloss:0.0619 dlossR:0.0064 dlossQ:0.0556\n",
      "Episode:482 meanR:0.1100 rate:-0.0769 gloss:-7.5965 dloss:-0.3436 dlossR:-0.4185 dlossQ:0.0749\n",
      "Episode:483 meanR:0.0900 rate:0.0000 gloss:-7.2200 dloss:0.1010 dlossR:0.0110 dlossQ:0.0900\n",
      "Episode:484 meanR:0.1000 rate:0.0000 gloss:-7.2229 dloss:0.1050 dlossR:0.0122 dlossQ:0.0927\n",
      "Episode:485 meanR:0.0900 rate:-0.0769 gloss:-8.0785 dloss:-0.3794 dlossR:-0.4464 dlossQ:0.0670\n",
      "Episode:486 meanR:0.0900 rate:0.0000 gloss:-7.7503 dloss:0.0990 dlossR:0.0111 dlossQ:0.0879\n",
      "Episode:487 meanR:0.1000 rate:0.0769 gloss:-6.5024 dloss:0.5247 dlossR:0.3977 dlossQ:0.1270\n",
      "Episode:488 meanR:0.1000 rate:0.0000 gloss:-4.0131 dloss:0.3037 dlossR:0.0644 dlossQ:0.2394\n",
      "Episode:489 meanR:0.0900 rate:-0.0769 gloss:-8.0723 dloss:-0.3715 dlossR:-0.4427 dlossQ:0.0712\n",
      "Episode:490 meanR:0.1100 rate:0.2308 gloss:-5.9305 dloss:1.2694 dlossR:1.1024 dlossQ:0.1670\n",
      "Episode:491 meanR:0.1200 rate:0.1538 gloss:-4.2346 dloss:0.7956 dlossR:0.5601 dlossQ:0.2355\n",
      "Episode:492 meanR:0.1300 rate:0.1538 gloss:-3.8951 dloss:0.7628 dlossR:0.5231 dlossQ:0.2398\n",
      "Episode:493 meanR:0.1900 rate:0.4615 gloss:-2.7524 dloss:1.6487 dlossR:1.2513 dlossQ:0.3974\n",
      "Episode:494 meanR:0.1900 rate:0.0000 gloss:-3.0847 dloss:0.4572 dlossR:0.1138 dlossQ:0.3434\n",
      "Episode:495 meanR:0.1500 rate:-0.3846 gloss:-3.4134 dloss:-0.4116 dlossR:-0.7082 dlossQ:0.2966\n",
      "Episode:496 meanR:0.0800 rate:-0.4615 gloss:-3.0425 dloss:-0.3252 dlossR:-0.6669 dlossQ:0.3417\n",
      "Episode:497 meanR:0.1200 rate:0.2308 gloss:-2.5442 dloss:1.0525 dlossR:0.6210 dlossQ:0.4315\n",
      "Episode:498 meanR:0.0900 rate:-0.1538 gloss:-3.6450 dloss:0.0430 dlossR:-0.2739 dlossQ:0.3169\n",
      "Episode:499 meanR:0.0900 rate:0.0000 gloss:-6.7484 dloss:0.1728 dlossR:0.0221 dlossQ:0.1507\n",
      "Episode:500 meanR:0.0900 rate:0.0000 gloss:-6.3900 dloss:0.1813 dlossR:0.0260 dlossQ:0.1553\n",
      "Episode:501 meanR:0.1000 rate:0.0769 gloss:-5.3252 dloss:0.5770 dlossR:0.3478 dlossQ:0.2292\n",
      "Episode:502 meanR:0.0800 rate:0.0000 gloss:-3.9200 dloss:0.3087 dlossR:0.0662 dlossQ:0.2425\n",
      "Episode:503 meanR:0.0800 rate:0.0000 gloss:-4.4041 dloss:0.2453 dlossR:0.0485 dlossQ:0.1967\n",
      "Episode:504 meanR:0.0900 rate:0.0769 gloss:-2.8237 dloss:0.6610 dlossR:0.2895 dlossQ:0.3715\n",
      "Episode:505 meanR:0.0800 rate:0.0000 gloss:-3.6270 dloss:0.3557 dlossR:0.0814 dlossQ:0.2743\n",
      "Episode:506 meanR:0.0800 rate:0.0769 gloss:-4.9203 dloss:0.4889 dlossR:0.3224 dlossQ:0.1665\n",
      "Episode:507 meanR:0.0900 rate:0.0769 gloss:-4.4336 dloss:0.4770 dlossR:0.2963 dlossQ:0.1807\n",
      "Episode:508 meanR:0.1000 rate:0.0769 gloss:-5.4925 dloss:0.4540 dlossR:0.3390 dlossQ:0.1150\n",
      "Episode:509 meanR:0.0900 rate:0.0000 gloss:-5.2199 dloss:0.1628 dlossR:0.0290 dlossQ:0.1339\n",
      "Episode:510 meanR:0.1000 rate:0.0769 gloss:-4.4377 dloss:0.4906 dlossR:0.2978 dlossQ:0.1928\n",
      "Episode:511 meanR:0.1000 rate:0.0769 gloss:-5.5667 dloss:0.4514 dlossR:0.3418 dlossQ:0.1097\n",
      "Episode:512 meanR:0.1000 rate:0.0769 gloss:-4.1717 dloss:0.5082 dlossR:0.2926 dlossQ:0.2155\n",
      "Episode:513 meanR:0.1200 rate:0.0769 gloss:-4.9559 dloss:0.4767 dlossR:0.3189 dlossQ:0.1577\n",
      "Episode:514 meanR:0.1400 rate:0.0000 gloss:-4.8658 dloss:0.1744 dlossR:0.0303 dlossQ:0.1441\n",
      "Episode:515 meanR:0.1700 rate:0.0000 gloss:-5.7410 dloss:0.1233 dlossR:0.0185 dlossQ:0.1047\n",
      "Episode:516 meanR:0.1700 rate:0.0000 gloss:-4.3122 dloss:0.2625 dlossR:0.0533 dlossQ:0.2091\n",
      "Episode:517 meanR:0.1800 rate:0.0000 gloss:-4.7930 dloss:0.1889 dlossR:0.0336 dlossQ:0.1554\n",
      "Episode:518 meanR:0.1800 rate:0.0769 gloss:-4.9912 dloss:0.4636 dlossR:0.3168 dlossQ:0.1468\n",
      "Episode:519 meanR:0.1900 rate:0.0000 gloss:-4.9801 dloss:0.1783 dlossR:0.0307 dlossQ:0.1477\n",
      "Episode:520 meanR:0.2100 rate:0.0769 gloss:-4.7048 dloss:0.4684 dlossR:0.3054 dlossQ:0.1630\n",
      "Episode:521 meanR:0.1900 rate:-0.0769 gloss:-4.6743 dloss:-0.0546 dlossR:-0.2195 dlossQ:0.1649\n",
      "Episode:522 meanR:0.1900 rate:0.0769 gloss:-4.6265 dloss:0.4765 dlossR:0.3036 dlossQ:0.1728\n",
      "Episode:523 meanR:0.2100 rate:0.2308 gloss:-4.0471 dloss:1.0126 dlossR:0.7862 dlossQ:0.2264\n",
      "Episode:524 meanR:0.2100 rate:0.0000 gloss:-4.9770 dloss:0.1724 dlossR:0.0296 dlossQ:0.1429\n",
      "Episode:525 meanR:0.2300 rate:0.1538 gloss:-3.9376 dloss:0.7605 dlossR:0.5222 dlossQ:0.2383\n",
      "Episode:526 meanR:0.2500 rate:0.1538 gloss:-4.3546 dloss:0.7516 dlossR:0.5564 dlossQ:0.1952\n",
      "Episode:527 meanR:0.2200 rate:-0.1538 gloss:-4.7432 dloss:-0.3187 dlossR:-0.4744 dlossQ:0.1557\n",
      "Episode:528 meanR:0.2300 rate:0.0000 gloss:-4.7538 dloss:0.1905 dlossR:0.0335 dlossQ:0.1570\n",
      "Episode:529 meanR:0.2400 rate:0.0000 gloss:-4.7683 dloss:0.1879 dlossR:0.0337 dlossQ:0.1542\n",
      "Episode:530 meanR:0.2500 rate:0.0000 gloss:-4.0443 dloss:0.2710 dlossR:0.0551 dlossQ:0.2159\n",
      "Episode:531 meanR:0.2400 rate:-0.0769 gloss:-4.6669 dloss:-0.0578 dlossR:-0.2191 dlossQ:0.1613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:532 meanR:0.2500 rate:0.0000 gloss:-4.8003 dloss:0.1695 dlossR:0.0295 dlossQ:0.1400\n",
      "Episode:533 meanR:0.2400 rate:0.0000 gloss:-3.8728 dloss:0.3034 dlossR:0.0650 dlossQ:0.2383\n",
      "Episode:534 meanR:0.2300 rate:-0.1538 gloss:-4.6997 dloss:-0.3057 dlossR:-0.4653 dlossQ:0.1597\n",
      "Episode:535 meanR:0.2500 rate:0.0769 gloss:-4.4173 dloss:0.4798 dlossR:0.2960 dlossQ:0.1838\n",
      "Episode:536 meanR:0.2600 rate:0.0769 gloss:-4.2197 dloss:0.4964 dlossR:0.2913 dlossQ:0.2051\n",
      "Episode:537 meanR:0.2700 rate:0.0000 gloss:-4.9824 dloss:0.1730 dlossR:0.0302 dlossQ:0.1428\n",
      "Episode:538 meanR:0.2700 rate:0.0000 gloss:-4.5999 dloss:0.2048 dlossR:0.0373 dlossQ:0.1675\n",
      "Episode:539 meanR:0.2800 rate:0.0000 gloss:-4.6257 dloss:0.2015 dlossR:0.0359 dlossQ:0.1656\n",
      "Episode:540 meanR:0.2700 rate:-0.0769 gloss:-5.0526 dloss:-0.1178 dlossR:-0.2506 dlossQ:0.1328\n",
      "Episode:541 meanR:0.2700 rate:0.0000 gloss:-4.0955 dloss:0.2615 dlossR:0.0524 dlossQ:0.2091\n",
      "Episode:542 meanR:0.2500 rate:-0.1538 gloss:-5.3096 dloss:-0.4351 dlossR:-0.5508 dlossQ:0.1157\n",
      "Episode:543 meanR:0.2600 rate:0.0769 gloss:-5.4926 dloss:0.4508 dlossR:0.3367 dlossQ:0.1141\n",
      "Episode:544 meanR:0.2600 rate:0.0000 gloss:-4.9439 dloss:0.1575 dlossR:0.0266 dlossQ:0.1310\n",
      "Episode:545 meanR:0.2500 rate:-0.0769 gloss:-6.0341 dloss:-0.2396 dlossR:-0.3205 dlossQ:0.0808\n",
      "Episode:546 meanR:0.2600 rate:0.0769 gloss:-4.4820 dloss:0.4864 dlossR:0.2977 dlossQ:0.1887\n",
      "Episode:547 meanR:0.2500 rate:-0.1538 gloss:-6.1687 dloss:-0.5847 dlossR:-0.6595 dlossQ:0.0749\n",
      "Episode:548 meanR:0.2200 rate:-0.1538 gloss:-6.6233 dloss:-0.6544 dlossR:-0.7142 dlossQ:0.0598\n",
      "Episode:549 meanR:0.2200 rate:0.0000 gloss:-5.8978 dloss:0.0933 dlossR:0.0134 dlossQ:0.0799\n",
      "Episode:550 meanR:0.2300 rate:0.0769 gloss:-6.2785 dloss:0.4435 dlossR:0.3703 dlossQ:0.0732\n",
      "Episode:551 meanR:0.2100 rate:0.0000 gloss:-5.9098 dloss:0.1005 dlossR:0.0147 dlossQ:0.0859\n",
      "Episode:552 meanR:0.2000 rate:-0.0769 gloss:-6.5677 dloss:-0.2898 dlossR:-0.3543 dlossQ:0.0645\n",
      "Episode:553 meanR:0.1900 rate:-0.0769 gloss:-7.1781 dloss:-0.3454 dlossR:-0.3928 dlossQ:0.0474\n",
      "Episode:554 meanR:0.2000 rate:0.0000 gloss:-8.0646 dloss:0.0363 dlossR:0.0034 dlossQ:0.0329\n",
      "Episode:555 meanR:0.2000 rate:0.0000 gloss:-7.5607 dloss:0.0504 dlossR:0.0056 dlossQ:0.0448\n",
      "Episode:556 meanR:0.2000 rate:0.0769 gloss:-7.8638 dloss:0.4924 dlossR:0.4537 dlossQ:0.0388\n",
      "Episode:557 meanR:0.2000 rate:0.0000 gloss:-8.0145 dloss:0.0334 dlossR:0.0029 dlossQ:0.0305\n",
      "Episode:558 meanR:0.2100 rate:0.0000 gloss:-8.3653 dloss:0.0311 dlossR:0.0026 dlossQ:0.0285\n",
      "Episode:559 meanR:0.2200 rate:0.0769 gloss:-8.3676 dloss:0.5109 dlossR:0.4804 dlossQ:0.0305\n",
      "Episode:560 meanR:0.2100 rate:-0.0769 gloss:-8.5686 dloss:-0.4475 dlossR:-0.4755 dlossQ:0.0280\n",
      "Episode:561 meanR:0.1800 rate:-0.2308 gloss:-8.8008 dloss:-1.4108 dlossR:-1.4351 dlossQ:0.0243\n",
      "Episode:562 meanR:0.2000 rate:0.1538 gloss:-8.3160 dloss:0.9976 dlossR:0.9656 dlossQ:0.0321\n",
      "Episode:563 meanR:0.1900 rate:0.0000 gloss:-10.6308 dloss:0.0202 dlossR:0.0007 dlossQ:0.0195\n",
      "Episode:564 meanR:0.2100 rate:0.0769 gloss:-7.9331 dloss:0.4942 dlossR:0.4572 dlossQ:0.0370\n",
      "Episode:565 meanR:0.2000 rate:0.0000 gloss:-9.5148 dloss:0.0228 dlossR:0.0013 dlossQ:0.0215\n",
      "Episode:566 meanR:0.2000 rate:0.0000 gloss:-8.2681 dloss:0.0330 dlossR:0.0028 dlossQ:0.0302\n",
      "Episode:567 meanR:0.2000 rate:-0.0769 gloss:-9.5530 dloss:-0.5128 dlossR:-0.5320 dlossQ:0.0193\n",
      "Episode:568 meanR:0.2100 rate:0.0000 gloss:-10.0096 dloss:0.0190 dlossR:0.0007 dlossQ:0.0183\n",
      "Episode:569 meanR:0.2200 rate:0.0000 gloss:-9.2234 dloss:0.0248 dlossR:0.0017 dlossQ:0.0232\n",
      "Episode:570 meanR:0.2100 rate:-0.0769 gloss:-9.6700 dloss:-0.5169 dlossR:-0.5393 dlossQ:0.0224\n",
      "Episode:571 meanR:0.2200 rate:0.0769 gloss:-9.1788 dloss:0.5525 dlossR:0.5259 dlossQ:0.0266\n",
      "Episode:572 meanR:0.2000 rate:-0.1538 gloss:-10.3905 dloss:-1.1283 dlossR:-1.1487 dlossQ:0.0204\n",
      "Episode:573 meanR:0.2000 rate:0.0000 gloss:-10.2149 dloss:0.0211 dlossR:0.0008 dlossQ:0.0203\n",
      "Episode:574 meanR:0.1800 rate:-0.1538 gloss:-10.3266 dloss:-1.1224 dlossR:-1.1415 dlossQ:0.0191\n",
      "Episode:575 meanR:0.1600 rate:0.0000 gloss:-10.8387 dloss:0.0150 dlossR:0.0006 dlossQ:0.0145\n",
      "Episode:576 meanR:0.1300 rate:-0.0769 gloss:-10.5794 dloss:-0.5713 dlossR:-0.5906 dlossQ:0.0193\n",
      "Episode:577 meanR:0.0700 rate:0.0769 gloss:-10.2485 dloss:0.6045 dlossR:0.5849 dlossQ:0.0196\n",
      "Episode:578 meanR:0.0700 rate:0.0000 gloss:-11.5716 dloss:0.0163 dlossR:0.0003 dlossQ:0.0160\n",
      "Episode:579 meanR:0.0500 rate:-0.0769 gloss:-10.0063 dloss:-0.5390 dlossR:-0.5602 dlossQ:0.0212\n",
      "Episode:580 meanR:0.0300 rate:-0.0769 gloss:-13.3811 dloss:-0.7327 dlossR:-0.7493 dlossQ:0.0166\n",
      "Episode:581 meanR:0.0500 rate:0.1538 gloss:-11.6101 dloss:1.3591 dlossR:1.3385 dlossQ:0.0206\n",
      "Episode:582 meanR:0.0700 rate:0.0769 gloss:-11.1614 dloss:0.6542 dlossR:0.6374 dlossQ:0.0168\n",
      "Episode:583 meanR:0.0700 rate:0.0000 gloss:-11.9646 dloss:0.0157 dlossR:0.0003 dlossQ:0.0154\n",
      "Episode:584 meanR:0.0700 rate:0.0000 gloss:-12.4188 dloss:0.0176 dlossR:0.0001 dlossQ:0.0175\n",
      "Episode:585 meanR:0.0800 rate:0.0000 gloss:-10.3102 dloss:0.0180 dlossR:0.0006 dlossQ:0.0175\n",
      "Episode:586 meanR:0.0500 rate:-0.2308 gloss:-15.2670 dloss:-2.5285 dlossR:-2.5511 dlossQ:0.0226\n",
      "Episode:587 meanR:0.0400 rate:0.0000 gloss:-12.0552 dloss:0.0167 dlossR:0.0002 dlossQ:0.0165\n",
      "Episode:588 meanR:0.0400 rate:0.0000 gloss:-11.4759 dloss:0.0166 dlossR:0.0003 dlossQ:0.0163\n",
      "Episode:589 meanR:0.0700 rate:0.1538 gloss:-11.1155 dloss:1.3089 dlossR:1.2881 dlossQ:0.0207\n",
      "Episode:590 meanR:0.0500 rate:0.0769 gloss:-11.8588 dloss:0.7007 dlossR:0.6803 dlossQ:0.0204\n",
      "Episode:591 meanR:0.0300 rate:0.0000 gloss:-11.9703 dloss:0.0162 dlossR:0.0003 dlossQ:0.0159\n",
      "Episode:592 meanR:-0.0200 rate:-0.2308 gloss:-14.2821 dloss:-2.3533 dlossR:-2.3773 dlossQ:0.0240\n",
      "Episode:593 meanR:-0.1000 rate:-0.1538 gloss:-14.5584 dloss:-1.6189 dlossR:-1.6336 dlossQ:0.0147\n",
      "Episode:594 meanR:-0.1100 rate:-0.0769 gloss:-15.7000 dloss:-0.8742 dlossR:-0.8905 dlossQ:0.0163\n",
      "Episode:595 meanR:-0.0500 rate:0.0769 gloss:-14.8779 dloss:0.8855 dlossR:0.8571 dlossQ:0.0284\n",
      "Episode:596 meanR:0.0100 rate:0.0000 gloss:-11.5149 dloss:0.0166 dlossR:0.0002 dlossQ:0.0164\n",
      "Episode:597 meanR:-0.0200 rate:0.0000 gloss:-14.2496 dloss:0.0255 dlossR:0.0001 dlossQ:0.0254\n",
      "Episode:598 meanR:0.0000 rate:0.0000 gloss:-18.5063 dloss:0.0198 dlossR:0.0000 dlossQ:0.0198\n",
      "Episode:599 meanR:0.0000 rate:0.0000 gloss:-16.7989 dloss:0.0273 dlossR:0.0000 dlossQ:0.0273\n",
      "Episode:600 meanR:0.0000 rate:0.0000 gloss:-18.2276 dloss:0.0278 dlossR:0.0000 dlossQ:0.0278\n",
      "Episode:601 meanR:-0.0100 rate:0.0000 gloss:-16.9197 dloss:0.0190 dlossR:0.0000 dlossQ:0.0190\n",
      "Episode:602 meanR:-0.0400 rate:-0.2308 gloss:-16.7185 dloss:-2.7779 dlossR:-2.7987 dlossQ:0.0207\n",
      "Episode:603 meanR:-0.0300 rate:0.0769 gloss:-17.1499 dloss:1.0020 dlossR:0.9796 dlossQ:0.0224\n",
      "Episode:604 meanR:-0.0500 rate:-0.0769 gloss:-21.8802 dloss:-1.2136 dlossR:-1.2317 dlossQ:0.0180\n",
      "Episode:605 meanR:-0.0400 rate:0.0769 gloss:-17.6898 dloss:1.0268 dlossR:1.0086 dlossQ:0.0183\n",
      "Episode:606 meanR:-0.0500 rate:0.0000 gloss:-21.3738 dloss:0.0412 dlossR:0.0001 dlossQ:0.0411\n",
      "Episode:607 meanR:-0.0700 rate:-0.0769 gloss:-18.7575 dloss:-1.0333 dlossR:-1.0589 dlossQ:0.0255\n",
      "Episode:608 meanR:-0.0700 rate:0.0769 gloss:-19.2971 dloss:1.1166 dlossR:1.1009 dlossQ:0.0158\n",
      "Episode:609 meanR:-0.0700 rate:0.0000 gloss:-21.1403 dloss:0.0344 dlossR:0.0000 dlossQ:0.0344\n",
      "Episode:610 meanR:-0.0700 rate:0.0769 gloss:-17.7951 dloss:1.0350 dlossR:1.0146 dlossQ:0.0205\n",
      "Episode:611 meanR:-0.0900 rate:-0.0769 gloss:-24.7636 dloss:-1.3790 dlossR:-1.4007 dlossQ:0.0216\n",
      "Episode:612 meanR:-0.0800 rate:0.1538 gloss:-20.0572 dloss:2.3155 dlossR:2.2915 dlossQ:0.0240\n",
      "Episode:613 meanR:-0.0500 rate:0.3077 gloss:-20.6011 dloss:4.8034 dlossR:4.7629 dlossQ:0.0405\n",
      "Episode:614 meanR:-0.0500 rate:0.0000 gloss:-24.5653 dloss:0.0181 dlossR:0.0000 dlossQ:0.0181\n",
      "Episode:615 meanR:-0.0300 rate:0.1538 gloss:-21.8828 dloss:2.5223 dlossR:2.5022 dlossQ:0.0200\n",
      "Episode:616 meanR:-0.0300 rate:0.0000 gloss:-19.3511 dloss:0.0395 dlossR:0.0001 dlossQ:0.0395\n",
      "Episode:617 meanR:-0.0300 rate:0.0000 gloss:-13.3891 dloss:0.0159 dlossR:0.0004 dlossQ:0.0155\n",
      "Episode:618 meanR:-0.0600 rate:-0.1538 gloss:-17.6389 dloss:-1.9605 dlossR:-1.9779 dlossQ:0.0174\n",
      "Episode:619 meanR:-0.0700 rate:-0.0769 gloss:-16.4136 dloss:-0.9083 dlossR:-0.9270 dlossQ:0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:620 meanR:-0.0800 rate:0.0000 gloss:-10.4572 dloss:0.0281 dlossR:0.0019 dlossQ:0.0263\n",
      "Episode:621 meanR:-0.0400 rate:0.2308 gloss:-11.2947 dloss:2.0053 dlossR:1.9790 dlossQ:0.0262\n",
      "Episode:622 meanR:0.0200 rate:0.5385 gloss:-8.4951 dloss:3.7202 dlossR:3.6631 dlossQ:0.0571\n",
      "Episode:623 meanR:0.0200 rate:0.2308 gloss:-9.1687 dloss:1.6933 dlossR:1.6222 dlossQ:0.0711\n",
      "Episode:624 meanR:0.0300 rate:0.0769 gloss:-11.5210 dloss:0.6999 dlossR:0.6638 dlossQ:0.0362\n",
      "Episode:625 meanR:0.0100 rate:0.0000 gloss:-11.6532 dloss:0.0633 dlossR:0.0055 dlossQ:0.0579\n",
      "Episode:626 meanR:0.0000 rate:0.0769 gloss:-14.3224 dloss:0.8758 dlossR:0.8251 dlossQ:0.0507\n",
      "Episode:627 meanR:0.0300 rate:0.0769 gloss:-10.0044 dloss:0.6441 dlossR:0.5789 dlossQ:0.0653\n",
      "Episode:628 meanR:0.0300 rate:0.0000 gloss:-8.1046 dloss:0.0786 dlossR:0.0093 dlossQ:0.0694\n",
      "Episode:629 meanR:0.0200 rate:-0.0769 gloss:-10.1971 dloss:-0.5374 dlossR:-0.5659 dlossQ:0.0285\n",
      "Episode:630 meanR:0.0300 rate:0.0769 gloss:-4.8995 dloss:0.6547 dlossR:0.3533 dlossQ:0.3013\n",
      "Episode:631 meanR:0.0400 rate:0.0000 gloss:-4.3247 dloss:0.4519 dlossR:0.1002 dlossQ:0.3517\n",
      "Episode:632 meanR:0.0400 rate:0.0000 gloss:-3.3319 dloss:0.5006 dlossR:0.1237 dlossQ:0.3769\n",
      "Episode:633 meanR:0.0900 rate:0.3846 gloss:-2.7918 dloss:1.5898 dlossR:1.0837 dlossQ:0.5061\n",
      "Episode:634 meanR:0.1300 rate:0.1538 gloss:-3.0168 dloss:0.9845 dlossR:0.5171 dlossQ:0.4674\n",
      "Episode:635 meanR:0.1200 rate:0.0000 gloss:-3.3368 dloss:0.7314 dlossR:0.1793 dlossQ:0.5522\n",
      "Episode:636 meanR:0.1100 rate:0.0000 gloss:-2.0393 dloss:0.9455 dlossR:0.2871 dlossQ:0.6584\n",
      "Episode:637 meanR:0.1200 rate:0.0769 gloss:-5.5845 dloss:1.1864 dlossR:0.4466 dlossQ:0.7398\n",
      "Episode:638 meanR:0.1100 rate:-0.0769 gloss:-2.3535 dloss:0.6151 dlossR:0.0995 dlossQ:0.5156\n",
      "Episode:639 meanR:0.0900 rate:-0.1538 gloss:-3.0217 dloss:0.2339 dlossR:-0.1616 dlossQ:0.3955\n",
      "Episode:640 meanR:0.1000 rate:0.0000 gloss:-2.9969 dloss:0.5237 dlossR:0.1328 dlossQ:0.3909\n",
      "Episode:641 meanR:0.1000 rate:0.0000 gloss:-3.9013 dloss:0.5567 dlossR:0.1064 dlossQ:0.4503\n",
      "Episode:642 meanR:0.1400 rate:0.1538 gloss:-3.2636 dloss:0.9206 dlossR:0.5026 dlossQ:0.4180\n",
      "Episode:643 meanR:0.1400 rate:0.0769 gloss:-3.4189 dloss:0.6348 dlossR:0.2950 dlossQ:0.3398\n",
      "Episode:644 meanR:0.1600 rate:0.1538 gloss:-3.0327 dloss:0.8374 dlossR:0.4713 dlossQ:0.3661\n",
      "Episode:645 meanR:0.1700 rate:0.0000 gloss:-4.6943 dloss:0.2345 dlossR:0.0413 dlossQ:0.1932\n",
      "Episode:646 meanR:0.1700 rate:0.0769 gloss:-3.6248 dloss:0.5912 dlossR:0.2910 dlossQ:0.3002\n",
      "Episode:647 meanR:0.1800 rate:-0.0769 gloss:-4.3987 dloss:0.0418 dlossR:-0.1838 dlossQ:0.2256\n",
      "Episode:648 meanR:0.1800 rate:-0.1538 gloss:-4.4151 dloss:-0.1779 dlossR:-0.4113 dlossQ:0.2333\n",
      "Episode:649 meanR:0.1800 rate:0.0000 gloss:-5.4621 dloss:0.1786 dlossR:0.0259 dlossQ:0.1527\n",
      "Episode:650 meanR:0.1700 rate:0.0000 gloss:-5.4365 dloss:0.1572 dlossR:0.0235 dlossQ:0.1337\n",
      "Episode:651 meanR:0.1600 rate:-0.0769 gloss:-4.8594 dloss:-0.0504 dlossR:-0.2280 dlossQ:0.1776\n",
      "Episode:652 meanR:0.1700 rate:0.0000 gloss:-2.7461 dloss:0.5108 dlossR:0.1302 dlossQ:0.3806\n",
      "Episode:653 meanR:0.1800 rate:0.0000 gloss:-6.0362 dloss:0.1001 dlossR:0.0141 dlossQ:0.0860\n",
      "Episode:654 meanR:0.1800 rate:0.0000 gloss:-3.9995 dloss:0.2658 dlossR:0.0530 dlossQ:0.2128\n",
      "Episode:655 meanR:0.1700 rate:-0.0769 gloss:-4.1004 dloss:0.0590 dlossR:-0.1672 dlossQ:0.2262\n",
      "Episode:656 meanR:0.1600 rate:0.0000 gloss:-3.5825 dloss:0.3282 dlossR:0.0704 dlossQ:0.2577\n",
      "Episode:657 meanR:0.1700 rate:0.0769 gloss:-4.8552 dloss:0.4637 dlossR:0.3110 dlossQ:0.1527\n",
      "Episode:658 meanR:0.1700 rate:0.0000 gloss:-4.4637 dloss:0.2225 dlossR:0.0423 dlossQ:0.1803\n",
      "Episode:659 meanR:0.1600 rate:0.0000 gloss:-6.2882 dloss:0.1513 dlossR:0.0269 dlossQ:0.1244\n",
      "Episode:660 meanR:0.1900 rate:0.1538 gloss:-5.7978 dloss:0.8189 dlossR:0.7020 dlossQ:0.1169\n",
      "Episode:661 meanR:0.2200 rate:0.0000 gloss:-8.2547 dloss:0.0509 dlossR:0.0052 dlossQ:0.0456\n",
      "Episode:662 meanR:0.2000 rate:0.0000 gloss:-6.1537 dloss:0.0814 dlossR:0.0111 dlossQ:0.0703\n",
      "Episode:663 meanR:0.1900 rate:-0.0769 gloss:-8.8931 dloss:-0.4582 dlossR:-0.4930 dlossQ:0.0348\n",
      "Episode:664 meanR:0.1800 rate:0.0000 gloss:-10.3126 dloss:0.0327 dlossR:0.0016 dlossQ:0.0311\n",
      "Episode:665 meanR:0.1900 rate:0.0769 gloss:-8.1561 dloss:0.5289 dlossR:0.4737 dlossQ:0.0552\n",
      "Episode:666 meanR:0.1900 rate:0.0000 gloss:-9.4544 dloss:0.0308 dlossR:0.0022 dlossQ:0.0286\n",
      "Episode:667 meanR:0.2000 rate:0.0000 gloss:-9.2947 dloss:0.0333 dlossR:0.0025 dlossQ:0.0308\n",
      "Episode:668 meanR:0.2000 rate:0.0000 gloss:-8.3554 dloss:0.0313 dlossR:0.0024 dlossQ:0.0289\n",
      "Episode:669 meanR:0.2100 rate:0.0769 gloss:-8.3540 dloss:0.5178 dlossR:0.4822 dlossQ:0.0356\n",
      "Episode:670 meanR:0.1900 rate:-0.2308 gloss:-8.6853 dloss:-1.3873 dlossR:-1.4151 dlossQ:0.0278\n",
      "Episode:671 meanR:0.1800 rate:0.0000 gloss:-8.8906 dloss:0.0334 dlossR:0.0027 dlossQ:0.0307\n",
      "Episode:672 meanR:0.2000 rate:0.0000 gloss:-8.8898 dloss:0.0375 dlossR:0.0030 dlossQ:0.0345\n",
      "Episode:673 meanR:0.2000 rate:0.0000 gloss:-6.5401 dloss:0.0691 dlossR:0.0089 dlossQ:0.0602\n",
      "Episode:674 meanR:0.2200 rate:0.0000 gloss:-10.3622 dloss:0.0228 dlossR:0.0012 dlossQ:0.0216\n",
      "Episode:675 meanR:0.2300 rate:0.0769 gloss:-6.5108 dloss:0.4663 dlossR:0.3858 dlossQ:0.0805\n",
      "Episode:676 meanR:0.2400 rate:0.0000 gloss:-10.7466 dloss:0.0220 dlossR:0.0011 dlossQ:0.0209\n",
      "Episode:677 meanR:0.2300 rate:0.0000 gloss:-10.4243 dloss:0.0319 dlossR:0.0014 dlossQ:0.0305\n",
      "Episode:678 meanR:0.2500 rate:0.1538 gloss:-9.3909 dloss:1.1075 dlossR:1.0832 dlossQ:0.0243\n",
      "Episode:679 meanR:0.2500 rate:-0.0769 gloss:-10.6057 dloss:-0.5704 dlossR:-0.5911 dlossQ:0.0207\n",
      "Episode:680 meanR:0.2700 rate:0.0769 gloss:-9.6522 dloss:0.5921 dlossR:0.5544 dlossQ:0.0377\n",
      "Episode:681 meanR:0.2600 rate:0.0769 gloss:-8.8569 dloss:0.5456 dlossR:0.5094 dlossQ:0.0362\n",
      "Episode:682 meanR:0.2400 rate:-0.0769 gloss:-10.1676 dloss:-0.5430 dlossR:-0.5665 dlossQ:0.0236\n",
      "Episode:683 meanR:0.2500 rate:0.0769 gloss:-8.2300 dloss:0.5105 dlossR:0.4739 dlossQ:0.0366\n",
      "Episode:684 meanR:0.2700 rate:0.1538 gloss:-8.3208 dloss:1.0019 dlossR:0.9657 dlossQ:0.0361\n",
      "Episode:685 meanR:0.2700 rate:0.0000 gloss:-8.0333 dloss:0.0478 dlossR:0.0047 dlossQ:0.0431\n",
      "Episode:686 meanR:0.2900 rate:-0.0769 gloss:-7.7046 dloss:-0.3817 dlossR:-0.4244 dlossQ:0.0428\n",
      "Episode:687 meanR:0.2800 rate:-0.0769 gloss:-7.1769 dloss:-0.3440 dlossR:-0.3930 dlossQ:0.0489\n",
      "Episode:688 meanR:0.2800 rate:0.0000 gloss:-6.5816 dloss:0.0710 dlossR:0.0090 dlossQ:0.0620\n",
      "Episode:689 meanR:0.2600 rate:0.0000 gloss:-7.8732 dloss:0.0472 dlossR:0.0044 dlossQ:0.0428\n",
      "Episode:690 meanR:0.2700 rate:0.1538 gloss:-7.1907 dloss:0.9115 dlossR:0.8432 dlossQ:0.0683\n",
      "Episode:691 meanR:0.2700 rate:0.0000 gloss:-7.3287 dloss:0.0602 dlossR:0.0069 dlossQ:0.0533\n",
      "Episode:692 meanR:0.3200 rate:0.1538 gloss:-7.9518 dloss:0.9869 dlossR:0.9275 dlossQ:0.0594\n",
      "Episode:693 meanR:0.3200 rate:-0.1538 gloss:-7.3121 dloss:-0.7492 dlossR:-0.7929 dlossQ:0.0438\n",
      "Episode:694 meanR:0.3400 rate:0.0769 gloss:-7.9250 dloss:0.5071 dlossR:0.4583 dlossQ:0.0488\n",
      "Episode:695 meanR:0.3300 rate:0.0000 gloss:-7.0812 dloss:0.0900 dlossR:0.0112 dlossQ:0.0788\n",
      "Episode:696 meanR:0.3200 rate:-0.0769 gloss:-7.9069 dloss:-0.3799 dlossR:-0.4337 dlossQ:0.0539\n",
      "Episode:697 meanR:0.3300 rate:0.0769 gloss:-7.2596 dloss:0.4874 dlossR:0.4236 dlossQ:0.0639\n",
      "Episode:698 meanR:0.3200 rate:-0.0769 gloss:-6.7606 dloss:-0.2871 dlossR:-0.3631 dlossQ:0.0760\n",
      "Episode:699 meanR:0.3000 rate:-0.1538 gloss:-5.9959 dloss:-0.5397 dlossR:-0.6346 dlossQ:0.0949\n",
      "Episode:700 meanR:0.2900 rate:-0.0769 gloss:-5.9430 dloss:-0.2115 dlossR:-0.3108 dlossQ:0.0994\n",
      "Episode:701 meanR:0.2800 rate:-0.0769 gloss:-6.0149 dloss:-0.2151 dlossR:-0.3150 dlossQ:0.0999\n",
      "Episode:702 meanR:0.3100 rate:0.0000 gloss:-7.7923 dloss:0.0511 dlossR:0.0051 dlossQ:0.0459\n",
      "Episode:703 meanR:0.3000 rate:0.0000 gloss:-7.1629 dloss:0.0673 dlossR:0.0081 dlossQ:0.0592\n",
      "Episode:704 meanR:0.3300 rate:0.1538 gloss:-7.0156 dloss:0.8865 dlossR:0.8228 dlossQ:0.0636\n",
      "Episode:705 meanR:0.3200 rate:0.0000 gloss:-8.6154 dloss:0.0380 dlossR:0.0034 dlossQ:0.0346\n",
      "Episode:706 meanR:0.3200 rate:0.0000 gloss:-7.1457 dloss:0.0590 dlossR:0.0070 dlossQ:0.0520\n",
      "Episode:707 meanR:0.3300 rate:0.0000 gloss:-7.0003 dloss:0.0772 dlossR:0.0095 dlossQ:0.0677\n",
      "Episode:708 meanR:0.3200 rate:0.0000 gloss:-6.6559 dloss:0.0867 dlossR:0.0110 dlossQ:0.0757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:709 meanR:0.3200 rate:0.0000 gloss:-5.0954 dloss:0.1721 dlossR:0.0283 dlossQ:0.1438\n",
      "Episode:710 meanR:0.3000 rate:-0.0769 gloss:-7.0114 dloss:-0.3178 dlossR:-0.3800 dlossQ:0.0622\n",
      "Episode:711 meanR:0.2800 rate:-0.2308 gloss:-9.3161 dloss:-1.4886 dlossR:-1.5194 dlossQ:0.0307\n",
      "Episode:712 meanR:0.2600 rate:0.0000 gloss:-6.7449 dloss:0.1032 dlossR:0.0131 dlossQ:0.0901\n",
      "Episode:713 meanR:0.2200 rate:0.0000 gloss:-7.7545 dloss:0.0531 dlossR:0.0052 dlossQ:0.0479\n",
      "Episode:714 meanR:0.2700 rate:0.3846 gloss:-6.7360 dloss:2.1282 dlossR:2.0560 dlossQ:0.0722\n",
      "Episode:715 meanR:0.2500 rate:0.0000 gloss:-6.9531 dloss:0.0934 dlossR:0.0114 dlossQ:0.0820\n",
      "Episode:716 meanR:0.2500 rate:0.0000 gloss:-7.0990 dloss:0.0788 dlossR:0.0094 dlossQ:0.0694\n",
      "Episode:717 meanR:0.2500 rate:0.0000 gloss:-6.7777 dloss:0.0986 dlossR:0.0126 dlossQ:0.0861\n",
      "Episode:718 meanR:0.2700 rate:0.0000 gloss:-7.8960 dloss:0.0805 dlossR:0.0078 dlossQ:0.0727\n",
      "Episode:719 meanR:0.2700 rate:-0.0769 gloss:-6.4088 dloss:-0.2626 dlossR:-0.3414 dlossQ:0.0788\n",
      "Episode:720 meanR:0.2800 rate:0.0769 gloss:-6.0750 dloss:0.4435 dlossR:0.3606 dlossQ:0.0829\n",
      "Episode:721 meanR:0.2500 rate:0.0000 gloss:-6.7787 dloss:0.0596 dlossR:0.0072 dlossQ:0.0524\n",
      "Episode:722 meanR:0.1800 rate:0.0000 gloss:-7.9682 dloss:0.0385 dlossR:0.0037 dlossQ:0.0349\n",
      "Episode:723 meanR:0.1500 rate:0.0000 gloss:-5.2229 dloss:0.1458 dlossR:0.0239 dlossQ:0.1219\n",
      "Episode:724 meanR:0.1300 rate:-0.0769 gloss:-7.2392 dloss:-0.3337 dlossR:-0.3929 dlossQ:0.0592\n",
      "Episode:725 meanR:0.1300 rate:0.0000 gloss:-7.1250 dloss:0.0662 dlossR:0.0076 dlossQ:0.0586\n",
      "Episode:726 meanR:0.1200 rate:0.0000 gloss:-7.4377 dloss:0.0796 dlossR:0.0083 dlossQ:0.0713\n",
      "Episode:727 meanR:0.1000 rate:-0.0769 gloss:-6.8914 dloss:-0.3214 dlossR:-0.3741 dlossQ:0.0527\n",
      "Episode:728 meanR:0.1000 rate:0.0000 gloss:-9.5113 dloss:0.0348 dlossR:0.0029 dlossQ:0.0320\n",
      "Episode:729 meanR:0.1100 rate:0.0000 gloss:-9.5421 dloss:0.0294 dlossR:0.0022 dlossQ:0.0273\n",
      "Episode:730 meanR:0.1000 rate:0.0000 gloss:-5.3852 dloss:0.1587 dlossR:0.0275 dlossQ:0.1312\n",
      "Episode:731 meanR:0.1000 rate:0.0000 gloss:-8.5903 dloss:0.0404 dlossR:0.0032 dlossQ:0.0372\n",
      "Episode:732 meanR:0.1100 rate:0.0769 gloss:-10.3197 dloss:0.6210 dlossR:0.5901 dlossQ:0.0310\n",
      "Episode:733 meanR:0.0500 rate:-0.0769 gloss:-7.5297 dloss:-0.3512 dlossR:-0.4109 dlossQ:0.0597\n",
      "Episode:734 meanR:0.0500 rate:0.1538 gloss:-5.5761 dloss:0.7854 dlossR:0.6739 dlossQ:0.1115\n",
      "Episode:735 meanR:0.1000 rate:0.3846 gloss:-6.0661 dloss:1.9764 dlossR:1.8819 dlossQ:0.0945\n",
      "Episode:736 meanR:0.1000 rate:0.0000 gloss:-6.4291 dloss:0.0819 dlossR:0.0108 dlossQ:0.0711\n",
      "Episode:737 meanR:0.0900 rate:0.0000 gloss:-6.0768 dloss:0.0982 dlossR:0.0139 dlossQ:0.0843\n",
      "Episode:738 meanR:0.1000 rate:0.0000 gloss:-5.5276 dloss:0.1331 dlossR:0.0206 dlossQ:0.1125\n",
      "Episode:739 meanR:0.1100 rate:-0.0769 gloss:-5.2745 dloss:-0.1380 dlossR:-0.2666 dlossQ:0.1286\n",
      "Episode:740 meanR:0.1100 rate:0.0000 gloss:-5.5645 dloss:0.1238 dlossR:0.0189 dlossQ:0.1049\n",
      "Episode:741 meanR:0.1200 rate:0.0769 gloss:-5.6265 dloss:0.4560 dlossR:0.3436 dlossQ:0.1125\n",
      "Episode:742 meanR:0.1000 rate:0.0000 gloss:-6.7721 dloss:0.0987 dlossR:0.0137 dlossQ:0.0850\n",
      "Episode:743 meanR:0.0900 rate:0.0000 gloss:-7.8607 dloss:0.0674 dlossR:0.0083 dlossQ:0.0591\n",
      "Episode:744 meanR:0.0700 rate:0.0000 gloss:-7.3312 dloss:0.0813 dlossR:0.0094 dlossQ:0.0719\n",
      "Episode:745 meanR:0.0700 rate:0.0000 gloss:-8.2112 dloss:0.0696 dlossR:0.0072 dlossQ:0.0625\n",
      "Episode:746 meanR:0.0600 rate:0.0000 gloss:-8.6361 dloss:0.0566 dlossR:0.0065 dlossQ:0.0501\n",
      "Episode:747 meanR:0.0700 rate:0.0000 gloss:-8.2023 dloss:0.0647 dlossR:0.0078 dlossQ:0.0569\n",
      "Episode:748 meanR:0.1000 rate:0.0769 gloss:-7.6563 dloss:0.5671 dlossR:0.4508 dlossQ:0.1163\n",
      "Episode:749 meanR:0.0700 rate:-0.2308 gloss:-5.5881 dloss:-0.7638 dlossR:-0.8690 dlossQ:0.1052\n",
      "Episode:750 meanR:0.0900 rate:0.1538 gloss:-5.3242 dloss:0.7780 dlossR:0.6485 dlossQ:0.1295\n",
      "Episode:751 meanR:0.1100 rate:0.0769 gloss:-5.1812 dloss:0.4544 dlossR:0.3231 dlossQ:0.1313\n",
      "Episode:752 meanR:0.1700 rate:0.4615 gloss:-4.2996 dloss:1.9172 dlossR:1.7068 dlossQ:0.2104\n",
      "Episode:753 meanR:0.1600 rate:-0.0769 gloss:-4.7039 dloss:-0.0641 dlossR:-0.2232 dlossQ:0.1591\n",
      "Episode:754 meanR:0.1800 rate:0.1538 gloss:-4.3401 dloss:0.7521 dlossR:0.5542 dlossQ:0.1979\n",
      "Episode:755 meanR:0.1800 rate:-0.0769 gloss:-5.0455 dloss:-0.0936 dlossR:-0.2453 dlossQ:0.1517\n",
      "Episode:756 meanR:0.1800 rate:0.0000 gloss:-5.5245 dloss:0.2761 dlossR:0.0374 dlossQ:0.2387\n",
      "Episode:757 meanR:0.1700 rate:0.0000 gloss:-4.7261 dloss:0.2166 dlossR:0.0388 dlossQ:0.1778\n",
      "Episode:758 meanR:0.1700 rate:0.0000 gloss:-4.0354 dloss:0.3095 dlossR:0.0587 dlossQ:0.2507\n",
      "Episode:759 meanR:0.1600 rate:-0.0769 gloss:-4.4078 dloss:0.0407 dlossR:-0.1901 dlossQ:0.2308\n",
      "Episode:760 meanR:0.1400 rate:0.0000 gloss:-4.7324 dloss:0.1817 dlossR:0.0321 dlossQ:0.1496\n",
      "Episode:761 meanR:0.1400 rate:0.0000 gloss:-5.7270 dloss:0.1084 dlossR:0.0159 dlossQ:0.0925\n",
      "Episode:762 meanR:0.1400 rate:0.0000 gloss:-3.7806 dloss:0.3175 dlossR:0.0646 dlossQ:0.2529\n",
      "Episode:763 meanR:0.1500 rate:0.0000 gloss:-4.9017 dloss:0.1642 dlossR:0.0284 dlossQ:0.1358\n",
      "Episode:764 meanR:0.1400 rate:-0.0769 gloss:-4.8956 dloss:-0.1035 dlossR:-0.2396 dlossQ:0.1361\n",
      "Episode:765 meanR:0.1200 rate:-0.0769 gloss:-5.6666 dloss:-0.1801 dlossR:-0.2904 dlossQ:0.1103\n",
      "Episode:766 meanR:0.1200 rate:0.0000 gloss:-7.0153 dloss:0.0995 dlossR:0.0146 dlossQ:0.0850\n",
      "Episode:767 meanR:0.1300 rate:0.0769 gloss:-6.8985 dloss:0.5427 dlossR:0.4154 dlossQ:0.1274\n",
      "Episode:768 meanR:0.1000 rate:-0.2308 gloss:-6.6481 dloss:-0.9576 dlossR:-1.0524 dlossQ:0.0948\n",
      "Episode:769 meanR:0.0800 rate:-0.0769 gloss:-5.6761 dloss:-0.1658 dlossR:-0.2896 dlossQ:0.1238\n",
      "Episode:770 meanR:0.1000 rate:-0.0769 gloss:-5.4435 dloss:-0.1414 dlossR:-0.2739 dlossQ:0.1325\n",
      "Episode:771 meanR:0.0700 rate:-0.2308 gloss:-6.2580 dloss:-0.8639 dlossR:-0.9807 dlossQ:0.1168\n",
      "Episode:772 meanR:0.0800 rate:0.0769 gloss:-6.0357 dloss:0.5076 dlossR:0.3684 dlossQ:0.1392\n",
      "Episode:773 meanR:0.0900 rate:0.0769 gloss:-6.6332 dloss:0.4915 dlossR:0.3944 dlossQ:0.0971\n",
      "Episode:774 meanR:0.0900 rate:0.0000 gloss:-6.3491 dloss:0.1148 dlossR:0.0160 dlossQ:0.0988\n",
      "Episode:775 meanR:0.0700 rate:-0.0769 gloss:-6.5569 dloss:-0.2659 dlossR:-0.3514 dlossQ:0.0855\n",
      "Episode:776 meanR:0.0500 rate:-0.1538 gloss:-7.0023 dloss:-0.6967 dlossR:-0.7562 dlossQ:0.0595\n",
      "Episode:777 meanR:0.0400 rate:-0.0769 gloss:-7.0513 dloss:-0.3289 dlossR:-0.3842 dlossQ:0.0552\n",
      "Episode:778 meanR:0.0200 rate:0.0000 gloss:-7.6240 dloss:0.0541 dlossR:0.0054 dlossQ:0.0487\n",
      "Episode:779 meanR:0.0200 rate:-0.0769 gloss:-8.2649 dloss:-0.4188 dlossR:-0.4559 dlossQ:0.0371\n",
      "Episode:780 meanR:-0.0100 rate:-0.1538 gloss:-8.8680 dloss:-0.9437 dlossR:-0.9739 dlossQ:0.0302\n",
      "Episode:781 meanR:-0.0200 rate:0.0000 gloss:-9.2935 dloss:0.0369 dlossR:0.0021 dlossQ:0.0348\n",
      "Episode:782 meanR:-0.0100 rate:0.0000 gloss:-8.2579 dloss:0.0379 dlossR:0.0031 dlossQ:0.0348\n",
      "Episode:783 meanR:-0.0100 rate:0.0769 gloss:-10.4666 dloss:0.6221 dlossR:0.5973 dlossQ:0.0248\n",
      "Episode:784 meanR:-0.0300 rate:0.0000 gloss:-9.1767 dloss:0.0305 dlossR:0.0023 dlossQ:0.0282\n",
      "Episode:785 meanR:-0.0300 rate:0.0000 gloss:-11.7064 dloss:0.0172 dlossR:0.0004 dlossQ:0.0167\n",
      "Episode:786 meanR:-0.0300 rate:-0.0769 gloss:-10.4249 dloss:-0.5580 dlossR:-0.5807 dlossQ:0.0228\n",
      "Episode:787 meanR:-0.0300 rate:-0.0769 gloss:-8.0888 dloss:-0.4172 dlossR:-0.4480 dlossQ:0.0309\n",
      "Episode:788 meanR:-0.0200 rate:0.0769 gloss:-11.1971 dloss:0.6549 dlossR:0.6377 dlossQ:0.0171\n",
      "Episode:789 meanR:-0.0200 rate:0.0000 gloss:-9.9015 dloss:0.0203 dlossR:0.0009 dlossQ:0.0195\n",
      "Episode:790 meanR:-0.0300 rate:0.0769 gloss:-11.1430 dloss:0.6547 dlossR:0.6367 dlossQ:0.0180\n",
      "Episode:791 meanR:-0.0300 rate:0.0000 gloss:-11.4774 dloss:0.0165 dlossR:0.0005 dlossQ:0.0160\n",
      "Episode:792 meanR:-0.0500 rate:0.0000 gloss:-11.5157 dloss:0.0178 dlossR:0.0004 dlossQ:0.0174\n",
      "Episode:793 meanR:-0.0300 rate:0.0000 gloss:-11.0500 dloss:0.0204 dlossR:0.0006 dlossQ:0.0197\n",
      "Episode:794 meanR:-0.0400 rate:0.0000 gloss:-13.2891 dloss:0.0208 dlossR:0.0002 dlossQ:0.0206\n",
      "Episode:795 meanR:-0.0500 rate:-0.0769 gloss:-12.5931 dloss:-0.6902 dlossR:-0.7053 dlossQ:0.0151\n",
      "Episode:796 meanR:-0.0300 rate:0.0769 gloss:-10.7834 dloss:0.6365 dlossR:0.6165 dlossQ:0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:797 meanR:-0.0400 rate:0.0000 gloss:-11.4510 dloss:0.0167 dlossR:0.0002 dlossQ:0.0165\n",
      "Episode:798 meanR:-0.0300 rate:0.0000 gloss:-10.0290 dloss:0.0203 dlossR:0.0011 dlossQ:0.0192\n",
      "Episode:799 meanR:-0.0100 rate:0.0000 gloss:-9.3520 dloss:0.0217 dlossR:0.0011 dlossQ:0.0206\n",
      "Episode:800 meanR:0.0000 rate:0.0000 gloss:-10.3010 dloss:0.0178 dlossR:0.0006 dlossQ:0.0172\n",
      "Episode:801 meanR:0.0100 rate:0.0000 gloss:-8.9199 dloss:0.0242 dlossR:0.0015 dlossQ:0.0227\n",
      "Episode:802 meanR:0.0100 rate:0.0000 gloss:-9.5269 dloss:0.0245 dlossR:0.0014 dlossQ:0.0231\n",
      "Episode:803 meanR:0.0100 rate:0.0000 gloss:-11.9282 dloss:0.0174 dlossR:0.0003 dlossQ:0.0171\n",
      "Episode:804 meanR:0.0000 rate:0.0769 gloss:-11.6874 dloss:0.6859 dlossR:0.6662 dlossQ:0.0197\n",
      "Episode:805 meanR:0.0000 rate:0.0000 gloss:-12.8093 dloss:0.0157 dlossR:0.0002 dlossQ:0.0155\n",
      "Episode:806 meanR:0.0100 rate:0.0769 gloss:-12.4593 dloss:0.7295 dlossR:0.7094 dlossQ:0.0201\n",
      "Episode:807 meanR:0.0100 rate:0.0000 gloss:-10.7480 dloss:0.0193 dlossR:0.0007 dlossQ:0.0186\n",
      "Episode:808 meanR:0.0200 rate:0.0769 gloss:-10.3849 dloss:0.6138 dlossR:0.5940 dlossQ:0.0197\n",
      "Episode:809 meanR:-0.0100 rate:-0.2308 gloss:-11.3171 dloss:-1.8507 dlossR:-1.8681 dlossQ:0.0174\n",
      "Episode:810 meanR:0.0000 rate:0.0000 gloss:-10.4738 dloss:0.0173 dlossR:0.0009 dlossQ:0.0164\n",
      "Episode:811 meanR:0.0300 rate:0.0000 gloss:-11.9787 dloss:0.0186 dlossR:0.0003 dlossQ:0.0183\n",
      "Episode:812 meanR:0.0400 rate:0.0769 gloss:-11.7715 dloss:0.6888 dlossR:0.6706 dlossQ:0.0182\n",
      "Episode:813 meanR:0.0500 rate:0.0769 gloss:-12.7130 dloss:0.7418 dlossR:0.7248 dlossQ:0.0169\n",
      "Episode:814 meanR:0.0000 rate:0.0000 gloss:-11.9242 dloss:0.0159 dlossR:0.0003 dlossQ:0.0156\n",
      "Episode:815 meanR:0.0000 rate:0.0000 gloss:-10.1015 dloss:0.0243 dlossR:0.0014 dlossQ:0.0228\n",
      "Episode:816 meanR:0.0000 rate:0.0000 gloss:-9.3622 dloss:0.0295 dlossR:0.0022 dlossQ:0.0273\n",
      "Episode:817 meanR:0.0000 rate:0.0000 gloss:-8.4687 dloss:0.0280 dlossR:0.0020 dlossQ:0.0260\n",
      "Episode:818 meanR:0.0000 rate:0.0000 gloss:-10.1874 dloss:0.0231 dlossR:0.0008 dlossQ:0.0223\n",
      "Episode:819 meanR:0.0200 rate:0.0769 gloss:-9.7904 dloss:0.5811 dlossR:0.5598 dlossQ:0.0213\n",
      "Episode:820 meanR:0.0100 rate:0.0000 gloss:-10.2183 dloss:0.0211 dlossR:0.0011 dlossQ:0.0200\n",
      "Episode:821 meanR:0.0300 rate:0.1538 gloss:-10.6164 dloss:1.2464 dlossR:1.2234 dlossQ:0.0231\n",
      "Episode:822 meanR:0.0400 rate:0.0769 gloss:-8.8671 dloss:0.5352 dlossR:0.5086 dlossQ:0.0266\n",
      "Episode:823 meanR:0.0400 rate:0.0000 gloss:-8.3867 dloss:0.0300 dlossR:0.0024 dlossQ:0.0276\n",
      "Episode:824 meanR:0.0500 rate:0.0000 gloss:-8.7416 dloss:0.0330 dlossR:0.0027 dlossQ:0.0303\n",
      "Episode:825 meanR:0.0500 rate:0.0000 gloss:-8.7508 dloss:0.0332 dlossR:0.0024 dlossQ:0.0308\n",
      "Episode:826 meanR:0.0500 rate:0.0000 gloss:-9.1107 dloss:0.0233 dlossR:0.0013 dlossQ:0.0220\n",
      "Episode:827 meanR:0.0700 rate:0.0769 gloss:-7.4981 dloss:0.4718 dlossR:0.4336 dlossQ:0.0382\n",
      "Episode:828 meanR:0.0200 rate:-0.3846 gloss:-9.8425 dloss:-2.6276 dlossR:-2.6484 dlossQ:0.0208\n",
      "Episode:829 meanR:-0.0100 rate:-0.2308 gloss:-9.6770 dloss:-1.5603 dlossR:-1.5850 dlossQ:0.0248\n",
      "Episode:830 meanR:-0.0100 rate:0.0000 gloss:-8.0545 dloss:0.0440 dlossR:0.0038 dlossQ:0.0401\n",
      "Episode:831 meanR:0.0000 rate:0.0769 gloss:-8.1439 dloss:0.5021 dlossR:0.4691 dlossQ:0.0330\n",
      "Episode:832 meanR:0.0000 rate:0.0769 gloss:-6.5679 dloss:0.4417 dlossR:0.3848 dlossQ:0.0569\n",
      "Episode:833 meanR:0.0100 rate:0.0000 gloss:-7.7870 dloss:0.0415 dlossR:0.0041 dlossQ:0.0375\n",
      "Episode:834 meanR:-0.0100 rate:0.0000 gloss:-9.3599 dloss:0.0258 dlossR:0.0014 dlossQ:0.0244\n",
      "Episode:835 meanR:-0.0500 rate:0.0769 gloss:-10.1789 dloss:0.6119 dlossR:0.5849 dlossQ:0.0270\n",
      "Episode:836 meanR:-0.0500 rate:0.0000 gloss:-10.9965 dloss:0.0237 dlossR:0.0007 dlossQ:0.0231\n",
      "Episode:837 meanR:-0.0500 rate:0.0000 gloss:-8.5257 dloss:0.0355 dlossR:0.0028 dlossQ:0.0327\n",
      "Episode:838 meanR:-0.0500 rate:0.0000 gloss:-8.3842 dloss:0.0342 dlossR:0.0026 dlossQ:0.0316\n",
      "Episode:839 meanR:-0.0300 rate:0.0769 gloss:-8.0093 dloss:0.5025 dlossR:0.4624 dlossQ:0.0401\n",
      "Episode:840 meanR:-0.0200 rate:0.0769 gloss:-8.9042 dloss:0.5443 dlossR:0.5121 dlossQ:0.0322\n",
      "Episode:841 meanR:-0.0300 rate:0.0000 gloss:-6.6398 dloss:0.0638 dlossR:0.0078 dlossQ:0.0560\n",
      "Episode:842 meanR:-0.0100 rate:0.1538 gloss:-8.4197 dloss:1.0177 dlossR:0.9813 dlossQ:0.0364\n",
      "Episode:843 meanR:-0.0100 rate:0.0000 gloss:-8.0103 dloss:0.0486 dlossR:0.0052 dlossQ:0.0434\n",
      "Episode:844 meanR:-0.0100 rate:0.0000 gloss:-7.6495 dloss:0.0608 dlossR:0.0074 dlossQ:0.0534\n",
      "Episode:845 meanR:-0.0200 rate:-0.0769 gloss:-8.1057 dloss:-0.4094 dlossR:-0.4480 dlossQ:0.0386\n",
      "Episode:846 meanR:-0.0200 rate:0.0000 gloss:-8.7614 dloss:0.0381 dlossR:0.0030 dlossQ:0.0351\n",
      "Episode:847 meanR:-0.0200 rate:0.0000 gloss:-9.4607 dloss:0.0326 dlossR:0.0023 dlossQ:0.0303\n",
      "Episode:848 meanR:-0.0200 rate:0.0769 gloss:-9.6743 dloss:0.5859 dlossR:0.5588 dlossQ:0.0271\n",
      "Episode:849 meanR:0.0000 rate:-0.0769 gloss:-8.9459 dloss:-0.4634 dlossR:-0.4982 dlossQ:0.0348\n",
      "Episode:850 meanR:-0.0300 rate:-0.0769 gloss:-8.5616 dloss:-0.4266 dlossR:-0.4735 dlossQ:0.0469\n",
      "Episode:851 meanR:-0.0400 rate:0.0000 gloss:-8.2213 dloss:0.0571 dlossR:0.0051 dlossQ:0.0521\n",
      "Episode:852 meanR:-0.1000 rate:0.0000 gloss:-6.7247 dloss:0.0942 dlossR:0.0125 dlossQ:0.0817\n",
      "Episode:853 meanR:-0.1100 rate:-0.1538 gloss:-7.7481 dloss:-0.7831 dlossR:-0.8464 dlossQ:0.0633\n",
      "Episode:854 meanR:-0.1000 rate:0.2308 gloss:-7.2811 dloss:1.3653 dlossR:1.2984 dlossQ:0.0669\n",
      "Episode:855 meanR:-0.0900 rate:0.0000 gloss:-7.0647 dloss:0.0906 dlossR:0.0107 dlossQ:0.0799\n",
      "Episode:856 meanR:-0.0900 rate:0.0000 gloss:-7.6932 dloss:0.1174 dlossR:0.0120 dlossQ:0.1055\n",
      "Episode:857 meanR:-0.0900 rate:0.0000 gloss:-7.6532 dloss:0.1019 dlossR:0.0106 dlossQ:0.0913\n",
      "Episode:858 meanR:-0.0900 rate:0.0000 gloss:-7.2936 dloss:0.0691 dlossR:0.0088 dlossQ:0.0603\n",
      "Episode:859 meanR:-0.0600 rate:0.1538 gloss:-9.7208 dloss:1.1717 dlossR:1.1283 dlossQ:0.0434\n",
      "Episode:860 meanR:-0.0800 rate:-0.1538 gloss:-10.2609 dloss:-1.1101 dlossR:-1.1343 dlossQ:0.0243\n",
      "Episode:861 meanR:-0.0800 rate:0.0000 gloss:-8.1800 dloss:0.0602 dlossR:0.0065 dlossQ:0.0538\n",
      "Episode:862 meanR:-0.0800 rate:0.0000 gloss:-7.1543 dloss:0.0667 dlossR:0.0084 dlossQ:0.0583\n",
      "Episode:863 meanR:-0.0700 rate:0.0769 gloss:-7.2111 dloss:0.4791 dlossR:0.4214 dlossQ:0.0577\n",
      "Episode:864 meanR:-0.0500 rate:0.0769 gloss:-6.7576 dloss:0.4683 dlossR:0.3990 dlossQ:0.0694\n",
      "Episode:865 meanR:-0.0100 rate:0.2308 gloss:-6.5933 dloss:1.2703 dlossR:1.1847 dlossQ:0.0857\n",
      "Episode:866 meanR:0.0000 rate:0.0769 gloss:-7.0579 dloss:0.4755 dlossR:0.4140 dlossQ:0.0615\n",
      "Episode:867 meanR:0.0100 rate:0.1538 gloss:-7.2824 dloss:0.9179 dlossR:0.8582 dlossQ:0.0597\n",
      "Episode:868 meanR:0.0500 rate:0.0769 gloss:-10.5230 dloss:0.6451 dlossR:0.6082 dlossQ:0.0369\n",
      "Episode:869 meanR:0.0600 rate:0.0000 gloss:-7.5423 dloss:0.0852 dlossR:0.0104 dlossQ:0.0748\n",
      "Episode:870 meanR:0.0700 rate:0.0000 gloss:-7.6932 dloss:0.1053 dlossR:0.0121 dlossQ:0.0932\n",
      "Episode:871 meanR:0.1200 rate:0.1538 gloss:-6.3151 dloss:0.9589 dlossR:0.7629 dlossQ:0.1959\n",
      "Episode:872 meanR:0.1100 rate:0.0000 gloss:-6.5824 dloss:0.1479 dlossR:0.0188 dlossQ:0.1291\n",
      "Episode:873 meanR:0.1000 rate:0.0000 gloss:-6.3667 dloss:0.2034 dlossR:0.0259 dlossQ:0.1774\n",
      "Episode:874 meanR:0.0900 rate:-0.0769 gloss:-5.8510 dloss:-0.1488 dlossR:-0.2985 dlossQ:0.1498\n",
      "Episode:875 meanR:0.1000 rate:0.0000 gloss:-4.9905 dloss:0.2170 dlossR:0.0377 dlossQ:0.1793\n",
      "Episode:876 meanR:0.1200 rate:0.0000 gloss:-5.3733 dloss:0.1369 dlossR:0.0209 dlossQ:0.1159\n",
      "Episode:877 meanR:0.1100 rate:-0.1538 gloss:-5.3095 dloss:-0.4063 dlossR:-0.5445 dlossQ:0.1382\n",
      "Episode:878 meanR:0.1100 rate:0.0000 gloss:-4.7239 dloss:0.1759 dlossR:0.0308 dlossQ:0.1451\n",
      "Episode:879 meanR:0.1200 rate:0.0000 gloss:-4.9179 dloss:0.1919 dlossR:0.0343 dlossQ:0.1576\n",
      "Episode:880 meanR:0.1400 rate:0.0000 gloss:-5.6482 dloss:0.1448 dlossR:0.0233 dlossQ:0.1214\n",
      "Episode:881 meanR:0.1400 rate:0.0000 gloss:-5.5303 dloss:0.1487 dlossR:0.0240 dlossQ:0.1247\n",
      "Episode:882 meanR:0.1200 rate:-0.1538 gloss:-6.0414 dloss:-0.5523 dlossR:-0.6400 dlossQ:0.0877\n",
      "Episode:883 meanR:0.1100 rate:0.0000 gloss:-5.9913 dloss:0.1388 dlossR:0.0219 dlossQ:0.1169\n",
      "Episode:884 meanR:0.1100 rate:0.0000 gloss:-5.7802 dloss:0.1491 dlossR:0.0244 dlossQ:0.1247\n",
      "Episode:885 meanR:0.1200 rate:0.0769 gloss:-5.3873 dloss:0.4867 dlossR:0.3374 dlossQ:0.1493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:886 meanR:0.1300 rate:0.0000 gloss:-5.0896 dloss:0.1856 dlossR:0.0322 dlossQ:0.1534\n",
      "Episode:887 meanR:0.1300 rate:-0.0769 gloss:-5.8377 dloss:-0.2002 dlossR:-0.3036 dlossQ:0.1034\n",
      "Episode:888 meanR:0.1200 rate:0.0000 gloss:-5.6870 dloss:0.2069 dlossR:0.0287 dlossQ:0.1782\n",
      "Episode:889 meanR:0.1100 rate:-0.0769 gloss:-5.1964 dloss:-0.1429 dlossR:-0.2625 dlossQ:0.1196\n",
      "Episode:890 meanR:0.1000 rate:0.0000 gloss:-5.5803 dloss:0.1150 dlossR:0.0172 dlossQ:0.0978\n",
      "Episode:891 meanR:0.1000 rate:0.0000 gloss:-5.3746 dloss:0.1322 dlossR:0.0211 dlossQ:0.1112\n",
      "Episode:892 meanR:0.1000 rate:0.0000 gloss:-5.2187 dloss:0.1431 dlossR:0.0232 dlossQ:0.1199\n",
      "Episode:893 meanR:0.1200 rate:0.1538 gloss:-5.6666 dloss:0.7837 dlossR:0.6806 dlossQ:0.1031\n",
      "Episode:894 meanR:0.1200 rate:0.0000 gloss:-7.0863 dloss:0.0870 dlossR:0.0107 dlossQ:0.0763\n",
      "Episode:895 meanR:0.1500 rate:0.1538 gloss:-6.3115 dloss:0.8805 dlossR:0.7551 dlossQ:0.1254\n",
      "Episode:896 meanR:0.1400 rate:0.0000 gloss:-6.6712 dloss:0.1088 dlossR:0.0158 dlossQ:0.0930\n",
      "Episode:897 meanR:0.1400 rate:0.0000 gloss:-6.1640 dloss:0.1035 dlossR:0.0152 dlossQ:0.0884\n",
      "Episode:898 meanR:0.1400 rate:0.0000 gloss:-5.3813 dloss:0.1278 dlossR:0.0202 dlossQ:0.1076\n",
      "Episode:899 meanR:0.1400 rate:0.0000 gloss:-5.4302 dloss:0.1209 dlossR:0.0188 dlossQ:0.1020\n",
      "Episode:900 meanR:0.1300 rate:-0.0769 gloss:-7.4782 dloss:-0.3525 dlossR:-0.4079 dlossQ:0.0554\n",
      "Episode:901 meanR:0.1200 rate:-0.0769 gloss:-6.6967 dloss:-0.2884 dlossR:-0.3601 dlossQ:0.0717\n",
      "Episode:902 meanR:0.1200 rate:0.0000 gloss:-6.4523 dloss:0.1203 dlossR:0.0145 dlossQ:0.1058\n",
      "Episode:903 meanR:0.1100 rate:-0.0769 gloss:-7.5782 dloss:-0.3638 dlossR:-0.4151 dlossQ:0.0514\n",
      "Episode:904 meanR:0.1000 rate:0.0000 gloss:-6.4202 dloss:0.0929 dlossR:0.0131 dlossQ:0.0797\n",
      "Episode:905 meanR:0.1100 rate:0.0769 gloss:-7.0193 dloss:0.4869 dlossR:0.4129 dlossQ:0.0740\n",
      "Episode:906 meanR:0.1000 rate:0.0000 gloss:-5.8535 dloss:0.1098 dlossR:0.0162 dlossQ:0.0936\n",
      "Episode:907 meanR:0.0900 rate:-0.0769 gloss:-6.5566 dloss:-0.2725 dlossR:-0.3502 dlossQ:0.0776\n",
      "Episode:908 meanR:0.1000 rate:0.1538 gloss:-6.4799 dloss:0.8594 dlossR:0.7676 dlossQ:0.0918\n",
      "Episode:909 meanR:0.1300 rate:0.0000 gloss:-7.1518 dloss:0.0724 dlossR:0.0091 dlossQ:0.0633\n",
      "Episode:910 meanR:0.1300 rate:0.0000 gloss:-7.8092 dloss:0.0678 dlossR:0.0063 dlossQ:0.0615\n",
      "Episode:911 meanR:0.1400 rate:0.0769 gloss:-7.5547 dloss:0.4987 dlossR:0.4390 dlossQ:0.0598\n",
      "Episode:912 meanR:0.1200 rate:-0.0769 gloss:-6.6979 dloss:-0.2890 dlossR:-0.3595 dlossQ:0.0705\n",
      "Episode:913 meanR:0.1000 rate:-0.0769 gloss:-6.8698 dloss:-0.2901 dlossR:-0.3687 dlossQ:0.0786\n",
      "Episode:914 meanR:0.0900 rate:-0.0769 gloss:-6.5924 dloss:-0.2859 dlossR:-0.3541 dlossQ:0.0682\n",
      "Episode:915 meanR:0.1200 rate:0.2308 gloss:-7.2356 dloss:1.3522 dlossR:1.2852 dlossQ:0.0670\n",
      "Episode:916 meanR:0.1200 rate:0.0000 gloss:-7.7708 dloss:0.0520 dlossR:0.0056 dlossQ:0.0464\n",
      "Episode:917 meanR:0.1300 rate:0.0769 gloss:-7.6180 dloss:0.4996 dlossR:0.4417 dlossQ:0.0579\n",
      "Episode:918 meanR:0.1300 rate:0.0000 gloss:-6.9795 dloss:0.0902 dlossR:0.0107 dlossQ:0.0796\n",
      "Episode:919 meanR:0.1200 rate:0.0000 gloss:-6.7557 dloss:0.0625 dlossR:0.0076 dlossQ:0.0549\n",
      "Episode:920 meanR:0.1300 rate:0.0769 gloss:-6.2247 dloss:0.4715 dlossR:0.3731 dlossQ:0.0984\n",
      "Episode:921 meanR:0.1100 rate:0.0000 gloss:-5.9789 dloss:0.1055 dlossR:0.0155 dlossQ:0.0900\n",
      "Episode:922 meanR:0.1100 rate:0.0769 gloss:-6.2040 dloss:0.4482 dlossR:0.3680 dlossQ:0.0802\n",
      "Episode:923 meanR:0.1000 rate:-0.0769 gloss:-6.7059 dloss:-0.3009 dlossR:-0.3626 dlossQ:0.0617\n",
      "Episode:924 meanR:0.0500 rate:-0.3846 gloss:-6.7510 dloss:-1.6831 dlossR:-1.7440 dlossQ:0.0609\n",
      "Episode:925 meanR:0.0400 rate:-0.0769 gloss:-6.5050 dloss:-0.2816 dlossR:-0.3490 dlossQ:0.0674\n",
      "Episode:926 meanR:0.0500 rate:0.0769 gloss:-6.7646 dloss:0.4646 dlossR:0.3965 dlossQ:0.0681\n",
      "Episode:927 meanR:0.0500 rate:0.0769 gloss:-7.0764 dloss:0.4665 dlossR:0.4116 dlossQ:0.0549\n",
      "Episode:928 meanR:0.1000 rate:0.0000 gloss:-6.1737 dloss:0.0916 dlossR:0.0122 dlossQ:0.0794\n",
      "Episode:929 meanR:0.1300 rate:0.0000 gloss:-6.1750 dloss:0.0896 dlossR:0.0128 dlossQ:0.0768\n",
      "Episode:930 meanR:0.1400 rate:0.0769 gloss:-7.2358 dloss:0.4855 dlossR:0.4227 dlossQ:0.0628\n",
      "Episode:931 meanR:0.1400 rate:0.0769 gloss:-7.1928 dloss:0.4842 dlossR:0.4189 dlossQ:0.0653\n",
      "Episode:932 meanR:0.1300 rate:0.0000 gloss:-5.8889 dloss:0.0942 dlossR:0.0135 dlossQ:0.0807\n",
      "Episode:933 meanR:0.1300 rate:0.0000 gloss:-6.9467 dloss:0.0544 dlossR:0.0063 dlossQ:0.0481\n",
      "Episode:934 meanR:0.1200 rate:-0.0769 gloss:-7.8464 dloss:-0.3882 dlossR:-0.4315 dlossQ:0.0433\n",
      "Episode:935 meanR:0.1100 rate:0.0000 gloss:-7.2141 dloss:0.0494 dlossR:0.0054 dlossQ:0.0440\n",
      "Episode:936 meanR:0.1100 rate:0.0000 gloss:-6.3614 dloss:0.0792 dlossR:0.0102 dlossQ:0.0690\n",
      "Episode:937 meanR:0.1100 rate:0.0000 gloss:-7.3324 dloss:0.0520 dlossR:0.0055 dlossQ:0.0464\n",
      "Episode:938 meanR:0.1100 rate:0.0000 gloss:-5.4723 dloss:0.1305 dlossR:0.0202 dlossQ:0.1103\n",
      "Episode:939 meanR:0.1100 rate:0.0769 gloss:-8.1434 dloss:0.5028 dlossR:0.4682 dlossQ:0.0346\n",
      "Episode:940 meanR:0.0900 rate:-0.0769 gloss:-7.4917 dloss:-0.3731 dlossR:-0.4113 dlossQ:0.0382\n",
      "Episode:941 meanR:0.0900 rate:0.0000 gloss:-6.4967 dloss:0.0699 dlossR:0.0090 dlossQ:0.0609\n",
      "Episode:942 meanR:0.0700 rate:0.0000 gloss:-7.6781 dloss:0.0432 dlossR:0.0042 dlossQ:0.0389\n",
      "Episode:943 meanR:0.0700 rate:0.0000 gloss:-5.9001 dloss:0.0939 dlossR:0.0135 dlossQ:0.0804\n",
      "Episode:944 meanR:0.0600 rate:-0.0769 gloss:-8.1897 dloss:-0.4175 dlossR:-0.4525 dlossQ:0.0350\n",
      "Episode:945 meanR:0.0800 rate:0.0769 gloss:-6.0924 dloss:0.4418 dlossR:0.3626 dlossQ:0.0793\n",
      "Episode:946 meanR:0.0600 rate:-0.1538 gloss:-8.2100 dloss:-0.8656 dlossR:-0.8981 dlossQ:0.0325\n",
      "Episode:947 meanR:0.0700 rate:0.0769 gloss:-7.6980 dloss:0.4910 dlossR:0.4454 dlossQ:0.0455\n",
      "Episode:948 meanR:0.0700 rate:0.0769 gloss:-7.7040 dloss:0.4852 dlossR:0.4449 dlossQ:0.0403\n",
      "Episode:949 meanR:0.0700 rate:-0.0769 gloss:-9.0321 dloss:-0.4758 dlossR:-0.5019 dlossQ:0.0261\n",
      "Episode:950 meanR:0.0800 rate:0.0000 gloss:-7.8618 dloss:0.0437 dlossR:0.0045 dlossQ:0.0392\n",
      "Episode:951 meanR:0.0900 rate:0.0769 gloss:-7.6812 dloss:0.4855 dlossR:0.4439 dlossQ:0.0416\n",
      "Episode:952 meanR:0.0800 rate:-0.0769 gloss:-8.0224 dloss:-0.4054 dlossR:-0.4423 dlossQ:0.0370\n",
      "Episode:953 meanR:0.1000 rate:0.0000 gloss:-8.2870 dloss:0.0353 dlossR:0.0032 dlossQ:0.0321\n",
      "Episode:954 meanR:0.0700 rate:0.0000 gloss:-7.7013 dloss:0.0440 dlossR:0.0041 dlossQ:0.0399\n",
      "Episode:955 meanR:0.0600 rate:-0.0769 gloss:-8.7930 dloss:-0.4584 dlossR:-0.4869 dlossQ:0.0285\n",
      "Episode:956 meanR:0.0400 rate:-0.1538 gloss:-8.3308 dloss:-0.8823 dlossR:-0.9124 dlossQ:0.0301\n",
      "Episode:957 meanR:0.0400 rate:0.0000 gloss:-7.3734 dloss:0.0569 dlossR:0.0058 dlossQ:0.0511\n",
      "Episode:958 meanR:0.0400 rate:0.0000 gloss:-7.4195 dloss:0.0451 dlossR:0.0046 dlossQ:0.0405\n",
      "Episode:959 meanR:0.0300 rate:0.0769 gloss:-8.0565 dloss:0.4973 dlossR:0.4631 dlossQ:0.0342\n",
      "Episode:960 meanR:0.0600 rate:0.0769 gloss:-9.6657 dloss:0.5738 dlossR:0.5513 dlossQ:0.0225\n",
      "Episode:961 meanR:0.0500 rate:-0.0769 gloss:-9.2137 dloss:-0.4860 dlossR:-0.5116 dlossQ:0.0255\n",
      "Episode:962 meanR:0.0500 rate:0.0000 gloss:-10.1155 dloss:0.0205 dlossR:0.0008 dlossQ:0.0197\n",
      "Episode:963 meanR:0.0400 rate:0.0000 gloss:-9.0806 dloss:0.0235 dlossR:0.0014 dlossQ:0.0221\n",
      "Episode:964 meanR:0.0300 rate:0.0000 gloss:-10.1891 dloss:0.0182 dlossR:0.0007 dlossQ:0.0176\n",
      "Episode:965 meanR:0.0000 rate:0.0000 gloss:-9.4678 dloss:0.0219 dlossR:0.0012 dlossQ:0.0207\n",
      "Episode:966 meanR:0.0100 rate:0.1538 gloss:-8.3732 dloss:1.0089 dlossR:0.9753 dlossQ:0.0336\n",
      "Episode:967 meanR:0.0000 rate:0.0769 gloss:-9.7267 dloss:0.5797 dlossR:0.5566 dlossQ:0.0230\n",
      "Episode:968 meanR:0.0000 rate:0.0769 gloss:-9.9280 dloss:0.5937 dlossR:0.5684 dlossQ:0.0253\n",
      "Episode:969 meanR:-0.0300 rate:-0.2308 gloss:-8.6926 dloss:-1.3822 dlossR:-1.4170 dlossQ:0.0348\n",
      "Episode:970 meanR:-0.0200 rate:0.0769 gloss:-10.3441 dloss:0.6119 dlossR:0.5916 dlossQ:0.0203\n",
      "Episode:971 meanR:-0.0100 rate:0.2308 gloss:-8.5771 dloss:1.5459 dlossR:1.5095 dlossQ:0.0365\n",
      "Episode:972 meanR:-0.0100 rate:0.0000 gloss:-8.2584 dloss:0.0404 dlossR:0.0036 dlossQ:0.0368\n",
      "Episode:973 meanR:0.0000 rate:0.0769 gloss:-8.4062 dloss:0.5162 dlossR:0.4844 dlossQ:0.0318\n",
      "Episode:974 meanR:0.0100 rate:0.0000 gloss:-8.0569 dloss:0.0336 dlossR:0.0030 dlossQ:0.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:975 meanR:0.0000 rate:-0.0769 gloss:-8.6987 dloss:-0.4545 dlossR:-0.4836 dlossQ:0.0291\n",
      "Episode:976 meanR:0.0100 rate:0.0769 gloss:-8.9039 dloss:0.5392 dlossR:0.5122 dlossQ:0.0270\n",
      "Episode:977 meanR:0.0400 rate:0.0769 gloss:-8.5632 dloss:0.5238 dlossR:0.4929 dlossQ:0.0309\n",
      "Episode:978 meanR:0.0200 rate:-0.1538 gloss:-7.7741 dloss:-0.8089 dlossR:-0.8492 dlossQ:0.0402\n",
      "Episode:979 meanR:0.0500 rate:0.2308 gloss:-7.0667 dloss:1.3217 dlossR:1.2583 dlossQ:0.0634\n",
      "Episode:980 meanR:0.0400 rate:-0.0769 gloss:-7.7604 dloss:-0.3891 dlossR:-0.4278 dlossQ:0.0387\n",
      "Episode:981 meanR:0.0300 rate:-0.0769 gloss:-7.2625 dloss:-0.3500 dlossR:-0.3983 dlossQ:0.0482\n",
      "Episode:982 meanR:0.0400 rate:-0.0769 gloss:-6.9501 dloss:-0.3260 dlossR:-0.3788 dlossQ:0.0528\n",
      "Episode:983 meanR:0.0300 rate:-0.0769 gloss:-6.8458 dloss:-0.3104 dlossR:-0.3715 dlossQ:0.0611\n",
      "Episode:984 meanR:0.0300 rate:0.0000 gloss:-6.3803 dloss:0.0842 dlossR:0.0112 dlossQ:0.0729\n",
      "Episode:985 meanR:0.0100 rate:-0.0769 gloss:-7.0499 dloss:-0.3241 dlossR:-0.3832 dlossQ:0.0591\n",
      "Episode:986 meanR:-0.0200 rate:-0.2308 gloss:-7.6978 dloss:-1.2019 dlossR:-1.2449 dlossQ:0.0430\n",
      "Episode:987 meanR:-0.0200 rate:-0.0769 gloss:-8.0638 dloss:-0.4029 dlossR:-0.4449 dlossQ:0.0421\n",
      "Episode:988 meanR:-0.0200 rate:0.0000 gloss:-7.3322 dloss:0.0586 dlossR:0.0061 dlossQ:0.0525\n",
      "Episode:989 meanR:-0.0100 rate:0.0000 gloss:-7.0536 dloss:0.0547 dlossR:0.0063 dlossQ:0.0484\n",
      "Episode:990 meanR:-0.0200 rate:-0.0769 gloss:-6.8908 dloss:-0.3245 dlossR:-0.3752 dlossQ:0.0508\n",
      "Episode:991 meanR:-0.0100 rate:0.0769 gloss:-8.4773 dloss:0.5178 dlossR:0.4869 dlossQ:0.0310\n",
      "Episode:992 meanR:0.0100 rate:0.1538 gloss:-9.1063 dloss:1.0804 dlossR:1.0530 dlossQ:0.0275\n",
      "Episode:993 meanR:-0.0100 rate:0.0000 gloss:-8.9489 dloss:0.0268 dlossR:0.0020 dlossQ:0.0248\n",
      "Episode:994 meanR:-0.0200 rate:-0.0769 gloss:-8.6230 dloss:-0.4461 dlossR:-0.4776 dlossQ:0.0315\n",
      "Episode:995 meanR:-0.0400 rate:0.0000 gloss:-7.8017 dloss:0.0428 dlossR:0.0038 dlossQ:0.0389\n",
      "Episode:996 meanR:-0.0400 rate:0.0000 gloss:-9.0519 dloss:0.0231 dlossR:0.0014 dlossQ:0.0218\n",
      "Episode:997 meanR:-0.0500 rate:-0.0769 gloss:-8.7406 dloss:-0.4577 dlossR:-0.4848 dlossQ:0.0271\n",
      "Episode:998 meanR:-0.0500 rate:0.0000 gloss:-7.1606 dloss:0.0558 dlossR:0.0061 dlossQ:0.0497\n",
      "Episode:999 meanR:-0.0600 rate:-0.0769 gloss:-9.4068 dloss:-0.4992 dlossR:-0.5229 dlossQ:0.0237\n",
      "Episode:1000 meanR:-0.0800 rate:-0.2308 gloss:-9.2707 dloss:-1.4898 dlossR:-1.5145 dlossQ:0.0247\n",
      "Episode:1001 meanR:-0.0900 rate:-0.1538 gloss:-9.4889 dloss:-1.0239 dlossR:-1.0453 dlossQ:0.0214\n",
      "Episode:1002 meanR:-0.0900 rate:0.0000 gloss:-9.1332 dloss:0.0297 dlossR:0.0019 dlossQ:0.0278\n",
      "Episode:1003 meanR:-0.0800 rate:0.0000 gloss:-9.9875 dloss:0.0212 dlossR:0.0008 dlossQ:0.0204\n",
      "Episode:1004 meanR:-0.0700 rate:0.0769 gloss:-11.1830 dloss:0.6532 dlossR:0.6370 dlossQ:0.0162\n",
      "Episode:1005 meanR:-0.0900 rate:-0.0769 gloss:-9.5707 dloss:-0.5117 dlossR:-0.5337 dlossQ:0.0220\n",
      "Episode:1006 meanR:-0.0800 rate:0.0769 gloss:-10.6989 dloss:0.6285 dlossR:0.6114 dlossQ:0.0171\n",
      "Episode:1007 meanR:-0.0500 rate:0.1538 gloss:-9.9302 dloss:1.1716 dlossR:1.1483 dlossQ:0.0233\n",
      "Episode:1008 meanR:-0.0700 rate:0.0000 gloss:-11.7027 dloss:0.0160 dlossR:0.0002 dlossQ:0.0158\n",
      "Episode:1009 meanR:-0.0700 rate:0.0000 gloss:-11.8018 dloss:0.0162 dlossR:0.0002 dlossQ:0.0161\n",
      "Episode:1010 meanR:-0.0400 rate:0.2308 gloss:-10.0491 dloss:1.7797 dlossR:1.7585 dlossQ:0.0213\n",
      "Episode:1011 meanR:-0.0600 rate:-0.0769 gloss:-8.4515 dloss:-0.4391 dlossR:-0.4683 dlossQ:0.0292\n",
      "Episode:1012 meanR:-0.0400 rate:0.0769 gloss:-7.8778 dloss:0.4857 dlossR:0.4532 dlossQ:0.0325\n",
      "Episode:1013 meanR:0.0000 rate:0.2308 gloss:-10.4216 dloss:1.8406 dlossR:1.8215 dlossQ:0.0190\n",
      "Episode:1014 meanR:0.0200 rate:0.0769 gloss:-9.3555 dloss:0.5592 dlossR:0.5358 dlossQ:0.0234\n",
      "Episode:1015 meanR:0.0000 rate:0.0769 gloss:-8.2511 dloss:0.5026 dlossR:0.4742 dlossQ:0.0283\n",
      "Episode:1016 meanR:0.0000 rate:0.0000 gloss:-9.1076 dloss:0.0250 dlossR:0.0016 dlossQ:0.0233\n",
      "Episode:1017 meanR:-0.0100 rate:0.0000 gloss:-7.8285 dloss:0.0358 dlossR:0.0033 dlossQ:0.0325\n",
      "Episode:1018 meanR:0.0000 rate:0.0769 gloss:-8.0360 dloss:0.4925 dlossR:0.4618 dlossQ:0.0307\n",
      "Episode:1019 meanR:0.0000 rate:0.0000 gloss:-8.3761 dloss:0.0312 dlossR:0.0026 dlossQ:0.0286\n",
      "Episode:1020 meanR:-0.0100 rate:0.0000 gloss:-8.1711 dloss:0.0376 dlossR:0.0031 dlossQ:0.0346\n",
      "Episode:1021 meanR:-0.0300 rate:-0.1538 gloss:-8.8511 dloss:-0.9443 dlossR:-0.9719 dlossQ:0.0276\n",
      "Episode:1022 meanR:-0.0400 rate:0.0000 gloss:-8.4894 dloss:0.0296 dlossR:0.0023 dlossQ:0.0273\n",
      "Episode:1023 meanR:-0.0300 rate:0.0000 gloss:-7.8656 dloss:0.0388 dlossR:0.0035 dlossQ:0.0353\n",
      "Episode:1024 meanR:0.0000 rate:-0.1538 gloss:-8.8797 dloss:-0.9518 dlossR:-0.9778 dlossQ:0.0260\n",
      "Episode:1025 meanR:0.0200 rate:0.0769 gloss:-7.8508 dloss:0.4896 dlossR:0.4538 dlossQ:0.0358\n",
      "Episode:1026 meanR:0.0100 rate:0.0000 gloss:-8.2147 dloss:0.0362 dlossR:0.0032 dlossQ:0.0330\n",
      "Episode:1027 meanR:-0.0100 rate:-0.0769 gloss:-7.9147 dloss:-0.3979 dlossR:-0.4367 dlossQ:0.0388\n",
      "Episode:1028 meanR:0.0100 rate:0.1538 gloss:-7.2638 dloss:0.9025 dlossR:0.8506 dlossQ:0.0519\n",
      "Episode:1029 meanR:0.0100 rate:0.0000 gloss:-8.3290 dloss:0.0364 dlossR:0.0029 dlossQ:0.0334\n",
      "Episode:1030 meanR:0.0000 rate:0.0000 gloss:-7.6182 dloss:0.0478 dlossR:0.0048 dlossQ:0.0430\n",
      "Episode:1031 meanR:-0.0200 rate:-0.0769 gloss:-7.8741 dloss:-0.4000 dlossR:-0.4344 dlossQ:0.0344\n",
      "Episode:1032 meanR:-0.0300 rate:-0.0769 gloss:-7.3938 dloss:-0.3607 dlossR:-0.4060 dlossQ:0.0454\n",
      "Episode:1033 meanR:-0.0200 rate:0.0769 gloss:-6.9420 dloss:0.4610 dlossR:0.4049 dlossQ:0.0561\n",
      "Episode:1034 meanR:0.0000 rate:0.0769 gloss:-8.0489 dloss:0.4974 dlossR:0.4634 dlossQ:0.0340\n",
      "Episode:1035 meanR:0.0000 rate:0.0000 gloss:-7.1406 dloss:0.0489 dlossR:0.0054 dlossQ:0.0435\n",
      "Episode:1036 meanR:-0.0100 rate:-0.0769 gloss:-8.8483 dloss:-0.4627 dlossR:-0.4918 dlossQ:0.0292\n",
      "Episode:1037 meanR:-0.0100 rate:0.0000 gloss:-6.5526 dloss:0.0666 dlossR:0.0085 dlossQ:0.0581\n",
      "Episode:1038 meanR:0.0500 rate:0.4615 gloss:-7.4456 dloss:2.8009 dlossR:2.7423 dlossQ:0.0586\n",
      "Episode:1039 meanR:0.0700 rate:0.2308 gloss:-7.2555 dloss:1.3443 dlossR:1.2871 dlossQ:0.0572\n",
      "Episode:1040 meanR:0.0900 rate:0.0769 gloss:-6.7993 dloss:0.4580 dlossR:0.3983 dlossQ:0.0597\n",
      "Episode:1041 meanR:0.1000 rate:0.0769 gloss:-5.9040 dloss:0.4406 dlossR:0.3533 dlossQ:0.0873\n",
      "Episode:1042 meanR:0.1000 rate:0.0000 gloss:-5.6329 dloss:0.1079 dlossR:0.0162 dlossQ:0.0917\n",
      "Episode:1043 meanR:0.1000 rate:0.0000 gloss:-6.2400 dloss:0.0791 dlossR:0.0107 dlossQ:0.0684\n",
      "Episode:1044 meanR:0.1300 rate:0.1538 gloss:-6.3270 dloss:0.8335 dlossR:0.7529 dlossQ:0.0807\n",
      "Episode:1045 meanR:0.1200 rate:0.0000 gloss:-5.5348 dloss:0.1254 dlossR:0.0203 dlossQ:0.1051\n",
      "Episode:1046 meanR:0.1400 rate:0.0000 gloss:-5.2355 dloss:0.1370 dlossR:0.0223 dlossQ:0.1147\n",
      "Episode:1047 meanR:0.1300 rate:0.0000 gloss:-5.8842 dloss:0.0944 dlossR:0.0137 dlossQ:0.0807\n",
      "Episode:1048 meanR:0.1200 rate:0.0000 gloss:-4.5893 dloss:0.2351 dlossR:0.0408 dlossQ:0.1943\n",
      "Episode:1049 meanR:0.1300 rate:0.0000 gloss:-5.9227 dloss:0.0928 dlossR:0.0133 dlossQ:0.0795\n",
      "Episode:1050 meanR:0.1200 rate:-0.0769 gloss:-5.0077 dloss:-0.1105 dlossR:-0.2468 dlossQ:0.1363\n",
      "Episode:1051 meanR:0.1100 rate:0.0000 gloss:-5.0888 dloss:0.1610 dlossR:0.0271 dlossQ:0.1340\n",
      "Episode:1052 meanR:0.1200 rate:0.0000 gloss:-4.9465 dloss:0.1712 dlossR:0.0301 dlossQ:0.1411\n",
      "Episode:1053 meanR:0.1200 rate:0.0000 gloss:-4.8384 dloss:0.1831 dlossR:0.0323 dlossQ:0.1508\n",
      "Episode:1054 meanR:0.1200 rate:0.0000 gloss:-3.9669 dloss:0.2899 dlossR:0.0592 dlossQ:0.2307\n",
      "Episode:1055 meanR:0.1400 rate:0.0769 gloss:-4.0678 dloss:0.5076 dlossR:0.2873 dlossQ:0.2203\n",
      "Episode:1056 meanR:0.1600 rate:0.0000 gloss:-4.0188 dloss:0.2738 dlossR:0.0550 dlossQ:0.2188\n",
      "Episode:1057 meanR:0.1700 rate:0.0769 gloss:-4.9254 dloss:0.4572 dlossR:0.3127 dlossQ:0.1445\n",
      "Episode:1058 meanR:0.1600 rate:-0.0769 gloss:-5.4229 dloss:-0.1645 dlossR:-0.2773 dlossQ:0.1128\n",
      "Episode:1059 meanR:0.1500 rate:0.0000 gloss:-4.8969 dloss:0.1745 dlossR:0.0302 dlossQ:0.1443\n",
      "Episode:1060 meanR:0.1200 rate:-0.1538 gloss:-5.5082 dloss:-0.4693 dlossR:-0.5751 dlossQ:0.1058\n",
      "Episode:1061 meanR:0.1300 rate:0.0000 gloss:-4.9526 dloss:0.1658 dlossR:0.0276 dlossQ:0.1382\n",
      "Episode:1062 meanR:0.1300 rate:0.0000 gloss:-5.0168 dloss:0.1569 dlossR:0.0259 dlossQ:0.1310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1063 meanR:0.1400 rate:0.0769 gloss:-4.0047 dloss:0.5045 dlossR:0.2828 dlossQ:0.2217\n",
      "Episode:1064 meanR:0.1400 rate:0.0000 gloss:-4.8071 dloss:0.1774 dlossR:0.0310 dlossQ:0.1464\n",
      "Episode:1065 meanR:0.1300 rate:-0.0769 gloss:-5.4311 dloss:-0.1609 dlossR:-0.2763 dlossQ:0.1153\n",
      "Episode:1066 meanR:0.1000 rate:-0.0769 gloss:-4.5521 dloss:-0.0440 dlossR:-0.2108 dlossQ:0.1668\n",
      "Episode:1067 meanR:0.0900 rate:0.0000 gloss:-4.5764 dloss:0.2023 dlossR:0.0369 dlossQ:0.1654\n",
      "Episode:1068 meanR:0.0900 rate:0.0769 gloss:-4.9379 dloss:0.4610 dlossR:0.3145 dlossQ:0.1465\n",
      "Episode:1069 meanR:0.1200 rate:0.0000 gloss:-5.5973 dloss:0.1178 dlossR:0.0179 dlossQ:0.1000\n",
      "Episode:1070 meanR:0.1000 rate:-0.0769 gloss:-6.0453 dloss:-0.2410 dlossR:-0.3213 dlossQ:0.0803\n",
      "Episode:1071 meanR:0.0700 rate:0.0000 gloss:-5.4217 dloss:0.1254 dlossR:0.0194 dlossQ:0.1060\n",
      "Episode:1072 meanR:0.0600 rate:-0.0769 gloss:-6.0537 dloss:-0.2358 dlossR:-0.3200 dlossQ:0.0841\n",
      "Episode:1073 meanR:0.0400 rate:-0.0769 gloss:-6.4832 dloss:-0.2837 dlossR:-0.3488 dlossQ:0.0652\n",
      "Episode:1074 meanR:0.0400 rate:0.0000 gloss:-5.7166 dloss:0.1163 dlossR:0.0180 dlossQ:0.0983\n",
      "Episode:1075 meanR:0.0300 rate:-0.1538 gloss:-6.3962 dloss:-0.6160 dlossR:-0.6850 dlossQ:0.0690\n",
      "Episode:1076 meanR:0.0100 rate:-0.0769 gloss:-5.4072 dloss:-0.1658 dlossR:-0.2761 dlossQ:0.1103\n",
      "Episode:1077 meanR:0.0000 rate:0.0000 gloss:-5.8169 dloss:0.1089 dlossR:0.0159 dlossQ:0.0930\n",
      "Episode:1078 meanR:0.0200 rate:0.0000 gloss:-6.6117 dloss:0.0749 dlossR:0.0098 dlossQ:0.0652\n",
      "Episode:1079 meanR:-0.0100 rate:0.0000 gloss:-5.7297 dloss:0.1085 dlossR:0.0162 dlossQ:0.0923\n",
      "Episode:1080 meanR:-0.0100 rate:-0.0769 gloss:-6.7463 dloss:-0.2984 dlossR:-0.3638 dlossQ:0.0654\n",
      "Episode:1081 meanR:-0.0100 rate:-0.0769 gloss:-6.7983 dloss:-0.3067 dlossR:-0.3673 dlossQ:0.0606\n",
      "Episode:1082 meanR:0.0000 rate:0.0000 gloss:-7.5697 dloss:0.0463 dlossR:0.0049 dlossQ:0.0415\n",
      "Episode:1083 meanR:0.0100 rate:0.0000 gloss:-7.3692 dloss:0.0511 dlossR:0.0056 dlossQ:0.0455\n",
      "Episode:1084 meanR:-0.0100 rate:-0.1538 gloss:-8.2628 dloss:-0.8726 dlossR:-0.9032 dlossQ:0.0307\n",
      "Episode:1085 meanR:0.0000 rate:0.0000 gloss:-6.2454 dloss:0.0773 dlossR:0.0103 dlossQ:0.0670\n",
      "Episode:1086 meanR:0.0300 rate:0.0000 gloss:-8.2996 dloss:0.0368 dlossR:0.0033 dlossQ:0.0335\n",
      "Episode:1087 meanR:0.0400 rate:0.0000 gloss:-9.4233 dloss:0.0241 dlossR:0.0016 dlossQ:0.0225\n",
      "Episode:1088 meanR:0.0400 rate:0.0000 gloss:-7.8810 dloss:0.0355 dlossR:0.0032 dlossQ:0.0323\n",
      "Episode:1089 meanR:0.0300 rate:-0.0769 gloss:-9.2967 dloss:-0.4924 dlossR:-0.5160 dlossQ:0.0236\n",
      "Episode:1090 meanR:0.0300 rate:-0.0769 gloss:-9.1126 dloss:-0.4815 dlossR:-0.5057 dlossQ:0.0242\n",
      "Episode:1091 meanR:0.0100 rate:-0.0769 gloss:-9.3343 dloss:-0.4939 dlossR:-0.5184 dlossQ:0.0245\n",
      "Episode:1092 meanR:-0.0300 rate:-0.1538 gloss:-9.6473 dloss:-1.0368 dlossR:-1.0625 dlossQ:0.0257\n",
      "Episode:1093 meanR:-0.0100 rate:0.1538 gloss:-9.3086 dloss:1.1013 dlossR:1.0744 dlossQ:0.0268\n",
      "Episode:1094 meanR:0.0100 rate:0.0769 gloss:-12.0741 dloss:0.7050 dlossR:0.6870 dlossQ:0.0180\n",
      "Episode:1095 meanR:0.0100 rate:0.0000 gloss:-8.7371 dloss:0.0275 dlossR:0.0021 dlossQ:0.0254\n",
      "Episode:1096 meanR:-0.0100 rate:-0.1538 gloss:-10.9236 dloss:-1.1883 dlossR:-1.2070 dlossQ:0.0187\n",
      "Episode:1097 meanR:0.0000 rate:0.0000 gloss:-11.8734 dloss:0.0181 dlossR:0.0003 dlossQ:0.0178\n",
      "Episode:1098 meanR:0.0000 rate:0.0000 gloss:-11.2746 dloss:0.0209 dlossR:0.0004 dlossQ:0.0205\n",
      "Episode:1099 meanR:0.0200 rate:0.0769 gloss:-12.7214 dloss:0.7404 dlossR:0.7236 dlossQ:0.0168\n",
      "Episode:1100 meanR:0.0400 rate:-0.0769 gloss:-13.0193 dloss:-0.7104 dlossR:-0.7284 dlossQ:0.0180\n",
      "Episode:1101 meanR:0.0600 rate:0.0000 gloss:-10.2099 dloss:0.0180 dlossR:0.0006 dlossQ:0.0175\n",
      "Episode:1102 meanR:0.0500 rate:-0.0769 gloss:-12.4309 dloss:-0.6780 dlossR:-0.6950 dlossQ:0.0170\n",
      "Episode:1103 meanR:0.0500 rate:0.0000 gloss:-13.0559 dloss:0.0149 dlossR:0.0001 dlossQ:0.0148\n",
      "Episode:1104 meanR:0.0400 rate:0.0000 gloss:-14.1284 dloss:0.0237 dlossR:0.0001 dlossQ:0.0236\n",
      "Episode:1105 meanR:0.0500 rate:0.0000 gloss:-12.9310 dloss:0.0162 dlossR:0.0001 dlossQ:0.0161\n",
      "Episode:1106 meanR:0.0500 rate:0.0769 gloss:-12.6224 dloss:0.7380 dlossR:0.7178 dlossQ:0.0202\n",
      "Episode:1107 meanR:0.0200 rate:-0.0769 gloss:-13.4083 dloss:-0.7342 dlossR:-0.7497 dlossQ:0.0156\n",
      "Episode:1108 meanR:0.0200 rate:0.0000 gloss:-12.3862 dloss:0.0186 dlossR:0.0002 dlossQ:0.0184\n",
      "Episode:1109 meanR:0.0300 rate:0.0769 gloss:-9.4843 dloss:0.5623 dlossR:0.5425 dlossQ:0.0199\n",
      "Episode:1110 meanR:0.0100 rate:0.0769 gloss:-12.9102 dloss:0.7506 dlossR:0.7341 dlossQ:0.0165\n",
      "Episode:1111 meanR:0.0200 rate:0.0000 gloss:-14.2875 dloss:0.0195 dlossR:0.0001 dlossQ:0.0194\n",
      "Episode:1112 meanR:0.0100 rate:0.0000 gloss:-12.6626 dloss:0.0161 dlossR:0.0001 dlossQ:0.0160\n",
      "Episode:1113 meanR:-0.0200 rate:0.0000 gloss:-15.2656 dloss:0.0209 dlossR:0.0000 dlossQ:0.0208\n",
      "Episode:1114 meanR:-0.0300 rate:0.0000 gloss:-14.6931 dloss:0.0189 dlossR:0.0001 dlossQ:0.0189\n",
      "Episode:1115 meanR:-0.0400 rate:0.0000 gloss:-15.6863 dloss:0.0187 dlossR:0.0000 dlossQ:0.0187\n",
      "Episode:1116 meanR:-0.0300 rate:0.0769 gloss:-13.5003 dloss:0.7913 dlossR:0.7680 dlossQ:0.0233\n",
      "Episode:1117 meanR:-0.0400 rate:-0.0769 gloss:-13.0650 dloss:-0.7124 dlossR:-0.7302 dlossQ:0.0178\n",
      "Episode:1118 meanR:-0.0500 rate:0.0000 gloss:-14.1942 dloss:0.0122 dlossR:0.0001 dlossQ:0.0121\n",
      "Episode:1119 meanR:-0.0500 rate:0.0000 gloss:-12.5637 dloss:0.0200 dlossR:0.0003 dlossQ:0.0197\n",
      "Episode:1120 meanR:-0.0300 rate:0.1538 gloss:-13.1841 dloss:1.5291 dlossR:1.5121 dlossQ:0.0170\n",
      "Episode:1121 meanR:-0.0200 rate:-0.0769 gloss:-13.8945 dloss:-0.7577 dlossR:-0.7777 dlossQ:0.0200\n",
      "Episode:1122 meanR:-0.0200 rate:0.0000 gloss:-11.9782 dloss:0.0190 dlossR:0.0002 dlossQ:0.0188\n",
      "Episode:1123 meanR:-0.0200 rate:0.0000 gloss:-14.3548 dloss:0.0200 dlossR:0.0000 dlossQ:0.0200\n",
      "Episode:1124 meanR:0.0000 rate:0.0000 gloss:-13.5591 dloss:0.0172 dlossR:0.0001 dlossQ:0.0171\n",
      "Episode:1125 meanR:0.0000 rate:0.0769 gloss:-9.9369 dloss:0.5864 dlossR:0.5667 dlossQ:0.0196\n",
      "Episode:1126 meanR:0.0000 rate:0.0000 gloss:-11.3605 dloss:0.0217 dlossR:0.0004 dlossQ:0.0214\n",
      "Episode:1127 meanR:0.0100 rate:0.0000 gloss:-9.5607 dloss:0.0221 dlossR:0.0010 dlossQ:0.0211\n",
      "Episode:1128 meanR:-0.0100 rate:0.0000 gloss:-10.0381 dloss:0.0189 dlossR:0.0006 dlossQ:0.0182\n",
      "Episode:1129 meanR:-0.0100 rate:0.0000 gloss:-13.8585 dloss:0.0215 dlossR:0.0001 dlossQ:0.0214\n",
      "Episode:1130 meanR:-0.0100 rate:0.0000 gloss:-11.8066 dloss:0.0160 dlossR:0.0002 dlossQ:0.0158\n",
      "Episode:1131 meanR:0.0000 rate:0.0000 gloss:-10.9318 dloss:0.0176 dlossR:0.0004 dlossQ:0.0172\n",
      "Episode:1132 meanR:0.0100 rate:0.0000 gloss:-11.8161 dloss:0.0196 dlossR:0.0004 dlossQ:0.0192\n",
      "Episode:1133 meanR:0.0000 rate:0.0000 gloss:-12.8754 dloss:0.0168 dlossR:0.0002 dlossQ:0.0166\n",
      "Episode:1134 meanR:-0.0100 rate:0.0000 gloss:-11.9211 dloss:0.0235 dlossR:0.0004 dlossQ:0.0231\n",
      "Episode:1135 meanR:0.0100 rate:0.1538 gloss:-10.1254 dloss:1.1874 dlossR:1.1688 dlossQ:0.0186\n",
      "Episode:1136 meanR:0.0300 rate:0.0769 gloss:-10.9904 dloss:0.6445 dlossR:0.6273 dlossQ:0.0172\n",
      "Episode:1137 meanR:0.0400 rate:0.0769 gloss:-9.5186 dloss:0.5660 dlossR:0.5451 dlossQ:0.0208\n",
      "Episode:1138 meanR:-0.0200 rate:0.0000 gloss:-9.6676 dloss:0.0215 dlossR:0.0013 dlossQ:0.0202\n",
      "Episode:1139 meanR:-0.0600 rate:-0.0769 gloss:-10.2901 dloss:-0.5522 dlossR:-0.5744 dlossQ:0.0222\n",
      "Episode:1140 meanR:-0.0700 rate:0.0000 gloss:-9.6424 dloss:0.0206 dlossR:0.0009 dlossQ:0.0197\n",
      "Episode:1141 meanR:-0.0800 rate:0.0000 gloss:-10.0978 dloss:0.0257 dlossR:0.0010 dlossQ:0.0247\n",
      "Episode:1142 meanR:-0.0700 rate:0.0769 gloss:-8.9330 dloss:0.5375 dlossR:0.5126 dlossQ:0.0249\n",
      "Episode:1143 meanR:-0.0600 rate:0.0769 gloss:-8.0893 dloss:0.4980 dlossR:0.4660 dlossQ:0.0321\n",
      "Episode:1144 meanR:-0.1200 rate:-0.3077 gloss:-10.2571 dloss:-2.2046 dlossR:-2.2230 dlossQ:0.0184\n",
      "Episode:1145 meanR:-0.1300 rate:-0.0769 gloss:-9.7773 dloss:-0.5238 dlossR:-0.5456 dlossQ:0.0217\n",
      "Episode:1146 meanR:-0.1200 rate:0.0769 gloss:-9.7438 dloss:0.5817 dlossR:0.5577 dlossQ:0.0240\n",
      "Episode:1147 meanR:-0.0700 rate:0.3846 gloss:-9.0306 dloss:2.7346 dlossR:2.7024 dlossQ:0.0322\n",
      "Episode:1148 meanR:-0.0800 rate:-0.0769 gloss:-8.6796 dloss:-0.4577 dlossR:-0.4831 dlossQ:0.0254\n",
      "Episode:1149 meanR:-0.0800 rate:0.0000 gloss:-8.8812 dloss:0.0265 dlossR:0.0016 dlossQ:0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1150 meanR:-0.0900 rate:-0.1538 gloss:-10.2168 dloss:-1.1096 dlossR:-1.1292 dlossQ:0.0195\n",
      "Episode:1151 meanR:-0.0700 rate:0.1538 gloss:-9.4872 dloss:1.1173 dlossR:1.0957 dlossQ:0.0216\n",
      "Episode:1152 meanR:-0.0700 rate:0.0000 gloss:-10.0695 dloss:0.0192 dlossR:0.0008 dlossQ:0.0185\n",
      "Episode:1153 meanR:-0.0600 rate:0.0769 gloss:-8.2950 dloss:0.5106 dlossR:0.4773 dlossQ:0.0333\n",
      "Episode:1154 meanR:-0.0600 rate:0.0000 gloss:-8.7688 dloss:0.0296 dlossR:0.0023 dlossQ:0.0273\n",
      "Episode:1155 meanR:-0.0800 rate:-0.0769 gloss:-8.2906 dloss:-0.4288 dlossR:-0.4590 dlossQ:0.0302\n",
      "Episode:1156 meanR:-0.0800 rate:0.0000 gloss:-7.7278 dloss:0.0530 dlossR:0.0058 dlossQ:0.0472\n",
      "Episode:1157 meanR:-0.0900 rate:0.0000 gloss:-8.9097 dloss:0.0246 dlossR:0.0016 dlossQ:0.0230\n",
      "Episode:1158 meanR:-0.0800 rate:0.0000 gloss:-7.4440 dloss:0.0538 dlossR:0.0062 dlossQ:0.0476\n",
      "Episode:1159 meanR:-0.0700 rate:0.0769 gloss:-5.9123 dloss:0.4433 dlossR:0.3546 dlossQ:0.0887\n",
      "Episode:1160 meanR:-0.0400 rate:0.0769 gloss:-6.0782 dloss:0.4412 dlossR:0.3618 dlossQ:0.0794\n",
      "Episode:1161 meanR:-0.0500 rate:-0.0769 gloss:-6.1374 dloss:-0.2456 dlossR:-0.3257 dlossQ:0.0802\n",
      "Episode:1162 meanR:-0.0400 rate:0.0769 gloss:-8.4391 dloss:0.5216 dlossR:0.4856 dlossQ:0.0360\n",
      "Episode:1163 meanR:-0.0500 rate:0.0000 gloss:-8.8284 dloss:0.0253 dlossR:0.0016 dlossQ:0.0237\n",
      "Episode:1164 meanR:-0.0600 rate:-0.0769 gloss:-6.3975 dloss:-0.2717 dlossR:-0.3426 dlossQ:0.0709\n",
      "Episode:1165 meanR:-0.0500 rate:0.0000 gloss:-6.2310 dloss:0.1015 dlossR:0.0134 dlossQ:0.0881\n",
      "Episode:1166 meanR:-0.0400 rate:0.0000 gloss:-8.5621 dloss:0.0332 dlossR:0.0031 dlossQ:0.0301\n",
      "Episode:1167 meanR:-0.0500 rate:-0.0769 gloss:-8.9730 dloss:-0.4698 dlossR:-0.4981 dlossQ:0.0284\n",
      "Episode:1168 meanR:-0.0800 rate:-0.1538 gloss:-8.5698 dloss:-0.9044 dlossR:-0.9389 dlossQ:0.0345\n",
      "Episode:1169 meanR:-0.1000 rate:-0.1538 gloss:-9.1598 dloss:-0.9804 dlossR:-1.0087 dlossQ:0.0283\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "episodes_total_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "saver = tf.train.Saver()\n",
    "rewards_list, g_loss_list, d_loss_list = [], [], []\n",
    "d_lossR_list, d_lossQ_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(111111):\n",
    "        batch = [] # every data batch\n",
    "        total_reward = 0\n",
    "        #state = env.reset() # env first state\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            state = env_info.vector_observations[0]   # get the next state\n",
    "            action_logits, Q_logits = sess.run(fetches=[model.actions_logits, model.Qs_logits], \n",
    "                                               feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            batch.append([state, action, Q_logits])\n",
    "            #state, reward, done, _ = env.step(action)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            total_reward += reward\n",
    "            if done is True: # episode ended success/failure\n",
    "                episodes_total_reward.append(total_reward) # stopping criteria\n",
    "                #rate = total_reward/ 500 # success is 500 points, rate is between 0 and +1 ~ sigmoid\n",
    "                rate = total_reward/ +13 # success is +13; rate is between -1 and +1 ~ tanh\n",
    "                if rate >= +1: rate = +1\n",
    "                if rate <= -1: rate = -1\n",
    "                break\n",
    "\n",
    "        # Training using batches\n",
    "        #batch = memory.buffer\n",
    "        states = np.array([each[0] for each in batch])\n",
    "        actions = np.array([each[1] for each in batch])\n",
    "        targetQs = np.array([each[2] for each in batch])\n",
    "        g_loss, d_loss, d_lossR, d_lossQ, _, _ = sess.run([model.g_loss, model.d_loss,\n",
    "                                                           model.d_lossR, model.d_lossQ, \n",
    "                                                           model.g_opt, model.d_opt],\n",
    "                                                          feed_dict = {model.states: states, \n",
    "                                                                       model.actions: actions,\n",
    "                                                                       model.reward: rate,\n",
    "                                                                       model.targetQs: targetQs.reshape([-1])})\n",
    "        # Average 100 episode total reward\n",
    "        # Print out\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episodes_total_reward)),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'gloss:{:.4f}'.format(g_loss),\n",
    "              'dloss:{:.4f}'.format(d_loss),\n",
    "              'dlossR:{:.4f}'.format(d_lossR),\n",
    "              'dlossQ:{:.4f}'.format(d_lossQ))\n",
    "        # Ploting out\n",
    "        rewards_list.append([ep, np.mean(episodes_total_reward)])\n",
    "        g_loss_list.append([ep, g_loss])\n",
    "        d_loss_list.append([ep, d_loss])\n",
    "        d_lossR_list.append([ep, d_lossR])\n",
    "        d_lossQ_list.append([ep, d_lossQ])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episodes_total_reward) >= +13:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints-nav/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import gym\n",
    "# # # env = gym.make('CartPole-v0')\n",
    "# # env = gym.make('CartPole-v1')\n",
    "# # # env = gym.make('Acrobot-v1')\n",
    "# # # env = gym.make('MountainCar-v0')\n",
    "# # # env = gym.make('Pendulum-v0')\n",
    "# # # env = gym.make('Blackjack-v0')\n",
    "# # # env = gym.make('FrozenLake-v0')\n",
    "# # # env = gym.make('AirRaid-ram-v0')\n",
    "# # # env = gym.make('AirRaid-v0')\n",
    "# # # env = gym.make('BipedalWalker-v2')\n",
    "# # # env = gym.make('Copy-v0')\n",
    "# # # env = gym.make('CarRacing-v0')\n",
    "# # # env = gym.make('Ant-v2') #mujoco\n",
    "# # # env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     #sess.run(tf.global_variables_initializer())\n",
    "#     saver.restore(sess, 'checkpoints/model-nav.ckpt')    \n",
    "#     #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "#     # Episodes/epochs\n",
    "#     for _ in range(1):\n",
    "#         state = env.reset()\n",
    "#         total_reward = 0\n",
    "\n",
    "#         # Steps/batches\n",
    "#         #for _ in range(111111111111111111):\n",
    "#         while True:\n",
    "#             env.render()\n",
    "#             action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "#             action = np.argmax(action_logits)\n",
    "#             state, reward, done, _ = env.step(action)\n",
    "#             total_reward += reward\n",
    "#             if done:\n",
    "#                 break\n",
    "                \n",
    "#         # Closing the env\n",
    "#         print('total_reward: {:.2f}'.format(total_reward))\n",
    "#         env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

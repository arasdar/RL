{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# env = UnityEnvironment(file_name=\"/home/arasdar/VisualBanana_Linux/Banana.x86\")\n",
    "env = UnityEnvironment(file_name=\"/home/arasdar/Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "# print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)\n",
    "# print(state.shape, len(env_info.vector_observations), env_info.vector_observations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37,)\n",
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        print(state.shape)\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    #print(state)\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "batch = []\n",
    "while True: # infinite number of steps\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    #print(state, action, reward, done)\n",
    "    batch.append([action, state, reward, done])\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "# print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, array([1.        , 0.        , 0.        , 0.        , 0.41103721,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.40960541,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.04057696,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.253993  ,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.30345654,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.19119175,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.3996276 ,\n",
       "         0.        , 0.        ]), 0.0, False], (37,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, array([1.        , 0.        , 0.        , 0.        , 0.41103721,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.40960541,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.04057696,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.253993  ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.30345654,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.19119175,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.3996276 ,\n",
       "        0.        , 0.        ]), 0.0, False]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array([each[0] for each in batch])\n",
    "states = np.array([each[1] for each in batch])\n",
    "rewards = np.array([each[2] for each in batch])\n",
    "dones = np.array([each[3] for each in batch])\n",
    "# infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,) (300, 37) (300,) (300,)\n",
      "float64 float64 int64 bool\n",
      "3 0 4\n",
      "0.0 0.0\n",
      "10.478745460510254 -9.995721817016602\n"
     ]
    }
   ],
   "source": [
    "# print(rewards[:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)), \n",
    "      (np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    rewards = tf.placeholder(tf.float32, [None], name='rewards')\n",
    "    rate = tf.placeholder(tf.float32, [], name='rate')\n",
    "    return states, actions, targetQs, rewards, rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator/Controller: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator/Dopamine: Reward function/planner/naviator/advisor/supervisor/cortical columns\n",
    "def discriminator(states, actions, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Fusion/merge states and actions/ SA/ SM\n",
    "        x_fused = tf.concat(axis=1, values=[states, actions])\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=x_fused, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return rewards logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, actions, targetQs, rewards, rate):\n",
    "    # G\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    neg_log_prob_actions = tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                      labels=actions_labels)\n",
    "    Qs_labels = rewards[:-1] + (0.99 * targetQs[1:])\n",
    "    #g_loss = tf.reduce_mean(neg_log_prob_actions[:-1] * targetQs[1:])\n",
    "    g_loss = tf.reduce_mean(neg_log_prob_actions[:-1] * Qs_labels)\n",
    "    \n",
    "    # D\n",
    "    Qs_logits = discriminator(actions=actions_logits, hidden_size=hidden_size, states=states)\n",
    "    d_lossR = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Qs_logits,\n",
    "                                                                     labels=rate * tf.ones_like(Qs_logits)))\n",
    "    d_lossQ = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.reshape(Qs_logits[:-1], shape=[-1]),\n",
    "                                                                     labels=tf.nn.sigmoid(Qs_labels)))\n",
    "    d_loss = d_lossR + d_lossQ\n",
    "\n",
    "    return actions_logits, Qs_logits, g_loss, d_loss, d_lossR, d_lossQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizating/training/learning G & D\n",
    "def model_opt(g_loss, d_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param g_loss: Generator loss Tensor for action prediction\n",
    "    :param d_loss: Discriminator loss Tensor for reward prediction for generated/prob/logits action\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, self.rewards, self.rate = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.Qs_logits, self.g_loss, self.d_loss, self.d_lossR, self.d_lossQ = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, # model input\n",
    "            targetQs=self.targetQs, rewards=self.rewards, rate=self.rate) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_opt, self.d_opt = model_opt(g_loss=self.g_loss, d_loss=self.d_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size:(300, 37) actions:(300,)\n",
      "action size:4\n"
     ]
    }
   ],
   "source": [
    "print('state size:{}'.format(states.shape), \n",
    "      'actions:{}'.format(actions.shape)) \n",
    "print('action size:{}'.format(np.max(actions) - np.min(actions)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Network parameters\n",
    "state_size = 37              # number of units for the input state/observation -- simulation\n",
    "action_size = 4              # number of units for the output actions -- simulation\n",
    "hidden_size = 37*16          # number of units in each Q-network hidden layer -- simulation\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "\n",
    "while True: # infinite number of steps\n",
    "#for _ in range(batch_size):\n",
    "    state = env_info.vector_observations[0]   # get the next state\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    #memory.buffer.append([action, state, done])\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:-1.0000 rate:-0.0769 rateProb:0.4615 gloss:-0.1109 dloss:1.3839 dlossR:0.6913 dlossQ:0.6926\n",
      "Episode:1 meanR:-1.5000 rate:-0.1538 rateProb:0.4231 gloss:-0.7434 dloss:1.3464 dlossR:0.7266 dlossQ:0.6198\n",
      "Episode:2 meanR:-1.0000 rate:0.0000 rateProb:0.5000 gloss:-0.7682 dloss:1.5477 dlossR:0.8315 dlossQ:0.7162\n",
      "Episode:3 meanR:-0.7500 rate:0.0000 rateProb:0.5000 gloss:0.0120 dloss:1.3880 dlossR:0.6959 dlossQ:0.6920\n",
      "Episode:4 meanR:-0.6000 rate:0.0000 rateProb:0.5000 gloss:0.1979 dloss:1.3897 dlossR:0.6989 dlossQ:0.6908\n",
      "Episode:5 meanR:-0.6667 rate:-0.0769 rateProb:0.4615 gloss:0.3223 dloss:1.4023 dlossR:0.7228 dlossQ:0.6794\n",
      "Episode:6 meanR:-0.5714 rate:0.0000 rateProb:0.5000 gloss:0.2551 dloss:1.3922 dlossR:0.7089 dlossQ:0.6833\n",
      "Episode:7 meanR:-0.5000 rate:0.0000 rateProb:0.5000 gloss:0.1615 dloss:1.3874 dlossR:0.7044 dlossQ:0.6830\n",
      "Episode:8 meanR:-0.4444 rate:0.0000 rateProb:0.5000 gloss:0.0291 dloss:1.3876 dlossR:0.6954 dlossQ:0.6922\n",
      "Episode:9 meanR:-0.4000 rate:0.0000 rateProb:0.5000 gloss:-0.0247 dloss:1.3896 dlossR:0.6953 dlossQ:0.6943\n",
      "Episode:10 meanR:-0.3636 rate:0.0000 rateProb:0.5000 gloss:-0.0428 dloss:1.3876 dlossR:0.6973 dlossQ:0.6904\n",
      "Episode:11 meanR:-0.3333 rate:0.0000 rateProb:0.5000 gloss:-0.0391 dloss:1.3879 dlossR:0.6978 dlossQ:0.6901\n",
      "Episode:12 meanR:-0.3077 rate:0.0000 rateProb:0.5000 gloss:-0.0285 dloss:1.3889 dlossR:0.6972 dlossQ:0.6917\n",
      "Episode:13 meanR:-0.2857 rate:0.0000 rateProb:0.5000 gloss:-0.0198 dloss:1.3868 dlossR:0.6960 dlossQ:0.6909\n",
      "Episode:14 meanR:-0.2667 rate:0.0000 rateProb:0.5000 gloss:-0.0027 dloss:1.3870 dlossR:0.6940 dlossQ:0.6930\n",
      "Episode:15 meanR:-0.2500 rate:0.0000 rateProb:0.5000 gloss:0.0196 dloss:1.3866 dlossR:0.6958 dlossQ:0.6908\n",
      "Episode:16 meanR:-0.2353 rate:0.0000 rateProb:0.5000 gloss:0.0213 dloss:1.3872 dlossR:0.6963 dlossQ:0.6909\n",
      "Episode:17 meanR:-0.2222 rate:0.0000 rateProb:0.5000 gloss:0.0242 dloss:1.3869 dlossR:0.6985 dlossQ:0.6885\n",
      "Episode:18 meanR:-0.2105 rate:0.0000 rateProb:0.5000 gloss:0.0125 dloss:1.3867 dlossR:0.6957 dlossQ:0.6910\n",
      "Episode:19 meanR:-0.2000 rate:0.0000 rateProb:0.5000 gloss:0.0008 dloss:1.3867 dlossR:0.6934 dlossQ:0.6933\n",
      "Episode:20 meanR:-0.1905 rate:0.0000 rateProb:0.5000 gloss:-0.0070 dloss:1.3866 dlossR:0.6943 dlossQ:0.6923\n",
      "Episode:21 meanR:-0.1818 rate:0.0000 rateProb:0.5000 gloss:-0.0100 dloss:1.3873 dlossR:0.6958 dlossQ:0.6916\n",
      "Episode:22 meanR:-0.1739 rate:0.0000 rateProb:0.5000 gloss:-0.0057 dloss:1.3868 dlossR:0.6949 dlossQ:0.6919\n",
      "Episode:23 meanR:-0.1667 rate:0.0000 rateProb:0.5000 gloss:-0.0038 dloss:1.3866 dlossR:0.6944 dlossQ:0.6922\n",
      "Episode:24 meanR:-0.1600 rate:0.0000 rateProb:0.5000 gloss:-0.0006 dloss:1.3866 dlossR:0.6933 dlossQ:0.6934\n",
      "Episode:25 meanR:-0.2308 rate:-0.1538 rateProb:0.4231 gloss:0.0030 dloss:1.3904 dlossR:0.6972 dlossQ:0.6932\n",
      "Episode:26 meanR:-0.1852 rate:0.0769 rateProb:0.5385 gloss:-0.0003 dloss:1.3868 dlossR:0.6935 dlossQ:0.6933\n",
      "Episode:27 meanR:-0.1786 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3866 dlossR:0.6936 dlossQ:0.6930\n",
      "Episode:28 meanR:-0.1724 rate:0.0000 rateProb:0.5000 gloss:-0.0024 dloss:1.3872 dlossR:0.6940 dlossQ:0.6932\n",
      "Episode:29 meanR:-0.1667 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3873 dlossR:0.6937 dlossQ:0.6936\n",
      "Episode:30 meanR:-0.1613 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3867 dlossR:0.6936 dlossQ:0.6931\n",
      "Episode:31 meanR:-0.1875 rate:-0.0769 rateProb:0.4615 gloss:0.0014 dloss:1.3883 dlossR:0.6953 dlossQ:0.6929\n",
      "Episode:32 meanR:-0.1818 rate:0.0000 rateProb:0.5000 gloss:-0.0015 dloss:1.3865 dlossR:0.6935 dlossQ:0.6930\n",
      "Episode:33 meanR:-0.1765 rate:0.0000 rateProb:0.5000 gloss:-0.0057 dloss:1.3867 dlossR:0.6949 dlossQ:0.6918\n",
      "Episode:34 meanR:-0.1714 rate:0.0000 rateProb:0.5000 gloss:-0.0048 dloss:1.3869 dlossR:0.6953 dlossQ:0.6916\n",
      "Episode:35 meanR:-0.1667 rate:0.0000 rateProb:0.5000 gloss:-0.0037 dloss:1.3869 dlossR:0.6946 dlossQ:0.6922\n",
      "Episode:36 meanR:-0.1622 rate:0.0000 rateProb:0.5000 gloss:-0.0017 dloss:1.3866 dlossR:0.6935 dlossQ:0.6931\n",
      "Episode:37 meanR:-0.1579 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3866 dlossR:0.6934 dlossQ:0.6932\n",
      "Episode:38 meanR:-0.1538 rate:0.0000 rateProb:0.5000 gloss:0.0017 dloss:1.3867 dlossR:0.6936 dlossQ:0.6931\n",
      "Episode:39 meanR:-0.1500 rate:0.0000 rateProb:0.5000 gloss:0.0036 dloss:1.3866 dlossR:0.6945 dlossQ:0.6921\n",
      "Episode:40 meanR:-0.1463 rate:0.0000 rateProb:0.5000 gloss:0.0029 dloss:1.3866 dlossR:0.6941 dlossQ:0.6925\n",
      "Episode:41 meanR:-0.1429 rate:0.0000 rateProb:0.5000 gloss:0.0034 dloss:1.3866 dlossR:0.6937 dlossQ:0.6929\n",
      "Episode:42 meanR:-0.1395 rate:0.0000 rateProb:0.5000 gloss:0.0015 dloss:1.3868 dlossR:0.6934 dlossQ:0.6934\n",
      "Episode:43 meanR:-0.1136 rate:0.0769 rateProb:0.5385 gloss:-0.0005 dloss:1.3871 dlossR:0.6940 dlossQ:0.6931\n",
      "Episode:44 meanR:-0.1111 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:45 meanR:-0.1087 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3866 dlossR:0.6934 dlossQ:0.6933\n",
      "Episode:46 meanR:-0.1064 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3865 dlossR:0.6934 dlossQ:0.6931\n",
      "Episode:47 meanR:-0.0833 rate:0.0769 rateProb:0.5385 gloss:0.0010 dloss:1.3864 dlossR:0.6931 dlossQ:0.6933\n",
      "Episode:48 meanR:-0.0816 rate:0.0000 rateProb:0.5000 gloss:0.0023 dloss:1.3866 dlossR:0.6937 dlossQ:0.6929\n",
      "Episode:49 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0033 dloss:1.3866 dlossR:0.6939 dlossQ:0.6927\n",
      "Episode:50 meanR:-0.0784 rate:0.0000 rateProb:0.5000 gloss:0.0035 dloss:1.3866 dlossR:0.6942 dlossQ:0.6924\n",
      "Episode:51 meanR:-0.0962 rate:-0.0769 rateProb:0.4615 gloss:0.0049 dloss:1.3900 dlossR:0.6975 dlossQ:0.6925\n",
      "Episode:52 meanR:-0.0943 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3864 dlossR:0.6933 dlossQ:0.6932\n",
      "Episode:53 meanR:-0.0926 rate:0.0000 rateProb:0.5000 gloss:-0.0025 dloss:1.3870 dlossR:0.6938 dlossQ:0.6932\n",
      "Episode:54 meanR:-0.1091 rate:-0.0769 rateProb:0.4615 gloss:-0.0032 dloss:1.3830 dlossR:0.6909 dlossQ:0.6921\n",
      "Episode:55 meanR:-0.1071 rate:0.0000 rateProb:0.5000 gloss:-0.0045 dloss:1.3869 dlossR:0.6959 dlossQ:0.6910\n",
      "Episode:56 meanR:-0.1053 rate:0.0000 rateProb:0.5000 gloss:-0.0057 dloss:1.3868 dlossR:0.6973 dlossQ:0.6895\n",
      "Episode:57 meanR:-0.1034 rate:0.0000 rateProb:0.5000 gloss:-0.0032 dloss:1.3870 dlossR:0.6944 dlossQ:0.6926\n",
      "Episode:58 meanR:-0.1017 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3866 dlossR:0.6934 dlossQ:0.6932\n",
      "Episode:59 meanR:-0.1000 rate:0.0000 rateProb:0.5000 gloss:0.0019 dloss:1.3865 dlossR:0.6935 dlossQ:0.6930\n",
      "Episode:60 meanR:-0.0984 rate:0.0000 rateProb:0.5000 gloss:0.0019 dloss:1.3865 dlossR:0.6936 dlossQ:0.6929\n",
      "Episode:61 meanR:-0.0968 rate:0.0000 rateProb:0.5000 gloss:0.0033 dloss:1.3866 dlossR:0.6947 dlossQ:0.6919\n",
      "Episode:62 meanR:-0.0952 rate:0.0000 rateProb:0.5000 gloss:0.0018 dloss:1.3868 dlossR:0.6939 dlossQ:0.6929\n",
      "Episode:63 meanR:-0.0938 rate:0.0000 rateProb:0.5000 gloss:0.0023 dloss:1.3867 dlossR:0.6939 dlossQ:0.6929\n",
      "Episode:64 meanR:-0.0923 rate:0.0000 rateProb:0.5000 gloss:-0.0023 dloss:1.3864 dlossR:0.6935 dlossQ:0.6930\n",
      "Episode:65 meanR:-0.0909 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3865 dlossR:0.6933 dlossQ:0.6932\n",
      "Episode:66 meanR:-0.0746 rate:0.0769 rateProb:0.5385 gloss:-0.0002 dloss:1.3868 dlossR:0.6936 dlossQ:0.6932\n",
      "Episode:67 meanR:-0.0735 rate:0.0000 rateProb:0.5000 gloss:0.0013 dloss:1.3865 dlossR:0.6936 dlossQ:0.6929\n",
      "Episode:68 meanR:-0.0725 rate:0.0000 rateProb:0.5000 gloss:0.0014 dloss:1.3864 dlossR:0.6936 dlossQ:0.6929\n",
      "Episode:69 meanR:-0.0714 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3865 dlossR:0.6933 dlossQ:0.6932\n",
      "Episode:70 meanR:-0.0704 rate:0.0000 rateProb:0.5000 gloss:0.0009 dloss:1.3866 dlossR:0.6934 dlossQ:0.6933\n",
      "Episode:71 meanR:-0.0694 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3864 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:72 meanR:-0.0685 rate:0.0000 rateProb:0.5000 gloss:-0.0009 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:73 meanR:-0.0541 rate:0.0769 rateProb:0.5385 gloss:-0.0003 dloss:1.3869 dlossR:0.6936 dlossQ:0.6932\n",
      "Episode:74 meanR:-0.0533 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3866 dlossR:0.6933 dlossQ:0.6933\n",
      "Episode:75 meanR:-0.0526 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:76 meanR:-0.0519 rate:0.0000 rateProb:0.5000 gloss:0.0014 dloss:1.3864 dlossR:0.6935 dlossQ:0.6928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:77 meanR:-0.0385 rate:0.0769 rateProb:0.5385 gloss:0.0018 dloss:1.3846 dlossR:0.6917 dlossQ:0.6930\n",
      "Episode:78 meanR:-0.0380 rate:0.0000 rateProb:0.5000 gloss:0.0027 dloss:1.3864 dlossR:0.6939 dlossQ:0.6925\n",
      "Episode:79 meanR:-0.0375 rate:0.0000 rateProb:0.5000 gloss:0.0028 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:80 meanR:-0.0370 rate:0.0000 rateProb:0.5000 gloss:0.0013 dloss:1.3865 dlossR:0.6935 dlossQ:0.6930\n",
      "Episode:81 meanR:-0.0366 rate:0.0000 rateProb:0.5000 gloss:0.0010 dloss:1.3864 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:82 meanR:-0.0361 rate:0.0000 rateProb:0.5000 gloss:0.0008 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:83 meanR:-0.0476 rate:-0.0769 rateProb:0.4615 gloss:-0.0006 dloss:1.3856 dlossR:0.6926 dlossQ:0.6930\n",
      "Episode:84 meanR:-0.0471 rate:0.0000 rateProb:0.5000 gloss:-0.0021 dloss:1.3864 dlossR:0.6945 dlossQ:0.6920\n",
      "Episode:85 meanR:-0.0465 rate:0.0000 rateProb:0.5000 gloss:-0.0034 dloss:1.3865 dlossR:0.6953 dlossQ:0.6912\n",
      "Episode:86 meanR:-0.0460 rate:0.0000 rateProb:0.5000 gloss:-0.0018 dloss:1.3864 dlossR:0.6941 dlossQ:0.6922\n",
      "Episode:87 meanR:-0.0455 rate:0.0000 rateProb:0.5000 gloss:-0.0013 dloss:1.3864 dlossR:0.6938 dlossQ:0.6926\n",
      "Episode:88 meanR:-0.0449 rate:0.0000 rateProb:0.5000 gloss:-0.0011 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:89 meanR:-0.0444 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:90 meanR:-0.0440 rate:0.0000 rateProb:0.5000 gloss:0.0017 dloss:1.3864 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:91 meanR:-0.0435 rate:0.0000 rateProb:0.5000 gloss:0.0019 dloss:1.3864 dlossR:0.6939 dlossQ:0.6925\n",
      "Episode:92 meanR:-0.0430 rate:0.0000 rateProb:0.5000 gloss:0.0024 dloss:1.3865 dlossR:0.6941 dlossQ:0.6924\n",
      "Episode:93 meanR:-0.0426 rate:0.0000 rateProb:0.5000 gloss:0.0013 dloss:1.3864 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:94 meanR:-0.0421 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3864 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:95 meanR:-0.0417 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:96 meanR:-0.0412 rate:0.0000 rateProb:0.5000 gloss:-0.0008 dloss:1.3865 dlossR:0.6933 dlossQ:0.6932\n",
      "Episode:97 meanR:-0.0408 rate:0.0000 rateProb:0.5000 gloss:-0.0011 dloss:1.3864 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:98 meanR:-0.0404 rate:0.0000 rateProb:0.5000 gloss:-0.0016 dloss:1.3865 dlossR:0.6937 dlossQ:0.6928\n",
      "Episode:99 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0013 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:100 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:101 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:102 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:103 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0009 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:104 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:105 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3864 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:106 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3864 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:107 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:108 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:109 meanR:-0.0100 rate:-0.0769 rateProb:0.4615 gloss:-0.0002 dloss:1.3863 dlossR:0.6931 dlossQ:0.6932\n",
      "Episode:110 meanR:0.0000 rate:0.0769 rateProb:0.5385 gloss:-0.0013 dloss:1.3885 dlossR:0.6956 dlossQ:0.6929\n",
      "Episode:111 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:112 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:113 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:114 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:115 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0010 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:116 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0008 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:117 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0013 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:118 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:119 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:120 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:121 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:122 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:123 meanR:0.0100 rate:0.0769 rateProb:0.5385 gloss:-0.0008 dloss:1.3878 dlossR:0.6948 dlossQ:0.6930\n",
      "Episode:124 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:125 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0008 dloss:1.3864 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:126 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0017 dloss:1.3863 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:127 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0016 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:128 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0011 dloss:1.3864 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:129 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0009 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:130 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:131 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:132 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:133 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:134 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0010 dloss:1.3864 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:135 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0013 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:136 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:137 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:138 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:139 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0008 dloss:1.3845 dlossR:0.6917 dlossQ:0.6929\n",
      "Episode:140 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0011 dloss:1.3863 dlossR:0.6942 dlossQ:0.6922\n",
      "Episode:141 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0014 dloss:1.3864 dlossR:0.6943 dlossQ:0.6921\n",
      "Episode:142 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0013 dloss:1.3864 dlossR:0.6941 dlossQ:0.6923\n",
      "Episode:143 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0010 dloss:1.3843 dlossR:0.6915 dlossQ:0.6928\n",
      "Episode:144 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0011 dloss:1.3865 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:145 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:146 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:147 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:148 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0009 dloss:1.3863 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:149 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:150 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0006 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:151 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3864 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:152 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:153 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:154 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:155 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:156 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:157 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3864 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:158 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:159 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:160 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:161 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:162 meanR:0.0600 rate:0.0769 rateProb:0.5385 gloss:-0.0005 dloss:1.3871 dlossR:0.6940 dlossQ:0.6932\n",
      "Episode:163 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:164 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3863 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:165 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0009 dloss:1.3864 dlossR:0.6938 dlossQ:0.6926\n",
      "Episode:166 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0011 dloss:1.3863 dlossR:0.6938 dlossQ:0.6926\n",
      "Episode:167 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0008 dloss:1.3863 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:168 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:169 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:170 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:171 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:172 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:173 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:174 meanR:0.0300 rate:-0.0769 rateProb:0.4615 gloss:-0.0003 dloss:1.3851 dlossR:0.6920 dlossQ:0.6931\n",
      "Episode:175 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:176 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:177 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:178 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:179 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:180 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:181 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:182 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:183 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:184 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:185 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:186 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:187 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:188 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:189 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:190 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:191 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:-0.0003 dloss:1.3874 dlossR:0.6942 dlossQ:0.6932\n",
      "Episode:192 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:193 meanR:0.0500 rate:0.0769 rateProb:0.5385 gloss:0.0007 dloss:1.3842 dlossR:0.6915 dlossQ:0.6927\n",
      "Episode:194 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0011 dloss:1.3864 dlossR:0.6947 dlossQ:0.6916\n",
      "Episode:195 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0013 dloss:1.3864 dlossR:0.6955 dlossQ:0.6908\n",
      "Episode:196 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0012 dloss:1.3864 dlossR:0.6952 dlossQ:0.6912\n",
      "Episode:197 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0012 dloss:1.3864 dlossR:0.6942 dlossQ:0.6922\n",
      "Episode:198 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:199 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3864 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:200 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:201 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0010 dloss:1.3864 dlossR:0.6944 dlossQ:0.6920\n",
      "Episode:202 meanR:0.0600 rate:0.0769 rateProb:0.5385 gloss:-0.0009 dloss:1.3904 dlossR:0.6984 dlossQ:0.6920\n",
      "Episode:203 meanR:0.0500 rate:-0.0769 rateProb:0.4615 gloss:-0.0005 dloss:1.3847 dlossR:0.6918 dlossQ:0.6929\n",
      "Episode:204 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:205 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:206 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:207 meanR:0.0600 rate:0.0769 rateProb:0.5385 gloss:0.0003 dloss:1.3855 dlossR:0.6924 dlossQ:0.6931\n",
      "Episode:208 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3863 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:209 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3863 dlossR:0.6943 dlossQ:0.6920\n",
      "Episode:210 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0008 dloss:1.3864 dlossR:0.6941 dlossQ:0.6923\n",
      "Episode:211 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:212 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:213 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:214 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:215 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:216 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:217 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:218 meanR:0.0500 rate:-0.0769 rateProb:0.4615 gloss:-0.0004 dloss:1.3845 dlossR:0.6917 dlossQ:0.6929\n",
      "Episode:219 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:220 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3864 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:221 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:222 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:223 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:224 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:225 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:226 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3864 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:227 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3864 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:228 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:229 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:230 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:231 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:232 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:233 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:234 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:235 meanR:0.0500 rate:0.0769 rateProb:0.5385 gloss:-0.0002 dloss:1.3876 dlossR:0.6945 dlossQ:0.6931\n",
      "Episode:236 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:237 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:238 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:239 meanR:0.0300 rate:-0.0769 rateProb:0.4615 gloss:0.0004 dloss:1.3889 dlossR:0.6962 dlossQ:0.6927\n",
      "Episode:240 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:241 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:242 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:243 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3864 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:244 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3864 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:245 meanR:0.0400 rate:0.1538 rateProb:0.5769 gloss:-0.0006 dloss:1.3914 dlossR:0.6986 dlossQ:0.6927\n",
      "Episode:246 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:247 meanR:0.0300 rate:-0.0769 rateProb:0.4615 gloss:0.0003 dloss:1.3881 dlossR:0.6951 dlossQ:0.6930\n",
      "Episode:248 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:249 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:250 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:251 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:252 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0002 dloss:1.3854 dlossR:0.6923 dlossQ:0.6931\n",
      "Episode:253 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:254 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3864 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:255 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:256 meanR:0.0300 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3871 dlossR:0.6939 dlossQ:0.6932\n",
      "Episode:257 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:258 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3864 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:259 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0006 dloss:1.3864 dlossR:0.6938 dlossQ:0.6926\n",
      "Episode:260 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0006 dloss:1.3865 dlossR:0.6937 dlossQ:0.6928\n",
      "Episode:261 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:262 meanR:0.0100 rate:-0.0769 rateProb:0.4615 gloss:-0.0003 dloss:1.3850 dlossR:0.6920 dlossQ:0.6930\n",
      "Episode:263 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3864 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:264 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:265 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3864 dlossR:0.6934 dlossQ:0.6931\n",
      "Episode:266 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:267 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:268 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:269 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:270 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:271 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:272 meanR:0.0200 rate:0.0769 rateProb:0.5385 gloss:0.0003 dloss:1.3853 dlossR:0.6923 dlossQ:0.6930\n",
      "Episode:273 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:274 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3863 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:275 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:276 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:277 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:278 meanR:0.0200 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3870 dlossR:0.6939 dlossQ:0.6931\n",
      "Episode:279 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:280 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:281 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0006 dloss:1.3863 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:282 meanR:0.0300 rate:0.0769 rateProb:0.5385 gloss:-0.0005 dloss:1.3894 dlossR:0.6970 dlossQ:0.6924\n",
      "Episode:283 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:284 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:285 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:286 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:287 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:288 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3864 dlossR:0.6935 dlossQ:0.6929\n",
      "Episode:289 meanR:0.0200 rate:-0.0769 rateProb:0.4615 gloss:0.0004 dloss:1.3891 dlossR:0.6964 dlossQ:0.6926\n",
      "Episode:290 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:291 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:292 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:293 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:294 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:295 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:296 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:297 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:298 meanR:-0.0100 rate:-0.0769 rateProb:0.4615 gloss:-0.0003 dloss:1.3849 dlossR:0.6919 dlossQ:0.6930\n",
      "Episode:299 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3864 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:300 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:301 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:302 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:303 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:304 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:305 meanR:-0.0200 rate:-0.0769 rateProb:0.4615 gloss:0.0000 dloss:1.3865 dlossR:0.6934 dlossQ:0.6931\n",
      "Episode:306 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:307 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:308 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:309 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:310 meanR:-0.0400 rate:-0.0769 rateProb:0.4615 gloss:-0.0001 dloss:1.3859 dlossR:0.6928 dlossQ:0.6931\n",
      "Episode:311 meanR:-0.0300 rate:0.0769 rateProb:0.5385 gloss:-0.0002 dloss:1.3876 dlossR:0.6946 dlossQ:0.6930\n",
      "Episode:312 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:313 meanR:-0.0200 rate:0.0769 rateProb:0.5385 gloss:-0.0002 dloss:1.3870 dlossR:0.6939 dlossQ:0.6931\n",
      "Episode:314 meanR:-0.0300 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3862 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:315 meanR:-0.0400 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:316 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:317 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:318 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:319 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:320 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:321 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:322 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:323 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:324 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:325 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:326 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:327 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:328 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:329 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:330 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:331 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:332 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:333 meanR:-0.0200 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3862 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:334 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:335 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:336 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:337 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:338 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:339 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:340 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:341 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:342 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:343 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:344 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:345 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:346 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:347 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:348 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:349 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:350 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:351 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:352 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:353 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:354 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:355 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:356 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:357 meanR:-0.0400 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3869 dlossR:0.6937 dlossQ:0.6931\n",
      "Episode:358 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:359 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:360 meanR:-0.0500 rate:-0.0769 rateProb:0.4615 gloss:-0.0003 dloss:1.3853 dlossR:0.6922 dlossQ:0.6931\n",
      "Episode:361 meanR:-0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:362 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3863 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:363 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0008 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:364 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0008 dloss:1.3863 dlossR:0.6940 dlossQ:0.6924\n",
      "Episode:365 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0007 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:366 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0005 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:367 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0006 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:368 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:369 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:370 meanR:-0.0500 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3868 dlossR:0.6937 dlossQ:0.6931\n",
      "Episode:371 meanR:-0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:372 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:373 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:374 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:375 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:376 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:377 meanR:-0.0500 rate:0.0769 rateProb:0.5385 gloss:-0.0000 dloss:1.3866 dlossR:0.6934 dlossQ:0.6932\n",
      "Episode:378 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:379 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:380 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:381 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:382 meanR:-0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0006 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:383 meanR:-0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0006 dloss:1.3850 dlossR:0.6920 dlossQ:0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:384 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:385 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0008 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:386 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0009 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:387 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:388 meanR:-0.0500 rate:-0.0769 rateProb:0.4615 gloss:0.0007 dloss:1.3878 dlossR:0.6948 dlossQ:0.6930\n",
      "Episode:389 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:390 meanR:-0.0300 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:391 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:392 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:393 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:394 meanR:-0.0200 rate:0.0769 rateProb:0.5385 gloss:-0.0001 dloss:1.3869 dlossR:0.6938 dlossQ:0.6931\n",
      "Episode:395 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:396 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:397 meanR:-0.0300 rate:-0.0769 rateProb:0.4615 gloss:0.0003 dloss:1.3871 dlossR:0.6940 dlossQ:0.6931\n",
      "Episode:398 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:399 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:400 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:401 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:402 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:403 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:404 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:405 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:406 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:407 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:408 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:409 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:410 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:411 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:412 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:413 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:414 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:415 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:416 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:417 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:418 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:419 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:420 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:421 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:422 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:423 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:424 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:425 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:426 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:427 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:428 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:429 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:430 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:431 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:432 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:433 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:434 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:435 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:436 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:437 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:438 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:439 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6932\n",
      "Episode:440 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:441 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:442 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:443 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:444 meanR:-0.0200 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:445 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:446 meanR:-0.0100 rate:0.0769 rateProb:0.5385 gloss:-0.0003 dloss:1.3873 dlossR:0.6942 dlossQ:0.6931\n",
      "Episode:447 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:448 meanR:0.0000 rate:0.0769 rateProb:0.5385 gloss:-0.0002 dloss:1.3870 dlossR:0.6939 dlossQ:0.6931\n",
      "Episode:449 meanR:-0.0100 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:450 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:451 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:452 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:453 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:454 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:455 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:456 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:457 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:458 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:459 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:460 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:461 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:462 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:463 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:464 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:465 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:466 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:467 meanR:0.0000 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3865 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:468 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:469 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:470 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:471 meanR:0.0200 rate:0.0769 rateProb:0.5385 gloss:-0.0003 dloss:1.3875 dlossR:0.6945 dlossQ:0.6931\n",
      "Episode:472 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:473 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:474 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:475 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:476 meanR:0.0100 rate:-0.0769 rateProb:0.4615 gloss:0.0003 dloss:1.3873 dlossR:0.6943 dlossQ:0.6931\n",
      "Episode:477 meanR:0.0100 rate:0.0769 rateProb:0.5385 gloss:0.0004 dloss:1.3853 dlossR:0.6923 dlossQ:0.6931\n",
      "Episode:478 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:479 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:480 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:481 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:482 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:483 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:484 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:485 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3864 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:486 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:487 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:488 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:489 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:490 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:491 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:492 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:493 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:494 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3864 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:495 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:496 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:497 meanR:0.0000 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:498 meanR:0.0100 rate:0.0769 rateProb:0.5385 gloss:0.0001 dloss:1.3862 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:499 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:500 meanR:0.0200 rate:0.0769 rateProb:0.5385 gloss:0.0003 dloss:1.3854 dlossR:0.6923 dlossQ:0.6931\n",
      "Episode:501 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:502 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0005 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:503 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3863 dlossR:0.6939 dlossQ:0.6924\n",
      "Episode:504 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0007 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:505 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:506 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:507 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:508 meanR:0.0300 rate:0.0769 rateProb:0.5385 gloss:0.0003 dloss:1.3850 dlossR:0.6920 dlossQ:0.6930\n",
      "Episode:509 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:510 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:511 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:512 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3862 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:513 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:514 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:515 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0004 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:516 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:517 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:518 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:519 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:520 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:521 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:522 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:523 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:524 meanR:0.0500 rate:0.0769 rateProb:0.5385 gloss:-0.0001 dloss:1.3868 dlossR:0.6936 dlossQ:0.6931\n",
      "Episode:525 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:526 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:527 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:528 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:529 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:530 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:531 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:532 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:533 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:534 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:535 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:536 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:537 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:538 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:539 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:540 meanR:0.0700 rate:0.1538 rateProb:0.5769 gloss:-0.0000 dloss:1.3873 dlossR:0.6941 dlossQ:0.6932\n",
      "Episode:541 meanR:0.0600 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3871 dlossR:0.6940 dlossQ:0.6931\n",
      "Episode:542 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:543 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:544 meanR:0.0600 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3880 dlossR:0.6950 dlossQ:0.6930\n",
      "Episode:545 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:546 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:547 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:548 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:549 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:550 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:551 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:552 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:553 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:554 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:555 meanR:0.0600 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3862 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:556 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:557 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:558 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:559 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:560 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:561 meanR:0.0700 rate:0.0769 rateProb:0.5385 gloss:0.0002 dloss:1.3843 dlossR:0.6915 dlossQ:0.6928\n",
      "Episode:562 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:563 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:564 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:565 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:566 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:567 meanR:0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:568 meanR:0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:569 meanR:0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:570 meanR:0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:571 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:572 meanR:0.0800 rate:0.0769 rateProb:0.5385 gloss:-0.0001 dloss:1.3877 dlossR:0.6947 dlossQ:0.6930\n",
      "Episode:573 meanR:0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:574 meanR:0.0700 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3860 dlossR:0.6929 dlossQ:0.6931\n",
      "Episode:575 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:576 meanR:0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:577 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:578 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:579 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:580 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:581 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:582 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:583 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:584 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:585 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:586 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:587 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:588 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:589 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:590 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:591 meanR:0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:592 meanR:0.0600 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3865 dlossR:0.6933 dlossQ:0.6932\n",
      "Episode:593 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:594 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:595 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:596 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:597 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:598 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:599 meanR:0.0600 rate:0.0769 rateProb:0.5385 gloss:-0.0001 dloss:1.3872 dlossR:0.6941 dlossQ:0.6931\n",
      "Episode:600 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:601 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:602 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:603 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:604 meanR:0.0600 rate:0.0769 rateProb:0.5385 gloss:0.0002 dloss:1.3840 dlossR:0.6913 dlossQ:0.6927\n",
      "Episode:605 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:606 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6939 dlossQ:0.6924\n",
      "Episode:607 meanR:0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0003 dloss:1.3863 dlossR:0.6939 dlossQ:0.6925\n",
      "Episode:608 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6938 dlossQ:0.6925\n",
      "Episode:609 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:610 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:611 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:612 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:613 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:614 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:615 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:616 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:617 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:618 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:619 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:620 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:621 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:622 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:623 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:624 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:625 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:626 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:627 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:628 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:629 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:630 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:631 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:632 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:633 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6932\n",
      "Episode:634 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:635 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:636 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:637 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:638 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:639 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:640 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:641 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:642 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:643 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:644 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:645 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:646 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:647 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3861 dlossR:0.6929 dlossQ:0.6931\n",
      "Episode:648 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:649 meanR:0.0300 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3875 dlossR:0.6944 dlossQ:0.6931\n",
      "Episode:650 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:651 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:652 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3857 dlossR:0.6926 dlossQ:0.6931\n",
      "Episode:653 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:654 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:655 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:656 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:657 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:658 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:659 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:660 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:661 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:662 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:663 meanR:0.0300 rate:0.0769 rateProb:0.5385 gloss:-0.0000 dloss:1.3868 dlossR:0.6936 dlossQ:0.6931\n",
      "Episode:664 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:665 meanR:0.0200 rate:-0.0769 rateProb:0.4615 gloss:0.0000 dloss:1.3872 dlossR:0.6941 dlossQ:0.6931\n",
      "Episode:666 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:667 meanR:0.0100 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3861 dlossR:0.6930 dlossQ:0.6931\n",
      "Episode:668 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:669 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:670 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:671 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:672 meanR:0.0100 rate:0.0769 rateProb:0.5385 gloss:-0.0002 dloss:1.3882 dlossR:0.6953 dlossQ:0.6929\n",
      "Episode:673 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:674 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:675 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:676 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:677 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:678 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:679 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:680 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:681 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:682 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:683 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:684 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:685 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:686 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:687 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:688 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:689 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:690 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:691 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:692 meanR:0.0200 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3857 dlossR:0.6926 dlossQ:0.6931\n",
      "Episode:693 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:694 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:695 meanR:0.0300 rate:0.0769 rateProb:0.5385 gloss:-0.0001 dloss:1.3879 dlossR:0.6949 dlossQ:0.6930\n",
      "Episode:696 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:697 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:698 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:699 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:700 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:701 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:702 meanR:0.0300 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3851 dlossR:0.6921 dlossQ:0.6930\n",
      "Episode:703 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:0.0002 dloss:1.3846 dlossR:0.6917 dlossQ:0.6929\n",
      "Episode:704 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:705 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6938 dlossQ:0.6925\n",
      "Episode:706 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6940 dlossQ:0.6923\n",
      "Episode:707 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6940 dlossQ:0.6924\n",
      "Episode:708 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6939 dlossQ:0.6924\n",
      "Episode:709 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:710 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:711 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:712 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:713 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6932\n",
      "Episode:714 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:715 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:716 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:717 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:718 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:719 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:720 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6930\n",
      "Episode:721 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:722 meanR:0.0400 rate:0.0769 rateProb:0.5385 gloss:-0.0000 dloss:1.3873 dlossR:0.6942 dlossQ:0.6931\n",
      "Episode:723 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:724 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:725 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:726 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:727 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:728 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:729 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:730 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:731 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:732 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:733 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:734 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:735 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:736 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:737 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:738 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:739 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:740 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:741 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6931\n",
      "Episode:742 meanR:0.0500 rate:0.0769 rateProb:0.5385 gloss:-0.0000 dloss:1.3872 dlossR:0.6941 dlossQ:0.6931\n",
      "Episode:743 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:744 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:745 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:746 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:747 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:748 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:749 meanR:0.0500 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:750 meanR:0.0400 rate:-0.0769 rateProb:0.4615 gloss:0.0000 dloss:1.3876 dlossR:0.6946 dlossQ:0.6930\n",
      "Episode:751 meanR:0.0400 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:752 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:753 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:754 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:755 meanR:0.0200 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3855 dlossR:0.6924 dlossQ:0.6931\n",
      "Episode:756 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:757 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:758 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6936 dlossQ:0.6928\n",
      "Episode:759 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:760 meanR:0.0300 rate:0.0769 rateProb:0.5385 gloss:-0.0001 dloss:1.3884 dlossR:0.6956 dlossQ:0.6928\n",
      "Episode:761 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:762 meanR:0.0200 rate:-0.0769 rateProb:0.4615 gloss:-0.0001 dloss:1.3850 dlossR:0.6920 dlossQ:0.6930\n",
      "Episode:763 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:764 meanR:0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:765 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:766 meanR:0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:767 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:768 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:769 meanR:0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:770 meanR:0.0200 rate:-0.0769 rateProb:0.4615 gloss:0.0000 dloss:1.3868 dlossR:0.6937 dlossQ:0.6931\n",
      "Episode:771 meanR:0.0000 rate:-0.1538 rateProb:0.4231 gloss:0.0000 dloss:1.3870 dlossR:0.6939 dlossQ:0.6932\n",
      "Episode:772 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:773 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:774 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:775 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:776 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:777 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:778 meanR:-0.0200 rate:-0.0769 rateProb:0.4615 gloss:-0.0001 dloss:1.3840 dlossR:0.6913 dlossQ:0.6927\n",
      "Episode:779 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6938 dlossQ:0.6926\n",
      "Episode:780 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6938 dlossQ:0.6925\n",
      "Episode:781 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6937 dlossQ:0.6927\n",
      "Episode:782 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:783 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:784 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:785 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:786 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:787 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:788 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:789 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:790 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:791 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:792 meanR:-0.0200 rate:-0.0769 rateProb:0.4615 gloss:0.0000 dloss:1.3879 dlossR:0.6949 dlossQ:0.6930\n",
      "Episode:793 meanR:-0.0100 rate:0.0769 rateProb:0.5385 gloss:0.0001 dloss:1.3854 dlossR:0.6923 dlossQ:0.6931\n",
      "Episode:794 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:795 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:796 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:797 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:798 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:799 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:800 meanR:-0.0100 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3862 dlossR:0.6930 dlossQ:0.6931\n",
      "Episode:801 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:802 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:803 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:804 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:805 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:806 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:807 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:808 meanR:-0.0200 rate:0.0769 rateProb:0.5385 gloss:0.0000 dloss:1.3858 dlossR:0.6927 dlossQ:0.6931\n",
      "Episode:809 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:810 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:811 meanR:-0.0100 rate:0.0769 rateProb:0.5385 gloss:0.0001 dloss:1.3853 dlossR:0.6923 dlossQ:0.6931\n",
      "Episode:812 meanR:-0.0100 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:813 meanR:-0.0200 rate:-0.0769 rateProb:0.4615 gloss:0.0000 dloss:1.3879 dlossR:0.6950 dlossQ:0.6930\n",
      "Episode:814 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:815 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:816 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:817 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:818 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:819 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:820 meanR:-0.0200 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:821 meanR:-0.0300 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3862 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:822 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:823 meanR:-0.0500 rate:-0.0769 rateProb:0.4615 gloss:-0.0001 dloss:1.3852 dlossR:0.6922 dlossQ:0.6930\n",
      "Episode:824 meanR:-0.0500 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:825 meanR:-0.0600 rate:-0.0769 rateProb:0.4615 gloss:-0.0002 dloss:1.3842 dlossR:0.6914 dlossQ:0.6928\n",
      "Episode:826 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6938 dlossQ:0.6925\n",
      "Episode:827 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6940 dlossQ:0.6923\n",
      "Episode:828 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6941 dlossQ:0.6922\n",
      "Episode:829 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6940 dlossQ:0.6923\n",
      "Episode:830 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6939 dlossQ:0.6924\n",
      "Episode:831 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6938 dlossQ:0.6925\n",
      "Episode:832 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6936 dlossQ:0.6927\n",
      "Episode:833 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:834 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:835 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:836 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:837 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:838 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:839 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:840 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:841 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:842 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:843 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:844 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:845 meanR:-0.0800 rate:-0.0769 rateProb:0.4615 gloss:0.0001 dloss:1.3877 dlossR:0.6947 dlossQ:0.6930\n",
      "Episode:846 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:847 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:848 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:849 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:850 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:851 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:852 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:853 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:854 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:855 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:856 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:857 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:858 meanR:-0.0800 rate:-0.1538 rateProb:0.4231 gloss:-0.0001 dloss:1.3845 dlossR:0.6914 dlossQ:0.6931\n",
      "Episode:859 meanR:-0.0900 rate:-0.0769 rateProb:0.4615 gloss:-0.0001 dloss:1.3850 dlossR:0.6920 dlossQ:0.6930\n",
      "Episode:860 meanR:-0.1000 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6934 dlossQ:0.6929\n",
      "Episode:861 meanR:-0.1100 rate:-0.0769 rateProb:0.4615 gloss:-0.0002 dloss:1.3840 dlossR:0.6913 dlossQ:0.6927\n",
      "Episode:862 meanR:-0.1000 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6938 dlossQ:0.6925\n",
      "Episode:863 meanR:-0.1100 rate:-0.0769 rateProb:0.4615 gloss:-0.0002 dloss:1.3835 dlossR:0.6910 dlossQ:0.6925\n",
      "Episode:864 meanR:-0.1100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3863 dlossR:0.6943 dlossQ:0.6920\n",
      "Episode:865 meanR:-0.1100 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3864 dlossR:0.6946 dlossQ:0.6918\n",
      "Episode:866 meanR:-0.1100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3864 dlossR:0.6947 dlossQ:0.6917\n",
      "Episode:867 meanR:-0.1100 rate:0.0000 rateProb:0.5000 gloss:-0.0003 dloss:1.3864 dlossR:0.6943 dlossQ:0.6920\n",
      "Episode:868 meanR:-0.1100 rate:0.0000 rateProb:0.5000 gloss:-0.0004 dloss:1.3864 dlossR:0.6941 dlossQ:0.6923\n",
      "Episode:869 meanR:-0.1100 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6939 dlossQ:0.6924\n",
      "Episode:870 meanR:-0.1000 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6937 dlossQ:0.6926\n",
      "Episode:871 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6935 dlossQ:0.6928\n",
      "Episode:872 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:873 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:874 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:875 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:876 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:877 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:878 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:879 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:880 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:881 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:882 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6933 dlossQ:0.6930\n",
      "Episode:883 meanR:-0.0800 rate:-0.0769 rateProb:0.4615 gloss:0.0002 dloss:1.3877 dlossR:0.6947 dlossQ:0.6930\n",
      "Episode:884 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:885 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:886 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:887 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:888 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:889 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:890 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:891 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:892 meanR:-0.0600 rate:0.0769 rateProb:0.5385 gloss:-0.0000 dloss:1.3868 dlossR:0.6936 dlossQ:0.6931\n",
      "Episode:893 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:894 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:895 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:896 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:897 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:898 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:899 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:900 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:901 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:902 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:903 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:904 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:905 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:906 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:907 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:908 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:909 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:910 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:911 meanR:-0.1000 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:912 meanR:-0.1000 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:913 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:914 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6932\n",
      "Episode:915 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:916 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:917 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:918 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:919 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:920 meanR:-0.0900 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:921 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:922 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6932\n",
      "Episode:923 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:924 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:925 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:926 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:927 meanR:-0.0700 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3862 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:928 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:929 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:930 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:931 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:932 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:933 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:934 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:935 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:936 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:937 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:938 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:939 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:940 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:941 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:942 meanR:-0.0800 rate:-0.0769 rateProb:0.4615 gloss:-0.0001 dloss:1.3859 dlossR:0.6928 dlossQ:0.6931\n",
      "Episode:943 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:944 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:945 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:946 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:947 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:948 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:949 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:950 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:951 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:952 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:953 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:954 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:955 meanR:-0.0700 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:956 meanR:-0.0800 rate:-0.0769 rateProb:0.4615 gloss:-0.0000 dloss:1.3863 dlossR:0.6931 dlossQ:0.6931\n",
      "Episode:957 meanR:-0.0800 rate:0.0000 rateProb:0.5000 gloss:-0.0000 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:958 meanR:-0.0600 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:959 meanR:-0.0400 rate:0.0769 rateProb:0.5385 gloss:-0.0001 dloss:1.3868 dlossR:0.6937 dlossQ:0.6931\n",
      "Episode:960 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:961 meanR:-0.0400 rate:-0.0769 rateProb:0.4615 gloss:-0.0001 dloss:1.3862 dlossR:0.6930 dlossQ:0.6931\n",
      "Episode:962 meanR:-0.0400 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:963 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0002 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:964 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:965 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n",
      "Episode:966 meanR:-0.0300 rate:0.0000 rateProb:0.5000 gloss:-0.0001 dloss:1.3863 dlossR:0.6932 dlossQ:0.6931\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "episodes_total_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "saver = tf.train.Saver()\n",
    "rewards_list, g_loss_list, d_loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(111111):\n",
    "        batch = [] # every data batch\n",
    "        total_reward = 0\n",
    "        #state = env.reset() # env first state\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            state = env_info.vector_observations[0]   # get the next state\n",
    "            action_logits, Q_logits = sess.run(fetches=[model.actions_logits, model.Qs_logits], \n",
    "                                               feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            #state, reward, done, _ = env.step(action)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            batch.append([state, action, Q_logits, reward])\n",
    "            total_reward += reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            if done is True: # episode ended success/failure\n",
    "                episodes_total_reward.append(total_reward) # stopping criteria\n",
    "                #rate = total_reward/ 500 # success is 500 points, rate is between 0 and +1 ~ sigmoid\n",
    "                rate = total_reward/ +13 # success is +13; rate is between -1 and +1 ~ tanh\n",
    "                if rate >= +1: rate = +1\n",
    "                if rate <= -1: rate = -1\n",
    "                # min -13, max +13\n",
    "                # min -1, max +1\n",
    "                #reward = x-(-13)/ 26 # 0-1\n",
    "                #prob_rate = (rate - (-1))/ (1-(-1))\n",
    "                #prob_rate = (rate - rate_min)/ (rate_max-rate_min)\n",
    "                rate_prob = (rate + 1)/2 # success rate 0-1\n",
    "                break\n",
    "\n",
    "        # Training using batches\n",
    "        #batch = memory.buffer\n",
    "        states = np.array([each[0] for each in batch])\n",
    "        actions = np.array([each[1] for each in batch])\n",
    "        targetQs = np.array([each[2] for each in batch])\n",
    "        rewards = np.array([each[3] for each in batch])\n",
    "        g_loss, d_loss, d_lossR, d_lossQ, _, _ = sess.run([model.g_loss, model.d_loss, \n",
    "                                                           model.d_lossR, model.d_lossQ, \n",
    "                                                           model.g_opt, model.d_opt],\n",
    "                                                          feed_dict = {model.states: states, \n",
    "                                                                       model.actions: actions,\n",
    "                                                                       model.targetQs: targetQs.reshape([-1]),\n",
    "                                                                       model.rewards: rewards, \n",
    "                                                                       model.rate: rate_prob})\n",
    "        # Average 100 episode total reward\n",
    "        # Print out\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episodes_total_reward)),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'rateProb:{:.4f}'.format(rate_prob),\n",
    "              'gloss:{:.4f}'.format(g_loss),\n",
    "              'dloss:{:.4f}'.format(d_loss),\n",
    "              'dlossR:{:.4f}'.format(d_lossR),\n",
    "              'dlossQ:{:.4f}'.format(d_lossQ))\n",
    "        # Ploting out\n",
    "        rewards_list.append([ep, np.mean(episodes_total_reward)])\n",
    "        g_loss_list.append([ep, g_loss])\n",
    "        d_loss_list.append([ep, d_loss])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episodes_total_reward) >= +13:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model-nav.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import gym\n",
    "# # # env = gym.make('CartPole-v0')\n",
    "# # env = gym.make('CartPole-v1')\n",
    "# # # env = gym.make('Acrobot-v1')\n",
    "# # # env = gym.make('MountainCar-v0')\n",
    "# # # env = gym.make('Pendulum-v0')\n",
    "# # # env = gym.make('Blackjack-v0')\n",
    "# # # env = gym.make('FrozenLake-v0')\n",
    "# # # env = gym.make('AirRaid-ram-v0')\n",
    "# # # env = gym.make('AirRaid-v0')\n",
    "# # # env = gym.make('BipedalWalker-v2')\n",
    "# # # env = gym.make('Copy-v0')\n",
    "# # # env = gym.make('CarRacing-v0')\n",
    "# # # env = gym.make('Ant-v2') #mujoco\n",
    "# # # env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     #sess.run(tf.global_variables_initializer())\n",
    "#     saver.restore(sess, 'checkpoints/model-nav.ckpt')    \n",
    "#     #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "#     # Episodes/epochs\n",
    "#     for _ in range(1):\n",
    "#         state = env.reset()\n",
    "#         total_reward = 0\n",
    "\n",
    "#         # Steps/batches\n",
    "#         #for _ in range(111111111111111111):\n",
    "#         while True:\n",
    "#             env.render()\n",
    "#             action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "#             action = np.argmax(action_logits)\n",
    "#             state, reward, done, _ = env.step(action)\n",
    "#             total_reward += reward\n",
    "#             if done:\n",
    "#                 break\n",
    "                \n",
    "#         # Closing the env\n",
    "#         print('total_reward: {:.2f}'.format(total_reward))\n",
    "#         env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

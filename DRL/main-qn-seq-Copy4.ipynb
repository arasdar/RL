{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info: [ 0.02782733 -0.19801476  0.04266009  0.30762757] 0 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02386703 -0.00352583  0.04881264  0.02869784] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02379652  0.19086337  0.0493866  -0.24819343] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02761378 -0.00492783  0.04442273  0.05964904] 0 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02751523  0.18952997  0.04561571 -0.21869391] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.03130583  0.38397118  0.04124183 -0.49664596] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.03898525  0.57848806  0.03130891 -0.77605152] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.05055501  0.77316572  0.01578788 -1.05872159] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.06601833  0.968075   -0.00538655 -1.34640762] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.08537983  1.16326426 -0.0323147  -1.6407709 ] 1 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    labelQs = tf.placeholder(tf.float32, [None], name='labelQs')\n",
    "        \n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return actions, states, targetQs, labelQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs, labelQs):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    lossQtgt = tf.reduce_mean(tf.square(Qs - targetQs)) # next state, next action and nextQs\n",
    "    lossQlbl = tf.reduce_mean(tf.square(Qs - labelQs)) # current state, action, and currentQs\n",
    "    lossQtgt_sigm = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Qs, \n",
    "                                                                           labels=tf.nn.sigmoid(targetQs)))\n",
    "    lossQlbl_sigm = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Qs,\n",
    "                                                                           labels=tf.nn.sigmoid(labelQs)))\n",
    "    loss = lossQtgt + lossQlbl + lossQtgt_sigm + lossQlbl_sigm\n",
    "    return actions_logits, final_state, loss, lossQtgt, lossQlbl, lossQtgt_sigm, lossQlbl_sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.actions, self.states, self.targetQs, self.labelQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss, self.lossQtgt, self.lossQlbl, self.lossQtgt_sigm, self.lossQlbl_sigm = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, labelQs=self.labelQs, \n",
    "            cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_total_reward = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state:', np.array(states).shape[1], \n",
    "#       'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation\n",
    "batch_size = 32                # number of samples in the memory/ experience as mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.0297722 , -0.04377287,  0.04515347, -0.03944067]),\n",
       " 0,\n",
       " array([-0.03064765, -0.23951226,  0.04436466,  0.26713977]),\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states, rewards, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 meanReward: 10.0000 meanLoss: 2.3103 meanLossQlbl: 0.0153 meanLossQlbl_sigm: 0.6746 meanLossQtgt: 0.9949 meanLossQtgt_sigm: 0.6255\n",
      "Episode: 1 meanReward: 9.5000 meanLoss: 2.5527 meanLossQlbl: 0.4651 meanLossQlbl_sigm: 0.5507 meanLossQtgt: 1.0530 meanLossQtgt_sigm: 0.4838\n",
      "Episode: 2 meanReward: 14.0000 meanLoss: 5.0278 meanLossQlbl: 2.4131 meanLossQlbl_sigm: 0.4239 meanLossQtgt: 1.7648 meanLossQtgt_sigm: 0.4260\n",
      "Episode: 3 meanReward: 12.7500 meanLoss: 4.0847 meanLossQlbl: 1.7088 meanLossQlbl_sigm: 0.2778 meanLossQtgt: 1.8149 meanLossQtgt_sigm: 0.2832\n",
      "Episode: 4 meanReward: 14.0000 meanLoss: 4.6253 meanLossQlbl: 1.6886 meanLossQlbl_sigm: 0.3908 meanLossQtgt: 2.1612 meanLossQtgt_sigm: 0.3846\n",
      "Episode: 5 meanReward: 13.3333 meanLoss: 5.4610 meanLossQlbl: 2.1427 meanLossQlbl_sigm: 0.4434 meanLossQtgt: 2.4018 meanLossQtgt_sigm: 0.4731\n",
      "Episode: 6 meanReward: 17.0000 meanLoss: 4.9509 meanLossQlbl: 1.5487 meanLossQlbl_sigm: 0.2573 meanLossQtgt: 2.8808 meanLossQtgt_sigm: 0.2641\n",
      "Episode: 7 meanReward: 16.1250 meanLoss: 7.8355 meanLossQlbl: 0.8652 meanLossQlbl_sigm: 0.0113 meanLossQtgt: 6.8367 meanLossQtgt_sigm: 0.1222\n",
      "Episode: 8 meanReward: 15.3333 meanLoss: 12.5044 meanLossQlbl: 0.4032 meanLossQlbl_sigm: 0.0011 meanLossQtgt: 11.8595 meanLossQtgt_sigm: 0.2406\n",
      "Episode: 9 meanReward: 14.8000 meanLoss: 17.7818 meanLossQlbl: 0.1849 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.2328 meanLossQtgt_sigm: 0.3641\n",
      "Episode: 10 meanReward: 14.3636 meanLoss: 16.3511 meanLossQlbl: 0.0168 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9666 meanLossQtgt_sigm: 0.3677\n",
      "Episode: 11 meanReward: 13.9167 meanLoss: 14.1787 meanLossQlbl: 0.0853 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.7516 meanLossQtgt_sigm: 0.3418\n",
      "Episode: 12 meanReward: 14.0769 meanLoss: 12.8172 meanLossQlbl: 0.4969 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.0302 meanLossQtgt_sigm: 0.2900\n",
      "Episode: 13 meanReward: 14.0000 meanLoss: 12.8703 meanLossQlbl: 0.0884 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5016 meanLossQtgt_sigm: 0.2803\n",
      "Episode: 14 meanReward: 13.8667 meanLoss: 11.9832 meanLossQlbl: 0.0042 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.7232 meanLossQtgt_sigm: 0.2558\n",
      "Episode: 15 meanReward: 15.0625 meanLoss: 9.4376 meanLossQlbl: 0.1327 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.1135 meanLossQtgt_sigm: 0.1914\n",
      "Episode: 16 meanReward: 15.2353 meanLoss: 7.5568 meanLossQlbl: 0.0551 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.3693 meanLossQtgt_sigm: 0.1325\n",
      "Episode: 17 meanReward: 15.8333 meanLoss: 11.6746 meanLossQlbl: 0.0956 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.3759 meanLossQtgt_sigm: 0.2031\n",
      "Episode: 18 meanReward: 21.2105 meanLoss: 3.4131 meanLossQlbl: 0.0546 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.3137 meanLossQtgt_sigm: 0.0447\n",
      "Episode: 19 meanReward: 21.2500 meanLoss: 21.2402 meanLossQlbl: 0.2055 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.8099 meanLossQtgt_sigm: 0.2248\n",
      "Episode: 20 meanReward: 21.4286 meanLoss: 27.7040 meanLossQlbl: 0.3565 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.0498 meanLossQtgt_sigm: 0.2977\n",
      "Episode: 21 meanReward: 21.3636 meanLoss: 27.4402 meanLossQlbl: 0.7160 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.4376 meanLossQtgt_sigm: 0.2867\n",
      "Episode: 22 meanReward: 24.7826 meanLoss: 8.1944 meanLossQlbl: 0.2744 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.8338 meanLossQtgt_sigm: 0.0862\n",
      "Episode: 23 meanReward: 24.2917 meanLoss: 35.8542 meanLossQlbl: 0.0864 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.4679 meanLossQtgt_sigm: 0.2999\n",
      "Episode: 24 meanReward: 23.9600 meanLoss: 49.5287 meanLossQlbl: 1.6892 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 47.3740 meanLossQtgt_sigm: 0.4655\n",
      "Episode: 25 meanReward: 28.3846 meanLoss: 7.4797 meanLossQlbl: 0.2578 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.1491 meanLossQtgt_sigm: 0.0728\n",
      "Episode: 26 meanReward: 29.4815 meanLoss: 155.0566 meanLossQlbl: 77.2807 meanLossQlbl_sigm: 0.3547 meanLossQtgt: 77.0041 meanLossQtgt_sigm: 0.4171\n",
      "Episode: 27 meanReward: 30.1786 meanLoss: 312.2537 meanLossQlbl: 159.3016 meanLossQlbl_sigm: 0.5194 meanLossQtgt: 151.8773 meanLossQtgt_sigm: 0.5555\n",
      "Episode: 28 meanReward: 31.3103 meanLoss: 149.0692 meanLossQlbl: 79.1013 meanLossQlbl_sigm: 0.3939 meanLossQtgt: 69.1672 meanLossQtgt_sigm: 0.4067\n",
      "Episode: 29 meanReward: 31.3667 meanLoss: 354.9331 meanLossQlbl: 188.4335 meanLossQlbl_sigm: 0.6172 meanLossQtgt: 165.2292 meanLossQtgt_sigm: 0.6531\n",
      "Episode: 30 meanReward: 32.0000 meanLoss: 205.1032 meanLossQlbl: 108.8614 meanLossQlbl_sigm: 0.6292 meanLossQtgt: 94.9683 meanLossQtgt_sigm: 0.6443\n",
      "Episode: 31 meanReward: 32.7812 meanLoss: 386.9685 meanLossQlbl: 206.1592 meanLossQlbl_sigm: 0.6869 meanLossQtgt: 179.4338 meanLossQtgt_sigm: 0.6885\n",
      "Episode: 32 meanReward: 34.2500 meanLoss: 576.8875 meanLossQlbl: 307.7949 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 267.7063 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 33 meanReward: 36.1250 meanLoss: 574.4919 meanLossQlbl: 307.2584 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 265.8472 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 34 meanReward: 37.2500 meanLoss: 536.4017 meanLossQlbl: 287.3186 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 247.6969 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 35 meanReward: 38.5938 meanLoss: 523.4202 meanLossQlbl: 279.8384 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 242.1955 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 36 meanReward: 39.7188 meanLoss: 580.2056 meanLossQlbl: 309.5599 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 269.2594 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 37 meanReward: 41.1875 meanLoss: 587.7781 meanLossQlbl: 314.1956 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 272.1961 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 38 meanReward: 41.7188 meanLoss: 527.0193 meanLossQlbl: 282.8803 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 242.7527 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 39 meanReward: 42.5625 meanLoss: 460.0213 meanLossQlbl: 247.1327 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 211.5023 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 40 meanReward: 43.4375 meanLoss: 295.7777 meanLossQlbl: 156.5619 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 137.8295 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 41 meanReward: 44.3438 meanLoss: 300.8414 meanLossQlbl: 159.1966 meanLossQlbl_sigm: 0.6930 meanLossQtgt: 140.2577 meanLossQtgt_sigm: 0.6941\n",
      "Episode: 42 meanReward: 45.7188 meanLoss: 290.4327 meanLossQlbl: 155.6337 meanLossQlbl_sigm: 0.6929 meanLossQtgt: 133.4134 meanLossQtgt_sigm: 0.6927\n",
      "Episode: 43 meanReward: 46.8750 meanLoss: 338.8088 meanLossQlbl: 181.0413 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 156.3812 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 44 meanReward: 48.0000 meanLoss: 325.3978 meanLossQlbl: 173.3046 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 150.7070 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 45 meanReward: 49.1875 meanLoss: 409.7245 meanLossQlbl: 221.8041 meanLossQlbl_sigm: 0.6929 meanLossQtgt: 186.5332 meanLossQtgt_sigm: 0.6943\n",
      "Episode: 46 meanReward: 50.2188 meanLoss: 411.6870 meanLossQlbl: 220.0852 meanLossQlbl_sigm: 0.6796 meanLossQtgt: 190.2339 meanLossQtgt_sigm: 0.6883\n",
      "Episode: 47 meanReward: 50.6250 meanLoss: 590.4302 meanLossQlbl: 316.0619 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 272.9819 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 48 meanReward: 52.2500 meanLoss: 559.5798 meanLossQlbl: 299.6664 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 258.5270 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 49 meanReward: 53.7812 meanLoss: 650.4262 meanLossQlbl: 346.8364 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 302.2036 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 50 meanReward: 52.0000 meanLoss: 741.4402 meanLossQlbl: 395.1353 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 344.9187 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 51 meanReward: 53.1250 meanLoss: 756.5868 meanLossQlbl: 403.4249 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 351.7756 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 52 meanReward: 54.2812 meanLoss: 731.5789 meanLossQlbl: 389.9395 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 340.2531 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 53 meanReward: 55.4375 meanLoss: 770.4407 meanLossQlbl: 410.6671 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 358.3872 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 54 meanReward: 55.0000 meanLoss: 624.9839 meanLossQlbl: 334.3820 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 289.2156 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 55 meanReward: 56.9375 meanLoss: 574.0433 meanLossQlbl: 307.5802 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 265.0768 meanLossQtgt_sigm: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 56 meanReward: 58.0938 meanLoss: 632.5571 meanLossQlbl: 337.8204 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 293.3504 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 57 meanReward: 55.9062 meanLoss: 469.8569 meanLossQlbl: 253.3288 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 215.1418 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 58 meanReward: 55.8438 meanLoss: 484.6460 meanLossQlbl: 259.8382 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 223.4214 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 59 meanReward: 56.1562 meanLoss: 384.9443 meanLossQlbl: 208.2625 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 175.2955 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 60 meanReward: 55.6875 meanLoss: 278.4822 meanLossQlbl: 149.5078 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 127.5881 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 61 meanReward: 56.1250 meanLoss: 402.5965 meanLossQlbl: 215.0907 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 186.1194 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 62 meanReward: 56.2812 meanLoss: 504.1919 meanLossQlbl: 270.3630 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 232.4426 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 63 meanReward: 56.5000 meanLoss: 448.3781 meanLossQlbl: 241.7424 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 205.2494 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 64 meanReward: 56.4375 meanLoss: 469.5883 meanLossQlbl: 251.2525 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 216.9495 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 65 meanReward: 56.0938 meanLoss: 515.9482 meanLossQlbl: 277.2711 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 237.2908 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 66 meanReward: 55.6562 meanLoss: 281.6799 meanLossQlbl: 150.8155 meanLossQlbl_sigm: 0.6890 meanLossQtgt: 129.4786 meanLossQtgt_sigm: 0.6967\n",
      "Episode: 67 meanReward: 55.7500 meanLoss: 468.9600 meanLossQlbl: 250.0221 meanLossQlbl_sigm: 0.6810 meanLossQtgt: 217.5616 meanLossQtgt_sigm: 0.6952\n",
      "Episode: 68 meanReward: 57.0312 meanLoss: 481.5567 meanLossQlbl: 258.8650 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 221.3054 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 69 meanReward: 57.1562 meanLoss: 670.9063 meanLossQlbl: 357.8251 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 311.6947 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 70 meanReward: 59.6562 meanLoss: 597.5172 meanLossQlbl: 319.5400 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 276.5909 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 71 meanReward: 61.2188 meanLoss: 679.2295 meanLossQlbl: 362.3063 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 315.5369 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 72 meanReward: 63.1875 meanLoss: 633.7983 meanLossQlbl: 338.8361 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 293.5758 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 73 meanReward: 64.5312 meanLoss: 682.3218 meanLossQlbl: 363.7897 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 317.1457 meanLossQtgt_sigm: 0.6931\n",
      "Episode: 74 meanReward: 65.9375 meanLoss: 395.0945 meanLossQlbl: 211.9314 meanLossQlbl_sigm: 0.4414 meanLossQtgt: 182.2768 meanLossQtgt_sigm: 0.4450\n",
      "Episode: 75 meanReward: 65.4062 meanLoss: 135.6930 meanLossQlbl: 53.2283 meanLossQlbl_sigm: 0.2266 meanLossQtgt: 81.7718 meanLossQtgt_sigm: 0.4662\n",
      "Episode: 76 meanReward: 65.0312 meanLoss: 260.8513 meanLossQlbl: 128.7982 meanLossQlbl_sigm: 0.3948 meanLossQtgt: 131.2013 meanLossQtgt_sigm: 0.4571\n",
      "Episode: 77 meanReward: 64.0312 meanLoss: 62.1350 meanLossQlbl: 0.7975 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 60.9590 meanLossQtgt_sigm: 0.3785\n",
      "Episode: 78 meanReward: 63.5625 meanLoss: 58.8586 meanLossQlbl: 0.5073 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 57.9125 meanLossQtgt_sigm: 0.4388\n",
      "Episode: 79 meanReward: 62.9688 meanLoss: 45.5265 meanLossQlbl: 0.2376 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.9550 meanLossQtgt_sigm: 0.3339\n",
      "Episode: 80 meanReward: 61.9375 meanLoss: 35.2691 meanLossQlbl: 1.0250 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.9712 meanLossQtgt_sigm: 0.2729\n",
      "Episode: 81 meanReward: 62.5312 meanLoss: 18.9744 meanLossQlbl: 0.5392 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3199 meanLossQtgt_sigm: 0.1152\n",
      "Episode: 82 meanReward: 61.1562 meanLoss: 80.9186 meanLossQlbl: 0.2658 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 80.2083 meanLossQtgt_sigm: 0.4446\n",
      "Episode: 83 meanReward: 60.9375 meanLoss: 56.8095 meanLossQlbl: 0.9597 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.5110 meanLossQtgt_sigm: 0.3387\n",
      "Episode: 84 meanReward: 59.8750 meanLoss: 73.7802 meanLossQlbl: 0.1947 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 73.1660 meanLossQtgt_sigm: 0.4195\n",
      "Episode: 85 meanReward: 61.6875 meanLoss: 18.3637 meanLossQlbl: 0.5383 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7155 meanLossQtgt_sigm: 0.1099\n",
      "Episode: 86 meanReward: 62.3750 meanLoss: 23.6498 meanLossQlbl: 0.1560 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.3697 meanLossQtgt_sigm: 0.1241\n",
      "Episode: 87 meanReward: 62.9688 meanLoss: 27.4697 meanLossQlbl: 0.1223 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.2028 meanLossQtgt_sigm: 0.1447\n",
      "Episode: 88 meanReward: 67.3438 meanLoss: 20.5197 meanLossQlbl: 5.7627 meanLossQlbl_sigm: 0.0163 meanLossQtgt: 14.6691 meanLossQtgt_sigm: 0.0716\n",
      "Episode: 89 meanReward: 66.0000 meanLoss: 468.5540 meanLossQlbl: 248.8844 meanLossQlbl_sigm: 0.4522 meanLossQtgt: 218.7032 meanLossQtgt_sigm: 0.5142\n",
      "Episode: 90 meanReward: 65.0312 meanLoss: 116.0417 meanLossQlbl: 4.1836 meanLossQlbl_sigm: 0.0181 meanLossQtgt: 111.2718 meanLossQtgt_sigm: 0.5683\n",
      "Episode: 91 meanReward: 64.0000 meanLoss: 99.8543 meanLossQlbl: 0.0762 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 99.2384 meanLossQtgt_sigm: 0.5396\n",
      "Episode: 92 meanReward: 68.2812 meanLoss: 13.5787 meanLossQlbl: 0.2550 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2494 meanLossQtgt_sigm: 0.0743\n",
      "Episode: 93 meanReward: 69.3750 meanLoss: 15.3691 meanLossQlbl: 0.4050 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.8776 meanLossQtgt_sigm: 0.0865\n",
      "Episode: 94 meanReward: 69.9062 meanLoss: 39.5575 meanLossQlbl: 1.3631 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 38.0016 meanLossQtgt_sigm: 0.1928\n",
      "Episode: 95 meanReward: 69.6875 meanLoss: 58.5308 meanLossQlbl: 0.5100 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 57.7547 meanLossQtgt_sigm: 0.2661\n",
      "Episode: 96 meanReward: 68.7500 meanLoss: 110.8830 meanLossQlbl: 1.7150 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 108.6599 meanLossQtgt_sigm: 0.5081\n",
      "Episode: 97 meanReward: 69.7812 meanLoss: 37.9872 meanLossQlbl: 0.5105 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 37.2932 meanLossQtgt_sigm: 0.1835\n",
      "Episode: 98 meanReward: 72.0312 meanLoss: 32.1925 meanLossQlbl: 0.1095 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.9420 meanLossQtgt_sigm: 0.1411\n",
      "Episode: 99 meanReward: 71.2500 meanLoss: 103.7607 meanLossQlbl: 0.4523 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 102.8139 meanLossQtgt_sigm: 0.4945\n",
      "Episode: 100 meanReward: 77.4062 meanLoss: 11.2420 meanLossQlbl: 0.2588 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.9311 meanLossQtgt_sigm: 0.0520\n",
      "Episode: 101 meanReward: 76.0625 meanLoss: 149.7786 meanLossQlbl: 0.1534 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 149.0255 meanLossQtgt_sigm: 0.5998\n",
      "Episode: 102 meanReward: 75.7812 meanLoss: 22.6186 meanLossQlbl: 1.9395 meanLossQlbl_sigm: 0.0112 meanLossQtgt: 20.5753 meanLossQtgt_sigm: 0.0926\n",
      "Episode: 103 meanReward: 73.4688 meanLoss: 89.9493 meanLossQlbl: 0.1199 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 89.3608 meanLossQtgt_sigm: 0.4687\n",
      "Episode: 104 meanReward: 71.3750 meanLoss: 123.4170 meanLossQlbl: 0.2915 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 122.4782 meanLossQtgt_sigm: 0.6473\n",
      "Episode: 105 meanReward: 69.4062 meanLoss: 69.4008 meanLossQlbl: 0.2961 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 68.6973 meanLossQtgt_sigm: 0.4074\n",
      "Episode: 106 meanReward: 68.3750 meanLoss: 33.6975 meanLossQlbl: 0.3029 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.1691 meanLossQtgt_sigm: 0.2255\n",
      "Episode: 107 meanReward: 83.0938 meanLoss: 4.4622 meanLossQlbl: 0.0261 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.4123 meanLossQtgt_sigm: 0.0238\n",
      "Episode: 108 meanReward: 97.4688 meanLoss: 10.9542 meanLossQlbl: 0.0700 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.8449 meanLossQtgt_sigm: 0.0393\n",
      "Episode: 109 meanReward: 97.5938 meanLoss: 201.9109 meanLossQlbl: 1.0993 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 200.1203 meanLossQtgt_sigm: 0.6913\n",
      "Episode: 110 meanReward: 107.6562 meanLoss: 15.2956 meanLossQlbl: 0.3212 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.9159 meanLossQtgt_sigm: 0.0585\n",
      "Episode: 111 meanReward: 110.3750 meanLoss: 40.5605 meanLossQlbl: 0.6455 meanLossQlbl_sigm: 0.0006 meanLossQtgt: 39.7631 meanLossQtgt_sigm: 0.1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 112 meanReward: 113.3750 meanLoss: 22.5578 meanLossQlbl: 0.1112 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.3382 meanLossQtgt_sigm: 0.1083\n",
      "Episode: 113 meanReward: 117.2188 meanLoss: 15.3576 meanLossQlbl: 5.9367 meanLossQlbl_sigm: 0.0247 meanLossQtgt: 9.3544 meanLossQtgt_sigm: 0.0418\n",
      "Episode: 114 meanReward: 126.3750 meanLoss: 12.0738 meanLossQlbl: 0.3848 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.6508 meanLossQtgt_sigm: 0.0382\n",
      "Episode: 115 meanReward: 140.4062 meanLoss: 10.4779 meanLossQlbl: 0.0379 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.4017 meanLossQtgt_sigm: 0.0383\n",
      "Episode: 116 meanReward: 140.1562 meanLoss: 262.0642 meanLossQlbl: 0.8934 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 260.3792 meanLossQtgt_sigm: 0.7917\n",
      "Episode: 117 meanReward: 137.8438 meanLoss: 156.3128 meanLossQlbl: 3.8418 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 152.0909 meanLossQtgt_sigm: 0.3801\n",
      "Episode: 118 meanReward: 138.2500 meanLoss: 38.1679 meanLossQlbl: 0.4697 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 37.5537 meanLossQtgt_sigm: 0.1445\n",
      "Episode: 119 meanReward: 139.0625 meanLoss: 18.1890 meanLossQlbl: 0.1903 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8959 meanLossQtgt_sigm: 0.1029\n",
      "Episode: 120 meanReward: 134.5625 meanLoss: 45.5570 meanLossQlbl: 0.5337 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.7669 meanLossQtgt_sigm: 0.2564\n",
      "Episode: 121 meanReward: 135.6875 meanLoss: 30.9102 meanLossQlbl: 0.0214 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 30.6990 meanLossQtgt_sigm: 0.1898\n",
      "Episode: 122 meanReward: 135.8750 meanLoss: 52.6461 meanLossQlbl: 0.0019 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 52.2901 meanLossQtgt_sigm: 0.3541\n",
      "Episode: 123 meanReward: 137.9688 meanLoss: 14.5615 meanLossQlbl: 0.4674 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.9960 meanLossQtgt_sigm: 0.0981\n",
      "Episode: 124 meanReward: 134.9688 meanLoss: 17.1497 meanLossQlbl: 0.1635 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8727 meanLossQtgt_sigm: 0.1135\n",
      "Episode: 125 meanReward: 141.0938 meanLoss: 4.9783 meanLossQlbl: 0.0206 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.9240 meanLossQtgt_sigm: 0.0337\n",
      "Episode: 126 meanReward: 141.5625 meanLoss: 17.0737 meanLossQlbl: 0.3811 meanLossQlbl_sigm: 0.0039 meanLossQtgt: 16.5840 meanLossQtgt_sigm: 0.1047\n",
      "Episode: 127 meanReward: 145.1875 meanLoss: 19.8806 meanLossQlbl: 7.8338 meanLossQlbl_sigm: 0.0276 meanLossQtgt: 11.9711 meanLossQtgt_sigm: 0.0480\n",
      "Episode: 128 meanReward: 154.2188 meanLoss: 5.6155 meanLossQlbl: 0.1095 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.4733 meanLossQtgt_sigm: 0.0327\n",
      "Episode: 129 meanReward: 152.6875 meanLoss: 30.4854 meanLossQlbl: 0.1029 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 30.1609 meanLossQtgt_sigm: 0.2217\n",
      "Episode: 130 meanReward: 164.6562 meanLoss: 13.8074 meanLossQlbl: 0.2419 meanLossQlbl_sigm: 0.0005 meanLossQtgt: 13.5215 meanLossQtgt_sigm: 0.0434\n",
      "Episode: 131 meanReward: 164.2188 meanLoss: 281.4816 meanLossQlbl: 1.0634 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 279.5933 meanLossQtgt_sigm: 0.8250\n",
      "Episode: 132 meanReward: 155.3438 meanLoss: 393.8289 meanLossQlbl: 6.7482 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 385.7453 meanLossQtgt_sigm: 1.3354\n",
      "Episode: 133 meanReward: 167.4375 meanLoss: 15.1209 meanLossQlbl: 0.2974 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.7689 meanLossQtgt_sigm: 0.0546\n",
      "Episode: 134 meanReward: 179.0938 meanLoss: 9.6506 meanLossQlbl: 0.2718 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.3430 meanLossQtgt_sigm: 0.0358\n",
      "Episode: 135 meanReward: 194.3125 meanLoss: 12.1729 meanLossQlbl: 0.2921 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.8401 meanLossQtgt_sigm: 0.0407\n",
      "Episode: 136 meanReward: 198.1562 meanLoss: 52.4150 meanLossQlbl: 0.2642 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 51.9957 meanLossQtgt_sigm: 0.1551\n",
      "Episode: 137 meanReward: 213.1875 meanLoss: 15.1795 meanLossQlbl: 0.2524 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.8813 meanLossQtgt_sigm: 0.0459\n",
      "Episode: 138 meanReward: 226.7500 meanLoss: 16.8571 meanLossQlbl: 0.0485 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7595 meanLossQtgt_sigm: 0.0491\n",
      "Episode: 139 meanReward: 213.6562 meanLoss: 101.9628 meanLossQlbl: 0.2846 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 101.3754 meanLossQtgt_sigm: 0.3028\n",
      "Episode: 140 meanReward: 213.6562 meanLoss: 13.3756 meanLossQlbl: 0.3025 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.0298 meanLossQtgt_sigm: 0.0433\n",
      "Episode: 141 meanReward: 228.5625 meanLoss: 15.3113 meanLossQlbl: 0.0836 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.1811 meanLossQtgt_sigm: 0.0465\n",
      "Episode: 142 meanReward: 233.1875 meanLoss: 10.7193 meanLossQlbl: 0.3937 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2877 meanLossQtgt_sigm: 0.0379\n",
      "Episode: 143 meanReward: 245.2500 meanLoss: 16.7201 meanLossQlbl: 0.1166 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5543 meanLossQtgt_sigm: 0.0492\n",
      "Episode: 144 meanReward: 242.7812 meanLoss: 156.6877 meanLossQlbl: 0.4563 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 155.7760 meanLossQtgt_sigm: 0.4554\n",
      "Episode: 145 meanReward: 251.6250 meanLoss: 10.9861 meanLossQlbl: 0.0767 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.8703 meanLossQtgt_sigm: 0.0391\n",
      "Episode: 146 meanReward: 257.5625 meanLoss: 16.0623 meanLossQlbl: 0.0427 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9714 meanLossQtgt_sigm: 0.0481\n",
      "Episode: 147 meanReward: 242.5000 meanLoss: 261.3553 meanLossQlbl: 1.1747 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 259.3885 meanLossQtgt_sigm: 0.7921\n",
      "Episode: 148 meanReward: 257.5000 meanLoss: 17.7149 meanLossQlbl: 0.6413 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0194 meanLossQtgt_sigm: 0.0542\n",
      "Episode: 149 meanReward: 271.8438 meanLoss: 16.2780 meanLossQlbl: 0.1194 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.1104 meanLossQtgt_sigm: 0.0482\n",
      "Episode: 150 meanReward: 283.6875 meanLoss: 16.5271 meanLossQlbl: 0.1249 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.3534 meanLossQtgt_sigm: 0.0488\n",
      "Episode: 151 meanReward: 295.5625 meanLoss: 15.9985 meanLossQlbl: 0.5076 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.4437 meanLossQtgt_sigm: 0.0472\n",
      "Episode: 152 meanReward: 309.6562 meanLoss: 17.0203 meanLossQlbl: 0.0596 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9112 meanLossQtgt_sigm: 0.0495\n",
      "Episode: 153 meanReward: 309.7188 meanLoss: 127.1391 meanLossQlbl: 0.7026 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 126.0568 meanLossQtgt_sigm: 0.3797\n",
      "Episode: 154 meanReward: 309.1250 meanLoss: 270.9096 meanLossQlbl: 0.8638 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 269.2266 meanLossQtgt_sigm: 0.8192\n",
      "Episode: 155 meanReward: 321.8438 meanLoss: 17.6895 meanLossQlbl: 0.9729 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.6605 meanLossQtgt_sigm: 0.0561\n",
      "Episode: 156 meanReward: 321.3750 meanLoss: 107.9505 meanLossQlbl: 0.2648 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 107.3624 meanLossQtgt_sigm: 0.3233\n",
      "Episode: 157 meanReward: 328.3125 meanLoss: 11.4094 meanLossQlbl: 0.0574 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.3122 meanLossQtgt_sigm: 0.0399\n",
      "Episode: 158 meanReward: 326.0938 meanLoss: 267.9464 meanLossQlbl: 0.3244 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 266.8159 meanLossQtgt_sigm: 0.8061\n",
      "Episode: 159 meanReward: 322.0625 meanLoss: 176.8591 meanLossQlbl: 11.8246 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 164.5957 meanLossQtgt_sigm: 0.4388\n",
      "Episode: 160 meanReward: 324.0000 meanLoss: 10.8932 meanLossQlbl: 0.8524 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.9993 meanLossQtgt_sigm: 0.0414\n",
      "Episode: 161 meanReward: 329.3125 meanLoss: 18.3351 meanLossQlbl: 0.5915 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.6745 meanLossQtgt_sigm: 0.0690\n",
      "Episode: 162 meanReward: 328.8750 meanLoss: 7.0104 meanLossQlbl: 0.1686 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.8123 meanLossQtgt_sigm: 0.0295\n",
      "Episode: 163 meanReward: 336.9062 meanLoss: 12.2564 meanLossQlbl: 0.8552 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.3509 meanLossQtgt_sigm: 0.0503\n",
      "Episode: 164 meanReward: 342.0938 meanLoss: 29.1775 meanLossQlbl: 0.3497 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.7289 meanLossQtgt_sigm: 0.0988\n",
      "Episode: 165 meanReward: 334.4062 meanLoss: 15.1526 meanLossQlbl: 0.8544 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.2280 meanLossQtgt_sigm: 0.0702\n",
      "Episode: 166 meanReward: 321.0000 meanLoss: 49.2121 meanLossQlbl: 0.8859 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 48.1065 meanLossQtgt_sigm: 0.2198\n",
      "Episode: 167 meanReward: 310.0312 meanLoss: 11.4136 meanLossQlbl: 0.4147 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.9383 meanLossQtgt_sigm: 0.0606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 168 meanReward: 320.7812 meanLoss: 4.6868 meanLossQlbl: 0.1019 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.5612 meanLossQtgt_sigm: 0.0237\n",
      "Episode: 169 meanReward: 320.7812 meanLoss: 10.5964 meanLossQlbl: 0.0274 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.5310 meanLossQtgt_sigm: 0.0380\n",
      "Episode: 170 meanReward: 310.9062 meanLoss: 43.0273 meanLossQlbl: 0.4497 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 42.4510 meanLossQtgt_sigm: 0.1266\n",
      "Episode: 171 meanReward: 309.3438 meanLoss: 148.3476 meanLossQlbl: 1.8674 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 145.9056 meanLossQtgt_sigm: 0.5746\n",
      "Episode: 172 meanReward: 309.3438 meanLoss: 5.7978 meanLossQlbl: 0.1870 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.5868 meanLossQtgt_sigm: 0.0240\n",
      "Episode: 173 meanReward: 299.7188 meanLoss: 25.0550 meanLossQlbl: 1.1195 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.8454 meanLossQtgt_sigm: 0.0901\n",
      "Episode: 174 meanReward: 288.4688 meanLoss: 14.2404 meanLossQlbl: 0.8483 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.3237 meanLossQtgt_sigm: 0.0684\n",
      "Episode: 175 meanReward: 288.4688 meanLoss: 3.9215 meanLossQlbl: 0.0136 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.8850 meanLossQtgt_sigm: 0.0229\n",
      "Episode: 176 meanReward: 289.2188 meanLoss: 107.8023 meanLossQlbl: 1.1017 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 106.3873 meanLossQtgt_sigm: 0.3133\n",
      "Episode: 177 meanReward: 274.5938 meanLoss: 40.3075 meanLossQlbl: 0.5201 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.5070 meanLossQtgt_sigm: 0.2804\n",
      "Episode: 178 meanReward: 274.5938 meanLoss: 2.2049 meanLossQlbl: 0.0721 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.1206 meanLossQtgt_sigm: 0.0122\n",
      "Episode: 179 meanReward: 280.5312 meanLoss: 34.1439 meanLossQlbl: 0.5439 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.4984 meanLossQtgt_sigm: 0.1016\n",
      "Episode: 180 meanReward: 270.3125 meanLoss: 13.4930 meanLossQlbl: 0.3058 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.1157 meanLossQtgt_sigm: 0.0714\n",
      "Episode: 181 meanReward: 258.2188 meanLoss: 13.4819 meanLossQlbl: 1.0521 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.3449 meanLossQtgt_sigm: 0.0849\n",
      "Episode: 182 meanReward: 246.0312 meanLoss: 12.7813 meanLossQlbl: 0.3520 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.3455 meanLossQtgt_sigm: 0.0839\n",
      "Episode: 183 meanReward: 234.4062 meanLoss: 6.1892 meanLossQlbl: 0.2405 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 5.8984 meanLossQtgt_sigm: 0.0502\n",
      "Episode: 184 meanReward: 222.7500 meanLoss: 4.5219 meanLossQlbl: 0.4275 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.0593 meanLossQtgt_sigm: 0.0351\n",
      "Episode: 185 meanReward: 224.8750 meanLoss: 6.3611 meanLossQlbl: 0.3918 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.9183 meanLossQtgt_sigm: 0.0509\n",
      "Episode: 186 meanReward: 229.0312 meanLoss: 4.3556 meanLossQlbl: 0.2285 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.0846 meanLossQtgt_sigm: 0.0425\n",
      "Episode: 187 meanReward: 226.9688 meanLoss: 1.4797 meanLossQlbl: 0.1211 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.3451 meanLossQtgt_sigm: 0.0135\n",
      "Episode: 188 meanReward: 231.8750 meanLoss: 3.3547 meanLossQlbl: 0.1393 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.1874 meanLossQtgt_sigm: 0.0280\n",
      "Episode: 189 meanReward: 222.8125 meanLoss: 1.4835 meanLossQlbl: 0.2157 meanLossQlbl_sigm: 0.0070 meanLossQtgt: 1.2490 meanLossQtgt_sigm: 0.0117\n",
      "Episode: 190 meanReward: 229.6875 meanLoss: 7.3937 meanLossQlbl: 0.1843 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.1635 meanLossQtgt_sigm: 0.0459\n",
      "Episode: 191 meanReward: 235.6875 meanLoss: 6.5043 meanLossQlbl: 0.3289 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.1344 meanLossQtgt_sigm: 0.0410\n",
      "Episode: 192 meanReward: 226.1562 meanLoss: 19.4146 meanLossQlbl: 1.0767 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2185 meanLossQtgt_sigm: 0.1194\n",
      "Episode: 193 meanReward: 223.3125 meanLoss: 13.9432 meanLossQlbl: 1.2503 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.6183 meanLossQtgt_sigm: 0.0746\n",
      "Episode: 194 meanReward: 213.8750 meanLoss: 4.2652 meanLossQlbl: 0.3489 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.8909 meanLossQtgt_sigm: 0.0254\n",
      "Episode: 195 meanReward: 220.9688 meanLoss: 2.1018 meanLossQlbl: 0.0284 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.0587 meanLossQtgt_sigm: 0.0147\n",
      "Episode: 196 meanReward: 224.5000 meanLoss: 32.9332 meanLossQlbl: 0.5011 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.3437 meanLossQtgt_sigm: 0.0884\n",
      "Episode: 197 meanReward: 235.1562 meanLoss: 4.7957 meanLossQlbl: 0.3705 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.4040 meanLossQtgt_sigm: 0.0212\n",
      "Episode: 198 meanReward: 238.0000 meanLoss: 50.8621 meanLossQlbl: 1.3531 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 49.3710 meanLossQtgt_sigm: 0.1380\n",
      "Episode: 199 meanReward: 233.6562 meanLoss: 39.0738 meanLossQlbl: 0.9584 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 37.8726 meanLossQtgt_sigm: 0.2428\n",
      "Episode: 200 meanReward: 218.3438 meanLoss: 112.7152 meanLossQlbl: 3.7723 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 108.5864 meanLossQtgt_sigm: 0.3563\n",
      "Episode: 201 meanReward: 205.0000 meanLoss: 53.8133 meanLossQlbl: 5.8449 meanLossQlbl_sigm: 0.0692 meanLossQtgt: 47.7639 meanLossQtgt_sigm: 0.1353\n",
      "Episode: 202 meanReward: 202.1250 meanLoss: 7.1198 meanLossQlbl: 0.5048 meanLossQlbl_sigm: 0.0025 meanLossQtgt: 6.5852 meanLossQtgt_sigm: 0.0274\n",
      "Episode: 203 meanReward: 205.1562 meanLoss: 4.8143 meanLossQlbl: 0.2312 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.5557 meanLossQtgt_sigm: 0.0274\n",
      "Episode: 204 meanReward: 199.7500 meanLoss: 3.3438 meanLossQlbl: 0.1104 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.2145 meanLossQtgt_sigm: 0.0189\n",
      "Episode: 205 meanReward: 200.0938 meanLoss: 10.5601 meanLossQlbl: 0.2794 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2357 meanLossQtgt_sigm: 0.0450\n",
      "Episode: 206 meanReward: 209.2812 meanLoss: 1.9962 meanLossQlbl: 0.0793 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.9032 meanLossQtgt_sigm: 0.0137\n",
      "Episode: 207 meanReward: 205.4062 meanLoss: 1.1700 meanLossQlbl: 0.0288 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.1345 meanLossQtgt_sigm: 0.0067\n",
      "Episode: 208 meanReward: 207.0938 meanLoss: 3.3349 meanLossQlbl: 0.1006 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 3.2132 meanLossQtgt_sigm: 0.0211\n",
      "Episode: 209 meanReward: 209.0000 meanLoss: 6.8432 meanLossQlbl: 0.2027 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.5857 meanLossQtgt_sigm: 0.0549\n",
      "Episode: 210 meanReward: 196.9062 meanLoss: 3.3982 meanLossQlbl: 0.1056 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 3.2698 meanLossQtgt_sigm: 0.0227\n",
      "Episode: 211 meanReward: 194.1562 meanLoss: 1.9825 meanLossQlbl: 0.0414 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 1.9220 meanLossQtgt_sigm: 0.0191\n",
      "Episode: 212 meanReward: 193.2188 meanLoss: 5.2492 meanLossQlbl: 0.0581 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.1439 meanLossQtgt_sigm: 0.0471\n",
      "Episode: 213 meanReward: 192.1250 meanLoss: 15.2164 meanLossQlbl: 0.4047 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.7068 meanLossQtgt_sigm: 0.1049\n",
      "Episode: 214 meanReward: 192.9688 meanLoss: 4.4217 meanLossQlbl: 0.2821 meanLossQlbl_sigm: 0.0038 meanLossQtgt: 4.1135 meanLossQtgt_sigm: 0.0222\n",
      "Episode: 215 meanReward: 194.4062 meanLoss: 5.4739 meanLossQlbl: 0.0396 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.3901 meanLossQtgt_sigm: 0.0442\n",
      "Episode: 216 meanReward: 196.0000 meanLoss: 6.8701 meanLossQlbl: 0.0533 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.7681 meanLossQtgt_sigm: 0.0487\n",
      "Episode: 217 meanReward: 200.6250 meanLoss: 5.0128 meanLossQlbl: 0.0488 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.9301 meanLossQtgt_sigm: 0.0339\n",
      "Episode: 218 meanReward: 196.4375 meanLoss: 113.5549 meanLossQlbl: 1.8796 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 111.1629 meanLossQtgt_sigm: 0.5124\n",
      "Episode: 219 meanReward: 198.5000 meanLoss: 10.9295 meanLossQlbl: 0.6087 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2740 meanLossQtgt_sigm: 0.0468\n",
      "Episode: 220 meanReward: 196.6875 meanLoss: 19.9908 meanLossQlbl: 0.1789 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.7270 meanLossQtgt_sigm: 0.0848\n",
      "Episode: 221 meanReward: 194.9062 meanLoss: 13.4080 meanLossQlbl: 0.1574 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.1741 meanLossQtgt_sigm: 0.0764\n",
      "Episode: 222 meanReward: 203.1250 meanLoss: 4.4931 meanLossQlbl: 0.1495 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.3201 meanLossQtgt_sigm: 0.0235\n",
      "Episode: 223 meanReward: 211.3750 meanLoss: 17.6381 meanLossQlbl: 0.5238 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0706 meanLossQtgt_sigm: 0.0438\n",
      "Episode: 224 meanReward: 224.7812 meanLoss: 23.0282 meanLossQlbl: 0.0515 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.9194 meanLossQtgt_sigm: 0.0573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 225 meanReward: 221.4375 meanLoss: 404.2200 meanLossQlbl: 0.9776 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 402.2487 meanLossQtgt_sigm: 0.9938\n",
      "Episode: 226 meanReward: 216.0312 meanLoss: 567.8749 meanLossQlbl: 3.5865 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 562.6924 meanLossQtgt_sigm: 1.5960\n",
      "Episode: 227 meanReward: 216.0312 meanLoss: 10.4405 meanLossQlbl: 0.3865 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.0186 meanLossQtgt_sigm: 0.0355\n",
      "Episode: 228 meanReward: 215.0000 meanLoss: 35.7084 meanLossQlbl: 0.4942 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.1160 meanLossQtgt_sigm: 0.0982\n",
      "Episode: 229 meanReward: 215.0000 meanLoss: 17.0261 meanLossQlbl: 0.1525 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8247 meanLossQtgt_sigm: 0.0489\n",
      "Episode: 230 meanReward: 225.5625 meanLoss: 18.7203 meanLossQlbl: 0.1992 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4707 meanLossQtgt_sigm: 0.0504\n",
      "Episode: 231 meanReward: 240.8750 meanLoss: 17.2588 meanLossQlbl: 0.1810 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0283 meanLossQtgt_sigm: 0.0494\n",
      "Episode: 232 meanReward: 241.2500 meanLoss: 270.7761 meanLossQlbl: 0.8332 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 269.1399 meanLossQtgt_sigm: 0.8031\n",
      "Episode: 233 meanReward: 239.2812 meanLoss: 451.2922 meanLossQlbl: 2.0914 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 447.8149 meanLossQtgt_sigm: 1.3858\n",
      "Episode: 234 meanReward: 252.0312 meanLoss: 11.4246 meanLossQlbl: 0.2689 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.1147 meanLossQtgt_sigm: 0.0410\n",
      "Episode: 235 meanReward: 263.6562 meanLoss: 16.1985 meanLossQlbl: 0.0590 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.0917 meanLossQtgt_sigm: 0.0479\n",
      "Episode: 236 meanReward: 269.0625 meanLoss: 19.5476 meanLossQlbl: 0.1426 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.3523 meanLossQtgt_sigm: 0.0527\n",
      "Episode: 237 meanReward: 278.3438 meanLoss: 13.3725 meanLossQlbl: 0.1152 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2153 meanLossQtgt_sigm: 0.0419\n",
      "Episode: 238 meanReward: 267.2812 meanLoss: 115.1569 meanLossQlbl: 0.5402 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 114.2960 meanLossQtgt_sigm: 0.3207\n",
      "Episode: 239 meanReward: 271.1562 meanLoss: 15.7070 meanLossQlbl: 0.1480 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.5117 meanLossQtgt_sigm: 0.0472\n",
      "Episode: 240 meanReward: 282.6562 meanLoss: 19.3559 meanLossQlbl: 0.0672 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.2358 meanLossQtgt_sigm: 0.0528\n",
      "Episode: 241 meanReward: 280.6875 meanLoss: 277.2960 meanLossQlbl: 0.7921 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 275.6969 meanLossQtgt_sigm: 0.8070\n",
      "Episode: 242 meanReward: 289.1250 meanLoss: 16.0540 meanLossQlbl: 0.1956 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.8042 meanLossQtgt_sigm: 0.0542\n",
      "Episode: 243 meanReward: 285.6562 meanLoss: 184.6537 meanLossQlbl: 0.4180 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 183.5591 meanLossQtgt_sigm: 0.6766\n",
      "Episode: 244 meanReward: 281.5000 meanLoss: 245.8654 meanLossQlbl: 5.0925 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 239.7896 meanLossQtgt_sigm: 0.9833\n",
      "Episode: 245 meanReward: 288.7188 meanLoss: 19.7262 meanLossQlbl: 0.8315 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.8406 meanLossQtgt_sigm: 0.0541\n",
      "Episode: 246 meanReward: 288.5625 meanLoss: 10.2519 meanLossQlbl: 0.1342 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.0502 meanLossQtgt_sigm: 0.0675\n",
      "Episode: 247 meanReward: 287.5000 meanLoss: 9.0146 meanLossQlbl: 0.1342 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.8269 meanLossQtgt_sigm: 0.0534\n",
      "Episode: 248 meanReward: 290.1250 meanLoss: 5.2518 meanLossQlbl: 0.1103 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.1116 meanLossQtgt_sigm: 0.0299\n",
      "Episode: 249 meanReward: 287.5312 meanLoss: 9.7649 meanLossQlbl: 0.2430 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.4735 meanLossQtgt_sigm: 0.0484\n",
      "Episode: 250 meanReward: 293.3750 meanLoss: 15.6486 meanLossQlbl: 0.3581 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.2235 meanLossQtgt_sigm: 0.0669\n",
      "Episode: 251 meanReward: 293.3750 meanLoss: 4.3908 meanLossQlbl: 0.0134 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.3542 meanLossQtgt_sigm: 0.0231\n",
      "Episode: 252 meanReward: 303.5938 meanLoss: 17.0471 meanLossQlbl: 0.0565 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9423 meanLossQtgt_sigm: 0.0483\n",
      "Episode: 253 meanReward: 302.2188 meanLoss: 67.1828 meanLossQlbl: 0.5286 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 66.4452 meanLossQtgt_sigm: 0.2090\n",
      "Episode: 254 meanReward: 290.6562 meanLoss: 28.2550 meanLossQlbl: 1.0172 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.1296 meanLossQtgt_sigm: 0.1081\n",
      "Episode: 255 meanReward: 275.5312 meanLoss: 93.4760 meanLossQlbl: 1.3106 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 91.7423 meanLossQtgt_sigm: 0.4231\n",
      "Episode: 256 meanReward: 263.0312 meanLoss: 53.4629 meanLossQlbl: 1.3784 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 51.8647 meanLossQtgt_sigm: 0.2199\n",
      "Episode: 257 meanReward: 268.5312 meanLoss: 8.9248 meanLossQlbl: 0.0660 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.8049 meanLossQtgt_sigm: 0.0539\n",
      "Episode: 258 meanReward: 276.8438 meanLoss: 6.3920 meanLossQlbl: 0.3377 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.0199 meanLossQtgt_sigm: 0.0344\n",
      "Episode: 259 meanReward: 264.8438 meanLoss: 34.0411 meanLossQlbl: 0.3806 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.5194 meanLossQtgt_sigm: 0.1411\n",
      "Episode: 260 meanReward: 266.9375 meanLoss: 10.0743 meanLossQlbl: 0.2383 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.7905 meanLossQtgt_sigm: 0.0455\n",
      "Episode: 261 meanReward: 254.0312 meanLoss: 34.6997 meanLossQlbl: 0.3732 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 34.1596 meanLossQtgt_sigm: 0.1669\n",
      "Episode: 262 meanReward: 241.8125 meanLoss: 38.9105 meanLossQlbl: 0.4876 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 38.2743 meanLossQtgt_sigm: 0.1486\n",
      "Episode: 263 meanReward: 226.5938 meanLoss: 37.9565 meanLossQlbl: 0.1833 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 37.5562 meanLossQtgt_sigm: 0.2170\n",
      "Episode: 264 meanReward: 241.5312 meanLoss: 7.7361 meanLossQlbl: 0.3999 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.3102 meanLossQtgt_sigm: 0.0260\n",
      "Episode: 265 meanReward: 256.8438 meanLoss: 20.2241 meanLossQlbl: 0.2305 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.9409 meanLossQtgt_sigm: 0.0527\n",
      "Episode: 266 meanReward: 241.9062 meanLoss: 325.3535 meanLossQlbl: 1.3401 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 323.1365 meanLossQtgt_sigm: 0.8768\n",
      "Episode: 267 meanReward: 226.5938 meanLoss: 349.8302 meanLossQlbl: 4.9814 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 343.7578 meanLossQtgt_sigm: 1.0910\n",
      "Episode: 268 meanReward: 215.2812 meanLoss: 24.6553 meanLossQlbl: 1.7382 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.8320 meanLossQtgt_sigm: 0.0851\n",
      "Episode: 269 meanReward: 203.1875 meanLoss: 9.1012 meanLossQlbl: 0.6325 meanLossQlbl_sigm: 0.0191 meanLossQtgt: 8.4126 meanLossQtgt_sigm: 0.0370\n",
      "Episode: 270 meanReward: 202.9375 meanLoss: 9.3243 meanLossQlbl: 1.8268 meanLossQlbl_sigm: 0.0468 meanLossQtgt: 7.3808 meanLossQtgt_sigm: 0.0700\n",
      "Episode: 271 meanReward: 201.4375 meanLoss: 4.9727 meanLossQlbl: 0.2673 meanLossQlbl_sigm: 0.0044 meanLossQtgt: 4.6888 meanLossQtgt_sigm: 0.0121\n",
      "Episode: 272 meanReward: 191.9375 meanLoss: 19.8792 meanLossQlbl: 1.0739 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.7485 meanLossQtgt_sigm: 0.0568\n",
      "Episode: 273 meanReward: 197.2188 meanLoss: 12.7639 meanLossQlbl: 0.2197 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.4967 meanLossQtgt_sigm: 0.0474\n",
      "Episode: 274 meanReward: 192.7188 meanLoss: 11.7797 meanLossQlbl: 0.5068 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.2179 meanLossQtgt_sigm: 0.0550\n",
      "Episode: 275 meanReward: 208.0625 meanLoss: 2.1312 meanLossQlbl: 0.0268 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.0899 meanLossQtgt_sigm: 0.0144\n",
      "Episode: 276 meanReward: 223.3750 meanLoss: 20.7162 meanLossQlbl: 0.0584 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.6037 meanLossQtgt_sigm: 0.0541\n",
      "Episode: 277 meanReward: 229.3438 meanLoss: 18.9514 meanLossQlbl: 0.0784 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.8206 meanLossQtgt_sigm: 0.0524\n",
      "Episode: 278 meanReward: 240.8438 meanLoss: 18.0865 meanLossQlbl: 0.1725 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8631 meanLossQtgt_sigm: 0.0508\n",
      "Episode: 279 meanReward: 252.0938 meanLoss: 5.7867 meanLossQlbl: 0.0536 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.7071 meanLossQtgt_sigm: 0.0259\n",
      "Episode: 280 meanReward: 259.5312 meanLoss: 17.8323 meanLossQlbl: 0.0532 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7282 meanLossQtgt_sigm: 0.0508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 281 meanReward: 254.3125 meanLoss: 316.7501 meanLossQlbl: 5.1973 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 310.7095 meanLossQtgt_sigm: 0.8434\n",
      "Episode: 282 meanReward: 248.4062 meanLoss: 327.5249 meanLossQlbl: 4.7648 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 321.8145 meanLossQtgt_sigm: 0.9456\n",
      "Episode: 283 meanReward: 233.1875 meanLoss: 360.9575 meanLossQlbl: 5.7629 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 354.0004 meanLossQtgt_sigm: 1.1943\n",
      "Episode: 284 meanReward: 226.0625 meanLoss: 13.4693 meanLossQlbl: 2.0005 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.4204 meanLossQtgt_sigm: 0.0483\n",
      "Episode: 285 meanReward: 228.2500 meanLoss: 39.3827 meanLossQlbl: 0.3657 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 38.8938 meanLossQtgt_sigm: 0.1231\n",
      "Episode: 286 meanReward: 224.5000 meanLoss: 180.2837 meanLossQlbl: 0.9088 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 178.7184 meanLossQtgt_sigm: 0.6565\n",
      "Episode: 287 meanReward: 224.2812 meanLoss: 317.4598 meanLossQlbl: 0.3521 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 315.9306 meanLossQtgt_sigm: 1.1771\n",
      "Episode: 288 meanReward: 229.1250 meanLoss: 23.5020 meanLossQlbl: 1.4496 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.9842 meanLossQtgt_sigm: 0.0682\n",
      "Episode: 289 meanReward: 238.8125 meanLoss: 9.9760 meanLossQlbl: 0.1256 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.8155 meanLossQtgt_sigm: 0.0348\n",
      "Episode: 290 meanReward: 245.7812 meanLoss: 15.0347 meanLossQlbl: 0.0142 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.9743 meanLossQtgt_sigm: 0.0463\n",
      "Episode: 291 meanReward: 257.7812 meanLoss: 14.4590 meanLossQlbl: 0.0204 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.3936 meanLossQtgt_sigm: 0.0450\n",
      "Episode: 292 meanReward: 254.7188 meanLoss: 36.0225 meanLossQlbl: 0.4693 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.4527 meanLossQtgt_sigm: 0.1005\n",
      "Episode: 293 meanReward: 257.6875 meanLoss: 14.1114 meanLossQlbl: 0.0550 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.9848 meanLossQtgt_sigm: 0.0716\n",
      "Episode: 294 meanReward: 259.0938 meanLoss: 16.5628 meanLossQlbl: 0.1414 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.3370 meanLossQtgt_sigm: 0.0844\n",
      "Episode: 295 meanReward: 274.3125 meanLoss: 4.5865 meanLossQlbl: 0.1332 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.4317 meanLossQtgt_sigm: 0.0215\n",
      "Episode: 296 meanReward: 263.2500 meanLoss: 43.3157 meanLossQlbl: 1.0472 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 42.1342 meanLossQtgt_sigm: 0.1344\n",
      "Episode: 297 meanReward: 252.9062 meanLoss: 11.7071 meanLossQlbl: 0.1514 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.4898 meanLossQtgt_sigm: 0.0659\n",
      "Episode: 298 meanReward: 253.4688 meanLoss: 88.4306 meanLossQlbl: 4.2766 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 83.8985 meanLossQtgt_sigm: 0.2555\n",
      "Episode: 299 meanReward: 256.2188 meanLoss: 60.0436 meanLossQlbl: 1.6107 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 58.2514 meanLossQtgt_sigm: 0.1815\n",
      "Episode: 300 meanReward: 267.5312 meanLoss: 13.7566 meanLossQlbl: 0.1208 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.5961 meanLossQtgt_sigm: 0.0397\n",
      "Episode: 301 meanReward: 264.8125 meanLoss: 309.1403 meanLossQlbl: 0.3145 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 307.9721 meanLossQtgt_sigm: 0.8537\n",
      "Episode: 302 meanReward: 262.9375 meanLoss: 356.5135 meanLossQlbl: 2.0904 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 353.3983 meanLossQtgt_sigm: 1.0248\n",
      "Episode: 303 meanReward: 264.4375 meanLoss: 16.7448 meanLossQlbl: 0.6819 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.0096 meanLossQtgt_sigm: 0.0533\n",
      "Episode: 304 meanReward: 273.9375 meanLoss: 15.6149 meanLossQlbl: 0.0898 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.4794 meanLossQtgt_sigm: 0.0458\n",
      "Episode: 305 meanReward: 283.3438 meanLoss: 19.3389 meanLossQlbl: 0.0772 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.2088 meanLossQtgt_sigm: 0.0529\n",
      "Episode: 306 meanReward: 291.5000 meanLoss: 19.1364 meanLossQlbl: 0.1463 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.9379 meanLossQtgt_sigm: 0.0522\n",
      "Episode: 307 meanReward: 277.3750 meanLoss: 184.4073 meanLossQlbl: 0.4936 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 183.3867 meanLossQtgt_sigm: 0.5271\n",
      "Episode: 308 meanReward: 263.7188 meanLoss: 99.1570 meanLossQlbl: 0.1778 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 98.6449 meanLossQtgt_sigm: 0.3343\n",
      "Episode: 309 meanReward: 248.4375 meanLoss: 227.7099 meanLossQlbl: 0.8097 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 226.1649 meanLossQtgt_sigm: 0.7352\n",
      "Episode: 310 meanReward: 233.1875 meanLoss: 199.5447 meanLossQlbl: 2.5379 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 196.2457 meanLossQtgt_sigm: 0.7611\n",
      "Episode: 311 meanReward: 222.0312 meanLoss: 20.7853 meanLossQlbl: 1.4120 meanLossQlbl_sigm: 0.0249 meanLossQtgt: 19.2878 meanLossQtgt_sigm: 0.0607\n",
      "Episode: 312 meanReward: 209.3438 meanLoss: 11.0113 meanLossQlbl: 0.2571 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.6805 meanLossQtgt_sigm: 0.0737\n",
      "Episode: 313 meanReward: 211.4688 meanLoss: 4.3201 meanLossQlbl: 0.0150 meanLossQlbl_sigm: 0.0031 meanLossQtgt: 4.2900 meanLossQtgt_sigm: 0.0120\n",
      "Episode: 314 meanReward: 213.7812 meanLoss: 3.8374 meanLossQlbl: 0.0764 meanLossQlbl_sigm: 0.0024 meanLossQtgt: 3.7304 meanLossQtgt_sigm: 0.0282\n",
      "Episode: 315 meanReward: 216.1250 meanLoss: 2.2256 meanLossQlbl: 0.2457 meanLossQlbl_sigm: 0.0305 meanLossQtgt: 1.8898 meanLossQtgt_sigm: 0.0596\n",
      "Episode: 316 meanReward: 208.2500 meanLoss: 5.1451 meanLossQlbl: 0.0225 meanLossQlbl_sigm: 0.0257 meanLossQtgt: 5.0300 meanLossQtgt_sigm: 0.0668\n",
      "Episode: 317 meanReward: 205.5312 meanLoss: 16.0575 meanLossQlbl: 0.3799 meanLossQlbl_sigm: 0.0029 meanLossQtgt: 15.5811 meanLossQtgt_sigm: 0.0936\n",
      "Episode: 318 meanReward: 208.5312 meanLoss: 4.5267 meanLossQlbl: 0.1699 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.3239 meanLossQtgt_sigm: 0.0328\n",
      "Episode: 319 meanReward: 223.8750 meanLoss: 2.0764 meanLossQlbl: 0.0549 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.0130 meanLossQtgt_sigm: 0.0085\n",
      "Episode: 320 meanReward: 231.5312 meanLoss: 15.3798 meanLossQlbl: 0.1354 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.1989 meanLossQtgt_sigm: 0.0456\n",
      "Episode: 321 meanReward: 216.5312 meanLoss: 237.5447 meanLossQlbl: 2.5326 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 234.2860 meanLossQtgt_sigm: 0.7261\n",
      "Episode: 322 meanReward: 205.0312 meanLoss: 44.4635 meanLossQlbl: 0.8403 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.4582 meanLossQtgt_sigm: 0.1650\n",
      "Episode: 323 meanReward: 190.7188 meanLoss: 187.4717 meanLossQlbl: 0.3566 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 186.5468 meanLossQtgt_sigm: 0.5683\n",
      "Episode: 324 meanReward: 187.3125 meanLoss: 23.7387 meanLossQlbl: 0.2773 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.3484 meanLossQtgt_sigm: 0.1130\n",
      "Episode: 325 meanReward: 183.9062 meanLoss: 96.5574 meanLossQlbl: 0.1347 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 96.1147 meanLossQtgt_sigm: 0.3080\n",
      "Episode: 326 meanReward: 182.2500 meanLoss: 32.8241 meanLossQlbl: 1.4500 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.2411 meanLossQtgt_sigm: 0.1331\n",
      "Episode: 327 meanReward: 168.7500 meanLoss: 63.5843 meanLossQlbl: 2.2086 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 61.1277 meanLossQtgt_sigm: 0.2480\n",
      "Episode: 328 meanReward: 165.7812 meanLoss: 94.8051 meanLossQlbl: 1.6654 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 92.8002 meanLossQtgt_sigm: 0.3395\n",
      "Episode: 329 meanReward: 164.5625 meanLoss: 37.0327 meanLossQlbl: 0.6798 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.2201 meanLossQtgt_sigm: 0.1328\n",
      "Episode: 330 meanReward: 165.1875 meanLoss: 51.1658 meanLossQlbl: 0.7213 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 50.2148 meanLossQtgt_sigm: 0.2297\n",
      "Episode: 331 meanReward: 172.0938 meanLoss: 18.7935 meanLossQlbl: 0.1845 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5472 meanLossQtgt_sigm: 0.0619\n",
      "Episode: 332 meanReward: 156.9375 meanLoss: 174.0670 meanLossQlbl: 0.1618 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 173.2767 meanLossQtgt_sigm: 0.6285\n",
      "Episode: 333 meanReward: 157.5938 meanLoss: 67.6262 meanLossQlbl: 2.5922 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 64.6974 meanLossQtgt_sigm: 0.3366\n",
      "Episode: 334 meanReward: 157.6250 meanLoss: 193.6718 meanLossQlbl: 0.3807 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 192.6043 meanLossQtgt_sigm: 0.6868\n",
      "Episode: 335 meanReward: 142.4688 meanLoss: 335.7061 meanLossQlbl: 0.0864 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 334.4025 meanLossQtgt_sigm: 1.2171\n",
      "Episode: 336 meanReward: 127.5312 meanLoss: 221.2299 meanLossQlbl: 0.1143 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 220.1629 meanLossQtgt_sigm: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 337 meanReward: 112.3750 meanLoss: 138.5301 meanLossQlbl: 0.0385 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 137.8032 meanLossQtgt_sigm: 0.6885\n",
      "Episode: 338 meanReward: 102.6250 meanLoss: 12.7394 meanLossQlbl: 0.7641 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.9361 meanLossQtgt_sigm: 0.0392\n",
      "Episode: 339 meanReward: 107.9062 meanLoss: 10.6703 meanLossQlbl: 0.3005 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.3161 meanLossQtgt_sigm: 0.0538\n",
      "Episode: 340 meanReward: 112.0625 meanLoss: 19.7199 meanLossQlbl: 0.9436 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.7103 meanLossQtgt_sigm: 0.0660\n",
      "Episode: 341 meanReward: 113.8438 meanLoss: 61.5299 meanLossQlbl: 0.6273 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 60.6541 meanLossQtgt_sigm: 0.2485\n",
      "Episode: 342 meanReward: 126.0312 meanLoss: 12.1106 meanLossQlbl: 0.4989 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.5815 meanLossQtgt_sigm: 0.0302\n",
      "Episode: 343 meanReward: 122.3125 meanLoss: 131.6662 meanLossQlbl: 2.2036 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 128.9348 meanLossQtgt_sigm: 0.5277\n",
      "Episode: 344 meanReward: 119.8750 meanLoss: 216.8828 meanLossQlbl: 1.4873 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 214.5614 meanLossQtgt_sigm: 0.8341\n",
      "Episode: 345 meanReward: 117.4688 meanLoss: 277.2075 meanLossQlbl: 0.1683 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 275.9933 meanLossQtgt_sigm: 1.0459\n",
      "Episode: 346 meanReward: 115.3125 meanLoss: 178.0362 meanLossQlbl: 0.5081 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 176.8241 meanLossQtgt_sigm: 0.7040\n",
      "Episode: 347 meanReward: 118.3750 meanLoss: 16.2136 meanLossQlbl: 0.8891 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.2643 meanLossQtgt_sigm: 0.0602\n",
      "Episode: 348 meanReward: 127.3125 meanLoss: 12.9990 meanLossQlbl: 0.6425 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.3250 meanLossQtgt_sigm: 0.0315\n",
      "Episode: 349 meanReward: 125.0000 meanLoss: 191.9985 meanLossQlbl: 0.3054 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 191.0238 meanLossQtgt_sigm: 0.6694\n",
      "Episode: 350 meanReward: 130.8750 meanLoss: 25.2366 meanLossQlbl: 0.3680 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.7859 meanLossQtgt_sigm: 0.0827\n",
      "Episode: 351 meanReward: 118.9688 meanLoss: 55.5611 meanLossQlbl: 0.1490 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.2296 meanLossQtgt_sigm: 0.1825\n",
      "Episode: 352 meanReward: 109.2188 meanLoss: 24.3026 meanLossQlbl: 0.1676 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.0405 meanLossQtgt_sigm: 0.0944\n",
      "Episode: 353 meanReward: 111.2188 meanLoss: 51.4390 meanLossQlbl: 0.0787 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 51.1528 meanLossQtgt_sigm: 0.2075\n",
      "Episode: 354 meanReward: 110.8750 meanLoss: 46.5218 meanLossQlbl: 0.5082 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 45.8559 meanLossQtgt_sigm: 0.1577\n",
      "Episode: 355 meanReward: 121.7812 meanLoss: 8.6622 meanLossQlbl: 0.1392 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.4857 meanLossQtgt_sigm: 0.0373\n",
      "Episode: 356 meanReward: 119.4062 meanLoss: 56.3307 meanLossQlbl: 0.6788 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.3856 meanLossQtgt_sigm: 0.2663\n",
      "Episode: 357 meanReward: 122.8125 meanLoss: 22.1054 meanLossQlbl: 0.3667 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.6524 meanLossQtgt_sigm: 0.0863\n",
      "Episode: 358 meanReward: 134.6250 meanLoss: 7.1024 meanLossQlbl: 0.0983 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.9737 meanLossQtgt_sigm: 0.0303\n",
      "Episode: 359 meanReward: 132.8750 meanLoss: 140.7827 meanLossQlbl: 1.7651 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 138.4915 meanLossQtgt_sigm: 0.5262\n",
      "Episode: 360 meanReward: 131.6875 meanLoss: 162.9631 meanLossQlbl: 0.9412 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 161.2634 meanLossQtgt_sigm: 0.7585\n",
      "Episode: 361 meanReward: 132.0625 meanLoss: 27.5020 meanLossQlbl: 1.2364 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.1568 meanLossQtgt_sigm: 0.1088\n",
      "Episode: 362 meanReward: 133.5312 meanLoss: 30.5024 meanLossQlbl: 0.4866 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.8829 meanLossQtgt_sigm: 0.1329\n",
      "Episode: 363 meanReward: 128.5625 meanLoss: 20.4568 meanLossQlbl: 0.3116 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.0517 meanLossQtgt_sigm: 0.0936\n",
      "Episode: 364 meanReward: 132.6562 meanLoss: 27.2432 meanLossQlbl: 0.1258 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.0034 meanLossQtgt_sigm: 0.1140\n",
      "Episode: 365 meanReward: 136.4062 meanLoss: 23.5592 meanLossQlbl: 0.2172 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.2450 meanLossQtgt_sigm: 0.0970\n",
      "Episode: 366 meanReward: 139.4062 meanLoss: 39.3082 meanLossQlbl: 0.1576 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 38.9909 meanLossQtgt_sigm: 0.1597\n",
      "Episode: 367 meanReward: 143.6875 meanLoss: 22.0533 meanLossQlbl: 0.1883 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.7727 meanLossQtgt_sigm: 0.0923\n",
      "Episode: 368 meanReward: 147.2500 meanLoss: 20.3177 meanLossQlbl: 0.0835 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.1392 meanLossQtgt_sigm: 0.0950\n",
      "Episode: 369 meanReward: 154.2812 meanLoss: 14.3058 meanLossQlbl: 0.2542 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.9911 meanLossQtgt_sigm: 0.0605\n",
      "Episode: 370 meanReward: 151.3125 meanLoss: 42.4198 meanLossQlbl: 0.3644 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 41.8784 meanLossQtgt_sigm: 0.1771\n",
      "Episode: 371 meanReward: 148.7500 meanLoss: 23.8473 meanLossQlbl: 1.6251 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.1487 meanLossQtgt_sigm: 0.0735\n",
      "Episode: 372 meanReward: 145.5625 meanLoss: 42.5705 meanLossQlbl: 0.9172 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 41.4831 meanLossQtgt_sigm: 0.1702\n",
      "Episode: 373 meanReward: 143.8125 meanLoss: 108.8188 meanLossQlbl: 7.4321 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 100.9178 meanLossQtgt_sigm: 0.4689\n",
      "Episode: 374 meanReward: 131.6562 meanLoss: 260.5129 meanLossQlbl: 4.8507 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 254.5982 meanLossQtgt_sigm: 1.0640\n",
      "Episode: 375 meanReward: 136.0000 meanLoss: 35.1572 meanLossQlbl: 1.3215 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.7097 meanLossQtgt_sigm: 0.1260\n",
      "Episode: 376 meanReward: 139.9062 meanLoss: 32.8428 meanLossQlbl: 0.2444 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.4722 meanLossQtgt_sigm: 0.1262\n",
      "Episode: 377 meanReward: 143.3125 meanLoss: 14.3921 meanLossQlbl: 0.4281 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.8849 meanLossQtgt_sigm: 0.0791\n",
      "Episode: 378 meanReward: 147.5312 meanLoss: 9.5406 meanLossQlbl: 0.5692 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.9227 meanLossQtgt_sigm: 0.0487\n",
      "Episode: 379 meanReward: 146.7188 meanLoss: 12.3207 meanLossQlbl: 0.3316 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.9244 meanLossQtgt_sigm: 0.0647\n",
      "Episode: 380 meanReward: 139.2500 meanLoss: 39.2198 meanLossQlbl: 1.8785 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 37.1708 meanLossQtgt_sigm: 0.1705\n",
      "Episode: 381 meanReward: 142.0000 meanLoss: 44.4560 meanLossQlbl: 0.7719 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.5225 meanLossQtgt_sigm: 0.1616\n",
      "Episode: 382 meanReward: 136.5938 meanLoss: 28.1490 meanLossQlbl: 1.0513 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.9812 meanLossQtgt_sigm: 0.1165\n",
      "Episode: 383 meanReward: 148.5000 meanLoss: 6.2156 meanLossQlbl: 0.3624 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.8422 meanLossQtgt_sigm: 0.0110\n",
      "Episode: 384 meanReward: 158.2500 meanLoss: 5.9958 meanLossQlbl: 0.2325 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.7408 meanLossQtgt_sigm: 0.0225\n",
      "Episode: 385 meanReward: 161.4062 meanLoss: 37.8286 meanLossQlbl: 0.4124 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 37.2991 meanLossQtgt_sigm: 0.1170\n",
      "Episode: 386 meanReward: 161.8125 meanLoss: 15.6751 meanLossQlbl: 0.4967 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.1012 meanLossQtgt_sigm: 0.0773\n",
      "Episode: 387 meanReward: 165.2188 meanLoss: 4.2606 meanLossQlbl: 0.1846 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.0650 meanLossQtgt_sigm: 0.0110\n",
      "Episode: 388 meanReward: 164.6250 meanLoss: 336.2865 meanLossQlbl: 0.2467 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 335.1415 meanLossQtgt_sigm: 0.8983\n",
      "Episode: 389 meanReward: 159.3438 meanLoss: 497.3986 meanLossQlbl: 1.1592 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 494.7708 meanLossQtgt_sigm: 1.4685\n",
      "Episode: 390 meanReward: 160.0000 meanLoss: 11.3729 meanLossQlbl: 0.5275 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.8034 meanLossQtgt_sigm: 0.0420\n",
      "Episode: 391 meanReward: 175.2500 meanLoss: 22.0009 meanLossQlbl: 0.3008 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.6471 meanLossQtgt_sigm: 0.0530\n",
      "Episode: 392 meanReward: 190.4688 meanLoss: 18.4499 meanLossQlbl: 0.0309 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3674 meanLossQtgt_sigm: 0.0516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 393 meanReward: 201.6562 meanLoss: 18.5665 meanLossQlbl: 0.3003 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2155 meanLossQtgt_sigm: 0.0506\n",
      "Episode: 394 meanReward: 198.8438 meanLoss: 302.5993 meanLossQlbl: 0.3387 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 301.4079 meanLossQtgt_sigm: 0.8527\n",
      "Episode: 395 meanReward: 194.1875 meanLoss: 489.9209 meanLossQlbl: 0.1253 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 488.2701 meanLossQtgt_sigm: 1.5256\n",
      "Episode: 396 meanReward: 190.0000 meanLoss: 444.9995 meanLossQlbl: 1.9461 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 441.5470 meanLossQtgt_sigm: 1.5064\n",
      "Episode: 397 meanReward: 186.7500 meanLoss: 86.4650 meanLossQlbl: 2.5459 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 83.6084 meanLossQtgt_sigm: 0.3107\n",
      "Episode: 398 meanReward: 188.2500 meanLoss: 33.3212 meanLossQlbl: 0.5963 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.6188 meanLossQtgt_sigm: 0.1061\n",
      "Episode: 399 meanReward: 199.1250 meanLoss: 10.4269 meanLossQlbl: 0.1072 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2817 meanLossQtgt_sigm: 0.0379\n",
      "Episode: 400 meanReward: 207.3750 meanLoss: 23.0250 meanLossQlbl: 0.0341 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.9272 meanLossQtgt_sigm: 0.0637\n",
      "Episode: 401 meanReward: 203.8750 meanLoss: 28.8644 meanLossQlbl: 0.4126 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.3486 meanLossQtgt_sigm: 0.1033\n",
      "Episode: 402 meanReward: 201.6250 meanLoss: 153.0574 meanLossQlbl: 0.3136 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 152.1408 meanLossQtgt_sigm: 0.6030\n",
      "Episode: 403 meanReward: 203.0625 meanLoss: 28.5025 meanLossQlbl: 1.0267 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.3878 meanLossQtgt_sigm: 0.0881\n",
      "Episode: 404 meanReward: 207.4062 meanLoss: 26.4282 meanLossQlbl: 0.1494 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.1935 meanLossQtgt_sigm: 0.0853\n",
      "Episode: 405 meanReward: 222.6562 meanLoss: 7.5436 meanLossQlbl: 0.0993 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.4157 meanLossQtgt_sigm: 0.0286\n",
      "Episode: 406 meanReward: 237.8750 meanLoss: 17.1894 meanLossQlbl: 0.0637 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0760 meanLossQtgt_sigm: 0.0498\n",
      "Episode: 407 meanReward: 248.4062 meanLoss: 17.7500 meanLossQlbl: 0.2737 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.4269 meanLossQtgt_sigm: 0.0494\n",
      "Episode: 408 meanReward: 259.6250 meanLoss: 17.5535 meanLossQlbl: 0.1409 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.3626 meanLossQtgt_sigm: 0.0501\n",
      "Episode: 409 meanReward: 258.0938 meanLoss: 109.1344 meanLossQlbl: 1.1559 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 107.6700 meanLossQtgt_sigm: 0.3086\n",
      "Episode: 410 meanReward: 258.4688 meanLoss: 9.3024 meanLossQlbl: 0.5906 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 8.6791 meanLossQtgt_sigm: 0.0325\n",
      "Episode: 411 meanReward: 254.3750 meanLoss: 84.2534 meanLossQlbl: 0.5825 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 83.2490 meanLossQtgt_sigm: 0.4219\n",
      "Episode: 412 meanReward: 259.2500 meanLoss: 20.5244 meanLossQlbl: 1.0714 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.3801 meanLossQtgt_sigm: 0.0729\n",
      "Episode: 413 meanReward: 270.2500 meanLoss: 2.3385 meanLossQlbl: 0.2521 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.0785 meanLossQtgt_sigm: 0.0079\n",
      "Episode: 414 meanReward: 267.3125 meanLoss: 224.0261 meanLossQlbl: 0.6724 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 222.6380 meanLossQtgt_sigm: 0.7157\n",
      "Episode: 415 meanReward: 252.7500 meanLoss: 124.9701 meanLossQlbl: 14.0257 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 110.5194 meanLossQtgt_sigm: 0.4249\n",
      "Episode: 416 meanReward: 252.7500 meanLoss: 15.7358 meanLossQlbl: 0.2830 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.4094 meanLossQtgt_sigm: 0.0434\n",
      "Episode: 417 meanReward: 251.3438 meanLoss: 58.3497 meanLossQlbl: 0.8004 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 57.3857 meanLossQtgt_sigm: 0.1636\n",
      "Episode: 418 meanReward: 254.0625 meanLoss: 15.1299 meanLossQlbl: 0.6567 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.4116 meanLossQtgt_sigm: 0.0617\n",
      "Episode: 419 meanReward: 254.0625 meanLoss: 12.7108 meanLossQlbl: 0.0241 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.6444 meanLossQtgt_sigm: 0.0423\n",
      "Episode: 420 meanReward: 269.0625 meanLoss: 18.8437 meanLossQlbl: 0.0500 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.7417 meanLossQtgt_sigm: 0.0519\n",
      "Episode: 421 meanReward: 272.0938 meanLoss: 67.1929 meanLossQlbl: 0.7166 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 66.2685 meanLossQtgt_sigm: 0.2078\n",
      "Episode: 422 meanReward: 261.0938 meanLoss: 32.8617 meanLossQlbl: 0.4608 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.2770 meanLossQtgt_sigm: 0.1238\n",
      "Episode: 423 meanReward: 246.7500 meanLoss: 114.2985 meanLossQlbl: 0.3256 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 113.5258 meanLossQtgt_sigm: 0.4471\n",
      "Episode: 424 meanReward: 234.7500 meanLoss: 40.9302 meanLossQlbl: 0.9914 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.7955 meanLossQtgt_sigm: 0.1432\n",
      "Episode: 425 meanReward: 234.7500 meanLoss: 7.2590 meanLossQlbl: 0.2208 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.0069 meanLossQtgt_sigm: 0.0314\n",
      "Episode: 426 meanReward: 249.8438 meanLoss: 12.5806 meanLossQlbl: 0.2486 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.2904 meanLossQtgt_sigm: 0.0417\n",
      "Episode: 427 meanReward: 265.1250 meanLoss: 13.9452 meanLossQlbl: 0.1718 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.7288 meanLossQtgt_sigm: 0.0447\n",
      "Episode: 428 meanReward: 280.3750 meanLoss: 16.7218 meanLossQlbl: 0.0421 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.6307 meanLossQtgt_sigm: 0.0490\n",
      "Episode: 429 meanReward: 285.9062 meanLoss: 28.5198 meanLossQlbl: 0.1982 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.2290 meanLossQtgt_sigm: 0.0926\n",
      "Episode: 430 meanReward: 282.1250 meanLoss: 132.7385 meanLossQlbl: 3.1795 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 129.1056 meanLossQtgt_sigm: 0.4535\n",
      "Episode: 431 meanReward: 267.0625 meanLoss: 231.3643 meanLossQlbl: 2.7255 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 227.9359 meanLossQtgt_sigm: 0.7030\n",
      "Episode: 432 meanReward: 270.1875 meanLoss: 11.2896 meanLossQlbl: 0.3646 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.8896 meanLossQtgt_sigm: 0.0354\n",
      "Episode: 433 meanReward: 269.9375 meanLoss: 58.7843 meanLossQlbl: 0.5086 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 58.0939 meanLossQtgt_sigm: 0.1818\n",
      "Episode: 434 meanReward: 269.8438 meanLoss: 105.1444 meanLossQlbl: 9.7759 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 94.9243 meanLossQtgt_sigm: 0.4442\n",
      "Episode: 435 meanReward: 272.6250 meanLoss: 21.6284 meanLossQlbl: 0.8432 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.7090 meanLossQtgt_sigm: 0.0762\n",
      "Episode: 436 meanReward: 280.9688 meanLoss: 8.7072 meanLossQlbl: 0.0935 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.5809 meanLossQtgt_sigm: 0.0328\n",
      "Episode: 437 meanReward: 269.2500 meanLoss: 80.8075 meanLossQlbl: 0.6877 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 79.9089 meanLossQtgt_sigm: 0.2109\n",
      "Episode: 438 meanReward: 255.5625 meanLoss: 85.3806 meanLossQlbl: 0.4451 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 84.6205 meanLossQtgt_sigm: 0.3150\n",
      "Episode: 439 meanReward: 247.2188 meanLoss: 21.4720 meanLossQlbl: 0.9572 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.4447 meanLossQtgt_sigm: 0.0701\n",
      "Episode: 440 meanReward: 247.2188 meanLoss: 9.9772 meanLossQlbl: 0.0399 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.8998 meanLossQtgt_sigm: 0.0375\n",
      "Episode: 441 meanReward: 249.7188 meanLoss: 55.3315 meanLossQlbl: 0.7809 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 54.3951 meanLossQtgt_sigm: 0.1555\n",
      "Episode: 442 meanReward: 260.3125 meanLoss: 8.7091 meanLossQlbl: 0.3436 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.3314 meanLossQtgt_sigm: 0.0341\n",
      "Episode: 443 meanReward: 275.0312 meanLoss: 19.4833 meanLossQlbl: 0.1045 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.3257 meanLossQtgt_sigm: 0.0530\n",
      "Episode: 444 meanReward: 283.6875 meanLoss: 18.6880 meanLossQlbl: 0.1032 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5329 meanLossQtgt_sigm: 0.0519\n",
      "Episode: 445 meanReward: 285.0000 meanLoss: 17.8573 meanLossQlbl: 0.0584 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7480 meanLossQtgt_sigm: 0.0509\n",
      "Episode: 446 meanReward: 299.7812 meanLoss: 14.4062 meanLossQlbl: 0.2861 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.0752 meanLossQtgt_sigm: 0.0449\n",
      "Episode: 447 meanReward: 314.3438 meanLoss: 13.2290 meanLossQlbl: 0.1400 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.0464 meanLossQtgt_sigm: 0.0425\n",
      "Episode: 448 meanReward: 314.3438 meanLoss: 18.4435 meanLossQlbl: 0.0704 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3216 meanLossQtgt_sigm: 0.0515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 449 meanReward: 325.5938 meanLoss: 17.3615 meanLossQlbl: 0.2721 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0400 meanLossQtgt_sigm: 0.0494\n",
      "Episode: 450 meanReward: 321.3438 meanLoss: 106.7128 meanLossQlbl: 1.8193 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 104.5992 meanLossQtgt_sigm: 0.2943\n",
      "Episode: 451 meanReward: 311.4062 meanLoss: 28.4163 meanLossQlbl: 0.3455 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.9661 meanLossQtgt_sigm: 0.1047\n",
      "Episode: 452 meanReward: 296.2188 meanLoss: 290.3668 meanLossQlbl: 1.9414 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 287.5859 meanLossQtgt_sigm: 0.8394\n",
      "Episode: 453 meanReward: 293.1250 meanLoss: 543.4620 meanLossQlbl: 5.7164 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 536.1633 meanLossQtgt_sigm: 1.5823\n",
      "Episode: 454 meanReward: 288.8438 meanLoss: 478.0087 meanLossQlbl: 1.5494 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 474.9526 meanLossQtgt_sigm: 1.5067\n",
      "Episode: 455 meanReward: 289.1875 meanLoss: 83.3444 meanLossQlbl: 4.9762 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 78.1065 meanLossQtgt_sigm: 0.2618\n",
      "Episode: 456 meanReward: 288.5312 meanLoss: 72.5291 meanLossQlbl: 0.8688 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 71.4394 meanLossQtgt_sigm: 0.2209\n",
      "Episode: 457 meanReward: 273.2812 meanLoss: 40.9762 meanLossQlbl: 1.8416 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.0037 meanLossQtgt_sigm: 0.1309\n",
      "Episode: 458 meanReward: 258.1250 meanLoss: 159.1723 meanLossQlbl: 1.2634 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 157.2767 meanLossQtgt_sigm: 0.6321\n",
      "Episode: 459 meanReward: 250.2812 meanLoss: 18.3864 meanLossQlbl: 0.7087 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.6082 meanLossQtgt_sigm: 0.0696\n",
      "Episode: 460 meanReward: 250.2812 meanLoss: 5.3649 meanLossQlbl: 0.3937 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.9462 meanLossQtgt_sigm: 0.0251\n",
      "Episode: 461 meanReward: 251.9062 meanLoss: 20.7075 meanLossQlbl: 0.1675 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.4734 meanLossQtgt_sigm: 0.0666\n",
      "Episode: 462 meanReward: 266.4062 meanLoss: 11.9272 meanLossQlbl: 0.0677 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.8186 meanLossQtgt_sigm: 0.0409\n",
      "Episode: 463 meanReward: 272.7500 meanLoss: 31.9928 meanLossQlbl: 0.3273 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.5656 meanLossQtgt_sigm: 0.0999\n",
      "Episode: 464 meanReward: 262.4062 meanLoss: 15.9263 meanLossQlbl: 0.2048 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.6453 meanLossQtgt_sigm: 0.0762\n",
      "Episode: 465 meanReward: 267.4688 meanLoss: 7.6762 meanLossQlbl: 0.2596 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.3837 meanLossQtgt_sigm: 0.0328\n",
      "Episode: 466 meanReward: 273.8438 meanLoss: 9.8924 meanLossQlbl: 0.6587 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.1850 meanLossQtgt_sigm: 0.0487\n",
      "Episode: 467 meanReward: 281.0312 meanLoss: 4.5315 meanLossQlbl: 0.3683 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.1411 meanLossQtgt_sigm: 0.0221\n",
      "Episode: 468 meanReward: 265.9375 meanLoss: 328.7096 meanLossQlbl: 0.7769 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 327.0432 meanLossQtgt_sigm: 0.8895\n",
      "Episode: 469 meanReward: 262.4375 meanLoss: 533.9689 meanLossQlbl: 2.4940 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 529.9599 meanLossQtgt_sigm: 1.5150\n",
      "Episode: 470 meanReward: 276.1250 meanLoss: 15.7232 meanLossQlbl: 0.6342 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.0349 meanLossQtgt_sigm: 0.0541\n",
      "Episode: 471 meanReward: 271.8125 meanLoss: 79.1673 meanLossQlbl: 0.7648 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 78.1626 meanLossQtgt_sigm: 0.2399\n",
      "Episode: 472 meanReward: 256.9688 meanLoss: 15.6909 meanLossQlbl: 0.7934 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 14.7981 meanLossQtgt_sigm: 0.0993\n",
      "Episode: 473 meanReward: 255.0938 meanLoss: 27.1727 meanLossQlbl: 0.6377 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.4223 meanLossQtgt_sigm: 0.1126\n",
      "Episode: 474 meanReward: 253.2812 meanLoss: 1.4610 meanLossQlbl: 0.0430 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.4104 meanLossQtgt_sigm: 0.0076\n",
      "Episode: 475 meanReward: 241.1875 meanLoss: 61.7999 meanLossQlbl: 3.9213 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 57.7012 meanLossQtgt_sigm: 0.1773\n",
      "Episode: 476 meanReward: 230.0625 meanLoss: 5.8616 meanLossQlbl: 0.2243 meanLossQlbl_sigm: 0.0009 meanLossQtgt: 5.6176 meanLossQtgt_sigm: 0.0187\n",
      "Episode: 477 meanReward: 218.4062 meanLoss: 31.6446 meanLossQlbl: 0.3744 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.1458 meanLossQtgt_sigm: 0.1244\n",
      "Episode: 478 meanReward: 208.7500 meanLoss: 20.1188 meanLossQlbl: 4.0271 meanLossQlbl_sigm: 0.1119 meanLossQtgt: 15.8050 meanLossQtgt_sigm: 0.1749\n",
      "Episode: 479 meanReward: 208.7500 meanLoss: 3.3352 meanLossQlbl: 1.0093 meanLossQlbl_sigm: 0.0215 meanLossQtgt: 2.2822 meanLossQtgt_sigm: 0.0222\n",
      "Episode: 480 meanReward: 194.2188 meanLoss: 36.0537 meanLossQlbl: 1.4098 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 34.4352 meanLossQtgt_sigm: 0.2087\n",
      "Episode: 481 meanReward: 181.9375 meanLoss: 78.5432 meanLossQlbl: 1.6411 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 76.6922 meanLossQtgt_sigm: 0.2098\n",
      "Episode: 482 meanReward: 182.4688 meanLoss: 49.8892 meanLossQlbl: 1.3783 meanLossQlbl_sigm: 0.0021 meanLossQtgt: 48.3395 meanLossQtgt_sigm: 0.1693\n",
      "Episode: 483 meanReward: 180.3750 meanLoss: 8.3864 meanLossQlbl: 0.9619 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.3954 meanLossQtgt_sigm: 0.0290\n",
      "Episode: 484 meanReward: 184.2500 meanLoss: 27.0154 meanLossQlbl: 0.6702 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.2322 meanLossQtgt_sigm: 0.1130\n",
      "Episode: 485 meanReward: 188.7188 meanLoss: 26.5363 meanLossQlbl: 0.2971 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.1317 meanLossQtgt_sigm: 0.1075\n",
      "Episode: 486 meanReward: 191.3438 meanLoss: 33.9533 meanLossQlbl: 0.6964 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.1105 meanLossQtgt_sigm: 0.1463\n",
      "Episode: 487 meanReward: 194.2188 meanLoss: 6.5766 meanLossQlbl: 0.2652 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.2718 meanLossQtgt_sigm: 0.0396\n",
      "Episode: 488 meanReward: 206.8750 meanLoss: 6.6876 meanLossQlbl: 0.0783 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.5800 meanLossQtgt_sigm: 0.0293\n",
      "Episode: 489 meanReward: 221.1875 meanLoss: 25.4638 meanLossQlbl: 0.3416 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.0650 meanLossQtgt_sigm: 0.0572\n",
      "Episode: 490 meanReward: 230.6562 meanLoss: 36.0830 meanLossQlbl: 0.2127 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.7825 meanLossQtgt_sigm: 0.0877\n",
      "Episode: 491 meanReward: 225.6562 meanLoss: 103.5128 meanLossQlbl: 0.4436 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 102.7869 meanLossQtgt_sigm: 0.2823\n",
      "Episode: 492 meanReward: 211.9062 meanLoss: 146.1951 meanLossQlbl: 2.0573 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 143.7414 meanLossQtgt_sigm: 0.3964\n",
      "Episode: 493 meanReward: 218.4062 meanLoss: 10.2307 meanLossQlbl: 0.0650 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.1289 meanLossQtgt_sigm: 0.0368\n",
      "Episode: 494 meanReward: 204.4375 meanLoss: 180.5108 meanLossQlbl: 1.1643 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 178.8647 meanLossQtgt_sigm: 0.4819\n",
      "Episode: 495 meanReward: 201.2812 meanLoss: 20.0856 meanLossQlbl: 2.5283 meanLossQlbl_sigm: 0.0039 meanLossQtgt: 17.5291 meanLossQtgt_sigm: 0.0243\n",
      "Episode: 496 meanReward: 199.5625 meanLoss: 18.1516 meanLossQlbl: 0.7478 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.3271 meanLossQtgt_sigm: 0.0768\n",
      "Episode: 497 meanReward: 194.1875 meanLoss: 15.1002 meanLossQlbl: 0.3391 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.6754 meanLossQtgt_sigm: 0.0858\n",
      "Episode: 498 meanReward: 190.6875 meanLoss: 13.7526 meanLossQlbl: 0.1304 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.5376 meanLossQtgt_sigm: 0.0847\n",
      "Episode: 499 meanReward: 181.4688 meanLoss: 9.4941 meanLossQlbl: 0.2121 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.2336 meanLossQtgt_sigm: 0.0484\n",
      "Episode: 500 meanReward: 186.0000 meanLoss: 28.4788 meanLossQlbl: 0.3169 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.0562 meanLossQtgt_sigm: 0.1057\n",
      "Episode: 501 meanReward: 193.4062 meanLoss: 17.1392 meanLossQlbl: 0.3413 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7323 meanLossQtgt_sigm: 0.0656\n",
      "Episode: 502 meanReward: 192.0000 meanLoss: 17.3186 meanLossQlbl: 0.1721 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0960 meanLossQtgt_sigm: 0.0505\n",
      "Episode: 503 meanReward: 190.8438 meanLoss: 153.5650 meanLossQlbl: 0.3628 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 152.7703 meanLossQtgt_sigm: 0.4319\n",
      "Episode: 504 meanReward: 205.6875 meanLoss: 18.0528 meanLossQlbl: 0.1430 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8600 meanLossQtgt_sigm: 0.0497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 505 meanReward: 211.1562 meanLoss: 36.0566 meanLossQlbl: 0.1683 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.7919 meanLossQtgt_sigm: 0.0964\n",
      "Episode: 506 meanReward: 212.9688 meanLoss: 14.7717 meanLossQlbl: 0.1638 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5630 meanLossQtgt_sigm: 0.0449\n",
      "Episode: 507 meanReward: 214.4375 meanLoss: 448.3215 meanLossQlbl: 224.9740 meanLossQlbl_sigm: 0.3496 meanLossQtgt: 222.5566 meanLossQtgt_sigm: 0.4413\n",
      "Episode: 508 meanReward: 217.1875 meanLoss: 72.1639 meanLossQlbl: 27.9076 meanLossQlbl_sigm: 0.1029 meanLossQtgt: 44.0022 meanLossQtgt_sigm: 0.1513\n",
      "Episode: 509 meanReward: 213.6875 meanLoss: 116.7195 meanLossQlbl: 2.9293 meanLossQlbl_sigm: 0.0072 meanLossQtgt: 113.5731 meanLossQtgt_sigm: 0.2099\n",
      "Episode: 510 meanReward: 208.0000 meanLoss: 108.0712 meanLossQlbl: 1.3680 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 106.2301 meanLossQtgt_sigm: 0.4730\n",
      "Episode: 511 meanReward: 192.7500 meanLoss: 156.8881 meanLossQlbl: 2.9252 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 153.2759 meanLossQtgt_sigm: 0.6870\n",
      "Episode: 512 meanReward: 192.1562 meanLoss: 85.9296 meanLossQlbl: 4.2439 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 81.3124 meanLossQtgt_sigm: 0.3734\n",
      "Episode: 513 meanReward: 189.5625 meanLoss: 29.3326 meanLossQlbl: 0.8923 meanLossQlbl_sigm: 0.0005 meanLossQtgt: 28.2805 meanLossQtgt_sigm: 0.1593\n",
      "Episode: 514 meanReward: 187.8438 meanLoss: 13.5488 meanLossQlbl: 0.6506 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 12.8235 meanLossQtgt_sigm: 0.0746\n",
      "Episode: 515 meanReward: 185.5938 meanLoss: 3.4082 meanLossQlbl: 0.0408 meanLossQlbl_sigm: 0.0049 meanLossQtgt: 3.3357 meanLossQtgt_sigm: 0.0268\n",
      "Episode: 516 meanReward: 182.9688 meanLoss: 4.2408 meanLossQlbl: 0.1783 meanLossQlbl_sigm: 0.0176 meanLossQtgt: 3.9995 meanLossQtgt_sigm: 0.0454\n",
      "Episode: 517 meanReward: 180.1250 meanLoss: 4.5147 meanLossQlbl: 0.6050 meanLossQlbl_sigm: 0.0601 meanLossQtgt: 3.7737 meanLossQtgt_sigm: 0.0759\n",
      "Episode: 518 meanReward: 180.5000 meanLoss: 11.1485 meanLossQlbl: 2.1360 meanLossQlbl_sigm: 0.0964 meanLossQtgt: 8.8065 meanLossQtgt_sigm: 0.1095\n",
      "Episode: 519 meanReward: 180.3438 meanLoss: 84.2662 meanLossQlbl: 44.0960 meanLossQlbl_sigm: 0.3456 meanLossQtgt: 39.4736 meanLossQtgt_sigm: 0.3510\n",
      "Episode: 520 meanReward: 180.3438 meanLoss: 11.8020 meanLossQlbl: 4.5052 meanLossQlbl_sigm: 0.0215 meanLossQtgt: 7.2521 meanLossQtgt_sigm: 0.0232\n",
      "Episode: 521 meanReward: 181.2812 meanLoss: 18.4130 meanLossQlbl: 0.0243 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3382 meanLossQtgt_sigm: 0.0505\n",
      "Episode: 522 meanReward: 186.9688 meanLoss: 18.2257 meanLossQlbl: 0.0740 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.1038 meanLossQtgt_sigm: 0.0480\n",
      "Episode: 523 meanReward: 199.8125 meanLoss: 16.7990 meanLossQlbl: 0.1962 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5547 meanLossQtgt_sigm: 0.0481\n",
      "Episode: 524 meanReward: 213.5625 meanLoss: 16.8259 meanLossQlbl: 0.0371 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7403 meanLossQtgt_sigm: 0.0485\n",
      "Episode: 525 meanReward: 213.5625 meanLoss: 17.9541 meanLossQlbl: 0.0821 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8225 meanLossQtgt_sigm: 0.0495\n",
      "Episode: 526 meanReward: 227.5312 meanLoss: 18.3311 meanLossQlbl: 0.0902 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.1898 meanLossQtgt_sigm: 0.0511\n",
      "Episode: 527 meanReward: 239.4062 meanLoss: 17.9946 meanLossQlbl: 0.1997 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7445 meanLossQtgt_sigm: 0.0504\n",
      "Episode: 528 meanReward: 251.4688 meanLoss: 18.4105 meanLossQlbl: 0.1569 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2024 meanLossQtgt_sigm: 0.0512\n",
      "Episode: 529 meanReward: 248.5000 meanLoss: 306.3039 meanLossQlbl: 0.8379 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 304.6050 meanLossQtgt_sigm: 0.8610\n",
      "Episode: 530 meanReward: 246.3438 meanLoss: 188.0386 meanLossQlbl: 7.9704 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 179.4210 meanLossQtgt_sigm: 0.6473\n",
      "Episode: 531 meanReward: 255.5625 meanLoss: 6.9914 meanLossQlbl: 0.3845 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.5803 meanLossQtgt_sigm: 0.0266\n",
      "Episode: 532 meanReward: 266.1250 meanLoss: 19.4453 meanLossQlbl: 0.2190 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.1768 meanLossQtgt_sigm: 0.0495\n",
      "Episode: 533 meanReward: 273.9375 meanLoss: 17.2517 meanLossQlbl: 0.0345 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.1673 meanLossQtgt_sigm: 0.0499\n",
      "Episode: 534 meanReward: 275.3438 meanLoss: 16.3986 meanLossQlbl: 0.1226 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.2274 meanLossQtgt_sigm: 0.0486\n",
      "Episode: 535 meanReward: 289.1562 meanLoss: 16.8294 meanLossQlbl: 0.0309 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7492 meanLossQtgt_sigm: 0.0493\n",
      "Episode: 536 meanReward: 289.1562 meanLoss: 16.9576 meanLossQlbl: 0.0223 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8860 meanLossQtgt_sigm: 0.0494\n",
      "Episode: 537 meanReward: 296.1562 meanLoss: 15.0759 meanLossQlbl: 0.0520 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.9778 meanLossQtgt_sigm: 0.0462\n",
      "Episode: 538 meanReward: 296.1562 meanLoss: 11.0553 meanLossQlbl: 0.2105 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.8071 meanLossQtgt_sigm: 0.0377\n",
      "Episode: 539 meanReward: 291.5312 meanLoss: 198.6432 meanLossQlbl: 0.3922 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 197.5507 meanLossQtgt_sigm: 0.7004\n",
      "Episode: 540 meanReward: 299.9062 meanLoss: 10.9579 meanLossQlbl: 0.5443 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.3731 meanLossQtgt_sigm: 0.0404\n",
      "Episode: 541 meanReward: 315.0625 meanLoss: 16.9973 meanLossQlbl: 0.0492 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8986 meanLossQtgt_sigm: 0.0496\n",
      "Episode: 542 meanReward: 330.4062 meanLoss: 16.9477 meanLossQlbl: 0.1045 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7938 meanLossQtgt_sigm: 0.0494\n",
      "Episode: 543 meanReward: 345.6562 meanLoss: 15.9646 meanLossQlbl: 0.2186 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.7009 meanLossQtgt_sigm: 0.0451\n",
      "Episode: 544 meanReward: 360.7812 meanLoss: 17.8567 meanLossQlbl: 0.0979 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7083 meanLossQtgt_sigm: 0.0505\n",
      "Episode: 545 meanReward: 375.6562 meanLoss: 16.0355 meanLossQlbl: 0.1408 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.8474 meanLossQtgt_sigm: 0.0473\n",
      "Episode: 546 meanReward: 374.6562 meanLoss: 294.5201 meanLossQlbl: 0.7087 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 292.9642 meanLossQtgt_sigm: 0.8471\n",
      "Episode: 547 meanReward: 375.8438 meanLoss: 125.7612 meanLossQlbl: 1.0954 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 124.2622 meanLossQtgt_sigm: 0.4036\n",
      "Episode: 548 meanReward: 374.6562 meanLoss: 106.7038 meanLossQlbl: 1.8212 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 104.4043 meanLossQtgt_sigm: 0.4783\n",
      "Episode: 549 meanReward: 376.6875 meanLoss: 32.7751 meanLossQlbl: 0.8506 meanLossQlbl_sigm: 0.0034 meanLossQtgt: 31.7759 meanLossQtgt_sigm: 0.1452\n",
      "Episode: 550 meanReward: 377.2188 meanLoss: 8.9623 meanLossQlbl: 1.9654 meanLossQlbl_sigm: 0.0441 meanLossQtgt: 6.9017 meanLossQtgt_sigm: 0.0511\n",
      "Episode: 551 meanReward: 375.4062 meanLoss: 12.1915 meanLossQlbl: 0.1644 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.9412 meanLossQtgt_sigm: 0.0860\n",
      "Episode: 552 meanReward: 361.0625 meanLoss: 21.1835 meanLossQlbl: 0.2972 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.7093 meanLossQtgt_sigm: 0.1770\n",
      "Episode: 553 meanReward: 350.6250 meanLoss: 10.3402 meanLossQlbl: 0.6565 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.6361 meanLossQtgt_sigm: 0.0476\n",
      "Episode: 554 meanReward: 347.5000 meanLoss: 3.4048 meanLossQlbl: 0.1675 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.2217 meanLossQtgt_sigm: 0.0156\n",
      "Episode: 555 meanReward: 340.0000 meanLoss: 4.3206 meanLossQlbl: 0.0598 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.2324 meanLossQtgt_sigm: 0.0284\n",
      "Episode: 556 meanReward: 340.0000 meanLoss: 6.5606 meanLossQlbl: 0.0265 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.5068 meanLossQtgt_sigm: 0.0272\n",
      "Episode: 557 meanReward: 329.0312 meanLoss: 48.3338 meanLossQlbl: 0.1401 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 48.0451 meanLossQtgt_sigm: 0.1486\n",
      "Episode: 558 meanReward: 315.7812 meanLoss: 20.5937 meanLossQlbl: 0.3538 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.1134 meanLossQtgt_sigm: 0.1264\n",
      "Episode: 559 meanReward: 301.2188 meanLoss: 21.9874 meanLossQlbl: 1.3066 meanLossQlbl_sigm: 0.0636 meanLossQtgt: 20.5236 meanLossQtgt_sigm: 0.0935\n",
      "Episode: 560 meanReward: 287.3125 meanLoss: 58.1643 meanLossQlbl: 7.6811 meanLossQlbl_sigm: 0.0011 meanLossQtgt: 50.3749 meanLossQtgt_sigm: 0.1072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 561 meanReward: 289.1875 meanLoss: 12.8560 meanLossQlbl: 1.1639 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.6469 meanLossQtgt_sigm: 0.0452\n",
      "Episode: 562 meanReward: 296.7812 meanLoss: 6.7953 meanLossQlbl: 1.0023 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.7779 meanLossQtgt_sigm: 0.0152\n",
      "Episode: 563 meanReward: 292.5000 meanLoss: 3.5267 meanLossQlbl: 0.1808 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.3289 meanLossQtgt_sigm: 0.0171\n",
      "Episode: 564 meanReward: 278.7500 meanLoss: 68.3875 meanLossQlbl: 0.3217 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.7835 meanLossQtgt_sigm: 0.2823\n",
      "Episode: 565 meanReward: 267.2812 meanLoss: 17.4094 meanLossQlbl: 0.8389 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.4932 meanLossQtgt_sigm: 0.0773\n",
      "Episode: 566 meanReward: 267.2812 meanLoss: 10.9833 meanLossQlbl: 0.3573 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.5931 meanLossQtgt_sigm: 0.0330\n",
      "Episode: 567 meanReward: 252.5625 meanLoss: 303.3392 meanLossQlbl: 2.5421 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 299.9611 meanLossQtgt_sigm: 0.8360\n",
      "Episode: 568 meanReward: 240.2500 meanLoss: 60.9930 meanLossQlbl: 2.3952 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 58.4248 meanLossQtgt_sigm: 0.1730\n",
      "Episode: 569 meanReward: 240.2500 meanLoss: 1.8597 meanLossQlbl: 0.0592 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.7889 meanLossQtgt_sigm: 0.0116\n",
      "Episode: 570 meanReward: 230.0938 meanLoss: 51.9820 meanLossQlbl: 0.7123 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 51.1257 meanLossQtgt_sigm: 0.1440\n",
      "Episode: 571 meanReward: 245.3438 meanLoss: 8.9423 meanLossQlbl: 0.2145 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.6940 meanLossQtgt_sigm: 0.0338\n",
      "Episode: 572 meanReward: 245.3438 meanLoss: 11.8482 meanLossQlbl: 0.0661 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.7414 meanLossQtgt_sigm: 0.0406\n",
      "Episode: 573 meanReward: 234.5000 meanLoss: 34.5556 meanLossQlbl: 0.6592 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.7733 meanLossQtgt_sigm: 0.1232\n",
      "Episode: 574 meanReward: 234.5000 meanLoss: 7.9759 meanLossQlbl: 0.1309 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.8117 meanLossQtgt_sigm: 0.0333\n",
      "Episode: 575 meanReward: 222.2500 meanLoss: 63.2724 meanLossQlbl: 0.7441 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 62.3284 meanLossQtgt_sigm: 0.1999\n",
      "Episode: 576 meanReward: 209.5312 meanLoss: 27.6327 meanLossQlbl: 0.6410 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.8694 meanLossQtgt_sigm: 0.1223\n",
      "Episode: 577 meanReward: 194.9375 meanLoss: 114.7367 meanLossQlbl: 0.7811 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 113.4586 meanLossQtgt_sigm: 0.4970\n",
      "Episode: 578 meanReward: 199.1562 meanLoss: 17.3526 meanLossQlbl: 0.8456 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.4373 meanLossQtgt_sigm: 0.0697\n",
      "Episode: 579 meanReward: 200.0938 meanLoss: 23.9598 meanLossQlbl: 0.1295 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.7084 meanLossQtgt_sigm: 0.1219\n",
      "Episode: 580 meanReward: 202.6250 meanLoss: 19.8495 meanLossQlbl: 0.4309 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.3146 meanLossQtgt_sigm: 0.1040\n",
      "Episode: 581 meanReward: 202.6875 meanLoss: 8.3798 meanLossQlbl: 0.3495 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.9711 meanLossQtgt_sigm: 0.0593\n",
      "Episode: 582 meanReward: 214.4375 meanLoss: 2.3102 meanLossQlbl: 0.0785 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.2178 meanLossQtgt_sigm: 0.0139\n",
      "Episode: 583 meanReward: 227.5312 meanLoss: 20.8454 meanLossQlbl: 0.1674 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.6236 meanLossQtgt_sigm: 0.0543\n",
      "Episode: 584 meanReward: 230.1562 meanLoss: 76.8971 meanLossQlbl: 0.3979 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 76.2903 meanLossQtgt_sigm: 0.2089\n",
      "Episode: 585 meanReward: 228.4375 meanLoss: 12.2996 meanLossQlbl: 0.4846 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.7321 meanLossQtgt_sigm: 0.0829\n",
      "Episode: 586 meanReward: 231.5625 meanLoss: 5.3516 meanLossQlbl: 0.1062 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.2189 meanLossQtgt_sigm: 0.0265\n",
      "Episode: 587 meanReward: 239.0625 meanLoss: 17.8458 meanLossQlbl: 0.1556 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.6398 meanLossQtgt_sigm: 0.0503\n",
      "Episode: 588 meanReward: 239.0625 meanLoss: 18.8712 meanLossQlbl: 0.3332 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4881 meanLossQtgt_sigm: 0.0500\n",
      "Episode: 589 meanReward: 243.4375 meanLoss: 33.4275 meanLossQlbl: 0.7570 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.5810 meanLossQtgt_sigm: 0.0895\n",
      "Episode: 590 meanReward: 245.3750 meanLoss: 19.0619 meanLossQlbl: 0.9103 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.0653 meanLossQtgt_sigm: 0.0863\n",
      "Episode: 591 meanReward: 259.2188 meanLoss: 3.8444 meanLossQlbl: 0.2636 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.5613 meanLossQtgt_sigm: 0.0195\n",
      "Episode: 592 meanReward: 269.0000 meanLoss: 4.5767 meanLossQlbl: 0.4518 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.1042 meanLossQtgt_sigm: 0.0206\n",
      "Episode: 593 meanReward: 267.0312 meanLoss: 343.0688 meanLossQlbl: 0.0662 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 342.0838 meanLossQtgt_sigm: 0.9188\n",
      "Episode: 594 meanReward: 273.7812 meanLoss: 17.8935 meanLossQlbl: 0.4635 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.3741 meanLossQtgt_sigm: 0.0559\n",
      "Episode: 595 meanReward: 278.0625 meanLoss: 17.9047 meanLossQlbl: 0.0282 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8256 meanLossQtgt_sigm: 0.0509\n",
      "Episode: 596 meanReward: 277.2188 meanLoss: 239.9952 meanLossQlbl: 2.3453 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 236.9316 meanLossQtgt_sigm: 0.7184\n",
      "Episode: 597 meanReward: 273.4375 meanLoss: 117.7779 meanLossQlbl: 1.5759 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 115.8058 meanLossQtgt_sigm: 0.3962\n",
      "Episode: 598 meanReward: 273.4375 meanLoss: 5.6157 meanLossQlbl: 0.5944 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.9983 meanLossQtgt_sigm: 0.0229\n",
      "Episode: 599 meanReward: 275.9062 meanLoss: 68.8598 meanLossQlbl: 2.4286 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 66.2480 meanLossQtgt_sigm: 0.1833\n",
      "Episode: 600 meanReward: 288.2188 meanLoss: 2.6831 meanLossQlbl: 0.1212 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.5466 meanLossQtgt_sigm: 0.0153\n",
      "Episode: 601 meanReward: 288.2188 meanLoss: 19.4182 meanLossQlbl: 0.1333 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.2327 meanLossQtgt_sigm: 0.0522\n",
      "Episode: 602 meanReward: 286.0938 meanLoss: 86.9732 meanLossQlbl: 0.9094 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 85.8362 meanLossQtgt_sigm: 0.2275\n",
      "Episode: 603 meanReward: 271.7500 meanLoss: 20.1749 meanLossQlbl: 0.8684 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.1537 meanLossQtgt_sigm: 0.1528\n",
      "Episode: 604 meanReward: 260.3125 meanLoss: 21.6025 meanLossQlbl: 0.6831 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.8257 meanLossQtgt_sigm: 0.0937\n",
      "Episode: 605 meanReward: 269.5000 meanLoss: 3.1772 meanLossQlbl: 0.2373 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.9280 meanLossQtgt_sigm: 0.0119\n",
      "Episode: 606 meanReward: 256.1562 meanLoss: 89.2274 meanLossQlbl: 1.1323 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 87.8130 meanLossQtgt_sigm: 0.2822\n",
      "Episode: 607 meanReward: 268.4062 meanLoss: 9.3143 meanLossQlbl: 0.6105 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.6724 meanLossQtgt_sigm: 0.0314\n",
      "Episode: 608 meanReward: 272.0000 meanLoss: 45.8717 meanLossQlbl: 0.4019 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 45.3467 meanLossQtgt_sigm: 0.1231\n",
      "Episode: 609 meanReward: 274.5312 meanLoss: 12.4819 meanLossQlbl: 1.1134 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.3103 meanLossQtgt_sigm: 0.0583\n",
      "Episode: 610 meanReward: 274.0625 meanLoss: 6.4395 meanLossQlbl: 0.4737 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.9344 meanLossQtgt_sigm: 0.0314\n",
      "Episode: 611 meanReward: 286.2188 meanLoss: 3.9284 meanLossQlbl: 0.1255 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.7839 meanLossQtgt_sigm: 0.0190\n",
      "Episode: 612 meanReward: 298.8125 meanLoss: 17.8397 meanLossQlbl: 0.0285 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7604 meanLossQtgt_sigm: 0.0507\n",
      "Episode: 613 meanReward: 295.8750 meanLoss: 224.5182 meanLossQlbl: 0.5566 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 223.2917 meanLossQtgt_sigm: 0.6699\n",
      "Episode: 614 meanReward: 295.8750 meanLoss: 4.1448 meanLossQlbl: 0.1017 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.0239 meanLossQtgt_sigm: 0.0192\n",
      "Episode: 615 meanReward: 295.8750 meanLoss: 16.3875 meanLossQlbl: 0.0604 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.2792 meanLossQtgt_sigm: 0.0479\n",
      "Episode: 616 meanReward: 292.7188 meanLoss: 258.1124 meanLossQlbl: 1.4917 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 255.8477 meanLossQtgt_sigm: 0.7730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 617 meanReward: 304.8750 meanLoss: 11.4098 meanLossQlbl: 0.7255 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.6590 meanLossQtgt_sigm: 0.0253\n",
      "Episode: 618 meanReward: 290.1562 meanLoss: 295.8043 meanLossQlbl: 0.6709 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 294.3033 meanLossQtgt_sigm: 0.8301\n",
      "Episode: 619 meanReward: 290.1562 meanLoss: 6.6749 meanLossQlbl: 0.3031 meanLossQlbl_sigm: 0.0004 meanLossQtgt: 6.3477 meanLossQtgt_sigm: 0.0236\n",
      "Episode: 620 meanReward: 290.1562 meanLoss: 19.9078 meanLossQlbl: 0.1732 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.6845 meanLossQtgt_sigm: 0.0502\n",
      "Episode: 621 meanReward: 296.7500 meanLoss: 17.2081 meanLossQlbl: 0.0988 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0618 meanLossQtgt_sigm: 0.0475\n",
      "Episode: 622 meanReward: 294.9062 meanLoss: 113.3076 meanLossQlbl: 0.8717 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 112.1154 meanLossQtgt_sigm: 0.3205\n",
      "Episode: 623 meanReward: 295.6250 meanLoss: 15.7393 meanLossQlbl: 0.0672 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.6249 meanLossQtgt_sigm: 0.0473\n",
      "Episode: 624 meanReward: 299.7500 meanLoss: 15.3324 meanLossQlbl: 0.0775 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.2093 meanLossQtgt_sigm: 0.0457\n",
      "Episode: 625 meanReward: 300.0312 meanLoss: 275.9658 meanLossQlbl: 0.7175 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 274.4500 meanLossQtgt_sigm: 0.7982\n",
      "Episode: 626 meanReward: 300.0312 meanLoss: 16.6206 meanLossQlbl: 0.2581 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.3099 meanLossQtgt_sigm: 0.0526\n",
      "Episode: 627 meanReward: 300.0312 meanLoss: 17.8464 meanLossQlbl: 0.3111 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.4853 meanLossQtgt_sigm: 0.0500\n",
      "Episode: 628 meanReward: 302.7500 meanLoss: 89.7335 meanLossQlbl: 2.6079 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 86.9084 meanLossQtgt_sigm: 0.2171\n",
      "Episode: 629 meanReward: 318.0000 meanLoss: 15.0667 meanLossQlbl: 0.0615 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.9593 meanLossQtgt_sigm: 0.0458\n",
      "Episode: 630 meanReward: 318.0000 meanLoss: 17.0894 meanLossQlbl: 0.1508 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8898 meanLossQtgt_sigm: 0.0488\n",
      "Episode: 631 meanReward: 330.2500 meanLoss: 18.2771 meanLossQlbl: 0.2065 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.0207 meanLossQtgt_sigm: 0.0499\n",
      "Episode: 632 meanReward: 315.0000 meanLoss: 337.4651 meanLossQlbl: 0.0974 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 336.4573 meanLossQtgt_sigm: 0.9103\n",
      "Episode: 633 meanReward: 299.8125 meanLoss: 475.6148 meanLossQlbl: 1.1872 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 472.9638 meanLossQtgt_sigm: 1.4639\n",
      "Episode: 634 meanReward: 296.8750 meanLoss: 289.3102 meanLossQlbl: 1.5010 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 286.6696 meanLossQtgt_sigm: 1.1395\n",
      "Episode: 635 meanReward: 295.9062 meanLoss: 105.1711 meanLossQlbl: 1.7927 meanLossQlbl_sigm: 0.0014 meanLossQtgt: 102.9417 meanLossQtgt_sigm: 0.4352\n",
      "Episode: 636 meanReward: 293.0000 meanLoss: 76.3626 meanLossQlbl: 15.3942 meanLossQlbl_sigm: 0.1086 meanLossQtgt: 60.4290 meanLossQtgt_sigm: 0.4308\n",
      "Episode: 637 meanReward: 279.4062 meanLoss: 152.9550 meanLossQlbl: 3.1186 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 149.2566 meanLossQtgt_sigm: 0.5799\n",
      "Episode: 638 meanReward: 277.4062 meanLoss: 236.1891 meanLossQlbl: 0.8954 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 234.2944 meanLossQtgt_sigm: 0.9993\n",
      "Episode: 639 meanReward: 262.1875 meanLoss: 181.1103 meanLossQlbl: 1.5421 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 178.6564 meanLossQtgt_sigm: 0.9118\n",
      "Episode: 640 meanReward: 271.3125 meanLoss: 7.9458 meanLossQlbl: 0.3418 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.5769 meanLossQtgt_sigm: 0.0271\n",
      "Episode: 641 meanReward: 283.3750 meanLoss: 15.9481 meanLossQlbl: 0.1149 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.7867 meanLossQtgt_sigm: 0.0465\n",
      "Episode: 642 meanReward: 294.7812 meanLoss: 15.6045 meanLossQlbl: 0.0155 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.5426 meanLossQtgt_sigm: 0.0464\n",
      "Episode: 643 meanReward: 294.7812 meanLoss: 14.2847 meanLossQlbl: 0.0568 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.1835 meanLossQtgt_sigm: 0.0444\n",
      "Episode: 644 meanReward: 293.9375 meanLoss: 16.8764 meanLossQlbl: 0.0613 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7653 meanLossQtgt_sigm: 0.0497\n",
      "Episode: 645 meanReward: 293.5312 meanLoss: 271.8902 meanLossQlbl: 1.3827 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 269.7367 meanLossQtgt_sigm: 0.7708\n",
      "Episode: 646 meanReward: 280.5938 meanLoss: 40.7534 meanLossQlbl: 2.3396 meanLossQlbl_sigm: 0.0035 meanLossQtgt: 38.2694 meanLossQtgt_sigm: 0.1408\n",
      "Episode: 647 meanReward: 280.5938 meanLoss: 8.3329 meanLossQlbl: 0.1230 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.1813 meanLossQtgt_sigm: 0.0286\n",
      "Episode: 648 meanReward: 295.4688 meanLoss: 14.3360 meanLossQlbl: 0.1920 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.0998 meanLossQtgt_sigm: 0.0441\n",
      "Episode: 649 meanReward: 284.4062 meanLoss: 52.3723 meanLossQlbl: 0.4842 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 51.7409 meanLossQtgt_sigm: 0.1471\n",
      "Episode: 650 meanReward: 285.9375 meanLoss: 28.8893 meanLossQlbl: 3.2909 meanLossQlbl_sigm: 0.0263 meanLossQtgt: 25.4634 meanLossQtgt_sigm: 0.1086\n",
      "Episode: 651 meanReward: 277.1562 meanLoss: 26.1140 meanLossQlbl: 1.2800 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.7841 meanLossQtgt_sigm: 0.0500\n",
      "Episode: 652 meanReward: 269.0938 meanLoss: 15.4670 meanLossQlbl: 0.4419 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.9671 meanLossQtgt_sigm: 0.0581\n",
      "Episode: 653 meanReward: 254.8125 meanLoss: 70.7176 meanLossQlbl: 0.1055 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 70.2699 meanLossQtgt_sigm: 0.3421\n",
      "Episode: 654 meanReward: 258.2188 meanLoss: 31.9309 meanLossQlbl: 0.4457 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.3925 meanLossQtgt_sigm: 0.0927\n",
      "Episode: 655 meanReward: 256.5000 meanLoss: 15.0200 meanLossQlbl: 0.4374 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5428 meanLossQtgt_sigm: 0.0398\n",
      "Episode: 656 meanReward: 243.4062 meanLoss: 15.1187 meanLossQlbl: 0.5297 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5163 meanLossQtgt_sigm: 0.0728\n",
      "Episode: 657 meanReward: 254.4062 meanLoss: 14.0221 meanLossQlbl: 0.2724 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.7095 meanLossQtgt_sigm: 0.0402\n",
      "Episode: 658 meanReward: 254.4062 meanLoss: 6.3485 meanLossQlbl: 0.4490 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.8848 meanLossQtgt_sigm: 0.0147\n",
      "Episode: 659 meanReward: 239.1875 meanLoss: 306.7066 meanLossQlbl: 0.1583 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 305.6864 meanLossQtgt_sigm: 0.8620\n",
      "Episode: 660 meanReward: 246.6250 meanLoss: 32.7592 meanLossQlbl: 1.0517 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.6357 meanLossQtgt_sigm: 0.0718\n",
      "Episode: 661 meanReward: 235.1562 meanLoss: 21.6432 meanLossQlbl: 2.6737 meanLossQlbl_sigm: 0.0089 meanLossQtgt: 18.9396 meanLossQtgt_sigm: 0.0210\n",
      "Episode: 662 meanReward: 235.1562 meanLoss: 15.3560 meanLossQlbl: 0.0922 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.2173 meanLossQtgt_sigm: 0.0465\n",
      "Episode: 663 meanReward: 235.1562 meanLoss: 17.4082 meanLossQlbl: 0.2225 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.1369 meanLossQtgt_sigm: 0.0487\n",
      "Episode: 664 meanReward: 242.1875 meanLoss: 40.2700 meanLossQlbl: 0.3019 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.8584 meanLossQtgt_sigm: 0.1096\n",
      "Episode: 665 meanReward: 248.4062 meanLoss: 42.7063 meanLossQlbl: 0.5365 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 42.0508 meanLossQtgt_sigm: 0.1190\n",
      "Episode: 666 meanReward: 252.6250 meanLoss: 24.5058 meanLossQlbl: 3.5750 meanLossQlbl_sigm: 0.0034 meanLossQtgt: 20.8997 meanLossQtgt_sigm: 0.0277\n",
      "Episode: 667 meanReward: 260.1562 meanLoss: 25.8453 meanLossQlbl: 0.3663 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.3947 meanLossQtgt_sigm: 0.0843\n",
      "Episode: 668 meanReward: 259.8750 meanLoss: 190.3647 meanLossQlbl: 1.9091 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 187.8035 meanLossQtgt_sigm: 0.6522\n",
      "Episode: 669 meanReward: 265.3750 meanLoss: 44.6593 meanLossQlbl: 0.6995 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.8300 meanLossQtgt_sigm: 0.1298\n",
      "Episode: 670 meanReward: 269.5625 meanLoss: 41.6986 meanLossQlbl: 0.2786 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 41.2802 meanLossQtgt_sigm: 0.1398\n",
      "Episode: 671 meanReward: 271.4375 meanLoss: 75.3879 meanLossQlbl: 1.0928 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 74.0290 meanLossQtgt_sigm: 0.2662\n",
      "Episode: 672 meanReward: 256.8438 meanLoss: 234.3558 meanLossQlbl: 0.0366 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 233.6018 meanLossQtgt_sigm: 0.7175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 673 meanReward: 246.0938 meanLoss: 19.6945 meanLossQlbl: 0.5009 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.1238 meanLossQtgt_sigm: 0.0699\n",
      "Episode: 674 meanReward: 238.2812 meanLoss: 12.4097 meanLossQlbl: 0.1506 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.2042 meanLossQtgt_sigm: 0.0550\n",
      "Episode: 675 meanReward: 223.1875 meanLoss: 82.7740 meanLossQlbl: 0.5795 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 81.7880 meanLossQtgt_sigm: 0.4064\n",
      "Episode: 676 meanReward: 217.8438 meanLoss: 9.1437 meanLossQlbl: 0.8986 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.2127 meanLossQtgt_sigm: 0.0325\n",
      "Episode: 677 meanReward: 225.8750 meanLoss: 7.9904 meanLossQlbl: 0.1953 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.7610 meanLossQtgt_sigm: 0.0341\n",
      "Episode: 678 meanReward: 230.2812 meanLoss: 8.7020 meanLossQlbl: 0.9884 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.6930 meanLossQtgt_sigm: 0.0206\n",
      "Episode: 679 meanReward: 218.8750 meanLoss: 29.7092 meanLossQlbl: 0.8292 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.7818 meanLossQtgt_sigm: 0.0983\n",
      "Episode: 680 meanReward: 212.7500 meanLoss: 15.2773 meanLossQlbl: 0.5795 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.6540 meanLossQtgt_sigm: 0.0438\n",
      "Episode: 681 meanReward: 215.3125 meanLoss: 14.2993 meanLossQlbl: 0.9908 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2524 meanLossQtgt_sigm: 0.0560\n",
      "Episode: 682 meanReward: 223.4688 meanLoss: 25.1036 meanLossQlbl: 0.6626 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.3711 meanLossQtgt_sigm: 0.0698\n",
      "Episode: 683 meanReward: 220.5312 meanLoss: 76.9605 meanLossQlbl: 0.5044 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 76.2502 meanLossQtgt_sigm: 0.2059\n",
      "Episode: 684 meanReward: 228.5938 meanLoss: 9.4169 meanLossQlbl: 0.0844 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.2995 meanLossQtgt_sigm: 0.0330\n",
      "Episode: 685 meanReward: 237.5625 meanLoss: 23.1318 meanLossQlbl: 0.1890 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.8730 meanLossQtgt_sigm: 0.0698\n",
      "Episode: 686 meanReward: 236.9375 meanLoss: 56.5251 meanLossQlbl: 1.2690 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.1162 meanLossQtgt_sigm: 0.1399\n",
      "Episode: 687 meanReward: 223.7188 meanLoss: 92.9814 meanLossQlbl: 2.9926 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 89.5734 meanLossQtgt_sigm: 0.4154\n",
      "Episode: 688 meanReward: 236.8125 meanLoss: 12.5372 meanLossQlbl: 1.0343 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.4788 meanLossQtgt_sigm: 0.0241\n",
      "Episode: 689 meanReward: 230.8750 meanLoss: 72.6863 meanLossQlbl: 1.4825 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 71.0410 meanLossQtgt_sigm: 0.1628\n",
      "Episode: 690 meanReward: 230.8750 meanLoss: 16.8578 meanLossQlbl: 0.2199 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5893 meanLossQtgt_sigm: 0.0487\n",
      "Episode: 691 meanReward: 246.0938 meanLoss: 25.5462 meanLossQlbl: 0.3779 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.1116 meanLossQtgt_sigm: 0.0566\n",
      "Episode: 692 meanReward: 237.7812 meanLoss: 69.0688 meanLossQlbl: 0.0841 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 68.7561 meanLossQtgt_sigm: 0.2286\n",
      "Episode: 693 meanReward: 237.0938 meanLoss: 37.4410 meanLossQlbl: 1.1322 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.2016 meanLossQtgt_sigm: 0.1073\n",
      "Episode: 694 meanReward: 225.4688 meanLoss: 53.7636 meanLossQlbl: 0.9701 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 52.6338 meanLossQtgt_sigm: 0.1598\n",
      "Episode: 695 meanReward: 213.0938 meanLoss: 43.2369 meanLossQlbl: 0.9119 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 42.1633 meanLossQtgt_sigm: 0.1617\n",
      "Episode: 696 meanReward: 210.0000 meanLoss: 42.7963 meanLossQlbl: 0.2411 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 42.4149 meanLossQtgt_sigm: 0.1403\n",
      "Episode: 697 meanReward: 207.7188 meanLoss: 32.5316 meanLossQlbl: 0.5508 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.8666 meanLossQtgt_sigm: 0.1142\n",
      "Episode: 698 meanReward: 210.3125 meanLoss: 20.4053 meanLossQlbl: 0.4052 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.9260 meanLossQtgt_sigm: 0.0741\n",
      "Episode: 699 meanReward: 218.0938 meanLoss: 12.9731 meanLossQlbl: 0.1707 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.7610 meanLossQtgt_sigm: 0.0414\n",
      "Episode: 700 meanReward: 218.7500 meanLoss: 179.8174 meanLossQlbl: 0.5791 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 178.7483 meanLossQtgt_sigm: 0.4899\n",
      "Episode: 701 meanReward: 228.5000 meanLoss: 4.6782 meanLossQlbl: 0.2749 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.3849 meanLossQtgt_sigm: 0.0185\n",
      "Episode: 702 meanReward: 224.4062 meanLoss: 298.3615 meanLossQlbl: 0.2261 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 297.2753 meanLossQtgt_sigm: 0.8600\n",
      "Episode: 703 meanReward: 237.7500 meanLoss: 17.2310 meanLossQlbl: 0.6310 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5538 meanLossQtgt_sigm: 0.0462\n",
      "Episode: 704 meanReward: 239.9062 meanLoss: 92.6127 meanLossQlbl: 0.5153 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 91.8490 meanLossQtgt_sigm: 0.2484\n",
      "Episode: 705 meanReward: 238.2812 meanLoss: 56.0537 meanLossQlbl: 0.7408 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.1234 meanLossQtgt_sigm: 0.1895\n",
      "Episode: 706 meanReward: 231.6250 meanLoss: 138.0856 meanLossQlbl: 0.4531 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 137.1183 meanLossQtgt_sigm: 0.5142\n",
      "Episode: 707 meanReward: 234.7188 meanLoss: 26.9130 meanLossQlbl: 1.5447 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.2890 meanLossQtgt_sigm: 0.0793\n",
      "Episode: 708 meanReward: 230.6250 meanLoss: 28.2098 meanLossQlbl: 0.5420 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.5659 meanLossQtgt_sigm: 0.1019\n",
      "Episode: 709 meanReward: 230.0000 meanLoss: 32.9557 meanLossQlbl: 0.1645 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.6961 meanLossQtgt_sigm: 0.0951\n",
      "Episode: 710 meanReward: 223.7500 meanLoss: 134.8425 meanLossQlbl: 1.2553 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 133.0519 meanLossQtgt_sigm: 0.5353\n",
      "Episode: 711 meanReward: 219.8438 meanLoss: 170.7271 meanLossQlbl: 0.4979 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 169.6286 meanLossQtgt_sigm: 0.6007\n",
      "Episode: 712 meanReward: 225.9688 meanLoss: 6.3462 meanLossQlbl: 0.5546 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.7751 meanLossQtgt_sigm: 0.0165\n",
      "Episode: 713 meanReward: 222.9688 meanLoss: 69.4764 meanLossQlbl: 0.4167 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 68.8665 meanLossQtgt_sigm: 0.1932\n",
      "Episode: 714 meanReward: 216.7188 meanLoss: 36.1045 meanLossQlbl: 0.4599 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.5199 meanLossQtgt_sigm: 0.1247\n",
      "Episode: 715 meanReward: 213.7500 meanLoss: 246.8808 meanLossQlbl: 1.4606 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 244.6611 meanLossQtgt_sigm: 0.7590\n",
      "Episode: 716 meanReward: 198.4688 meanLoss: 309.3585 meanLossQlbl: 4.2870 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 304.1696 meanLossQtgt_sigm: 0.9019\n",
      "Episode: 717 meanReward: 188.4688 meanLoss: 427.4360 meanLossQlbl: 4.7578 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 421.2939 meanLossQtgt_sigm: 1.3844\n",
      "Episode: 718 meanReward: 198.8438 meanLoss: 15.2822 meanLossQlbl: 1.7355 meanLossQlbl_sigm: 0.0006 meanLossQtgt: 13.5142 meanLossQtgt_sigm: 0.0319\n",
      "Episode: 719 meanReward: 213.7812 meanLoss: 12.6856 meanLossQlbl: 0.0703 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5738 meanLossQtgt_sigm: 0.0415\n",
      "Episode: 720 meanReward: 213.7812 meanLoss: 15.6059 meanLossQlbl: 0.1502 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.4098 meanLossQtgt_sigm: 0.0459\n",
      "Episode: 721 meanReward: 223.6875 meanLoss: 12.9844 meanLossQlbl: 0.3869 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5566 meanLossQtgt_sigm: 0.0409\n",
      "Episode: 722 meanReward: 223.6875 meanLoss: 16.0257 meanLossQlbl: 0.0835 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.8946 meanLossQtgt_sigm: 0.0476\n",
      "Episode: 723 meanReward: 223.6875 meanLoss: 16.8684 meanLossQlbl: 0.2076 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.6130 meanLossQtgt_sigm: 0.0478\n",
      "Episode: 724 meanReward: 222.9375 meanLoss: 154.7104 meanLossQlbl: 1.3747 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 152.9325 meanLossQtgt_sigm: 0.4032\n",
      "Episode: 725 meanReward: 235.0938 meanLoss: 19.1456 meanLossQlbl: 0.2633 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.8301 meanLossQtgt_sigm: 0.0522\n",
      "Episode: 726 meanReward: 231.5312 meanLoss: 276.6020 meanLossQlbl: 0.3279 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 275.4523 meanLossQtgt_sigm: 0.8218\n",
      "Episode: 727 meanReward: 243.9062 meanLoss: 18.3718 meanLossQlbl: 1.1615 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.1640 meanLossQtgt_sigm: 0.0464\n",
      "Episode: 728 meanReward: 255.2188 meanLoss: 19.7163 meanLossQlbl: 0.0191 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.6446 meanLossQtgt_sigm: 0.0526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 729 meanReward: 254.7500 meanLoss: 71.0206 meanLossQlbl: 0.4004 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 70.4194 meanLossQtgt_sigm: 0.2008\n",
      "Episode: 730 meanReward: 263.1562 meanLoss: 5.4945 meanLossQlbl: 0.1560 meanLossQlbl_sigm: 0.0004 meanLossQtgt: 5.3176 meanLossQtgt_sigm: 0.0204\n",
      "Episode: 731 meanReward: 250.9688 meanLoss: 65.7025 meanLossQlbl: 0.7096 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 64.7905 meanLossQtgt_sigm: 0.2024\n",
      "Episode: 732 meanReward: 252.9062 meanLoss: 22.3129 meanLossQlbl: 0.2577 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.9436 meanLossQtgt_sigm: 0.1116\n",
      "Episode: 733 meanReward: 240.0625 meanLoss: 13.5561 meanLossQlbl: 1.0023 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5151 meanLossQtgt_sigm: 0.0387\n",
      "Episode: 734 meanReward: 255.3125 meanLoss: 2.2860 meanLossQlbl: 0.3038 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.9729 meanLossQtgt_sigm: 0.0092\n",
      "Episode: 735 meanReward: 255.3125 meanLoss: 17.1694 meanLossQlbl: 0.2137 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9066 meanLossQtgt_sigm: 0.0492\n",
      "Episode: 736 meanReward: 258.6562 meanLoss: 39.7321 meanLossQlbl: 0.2231 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.3921 meanLossQtgt_sigm: 0.1169\n",
      "Episode: 737 meanReward: 271.0312 meanLoss: 13.6952 meanLossQlbl: 0.2180 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.4331 meanLossQtgt_sigm: 0.0441\n",
      "Episode: 738 meanReward: 285.5000 meanLoss: 16.0353 meanLossQlbl: 0.0824 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9048 meanLossQtgt_sigm: 0.0480\n",
      "Episode: 739 meanReward: 282.6875 meanLoss: 263.5527 meanLossQlbl: 2.2959 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 260.4715 meanLossQtgt_sigm: 0.7853\n",
      "Episode: 740 meanReward: 282.5000 meanLoss: 45.3306 meanLossQlbl: 1.2004 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.9964 meanLossQtgt_sigm: 0.1337\n",
      "Episode: 741 meanReward: 285.7500 meanLoss: 21.1731 meanLossQlbl: 0.1669 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.9418 meanLossQtgt_sigm: 0.0644\n",
      "Episode: 742 meanReward: 290.4688 meanLoss: 33.2366 meanLossQlbl: 0.2864 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.8358 meanLossQtgt_sigm: 0.1144\n",
      "Episode: 743 meanReward: 296.5625 meanLoss: 17.9580 meanLossQlbl: 1.2328 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.6713 meanLossQtgt_sigm: 0.0539\n",
      "Episode: 744 meanReward: 289.3125 meanLoss: 8.1457 meanLossQlbl: 0.1937 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.9130 meanLossQtgt_sigm: 0.0391\n",
      "Episode: 745 meanReward: 300.8125 meanLoss: 5.7590 meanLossQlbl: 0.2188 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.5199 meanLossQtgt_sigm: 0.0203\n",
      "Episode: 746 meanReward: 304.0000 meanLoss: 33.7639 meanLossQlbl: 0.2228 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.4415 meanLossQtgt_sigm: 0.0997\n",
      "Episode: 747 meanReward: 303.4688 meanLoss: 202.9979 meanLossQlbl: 0.1939 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 202.0993 meanLossQtgt_sigm: 0.7047\n",
      "Episode: 748 meanReward: 303.4688 meanLoss: 435.7346 meanLossQlbl: 0.4668 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 433.8363 meanLossQtgt_sigm: 1.4315\n",
      "Episode: 749 meanReward: 311.0000 meanLoss: 33.6644 meanLossQlbl: 1.0785 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 32.4771 meanLossQtgt_sigm: 0.1088\n",
      "Episode: 750 meanReward: 300.1875 meanLoss: 9.1567 meanLossQlbl: 0.1650 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.9381 meanLossQtgt_sigm: 0.0536\n",
      "Episode: 751 meanReward: 289.7188 meanLoss: 6.6557 meanLossQlbl: 0.0427 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.5699 meanLossQtgt_sigm: 0.0432\n",
      "Episode: 752 meanReward: 280.7812 meanLoss: 3.6602 meanLossQlbl: 0.5069 meanLossQlbl_sigm: 0.0005 meanLossQtgt: 3.1414 meanLossQtgt_sigm: 0.0114\n",
      "Episode: 753 meanReward: 273.6562 meanLoss: 10.1815 meanLossQlbl: 0.1610 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.9739 meanLossQtgt_sigm: 0.0465\n",
      "Episode: 754 meanReward: 263.9375 meanLoss: 13.1414 meanLossQlbl: 0.5438 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5374 meanLossQtgt_sigm: 0.0602\n",
      "Episode: 755 meanReward: 251.8438 meanLoss: 19.3125 meanLossQlbl: 1.8379 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.4178 meanLossQtgt_sigm: 0.0569\n",
      "Episode: 756 meanReward: 265.3438 meanLoss: 2.8357 meanLossQlbl: 0.1012 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.7167 meanLossQtgt_sigm: 0.0179\n",
      "Episode: 757 meanReward: 260.3438 meanLoss: 19.4274 meanLossQlbl: 0.1430 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.2235 meanLossQtgt_sigm: 0.0609\n",
      "Episode: 758 meanReward: 272.0938 meanLoss: 6.8454 meanLossQlbl: 0.1485 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.6691 meanLossQtgt_sigm: 0.0278\n",
      "Episode: 759 meanReward: 262.9375 meanLoss: 11.9820 meanLossQlbl: 0.5118 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.4260 meanLossQtgt_sigm: 0.0442\n",
      "Episode: 760 meanReward: 249.3750 meanLoss: 95.1782 meanLossQlbl: 3.5164 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 91.3789 meanLossQtgt_sigm: 0.2829\n",
      "Episode: 761 meanReward: 246.0625 meanLoss: 331.3585 meanLossQlbl: 0.6667 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 329.8085 meanLossQtgt_sigm: 0.8834\n",
      "Episode: 762 meanReward: 230.7500 meanLoss: 395.5483 meanLossQlbl: 1.2899 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 392.9727 meanLossQtgt_sigm: 1.2857\n",
      "Episode: 763 meanReward: 242.9375 meanLoss: 9.7183 meanLossQlbl: 0.8106 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.8923 meanLossQtgt_sigm: 0.0154\n",
      "Episode: 764 meanReward: 254.9688 meanLoss: 21.4619 meanLossQlbl: 0.1505 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.2580 meanLossQtgt_sigm: 0.0534\n",
      "Episode: 765 meanReward: 262.2188 meanLoss: 24.9806 meanLossQlbl: 0.1123 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.7969 meanLossQtgt_sigm: 0.0713\n",
      "Episode: 766 meanReward: 262.2188 meanLoss: 4.4206 meanLossQlbl: 0.5258 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.8783 meanLossQtgt_sigm: 0.0166\n",
      "Episode: 767 meanReward: 251.1562 meanLoss: 69.2884 meanLossQlbl: 1.8771 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.2342 meanLossQtgt_sigm: 0.1772\n",
      "Episode: 768 meanReward: 247.8125 meanLoss: 49.2960 meanLossQlbl: 0.6567 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 48.4592 meanLossQtgt_sigm: 0.1802\n",
      "Episode: 769 meanReward: 239.5625 meanLoss: 16.9733 meanLossQlbl: 1.4090 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.5012 meanLossQtgt_sigm: 0.0631\n",
      "Episode: 770 meanReward: 236.6875 meanLoss: 9.5587 meanLossQlbl: 0.2047 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.3169 meanLossQtgt_sigm: 0.0372\n",
      "Episode: 771 meanReward: 239.6250 meanLoss: 21.3025 meanLossQlbl: 1.4632 meanLossQlbl_sigm: 0.0049 meanLossQtgt: 19.7915 meanLossQtgt_sigm: 0.0429\n",
      "Episode: 772 meanReward: 234.8125 meanLoss: 110.2286 meanLossQlbl: 10.6935 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 99.1021 meanLossQtgt_sigm: 0.4331\n",
      "Episode: 773 meanReward: 223.7812 meanLoss: 202.4247 meanLossQlbl: 0.8899 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 200.6992 meanLossQtgt_sigm: 0.8356\n",
      "Episode: 774 meanReward: 227.2188 meanLoss: 19.6560 meanLossQlbl: 1.4705 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.1391 meanLossQtgt_sigm: 0.0464\n",
      "Episode: 775 meanReward: 225.6250 meanLoss: 20.0683 meanLossQlbl: 0.4066 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.5770 meanLossQtgt_sigm: 0.0847\n",
      "Episode: 776 meanReward: 218.8125 meanLoss: 62.0357 meanLossQlbl: 0.0629 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 61.7125 meanLossQtgt_sigm: 0.2603\n",
      "Episode: 777 meanReward: 218.5938 meanLoss: 7.6983 meanLossQlbl: 1.1418 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.5464 meanLossQtgt_sigm: 0.0101\n",
      "Episode: 778 meanReward: 220.0938 meanLoss: 14.2722 meanLossQlbl: 0.2585 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.9600 meanLossQtgt_sigm: 0.0538\n",
      "Episode: 779 meanReward: 235.3125 meanLoss: 3.7409 meanLossQlbl: 0.0980 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.6242 meanLossQtgt_sigm: 0.0187\n",
      "Episode: 780 meanReward: 239.0625 meanLoss: 81.1280 meanLossQlbl: 0.8973 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 80.0260 meanLossQtgt_sigm: 0.2047\n",
      "Episode: 781 meanReward: 234.5312 meanLoss: 9.8207 meanLossQlbl: 0.6216 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.1437 meanLossQtgt_sigm: 0.0554\n",
      "Episode: 782 meanReward: 234.5938 meanLoss: 6.5431 meanLossQlbl: 0.4844 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.0268 meanLossQtgt_sigm: 0.0319\n",
      "Episode: 783 meanReward: 242.7500 meanLoss: 4.0164 meanLossQlbl: 0.0821 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.9115 meanLossQtgt_sigm: 0.0228\n",
      "Episode: 784 meanReward: 251.6875 meanLoss: 20.0262 meanLossQlbl: 0.1584 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.8151 meanLossQtgt_sigm: 0.0527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 785 meanReward: 258.8125 meanLoss: 22.7580 meanLossQlbl: 0.6271 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.0792 meanLossQtgt_sigm: 0.0517\n",
      "Episode: 786 meanReward: 268.5312 meanLoss: 21.3576 meanLossQlbl: 0.1758 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.1276 meanLossQtgt_sigm: 0.0543\n",
      "Episode: 787 meanReward: 280.6250 meanLoss: 19.8468 meanLossQlbl: 0.0644 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.7292 meanLossQtgt_sigm: 0.0532\n",
      "Episode: 788 meanReward: 280.6250 meanLoss: 20.7531 meanLossQlbl: 0.0921 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.6064 meanLossQtgt_sigm: 0.0545\n",
      "Episode: 789 meanReward: 270.6250 meanLoss: 330.9990 meanLossQlbl: 0.5745 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 329.5370 meanLossQtgt_sigm: 0.8873\n",
      "Episode: 790 meanReward: 274.0625 meanLoss: 14.9447 meanLossQlbl: 0.1941 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.7068 meanLossQtgt_sigm: 0.0438\n",
      "Episode: 791 meanReward: 283.2188 meanLoss: 17.8350 meanLossQlbl: 0.1350 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.6494 meanLossQtgt_sigm: 0.0506\n",
      "Episode: 792 meanReward: 296.7812 meanLoss: 18.6408 meanLossQlbl: 0.3375 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2521 meanLossQtgt_sigm: 0.0512\n",
      "Episode: 793 meanReward: 311.8125 meanLoss: 19.9260 meanLossQlbl: 0.3242 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.5488 meanLossQtgt_sigm: 0.0531\n",
      "Episode: 794 meanReward: 327.1250 meanLoss: 18.7503 meanLossQlbl: 0.1576 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5408 meanLossQtgt_sigm: 0.0520\n",
      "Episode: 795 meanReward: 314.3125 meanLoss: 97.9639 meanLossQlbl: 0.7299 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 96.9546 meanLossQtgt_sigm: 0.2795\n",
      "Episode: 796 meanReward: 301.3438 meanLoss: 32.6805 meanLossQlbl: 1.7683 meanLossQlbl_sigm: 0.0006 meanLossQtgt: 30.8562 meanLossQtgt_sigm: 0.0555\n",
      "Episode: 797 meanReward: 294.5000 meanLoss: 15.3345 meanLossQlbl: 0.4068 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.8426 meanLossQtgt_sigm: 0.0851\n",
      "Episode: 798 meanReward: 283.3438 meanLoss: 6.4460 meanLossQlbl: 0.5835 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.8230 meanLossQtgt_sigm: 0.0395\n",
      "Episode: 799 meanReward: 285.0625 meanLoss: 6.0592 meanLossQlbl: 0.3117 meanLossQlbl_sigm: 0.0003 meanLossQtgt: 5.7371 meanLossQtgt_sigm: 0.0102\n",
      "Episode: 800 meanReward: 290.5938 meanLoss: 3.9854 meanLossQlbl: 0.1799 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 3.7964 meanLossQtgt_sigm: 0.0089\n",
      "Episode: 801 meanReward: 298.8438 meanLoss: 7.5716 meanLossQlbl: 0.1516 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.3879 meanLossQtgt_sigm: 0.0321\n",
      "Episode: 802 meanReward: 298.2500 meanLoss: 21.8233 meanLossQlbl: 0.1724 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.5893 meanLossQtgt_sigm: 0.0616\n",
      "Episode: 803 meanReward: 310.1250 meanLoss: 16.6985 meanLossQlbl: 0.0235 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.6262 meanLossQtgt_sigm: 0.0488\n",
      "Episode: 804 meanReward: 312.9688 meanLoss: 83.6978 meanLossQlbl: 1.2699 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 82.1886 meanLossQtgt_sigm: 0.2393\n",
      "Episode: 805 meanReward: 315.7188 meanLoss: 42.4140 meanLossQlbl: 1.1079 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 41.1432 meanLossQtgt_sigm: 0.1629\n",
      "Episode: 806 meanReward: 309.8438 meanLoss: 31.2913 meanLossQlbl: 0.3809 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 30.7632 meanLossQtgt_sigm: 0.1472\n",
      "Episode: 807 meanReward: 308.1250 meanLoss: 33.6151 meanLossQlbl: 0.4930 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.9672 meanLossQtgt_sigm: 0.1549\n",
      "Episode: 808 meanReward: 308.1562 meanLoss: 74.5377 meanLossQlbl: 0.7084 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 73.5038 meanLossQtgt_sigm: 0.3255\n",
      "Episode: 809 meanReward: 304.4062 meanLoss: 8.8763 meanLossQlbl: 0.7087 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.1483 meanLossQtgt_sigm: 0.0193\n",
      "Episode: 810 meanReward: 305.2188 meanLoss: 19.6346 meanLossQlbl: 0.1492 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.4194 meanLossQtgt_sigm: 0.0660\n",
      "Episode: 811 meanReward: 305.2188 meanLoss: 14.4643 meanLossQlbl: 0.2090 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.2103 meanLossQtgt_sigm: 0.0450\n",
      "Episode: 812 meanReward: 306.9062 meanLoss: 47.4288 meanLossQlbl: 0.6735 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 46.6222 meanLossQtgt_sigm: 0.1332\n",
      "Episode: 813 meanReward: 319.2188 meanLoss: 8.6967 meanLossQlbl: 0.3362 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.3263 meanLossQtgt_sigm: 0.0342\n",
      "Episode: 814 meanReward: 315.9688 meanLoss: 159.9940 meanLossQlbl: 0.6630 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 158.8600 meanLossQtgt_sigm: 0.4711\n",
      "Episode: 815 meanReward: 318.2812 meanLoss: 5.8564 meanLossQlbl: 0.3776 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.4647 meanLossQtgt_sigm: 0.0140\n",
      "Episode: 816 meanReward: 318.2812 meanLoss: 16.1963 meanLossQlbl: 0.1462 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.0029 meanLossQtgt_sigm: 0.0472\n",
      "Episode: 817 meanReward: 318.2812 meanLoss: 17.1506 meanLossQlbl: 0.2769 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8251 meanLossQtgt_sigm: 0.0486\n",
      "Episode: 818 meanReward: 312.5312 meanLoss: 29.1089 meanLossQlbl: 0.2734 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.7556 meanLossQtgt_sigm: 0.0800\n",
      "Episode: 819 meanReward: 302.1875 meanLoss: 31.4781 meanLossQlbl: 1.5683 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.8318 meanLossQtgt_sigm: 0.0780\n",
      "Episode: 820 meanReward: 290.0312 meanLoss: 57.3928 meanLossQlbl: 1.6654 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.5405 meanLossQtgt_sigm: 0.1869\n",
      "Episode: 821 meanReward: 293.8438 meanLoss: 44.6671 meanLossQlbl: 0.2117 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.3059 meanLossQtgt_sigm: 0.1495\n",
      "Episode: 822 meanReward: 282.8750 meanLoss: 35.0461 meanLossQlbl: 0.2183 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 34.6993 meanLossQtgt_sigm: 0.1285\n",
      "Episode: 823 meanReward: 270.9688 meanLoss: 31.1961 meanLossQlbl: 0.1256 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 30.9336 meanLossQtgt_sigm: 0.1370\n",
      "Episode: 824 meanReward: 262.1875 meanLoss: 10.9093 meanLossQlbl: 0.9913 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.8832 meanLossQtgt_sigm: 0.0349\n",
      "Episode: 825 meanReward: 262.1875 meanLoss: 12.5911 meanLossQlbl: 0.0424 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5066 meanLossQtgt_sigm: 0.0421\n",
      "Episode: 826 meanReward: 247.3438 meanLoss: 265.5704 meanLossQlbl: 0.0485 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 264.7265 meanLossQtgt_sigm: 0.7954\n",
      "Episode: 827 meanReward: 260.1562 meanLoss: 9.9582 meanLossQlbl: 0.2756 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.6504 meanLossQtgt_sigm: 0.0322\n",
      "Episode: 828 meanReward: 272.8438 meanLoss: 12.7553 meanLossQlbl: 0.0726 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.6428 meanLossQtgt_sigm: 0.0399\n",
      "Episode: 829 meanReward: 273.8438 meanLoss: 7.2309 meanLossQlbl: 0.3412 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.8496 meanLossQtgt_sigm: 0.0401\n",
      "Episode: 830 meanReward: 273.2500 meanLoss: 17.1940 meanLossQlbl: 2.0463 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.0667 meanLossQtgt_sigm: 0.0811\n",
      "Episode: 831 meanReward: 272.5000 meanLoss: 19.0627 meanLossQlbl: 0.4865 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4976 meanLossQtgt_sigm: 0.0787\n",
      "Episode: 832 meanReward: 268.4688 meanLoss: 9.6550 meanLossQlbl: 0.1538 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.4435 meanLossQtgt_sigm: 0.0576\n",
      "Episode: 833 meanReward: 257.2500 meanLoss: 7.7238 meanLossQlbl: 0.6114 meanLossQlbl_sigm: 0.0061 meanLossQtgt: 7.0483 meanLossQtgt_sigm: 0.0580\n",
      "Episode: 834 meanReward: 249.8750 meanLoss: 50.9887 meanLossQlbl: 25.0785 meanLossQlbl_sigm: 0.1149 meanLossQtgt: 25.6617 meanLossQtgt_sigm: 0.1337\n",
      "Episode: 835 meanReward: 239.3438 meanLoss: 496.2692 meanLossQlbl: 258.8496 meanLossQlbl_sigm: 0.3569 meanLossQtgt: 236.6754 meanLossQtgt_sigm: 0.3872\n",
      "Episode: 836 meanReward: 238.8125 meanLoss: 473.0600 meanLossQlbl: 248.8187 meanLossQlbl_sigm: 0.3301 meanLossQtgt: 223.5434 meanLossQtgt_sigm: 0.3677\n",
      "Episode: 837 meanReward: 245.4375 meanLoss: 1027.0432 meanLossQlbl: 526.4124 meanLossQlbl_sigm: 0.4807 meanLossQtgt: 499.5323 meanLossQtgt_sigm: 0.6178\n",
      "Episode: 838 meanReward: 257.9375 meanLoss: 16.8317 meanLossQlbl: 1.0099 meanLossQlbl_sigm: 0.0056 meanLossQtgt: 15.7850 meanLossQtgt_sigm: 0.0311\n",
      "Episode: 839 meanReward: 256.0625 meanLoss: 242.7328 meanLossQlbl: 1.0169 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 241.0603 meanLossQtgt_sigm: 0.6556\n",
      "Episode: 840 meanReward: 256.5000 meanLoss: 44.7776 meanLossQlbl: 2.0585 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 42.5669 meanLossQtgt_sigm: 0.1522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 841 meanReward: 260.4688 meanLoss: 12.8216 meanLossQlbl: 0.1086 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.6739 meanLossQtgt_sigm: 0.0391\n",
      "Episode: 842 meanReward: 266.2500 meanLoss: 19.3322 meanLossQlbl: 0.1729 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.1071 meanLossQtgt_sigm: 0.0521\n",
      "Episode: 843 meanReward: 255.3750 meanLoss: 61.3964 meanLossQlbl: 0.6515 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 60.5791 meanLossQtgt_sigm: 0.1658\n",
      "Episode: 844 meanReward: 250.6562 meanLoss: 208.5741 meanLossQlbl: 0.6348 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 207.2828 meanLossQtgt_sigm: 0.6565\n",
      "Episode: 845 meanReward: 237.9688 meanLoss: 39.2575 meanLossQlbl: 0.9617 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 38.1562 meanLossQtgt_sigm: 0.1396\n",
      "Episode: 846 meanReward: 240.2500 meanLoss: 51.0170 meanLossQlbl: 0.1422 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 50.7054 meanLossQtgt_sigm: 0.1694\n",
      "Episode: 847 meanReward: 228.7500 meanLoss: 36.4605 meanLossQlbl: 0.1230 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.2060 meanLossQtgt_sigm: 0.1314\n",
      "Episode: 848 meanReward: 217.1875 meanLoss: 41.2796 meanLossQlbl: 0.4898 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 40.6499 meanLossQtgt_sigm: 0.1400\n",
      "Episode: 849 meanReward: 217.1875 meanLoss: 21.0998 meanLossQlbl: 0.3281 meanLossQlbl_sigm: 0.0010 meanLossQtgt: 20.7169 meanLossQtgt_sigm: 0.0537\n",
      "Episode: 850 meanReward: 211.0312 meanLoss: 67.0177 meanLossQlbl: 0.9988 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 65.8274 meanLossQtgt_sigm: 0.1915\n",
      "Episode: 851 meanReward: 214.6250 meanLoss: 23.2395 meanLossQlbl: 0.0894 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.0787 meanLossQtgt_sigm: 0.0714\n",
      "Episode: 852 meanReward: 213.8125 meanLoss: 29.1378 meanLossQlbl: 0.2697 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.7442 meanLossQtgt_sigm: 0.1239\n",
      "Episode: 853 meanReward: 213.2500 meanLoss: 15.4827 meanLossQlbl: 1.9374 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.4784 meanLossQtgt_sigm: 0.0668\n",
      "Episode: 854 meanReward: 215.9375 meanLoss: 14.7119 meanLossQlbl: 0.0527 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5967 meanLossQtgt_sigm: 0.0625\n",
      "Episode: 855 meanReward: 227.8438 meanLoss: 8.1812 meanLossQlbl: 0.0396 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.1083 meanLossQtgt_sigm: 0.0334\n",
      "Episode: 856 meanReward: 236.6250 meanLoss: 13.1669 meanLossQlbl: 0.0681 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.0553 meanLossQtgt_sigm: 0.0434\n",
      "Episode: 857 meanReward: 225.7188 meanLoss: 57.9301 meanLossQlbl: 0.2009 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 57.5700 meanLossQtgt_sigm: 0.1589\n",
      "Episode: 858 meanReward: 230.4375 meanLoss: 11.3880 meanLossQlbl: 1.1803 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.1897 meanLossQtgt_sigm: 0.0180\n",
      "Episode: 859 meanReward: 219.4062 meanLoss: 30.7166 meanLossQlbl: 0.5073 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 30.0969 meanLossQtgt_sigm: 0.1124\n",
      "Episode: 860 meanReward: 210.0000 meanLoss: 21.4288 meanLossQlbl: 0.4866 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.8652 meanLossQtgt_sigm: 0.0770\n",
      "Episode: 861 meanReward: 214.5625 meanLoss: 14.9170 meanLossQlbl: 0.4366 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.4237 meanLossQtgt_sigm: 0.0566\n",
      "Episode: 862 meanReward: 216.9062 meanLoss: 32.7325 meanLossQlbl: 0.1860 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.4395 meanLossQtgt_sigm: 0.1069\n",
      "Episode: 863 meanReward: 216.9688 meanLoss: 22.8646 meanLossQlbl: 0.1271 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.6462 meanLossQtgt_sigm: 0.0913\n",
      "Episode: 864 meanReward: 227.9062 meanLoss: 6.2201 meanLossQlbl: 0.0786 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.1122 meanLossQtgt_sigm: 0.0293\n",
      "Episode: 865 meanReward: 230.2812 meanLoss: 41.4971 meanLossQlbl: 0.4288 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 40.9546 meanLossQtgt_sigm: 0.1136\n",
      "Episode: 866 meanReward: 241.1250 meanLoss: 6.1095 meanLossQlbl: 0.1306 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.9499 meanLossQtgt_sigm: 0.0290\n",
      "Episode: 867 meanReward: 251.6562 meanLoss: 17.0827 meanLossQlbl: 0.0594 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9738 meanLossQtgt_sigm: 0.0495\n",
      "Episode: 868 meanReward: 264.6250 meanLoss: 16.9134 meanLossQlbl: 0.1640 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7008 meanLossQtgt_sigm: 0.0486\n",
      "Episode: 869 meanReward: 270.5312 meanLoss: 15.8991 meanLossQlbl: 0.2988 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.5533 meanLossQtgt_sigm: 0.0470\n",
      "Episode: 870 meanReward: 259.5938 meanLoss: 54.6118 meanLossQlbl: 1.6332 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 52.8203 meanLossQtgt_sigm: 0.1583\n",
      "Episode: 871 meanReward: 259.1875 meanLoss: 144.1566 meanLossQlbl: 0.4277 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 143.1550 meanLossQtgt_sigm: 0.5740\n",
      "Episode: 872 meanReward: 272.7812 meanLoss: 10.6483 meanLossQlbl: 1.1270 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.4954 meanLossQtgt_sigm: 0.0259\n",
      "Episode: 873 meanReward: 272.7812 meanLoss: 19.0489 meanLossQlbl: 0.0305 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.9664 meanLossQtgt_sigm: 0.0521\n",
      "Episode: 874 meanReward: 260.5938 meanLoss: 80.9269 meanLossQlbl: 0.7231 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 79.9787 meanLossQtgt_sigm: 0.2250\n",
      "Episode: 875 meanReward: 271.4688 meanLoss: 4.3866 meanLossQlbl: 0.0606 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.3017 meanLossQtgt_sigm: 0.0244\n",
      "Episode: 876 meanReward: 286.0312 meanLoss: 18.8072 meanLossQlbl: 0.3454 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4120 meanLossQtgt_sigm: 0.0499\n",
      "Episode: 877 meanReward: 288.2500 meanLoss: 50.1816 meanLossQlbl: 0.4509 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 49.5837 meanLossQtgt_sigm: 0.1471\n",
      "Episode: 878 meanReward: 299.9688 meanLoss: 15.5775 meanLossQlbl: 0.2051 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.3255 meanLossQtgt_sigm: 0.0469\n",
      "Episode: 879 meanReward: 311.4688 meanLoss: 18.1418 meanLossQlbl: 0.1136 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.9773 meanLossQtgt_sigm: 0.0510\n",
      "Episode: 880 meanReward: 323.0312 meanLoss: 17.7966 meanLossQlbl: 0.1555 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.5905 meanLossQtgt_sigm: 0.0506\n",
      "Episode: 881 meanReward: 323.0312 meanLoss: 16.9631 meanLossQlbl: 0.1465 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7676 meanLossQtgt_sigm: 0.0491\n",
      "Episode: 882 meanReward: 319.8750 meanLoss: 276.0508 meanLossQlbl: 1.3105 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 273.9251 meanLossQtgt_sigm: 0.8152\n",
      "Episode: 883 meanReward: 311.4688 meanLoss: 500.2418 meanLossQlbl: 4.2852 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 494.4808 meanLossQtgt_sigm: 1.4757\n",
      "Episode: 884 meanReward: 310.5938 meanLoss: 141.2919 meanLossQlbl: 5.2525 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 135.6039 meanLossQtgt_sigm: 0.4354\n",
      "Episode: 885 meanReward: 322.3438 meanLoss: 12.1056 meanLossQlbl: 0.1566 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.9091 meanLossQtgt_sigm: 0.0399\n",
      "Episode: 886 meanReward: 330.6250 meanLoss: 17.1776 meanLossQlbl: 0.0712 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0569 meanLossQtgt_sigm: 0.0496\n",
      "Episode: 887 meanReward: 330.6250 meanLoss: 15.9948 meanLossQlbl: 0.0338 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9135 meanLossQtgt_sigm: 0.0475\n",
      "Episode: 888 meanReward: 330.6250 meanLoss: 16.6397 meanLossQlbl: 0.0964 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.4946 meanLossQtgt_sigm: 0.0488\n",
      "Episode: 889 meanReward: 341.5312 meanLoss: 15.0461 meanLossQlbl: 0.2017 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.7984 meanLossQtgt_sigm: 0.0460\n",
      "Episode: 890 meanReward: 351.6562 meanLoss: 26.1386 meanLossQlbl: 1.3687 meanLossQlbl_sigm: 0.0011 meanLossQtgt: 24.7187 meanLossQtgt_sigm: 0.0502\n",
      "Episode: 891 meanReward: 362.6875 meanLoss: 12.0304 meanLossQlbl: 0.2288 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.7665 meanLossQtgt_sigm: 0.0350\n",
      "Episode: 892 meanReward: 362.8438 meanLoss: 27.3541 meanLossQlbl: 1.0843 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.1851 meanLossQtgt_sigm: 0.0846\n",
      "Episode: 893 meanReward: 369.7188 meanLoss: 20.3747 meanLossQlbl: 0.8354 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.4897 meanLossQtgt_sigm: 0.0496\n",
      "Episode: 894 meanReward: 379.1250 meanLoss: 21.7344 meanLossQlbl: 0.1503 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.5318 meanLossQtgt_sigm: 0.0523\n",
      "Episode: 895 meanReward: 389.1562 meanLoss: 20.0009 meanLossQlbl: 0.1473 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.8014 meanLossQtgt_sigm: 0.0522\n",
      "Episode: 896 meanReward: 389.1562 meanLoss: 19.1326 meanLossQlbl: 0.0645 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.0164 meanLossQtgt_sigm: 0.0517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 897 meanReward: 398.0000 meanLoss: 18.4033 meanLossQlbl: 0.0729 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2798 meanLossQtgt_sigm: 0.0506\n",
      "Episode: 898 meanReward: 396.9375 meanLoss: 18.2475 meanLossQlbl: 0.1226 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.0719 meanLossQtgt_sigm: 0.0530\n",
      "Episode: 899 meanReward: 385.2500 meanLoss: 41.2285 meanLossQlbl: 0.5677 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 40.5180 meanLossQtgt_sigm: 0.1427\n",
      "Episode: 900 meanReward: 385.2500 meanLoss: 12.2170 meanLossQlbl: 0.2072 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.9704 meanLossQtgt_sigm: 0.0393\n",
      "Episode: 901 meanReward: 385.2500 meanLoss: 15.8246 meanLossQlbl: 0.1905 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.5899 meanLossQtgt_sigm: 0.0442\n",
      "Episode: 902 meanReward: 396.1875 meanLoss: 14.2268 meanLossQlbl: 0.1356 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.0511 meanLossQtgt_sigm: 0.0401\n",
      "Episode: 903 meanReward: 411.0000 meanLoss: 27.2725 meanLossQlbl: 1.1816 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 26.0474 meanLossQtgt_sigm: 0.0433\n",
      "Episode: 904 meanReward: 402.4375 meanLoss: 44.8554 meanLossQlbl: 0.1299 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.6085 meanLossQtgt_sigm: 0.1170\n",
      "Episode: 905 meanReward: 402.4375 meanLoss: 7.5012 meanLossQlbl: 0.4764 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.9998 meanLossQtgt_sigm: 0.0249\n",
      "Episode: 906 meanReward: 404.1875 meanLoss: 61.4482 meanLossQlbl: 0.9478 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 60.3388 meanLossQtgt_sigm: 0.1615\n",
      "Episode: 907 meanReward: 394.6250 meanLoss: 21.4261 meanLossQlbl: 1.3897 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.9615 meanLossQtgt_sigm: 0.0749\n",
      "Episode: 908 meanReward: 383.9062 meanLoss: 29.8914 meanLossQlbl: 0.7975 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.9825 meanLossQtgt_sigm: 0.1115\n",
      "Episode: 909 meanReward: 383.2812 meanLoss: 24.4338 meanLossQlbl: 0.5846 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.7483 meanLossQtgt_sigm: 0.1008\n",
      "Episode: 910 meanReward: 367.9688 meanLoss: 98.4556 meanLossQlbl: 0.1367 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 97.8595 meanLossQtgt_sigm: 0.4593\n",
      "Episode: 911 meanReward: 355.8438 meanLoss: 54.3700 meanLossQlbl: 1.5950 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 52.5767 meanLossQtgt_sigm: 0.1983\n",
      "Episode: 912 meanReward: 348.0312 meanLoss: 4.7400 meanLossQlbl: 0.2594 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.4602 meanLossQtgt_sigm: 0.0204\n",
      "Episode: 913 meanReward: 344.4375 meanLoss: 4.2653 meanLossQlbl: 0.1748 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.0678 meanLossQtgt_sigm: 0.0227\n",
      "Episode: 914 meanReward: 352.0000 meanLoss: 8.4087 meanLossQlbl: 0.1097 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.2564 meanLossQtgt_sigm: 0.0426\n",
      "Episode: 915 meanReward: 356.9375 meanLoss: 40.4064 meanLossQlbl: 0.1658 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 40.1162 meanLossQtgt_sigm: 0.1245\n",
      "Episode: 916 meanReward: 370.7812 meanLoss: 5.1683 meanLossQlbl: 0.0889 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.0549 meanLossQtgt_sigm: 0.0244\n",
      "Episode: 917 meanReward: 370.7812 meanLoss: 18.6238 meanLossQlbl: 0.1033 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4694 meanLossQtgt_sigm: 0.0512\n",
      "Episode: 918 meanReward: 370.7812 meanLoss: 18.3412 meanLossQlbl: 0.2120 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.0788 meanLossQtgt_sigm: 0.0504\n",
      "Episode: 919 meanReward: 370.7812 meanLoss: 19.0589 meanLossQlbl: 0.1213 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.8854 meanLossQtgt_sigm: 0.0522\n",
      "Episode: 920 meanReward: 358.4062 meanLoss: 91.9863 meanLossQlbl: 0.8131 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 90.9239 meanLossQtgt_sigm: 0.2492\n",
      "Episode: 921 meanReward: 358.4062 meanLoss: 11.1421 meanLossQlbl: 0.4562 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.6563 meanLossQtgt_sigm: 0.0297\n",
      "Episode: 922 meanReward: 343.0938 meanLoss: 336.8984 meanLossQlbl: 0.5454 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 335.4373 meanLossQtgt_sigm: 0.9157\n",
      "Episode: 923 meanReward: 329.3125 meanLoss: 162.0431 meanLossQlbl: 5.0456 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 156.5577 meanLossQtgt_sigm: 0.4398\n",
      "Episode: 924 meanReward: 335.7500 meanLoss: 20.1669 meanLossQlbl: 0.1814 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.9289 meanLossQtgt_sigm: 0.0565\n",
      "Episode: 925 meanReward: 320.5312 meanLoss: 305.9927 meanLossQlbl: 0.0982 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 305.0380 meanLossQtgt_sigm: 0.8566\n",
      "Episode: 926 meanReward: 320.5312 meanLoss: 25.6350 meanLossQlbl: 0.1595 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.4036 meanLossQtgt_sigm: 0.0719\n",
      "Episode: 927 meanReward: 309.1875 meanLoss: 65.3967 meanLossQlbl: 0.5208 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 64.6931 meanLossQtgt_sigm: 0.1828\n",
      "Episode: 928 meanReward: 299.2812 meanLoss: 22.4404 meanLossQlbl: 0.8433 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.5076 meanLossQtgt_sigm: 0.0895\n",
      "Episode: 929 meanReward: 284.0625 meanLoss: 262.0721 meanLossQlbl: 0.1442 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 261.1330 meanLossQtgt_sigm: 0.7948\n",
      "Episode: 930 meanReward: 269.9688 meanLoss: 402.4101 meanLossQlbl: 0.3837 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 400.6725 meanLossQtgt_sigm: 1.3539\n",
      "Episode: 931 meanReward: 281.6562 meanLoss: 19.8695 meanLossQlbl: 0.1807 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.6269 meanLossQtgt_sigm: 0.0619\n",
      "Episode: 932 meanReward: 279.5312 meanLoss: 21.7739 meanLossQlbl: 0.2846 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.4320 meanLossQtgt_sigm: 0.0573\n",
      "Episode: 933 meanReward: 271.0000 meanLoss: 34.0215 meanLossQlbl: 0.1246 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.7961 meanLossQtgt_sigm: 0.1009\n",
      "Episode: 934 meanReward: 265.2188 meanLoss: 18.5492 meanLossQlbl: 0.1874 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3015 meanLossQtgt_sigm: 0.0603\n",
      "Episode: 935 meanReward: 265.2188 meanLoss: 16.0004 meanLossQlbl: 0.1374 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.8154 meanLossQtgt_sigm: 0.0476\n",
      "Episode: 936 meanReward: 273.7812 meanLoss: 15.8353 meanLossQlbl: 0.2133 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.5758 meanLossQtgt_sigm: 0.0461\n",
      "Episode: 937 meanReward: 259.3750 meanLoss: 203.3519 meanLossQlbl: 1.8895 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 200.8524 meanLossQtgt_sigm: 0.6100\n",
      "Episode: 938 meanReward: 254.7188 meanLoss: 263.6665 meanLossQlbl: 2.0232 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 260.8558 meanLossQtgt_sigm: 0.7876\n",
      "Episode: 939 meanReward: 248.9688 meanLoss: 464.1614 meanLossQlbl: 1.7495 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 460.9476 meanLossQtgt_sigm: 1.4644\n",
      "Episode: 940 meanReward: 244.3750 meanLoss: 352.9403 meanLossQlbl: 18.8820 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 333.0916 meanLossQtgt_sigm: 0.9667\n",
      "Episode: 941 meanReward: 241.0312 meanLoss: 155.3623 meanLossQlbl: 23.3461 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 131.7268 meanLossQtgt_sigm: 0.2894\n",
      "Episode: 942 meanReward: 249.8438 meanLoss: 18.6565 meanLossQlbl: 0.0401 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5546 meanLossQtgt_sigm: 0.0618\n",
      "Episode: 943 meanReward: 247.8438 meanLoss: 40.2540 meanLossQlbl: 2.6216 meanLossQlbl_sigm: 0.0595 meanLossQtgt: 37.3346 meanLossQtgt_sigm: 0.2382\n",
      "Episode: 944 meanReward: 240.4062 meanLoss: 117.5451 meanLossQlbl: 27.9767 meanLossQlbl_sigm: 0.1828 meanLossQtgt: 88.7077 meanLossQtgt_sigm: 0.6780\n",
      "Episode: 945 meanReward: 228.7500 meanLoss: 261.4174 meanLossQlbl: 32.8155 meanLossQlbl_sigm: 0.2176 meanLossQtgt: 227.2292 meanLossQtgt_sigm: 1.1550\n",
      "Episode: 946 meanReward: 220.9688 meanLoss: 287.2141 meanLossQlbl: 2.2121 meanLossQlbl_sigm: 0.0551 meanLossQtgt: 283.7611 meanLossQtgt_sigm: 1.1858\n",
      "Episode: 947 meanReward: 215.8750 meanLoss: 300.0150 meanLossQlbl: 0.1296 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 298.5256 meanLossQtgt_sigm: 1.3597\n",
      "Episode: 948 meanReward: 203.6250 meanLoss: 135.1854 meanLossQlbl: 46.6708 meanLossQlbl_sigm: 0.2090 meanLossQtgt: 87.8171 meanLossQtgt_sigm: 0.4885\n",
      "Episode: 949 meanReward: 203.6250 meanLoss: 4.6631 meanLossQlbl: 0.1143 meanLossQlbl_sigm: 0.0015 meanLossQtgt: 4.5271 meanLossQtgt_sigm: 0.0202\n",
      "Episode: 950 meanReward: 192.2500 meanLoss: 20.4879 meanLossQlbl: 0.4618 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.9730 meanLossQtgt_sigm: 0.0531\n",
      "Episode: 951 meanReward: 184.8438 meanLoss: 4.5845 meanLossQlbl: 0.2430 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.3335 meanLossQtgt_sigm: 0.0079\n",
      "Episode: 952 meanReward: 186.3750 meanLoss: 13.8806 meanLossQlbl: 0.2625 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 13.6054 meanLossQtgt_sigm: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 953 meanReward: 181.1562 meanLoss: 6.5629 meanLossQlbl: 0.2428 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.3119 meanLossQtgt_sigm: 0.0081\n",
      "Episode: 954 meanReward: 186.0938 meanLoss: 5.3674 meanLossQlbl: 0.0374 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.2917 meanLossQtgt_sigm: 0.0383\n",
      "Episode: 955 meanReward: 199.8750 meanLoss: 1.3135 meanLossQlbl: 0.0042 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.2981 meanLossQtgt_sigm: 0.0111\n",
      "Episode: 956 meanReward: 190.2188 meanLoss: 87.1045 meanLossQlbl: 0.5063 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 86.3439 meanLossQtgt_sigm: 0.2543\n",
      "Episode: 957 meanReward: 205.4375 meanLoss: 1.1984 meanLossQlbl: 0.0325 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.1597 meanLossQtgt_sigm: 0.0062\n",
      "Episode: 958 meanReward: 205.4375 meanLoss: 16.1153 meanLossQlbl: 0.1427 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9248 meanLossQtgt_sigm: 0.0479\n",
      "Episode: 959 meanReward: 208.3750 meanLoss: 35.7840 meanLossQlbl: 0.5462 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.1350 meanLossQtgt_sigm: 0.1028\n",
      "Episode: 960 meanReward: 209.0000 meanLoss: 17.7146 meanLossQlbl: 0.2774 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.3638 meanLossQtgt_sigm: 0.0735\n",
      "Episode: 961 meanReward: 217.7812 meanLoss: 14.9113 meanLossQlbl: 0.2933 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5709 meanLossQtgt_sigm: 0.0471\n",
      "Episode: 962 meanReward: 219.7812 meanLoss: 18.2501 meanLossQlbl: 1.7844 meanLossQlbl_sigm: 0.0034 meanLossQtgt: 16.4237 meanLossQtgt_sigm: 0.0387\n",
      "Episode: 963 meanReward: 210.6250 meanLoss: 3.7042 meanLossQlbl: 0.1467 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.5440 meanLossQtgt_sigm: 0.0135\n",
      "Episode: 964 meanReward: 212.7500 meanLoss: 16.3630 meanLossQlbl: 6.3539 meanLossQlbl_sigm: 0.0104 meanLossQtgt: 9.9727 meanLossQtgt_sigm: 0.0260\n",
      "Episode: 965 meanReward: 210.7812 meanLoss: 32.9940 meanLossQlbl: 10.7179 meanLossQlbl_sigm: 0.0284 meanLossQtgt: 22.1746 meanLossQtgt_sigm: 0.0730\n",
      "Episode: 966 meanReward: 216.5625 meanLoss: 2.3086 meanLossQlbl: 0.0895 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 2.2143 meanLossQtgt_sigm: 0.0046\n",
      "Episode: 967 meanReward: 203.3125 meanLoss: 139.4177 meanLossQlbl: 0.8386 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 138.2219 meanLossQtgt_sigm: 0.3571\n",
      "Episode: 968 meanReward: 203.3125 meanLoss: 23.5750 meanLossQlbl: 1.1586 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.3710 meanLossQtgt_sigm: 0.0455\n",
      "Episode: 969 meanReward: 203.2188 meanLoss: 287.7228 meanLossQlbl: 0.5338 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 286.4277 meanLossQtgt_sigm: 0.7613\n",
      "Episode: 970 meanReward: 218.3125 meanLoss: 14.9354 meanLossQlbl: 0.7862 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.1150 meanLossQtgt_sigm: 0.0342\n",
      "Episode: 971 meanReward: 223.0625 meanLoss: 58.5134 meanLossQlbl: 0.2762 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 58.0802 meanLossQtgt_sigm: 0.1570\n",
      "Episode: 972 meanReward: 227.6562 meanLoss: 44.1899 meanLossQlbl: 0.5133 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.5393 meanLossQtgt_sigm: 0.1373\n",
      "Episode: 973 meanReward: 227.0000 meanLoss: 299.6270 meanLossQlbl: 1.8324 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 296.9467 meanLossQtgt_sigm: 0.8478\n",
      "Episode: 974 meanReward: 233.5000 meanLoss: 23.1143 meanLossQlbl: 0.7066 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.3404 meanLossQtgt_sigm: 0.0673\n",
      "Episode: 975 meanReward: 247.6250 meanLoss: 18.0474 meanLossQlbl: 0.1744 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8226 meanLossQtgt_sigm: 0.0504\n",
      "Episode: 976 meanReward: 262.8750 meanLoss: 17.0870 meanLossQlbl: 0.1483 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8893 meanLossQtgt_sigm: 0.0494\n",
      "Episode: 977 meanReward: 271.4375 meanLoss: 29.0534 meanLossQlbl: 0.3719 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.5985 meanLossQtgt_sigm: 0.0830\n",
      "Episode: 978 meanReward: 284.9062 meanLoss: 9.8967 meanLossQlbl: 0.1002 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.7584 meanLossQtgt_sigm: 0.0382\n",
      "Episode: 979 meanReward: 284.9688 meanLoss: 289.8123 meanLossQlbl: 0.6732 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 288.2935 meanLossQtgt_sigm: 0.8456\n",
      "Episode: 980 meanReward: 281.9062 meanLoss: 466.3092 meanLossQlbl: 1.8278 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 463.0142 meanLossQtgt_sigm: 1.4672\n",
      "Episode: 981 meanReward: 266.6250 meanLoss: 412.6928 meanLossQlbl: 1.2419 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 410.0311 meanLossQtgt_sigm: 1.4199\n",
      "Episode: 982 meanReward: 262.7188 meanLoss: 201.4827 meanLossQlbl: 0.7947 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 199.9369 meanLossQtgt_sigm: 0.7511\n",
      "Episode: 983 meanReward: 254.9062 meanLoss: 114.8424 meanLossQlbl: 3.4895 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 111.0437 meanLossQtgt_sigm: 0.3091\n",
      "Episode: 984 meanReward: 265.7500 meanLoss: 6.3341 meanLossQlbl: 0.5801 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.7311 meanLossQtgt_sigm: 0.0228\n",
      "Episode: 985 meanReward: 270.9688 meanLoss: 16.9392 meanLossQlbl: 0.0572 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8337 meanLossQtgt_sigm: 0.0483\n",
      "Episode: 986 meanReward: 281.3438 meanLoss: 17.1953 meanLossQlbl: 0.2719 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8743 meanLossQtgt_sigm: 0.0491\n",
      "Episode: 987 meanReward: 281.3438 meanLoss: 17.4735 meanLossQlbl: 0.2097 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.2153 meanLossQtgt_sigm: 0.0485\n",
      "Episode: 988 meanReward: 282.6562 meanLoss: 68.3260 meanLossQlbl: 0.7934 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.3433 meanLossQtgt_sigm: 0.1893\n",
      "Episode: 989 meanReward: 282.6562 meanLoss: 10.4706 meanLossQlbl: 0.1067 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.3254 meanLossQtgt_sigm: 0.0385\n",
      "Episode: 990 meanReward: 275.0625 meanLoss: 35.8522 meanLossQlbl: 0.2868 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.4675 meanLossQtgt_sigm: 0.0980\n",
      "Episode: 991 meanReward: 283.4688 meanLoss: 12.4430 meanLossQlbl: 0.1099 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.2907 meanLossQtgt_sigm: 0.0424\n",
      "Episode: 992 meanReward: 280.0938 meanLoss: 91.3561 meanLossQlbl: 0.4183 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 90.6753 meanLossQtgt_sigm: 0.2626\n",
      "Episode: 993 meanReward: 286.5312 meanLoss: 9.5445 meanLossQlbl: 0.5139 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.0018 meanLossQtgt_sigm: 0.0288\n",
      "Episode: 994 meanReward: 284.4375 meanLoss: 332.1768 meanLossQlbl: 2.6356 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 328.6561 meanLossQtgt_sigm: 0.8851\n",
      "Episode: 995 meanReward: 278.9062 meanLoss: 388.9481 meanLossQlbl: 5.0657 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 382.6882 meanLossQtgt_sigm: 1.1942\n",
      "Episode: 996 meanReward: 266.2812 meanLoss: 66.7201 meanLossQlbl: 1.2012 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 65.3129 meanLossQtgt_sigm: 0.2060\n",
      "Episode: 997 meanReward: 265.5938 meanLoss: 16.0745 meanLossQlbl: 0.3290 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.6808 meanLossQtgt_sigm: 0.0647\n",
      "Episode: 998 meanReward: 252.5938 meanLoss: 49.8541 meanLossQlbl: 0.8460 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 48.8216 meanLossQtgt_sigm: 0.1865\n",
      "Episode: 999 meanReward: 254.5000 meanLoss: 17.4146 meanLossQlbl: 0.9367 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.4346 meanLossQtgt_sigm: 0.0434\n",
      "Episode: 1000 meanReward: 242.6875 meanLoss: 16.4643 meanLossQlbl: 0.7436 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.6413 meanLossQtgt_sigm: 0.0794\n",
      "Episode: 1001 meanReward: 257.1875 meanLoss: 2.4696 meanLossQlbl: 0.0228 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.4300 meanLossQtgt_sigm: 0.0168\n",
      "Episode: 1002 meanReward: 257.1875 meanLoss: 16.7134 meanLossQlbl: 0.1128 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5529 meanLossQtgt_sigm: 0.0476\n",
      "Episode: 1003 meanReward: 261.3438 meanLoss: 30.8599 meanLossQlbl: 0.1889 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 30.5871 meanLossQtgt_sigm: 0.0839\n",
      "Episode: 1004 meanReward: 261.6250 meanLoss: 11.8950 meanLossQlbl: 0.2300 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.6029 meanLossQtgt_sigm: 0.0620\n",
      "Episode: 1005 meanReward: 266.1875 meanLoss: 16.3668 meanLossQlbl: 0.6662 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.6316 meanLossQtgt_sigm: 0.0690\n",
      "Episode: 1006 meanReward: 255.5312 meanLoss: 11.9507 meanLossQlbl: 0.8135 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.0746 meanLossQtgt_sigm: 0.0627\n",
      "Episode: 1007 meanReward: 244.7812 meanLoss: 20.0601 meanLossQlbl: 0.6866 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.2892 meanLossQtgt_sigm: 0.0842\n",
      "Episode: 1008 meanReward: 239.4375 meanLoss: 7.9329 meanLossQlbl: 0.1976 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.6966 meanLossQtgt_sigm: 0.0388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1009 meanReward: 234.6875 meanLoss: 28.5571 meanLossQlbl: 1.6943 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.7585 meanLossQtgt_sigm: 0.1043\n",
      "Episode: 1010 meanReward: 221.2500 meanLoss: 109.0402 meanLossQlbl: 2.0267 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 106.5210 meanLossQtgt_sigm: 0.4925\n",
      "Episode: 1011 meanReward: 221.3438 meanLoss: 273.0949 meanLossQlbl: 0.9284 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 271.1129 meanLossQtgt_sigm: 1.0537\n",
      "Episode: 1012 meanReward: 221.4688 meanLoss: 258.7530 meanLossQlbl: 8.0065 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 249.7640 meanLossQtgt_sigm: 0.9825\n",
      "Episode: 1013 meanReward: 225.1250 meanLoss: 38.0724 meanLossQlbl: 2.5753 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.3634 meanLossQtgt_sigm: 0.1337\n",
      "Episode: 1014 meanReward: 240.4062 meanLoss: 5.0556 meanLossQlbl: 0.0622 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.9686 meanLossQtgt_sigm: 0.0248\n",
      "Episode: 1015 meanReward: 255.6250 meanLoss: 18.2748 meanLossQlbl: 0.0653 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.1591 meanLossQtgt_sigm: 0.0503\n",
      "Episode: 1016 meanReward: 240.3438 meanLoss: 326.0529 meanLossQlbl: 0.2496 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 324.9008 meanLossQtgt_sigm: 0.9026\n",
      "Episode: 1017 meanReward: 225.0625 meanLoss: 538.0284 meanLossQlbl: 1.4111 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 535.0233 meanLossQtgt_sigm: 1.5940\n",
      "Episode: 1018 meanReward: 225.0625 meanLoss: 19.8394 meanLossQlbl: 0.4188 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.3551 meanLossQtgt_sigm: 0.0655\n",
      "Episode: 1019 meanReward: 210.6562 meanLoss: 189.9036 meanLossQlbl: 3.1337 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 186.1921 meanLossQtgt_sigm: 0.5777\n",
      "Episode: 1020 meanReward: 217.4062 meanLoss: 5.6577 meanLossQlbl: 0.3529 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.2916 meanLossQtgt_sigm: 0.0131\n",
      "Episode: 1021 meanReward: 217.4062 meanLoss: 13.2028 meanLossQlbl: 0.2812 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.8886 meanLossQtgt_sigm: 0.0330\n",
      "Episode: 1022 meanReward: 225.0000 meanLoss: 19.7250 meanLossQlbl: 0.1336 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.5388 meanLossQtgt_sigm: 0.0525\n",
      "Episode: 1023 meanReward: 225.0000 meanLoss: 21.4220 meanLossQlbl: 0.1731 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.1938 meanLossQtgt_sigm: 0.0551\n",
      "Episode: 1024 meanReward: 237.6562 meanLoss: 19.5763 meanLossQlbl: 0.3208 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.2028 meanLossQtgt_sigm: 0.0526\n",
      "Episode: 1025 meanReward: 237.6562 meanLoss: 18.7558 meanLossQlbl: 0.1754 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5288 meanLossQtgt_sigm: 0.0516\n",
      "Episode: 1026 meanReward: 252.9062 meanLoss: 18.4476 meanLossQlbl: 0.1334 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2626 meanLossQtgt_sigm: 0.0516\n",
      "Episode: 1027 meanReward: 256.9062 meanLoss: 56.8759 meanLossQlbl: 0.9558 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.7614 meanLossQtgt_sigm: 0.1587\n",
      "Episode: 1028 meanReward: 258.9688 meanLoss: 17.1607 meanLossQlbl: 0.6343 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.4668 meanLossQtgt_sigm: 0.0596\n",
      "Episode: 1029 meanReward: 255.0312 meanLoss: 87.5285 meanLossQlbl: 2.0079 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 85.1256 meanLossQtgt_sigm: 0.3951\n",
      "Episode: 1030 meanReward: 268.0312 meanLoss: 9.8385 meanLossQlbl: 0.1913 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.6132 meanLossQtgt_sigm: 0.0340\n",
      "Episode: 1031 meanReward: 279.3750 meanLoss: 17.7529 meanLossQlbl: 0.1754 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.5276 meanLossQtgt_sigm: 0.0499\n",
      "Episode: 1032 meanReward: 280.4375 meanLoss: 56.3866 meanLossQlbl: 0.5005 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.7291 meanLossQtgt_sigm: 0.1570\n",
      "Episode: 1033 meanReward: 273.3438 meanLoss: 14.6711 meanLossQlbl: 0.2338 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.3814 meanLossQtgt_sigm: 0.0558\n",
      "Episode: 1034 meanReward: 273.3438 meanLoss: 4.0487 meanLossQlbl: 0.1654 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.8693 meanLossQtgt_sigm: 0.0141\n",
      "Episode: 1035 meanReward: 270.5000 meanLoss: 44.6507 meanLossQlbl: 0.4672 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.0618 meanLossQtgt_sigm: 0.1217\n",
      "Episode: 1036 meanReward: 280.9375 meanLoss: 7.0892 meanLossQlbl: 0.1631 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.8962 meanLossQtgt_sigm: 0.0299\n",
      "Episode: 1037 meanReward: 281.5938 meanLoss: 28.5443 meanLossQlbl: 0.2870 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.1564 meanLossQtgt_sigm: 0.1009\n",
      "Episode: 1038 meanReward: 282.3750 meanLoss: 11.8534 meanLossQlbl: 0.3828 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.4140 meanLossQtgt_sigm: 0.0565\n",
      "Episode: 1039 meanReward: 284.1562 meanLoss: 7.7960 meanLossQlbl: 0.3928 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.3636 meanLossQtgt_sigm: 0.0396\n",
      "Episode: 1040 meanReward: 285.0312 meanLoss: 8.6002 meanLossQlbl: 0.2444 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.3228 meanLossQtgt_sigm: 0.0329\n",
      "Episode: 1041 meanReward: 283.3125 meanLoss: 57.6437 meanLossQlbl: 1.1331 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 56.3236 meanLossQtgt_sigm: 0.1869\n",
      "Episode: 1042 meanReward: 285.4688 meanLoss: 16.7021 meanLossQlbl: 0.8729 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 15.7852 meanLossQtgt_sigm: 0.0439\n",
      "Episode: 1043 meanReward: 300.6250 meanLoss: 2.1003 meanLossQlbl: 0.0646 meanLossQlbl_sigm: 0.0003 meanLossQtgt: 2.0270 meanLossQtgt_sigm: 0.0084\n",
      "Episode: 1044 meanReward: 315.8125 meanLoss: 18.5287 meanLossQlbl: 0.0547 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4226 meanLossQtgt_sigm: 0.0514\n",
      "Episode: 1045 meanReward: 316.5000 meanLoss: 57.3200 meanLossQlbl: 0.6933 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 56.4642 meanLossQtgt_sigm: 0.1624\n",
      "Episode: 1046 meanReward: 301.2188 meanLoss: 220.1676 meanLossQlbl: 0.2684 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 219.2648 meanLossQtgt_sigm: 0.6343\n",
      "Episode: 1047 meanReward: 295.2812 meanLoss: 27.8061 meanLossQlbl: 2.6202 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.1308 meanLossQtgt_sigm: 0.0551\n",
      "Episode: 1048 meanReward: 310.5625 meanLoss: 15.6005 meanLossQlbl: 0.1012 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.4518 meanLossQtgt_sigm: 0.0475\n",
      "Episode: 1049 meanReward: 313.9375 meanLoss: 78.6236 meanLossQlbl: 0.3885 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 78.0185 meanLossQtgt_sigm: 0.2167\n",
      "Episode: 1050 meanReward: 313.9375 meanLoss: 13.4173 meanLossQlbl: 0.0946 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2792 meanLossQtgt_sigm: 0.0435\n",
      "Episode: 1051 meanReward: 328.3438 meanLoss: 18.3624 meanLossQlbl: 0.2914 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.0212 meanLossQtgt_sigm: 0.0498\n",
      "Episode: 1052 meanReward: 326.1875 meanLoss: 33.0488 meanLossQlbl: 0.5607 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.3991 meanLossQtgt_sigm: 0.0890\n",
      "Episode: 1053 meanReward: 310.8750 meanLoss: 184.7287 meanLossQlbl: 0.5377 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 183.5507 meanLossQtgt_sigm: 0.6404\n",
      "Episode: 1054 meanReward: 295.5625 meanLoss: 188.2484 meanLossQlbl: 4.0711 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 183.4617 meanLossQtgt_sigm: 0.7157\n",
      "Episode: 1055 meanReward: 280.2188 meanLoss: 214.5083 meanLossQlbl: 3.1279 meanLossQlbl_sigm: 0.0016 meanLossQtgt: 210.6791 meanLossQtgt_sigm: 0.6997\n",
      "Episode: 1056 meanReward: 266.3125 meanLoss: 81.4506 meanLossQlbl: 5.0723 meanLossQlbl_sigm: 0.0549 meanLossQtgt: 76.1454 meanLossQtgt_sigm: 0.1780\n",
      "Episode: 1057 meanReward: 251.3438 meanLoss: 209.1761 meanLossQlbl: 0.0158 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 208.4625 meanLossQtgt_sigm: 0.6979\n",
      "Episode: 1058 meanReward: 236.1250 meanLoss: 319.3600 meanLossQlbl: 0.2040 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 318.0021 meanLossQtgt_sigm: 1.1538\n",
      "Episode: 1059 meanReward: 231.5938 meanLoss: 328.3848 meanLossQlbl: 0.1627 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 326.9842 meanLossQtgt_sigm: 1.2379\n",
      "Episode: 1060 meanReward: 226.9688 meanLoss: 345.2449 meanLossQlbl: 0.0492 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 343.8281 meanLossQtgt_sigm: 1.3676\n",
      "Episode: 1061 meanReward: 230.7188 meanLoss: 33.6882 meanLossQlbl: 1.3891 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.1840 meanLossQtgt_sigm: 0.1151\n",
      "Episode: 1062 meanReward: 230.7188 meanLoss: 11.0975 meanLossQlbl: 0.2788 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.7830 meanLossQtgt_sigm: 0.0357\n",
      "Episode: 1063 meanReward: 230.7188 meanLoss: 17.2879 meanLossQlbl: 0.2117 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0264 meanLossQtgt_sigm: 0.0497\n",
      "Episode: 1064 meanReward: 230.0938 meanLoss: 58.1960 meanLossQlbl: 0.2457 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 57.7786 meanLossQtgt_sigm: 0.1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1065 meanReward: 237.1875 meanLoss: 9.0699 meanLossQlbl: 0.3067 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.7297 meanLossQtgt_sigm: 0.0335\n",
      "Episode: 1066 meanReward: 237.1875 meanLoss: 18.4059 meanLossQlbl: 0.1063 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2487 meanLossQtgt_sigm: 0.0510\n",
      "Episode: 1067 meanReward: 246.4375 meanLoss: 15.1017 meanLossQlbl: 0.0368 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.0188 meanLossQtgt_sigm: 0.0461\n",
      "Episode: 1068 meanReward: 239.6250 meanLoss: 28.8130 meanLossQlbl: 0.5580 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.1755 meanLossQtgt_sigm: 0.0795\n",
      "Episode: 1069 meanReward: 234.2188 meanLoss: 95.4923 meanLossQlbl: 1.7293 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 93.5185 meanLossQtgt_sigm: 0.2445\n",
      "Episode: 1070 meanReward: 234.6562 meanLoss: 21.9534 meanLossQlbl: 1.9914 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.9185 meanLossQtgt_sigm: 0.0436\n",
      "Episode: 1071 meanReward: 242.7500 meanLoss: 6.1585 meanLossQlbl: 0.5907 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.5457 meanLossQtgt_sigm: 0.0222\n",
      "Episode: 1072 meanReward: 247.2188 meanLoss: 7.2671 meanLossQlbl: 0.2070 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.0393 meanLossQtgt_sigm: 0.0207\n",
      "Episode: 1073 meanReward: 255.0000 meanLoss: 36.2659 meanLossQlbl: 0.6166 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.5667 meanLossQtgt_sigm: 0.0826\n",
      "Episode: 1074 meanReward: 268.0938 meanLoss: 8.2995 meanLossQlbl: 0.1168 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.1520 meanLossQtgt_sigm: 0.0306\n",
      "Episode: 1075 meanReward: 257.7500 meanLoss: 44.0231 meanLossQlbl: 0.1673 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.7254 meanLossQtgt_sigm: 0.1303\n",
      "Episode: 1076 meanReward: 242.4688 meanLoss: 168.7919 meanLossQlbl: 0.4497 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 167.8756 meanLossQtgt_sigm: 0.4666\n",
      "Episode: 1077 meanReward: 253.4062 meanLoss: 9.7535 meanLossQlbl: 0.2260 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.4976 meanLossQtgt_sigm: 0.0300\n",
      "Episode: 1078 meanReward: 253.9062 meanLoss: 305.2501 meanLossQlbl: 2.9343 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 301.4771 meanLossQtgt_sigm: 0.8386\n",
      "Episode: 1079 meanReward: 244.6562 meanLoss: 364.0412 meanLossQlbl: 1.2394 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 361.7471 meanLossQtgt_sigm: 1.0546\n",
      "Episode: 1080 meanReward: 232.1250 meanLoss: 108.1477 meanLossQlbl: 0.1190 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 107.6834 meanLossQtgt_sigm: 0.3453\n",
      "Episode: 1081 meanReward: 244.0312 meanLoss: 7.3279 meanLossQlbl: 0.0625 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.2359 meanLossQtgt_sigm: 0.0295\n",
      "Episode: 1082 meanReward: 244.0312 meanLoss: 17.0394 meanLossQlbl: 0.0566 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9339 meanLossQtgt_sigm: 0.0489\n",
      "Episode: 1083 meanReward: 244.0312 meanLoss: 17.0899 meanLossQlbl: 0.0917 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9499 meanLossQtgt_sigm: 0.0483\n",
      "Episode: 1084 meanReward: 236.8750 meanLoss: 156.4153 meanLossQlbl: 2.1030 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 153.8491 meanLossQtgt_sigm: 0.4632\n",
      "Episode: 1085 meanReward: 245.1562 meanLoss: 25.9160 meanLossQlbl: 0.3249 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.5134 meanLossQtgt_sigm: 0.0777\n",
      "Episode: 1086 meanReward: 247.4688 meanLoss: 72.0296 meanLossQlbl: 0.2964 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 71.4919 meanLossQtgt_sigm: 0.2413\n",
      "Episode: 1087 meanReward: 253.0625 meanLoss: 13.5074 meanLossQlbl: 1.8131 meanLossQlbl_sigm: 0.0012 meanLossQtgt: 11.6721 meanLossQtgt_sigm: 0.0210\n",
      "Episode: 1088 meanReward: 251.6562 meanLoss: 94.8389 meanLossQlbl: 0.4958 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 93.9113 meanLossQtgt_sigm: 0.4319\n",
      "Episode: 1089 meanReward: 255.3750 meanLoss: 25.9640 meanLossQlbl: 2.3148 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.5638 meanLossQtgt_sigm: 0.0854\n",
      "Episode: 1090 meanReward: 259.5312 meanLoss: 20.6751 meanLossQlbl: 0.7254 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.8680 meanLossQtgt_sigm: 0.0816\n",
      "Episode: 1091 meanReward: 262.1250 meanLoss: 54.4205 meanLossQlbl: 0.3096 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 53.9117 meanLossQtgt_sigm: 0.1992\n",
      "Episode: 1092 meanReward: 264.9375 meanLoss: 26.2890 meanLossQlbl: 1.1150 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.0594 meanLossQtgt_sigm: 0.1145\n",
      "Episode: 1093 meanReward: 264.0938 meanLoss: 6.3461 meanLossQlbl: 0.1235 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.1817 meanLossQtgt_sigm: 0.0409\n",
      "Episode: 1094 meanReward: 264.0938 meanLoss: 2.1339 meanLossQlbl: 0.1670 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.9580 meanLossQtgt_sigm: 0.0089\n",
      "Episode: 1095 meanReward: 252.2812 meanLoss: 72.6072 meanLossQlbl: 1.0512 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 71.3582 meanLossQtgt_sigm: 0.1978\n",
      "Episode: 1096 meanReward: 254.9375 meanLoss: 9.3759 meanLossQlbl: 0.9906 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.3649 meanLossQtgt_sigm: 0.0204\n",
      "Episode: 1097 meanReward: 239.5938 meanLoss: 251.3363 meanLossQlbl: 0.4968 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 250.1180 meanLossQtgt_sigm: 0.7215\n",
      "Episode: 1098 meanReward: 228.7812 meanLoss: 37.9384 meanLossQlbl: 2.6780 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.1423 meanLossQtgt_sigm: 0.1181\n",
      "Episode: 1099 meanReward: 217.1562 meanLoss: 39.0273 meanLossQlbl: 0.1627 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 38.7211 meanLossQtgt_sigm: 0.1435\n",
      "Episode: 1100 meanReward: 212.1250 meanLoss: 56.2794 meanLossQlbl: 0.6736 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 55.4314 meanLossQtgt_sigm: 0.1744\n",
      "Episode: 1101 meanReward: 216.7188 meanLoss: 11.8265 meanLossQlbl: 1.1210 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.6562 meanLossQtgt_sigm: 0.0492\n",
      "Episode: 1102 meanReward: 226.1562 meanLoss: 4.6617 meanLossQlbl: 0.0510 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.5880 meanLossQtgt_sigm: 0.0227\n",
      "Episode: 1103 meanReward: 213.0938 meanLoss: 168.3217 meanLossQlbl: 2.7610 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 165.0920 meanLossQtgt_sigm: 0.4687\n",
      "Episode: 1104 meanReward: 201.2500 meanLoss: 58.1850 meanLossQlbl: 0.4936 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 57.5170 meanLossQtgt_sigm: 0.1745\n",
      "Episode: 1105 meanReward: 197.7188 meanLoss: 9.7170 meanLossQlbl: 0.3301 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.3409 meanLossQtgt_sigm: 0.0459\n",
      "Episode: 1106 meanReward: 187.4375 meanLoss: 34.1144 meanLossQlbl: 0.8720 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.1304 meanLossQtgt_sigm: 0.1120\n",
      "Episode: 1107 meanReward: 197.7812 meanLoss: 11.4172 meanLossQlbl: 0.2705 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.1080 meanLossQtgt_sigm: 0.0388\n",
      "Episode: 1108 meanReward: 197.9375 meanLoss: 298.9496 meanLossQlbl: 1.5565 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 296.5443 meanLossQtgt_sigm: 0.8489\n",
      "Episode: 1109 meanReward: 182.7500 meanLoss: 542.8851 meanLossQlbl: 3.1568 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 538.1485 meanLossQtgt_sigm: 1.5798\n",
      "Episode: 1110 meanReward: 182.2188 meanLoss: 343.7234 meanLossQlbl: 10.0900 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 332.5147 meanLossQtgt_sigm: 1.1186\n",
      "Episode: 1111 meanReward: 188.1875 meanLoss: 25.9720 meanLossQlbl: 2.9792 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.9306 meanLossQtgt_sigm: 0.0622\n",
      "Episode: 1112 meanReward: 200.7188 meanLoss: 9.9247 meanLossQlbl: 0.1531 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.7382 meanLossQtgt_sigm: 0.0334\n",
      "Episode: 1113 meanReward: 199.2812 meanLoss: 14.1633 meanLossQlbl: 0.2435 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.8735 meanLossQtgt_sigm: 0.0462\n",
      "Episode: 1114 meanReward: 199.2812 meanLoss: 12.3559 meanLossQlbl: 0.0769 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.2375 meanLossQtgt_sigm: 0.0415\n",
      "Episode: 1115 meanReward: 199.2812 meanLoss: 19.6337 meanLossQlbl: 0.6095 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.9733 meanLossQtgt_sigm: 0.0509\n",
      "Episode: 1116 meanReward: 213.2812 meanLoss: 19.4230 meanLossQlbl: 0.1794 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.1911 meanLossQtgt_sigm: 0.0525\n",
      "Episode: 1117 meanReward: 220.3125 meanLoss: 18.7289 meanLossQlbl: 0.1893 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4886 meanLossQtgt_sigm: 0.0510\n",
      "Episode: 1118 meanReward: 218.9062 meanLoss: 239.2142 meanLossQlbl: 4.0656 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 234.4882 meanLossQtgt_sigm: 0.6603\n",
      "Episode: 1119 meanReward: 219.7188 meanLoss: 32.5389 meanLossQlbl: 0.1874 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.2485 meanLossQtgt_sigm: 0.1029\n",
      "Episode: 1120 meanReward: 220.0625 meanLoss: 264.7185 meanLossQlbl: 0.0712 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 263.8501 meanLossQtgt_sigm: 0.7973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1121 meanReward: 216.3750 meanLoss: 305.7656 meanLossQlbl: 0.6461 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 304.1408 meanLossQtgt_sigm: 0.9787\n",
      "Episode: 1122 meanReward: 223.3750 meanLoss: 13.8921 meanLossQlbl: 0.9635 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.8966 meanLossQtgt_sigm: 0.0320\n",
      "Episode: 1123 meanReward: 223.4688 meanLoss: 18.9626 meanLossQlbl: 1.3442 meanLossQlbl_sigm: 0.0003 meanLossQtgt: 17.5923 meanLossQtgt_sigm: 0.0257\n",
      "Episode: 1124 meanReward: 223.0312 meanLoss: 10.4581 meanLossQlbl: 1.1813 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.2383 meanLossQtgt_sigm: 0.0385\n",
      "Episode: 1125 meanReward: 223.2500 meanLoss: 9.9843 meanLossQlbl: 0.5720 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.3714 meanLossQtgt_sigm: 0.0409\n",
      "Episode: 1126 meanReward: 210.8750 meanLoss: 22.9556 meanLossQlbl: 0.3299 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.5206 meanLossQtgt_sigm: 0.1051\n",
      "Episode: 1127 meanReward: 210.7188 meanLoss: 9.0392 meanLossQlbl: 0.6396 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.3581 meanLossQtgt_sigm: 0.0415\n",
      "Episode: 1128 meanReward: 206.1562 meanLoss: 29.5298 meanLossQlbl: 0.2588 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.1107 meanLossQtgt_sigm: 0.1604\n",
      "Episode: 1129 meanReward: 207.8438 meanLoss: 32.4491 meanLossQlbl: 0.2928 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.9711 meanLossQtgt_sigm: 0.1852\n",
      "Episode: 1130 meanReward: 206.6875 meanLoss: 13.1515 meanLossQlbl: 0.0397 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.0364 meanLossQtgt_sigm: 0.0754\n",
      "Episode: 1131 meanReward: 207.4062 meanLoss: 8.5346 meanLossQlbl: 0.8602 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.6423 meanLossQtgt_sigm: 0.0321\n",
      "Episode: 1132 meanReward: 206.3125 meanLoss: 18.4100 meanLossQlbl: 0.0454 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2529 meanLossQtgt_sigm: 0.1117\n",
      "Episode: 1133 meanReward: 205.2500 meanLoss: 6.2166 meanLossQlbl: 0.1054 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.0744 meanLossQtgt_sigm: 0.0368\n",
      "Episode: 1134 meanReward: 195.4375 meanLoss: 9.3397 meanLossQlbl: 0.2201 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.0697 meanLossQtgt_sigm: 0.0499\n",
      "Episode: 1135 meanReward: 200.9375 meanLoss: 9.4009 meanLossQlbl: 0.0898 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.2627 meanLossQtgt_sigm: 0.0484\n",
      "Episode: 1136 meanReward: 203.8125 meanLoss: 11.4165 meanLossQlbl: 0.2303 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.1290 meanLossQtgt_sigm: 0.0572\n",
      "Episode: 1137 meanReward: 203.5625 meanLoss: 12.9644 meanLossQlbl: 0.1712 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.7299 meanLossQtgt_sigm: 0.0633\n",
      "Episode: 1138 meanReward: 213.8438 meanLoss: 5.4677 meanLossQlbl: 0.0582 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.3834 meanLossQtgt_sigm: 0.0261\n",
      "Episode: 1139 meanReward: 202.7188 meanLoss: 67.9272 meanLossQlbl: 0.4593 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.2846 meanLossQtgt_sigm: 0.1833\n",
      "Episode: 1140 meanReward: 217.8438 meanLoss: 13.5857 meanLossQlbl: 0.0885 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.4530 meanLossQtgt_sigm: 0.0442\n",
      "Episode: 1141 meanReward: 230.9688 meanLoss: 14.1497 meanLossQlbl: 0.1963 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.9069 meanLossQtgt_sigm: 0.0465\n",
      "Episode: 1142 meanReward: 246.2812 meanLoss: 5.4879 meanLossQlbl: 0.0367 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.4247 meanLossQtgt_sigm: 0.0266\n",
      "Episode: 1143 meanReward: 255.5000 meanLoss: 16.6471 meanLossQlbl: 0.1870 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.4122 meanLossQtgt_sigm: 0.0480\n",
      "Episode: 1144 meanReward: 255.5000 meanLoss: 17.4083 meanLossQlbl: 0.2081 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.1504 meanLossQtgt_sigm: 0.0499\n",
      "Episode: 1145 meanReward: 245.5938 meanLoss: 48.7602 meanLossQlbl: 0.8664 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 47.7399 meanLossQtgt_sigm: 0.1539\n",
      "Episode: 1146 meanReward: 245.5938 meanLoss: 2.0637 meanLossQlbl: 0.0834 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.9680 meanLossQtgt_sigm: 0.0122\n",
      "Episode: 1147 meanReward: 245.5938 meanLoss: 18.2374 meanLossQlbl: 0.3423 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8444 meanLossQtgt_sigm: 0.0507\n",
      "Episode: 1148 meanReward: 245.5938 meanLoss: 18.3474 meanLossQlbl: 0.1888 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.1075 meanLossQtgt_sigm: 0.0511\n",
      "Episode: 1149 meanReward: 245.5938 meanLoss: 18.8309 meanLossQlbl: 0.2126 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5667 meanLossQtgt_sigm: 0.0515\n",
      "Episode: 1150 meanReward: 251.8438 meanLoss: 36.4497 meanLossQlbl: 0.3765 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.9688 meanLossQtgt_sigm: 0.1043\n",
      "Episode: 1151 meanReward: 260.7812 meanLoss: 14.7152 meanLossQlbl: 0.0687 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.6006 meanLossQtgt_sigm: 0.0459\n",
      "Episode: 1152 meanReward: 275.7500 meanLoss: 16.5671 meanLossQlbl: 0.2158 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.3040 meanLossQtgt_sigm: 0.0473\n",
      "Episode: 1153 meanReward: 275.4062 meanLoss: 293.7387 meanLossQlbl: 2.3291 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 290.5606 meanLossQtgt_sigm: 0.8490\n",
      "Episode: 1154 meanReward: 278.6875 meanLoss: 21.9035 meanLossQlbl: 1.5491 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.3110 meanLossQtgt_sigm: 0.0434\n",
      "Episode: 1155 meanReward: 280.1562 meanLoss: 25.8569 meanLossQlbl: 1.2921 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.4601 meanLossQtgt_sigm: 0.1047\n",
      "Episode: 1156 meanReward: 282.0625 meanLoss: 30.5175 meanLossQlbl: 0.6161 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.7890 meanLossQtgt_sigm: 0.1124\n",
      "Episode: 1157 meanReward: 281.4688 meanLoss: 44.1999 meanLossQlbl: 0.2111 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.8117 meanLossQtgt_sigm: 0.1771\n",
      "Episode: 1158 meanReward: 286.2812 meanLoss: 16.1768 meanLossQlbl: 0.3990 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.7171 meanLossQtgt_sigm: 0.0608\n",
      "Episode: 1159 meanReward: 283.5938 meanLoss: 170.1127 meanLossQlbl: 0.5064 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 168.9779 meanLossQtgt_sigm: 0.6284\n",
      "Episode: 1160 meanReward: 282.3438 meanLoss: 207.0393 meanLossQlbl: 0.0969 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 206.2903 meanLossQtgt_sigm: 0.6522\n",
      "Episode: 1161 meanReward: 283.8125 meanLoss: 45.0852 meanLossQlbl: 0.2957 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.6250 meanLossQtgt_sigm: 0.1646\n",
      "Episode: 1162 meanReward: 295.7812 meanLoss: 7.3776 meanLossQlbl: 0.0400 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.3073 meanLossQtgt_sigm: 0.0303\n",
      "Episode: 1163 meanReward: 306.6875 meanLoss: 17.0212 meanLossQlbl: 0.0582 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9140 meanLossQtgt_sigm: 0.0490\n",
      "Episode: 1164 meanReward: 319.6250 meanLoss: 14.0598 meanLossQlbl: 0.2656 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.7498 meanLossQtgt_sigm: 0.0445\n",
      "Episode: 1165 meanReward: 331.3750 meanLoss: 16.2087 meanLossQlbl: 0.0803 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.0805 meanLossQtgt_sigm: 0.0479\n",
      "Episode: 1166 meanReward: 341.1875 meanLoss: 16.3756 meanLossQlbl: 0.1311 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.1959 meanLossQtgt_sigm: 0.0486\n",
      "Episode: 1167 meanReward: 349.6250 meanLoss: 14.4676 meanLossQlbl: 0.0959 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.3273 meanLossQtgt_sigm: 0.0444\n",
      "Episode: 1168 meanReward: 347.5312 meanLoss: 62.9029 meanLossQlbl: 1.9471 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 60.7916 meanLossQtgt_sigm: 0.1641\n",
      "Episode: 1169 meanReward: 341.4688 meanLoss: 100.4149 meanLossQlbl: 0.1783 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 99.7501 meanLossQtgt_sigm: 0.4865\n",
      "Episode: 1170 meanReward: 328.0312 meanLoss: 86.6853 meanLossQlbl: 0.4273 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 85.9181 meanLossQtgt_sigm: 0.3399\n",
      "Episode: 1171 meanReward: 339.1562 meanLoss: 3.3648 meanLossQlbl: 0.1958 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.1537 meanLossQtgt_sigm: 0.0153\n",
      "Episode: 1172 meanReward: 339.1562 meanLoss: 16.2099 meanLossQlbl: 0.0920 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.0696 meanLossQtgt_sigm: 0.0482\n",
      "Episode: 1173 meanReward: 341.2188 meanLoss: 17.2358 meanLossQlbl: 0.1604 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0280 meanLossQtgt_sigm: 0.0474\n",
      "Episode: 1174 meanReward: 329.8438 meanLoss: 68.6853 meanLossQlbl: 0.6545 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.8471 meanLossQtgt_sigm: 0.1837\n",
      "Episode: 1175 meanReward: 314.7500 meanLoss: 85.9291 meanLossQlbl: 2.8468 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 82.6524 meanLossQtgt_sigm: 0.4299\n",
      "Episode: 1176 meanReward: 302.8125 meanLoss: 35.5859 meanLossQlbl: 3.3255 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.1412 meanLossQtgt_sigm: 0.1192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1177 meanReward: 302.1562 meanLoss: 19.6360 meanLossQlbl: 0.0838 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.4499 meanLossQtgt_sigm: 0.1023\n",
      "Episode: 1178 meanReward: 290.4688 meanLoss: 13.6803 meanLossQlbl: 0.3103 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2917 meanLossQtgt_sigm: 0.0782\n",
      "Episode: 1179 meanReward: 278.4062 meanLoss: 16.6189 meanLossQlbl: 0.0754 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.4493 meanLossQtgt_sigm: 0.0943\n",
      "Episode: 1180 meanReward: 266.3750 meanLoss: 13.0450 meanLossQlbl: 0.2580 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.7136 meanLossQtgt_sigm: 0.0734\n",
      "Episode: 1181 meanReward: 254.6562 meanLoss: 16.7221 meanLossQlbl: 0.1279 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5017 meanLossQtgt_sigm: 0.0925\n",
      "Episode: 1182 meanReward: 251.6875 meanLoss: 15.7443 meanLossQlbl: 0.6248 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.0419 meanLossQtgt_sigm: 0.0776\n",
      "Episode: 1183 meanReward: 240.4062 meanLoss: 19.2202 meanLossQlbl: 0.1006 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.0256 meanLossQtgt_sigm: 0.0939\n",
      "Episode: 1184 meanReward: 225.2188 meanLoss: 67.9526 meanLossQlbl: 0.0230 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.5290 meanLossQtgt_sigm: 0.4006\n",
      "Episode: 1185 meanReward: 240.5000 meanLoss: 8.1316 meanLossQlbl: 0.3659 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.7326 meanLossQtgt_sigm: 0.0331\n",
      "Episode: 1186 meanReward: 241.2812 meanLoss: 12.6140 meanLossQlbl: 0.2018 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.3706 meanLossQtgt_sigm: 0.0416\n",
      "Episode: 1187 meanReward: 252.3438 meanLoss: 18.0294 meanLossQlbl: 0.2884 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.6904 meanLossQtgt_sigm: 0.0506\n",
      "Episode: 1188 meanReward: 248.8438 meanLoss: 233.1152 meanLossQlbl: 2.0123 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 230.4517 meanLossQtgt_sigm: 0.6512\n",
      "Episode: 1189 meanReward: 261.4375 meanLoss: 7.7653 meanLossQlbl: 0.4395 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.2986 meanLossQtgt_sigm: 0.0272\n",
      "Episode: 1190 meanReward: 254.6250 meanLoss: 166.2625 meanLossQlbl: 0.8080 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 164.9118 meanLossQtgt_sigm: 0.5427\n",
      "Episode: 1191 meanReward: 269.2812 meanLoss: 6.6092 meanLossQlbl: 0.4858 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.1115 meanLossQtgt_sigm: 0.0119\n",
      "Episode: 1192 meanReward: 268.5625 meanLoss: 335.5228 meanLossQlbl: 1.4011 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 333.2176 meanLossQtgt_sigm: 0.9042\n",
      "Episode: 1193 meanReward: 265.5312 meanLoss: 580.8904 meanLossQlbl: 2.7048 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 576.5437 meanLossQtgt_sigm: 1.6419\n",
      "Episode: 1194 meanReward: 250.2500 meanLoss: 605.8453 meanLossQlbl: 2.1185 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 601.8596 meanLossQtgt_sigm: 1.8673\n",
      "Episode: 1195 meanReward: 234.9688 meanLoss: 414.7103 meanLossQlbl: 0.7290 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 412.4795 meanLossQtgt_sigm: 1.5018\n",
      "Episode: 1196 meanReward: 219.6562 meanLoss: 314.3127 meanLossQlbl: 0.6008 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 312.4240 meanLossQtgt_sigm: 1.2878\n",
      "Episode: 1197 meanReward: 204.3750 meanLoss: 201.3718 meanLossQlbl: 0.0523 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 200.3287 meanLossQtgt_sigm: 0.9908\n",
      "Episode: 1198 meanReward: 198.2500 meanLoss: 18.1320 meanLossQlbl: 1.2585 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8274 meanLossQtgt_sigm: 0.0462\n",
      "Episode: 1199 meanReward: 190.6875 meanLoss: 17.5891 meanLossQlbl: 0.7218 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8094 meanLossQtgt_sigm: 0.0579\n",
      "Episode: 1200 meanReward: 192.4062 meanLoss: 12.3419 meanLossQlbl: 1.3219 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.9783 meanLossQtgt_sigm: 0.0417\n",
      "Episode: 1201 meanReward: 196.0312 meanLoss: 7.9134 meanLossQlbl: 0.1123 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.7619 meanLossQtgt_sigm: 0.0391\n",
      "Episode: 1202 meanReward: 199.1562 meanLoss: 8.8509 meanLossQlbl: 0.6736 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.1639 meanLossQtgt_sigm: 0.0134\n",
      "Episode: 1203 meanReward: 186.3750 meanLoss: 5.4117 meanLossQlbl: 0.2680 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.0985 meanLossQtgt_sigm: 0.0451\n",
      "Episode: 1204 meanReward: 174.4062 meanLoss: 22.0639 meanLossQlbl: 0.6997 meanLossQlbl_sigm: 0.0003 meanLossQtgt: 21.3298 meanLossQtgt_sigm: 0.0341\n",
      "Episode: 1205 meanReward: 167.5938 meanLoss: 19.0536 meanLossQlbl: 0.6914 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3438 meanLossQtgt_sigm: 0.0184\n",
      "Episode: 1206 meanReward: 175.3125 meanLoss: 10.4504 meanLossQlbl: 0.2077 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2204 meanLossQtgt_sigm: 0.0224\n",
      "Episode: 1207 meanReward: 190.4062 meanLoss: 2.8182 meanLossQlbl: 0.2533 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.5547 meanLossQtgt_sigm: 0.0102\n",
      "Episode: 1208 meanReward: 202.3438 meanLoss: 9.7616 meanLossQlbl: 0.0723 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.6553 meanLossQtgt_sigm: 0.0340\n",
      "Episode: 1209 meanReward: 201.9375 meanLoss: 98.0982 meanLossQlbl: 0.5646 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 97.2806 meanLossQtgt_sigm: 0.2530\n",
      "Episode: 1210 meanReward: 213.6250 meanLoss: 1.9862 meanLossQlbl: 0.0176 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.9597 meanLossQtgt_sigm: 0.0089\n",
      "Episode: 1211 meanReward: 225.6875 meanLoss: 18.9438 meanLossQlbl: 0.0691 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.8230 meanLossQtgt_sigm: 0.0517\n",
      "Episode: 1212 meanReward: 225.4375 meanLoss: 85.2055 meanLossQlbl: 0.5124 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 84.4633 meanLossQtgt_sigm: 0.2298\n",
      "Episode: 1213 meanReward: 237.1562 meanLoss: 1.7265 meanLossQlbl: 0.0114 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.7055 meanLossQtgt_sigm: 0.0096\n",
      "Episode: 1214 meanReward: 238.3438 meanLoss: 50.8629 meanLossQlbl: 1.0843 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 49.6503 meanLossQtgt_sigm: 0.1283\n",
      "Episode: 1215 meanReward: 239.2188 meanLoss: 10.8949 meanLossQlbl: 0.6146 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2562 meanLossQtgt_sigm: 0.0242\n",
      "Episode: 1216 meanReward: 242.3750 meanLoss: 15.9688 meanLossQlbl: 0.6743 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.2306 meanLossQtgt_sigm: 0.0640\n",
      "Episode: 1217 meanReward: 229.8125 meanLoss: 14.0188 meanLossQlbl: 0.4282 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.5209 meanLossQtgt_sigm: 0.0697\n",
      "Episode: 1218 meanReward: 217.9062 meanLoss: 12.4092 meanLossQlbl: 0.3175 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.0322 meanLossQtgt_sigm: 0.0595\n",
      "Episode: 1219 meanReward: 205.8750 meanLoss: 16.6890 meanLossQlbl: 0.3560 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.2463 meanLossQtgt_sigm: 0.0868\n",
      "Episode: 1220 meanReward: 206.6562 meanLoss: 25.4547 meanLossQlbl: 0.6423 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.6568 meanLossQtgt_sigm: 0.1556\n",
      "Episode: 1221 meanReward: 194.5938 meanLoss: 21.7975 meanLossQlbl: 0.5745 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.1412 meanLossQtgt_sigm: 0.0818\n",
      "Episode: 1222 meanReward: 197.0625 meanLoss: 16.5005 meanLossQlbl: 0.1227 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.2916 meanLossQtgt_sigm: 0.0862\n",
      "Episode: 1223 meanReward: 185.3750 meanLoss: 18.7154 meanLossQlbl: 0.9125 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7219 meanLossQtgt_sigm: 0.0810\n",
      "Episode: 1224 meanReward: 188.3750 meanLoss: 17.3330 meanLossQlbl: 0.3631 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.8739 meanLossQtgt_sigm: 0.0960\n",
      "Episode: 1225 meanReward: 192.1875 meanLoss: 16.1204 meanLossQlbl: 0.1165 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9226 meanLossQtgt_sigm: 0.0813\n",
      "Episode: 1226 meanReward: 196.5000 meanLoss: 12.0414 meanLossQlbl: 0.2029 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.7689 meanLossQtgt_sigm: 0.0696\n",
      "Episode: 1227 meanReward: 201.2188 meanLoss: 13.5950 meanLossQlbl: 0.3068 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2286 meanLossQtgt_sigm: 0.0596\n",
      "Episode: 1228 meanReward: 205.0312 meanLoss: 13.4411 meanLossQlbl: 0.1421 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2255 meanLossQtgt_sigm: 0.0734\n",
      "Episode: 1229 meanReward: 210.0625 meanLoss: 10.4907 meanLossQlbl: 0.1720 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2624 meanLossQtgt_sigm: 0.0563\n",
      "Episode: 1230 meanReward: 204.6875 meanLoss: 21.4687 meanLossQlbl: 0.1737 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.2043 meanLossQtgt_sigm: 0.0907\n",
      "Episode: 1231 meanReward: 203.4688 meanLoss: 9.1105 meanLossQlbl: 0.3082 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.7596 meanLossQtgt_sigm: 0.0427\n",
      "Episode: 1232 meanReward: 202.7188 meanLoss: 17.5706 meanLossQlbl: 0.4008 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.0931 meanLossQtgt_sigm: 0.0768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1233 meanReward: 208.0312 meanLoss: 6.2050 meanLossQlbl: 0.0990 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.0724 meanLossQtgt_sigm: 0.0337\n",
      "Episode: 1234 meanReward: 203.7500 meanLoss: 108.0631 meanLossQlbl: 0.7849 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 106.8009 meanLossQtgt_sigm: 0.4774\n",
      "Episode: 1235 meanReward: 205.9062 meanLoss: 18.0531 meanLossQlbl: 0.7896 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.1945 meanLossQtgt_sigm: 0.0690\n",
      "Episode: 1236 meanReward: 208.0938 meanLoss: 20.2838 meanLossQlbl: 0.4157 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.7854 meanLossQtgt_sigm: 0.0826\n",
      "Episode: 1237 meanReward: 201.2188 meanLoss: 24.3655 meanLossQlbl: 0.1176 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.0886 meanLossQtgt_sigm: 0.1592\n",
      "Episode: 1238 meanReward: 193.7812 meanLoss: 17.1723 meanLossQlbl: 2.2103 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.9044 meanLossQtgt_sigm: 0.0576\n",
      "Episode: 1239 meanReward: 186.4688 meanLoss: 9.4388 meanLossQlbl: 0.2026 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.1943 meanLossQtgt_sigm: 0.0419\n",
      "Episode: 1240 meanReward: 178.6875 meanLoss: 10.6619 meanLossQlbl: 0.1194 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.4917 meanLossQtgt_sigm: 0.0508\n",
      "Episode: 1241 meanReward: 186.1250 meanLoss: 6.5579 meanLossQlbl: 0.2385 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.2865 meanLossQtgt_sigm: 0.0328\n",
      "Episode: 1242 meanReward: 174.8750 meanLoss: 20.5200 meanLossQlbl: 0.5971 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.8356 meanLossQtgt_sigm: 0.0873\n",
      "Episode: 1243 meanReward: 169.5000 meanLoss: 5.3453 meanLossQlbl: 0.1202 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.1940 meanLossQtgt_sigm: 0.0311\n",
      "Episode: 1244 meanReward: 170.5000 meanLoss: 14.9412 meanLossQlbl: 0.3374 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5209 meanLossQtgt_sigm: 0.0829\n",
      "Episode: 1245 meanReward: 158.6250 meanLoss: 14.4273 meanLossQlbl: 0.2237 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.1226 meanLossQtgt_sigm: 0.0811\n",
      "Episode: 1246 meanReward: 157.6875 meanLoss: 5.9856 meanLossQlbl: 0.5254 meanLossQlbl_sigm: 0.0012 meanLossQtgt: 5.4218 meanLossQtgt_sigm: 0.0372\n",
      "Episode: 1247 meanReward: 158.7188 meanLoss: 5.4342 meanLossQlbl: 0.3653 meanLossQlbl_sigm: 0.0094 meanLossQtgt: 5.0468 meanLossQtgt_sigm: 0.0128\n",
      "Episode: 1248 meanReward: 159.6562 meanLoss: 16.7869 meanLossQlbl: 0.3565 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.3472 meanLossQtgt_sigm: 0.0833\n",
      "Episode: 1249 meanReward: 160.5625 meanLoss: 18.3283 meanLossQlbl: 0.1135 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.1206 meanLossQtgt_sigm: 0.0942\n",
      "Episode: 1250 meanReward: 162.1875 meanLoss: 12.5237 meanLossQlbl: 0.2439 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.2152 meanLossQtgt_sigm: 0.0646\n",
      "Episode: 1251 meanReward: 165.5938 meanLoss: 14.0366 meanLossQlbl: 0.2802 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.6967 meanLossQtgt_sigm: 0.0597\n",
      "Episode: 1252 meanReward: 169.7188 meanLoss: 30.0637 meanLossQlbl: 0.8388 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.1441 meanLossQtgt_sigm: 0.0807\n",
      "Episode: 1253 meanReward: 171.2500 meanLoss: 39.3563 meanLossQlbl: 4.8495 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 34.4184 meanLossQtgt_sigm: 0.0883\n",
      "Episode: 1254 meanReward: 178.9688 meanLoss: 23.9567 meanLossQlbl: 0.5947 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.3028 meanLossQtgt_sigm: 0.0592\n",
      "Episode: 1255 meanReward: 178.7500 meanLoss: 21.1078 meanLossQlbl: 1.4476 meanLossQlbl_sigm: 0.0025 meanLossQtgt: 19.6400 meanLossQtgt_sigm: 0.0176\n",
      "Episode: 1256 meanReward: 178.3125 meanLoss: 19.6281 meanLossQlbl: 0.9573 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5694 meanLossQtgt_sigm: 0.1015\n",
      "Episode: 1257 meanReward: 176.6250 meanLoss: 29.0066 meanLossQlbl: 0.3178 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.5431 meanLossQtgt_sigm: 0.1456\n",
      "Episode: 1258 meanReward: 175.6875 meanLoss: 23.1188 meanLossQlbl: 0.4275 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.5862 meanLossQtgt_sigm: 0.1050\n",
      "Episode: 1259 meanReward: 174.6875 meanLoss: 12.4984 meanLossQlbl: 0.2275 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.2050 meanLossQtgt_sigm: 0.0659\n",
      "Episode: 1260 meanReward: 174.0938 meanLoss: 20.4292 meanLossQlbl: 0.0900 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.2415 meanLossQtgt_sigm: 0.0978\n",
      "Episode: 1261 meanReward: 175.1875 meanLoss: 11.7885 meanLossQlbl: 0.1518 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.5820 meanLossQtgt_sigm: 0.0547\n",
      "Episode: 1262 meanReward: 174.6875 meanLoss: 14.3498 meanLossQlbl: 0.1226 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.1427 meanLossQtgt_sigm: 0.0845\n",
      "Episode: 1263 meanReward: 170.6562 meanLoss: 20.7570 meanLossQlbl: 1.0427 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.6042 meanLossQtgt_sigm: 0.1101\n",
      "Episode: 1264 meanReward: 180.7500 meanLoss: 4.9131 meanLossQlbl: 0.0586 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.8319 meanLossQtgt_sigm: 0.0226\n",
      "Episode: 1265 meanReward: 187.0312 meanLoss: 21.7689 meanLossQlbl: 0.5549 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.1675 meanLossQtgt_sigm: 0.0464\n",
      "Episode: 1266 meanReward: 201.6250 meanLoss: 19.5593 meanLossQlbl: 0.0570 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.4502 meanLossQtgt_sigm: 0.0520\n",
      "Episode: 1267 meanReward: 212.2500 meanLoss: 19.3727 meanLossQlbl: 0.0733 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.2475 meanLossQtgt_sigm: 0.0519\n",
      "Episode: 1268 meanReward: 222.0312 meanLoss: 18.6187 meanLossQlbl: 0.1805 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3884 meanLossQtgt_sigm: 0.0498\n",
      "Episode: 1269 meanReward: 235.7188 meanLoss: 17.9887 meanLossQlbl: 0.1440 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7940 meanLossQtgt_sigm: 0.0507\n",
      "Episode: 1270 meanReward: 235.0000 meanLoss: 82.5624 meanLossQlbl: 0.9557 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 81.3893 meanLossQtgt_sigm: 0.2174\n",
      "Episode: 1271 meanReward: 241.4375 meanLoss: 12.9289 meanLossQlbl: 0.5062 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.3834 meanLossQtgt_sigm: 0.0393\n",
      "Episode: 1272 meanReward: 249.2188 meanLoss: 12.7661 meanLossQlbl: 0.3302 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.3951 meanLossQtgt_sigm: 0.0407\n",
      "Episode: 1273 meanReward: 240.1562 meanLoss: 204.6243 meanLossQlbl: 0.5468 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 203.5400 meanLossQtgt_sigm: 0.5375\n",
      "Episode: 1274 meanReward: 244.3125 meanLoss: 24.9355 meanLossQlbl: 0.3865 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.4748 meanLossQtgt_sigm: 0.0743\n",
      "Episode: 1275 meanReward: 238.3125 meanLoss: 43.9796 meanLossQlbl: 0.6867 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.1478 meanLossQtgt_sigm: 0.1452\n",
      "Episode: 1276 meanReward: 249.5938 meanLoss: 12.2167 meanLossQlbl: 0.0787 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.0976 meanLossQtgt_sigm: 0.0404\n",
      "Episode: 1277 meanReward: 261.4688 meanLoss: 18.9332 meanLossQlbl: 0.1673 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.7145 meanLossQtgt_sigm: 0.0514\n",
      "Episode: 1278 meanReward: 272.3438 meanLoss: 16.5201 meanLossQlbl: 0.1450 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.3270 meanLossQtgt_sigm: 0.0482\n",
      "Episode: 1279 meanReward: 270.5312 meanLoss: 61.0031 meanLossQlbl: 0.9463 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 59.8864 meanLossQtgt_sigm: 0.1704\n",
      "Episode: 1280 meanReward: 273.7812 meanLoss: 37.4385 meanLossQlbl: 0.4734 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.8716 meanLossQtgt_sigm: 0.0936\n",
      "Episode: 1281 meanReward: 285.4375 meanLoss: 11.6738 meanLossQlbl: 0.1489 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.4877 meanLossQtgt_sigm: 0.0372\n",
      "Episode: 1282 meanReward: 287.0312 meanLoss: 41.9805 meanLossQlbl: 0.2723 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 41.5959 meanLossQtgt_sigm: 0.1122\n",
      "Episode: 1283 meanReward: 282.7500 meanLoss: 82.0537 meanLossQlbl: 0.8547 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 80.9492 meanLossQtgt_sigm: 0.2497\n",
      "Episode: 1284 meanReward: 278.6562 meanLoss: 108.2846 meanLossQlbl: 0.9494 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 106.9985 meanLossQtgt_sigm: 0.3368\n",
      "Episode: 1285 meanReward: 274.9062 meanLoss: 166.7118 meanLossQlbl: 0.8800 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 165.3149 meanLossQtgt_sigm: 0.5168\n",
      "Episode: 1286 meanReward: 269.7812 meanLoss: 44.5782 meanLossQlbl: 0.6645 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.7959 meanLossQtgt_sigm: 0.1179\n",
      "Episode: 1287 meanReward: 270.2812 meanLoss: 18.8666 meanLossQlbl: 1.0056 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8142 meanLossQtgt_sigm: 0.0468\n",
      "Episode: 1288 meanReward: 271.8438 meanLoss: 22.0959 meanLossQlbl: 0.4096 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.5901 meanLossQtgt_sigm: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1289 meanReward: 273.3125 meanLoss: 17.5576 meanLossQlbl: 1.5339 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9522 meanLossQtgt_sigm: 0.0715\n",
      "Episode: 1290 meanReward: 275.0312 meanLoss: 7.9117 meanLossQlbl: 0.3650 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.5097 meanLossQtgt_sigm: 0.0370\n",
      "Episode: 1291 meanReward: 286.5938 meanLoss: 5.0343 meanLossQlbl: 0.3001 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.7191 meanLossQtgt_sigm: 0.0151\n",
      "Episode: 1292 meanReward: 287.3438 meanLoss: 44.6810 meanLossQlbl: 0.6804 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.8554 meanLossQtgt_sigm: 0.1452\n",
      "Episode: 1293 meanReward: 284.5938 meanLoss: 87.1896 meanLossQlbl: 0.3264 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 86.6366 meanLossQtgt_sigm: 0.2266\n",
      "Episode: 1294 meanReward: 296.5938 meanLoss: 6.8647 meanLossQlbl: 0.5047 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.3347 meanLossQtgt_sigm: 0.0254\n",
      "Episode: 1295 meanReward: 299.8750 meanLoss: 50.4419 meanLossQlbl: 0.3084 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 50.0006 meanLossQtgt_sigm: 0.1330\n",
      "Episode: 1296 meanReward: 284.7500 meanLoss: 83.4865 meanLossQlbl: 4.5960 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 78.6317 meanLossQtgt_sigm: 0.2588\n",
      "Episode: 1297 meanReward: 273.2500 meanLoss: 73.2674 meanLossQlbl: 0.9274 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 72.1401 meanLossQtgt_sigm: 0.1999\n",
      "Episode: 1298 meanReward: 258.1562 meanLoss: 181.2916 meanLossQlbl: 1.9318 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 178.7261 meanLossQtgt_sigm: 0.6337\n",
      "Episode: 1299 meanReward: 243.0938 meanLoss: 295.8949 meanLossQlbl: 7.2654 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 287.5648 meanLossQtgt_sigm: 1.0647\n",
      "Episode: 1300 meanReward: 231.7188 meanLoss: 73.4439 meanLossQlbl: 0.4985 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 72.7216 meanLossQtgt_sigm: 0.2238\n",
      "Episode: 1301 meanReward: 231.7188 meanLoss: 8.4839 meanLossQlbl: 0.0568 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.3930 meanLossQtgt_sigm: 0.0341\n",
      "Episode: 1302 meanReward: 243.5312 meanLoss: 16.7635 meanLossQlbl: 0.1220 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5930 meanLossQtgt_sigm: 0.0485\n",
      "Episode: 1303 meanReward: 244.4062 meanLoss: 18.7665 meanLossQlbl: 0.1372 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5791 meanLossQtgt_sigm: 0.0502\n",
      "Episode: 1304 meanReward: 244.4062 meanLoss: 17.7088 meanLossQlbl: 0.0612 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.5974 meanLossQtgt_sigm: 0.0502\n",
      "Episode: 1305 meanReward: 258.4375 meanLoss: 17.3390 meanLossQlbl: 0.1725 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.1173 meanLossQtgt_sigm: 0.0492\n",
      "Episode: 1306 meanReward: 256.8438 meanLoss: 39.8902 meanLossQlbl: 0.4735 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.3043 meanLossQtgt_sigm: 0.1124\n",
      "Episode: 1307 meanReward: 268.2188 meanLoss: 12.8668 meanLossQlbl: 0.0223 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.8014 meanLossQtgt_sigm: 0.0430\n",
      "Episode: 1308 meanReward: 268.2188 meanLoss: 18.8222 meanLossQlbl: 0.2352 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.5363 meanLossQtgt_sigm: 0.0507\n",
      "Episode: 1309 meanReward: 253.5625 meanLoss: 289.8597 meanLossQlbl: 1.2742 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 287.7607 meanLossQtgt_sigm: 0.8248\n",
      "Episode: 1310 meanReward: 244.2188 meanLoss: 31.9623 meanLossQlbl: 0.2934 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.5636 meanLossQtgt_sigm: 0.1053\n",
      "Episode: 1311 meanReward: 255.4062 meanLoss: 14.2703 meanLossQlbl: 0.1686 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.0568 meanLossQtgt_sigm: 0.0449\n",
      "Episode: 1312 meanReward: 248.8438 meanLoss: 213.4019 meanLossQlbl: 1.2340 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 211.5381 meanLossQtgt_sigm: 0.6298\n",
      "Episode: 1313 meanReward: 248.8438 meanLoss: 11.4612 meanLossQlbl: 0.1064 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.3148 meanLossQtgt_sigm: 0.0400\n",
      "Episode: 1314 meanReward: 242.5000 meanLoss: 251.7315 meanLossQlbl: 1.4468 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 249.5084 meanLossQtgt_sigm: 0.7763\n",
      "Episode: 1315 meanReward: 240.1875 meanLoss: 419.5359 meanLossQlbl: 4.2783 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 413.9055 meanLossQtgt_sigm: 1.3521\n",
      "Episode: 1316 meanReward: 239.9688 meanLoss: 85.3537 meanLossQlbl: 2.5989 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 82.4907 meanLossQtgt_sigm: 0.2640\n",
      "Episode: 1317 meanReward: 244.2500 meanLoss: 37.1976 meanLossQlbl: 0.2371 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.8410 meanLossQtgt_sigm: 0.1195\n",
      "Episode: 1318 meanReward: 253.5625 meanLoss: 6.4392 meanLossQlbl: 0.1555 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.2544 meanLossQtgt_sigm: 0.0293\n",
      "Episode: 1319 meanReward: 251.6875 meanLoss: 93.0484 meanLossQlbl: 0.1708 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 92.5788 meanLossQtgt_sigm: 0.2989\n",
      "Episode: 1320 meanReward: 250.2500 meanLoss: 30.8755 meanLossQlbl: 0.8478 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.8891 meanLossQtgt_sigm: 0.1386\n",
      "Episode: 1321 meanReward: 248.7188 meanLoss: 7.5458 meanLossQlbl: 0.2949 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.2044 meanLossQtgt_sigm: 0.0465\n",
      "Episode: 1322 meanReward: 246.6250 meanLoss: 16.4279 meanLossQlbl: 1.7555 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5967 meanLossQtgt_sigm: 0.0756\n",
      "Episode: 1323 meanReward: 245.0000 meanLoss: 2.8191 meanLossQlbl: 0.1771 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.6253 meanLossQtgt_sigm: 0.0167\n",
      "Episode: 1324 meanReward: 242.1250 meanLoss: 75.1111 meanLossQlbl: 0.4263 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 74.3518 meanLossQtgt_sigm: 0.3329\n",
      "Episode: 1325 meanReward: 254.0312 meanLoss: 12.7312 meanLossQlbl: 0.1822 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5084 meanLossQtgt_sigm: 0.0406\n",
      "Episode: 1326 meanReward: 239.0000 meanLoss: 267.9626 meanLossQlbl: 0.0998 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 267.0611 meanLossQtgt_sigm: 0.8018\n",
      "Episode: 1327 meanReward: 233.3438 meanLoss: 412.4419 meanLossQlbl: 0.9325 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 410.1714 meanLossQtgt_sigm: 1.3380\n",
      "Episode: 1328 meanReward: 233.1875 meanLoss: 425.0192 meanLossQlbl: 0.1674 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 423.4341 meanLossQtgt_sigm: 1.4177\n",
      "Episode: 1329 meanReward: 233.1250 meanLoss: 65.8027 meanLossQlbl: 0.8675 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 64.6895 meanLossQtgt_sigm: 0.2457\n",
      "Episode: 1330 meanReward: 248.2188 meanLoss: 5.3333 meanLossQlbl: 0.1450 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.1705 meanLossQtgt_sigm: 0.0177\n",
      "Episode: 1331 meanReward: 259.6562 meanLoss: 19.0683 meanLossQlbl: 0.2285 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.7817 meanLossQtgt_sigm: 0.0582\n",
      "Episode: 1332 meanReward: 259.0625 meanLoss: 36.2890 meanLossQlbl: 0.6841 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 35.4653 meanLossQtgt_sigm: 0.1396\n",
      "Episode: 1333 meanReward: 247.8750 meanLoss: 21.6175 meanLossQlbl: 0.5483 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.9792 meanLossQtgt_sigm: 0.0900\n",
      "Episode: 1334 meanReward: 232.5938 meanLoss: 84.8224 meanLossQlbl: 0.4810 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 83.9550 meanLossQtgt_sigm: 0.3864\n",
      "Episode: 1335 meanReward: 230.3125 meanLoss: 15.4775 meanLossQlbl: 0.7640 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.6793 meanLossQtgt_sigm: 0.0343\n",
      "Episode: 1336 meanReward: 219.4062 meanLoss: 19.9852 meanLossQlbl: 0.2465 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.6566 meanLossQtgt_sigm: 0.0821\n",
      "Episode: 1337 meanReward: 206.8125 meanLoss: 17.1736 meanLossQlbl: 0.3614 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7241 meanLossQtgt_sigm: 0.0882\n",
      "Episode: 1338 meanReward: 202.5938 meanLoss: 13.8818 meanLossQlbl: 0.3863 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.4231 meanLossQtgt_sigm: 0.0724\n",
      "Episode: 1339 meanReward: 189.9062 meanLoss: 13.5068 meanLossQlbl: 0.9211 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.5168 meanLossQtgt_sigm: 0.0689\n",
      "Episode: 1340 meanReward: 176.4375 meanLoss: 10.9788 meanLossQlbl: 0.1566 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.7404 meanLossQtgt_sigm: 0.0818\n",
      "Episode: 1341 meanReward: 177.0312 meanLoss: 17.0105 meanLossQlbl: 0.3291 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.5521 meanLossQtgt_sigm: 0.1293\n",
      "Episode: 1342 meanReward: 172.6562 meanLoss: 23.3913 meanLossQlbl: 0.3628 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.8879 meanLossQtgt_sigm: 0.1407\n",
      "Episode: 1343 meanReward: 161.0312 meanLoss: 8.7575 meanLossQlbl: 0.3557 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 8.3700 meanLossQtgt_sigm: 0.0318\n",
      "Episode: 1344 meanReward: 172.2812 meanLoss: 3.9963 meanLossQlbl: 0.6303 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 3.3480 meanLossQtgt_sigm: 0.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1345 meanReward: 159.1875 meanLoss: 15.2477 meanLossQlbl: 0.0538 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.0872 meanLossQtgt_sigm: 0.1066\n",
      "Episode: 1346 meanReward: 174.2188 meanLoss: 4.8580 meanLossQlbl: 0.2891 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.5538 meanLossQtgt_sigm: 0.0152\n",
      "Episode: 1347 meanReward: 189.4375 meanLoss: 18.9588 meanLossQlbl: 0.2288 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.6819 meanLossQtgt_sigm: 0.0481\n",
      "Episode: 1348 meanReward: 190.0625 meanLoss: 12.1579 meanLossQlbl: 0.2096 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.8626 meanLossQtgt_sigm: 0.0857\n",
      "Episode: 1349 meanReward: 188.0312 meanLoss: 6.1122 meanLossQlbl: 0.1979 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.8721 meanLossQtgt_sigm: 0.0423\n",
      "Episode: 1350 meanReward: 177.1875 meanLoss: 4.5819 meanLossQlbl: 0.1961 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 4.3682 meanLossQtgt_sigm: 0.0174\n",
      "Episode: 1351 meanReward: 183.4375 meanLoss: 5.2996 meanLossQlbl: 0.1539 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.1228 meanLossQtgt_sigm: 0.0229\n",
      "Episode: 1352 meanReward: 196.0000 meanLoss: 16.0808 meanLossQlbl: 0.0769 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.9569 meanLossQtgt_sigm: 0.0470\n",
      "Episode: 1353 meanReward: 196.3750 meanLoss: 89.9802 meanLossQlbl: 1.4780 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 88.2455 meanLossQtgt_sigm: 0.2567\n",
      "Episode: 1354 meanReward: 197.4375 meanLoss: 8.1248 meanLossQlbl: 0.4627 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.6308 meanLossQtgt_sigm: 0.0312\n",
      "Episode: 1355 meanReward: 199.0625 meanLoss: 2.9543 meanLossQlbl: 0.0842 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 2.8603 meanLossQtgt_sigm: 0.0098\n",
      "Episode: 1356 meanReward: 201.4688 meanLoss: 70.0980 meanLossQlbl: 0.8929 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 69.0116 meanLossQtgt_sigm: 0.1935\n",
      "Episode: 1357 meanReward: 201.4688 meanLoss: 3.6524 meanLossQlbl: 0.1821 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 3.4652 meanLossQtgt_sigm: 0.0049\n",
      "Episode: 1358 meanReward: 205.4375 meanLoss: 74.4581 meanLossQlbl: 0.3382 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 73.9290 meanLossQtgt_sigm: 0.1909\n",
      "Episode: 1359 meanReward: 212.1562 meanLoss: 31.6169 meanLossQlbl: 0.1753 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.3442 meanLossQtgt_sigm: 0.0974\n",
      "Episode: 1360 meanReward: 227.4375 meanLoss: 7.7750 meanLossQlbl: 0.0858 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 7.6593 meanLossQtgt_sigm: 0.0299\n",
      "Episode: 1361 meanReward: 239.0000 meanLoss: 20.4978 meanLossQlbl: 0.1567 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.2890 meanLossQtgt_sigm: 0.0522\n",
      "Episode: 1362 meanReward: 236.3438 meanLoss: 22.8876 meanLossQlbl: 0.4137 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.4163 meanLossQtgt_sigm: 0.0575\n",
      "Episode: 1363 meanReward: 239.9688 meanLoss: 5.4164 meanLossQlbl: 0.2851 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 5.1141 meanLossQtgt_sigm: 0.0172\n",
      "Episode: 1364 meanReward: 251.9375 meanLoss: 19.9876 meanLossQlbl: 0.0669 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 19.8671 meanLossQtgt_sigm: 0.0536\n",
      "Episode: 1365 meanReward: 263.1250 meanLoss: 18.4995 meanLossQlbl: 0.1158 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.3325 meanLossQtgt_sigm: 0.0511\n",
      "Episode: 1366 meanReward: 278.4062 meanLoss: 19.2552 meanLossQlbl: 0.2114 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.9935 meanLossQtgt_sigm: 0.0503\n",
      "Episode: 1367 meanReward: 280.6875 meanLoss: 18.7991 meanLossQlbl: 0.1415 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.6058 meanLossQtgt_sigm: 0.0518\n",
      "Episode: 1368 meanReward: 280.5938 meanLoss: 64.9217 meanLossQlbl: 1.5903 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 63.1639 meanLossQtgt_sigm: 0.1675\n",
      "Episode: 1369 meanReward: 293.1875 meanLoss: 15.7063 meanLossQlbl: 0.1187 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.5405 meanLossQtgt_sigm: 0.0472\n",
      "Episode: 1370 meanReward: 306.0938 meanLoss: 17.7971 meanLossQlbl: 0.0412 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.7053 meanLossQtgt_sigm: 0.0506\n",
      "Episode: 1371 meanReward: 318.7812 meanLoss: 17.2282 meanLossQlbl: 0.0545 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.1243 meanLossQtgt_sigm: 0.0494\n",
      "Episode: 1372 meanReward: 327.1875 meanLoss: 25.0167 meanLossQlbl: 0.0481 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.8956 meanLossQtgt_sigm: 0.0730\n",
      "Episode: 1373 meanReward: 325.9062 meanLoss: 265.6706 meanLossQlbl: 0.1578 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 264.6927 meanLossQtgt_sigm: 0.8201\n",
      "Episode: 1374 meanReward: 324.3438 meanLoss: 342.5466 meanLossQlbl: 2.5588 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 338.8239 meanLossQtgt_sigm: 1.1639\n",
      "Episode: 1375 meanReward: 322.0000 meanLoss: 94.1242 meanLossQlbl: 7.7656 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 86.0777 meanLossQtgt_sigm: 0.2809\n",
      "Episode: 1376 meanReward: 317.4375 meanLoss: 25.7284 meanLossQlbl: 0.1805 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.4641 meanLossQtgt_sigm: 0.0839\n",
      "Episode: 1377 meanReward: 315.2812 meanLoss: 240.0212 meanLossQlbl: 0.4564 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 238.7937 meanLossQtgt_sigm: 0.7711\n",
      "Episode: 1378 meanReward: 299.9688 meanLoss: 400.7350 meanLossQlbl: 2.1079 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 397.2600 meanLossQtgt_sigm: 1.3672\n",
      "Episode: 1379 meanReward: 284.6562 meanLoss: 491.9924 meanLossQlbl: 0.9321 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 489.2447 meanLossQtgt_sigm: 1.8156\n",
      "Episode: 1380 meanReward: 282.5625 meanLoss: 413.4222 meanLossQlbl: 0.1769 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 411.5586 meanLossQtgt_sigm: 1.6868\n",
      "Episode: 1381 meanReward: 279.3125 meanLoss: 314.8769 meanLossQlbl: 1.7680 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 311.6812 meanLossQtgt_sigm: 1.4276\n",
      "Episode: 1382 meanReward: 274.9375 meanLoss: 223.1546 meanLossQlbl: 8.8295 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 213.2162 meanLossQtgt_sigm: 1.1089\n",
      "Episode: 1383 meanReward: 267.0625 meanLoss: 162.7350 meanLossQlbl: 5.3373 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 156.5565 meanLossQtgt_sigm: 0.8412\n",
      "Episode: 1384 meanReward: 264.0000 meanLoss: 14.9145 meanLossQlbl: 0.2601 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.6085 meanLossQtgt_sigm: 0.0458\n",
      "Episode: 1385 meanReward: 265.0625 meanLoss: 43.8052 meanLossQlbl: 0.2630 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.3947 meanLossQtgt_sigm: 0.1475\n",
      "Episode: 1386 meanReward: 265.9062 meanLoss: 29.6222 meanLossQlbl: 0.1708 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.3451 meanLossQtgt_sigm: 0.1063\n",
      "Episode: 1387 meanReward: 254.1875 meanLoss: 42.3733 meanLossQlbl: 0.2207 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 42.0080 meanLossQtgt_sigm: 0.1446\n",
      "Episode: 1388 meanReward: 262.0625 meanLoss: 13.1207 meanLossQlbl: 0.0783 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.9946 meanLossQtgt_sigm: 0.0478\n",
      "Episode: 1389 meanReward: 252.9688 meanLoss: 23.7019 meanLossQlbl: 0.1151 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.4990 meanLossQtgt_sigm: 0.0878\n",
      "Episode: 1390 meanReward: 251.4688 meanLoss: 53.0717 meanLossQlbl: 0.3949 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 52.4823 meanLossQtgt_sigm: 0.1945\n",
      "Episode: 1391 meanReward: 249.7500 meanLoss: 28.1260 meanLossQlbl: 0.1242 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.8961 meanLossQtgt_sigm: 0.1058\n",
      "Episode: 1392 meanReward: 240.1562 meanLoss: 25.8916 meanLossQlbl: 0.1351 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.6621 meanLossQtgt_sigm: 0.0945\n",
      "Episode: 1393 meanReward: 228.2812 meanLoss: 30.4547 meanLossQlbl: 0.3497 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.9737 meanLossQtgt_sigm: 0.1313\n",
      "Episode: 1394 meanReward: 218.5000 meanLoss: 15.2093 meanLossQlbl: 0.4132 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.7058 meanLossQtgt_sigm: 0.0903\n",
      "Episode: 1395 meanReward: 205.6875 meanLoss: 17.0759 meanLossQlbl: 0.1914 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.7859 meanLossQtgt_sigm: 0.0986\n",
      "Episode: 1396 meanReward: 193.0312 meanLoss: 10.5064 meanLossQlbl: 0.1018 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.3310 meanLossQtgt_sigm: 0.0736\n",
      "Episode: 1397 meanReward: 178.7188 meanLoss: 14.1399 meanLossQlbl: 0.0556 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.9426 meanLossQtgt_sigm: 0.1417\n",
      "Episode: 1398 meanReward: 165.5312 meanLoss: 37.1313 meanLossQlbl: 0.1251 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.8368 meanLossQtgt_sigm: 0.1694\n",
      "Episode: 1399 meanReward: 151.7812 meanLoss: 18.7727 meanLossQlbl: 0.7214 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.9948 meanLossQtgt_sigm: 0.0565\n",
      "Episode: 1400 meanReward: 149.2188 meanLoss: 6.9284 meanLossQlbl: 0.0988 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 6.7964 meanLossQtgt_sigm: 0.0330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1401 meanReward: 135.4375 meanLoss: 5.6648 meanLossQlbl: 0.0400 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 5.5841 meanLossQtgt_sigm: 0.0405\n",
      "Episode: 1402 meanReward: 121.7500 meanLoss: 8.1683 meanLossQlbl: 0.5160 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 7.6121 meanLossQtgt_sigm: 0.0401\n",
      "Episode: 1403 meanReward: 108.0625 meanLoss: 6.9538 meanLossQlbl: 0.0952 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 6.8160 meanLossQtgt_sigm: 0.0424\n",
      "Episode: 1404 meanReward: 98.2812 meanLoss: 12.3421 meanLossQlbl: 0.0453 meanLossQlbl_sigm: 0.0003 meanLossQtgt: 12.2010 meanLossQtgt_sigm: 0.0955\n",
      "Episode: 1405 meanReward: 99.0938 meanLoss: 58.9386 meanLossQlbl: 0.0705 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 58.5170 meanLossQtgt_sigm: 0.3511\n",
      "Episode: 1406 meanReward: 100.6562 meanLoss: 14.1225 meanLossQlbl: 0.2567 meanLossQlbl_sigm: 0.0014 meanLossQtgt: 13.7678 meanLossQtgt_sigm: 0.0967\n",
      "Episode: 1407 meanReward: 101.2500 meanLoss: 3.3603 meanLossQlbl: 0.0763 meanLossQlbl_sigm: 0.0014 meanLossQtgt: 3.2551 meanLossQtgt_sigm: 0.0276\n",
      "Episode: 1408 meanReward: 104.7812 meanLoss: 4.9331 meanLossQlbl: 0.2271 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 4.6998 meanLossQtgt_sigm: 0.0061\n",
      "Episode: 1409 meanReward: 110.0625 meanLoss: 25.0325 meanLossQlbl: 0.3032 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.6370 meanLossQtgt_sigm: 0.0923\n",
      "Episode: 1410 meanReward: 119.2812 meanLoss: 9.5659 meanLossQlbl: 0.3811 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 9.1411 meanLossQtgt_sigm: 0.0437\n",
      "Episode: 1411 meanReward: 128.2500 meanLoss: 22.4489 meanLossQlbl: 0.1469 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 22.2308 meanLossQtgt_sigm: 0.0712\n",
      "Episode: 1412 meanReward: 132.0000 meanLoss: 51.3069 meanLossQlbl: 0.4162 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 50.7234 meanLossQtgt_sigm: 0.1673\n",
      "Episode: 1413 meanReward: 136.0312 meanLoss: 46.2373 meanLossQlbl: 0.0909 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 45.9937 meanLossQtgt_sigm: 0.1528\n",
      "Episode: 1414 meanReward: 144.2188 meanLoss: 20.4672 meanLossQlbl: 0.0764 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.3195 meanLossQtgt_sigm: 0.0714\n",
      "Episode: 1415 meanReward: 146.1562 meanLoss: 72.5754 meanLossQlbl: 0.9510 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 71.3925 meanLossQtgt_sigm: 0.2319\n",
      "Episode: 1416 meanReward: 147.9688 meanLoss: 4.7919 meanLossQlbl: 0.1591 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.6100 meanLossQtgt_sigm: 0.0227\n",
      "Episode: 1417 meanReward: 147.0312 meanLoss: 72.5604 meanLossQlbl: 0.3692 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 71.9641 meanLossQtgt_sigm: 0.2271\n",
      "Episode: 1418 meanReward: 157.4062 meanLoss: 1.8437 meanLossQlbl: 0.0126 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 1.8178 meanLossQtgt_sigm: 0.0133\n",
      "Episode: 1419 meanReward: 169.1250 meanLoss: 14.8525 meanLossQlbl: 0.2259 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.5811 meanLossQtgt_sigm: 0.0455\n",
      "Episode: 1420 meanReward: 173.0625 meanLoss: 16.5195 meanLossQlbl: 0.2250 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.2464 meanLossQtgt_sigm: 0.0481\n",
      "Episode: 1421 meanReward: 182.1562 meanLoss: 17.6354 meanLossQlbl: 0.1445 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.4406 meanLossQtgt_sigm: 0.0502\n",
      "Episode: 1422 meanReward: 183.2188 meanLoss: 66.7230 meanLossQlbl: 0.7889 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 65.7459 meanLossQtgt_sigm: 0.1882\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver() # save the trained model\n",
    "rewards_list, loss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    episode_loss = deque(maxlen=batch_size)\n",
    "    episode_reward = deque(maxlen=batch_size)\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        lossQlbl_batch, lossQlbl_sigm_batch, lossQtgt_batch, lossQtgt_sigm_batch = [], [], [], []\n",
    "        state = env.reset()\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Testing\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([initial_state, final_state])\n",
    "            total_reward += reward\n",
    "            initial_state = final_state\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            initial_states = np.array([each[0] for each in rnn_states])\n",
    "            final_states = np.array([each[1] for each in rnn_states])\n",
    "            actions_logits = sess.run(model.actions_logits, \n",
    "                                      feed_dict = {model.states: states, \n",
    "                                                   model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            labelQs = np.max(actions_logits, axis=1) # explore\n",
    "            next_actions_logits = sess.run(model.actions_logits, \n",
    "                                           feed_dict = {model.states: next_states, \n",
    "                                                        model.initial_state: final_states[0].reshape([1, -1])})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones) # exploit\n",
    "            targetQs = rewards + (0.99 * nextQs)\n",
    "            loss, _, lossQlbl, lossQlbl_sigm, lossQtgt, lossQtgt_sigm = sess.run([model.loss, model.opt, \n",
    "                                                                                  model.lossQlbl, \n",
    "                                                                                  model.lossQlbl_sigm, \n",
    "                                                                                  model.lossQtgt, \n",
    "                                                                                  model.lossQtgt_sigm], \n",
    "                                            feed_dict = {model.states: states, \n",
    "                                                         model.actions: actions,\n",
    "                                                         model.targetQs: targetQs,\n",
    "                                                         \n",
    "                                                         model.labelQs: labelQs,\n",
    "                                                         model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            loss_batch.append(loss)\n",
    "            lossQlbl_batch.append(lossQlbl)\n",
    "            lossQlbl_sigm_batch.append(lossQlbl_sigm)\n",
    "            lossQtgt_batch.append(lossQtgt)\n",
    "            lossQtgt_sigm_batch.append(lossQtgt_sigm)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode: {}'.format(ep),\n",
    "              'meanReward: {:.4f}'.format(np.mean(episode_reward)),\n",
    "              'meanLoss: {:.4f}'.format(np.mean(loss_batch)),\n",
    "              'meanLossQlbl: {:.4f}'.format(np.mean(lossQlbl_batch)),\n",
    "              'meanLossQlbl_sigm: {:.4f}'.format(np.mean(lossQlbl_sigm_batch)),\n",
    "              'meanLossQtgt: {:.4f}'.format(np.mean(lossQtgt_batch)),\n",
    "              'meanLossQtgt_sigm: {:.4f}'.format(np.mean(lossQtgt_sigm_batch)))\n",
    "        rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        if(np.mean(episode_reward) >= 500):\n",
    "            break\n",
    "    \n",
    "    saver.save(sess, 'checkpoints/model5.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward:120.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-seq.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action_logits, initial_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                             model.initial_state: initial_state})\n",
    "        action = np.argmax(action_logits)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "print('total_reward:{}'.format(total_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# env = UnityEnvironment(file_name=\"/home/arasdar/VisualBanana_Linux/Banana.x86\")\n",
    "env = UnityEnvironment(file_name=\"/home/arasdar/unity-envs/Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "# print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)\n",
    "# print(state.shape, len(env_info.vector_observations), env_info.vector_observations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37,)\n",
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        print(state.shape)\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    #print(state)\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "batch = []\n",
    "while True: # infinite number of steps\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    #print(state, action, reward, done)\n",
    "    batch.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.        , 0.        , 1.        , 0.        , 0.42380726,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.07645891,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.59556293,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.76522499,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.81929988,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.06445977,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.48016095,\n",
       "         0.        , 0.        ]),\n",
       "  2,\n",
       "  array([0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.44709426,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.76708418,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.57643121,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.47142395,\n",
       "         0.        , 1.        , 0.        , 0.        , 0.74959463,\n",
       "         0.        , 0.        ]),\n",
       "  0.0,\n",
       "  0.0],\n",
       " 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.        , 0.        , 1.        , 0.        , 0.42380726,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.07645891,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.59556293,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.76522499,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.81929988,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.06445977,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.48016095,\n",
       "        0.        , 0.        ]),\n",
       " 2,\n",
       " array([0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.44709426,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.76708418,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.57643121,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.47142395,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.74959463,\n",
       "        0.        , 0.        ]),\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([each[1] for each in batch])\n",
    "actions = np.array([each[0] for each in batch])\n",
    "next_states = np.array([each[1] for each in batch])\n",
    "rewards = np.array([each[2] for each in batch])\n",
    "dones = np.array([each[3] for each in batch])\n",
    "# infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 37) (300,) (300, 37) (300,)\n",
      "float64 int64 float64 float64\n",
      "11.040274620056152 -10.833015441894531 22.873290061950684\n",
      "11.040274620056152 -10.833015441894531\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "# print(rewards[:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)), \n",
    "      (np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    # RNN\n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    return states, actions, targetQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, final_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx], [self.states[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "action_size = 4\n",
    "state_size = 37\n",
    "hidden_size = 37*4             # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 128            # memory capacity\n",
    "batch_size = 128             # experience mini-batch size\n",
    "gamma = 0.99                 # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 37) (?, 148)\n",
      "(1, ?, 148) (1, 148)\n",
      "(1, ?, 148) (1, 148)\n",
      "(?, 148)\n",
      "(?, 4)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = env.reset()\n",
    "# for _ in range(batch_size):\n",
    "#     action = env.action_space.sample()\n",
    "#     next_state, reward, done, _ = env.step(action)\n",
    "#     memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "#     state = next_state\n",
    "#     if done is True:\n",
    "#         state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]   # get the state\n",
    "for _ in range(memory_size):\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]   # get the state\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:2.0000 R:2.0 loss:0.3006 exploreP:0.9707\n",
      "Episode:1 meanR:0.0000 R:-2.0 loss:0.1314 exploreP:0.9423\n",
      "Episode:2 meanR:-0.6667 R:-2.0 loss:0.1372 exploreP:0.9148\n",
      "Episode:3 meanR:-0.7500 R:-1.0 loss:0.1735 exploreP:0.8881\n",
      "Episode:4 meanR:-0.6000 R:0.0 loss:0.1825 exploreP:0.8621\n",
      "Episode:5 meanR:-0.1667 R:2.0 loss:0.2299 exploreP:0.8369\n",
      "Episode:6 meanR:-0.2857 R:-1.0 loss:0.2194 exploreP:0.8125\n",
      "Episode:7 meanR:-0.2500 R:0.0 loss:0.2632 exploreP:0.7888\n",
      "Episode:8 meanR:0.0000 R:2.0 loss:0.1097 exploreP:0.7657\n",
      "Episode:9 meanR:-0.1000 R:-1.0 loss:0.1322 exploreP:0.7434\n",
      "Episode:10 meanR:-0.0909 R:0.0 loss:0.1182 exploreP:0.7217\n",
      "Episode:11 meanR:-0.1667 R:-1.0 loss:0.0977 exploreP:0.7007\n",
      "Episode:12 meanR:-0.1538 R:0.0 loss:0.1603 exploreP:0.6803\n",
      "Episode:13 meanR:0.0000 R:2.0 loss:0.1571 exploreP:0.6605\n",
      "Episode:14 meanR:-0.0667 R:-1.0 loss:0.1785 exploreP:0.6413\n",
      "Episode:15 meanR:-0.1875 R:-2.0 loss:0.1386 exploreP:0.6226\n",
      "Episode:16 meanR:-0.1765 R:0.0 loss:0.1860 exploreP:0.6045\n",
      "Episode:17 meanR:-0.3333 R:-3.0 loss:0.1193 exploreP:0.5869\n",
      "Episode:18 meanR:-0.4211 R:-2.0 loss:0.0668 exploreP:0.5699\n",
      "Episode:19 meanR:-0.6000 R:-4.0 loss:0.0663 exploreP:0.5533\n",
      "Episode:20 meanR:-0.5714 R:0.0 loss:0.1283 exploreP:0.5373\n",
      "Episode:21 meanR:-0.5909 R:-1.0 loss:0.0966 exploreP:0.5217\n",
      "Episode:22 meanR:-0.6087 R:-1.0 loss:0.1319 exploreP:0.5066\n",
      "Episode:23 meanR:-0.6250 R:-1.0 loss:0.1237 exploreP:0.4919\n",
      "Episode:24 meanR:-0.6000 R:0.0 loss:0.0992 exploreP:0.4776\n",
      "Episode:25 meanR:-0.5769 R:0.0 loss:0.0876 exploreP:0.4638\n",
      "Episode:26 meanR:-0.5926 R:-1.0 loss:0.0597 exploreP:0.4504\n",
      "Episode:27 meanR:-0.6071 R:-1.0 loss:0.0861 exploreP:0.4374\n",
      "Episode:28 meanR:-0.6207 R:-1.0 loss:0.0569 exploreP:0.4248\n",
      "Episode:29 meanR:-0.6333 R:-1.0 loss:0.0497 exploreP:0.4125\n",
      "Episode:30 meanR:-0.5484 R:2.0 loss:0.0676 exploreP:0.4006\n",
      "Episode:31 meanR:-0.5625 R:-1.0 loss:0.0569 exploreP:0.3891\n",
      "Episode:32 meanR:-0.4545 R:3.0 loss:0.0500 exploreP:0.3779\n",
      "Episode:33 meanR:-0.3824 R:2.0 loss:0.1160 exploreP:0.3670\n",
      "Episode:34 meanR:-0.3714 R:0.0 loss:0.1238 exploreP:0.3564\n",
      "Episode:35 meanR:-0.2778 R:3.0 loss:0.0984 exploreP:0.3462\n",
      "Episode:36 meanR:-0.2432 R:1.0 loss:0.1208 exploreP:0.3363\n",
      "Episode:37 meanR:-0.2368 R:0.0 loss:0.0833 exploreP:0.3266\n",
      "Episode:38 meanR:-0.2564 R:-1.0 loss:0.0931 exploreP:0.3173\n",
      "Episode:39 meanR:-0.2000 R:2.0 loss:0.0744 exploreP:0.3082\n",
      "Episode:40 meanR:-0.2195 R:-1.0 loss:0.1110 exploreP:0.2994\n",
      "Episode:41 meanR:-0.2381 R:-1.0 loss:0.0710 exploreP:0.2908\n",
      "Episode:42 meanR:-0.1860 R:2.0 loss:0.0863 exploreP:0.2825\n",
      "Episode:43 meanR:-0.1818 R:0.0 loss:0.0985 exploreP:0.2745\n",
      "Episode:44 meanR:-0.1333 R:2.0 loss:0.0531 exploreP:0.2666\n",
      "Episode:45 meanR:-0.1304 R:0.0 loss:0.2172 exploreP:0.2591\n",
      "Episode:46 meanR:-0.1915 R:-3.0 loss:0.1838 exploreP:0.2517\n",
      "Episode:47 meanR:-0.1875 R:0.0 loss:0.1167 exploreP:0.2446\n",
      "Episode:48 meanR:-0.2041 R:-1.0 loss:0.1446 exploreP:0.2376\n",
      "Episode:49 meanR:-0.1800 R:1.0 loss:0.1547 exploreP:0.2309\n",
      "Episode:50 meanR:-0.1765 R:0.0 loss:0.0967 exploreP:0.2244\n",
      "Episode:51 meanR:-0.2308 R:-3.0 loss:0.2734 exploreP:0.2180\n",
      "Episode:52 meanR:-0.2264 R:0.0 loss:0.1558 exploreP:0.2119\n",
      "Episode:53 meanR:-0.1852 R:2.0 loss:0.1536 exploreP:0.2059\n",
      "Episode:54 meanR:-0.1818 R:0.0 loss:0.0978 exploreP:0.2001\n",
      "Episode:55 meanR:-0.1607 R:1.0 loss:0.1547 exploreP:0.1945\n",
      "Episode:56 meanR:-0.1228 R:2.0 loss:0.1049 exploreP:0.1891\n",
      "Episode:57 meanR:-0.1207 R:0.0 loss:0.1508 exploreP:0.1838\n",
      "Episode:58 meanR:-0.1186 R:0.0 loss:0.1155 exploreP:0.1786\n",
      "Episode:59 meanR:-0.0667 R:3.0 loss:0.0729 exploreP:0.1736\n",
      "Episode:60 meanR:-0.0328 R:2.0 loss:0.1772 exploreP:0.1688\n",
      "Episode:61 meanR:0.0645 R:6.0 loss:0.1694 exploreP:0.1641\n",
      "Episode:62 meanR:0.0952 R:2.0 loss:0.1196 exploreP:0.1596\n",
      "Episode:63 meanR:0.1562 R:4.0 loss:0.0881 exploreP:0.1551\n",
      "Episode:64 meanR:0.2000 R:3.0 loss:0.0985 exploreP:0.1509\n",
      "Episode:65 meanR:0.2121 R:1.0 loss:0.0828 exploreP:0.1467\n",
      "Episode:66 meanR:0.2239 R:1.0 loss:0.1052 exploreP:0.1426\n",
      "Episode:67 meanR:0.2500 R:2.0 loss:0.0651 exploreP:0.1387\n",
      "Episode:68 meanR:0.2609 R:1.0 loss:0.1110 exploreP:0.1349\n",
      "Episode:69 meanR:0.2857 R:2.0 loss:0.1090 exploreP:0.1312\n",
      "Episode:70 meanR:0.2958 R:1.0 loss:0.2129 exploreP:0.1276\n",
      "Episode:71 meanR:0.2917 R:0.0 loss:0.0782 exploreP:0.1242\n",
      "Episode:72 meanR:0.2877 R:0.0 loss:0.0735 exploreP:0.1208\n",
      "Episode:73 meanR:0.2838 R:0.0 loss:0.0763 exploreP:0.1175\n",
      "Episode:74 meanR:0.2800 R:0.0 loss:0.1162 exploreP:0.1143\n",
      "Episode:75 meanR:0.2632 R:-1.0 loss:0.0908 exploreP:0.1113\n",
      "Episode:76 meanR:0.2727 R:1.0 loss:0.0772 exploreP:0.1083\n",
      "Episode:77 meanR:0.2821 R:1.0 loss:0.1172 exploreP:0.1054\n",
      "Episode:78 meanR:0.2658 R:-1.0 loss:0.1135 exploreP:0.1025\n",
      "Episode:79 meanR:0.2625 R:0.0 loss:0.0780 exploreP:0.0998\n",
      "Episode:80 meanR:0.2346 R:-2.0 loss:0.0593 exploreP:0.0972\n",
      "Episode:81 meanR:0.2317 R:0.0 loss:0.0165 exploreP:0.0946\n",
      "Episode:82 meanR:0.2169 R:-1.0 loss:0.0360 exploreP:0.0921\n",
      "Episode:83 meanR:0.2024 R:-1.0 loss:0.0280 exploreP:0.0897\n",
      "Episode:84 meanR:0.1765 R:-2.0 loss:0.0568 exploreP:0.0873\n",
      "Episode:85 meanR:0.1628 R:-1.0 loss:0.0280 exploreP:0.0850\n",
      "Episode:86 meanR:0.2069 R:4.0 loss:0.0585 exploreP:0.0828\n",
      "Episode:87 meanR:0.2045 R:0.0 loss:0.1202 exploreP:0.0806\n",
      "Episode:88 meanR:0.1798 R:-2.0 loss:0.0835 exploreP:0.0786\n",
      "Episode:89 meanR:0.1778 R:0.0 loss:0.0492 exploreP:0.0765\n",
      "Episode:90 meanR:0.1978 R:2.0 loss:0.0415 exploreP:0.0746\n",
      "Episode:91 meanR:0.2283 R:3.0 loss:0.0901 exploreP:0.0727\n",
      "Episode:92 meanR:0.2258 R:0.0 loss:0.1180 exploreP:0.0708\n",
      "Episode:93 meanR:0.2021 R:-2.0 loss:0.0351 exploreP:0.0690\n",
      "Episode:94 meanR:0.1789 R:-2.0 loss:0.0622 exploreP:0.0673\n",
      "Episode:95 meanR:0.1458 R:-3.0 loss:0.0534 exploreP:0.0656\n",
      "Episode:96 meanR:0.1443 R:0.0 loss:0.1036 exploreP:0.0639\n",
      "Episode:97 meanR:0.1429 R:0.0 loss:0.0747 exploreP:0.0623\n",
      "Episode:98 meanR:0.1313 R:-1.0 loss:0.0811 exploreP:0.0608\n",
      "Episode:99 meanR:0.1600 R:3.0 loss:0.0482 exploreP:0.0593\n",
      "Episode:100 meanR:0.1300 R:-1.0 loss:0.0341 exploreP:0.0578\n",
      "Episode:101 meanR:0.1400 R:-1.0 loss:0.0488 exploreP:0.0564\n",
      "Episode:102 meanR:0.1700 R:1.0 loss:0.0313 exploreP:0.0550\n",
      "Episode:103 meanR:0.1800 R:0.0 loss:0.0389 exploreP:0.0537\n",
      "Episode:104 meanR:0.1900 R:1.0 loss:0.0402 exploreP:0.0524\n",
      "Episode:105 meanR:0.1900 R:2.0 loss:0.0635 exploreP:0.0512\n",
      "Episode:106 meanR:0.2300 R:3.0 loss:0.0617 exploreP:0.0500\n",
      "Episode:107 meanR:0.3000 R:7.0 loss:0.0967 exploreP:0.0488\n",
      "Episode:108 meanR:0.2700 R:-1.0 loss:0.1173 exploreP:0.0476\n",
      "Episode:109 meanR:0.3100 R:3.0 loss:0.0634 exploreP:0.0465\n",
      "Episode:110 meanR:0.3300 R:2.0 loss:0.0559 exploreP:0.0454\n",
      "Episode:111 meanR:0.3400 R:0.0 loss:0.0515 exploreP:0.0444\n",
      "Episode:112 meanR:0.3700 R:3.0 loss:0.0450 exploreP:0.0434\n",
      "Episode:113 meanR:0.3600 R:1.0 loss:0.0562 exploreP:0.0424\n",
      "Episode:114 meanR:0.3800 R:1.0 loss:0.0437 exploreP:0.0414\n",
      "Episode:115 meanR:0.3900 R:-1.0 loss:0.0603 exploreP:0.0405\n",
      "Episode:116 meanR:0.3900 R:0.0 loss:0.0400 exploreP:0.0396\n",
      "Episode:117 meanR:0.4200 R:0.0 loss:0.0393 exploreP:0.0387\n",
      "Episode:118 meanR:0.4300 R:-1.0 loss:0.0323 exploreP:0.0379\n",
      "Episode:119 meanR:0.4800 R:1.0 loss:0.0402 exploreP:0.0371\n",
      "Episode:120 meanR:0.4900 R:1.0 loss:0.0335 exploreP:0.0363\n",
      "Episode:121 meanR:0.5200 R:2.0 loss:0.0212 exploreP:0.0355\n",
      "Episode:122 meanR:0.5200 R:-1.0 loss:0.0498 exploreP:0.0347\n",
      "Episode:123 meanR:0.5500 R:2.0 loss:0.0406 exploreP:0.0340\n",
      "Episode:124 meanR:0.5600 R:1.0 loss:0.0728 exploreP:0.0333\n",
      "Episode:125 meanR:0.6000 R:4.0 loss:0.1138 exploreP:0.0326\n",
      "Episode:126 meanR:0.6200 R:1.0 loss:0.0919 exploreP:0.0319\n",
      "Episode:127 meanR:0.6200 R:-1.0 loss:0.1357 exploreP:0.0313\n",
      "Episode:128 meanR:0.6300 R:0.0 loss:0.0539 exploreP:0.0306\n",
      "Episode:129 meanR:0.6400 R:0.0 loss:0.0266 exploreP:0.0300\n",
      "Episode:130 meanR:0.6300 R:1.0 loss:0.0635 exploreP:0.0294\n",
      "Episode:131 meanR:0.6400 R:0.0 loss:0.0318 exploreP:0.0289\n",
      "Episode:132 meanR:0.6400 R:3.0 loss:0.0285 exploreP:0.0283\n",
      "Episode:133 meanR:0.6200 R:0.0 loss:0.0837 exploreP:0.0278\n",
      "Episode:134 meanR:0.6600 R:4.0 loss:0.0478 exploreP:0.0272\n",
      "Episode:135 meanR:0.6900 R:6.0 loss:0.0628 exploreP:0.0267\n",
      "Episode:136 meanR:0.7100 R:3.0 loss:0.0814 exploreP:0.0262\n",
      "Episode:137 meanR:0.7300 R:2.0 loss:0.0945 exploreP:0.0258\n",
      "Episode:138 meanR:0.7600 R:2.0 loss:0.0384 exploreP:0.0253\n",
      "Episode:139 meanR:0.7900 R:5.0 loss:0.0528 exploreP:0.0248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:140 meanR:0.8000 R:0.0 loss:0.0622 exploreP:0.0244\n",
      "Episode:141 meanR:0.8300 R:2.0 loss:0.0351 exploreP:0.0240\n",
      "Episode:142 meanR:0.8600 R:5.0 loss:0.0508 exploreP:0.0236\n",
      "Episode:143 meanR:0.8700 R:1.0 loss:0.0585 exploreP:0.0232\n",
      "Episode:144 meanR:0.8700 R:2.0 loss:0.0450 exploreP:0.0228\n",
      "Episode:145 meanR:0.9200 R:5.0 loss:0.1082 exploreP:0.0224\n",
      "Episode:146 meanR:0.9800 R:3.0 loss:0.0893 exploreP:0.0220\n",
      "Episode:147 meanR:1.0100 R:3.0 loss:0.0449 exploreP:0.0217\n",
      "Episode:148 meanR:1.0500 R:3.0 loss:0.0566 exploreP:0.0213\n",
      "Episode:149 meanR:1.0700 R:3.0 loss:0.0565 exploreP:0.0210\n",
      "Episode:150 meanR:1.0700 R:0.0 loss:0.0284 exploreP:0.0207\n",
      "Episode:151 meanR:1.1500 R:5.0 loss:0.0446 exploreP:0.0204\n",
      "Episode:152 meanR:1.1500 R:0.0 loss:0.0560 exploreP:0.0201\n",
      "Episode:153 meanR:1.1400 R:1.0 loss:0.0556 exploreP:0.0198\n",
      "Episode:154 meanR:1.1500 R:1.0 loss:0.0675 exploreP:0.0195\n",
      "Episode:155 meanR:1.1500 R:1.0 loss:0.0858 exploreP:0.0192\n",
      "Episode:156 meanR:1.1300 R:0.0 loss:0.0627 exploreP:0.0189\n",
      "Episode:157 meanR:1.1500 R:2.0 loss:0.0244 exploreP:0.0187\n",
      "Episode:158 meanR:1.1800 R:3.0 loss:0.0361 exploreP:0.0184\n",
      "Episode:159 meanR:1.1600 R:1.0 loss:0.0472 exploreP:0.0181\n",
      "Episode:160 meanR:1.1800 R:4.0 loss:0.0737 exploreP:0.0179\n",
      "Episode:161 meanR:1.1200 R:0.0 loss:0.0570 exploreP:0.0177\n",
      "Episode:162 meanR:1.1300 R:3.0 loss:0.0909 exploreP:0.0174\n",
      "Episode:163 meanR:1.1400 R:5.0 loss:0.0599 exploreP:0.0172\n",
      "Episode:164 meanR:1.1400 R:3.0 loss:0.1302 exploreP:0.0170\n",
      "Episode:165 meanR:1.1300 R:0.0 loss:0.0705 exploreP:0.0168\n",
      "Episode:166 meanR:1.1400 R:2.0 loss:0.0414 exploreP:0.0166\n",
      "Episode:167 meanR:1.1300 R:1.0 loss:0.0484 exploreP:0.0164\n",
      "Episode:168 meanR:1.1600 R:4.0 loss:0.0491 exploreP:0.0162\n",
      "Episode:169 meanR:1.1900 R:5.0 loss:0.0451 exploreP:0.0160\n",
      "Episode:170 meanR:1.1900 R:1.0 loss:0.0390 exploreP:0.0159\n",
      "Episode:171 meanR:1.2000 R:1.0 loss:0.0831 exploreP:0.0157\n",
      "Episode:172 meanR:1.2400 R:4.0 loss:0.0675 exploreP:0.0155\n",
      "Episode:173 meanR:1.3200 R:8.0 loss:0.0505 exploreP:0.0154\n",
      "Episode:174 meanR:1.3700 R:5.0 loss:0.0572 exploreP:0.0152\n",
      "Episode:175 meanR:1.4300 R:5.0 loss:0.0707 exploreP:0.0150\n",
      "Episode:176 meanR:1.4500 R:3.0 loss:0.0289 exploreP:0.0149\n",
      "Episode:177 meanR:1.4600 R:2.0 loss:0.0490 exploreP:0.0147\n",
      "Episode:178 meanR:1.4700 R:0.0 loss:0.0197 exploreP:0.0146\n",
      "Episode:179 meanR:1.4800 R:1.0 loss:0.0396 exploreP:0.0145\n",
      "Episode:180 meanR:1.4800 R:-2.0 loss:0.0336 exploreP:0.0143\n",
      "Episode:181 meanR:1.5100 R:3.0 loss:0.0362 exploreP:0.0142\n",
      "Episode:182 meanR:1.5300 R:1.0 loss:0.0216 exploreP:0.0141\n",
      "Episode:183 meanR:1.5800 R:4.0 loss:0.0168 exploreP:0.0140\n",
      "Episode:184 meanR:1.6400 R:4.0 loss:0.0459 exploreP:0.0138\n",
      "Episode:185 meanR:1.6800 R:3.0 loss:0.0632 exploreP:0.0137\n",
      "Episode:186 meanR:1.6500 R:1.0 loss:0.0576 exploreP:0.0136\n",
      "Episode:187 meanR:1.6500 R:0.0 loss:0.0804 exploreP:0.0135\n",
      "Episode:188 meanR:1.6600 R:-1.0 loss:0.0446 exploreP:0.0134\n",
      "Episode:189 meanR:1.6800 R:2.0 loss:0.0638 exploreP:0.0133\n",
      "Episode:190 meanR:1.6700 R:1.0 loss:0.0658 exploreP:0.0132\n",
      "Episode:191 meanR:1.6800 R:4.0 loss:0.0450 exploreP:0.0131\n",
      "Episode:192 meanR:1.7000 R:2.0 loss:0.0847 exploreP:0.0130\n",
      "Episode:193 meanR:1.7100 R:-1.0 loss:0.0810 exploreP:0.0129\n",
      "Episode:194 meanR:1.7500 R:2.0 loss:0.0813 exploreP:0.0129\n",
      "Episode:195 meanR:1.8300 R:5.0 loss:0.1007 exploreP:0.0128\n",
      "Episode:196 meanR:1.8300 R:0.0 loss:0.0516 exploreP:0.0127\n",
      "Episode:197 meanR:1.8400 R:1.0 loss:0.0309 exploreP:0.0126\n",
      "Episode:198 meanR:1.8600 R:1.0 loss:0.0611 exploreP:0.0125\n",
      "Episode:199 meanR:1.8300 R:0.0 loss:0.0442 exploreP:0.0125\n",
      "Episode:200 meanR:1.9000 R:6.0 loss:0.0348 exploreP:0.0124\n",
      "Episode:201 meanR:1.9200 R:1.0 loss:0.1126 exploreP:0.0123\n",
      "Episode:202 meanR:1.9600 R:5.0 loss:0.0499 exploreP:0.0122\n",
      "Episode:203 meanR:1.9500 R:-1.0 loss:0.0725 exploreP:0.0122\n",
      "Episode:204 meanR:1.9400 R:0.0 loss:0.0517 exploreP:0.0121\n",
      "Episode:205 meanR:1.9500 R:3.0 loss:0.0581 exploreP:0.0120\n",
      "Episode:206 meanR:2.0000 R:8.0 loss:0.0490 exploreP:0.0120\n",
      "Episode:207 meanR:1.9500 R:2.0 loss:0.0757 exploreP:0.0119\n",
      "Episode:208 meanR:1.9700 R:1.0 loss:0.0460 exploreP:0.0119\n",
      "Episode:209 meanR:2.0200 R:8.0 loss:0.0617 exploreP:0.0118\n",
      "Episode:210 meanR:2.0500 R:5.0 loss:0.0628 exploreP:0.0118\n",
      "Episode:211 meanR:2.0500 R:0.0 loss:0.0898 exploreP:0.0117\n",
      "Episode:212 meanR:2.0500 R:3.0 loss:0.0593 exploreP:0.0117\n",
      "Episode:213 meanR:2.0500 R:1.0 loss:0.0883 exploreP:0.0116\n",
      "Episode:214 meanR:2.0500 R:1.0 loss:0.0440 exploreP:0.0116\n",
      "Episode:215 meanR:2.1100 R:5.0 loss:0.0321 exploreP:0.0115\n",
      "Episode:216 meanR:2.1300 R:2.0 loss:0.0512 exploreP:0.0115\n",
      "Episode:217 meanR:2.1500 R:2.0 loss:0.0783 exploreP:0.0114\n",
      "Episode:218 meanR:2.1900 R:3.0 loss:0.0370 exploreP:0.0114\n",
      "Episode:219 meanR:2.2500 R:7.0 loss:0.0868 exploreP:0.0113\n",
      "Episode:220 meanR:2.2400 R:0.0 loss:0.0695 exploreP:0.0113\n",
      "Episode:221 meanR:2.2900 R:7.0 loss:0.0465 exploreP:0.0113\n",
      "Episode:222 meanR:2.3300 R:3.0 loss:0.0581 exploreP:0.0112\n",
      "Episode:223 meanR:2.3300 R:2.0 loss:0.0742 exploreP:0.0112\n",
      "Episode:224 meanR:2.4000 R:8.0 loss:0.0502 exploreP:0.0112\n",
      "Episode:225 meanR:2.4100 R:5.0 loss:0.0919 exploreP:0.0111\n",
      "Episode:226 meanR:2.4400 R:4.0 loss:0.0885 exploreP:0.0111\n",
      "Episode:227 meanR:2.5000 R:5.0 loss:0.0370 exploreP:0.0111\n",
      "Episode:228 meanR:2.5400 R:4.0 loss:0.0614 exploreP:0.0110\n",
      "Episode:229 meanR:2.5800 R:4.0 loss:0.0581 exploreP:0.0110\n",
      "Episode:230 meanR:2.6000 R:3.0 loss:0.0584 exploreP:0.0110\n",
      "Episode:231 meanR:2.6300 R:3.0 loss:0.0524 exploreP:0.0109\n",
      "Episode:232 meanR:2.6300 R:3.0 loss:0.0840 exploreP:0.0109\n",
      "Episode:233 meanR:2.6700 R:4.0 loss:0.0774 exploreP:0.0109\n",
      "Episode:234 meanR:2.6400 R:1.0 loss:0.0726 exploreP:0.0109\n",
      "Episode:235 meanR:2.6300 R:5.0 loss:0.1242 exploreP:0.0108\n",
      "Episode:236 meanR:2.6200 R:2.0 loss:0.0556 exploreP:0.0108\n",
      "Episode:237 meanR:2.6300 R:3.0 loss:0.0783 exploreP:0.0108\n",
      "Episode:238 meanR:2.6300 R:2.0 loss:0.0479 exploreP:0.0108\n",
      "Episode:239 meanR:2.6200 R:4.0 loss:0.0517 exploreP:0.0107\n",
      "Episode:240 meanR:2.6200 R:0.0 loss:0.0442 exploreP:0.0107\n",
      "Episode:241 meanR:2.6600 R:6.0 loss:0.0730 exploreP:0.0107\n",
      "Episode:242 meanR:2.6900 R:8.0 loss:0.0399 exploreP:0.0107\n",
      "Episode:243 meanR:2.7300 R:5.0 loss:0.1025 exploreP:0.0107\n",
      "Episode:244 meanR:2.7200 R:1.0 loss:0.0701 exploreP:0.0106\n",
      "Episode:245 meanR:2.6800 R:1.0 loss:0.1514 exploreP:0.0106\n",
      "Episode:246 meanR:2.6800 R:3.0 loss:0.0606 exploreP:0.0106\n",
      "Episode:247 meanR:2.6500 R:0.0 loss:0.0866 exploreP:0.0106\n",
      "Episode:248 meanR:2.6500 R:3.0 loss:0.0534 exploreP:0.0106\n",
      "Episode:249 meanR:2.7300 R:11.0 loss:0.0513 exploreP:0.0105\n",
      "Episode:250 meanR:2.7500 R:2.0 loss:0.0940 exploreP:0.0105\n",
      "Episode:251 meanR:2.7600 R:6.0 loss:0.0388 exploreP:0.0105\n",
      "Episode:252 meanR:2.8100 R:5.0 loss:0.0596 exploreP:0.0105\n",
      "Episode:253 meanR:2.8000 R:0.0 loss:0.0478 exploreP:0.0105\n",
      "Episode:254 meanR:2.8000 R:1.0 loss:0.1110 exploreP:0.0105\n",
      "Episode:255 meanR:2.7800 R:-1.0 loss:0.0459 exploreP:0.0105\n",
      "Episode:256 meanR:2.8300 R:5.0 loss:0.0566 exploreP:0.0104\n",
      "Episode:257 meanR:2.8500 R:4.0 loss:0.0843 exploreP:0.0104\n",
      "Episode:258 meanR:2.8600 R:4.0 loss:0.0434 exploreP:0.0104\n",
      "Episode:259 meanR:2.8300 R:-2.0 loss:0.0826 exploreP:0.0104\n",
      "Episode:260 meanR:2.7900 R:0.0 loss:0.0452 exploreP:0.0104\n",
      "Episode:261 meanR:2.8000 R:1.0 loss:0.0572 exploreP:0.0104\n",
      "Episode:262 meanR:2.8300 R:6.0 loss:0.0573 exploreP:0.0104\n",
      "Episode:263 meanR:2.8000 R:2.0 loss:0.0449 exploreP:0.0104\n",
      "Episode:264 meanR:2.8000 R:3.0 loss:0.0635 exploreP:0.0103\n",
      "Episode:265 meanR:2.8200 R:2.0 loss:0.0248 exploreP:0.0103\n",
      "Episode:266 meanR:2.8300 R:3.0 loss:0.0346 exploreP:0.0103\n",
      "Episode:267 meanR:2.8600 R:4.0 loss:0.0335 exploreP:0.0103\n",
      "Episode:268 meanR:2.8800 R:6.0 loss:0.0484 exploreP:0.0103\n",
      "Episode:269 meanR:2.8300 R:0.0 loss:0.0970 exploreP:0.0103\n",
      "Episode:270 meanR:2.8300 R:1.0 loss:0.0469 exploreP:0.0103\n",
      "Episode:271 meanR:2.8900 R:7.0 loss:0.0559 exploreP:0.0103\n",
      "Episode:272 meanR:2.8700 R:2.0 loss:0.1219 exploreP:0.0103\n",
      "Episode:273 meanR:2.8300 R:4.0 loss:0.0620 exploreP:0.0103\n",
      "Episode:274 meanR:2.7800 R:0.0 loss:0.0423 exploreP:0.0103\n",
      "Episode:275 meanR:2.7400 R:1.0 loss:0.0377 exploreP:0.0103\n",
      "Episode:276 meanR:2.7300 R:2.0 loss:0.0480 exploreP:0.0102\n",
      "Episode:277 meanR:2.7600 R:5.0 loss:0.0560 exploreP:0.0102\n",
      "Episode:278 meanR:2.7900 R:3.0 loss:0.0549 exploreP:0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:279 meanR:2.8000 R:2.0 loss:0.0887 exploreP:0.0102\n",
      "Episode:280 meanR:2.8200 R:0.0 loss:0.0842 exploreP:0.0102\n",
      "Episode:281 meanR:2.7900 R:0.0 loss:0.0665 exploreP:0.0102\n",
      "Episode:282 meanR:2.7900 R:1.0 loss:0.0450 exploreP:0.0102\n",
      "Episode:283 meanR:2.7900 R:4.0 loss:0.0649 exploreP:0.0102\n",
      "Episode:284 meanR:2.8000 R:5.0 loss:0.1016 exploreP:0.0102\n",
      "Episode:285 meanR:2.8400 R:7.0 loss:0.1168 exploreP:0.0102\n",
      "Episode:286 meanR:2.8900 R:6.0 loss:0.1060 exploreP:0.0102\n",
      "Episode:287 meanR:2.9300 R:4.0 loss:0.0896 exploreP:0.0102\n",
      "Episode:288 meanR:2.9700 R:3.0 loss:0.0703 exploreP:0.0102\n",
      "Episode:289 meanR:2.9800 R:3.0 loss:0.0944 exploreP:0.0102\n",
      "Episode:290 meanR:3.0400 R:7.0 loss:0.0671 exploreP:0.0102\n",
      "Episode:291 meanR:3.0700 R:7.0 loss:0.0608 exploreP:0.0102\n",
      "Episode:292 meanR:3.1100 R:6.0 loss:0.0463 exploreP:0.0102\n",
      "Episode:293 meanR:3.1300 R:1.0 loss:0.0771 exploreP:0.0101\n",
      "Episode:294 meanR:3.1500 R:4.0 loss:0.0415 exploreP:0.0101\n",
      "Episode:295 meanR:3.1600 R:6.0 loss:0.0515 exploreP:0.0101\n",
      "Episode:296 meanR:3.1800 R:2.0 loss:0.0717 exploreP:0.0101\n",
      "Episode:297 meanR:3.2100 R:4.0 loss:0.0582 exploreP:0.0101\n",
      "Episode:298 meanR:3.2100 R:1.0 loss:0.0318 exploreP:0.0101\n",
      "Episode:299 meanR:3.2200 R:1.0 loss:0.0349 exploreP:0.0101\n",
      "Episode:300 meanR:3.1800 R:2.0 loss:0.0643 exploreP:0.0101\n",
      "Episode:301 meanR:3.2000 R:3.0 loss:0.0672 exploreP:0.0101\n",
      "Episode:302 meanR:3.2000 R:5.0 loss:0.0590 exploreP:0.0101\n",
      "Episode:303 meanR:3.2000 R:-1.0 loss:0.0444 exploreP:0.0101\n",
      "Episode:304 meanR:3.2600 R:6.0 loss:0.0742 exploreP:0.0101\n",
      "Episode:305 meanR:3.2400 R:1.0 loss:0.0301 exploreP:0.0101\n",
      "Episode:306 meanR:3.1700 R:1.0 loss:0.0732 exploreP:0.0101\n",
      "Episode:307 meanR:3.1600 R:1.0 loss:0.0430 exploreP:0.0101\n",
      "Episode:308 meanR:3.1600 R:1.0 loss:0.0196 exploreP:0.0101\n",
      "Episode:309 meanR:3.0700 R:-1.0 loss:0.0297 exploreP:0.0101\n",
      "Episode:310 meanR:3.0100 R:-1.0 loss:0.0357 exploreP:0.0101\n",
      "Episode:311 meanR:3.0000 R:-1.0 loss:0.0382 exploreP:0.0101\n",
      "Episode:312 meanR:3.0000 R:3.0 loss:0.0505 exploreP:0.0101\n",
      "Episode:313 meanR:2.9900 R:0.0 loss:0.0331 exploreP:0.0101\n",
      "Episode:314 meanR:3.0200 R:4.0 loss:0.0406 exploreP:0.0101\n",
      "Episode:315 meanR:3.0100 R:4.0 loss:0.0383 exploreP:0.0101\n",
      "Episode:316 meanR:3.0600 R:7.0 loss:0.0602 exploreP:0.0101\n",
      "Episode:317 meanR:3.1000 R:6.0 loss:0.0906 exploreP:0.0101\n",
      "Episode:318 meanR:3.1200 R:5.0 loss:0.1175 exploreP:0.0101\n",
      "Episode:319 meanR:3.1100 R:6.0 loss:0.0669 exploreP:0.0101\n",
      "Episode:320 meanR:3.1800 R:7.0 loss:0.0574 exploreP:0.0101\n",
      "Episode:321 meanR:3.1400 R:3.0 loss:0.0758 exploreP:0.0101\n",
      "Episode:322 meanR:3.1300 R:2.0 loss:0.0744 exploreP:0.0101\n",
      "Episode:323 meanR:3.1400 R:3.0 loss:0.0508 exploreP:0.0101\n",
      "Episode:324 meanR:3.1000 R:4.0 loss:0.0922 exploreP:0.0101\n",
      "Episode:325 meanR:3.0600 R:1.0 loss:0.0651 exploreP:0.0101\n",
      "Episode:326 meanR:3.0600 R:4.0 loss:0.0378 exploreP:0.0101\n",
      "Episode:327 meanR:3.0900 R:8.0 loss:0.0470 exploreP:0.0101\n",
      "Episode:328 meanR:3.0600 R:1.0 loss:0.0914 exploreP:0.0101\n",
      "Episode:329 meanR:3.0700 R:5.0 loss:0.0566 exploreP:0.0100\n",
      "Episode:330 meanR:3.0500 R:1.0 loss:0.0413 exploreP:0.0100\n",
      "Episode:331 meanR:3.0200 R:0.0 loss:0.0595 exploreP:0.0100\n",
      "Episode:332 meanR:3.0000 R:1.0 loss:0.0301 exploreP:0.0100\n",
      "Episode:333 meanR:2.9900 R:3.0 loss:0.0429 exploreP:0.0100\n",
      "Episode:334 meanR:3.0100 R:3.0 loss:0.0565 exploreP:0.0100\n",
      "Episode:335 meanR:3.0100 R:5.0 loss:0.0626 exploreP:0.0100\n",
      "Episode:336 meanR:3.0300 R:4.0 loss:0.0605 exploreP:0.0100\n",
      "Episode:337 meanR:3.0400 R:4.0 loss:0.0584 exploreP:0.0100\n",
      "Episode:338 meanR:3.0900 R:7.0 loss:0.1035 exploreP:0.0100\n",
      "Episode:339 meanR:3.0600 R:1.0 loss:0.0747 exploreP:0.0100\n",
      "Episode:340 meanR:3.1000 R:4.0 loss:0.0563 exploreP:0.0100\n",
      "Episode:341 meanR:3.1300 R:9.0 loss:0.0519 exploreP:0.0100\n",
      "Episode:342 meanR:3.0600 R:1.0 loss:0.1061 exploreP:0.0100\n",
      "Episode:343 meanR:3.0700 R:6.0 loss:0.0577 exploreP:0.0100\n",
      "Episode:344 meanR:3.0600 R:0.0 loss:0.0707 exploreP:0.0100\n",
      "Episode:345 meanR:3.0500 R:0.0 loss:0.0742 exploreP:0.0100\n",
      "Episode:346 meanR:3.0600 R:4.0 loss:0.0484 exploreP:0.0100\n",
      "Episode:347 meanR:3.0800 R:2.0 loss:0.0636 exploreP:0.0100\n",
      "Episode:348 meanR:3.0500 R:0.0 loss:0.0512 exploreP:0.0100\n",
      "Episode:349 meanR:3.0000 R:6.0 loss:0.0523 exploreP:0.0100\n",
      "Episode:350 meanR:2.9900 R:1.0 loss:0.0407 exploreP:0.0100\n",
      "Episode:351 meanR:2.9300 R:0.0 loss:0.0414 exploreP:0.0100\n",
      "Episode:352 meanR:2.8700 R:-1.0 loss:0.0267 exploreP:0.0100\n",
      "Episode:353 meanR:2.8800 R:1.0 loss:0.0256 exploreP:0.0100\n",
      "Episode:354 meanR:2.8500 R:-2.0 loss:0.0346 exploreP:0.0100\n",
      "Episode:355 meanR:2.8500 R:-1.0 loss:0.0199 exploreP:0.0100\n",
      "Episode:356 meanR:2.8200 R:2.0 loss:0.0273 exploreP:0.0100\n",
      "Episode:357 meanR:2.8000 R:2.0 loss:0.0367 exploreP:0.0100\n",
      "Episode:358 meanR:2.7800 R:2.0 loss:0.0376 exploreP:0.0100\n",
      "Episode:359 meanR:2.8500 R:5.0 loss:0.0256 exploreP:0.0100\n",
      "Episode:360 meanR:2.8900 R:4.0 loss:0.0486 exploreP:0.0100\n",
      "Episode:361 meanR:2.9000 R:2.0 loss:0.0559 exploreP:0.0100\n",
      "Episode:362 meanR:2.8700 R:3.0 loss:0.0315 exploreP:0.0100\n",
      "Episode:363 meanR:2.9200 R:7.0 loss:0.0403 exploreP:0.0100\n",
      "Episode:364 meanR:2.9400 R:5.0 loss:0.0433 exploreP:0.0100\n",
      "Episode:365 meanR:3.0100 R:9.0 loss:0.0302 exploreP:0.0100\n",
      "Episode:366 meanR:3.0400 R:6.0 loss:0.0367 exploreP:0.0100\n",
      "Episode:367 meanR:3.0200 R:2.0 loss:0.0404 exploreP:0.0100\n",
      "Episode:368 meanR:2.9900 R:3.0 loss:0.0580 exploreP:0.0100\n",
      "Episode:369 meanR:3.0100 R:2.0 loss:0.0538 exploreP:0.0100\n",
      "Episode:370 meanR:3.0400 R:4.0 loss:0.0333 exploreP:0.0100\n",
      "Episode:371 meanR:2.9800 R:1.0 loss:0.0442 exploreP:0.0100\n",
      "Episode:372 meanR:3.0000 R:4.0 loss:0.0584 exploreP:0.0100\n",
      "Episode:373 meanR:2.9900 R:3.0 loss:0.0426 exploreP:0.0100\n",
      "Episode:374 meanR:3.0700 R:8.0 loss:0.0695 exploreP:0.0100\n",
      "Episode:375 meanR:3.0600 R:0.0 loss:0.0682 exploreP:0.0100\n",
      "Episode:376 meanR:3.1300 R:9.0 loss:0.0549 exploreP:0.0100\n",
      "Episode:377 meanR:3.0900 R:1.0 loss:0.0709 exploreP:0.0100\n",
      "Episode:378 meanR:3.0700 R:1.0 loss:0.0308 exploreP:0.0100\n",
      "Episode:379 meanR:3.0500 R:0.0 loss:0.0389 exploreP:0.0100\n",
      "Episode:380 meanR:3.0800 R:3.0 loss:0.0188 exploreP:0.0100\n",
      "Episode:381 meanR:3.0800 R:0.0 loss:0.0254 exploreP:0.0100\n",
      "Episode:382 meanR:3.1000 R:3.0 loss:0.0449 exploreP:0.0100\n",
      "Episode:383 meanR:3.0400 R:-2.0 loss:0.0621 exploreP:0.0100\n",
      "Episode:384 meanR:3.0000 R:1.0 loss:0.0445 exploreP:0.0100\n",
      "Episode:385 meanR:2.9200 R:-1.0 loss:0.0517 exploreP:0.0100\n",
      "Episode:386 meanR:2.8400 R:-2.0 loss:0.0561 exploreP:0.0100\n",
      "Episode:387 meanR:2.8000 R:0.0 loss:0.0667 exploreP:0.0100\n",
      "Episode:388 meanR:2.8000 R:3.0 loss:0.0958 exploreP:0.0100\n",
      "Episode:389 meanR:2.8000 R:3.0 loss:0.0762 exploreP:0.0100\n",
      "Episode:390 meanR:2.7400 R:1.0 loss:0.0276 exploreP:0.0100\n",
      "Episode:391 meanR:2.6700 R:0.0 loss:0.0199 exploreP:0.0100\n",
      "Episode:392 meanR:2.6300 R:2.0 loss:0.0459 exploreP:0.0100\n",
      "Episode:393 meanR:2.6200 R:0.0 loss:0.0551 exploreP:0.0100\n",
      "Episode:394 meanR:2.5900 R:1.0 loss:0.0524 exploreP:0.0100\n",
      "Episode:395 meanR:2.5500 R:2.0 loss:0.0496 exploreP:0.0100\n",
      "Episode:396 meanR:2.5300 R:0.0 loss:0.0316 exploreP:0.0100\n",
      "Episode:397 meanR:2.5400 R:5.0 loss:0.0403 exploreP:0.0100\n",
      "Episode:398 meanR:2.5500 R:2.0 loss:0.0504 exploreP:0.0100\n",
      "Episode:399 meanR:2.5500 R:1.0 loss:0.0328 exploreP:0.0100\n",
      "Episode:400 meanR:2.5400 R:1.0 loss:0.0269 exploreP:0.0100\n",
      "Episode:401 meanR:2.5200 R:1.0 loss:0.0265 exploreP:0.0100\n",
      "Episode:402 meanR:2.4700 R:0.0 loss:0.0207 exploreP:0.0100\n",
      "Episode:403 meanR:2.4900 R:1.0 loss:0.0307 exploreP:0.0100\n",
      "Episode:404 meanR:2.4500 R:2.0 loss:0.0396 exploreP:0.0100\n",
      "Episode:405 meanR:2.4700 R:3.0 loss:0.0413 exploreP:0.0100\n",
      "Episode:406 meanR:2.4700 R:1.0 loss:0.0549 exploreP:0.0100\n",
      "Episode:407 meanR:2.4900 R:3.0 loss:0.0375 exploreP:0.0100\n",
      "Episode:408 meanR:2.5500 R:7.0 loss:0.0612 exploreP:0.0100\n",
      "Episode:409 meanR:2.6100 R:5.0 loss:0.0488 exploreP:0.0100\n",
      "Episode:410 meanR:2.6400 R:2.0 loss:0.0697 exploreP:0.0100\n",
      "Episode:411 meanR:2.6700 R:2.0 loss:0.0674 exploreP:0.0100\n",
      "Episode:412 meanR:2.6700 R:3.0 loss:0.0497 exploreP:0.0100\n",
      "Episode:413 meanR:2.7800 R:11.0 loss:0.0435 exploreP:0.0100\n",
      "Episode:414 meanR:2.8400 R:10.0 loss:0.0627 exploreP:0.0100\n",
      "Episode:415 meanR:2.8200 R:2.0 loss:0.0895 exploreP:0.0100\n",
      "Episode:416 meanR:2.7900 R:4.0 loss:0.0741 exploreP:0.0100\n",
      "Episode:417 meanR:2.7700 R:4.0 loss:0.0473 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:418 meanR:2.7700 R:5.0 loss:0.0575 exploreP:0.0100\n",
      "Episode:419 meanR:2.7400 R:3.0 loss:0.0620 exploreP:0.0100\n",
      "Episode:420 meanR:2.6900 R:2.0 loss:0.0996 exploreP:0.0100\n",
      "Episode:421 meanR:2.6800 R:2.0 loss:0.0498 exploreP:0.0100\n",
      "Episode:422 meanR:2.6700 R:1.0 loss:0.0424 exploreP:0.0100\n",
      "Episode:423 meanR:2.6800 R:4.0 loss:0.0598 exploreP:0.0100\n",
      "Episode:424 meanR:2.6900 R:5.0 loss:0.0483 exploreP:0.0100\n",
      "Episode:425 meanR:2.7300 R:5.0 loss:0.0892 exploreP:0.0100\n",
      "Episode:426 meanR:2.6900 R:0.0 loss:0.0738 exploreP:0.0100\n",
      "Episode:427 meanR:2.6300 R:2.0 loss:0.0893 exploreP:0.0100\n",
      "Episode:428 meanR:2.6500 R:3.0 loss:0.1183 exploreP:0.0100\n",
      "Episode:429 meanR:2.6400 R:4.0 loss:0.0580 exploreP:0.0100\n",
      "Episode:430 meanR:2.6400 R:1.0 loss:0.0434 exploreP:0.0100\n",
      "Episode:431 meanR:2.6800 R:4.0 loss:0.0648 exploreP:0.0100\n",
      "Episode:432 meanR:2.6800 R:1.0 loss:0.0722 exploreP:0.0100\n",
      "Episode:433 meanR:2.6700 R:2.0 loss:0.0510 exploreP:0.0100\n",
      "Episode:434 meanR:2.6700 R:3.0 loss:0.0739 exploreP:0.0100\n",
      "Episode:435 meanR:2.6000 R:-2.0 loss:0.0800 exploreP:0.0100\n",
      "Episode:436 meanR:2.5900 R:3.0 loss:0.0357 exploreP:0.0100\n",
      "Episode:437 meanR:2.5600 R:1.0 loss:0.0613 exploreP:0.0100\n",
      "Episode:438 meanR:2.5000 R:1.0 loss:0.0424 exploreP:0.0100\n",
      "Episode:439 meanR:2.5200 R:3.0 loss:0.0575 exploreP:0.0100\n",
      "Episode:440 meanR:2.5000 R:2.0 loss:0.0575 exploreP:0.0100\n",
      "Episode:441 meanR:2.4300 R:2.0 loss:0.0401 exploreP:0.0100\n",
      "Episode:442 meanR:2.4000 R:-2.0 loss:0.0498 exploreP:0.0100\n",
      "Episode:443 meanR:2.3600 R:2.0 loss:0.0329 exploreP:0.0100\n",
      "Episode:444 meanR:2.3600 R:0.0 loss:0.0271 exploreP:0.0100\n",
      "Episode:445 meanR:2.3600 R:0.0 loss:0.0292 exploreP:0.0100\n",
      "Episode:446 meanR:2.3300 R:1.0 loss:0.0273 exploreP:0.0100\n",
      "Episode:447 meanR:2.3300 R:2.0 loss:0.0494 exploreP:0.0100\n",
      "Episode:448 meanR:2.3700 R:4.0 loss:0.0524 exploreP:0.0100\n",
      "Episode:449 meanR:2.2900 R:-2.0 loss:0.0831 exploreP:0.0100\n",
      "Episode:450 meanR:2.3300 R:5.0 loss:0.1487 exploreP:0.0100\n",
      "Episode:451 meanR:2.3600 R:3.0 loss:0.0549 exploreP:0.0100\n",
      "Episode:452 meanR:2.4500 R:8.0 loss:0.0866 exploreP:0.0100\n",
      "Episode:453 meanR:2.4900 R:5.0 loss:0.1124 exploreP:0.0100\n",
      "Episode:454 meanR:2.4900 R:-2.0 loss:0.0730 exploreP:0.0100\n",
      "Episode:455 meanR:2.4900 R:-1.0 loss:0.0416 exploreP:0.0100\n",
      "Episode:456 meanR:2.5100 R:4.0 loss:0.0296 exploreP:0.0100\n",
      "Episode:457 meanR:2.5200 R:3.0 loss:0.0463 exploreP:0.0100\n",
      "Episode:458 meanR:2.5600 R:6.0 loss:0.0374 exploreP:0.0100\n",
      "Episode:459 meanR:2.5800 R:7.0 loss:0.0567 exploreP:0.0100\n",
      "Episode:460 meanR:2.5400 R:0.0 loss:0.0398 exploreP:0.0100\n",
      "Episode:461 meanR:2.5100 R:-1.0 loss:0.0774 exploreP:0.0100\n",
      "Episode:462 meanR:2.5200 R:4.0 loss:0.0501 exploreP:0.0100\n",
      "Episode:463 meanR:2.4800 R:3.0 loss:0.0494 exploreP:0.0100\n",
      "Episode:464 meanR:2.4600 R:3.0 loss:0.0769 exploreP:0.0100\n",
      "Episode:465 meanR:2.4000 R:3.0 loss:0.0363 exploreP:0.0100\n",
      "Episode:466 meanR:2.3600 R:2.0 loss:0.0533 exploreP:0.0100\n",
      "Episode:467 meanR:2.3800 R:4.0 loss:0.0779 exploreP:0.0100\n",
      "Episode:468 meanR:2.3800 R:3.0 loss:0.0571 exploreP:0.0100\n",
      "Episode:469 meanR:2.3700 R:1.0 loss:0.1021 exploreP:0.0100\n",
      "Episode:470 meanR:2.4300 R:10.0 loss:0.0856 exploreP:0.0100\n",
      "Episode:471 meanR:2.5000 R:8.0 loss:0.0704 exploreP:0.0100\n",
      "Episode:472 meanR:2.4800 R:2.0 loss:0.0848 exploreP:0.0100\n",
      "Episode:473 meanR:2.5000 R:5.0 loss:0.0861 exploreP:0.0100\n",
      "Episode:474 meanR:2.4200 R:0.0 loss:0.0665 exploreP:0.0100\n",
      "Episode:475 meanR:2.4600 R:4.0 loss:0.0691 exploreP:0.0100\n",
      "Episode:476 meanR:2.3600 R:-1.0 loss:0.0866 exploreP:0.0100\n",
      "Episode:477 meanR:2.4100 R:6.0 loss:0.0547 exploreP:0.0100\n",
      "Episode:478 meanR:2.4400 R:4.0 loss:0.0782 exploreP:0.0100\n",
      "Episode:479 meanR:2.4700 R:3.0 loss:0.0408 exploreP:0.0100\n",
      "Episode:480 meanR:2.4600 R:2.0 loss:0.0602 exploreP:0.0100\n",
      "Episode:481 meanR:2.4700 R:1.0 loss:0.0266 exploreP:0.0100\n",
      "Episode:482 meanR:2.4200 R:-2.0 loss:0.0335 exploreP:0.0100\n",
      "Episode:483 meanR:2.4500 R:1.0 loss:0.0151 exploreP:0.0100\n",
      "Episode:484 meanR:2.4500 R:1.0 loss:0.0432 exploreP:0.0100\n",
      "Episode:485 meanR:2.4900 R:3.0 loss:0.0371 exploreP:0.0100\n",
      "Episode:486 meanR:2.5100 R:0.0 loss:0.0403 exploreP:0.0100\n",
      "Episode:487 meanR:2.5100 R:0.0 loss:0.0239 exploreP:0.0100\n",
      "Episode:488 meanR:2.5300 R:5.0 loss:0.0359 exploreP:0.0100\n",
      "Episode:489 meanR:2.5100 R:1.0 loss:0.0429 exploreP:0.0100\n",
      "Episode:490 meanR:2.5000 R:0.0 loss:0.0244 exploreP:0.0100\n",
      "Episode:491 meanR:2.4900 R:-1.0 loss:0.0416 exploreP:0.0100\n",
      "Episode:492 meanR:2.4800 R:1.0 loss:0.0621 exploreP:0.0100\n",
      "Episode:493 meanR:2.4900 R:1.0 loss:0.0422 exploreP:0.0100\n",
      "Episode:494 meanR:2.4800 R:0.0 loss:0.0298 exploreP:0.0100\n",
      "Episode:495 meanR:2.4600 R:0.0 loss:0.0588 exploreP:0.0100\n",
      "Episode:496 meanR:2.5200 R:6.0 loss:0.0702 exploreP:0.0100\n",
      "Episode:497 meanR:2.5000 R:3.0 loss:0.0862 exploreP:0.0100\n",
      "Episode:498 meanR:2.5100 R:3.0 loss:0.0671 exploreP:0.0100\n",
      "Episode:499 meanR:2.5800 R:8.0 loss:0.0552 exploreP:0.0100\n",
      "Episode:500 meanR:2.5600 R:-1.0 loss:0.0740 exploreP:0.0100\n",
      "Episode:501 meanR:2.6100 R:6.0 loss:0.0504 exploreP:0.0100\n",
      "Episode:502 meanR:2.6700 R:6.0 loss:0.0767 exploreP:0.0100\n",
      "Episode:503 meanR:2.7000 R:4.0 loss:0.0660 exploreP:0.0100\n",
      "Episode:504 meanR:2.6900 R:1.0 loss:0.0293 exploreP:0.0100\n",
      "Episode:505 meanR:2.6300 R:-3.0 loss:0.0518 exploreP:0.0100\n",
      "Episode:506 meanR:2.6200 R:0.0 loss:0.0176 exploreP:0.0100\n",
      "Episode:507 meanR:2.6000 R:1.0 loss:0.0325 exploreP:0.0100\n",
      "Episode:508 meanR:2.5700 R:4.0 loss:0.0580 exploreP:0.0100\n",
      "Episode:509 meanR:2.5500 R:3.0 loss:0.0406 exploreP:0.0100\n",
      "Episode:510 meanR:2.5300 R:0.0 loss:0.0214 exploreP:0.0100\n",
      "Episode:511 meanR:2.5800 R:7.0 loss:0.0860 exploreP:0.0100\n",
      "Episode:512 meanR:2.5400 R:-1.0 loss:0.1098 exploreP:0.0100\n",
      "Episode:513 meanR:2.4500 R:2.0 loss:0.0563 exploreP:0.0100\n",
      "Episode:514 meanR:2.3500 R:0.0 loss:0.0532 exploreP:0.0100\n",
      "Episode:515 meanR:2.3400 R:1.0 loss:0.0335 exploreP:0.0100\n",
      "Episode:516 meanR:2.3500 R:5.0 loss:0.0327 exploreP:0.0100\n",
      "Episode:517 meanR:2.3200 R:1.0 loss:0.0379 exploreP:0.0100\n",
      "Episode:518 meanR:2.2800 R:1.0 loss:0.0239 exploreP:0.0100\n",
      "Episode:519 meanR:2.2500 R:0.0 loss:0.0491 exploreP:0.0100\n",
      "Episode:520 meanR:2.2200 R:-1.0 loss:0.0525 exploreP:0.0100\n",
      "Episode:521 meanR:2.2100 R:1.0 loss:0.0243 exploreP:0.0100\n",
      "Episode:522 meanR:2.2000 R:0.0 loss:0.0197 exploreP:0.0100\n",
      "Episode:523 meanR:2.1600 R:0.0 loss:0.0105 exploreP:0.0100\n",
      "Episode:524 meanR:2.1200 R:1.0 loss:0.0513 exploreP:0.0100\n",
      "Episode:525 meanR:2.1000 R:3.0 loss:0.0446 exploreP:0.0100\n",
      "Episode:526 meanR:2.1800 R:8.0 loss:0.0316 exploreP:0.0100\n",
      "Episode:527 meanR:2.1600 R:0.0 loss:0.0333 exploreP:0.0100\n",
      "Episode:528 meanR:2.1300 R:0.0 loss:0.0362 exploreP:0.0100\n",
      "Episode:529 meanR:2.1200 R:3.0 loss:0.0376 exploreP:0.0100\n",
      "Episode:530 meanR:2.1100 R:0.0 loss:0.0418 exploreP:0.0100\n",
      "Episode:531 meanR:2.0700 R:0.0 loss:0.0203 exploreP:0.0100\n",
      "Episode:532 meanR:2.1100 R:5.0 loss:0.0564 exploreP:0.0100\n",
      "Episode:533 meanR:2.1100 R:2.0 loss:0.0418 exploreP:0.0100\n",
      "Episode:534 meanR:2.0600 R:-2.0 loss:0.0442 exploreP:0.0100\n",
      "Episode:535 meanR:2.1200 R:4.0 loss:0.0330 exploreP:0.0100\n",
      "Episode:536 meanR:2.0900 R:0.0 loss:0.0368 exploreP:0.0100\n",
      "Episode:537 meanR:2.1700 R:9.0 loss:0.0413 exploreP:0.0100\n",
      "Episode:538 meanR:2.2100 R:5.0 loss:0.0701 exploreP:0.0100\n",
      "Episode:539 meanR:2.1800 R:0.0 loss:0.0672 exploreP:0.0100\n",
      "Episode:540 meanR:2.2100 R:5.0 loss:0.0767 exploreP:0.0100\n",
      "Episode:541 meanR:2.2100 R:2.0 loss:0.0822 exploreP:0.0100\n",
      "Episode:542 meanR:2.2900 R:6.0 loss:0.0726 exploreP:0.0100\n",
      "Episode:543 meanR:2.3400 R:7.0 loss:0.0456 exploreP:0.0100\n",
      "Episode:544 meanR:2.4000 R:6.0 loss:0.0623 exploreP:0.0100\n",
      "Episode:545 meanR:2.4800 R:8.0 loss:0.0576 exploreP:0.0100\n",
      "Episode:546 meanR:2.4900 R:2.0 loss:0.0889 exploreP:0.0100\n",
      "Episode:547 meanR:2.5000 R:3.0 loss:0.0420 exploreP:0.0100\n",
      "Episode:548 meanR:2.5400 R:8.0 loss:0.0356 exploreP:0.0100\n",
      "Episode:549 meanR:2.6600 R:10.0 loss:0.0827 exploreP:0.0100\n",
      "Episode:550 meanR:2.6400 R:3.0 loss:0.1489 exploreP:0.0100\n",
      "Episode:551 meanR:2.7000 R:9.0 loss:0.0783 exploreP:0.0100\n",
      "Episode:552 meanR:2.7300 R:11.0 loss:0.0826 exploreP:0.0100\n",
      "Episode:553 meanR:2.7600 R:8.0 loss:0.1159 exploreP:0.0100\n",
      "Episode:554 meanR:2.7800 R:0.0 loss:0.0505 exploreP:0.0100\n",
      "Episode:555 meanR:2.8700 R:8.0 loss:0.1289 exploreP:0.0100\n",
      "Episode:556 meanR:2.8300 R:0.0 loss:0.1173 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:557 meanR:2.7900 R:-1.0 loss:0.0525 exploreP:0.0100\n",
      "Episode:558 meanR:2.7900 R:6.0 loss:0.0464 exploreP:0.0100\n",
      "Episode:559 meanR:2.7300 R:1.0 loss:0.0596 exploreP:0.0100\n",
      "Episode:560 meanR:2.8100 R:8.0 loss:0.0576 exploreP:0.0100\n",
      "Episode:561 meanR:2.8400 R:2.0 loss:0.0461 exploreP:0.0100\n",
      "Episode:562 meanR:2.8300 R:3.0 loss:0.0594 exploreP:0.0100\n",
      "Episode:563 meanR:2.8100 R:1.0 loss:0.0726 exploreP:0.0100\n",
      "Episode:564 meanR:2.8000 R:2.0 loss:0.0400 exploreP:0.0100\n",
      "Episode:565 meanR:2.7500 R:-2.0 loss:0.0315 exploreP:0.0100\n",
      "Episode:566 meanR:2.7900 R:6.0 loss:0.0542 exploreP:0.0100\n",
      "Episode:567 meanR:2.7500 R:0.0 loss:0.0336 exploreP:0.0100\n",
      "Episode:568 meanR:2.7300 R:1.0 loss:0.0331 exploreP:0.0100\n",
      "Episode:569 meanR:2.7200 R:0.0 loss:0.0320 exploreP:0.0100\n",
      "Episode:570 meanR:2.6100 R:-1.0 loss:0.0150 exploreP:0.0100\n",
      "Episode:571 meanR:2.5500 R:2.0 loss:0.0326 exploreP:0.0100\n",
      "Episode:572 meanR:2.5300 R:0.0 loss:0.0332 exploreP:0.0100\n",
      "Episode:573 meanR:2.5000 R:2.0 loss:0.0331 exploreP:0.0100\n",
      "Episode:574 meanR:2.5200 R:2.0 loss:0.0559 exploreP:0.0100\n",
      "Episode:575 meanR:2.5100 R:3.0 loss:0.0607 exploreP:0.0100\n",
      "Episode:576 meanR:2.5300 R:1.0 loss:0.0336 exploreP:0.0100\n",
      "Episode:577 meanR:2.5300 R:6.0 loss:0.0390 exploreP:0.0100\n",
      "Episode:578 meanR:2.4900 R:0.0 loss:0.0464 exploreP:0.0100\n",
      "Episode:579 meanR:2.5200 R:6.0 loss:0.0514 exploreP:0.0100\n",
      "Episode:580 meanR:2.5100 R:1.0 loss:0.0462 exploreP:0.0100\n",
      "Episode:581 meanR:2.5100 R:1.0 loss:0.0387 exploreP:0.0100\n",
      "Episode:582 meanR:2.5800 R:5.0 loss:0.0446 exploreP:0.0100\n",
      "Episode:583 meanR:2.6200 R:5.0 loss:0.0675 exploreP:0.0100\n",
      "Episode:584 meanR:2.6300 R:2.0 loss:0.0870 exploreP:0.0100\n",
      "Episode:585 meanR:2.6300 R:3.0 loss:0.0700 exploreP:0.0100\n",
      "Episode:586 meanR:2.6600 R:3.0 loss:0.0531 exploreP:0.0100\n",
      "Episode:587 meanR:2.6700 R:1.0 loss:0.0153 exploreP:0.0100\n",
      "Episode:588 meanR:2.7200 R:10.0 loss:0.0505 exploreP:0.0100\n",
      "Episode:589 meanR:2.7000 R:-1.0 loss:0.0683 exploreP:0.0100\n",
      "Episode:590 meanR:2.7000 R:0.0 loss:0.0537 exploreP:0.0100\n",
      "Episode:591 meanR:2.7000 R:-1.0 loss:0.0298 exploreP:0.0100\n",
      "Episode:592 meanR:2.6900 R:0.0 loss:0.0267 exploreP:0.0100\n",
      "Episode:593 meanR:2.7000 R:2.0 loss:0.0316 exploreP:0.0100\n",
      "Episode:594 meanR:2.7300 R:3.0 loss:0.0443 exploreP:0.0100\n",
      "Episode:595 meanR:2.7300 R:0.0 loss:0.0500 exploreP:0.0100\n",
      "Episode:596 meanR:2.7000 R:3.0 loss:0.0786 exploreP:0.0100\n",
      "Episode:597 meanR:2.7100 R:4.0 loss:0.0502 exploreP:0.0100\n",
      "Episode:598 meanR:2.7600 R:8.0 loss:0.0594 exploreP:0.0100\n",
      "Episode:599 meanR:2.7200 R:4.0 loss:0.0351 exploreP:0.0100\n",
      "Episode:600 meanR:2.7400 R:1.0 loss:0.0427 exploreP:0.0100\n",
      "Episode:601 meanR:2.7100 R:3.0 loss:0.0493 exploreP:0.0100\n",
      "Episode:602 meanR:2.6700 R:2.0 loss:0.0434 exploreP:0.0100\n",
      "Episode:603 meanR:2.6500 R:2.0 loss:0.0450 exploreP:0.0100\n",
      "Episode:604 meanR:2.6600 R:2.0 loss:0.0313 exploreP:0.0100\n",
      "Episode:605 meanR:2.7400 R:5.0 loss:0.0458 exploreP:0.0100\n",
      "Episode:606 meanR:2.7500 R:1.0 loss:0.0875 exploreP:0.0100\n",
      "Episode:607 meanR:2.7600 R:2.0 loss:0.0735 exploreP:0.0100\n",
      "Episode:608 meanR:2.7200 R:0.0 loss:0.0556 exploreP:0.0100\n",
      "Episode:609 meanR:2.7100 R:2.0 loss:0.0244 exploreP:0.0100\n",
      "Episode:610 meanR:2.7100 R:0.0 loss:0.0316 exploreP:0.0100\n",
      "Episode:611 meanR:2.6400 R:0.0 loss:0.0232 exploreP:0.0100\n",
      "Episode:612 meanR:2.6700 R:2.0 loss:0.0328 exploreP:0.0100\n",
      "Episode:613 meanR:2.7000 R:5.0 loss:0.0477 exploreP:0.0100\n",
      "Episode:614 meanR:2.7100 R:1.0 loss:0.0448 exploreP:0.0100\n",
      "Episode:615 meanR:2.7100 R:1.0 loss:0.0389 exploreP:0.0100\n",
      "Episode:616 meanR:2.6700 R:1.0 loss:0.0319 exploreP:0.0100\n",
      "Episode:617 meanR:2.6700 R:1.0 loss:0.0317 exploreP:0.0100\n",
      "Episode:618 meanR:2.6600 R:0.0 loss:0.0285 exploreP:0.0100\n",
      "Episode:619 meanR:2.6800 R:2.0 loss:0.0375 exploreP:0.0100\n",
      "Episode:620 meanR:2.7000 R:1.0 loss:0.0253 exploreP:0.0100\n",
      "Episode:621 meanR:2.6800 R:-1.0 loss:0.0131 exploreP:0.0100\n",
      "Episode:622 meanR:2.7000 R:2.0 loss:0.0230 exploreP:0.0100\n",
      "Episode:623 meanR:2.6900 R:-1.0 loss:0.0221 exploreP:0.0100\n",
      "Episode:624 meanR:2.6900 R:1.0 loss:0.0140 exploreP:0.0100\n",
      "Episode:625 meanR:2.6500 R:-1.0 loss:0.0107 exploreP:0.0100\n",
      "Episode:626 meanR:2.5700 R:0.0 loss:0.0073 exploreP:0.0100\n",
      "Episode:627 meanR:2.5800 R:1.0 loss:0.0090 exploreP:0.0100\n",
      "Episode:628 meanR:2.5800 R:0.0 loss:0.0297 exploreP:0.0100\n",
      "Episode:629 meanR:2.5700 R:2.0 loss:0.0203 exploreP:0.0100\n",
      "Episode:630 meanR:2.5600 R:-1.0 loss:0.0260 exploreP:0.0100\n",
      "Episode:631 meanR:2.5600 R:0.0 loss:0.0152 exploreP:0.0100\n",
      "Episode:632 meanR:2.5100 R:0.0 loss:0.0219 exploreP:0.0100\n",
      "Episode:633 meanR:2.5100 R:2.0 loss:0.0443 exploreP:0.0100\n",
      "Episode:634 meanR:2.5300 R:0.0 loss:0.0113 exploreP:0.0100\n",
      "Episode:635 meanR:2.5100 R:2.0 loss:0.0282 exploreP:0.0100\n",
      "Episode:636 meanR:2.5100 R:0.0 loss:0.0130 exploreP:0.0100\n",
      "Episode:637 meanR:2.4200 R:0.0 loss:0.0249 exploreP:0.0100\n",
      "Episode:638 meanR:2.4100 R:4.0 loss:0.0267 exploreP:0.0100\n",
      "Episode:639 meanR:2.4400 R:3.0 loss:0.0461 exploreP:0.0100\n",
      "Episode:640 meanR:2.3700 R:-2.0 loss:0.0279 exploreP:0.0100\n",
      "Episode:641 meanR:2.3500 R:0.0 loss:0.0181 exploreP:0.0100\n",
      "Episode:642 meanR:2.3000 R:1.0 loss:0.0232 exploreP:0.0100\n",
      "Episode:643 meanR:2.2300 R:0.0 loss:0.0290 exploreP:0.0100\n",
      "Episode:644 meanR:2.1800 R:1.0 loss:0.0298 exploreP:0.0100\n",
      "Episode:645 meanR:2.1000 R:0.0 loss:0.0260 exploreP:0.0100\n",
      "Episode:646 meanR:2.1100 R:3.0 loss:0.0286 exploreP:0.0100\n",
      "Episode:647 meanR:2.1200 R:4.0 loss:0.0429 exploreP:0.0100\n",
      "Episode:648 meanR:2.0400 R:0.0 loss:0.0619 exploreP:0.0100\n",
      "Episode:649 meanR:1.9500 R:1.0 loss:0.0550 exploreP:0.0100\n",
      "Episode:650 meanR:1.9200 R:0.0 loss:0.0317 exploreP:0.0100\n",
      "Episode:651 meanR:1.8700 R:4.0 loss:0.0403 exploreP:0.0100\n",
      "Episode:652 meanR:1.7700 R:1.0 loss:0.0669 exploreP:0.0100\n",
      "Episode:653 meanR:1.7100 R:2.0 loss:0.0395 exploreP:0.0100\n",
      "Episode:654 meanR:1.7300 R:2.0 loss:0.0294 exploreP:0.0100\n",
      "Episode:655 meanR:1.6600 R:1.0 loss:0.0429 exploreP:0.0100\n",
      "Episode:656 meanR:1.6500 R:-1.0 loss:0.0294 exploreP:0.0100\n",
      "Episode:657 meanR:1.6600 R:0.0 loss:0.0237 exploreP:0.0100\n",
      "Episode:658 meanR:1.6000 R:0.0 loss:0.0164 exploreP:0.0100\n",
      "Episode:659 meanR:1.6000 R:1.0 loss:0.0201 exploreP:0.0100\n",
      "Episode:660 meanR:1.5100 R:-1.0 loss:0.0525 exploreP:0.0100\n",
      "Episode:661 meanR:1.4700 R:-2.0 loss:0.0289 exploreP:0.0100\n",
      "Episode:662 meanR:1.4700 R:3.0 loss:0.0244 exploreP:0.0100\n",
      "Episode:663 meanR:1.4600 R:0.0 loss:0.0150 exploreP:0.0100\n",
      "Episode:664 meanR:1.4200 R:-2.0 loss:0.0208 exploreP:0.0100\n",
      "Episode:665 meanR:1.4300 R:-1.0 loss:0.0157 exploreP:0.0100\n",
      "Episode:666 meanR:1.4100 R:4.0 loss:0.0336 exploreP:0.0100\n",
      "Episode:667 meanR:1.4600 R:5.0 loss:0.0414 exploreP:0.0100\n",
      "Episode:668 meanR:1.4700 R:2.0 loss:0.0490 exploreP:0.0100\n",
      "Episode:669 meanR:1.5000 R:3.0 loss:0.0463 exploreP:0.0100\n",
      "Episode:670 meanR:1.5300 R:2.0 loss:0.0288 exploreP:0.0100\n",
      "Episode:671 meanR:1.5700 R:6.0 loss:0.0457 exploreP:0.0100\n",
      "Episode:672 meanR:1.5800 R:1.0 loss:0.0623 exploreP:0.0100\n",
      "Episode:673 meanR:1.5700 R:1.0 loss:0.0675 exploreP:0.0100\n",
      "Episode:674 meanR:1.5700 R:2.0 loss:0.0498 exploreP:0.0100\n",
      "Episode:675 meanR:1.5800 R:4.0 loss:0.0454 exploreP:0.0100\n",
      "Episode:676 meanR:1.6400 R:7.0 loss:0.0912 exploreP:0.0100\n",
      "Episode:677 meanR:1.6200 R:4.0 loss:0.0748 exploreP:0.0100\n",
      "Episode:678 meanR:1.6600 R:4.0 loss:0.0731 exploreP:0.0100\n",
      "Episode:679 meanR:1.6100 R:1.0 loss:0.0481 exploreP:0.0100\n",
      "Episode:680 meanR:1.6300 R:3.0 loss:0.0743 exploreP:0.0100\n",
      "Episode:681 meanR:1.6500 R:3.0 loss:0.0670 exploreP:0.0100\n",
      "Episode:682 meanR:1.6500 R:5.0 loss:0.0566 exploreP:0.0100\n",
      "Episode:683 meanR:1.6400 R:4.0 loss:0.0334 exploreP:0.0100\n",
      "Episode:684 meanR:1.6600 R:4.0 loss:0.0785 exploreP:0.0100\n",
      "Episode:685 meanR:1.6300 R:0.0 loss:0.0566 exploreP:0.0100\n",
      "Episode:686 meanR:1.6100 R:1.0 loss:0.0861 exploreP:0.0100\n",
      "Episode:687 meanR:1.6500 R:5.0 loss:0.0651 exploreP:0.0100\n",
      "Episode:688 meanR:1.5400 R:-1.0 loss:0.0681 exploreP:0.0100\n",
      "Episode:689 meanR:1.5700 R:2.0 loss:0.0550 exploreP:0.0100\n",
      "Episode:690 meanR:1.5800 R:1.0 loss:0.0523 exploreP:0.0100\n",
      "Episode:691 meanR:1.5900 R:0.0 loss:0.0435 exploreP:0.0100\n",
      "Episode:692 meanR:1.6000 R:1.0 loss:0.0387 exploreP:0.0100\n",
      "Episode:693 meanR:1.6100 R:3.0 loss:0.0434 exploreP:0.0100\n",
      "Episode:694 meanR:1.6000 R:2.0 loss:0.0429 exploreP:0.0100\n",
      "Episode:695 meanR:1.6100 R:1.0 loss:0.0528 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:696 meanR:1.6000 R:2.0 loss:0.0311 exploreP:0.0100\n",
      "Episode:697 meanR:1.6000 R:4.0 loss:0.0630 exploreP:0.0100\n",
      "Episode:698 meanR:1.5200 R:0.0 loss:0.0263 exploreP:0.0100\n",
      "Episode:699 meanR:1.5200 R:4.0 loss:0.0327 exploreP:0.0100\n",
      "Episode:700 meanR:1.5100 R:0.0 loss:0.0190 exploreP:0.0100\n",
      "Episode:701 meanR:1.5100 R:3.0 loss:0.0382 exploreP:0.0100\n",
      "Episode:702 meanR:1.4600 R:-3.0 loss:0.0499 exploreP:0.0100\n",
      "Episode:703 meanR:1.4900 R:5.0 loss:0.0283 exploreP:0.0100\n",
      "Episode:704 meanR:1.4600 R:-1.0 loss:0.0405 exploreP:0.0100\n",
      "Episode:705 meanR:1.4500 R:4.0 loss:0.0521 exploreP:0.0100\n",
      "Episode:706 meanR:1.4500 R:1.0 loss:0.0813 exploreP:0.0100\n",
      "Episode:707 meanR:1.4500 R:2.0 loss:0.0805 exploreP:0.0100\n",
      "Episode:708 meanR:1.4700 R:2.0 loss:0.0624 exploreP:0.0100\n",
      "Episode:709 meanR:1.4800 R:3.0 loss:0.0770 exploreP:0.0100\n",
      "Episode:710 meanR:1.5400 R:6.0 loss:0.1142 exploreP:0.0100\n",
      "Episode:711 meanR:1.6300 R:9.0 loss:0.1242 exploreP:0.0100\n",
      "Episode:712 meanR:1.6600 R:5.0 loss:0.1170 exploreP:0.0100\n",
      "Episode:713 meanR:1.6300 R:2.0 loss:0.1056 exploreP:0.0100\n",
      "Episode:714 meanR:1.6500 R:3.0 loss:0.1223 exploreP:0.0100\n",
      "Episode:715 meanR:1.6600 R:2.0 loss:0.0932 exploreP:0.0100\n",
      "Episode:716 meanR:1.6800 R:3.0 loss:0.0419 exploreP:0.0100\n",
      "Episode:717 meanR:1.6800 R:1.0 loss:0.0283 exploreP:0.0100\n",
      "Episode:718 meanR:1.6800 R:0.0 loss:0.0223 exploreP:0.0100\n",
      "Episode:719 meanR:1.6600 R:0.0 loss:0.0341 exploreP:0.0100\n",
      "Episode:720 meanR:1.6500 R:0.0 loss:0.0288 exploreP:0.0100\n",
      "Episode:721 meanR:1.6600 R:0.0 loss:0.0256 exploreP:0.0100\n",
      "Episode:722 meanR:1.6300 R:-1.0 loss:0.0211 exploreP:0.0100\n",
      "Episode:723 meanR:1.6500 R:1.0 loss:0.0175 exploreP:0.0100\n",
      "Episode:724 meanR:1.6600 R:2.0 loss:0.0210 exploreP:0.0100\n",
      "Episode:725 meanR:1.6700 R:0.0 loss:0.0546 exploreP:0.0100\n",
      "Episode:726 meanR:1.6800 R:1.0 loss:0.0290 exploreP:0.0100\n",
      "Episode:727 meanR:1.6700 R:0.0 loss:0.0257 exploreP:0.0100\n",
      "Episode:728 meanR:1.6700 R:0.0 loss:0.0260 exploreP:0.0100\n",
      "Episode:729 meanR:1.6600 R:1.0 loss:0.0247 exploreP:0.0100\n",
      "Episode:730 meanR:1.6800 R:1.0 loss:0.0147 exploreP:0.0100\n",
      "Episode:731 meanR:1.7000 R:2.0 loss:0.0190 exploreP:0.0100\n",
      "Episode:732 meanR:1.7800 R:8.0 loss:0.0401 exploreP:0.0100\n",
      "Episode:733 meanR:1.7800 R:2.0 loss:0.0712 exploreP:0.0100\n",
      "Episode:734 meanR:1.8200 R:4.0 loss:0.0382 exploreP:0.0100\n",
      "Episode:735 meanR:1.7900 R:-1.0 loss:0.0259 exploreP:0.0100\n",
      "Episode:736 meanR:1.7800 R:-1.0 loss:0.0258 exploreP:0.0100\n",
      "Episode:737 meanR:1.8100 R:3.0 loss:0.0372 exploreP:0.0100\n",
      "Episode:738 meanR:1.7800 R:1.0 loss:0.0417 exploreP:0.0100\n",
      "Episode:739 meanR:1.7200 R:-3.0 loss:0.0267 exploreP:0.0100\n",
      "Episode:740 meanR:1.7200 R:-2.0 loss:0.0164 exploreP:0.0100\n",
      "Episode:741 meanR:1.7500 R:3.0 loss:0.0174 exploreP:0.0100\n",
      "Episode:742 meanR:1.7400 R:0.0 loss:0.0394 exploreP:0.0100\n",
      "Episode:743 meanR:1.7200 R:-2.0 loss:0.0480 exploreP:0.0100\n",
      "Episode:744 meanR:1.6600 R:-5.0 loss:0.0548 exploreP:0.0100\n",
      "Episode:745 meanR:1.6900 R:3.0 loss:0.0293 exploreP:0.0100\n",
      "Episode:746 meanR:1.7200 R:6.0 loss:0.0604 exploreP:0.0100\n",
      "Episode:747 meanR:1.7500 R:7.0 loss:0.1043 exploreP:0.0100\n",
      "Episode:748 meanR:1.8000 R:5.0 loss:0.0618 exploreP:0.0100\n",
      "Episode:749 meanR:1.8000 R:1.0 loss:0.0827 exploreP:0.0100\n",
      "Episode:750 meanR:1.8700 R:7.0 loss:0.0887 exploreP:0.0100\n",
      "Episode:751 meanR:1.9000 R:7.0 loss:0.0795 exploreP:0.0100\n",
      "Episode:752 meanR:1.9500 R:6.0 loss:0.0742 exploreP:0.0100\n",
      "Episode:753 meanR:1.9400 R:1.0 loss:0.0556 exploreP:0.0100\n",
      "Episode:754 meanR:1.9400 R:2.0 loss:0.0509 exploreP:0.0100\n",
      "Episode:755 meanR:1.9800 R:5.0 loss:0.0549 exploreP:0.0100\n",
      "Episode:756 meanR:2.0200 R:3.0 loss:0.0304 exploreP:0.0100\n",
      "Episode:757 meanR:2.0400 R:2.0 loss:0.0449 exploreP:0.0100\n",
      "Episode:758 meanR:2.0800 R:4.0 loss:0.0721 exploreP:0.0100\n",
      "Episode:759 meanR:2.0600 R:-1.0 loss:0.0839 exploreP:0.0100\n",
      "Episode:760 meanR:2.0900 R:2.0 loss:0.0565 exploreP:0.0100\n",
      "Episode:761 meanR:2.1000 R:-1.0 loss:0.0411 exploreP:0.0100\n",
      "Episode:762 meanR:2.0800 R:1.0 loss:0.0306 exploreP:0.0100\n",
      "Episode:763 meanR:2.1000 R:2.0 loss:0.0356 exploreP:0.0100\n",
      "Episode:764 meanR:2.1400 R:2.0 loss:0.0526 exploreP:0.0100\n",
      "Episode:765 meanR:2.1600 R:1.0 loss:0.0325 exploreP:0.0100\n",
      "Episode:766 meanR:2.1300 R:1.0 loss:0.0335 exploreP:0.0100\n",
      "Episode:767 meanR:2.1100 R:3.0 loss:0.0243 exploreP:0.0100\n",
      "Episode:768 meanR:2.1100 R:2.0 loss:0.0301 exploreP:0.0100\n",
      "Episode:769 meanR:2.1400 R:6.0 loss:0.0348 exploreP:0.0100\n",
      "Episode:770 meanR:2.1300 R:1.0 loss:0.0797 exploreP:0.0100\n",
      "Episode:771 meanR:2.1000 R:3.0 loss:0.0972 exploreP:0.0100\n",
      "Episode:772 meanR:2.0700 R:-2.0 loss:0.0712 exploreP:0.0100\n",
      "Episode:773 meanR:2.0700 R:1.0 loss:0.0372 exploreP:0.0100\n",
      "Episode:774 meanR:2.0800 R:3.0 loss:0.0318 exploreP:0.0100\n",
      "Episode:775 meanR:2.0500 R:1.0 loss:0.0295 exploreP:0.0100\n",
      "Episode:776 meanR:2.0200 R:4.0 loss:0.0304 exploreP:0.0100\n",
      "Episode:777 meanR:1.9900 R:1.0 loss:0.0192 exploreP:0.0100\n",
      "Episode:778 meanR:2.0000 R:5.0 loss:0.0455 exploreP:0.0100\n",
      "Episode:779 meanR:2.0300 R:4.0 loss:0.0429 exploreP:0.0100\n",
      "Episode:780 meanR:2.0400 R:4.0 loss:0.0472 exploreP:0.0100\n",
      "Episode:781 meanR:2.0400 R:3.0 loss:0.0683 exploreP:0.0100\n",
      "Episode:782 meanR:2.0600 R:7.0 loss:0.0484 exploreP:0.0100\n",
      "Episode:783 meanR:2.0200 R:0.0 loss:0.0502 exploreP:0.0100\n",
      "Episode:784 meanR:2.0200 R:4.0 loss:0.0705 exploreP:0.0100\n",
      "Episode:785 meanR:2.0400 R:2.0 loss:0.0566 exploreP:0.0100\n",
      "Episode:786 meanR:2.0400 R:1.0 loss:0.0580 exploreP:0.0100\n",
      "Episode:787 meanR:1.9900 R:0.0 loss:0.0432 exploreP:0.0100\n",
      "Episode:788 meanR:2.0100 R:1.0 loss:0.0221 exploreP:0.0100\n",
      "Episode:789 meanR:2.0200 R:3.0 loss:0.0404 exploreP:0.0100\n",
      "Episode:790 meanR:2.0200 R:1.0 loss:0.0309 exploreP:0.0100\n",
      "Episode:791 meanR:2.0200 R:0.0 loss:0.0514 exploreP:0.0100\n",
      "Episode:792 meanR:2.0100 R:0.0 loss:0.0614 exploreP:0.0100\n",
      "Episode:793 meanR:1.9900 R:1.0 loss:0.0678 exploreP:0.0100\n",
      "Episode:794 meanR:2.0600 R:9.0 loss:0.0458 exploreP:0.0100\n",
      "Episode:795 meanR:2.0700 R:2.0 loss:0.0807 exploreP:0.0100\n",
      "Episode:796 meanR:2.0900 R:4.0 loss:0.0693 exploreP:0.0100\n",
      "Episode:797 meanR:2.1100 R:6.0 loss:0.0927 exploreP:0.0100\n",
      "Episode:798 meanR:2.1500 R:4.0 loss:0.0655 exploreP:0.0100\n",
      "Episode:799 meanR:2.1300 R:2.0 loss:0.0566 exploreP:0.0100\n",
      "Episode:800 meanR:2.1500 R:2.0 loss:0.0442 exploreP:0.0100\n",
      "Episode:801 meanR:2.1700 R:5.0 loss:0.0259 exploreP:0.0100\n",
      "Episode:802 meanR:2.2200 R:2.0 loss:0.0305 exploreP:0.0100\n",
      "Episode:803 meanR:2.2100 R:4.0 loss:0.0431 exploreP:0.0100\n",
      "Episode:804 meanR:2.2400 R:2.0 loss:0.0479 exploreP:0.0100\n",
      "Episode:805 meanR:2.2400 R:4.0 loss:0.0510 exploreP:0.0100\n",
      "Episode:806 meanR:2.2700 R:4.0 loss:0.0701 exploreP:0.0100\n",
      "Episode:807 meanR:2.2500 R:0.0 loss:0.0869 exploreP:0.0100\n",
      "Episode:808 meanR:2.2700 R:4.0 loss:0.0494 exploreP:0.0100\n",
      "Episode:809 meanR:2.2700 R:3.0 loss:0.0568 exploreP:0.0100\n",
      "Episode:810 meanR:2.2300 R:2.0 loss:0.0429 exploreP:0.0100\n",
      "Episode:811 meanR:2.1600 R:2.0 loss:0.0291 exploreP:0.0100\n",
      "Episode:812 meanR:2.1400 R:3.0 loss:0.0515 exploreP:0.0100\n",
      "Episode:813 meanR:2.1600 R:4.0 loss:0.0462 exploreP:0.0100\n",
      "Episode:814 meanR:2.1400 R:1.0 loss:0.0594 exploreP:0.0100\n",
      "Episode:815 meanR:2.1700 R:5.0 loss:0.0686 exploreP:0.0100\n",
      "Episode:816 meanR:2.1600 R:2.0 loss:0.0525 exploreP:0.0100\n",
      "Episode:817 meanR:2.1800 R:3.0 loss:0.0446 exploreP:0.0100\n",
      "Episode:818 meanR:2.2100 R:3.0 loss:0.0690 exploreP:0.0100\n",
      "Episode:819 meanR:2.2200 R:1.0 loss:0.0705 exploreP:0.0100\n",
      "Episode:820 meanR:2.2400 R:2.0 loss:0.0354 exploreP:0.0100\n",
      "Episode:821 meanR:2.2700 R:3.0 loss:0.0276 exploreP:0.0100\n",
      "Episode:822 meanR:2.3200 R:4.0 loss:0.0369 exploreP:0.0100\n",
      "Episode:823 meanR:2.3100 R:0.0 loss:0.0201 exploreP:0.0100\n",
      "Episode:824 meanR:2.3700 R:8.0 loss:0.0246 exploreP:0.0100\n",
      "Episode:825 meanR:2.4300 R:6.0 loss:0.0779 exploreP:0.0100\n",
      "Episode:826 meanR:2.4300 R:1.0 loss:0.0490 exploreP:0.0100\n",
      "Episode:827 meanR:2.4700 R:4.0 loss:0.0461 exploreP:0.0100\n",
      "Episode:828 meanR:2.4500 R:-2.0 loss:0.0763 exploreP:0.0100\n",
      "Episode:829 meanR:2.4300 R:-1.0 loss:0.0363 exploreP:0.0100\n",
      "Episode:830 meanR:2.4400 R:2.0 loss:0.0315 exploreP:0.0100\n",
      "Episode:831 meanR:2.4400 R:2.0 loss:0.0295 exploreP:0.0100\n",
      "Episode:832 meanR:2.4000 R:4.0 loss:0.0235 exploreP:0.0100\n",
      "Episode:833 meanR:2.3800 R:0.0 loss:0.0268 exploreP:0.0100\n",
      "Episode:834 meanR:2.4500 R:11.0 loss:0.0434 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:835 meanR:2.5000 R:4.0 loss:0.0676 exploreP:0.0100\n",
      "Episode:836 meanR:2.5100 R:0.0 loss:0.0460 exploreP:0.0100\n",
      "Episode:837 meanR:2.5300 R:5.0 loss:0.0520 exploreP:0.0100\n",
      "Episode:838 meanR:2.6100 R:9.0 loss:0.0708 exploreP:0.0100\n",
      "Episode:839 meanR:2.7100 R:7.0 loss:0.1382 exploreP:0.0100\n",
      "Episode:840 meanR:2.7800 R:5.0 loss:0.1435 exploreP:0.0100\n",
      "Episode:841 meanR:2.7600 R:1.0 loss:0.0723 exploreP:0.0100\n",
      "Episode:842 meanR:2.8100 R:5.0 loss:0.0619 exploreP:0.0100\n",
      "Episode:843 meanR:2.8500 R:2.0 loss:0.0333 exploreP:0.0100\n",
      "Episode:844 meanR:2.9100 R:1.0 loss:0.0319 exploreP:0.0100\n",
      "Episode:845 meanR:2.9400 R:6.0 loss:0.0295 exploreP:0.0100\n",
      "Episode:846 meanR:2.8900 R:1.0 loss:0.0321 exploreP:0.0100\n",
      "Episode:847 meanR:2.8200 R:0.0 loss:0.0401 exploreP:0.0100\n",
      "Episode:848 meanR:2.8400 R:7.0 loss:0.0270 exploreP:0.0100\n",
      "Episode:849 meanR:2.8800 R:5.0 loss:0.0625 exploreP:0.0100\n",
      "Episode:850 meanR:2.8900 R:8.0 loss:0.1182 exploreP:0.0100\n",
      "Episode:851 meanR:2.8200 R:0.0 loss:0.0980 exploreP:0.0100\n",
      "Episode:852 meanR:2.8200 R:6.0 loss:0.0720 exploreP:0.0100\n",
      "Episode:853 meanR:2.8700 R:6.0 loss:0.0982 exploreP:0.0100\n",
      "Episode:854 meanR:2.9100 R:6.0 loss:0.0639 exploreP:0.0100\n",
      "Episode:855 meanR:2.9400 R:8.0 loss:0.0910 exploreP:0.0100\n",
      "Episode:856 meanR:2.9900 R:8.0 loss:0.0579 exploreP:0.0100\n",
      "Episode:857 meanR:3.0100 R:4.0 loss:0.0715 exploreP:0.0100\n",
      "Episode:858 meanR:3.0100 R:4.0 loss:0.0581 exploreP:0.0100\n",
      "Episode:859 meanR:3.0700 R:5.0 loss:0.0782 exploreP:0.0100\n",
      "Episode:860 meanR:3.0700 R:2.0 loss:0.0710 exploreP:0.0100\n",
      "Episode:861 meanR:3.1000 R:2.0 loss:0.0549 exploreP:0.0100\n",
      "Episode:862 meanR:3.1000 R:1.0 loss:0.0341 exploreP:0.0100\n",
      "Episode:863 meanR:3.1300 R:5.0 loss:0.0509 exploreP:0.0100\n",
      "Episode:864 meanR:3.1500 R:4.0 loss:0.0587 exploreP:0.0100\n",
      "Episode:865 meanR:3.1700 R:3.0 loss:0.0620 exploreP:0.0100\n",
      "Episode:866 meanR:3.2400 R:8.0 loss:0.0806 exploreP:0.0100\n",
      "Episode:867 meanR:3.2600 R:5.0 loss:0.0985 exploreP:0.0100\n",
      "Episode:868 meanR:3.3100 R:7.0 loss:0.1403 exploreP:0.0100\n",
      "Episode:869 meanR:3.2700 R:2.0 loss:0.1155 exploreP:0.0100\n",
      "Episode:870 meanR:3.2700 R:1.0 loss:0.0736 exploreP:0.0100\n",
      "Episode:871 meanR:3.2600 R:2.0 loss:0.0646 exploreP:0.0100\n",
      "Episode:872 meanR:3.3100 R:3.0 loss:0.0223 exploreP:0.0100\n",
      "Episode:873 meanR:3.3000 R:0.0 loss:0.0242 exploreP:0.0100\n",
      "Episode:874 meanR:3.2800 R:1.0 loss:0.0205 exploreP:0.0100\n",
      "Episode:875 meanR:3.2700 R:0.0 loss:0.0166 exploreP:0.0100\n",
      "Episode:876 meanR:3.2200 R:-1.0 loss:0.0158 exploreP:0.0100\n",
      "Episode:877 meanR:3.2200 R:1.0 loss:0.0287 exploreP:0.0100\n",
      "Episode:878 meanR:3.1500 R:-2.0 loss:0.0201 exploreP:0.0100\n",
      "Episode:879 meanR:3.1300 R:2.0 loss:0.0314 exploreP:0.0100\n",
      "Episode:880 meanR:3.1000 R:1.0 loss:0.0112 exploreP:0.0100\n",
      "Episode:881 meanR:3.0800 R:1.0 loss:0.0201 exploreP:0.0100\n",
      "Episode:882 meanR:3.0200 R:1.0 loss:0.0212 exploreP:0.0100\n",
      "Episode:883 meanR:3.0100 R:-1.0 loss:0.0135 exploreP:0.0100\n",
      "Episode:884 meanR:3.0000 R:3.0 loss:0.0175 exploreP:0.0100\n",
      "Episode:885 meanR:3.0000 R:2.0 loss:0.0365 exploreP:0.0100\n",
      "Episode:886 meanR:3.0200 R:3.0 loss:0.0345 exploreP:0.0100\n",
      "Episode:887 meanR:3.0200 R:0.0 loss:0.0301 exploreP:0.0100\n",
      "Episode:888 meanR:3.0400 R:3.0 loss:0.0208 exploreP:0.0100\n",
      "Episode:889 meanR:3.0000 R:-1.0 loss:0.0210 exploreP:0.0100\n",
      "Episode:890 meanR:3.0300 R:4.0 loss:0.0199 exploreP:0.0100\n",
      "Episode:891 meanR:3.0200 R:-1.0 loss:0.0360 exploreP:0.0100\n",
      "Episode:892 meanR:3.0400 R:2.0 loss:0.0198 exploreP:0.0100\n",
      "Episode:893 meanR:3.0600 R:3.0 loss:0.0254 exploreP:0.0100\n",
      "Episode:894 meanR:3.0100 R:4.0 loss:0.0629 exploreP:0.0100\n",
      "Episode:895 meanR:3.0200 R:3.0 loss:0.0630 exploreP:0.0100\n",
      "Episode:896 meanR:2.9500 R:-3.0 loss:0.0513 exploreP:0.0100\n",
      "Episode:897 meanR:2.9100 R:2.0 loss:0.0299 exploreP:0.0100\n",
      "Episode:898 meanR:2.9100 R:4.0 loss:0.0385 exploreP:0.0100\n",
      "Episode:899 meanR:2.9000 R:1.0 loss:0.0487 exploreP:0.0100\n",
      "Episode:900 meanR:2.9300 R:5.0 loss:0.0460 exploreP:0.0100\n",
      "Episode:901 meanR:2.9200 R:4.0 loss:0.0488 exploreP:0.0100\n",
      "Episode:902 meanR:2.9200 R:2.0 loss:0.0411 exploreP:0.0100\n",
      "Episode:903 meanR:2.9500 R:7.0 loss:0.0780 exploreP:0.0100\n",
      "Episode:904 meanR:2.9500 R:2.0 loss:0.0727 exploreP:0.0100\n",
      "Episode:905 meanR:2.9300 R:2.0 loss:0.0364 exploreP:0.0100\n",
      "Episode:906 meanR:2.9200 R:3.0 loss:0.0456 exploreP:0.0100\n",
      "Episode:907 meanR:2.9700 R:5.0 loss:0.0580 exploreP:0.0100\n",
      "Episode:908 meanR:2.9400 R:1.0 loss:0.0530 exploreP:0.0100\n",
      "Episode:909 meanR:2.9300 R:2.0 loss:0.0847 exploreP:0.0100\n",
      "Episode:910 meanR:2.9000 R:-1.0 loss:0.0348 exploreP:0.0100\n",
      "Episode:911 meanR:2.8800 R:0.0 loss:0.0227 exploreP:0.0100\n",
      "Episode:912 meanR:2.8500 R:0.0 loss:0.0097 exploreP:0.0100\n",
      "Episode:913 meanR:2.8300 R:2.0 loss:0.0287 exploreP:0.0100\n",
      "Episode:914 meanR:2.8300 R:1.0 loss:0.0562 exploreP:0.0100\n",
      "Episode:915 meanR:2.7800 R:0.0 loss:0.0246 exploreP:0.0100\n",
      "Episode:916 meanR:2.7700 R:1.0 loss:0.0369 exploreP:0.0100\n",
      "Episode:917 meanR:2.7500 R:1.0 loss:0.0327 exploreP:0.0100\n",
      "Episode:918 meanR:2.7100 R:-1.0 loss:0.0356 exploreP:0.0100\n",
      "Episode:919 meanR:2.7300 R:3.0 loss:0.0303 exploreP:0.0100\n",
      "Episode:920 meanR:2.7500 R:4.0 loss:0.0388 exploreP:0.0100\n",
      "Episode:921 meanR:2.7500 R:3.0 loss:0.0308 exploreP:0.0100\n",
      "Episode:922 meanR:2.7600 R:5.0 loss:0.0443 exploreP:0.0100\n",
      "Episode:923 meanR:2.8300 R:7.0 loss:0.0630 exploreP:0.0100\n",
      "Episode:924 meanR:2.8400 R:9.0 loss:0.0568 exploreP:0.0100\n",
      "Episode:925 meanR:2.7800 R:0.0 loss:0.0450 exploreP:0.0100\n",
      "Episode:926 meanR:2.8200 R:5.0 loss:0.0704 exploreP:0.0100\n",
      "Episode:927 meanR:2.8200 R:4.0 loss:0.0661 exploreP:0.0100\n",
      "Episode:928 meanR:2.9300 R:9.0 loss:0.0676 exploreP:0.0100\n",
      "Episode:929 meanR:3.0200 R:8.0 loss:0.0793 exploreP:0.0100\n",
      "Episode:930 meanR:3.0100 R:1.0 loss:0.0933 exploreP:0.0100\n",
      "Episode:931 meanR:3.0500 R:6.0 loss:0.0690 exploreP:0.0100\n",
      "Episode:932 meanR:3.0100 R:0.0 loss:0.0557 exploreP:0.0100\n",
      "Episode:933 meanR:3.0100 R:0.0 loss:0.0243 exploreP:0.0100\n",
      "Episode:934 meanR:2.8600 R:-4.0 loss:0.0276 exploreP:0.0100\n",
      "Episode:935 meanR:2.8800 R:6.0 loss:0.0509 exploreP:0.0100\n",
      "Episode:936 meanR:2.9000 R:2.0 loss:0.0755 exploreP:0.0100\n",
      "Episode:937 meanR:2.8600 R:1.0 loss:0.0756 exploreP:0.0100\n",
      "Episode:938 meanR:2.9000 R:13.0 loss:0.0549 exploreP:0.0100\n",
      "Episode:939 meanR:2.8800 R:5.0 loss:0.0968 exploreP:0.0100\n",
      "Episode:940 meanR:2.9300 R:10.0 loss:0.0925 exploreP:0.0100\n",
      "Episode:941 meanR:3.0000 R:8.0 loss:0.1125 exploreP:0.0100\n",
      "Episode:942 meanR:3.0700 R:12.0 loss:0.1058 exploreP:0.0100\n",
      "Episode:943 meanR:3.1200 R:7.0 loss:0.1140 exploreP:0.0100\n",
      "Episode:944 meanR:3.2200 R:11.0 loss:0.1235 exploreP:0.0100\n",
      "Episode:945 meanR:3.1800 R:2.0 loss:0.1208 exploreP:0.0100\n",
      "Episode:946 meanR:3.1700 R:0.0 loss:0.0906 exploreP:0.0100\n",
      "Episode:947 meanR:3.1800 R:1.0 loss:0.0881 exploreP:0.0100\n",
      "Episode:948 meanR:3.1400 R:3.0 loss:0.0520 exploreP:0.0100\n",
      "Episode:949 meanR:3.1500 R:6.0 loss:0.0623 exploreP:0.0100\n",
      "Episode:950 meanR:3.1200 R:5.0 loss:0.0637 exploreP:0.0100\n",
      "Episode:951 meanR:3.1600 R:4.0 loss:0.0786 exploreP:0.0100\n",
      "Episode:952 meanR:3.1700 R:7.0 loss:0.0904 exploreP:0.0100\n",
      "Episode:953 meanR:3.1400 R:3.0 loss:0.0893 exploreP:0.0100\n",
      "Episode:954 meanR:3.1200 R:4.0 loss:0.0877 exploreP:0.0100\n",
      "Episode:955 meanR:3.0600 R:2.0 loss:0.0662 exploreP:0.0100\n",
      "Episode:956 meanR:3.0400 R:6.0 loss:0.0616 exploreP:0.0100\n",
      "Episode:957 meanR:3.0700 R:7.0 loss:0.0931 exploreP:0.0100\n",
      "Episode:958 meanR:3.0200 R:-1.0 loss:0.0740 exploreP:0.0100\n",
      "Episode:959 meanR:3.0100 R:4.0 loss:0.0458 exploreP:0.0100\n",
      "Episode:960 meanR:3.0200 R:3.0 loss:0.0498 exploreP:0.0100\n",
      "Episode:961 meanR:3.0400 R:4.0 loss:0.0614 exploreP:0.0100\n",
      "Episode:962 meanR:3.1000 R:7.0 loss:0.0621 exploreP:0.0100\n",
      "Episode:963 meanR:3.0600 R:1.0 loss:0.0731 exploreP:0.0100\n",
      "Episode:964 meanR:3.0200 R:0.0 loss:0.0629 exploreP:0.0100\n",
      "Episode:965 meanR:3.0400 R:5.0 loss:0.0621 exploreP:0.0100\n",
      "Episode:966 meanR:2.9800 R:2.0 loss:0.0455 exploreP:0.0100\n",
      "Episode:967 meanR:3.0500 R:12.0 loss:0.0538 exploreP:0.0100\n",
      "Episode:968 meanR:3.0400 R:6.0 loss:0.1019 exploreP:0.0100\n",
      "Episode:969 meanR:3.0500 R:3.0 loss:0.1300 exploreP:0.0100\n",
      "Episode:970 meanR:3.0600 R:2.0 loss:0.0989 exploreP:0.0100\n",
      "Episode:971 meanR:3.1000 R:6.0 loss:0.0729 exploreP:0.0100\n",
      "Episode:972 meanR:3.0800 R:1.0 loss:0.1360 exploreP:0.0100\n",
      "Episode:973 meanR:3.1000 R:2.0 loss:0.0451 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:974 meanR:3.1200 R:3.0 loss:0.0356 exploreP:0.0100\n",
      "Episode:975 meanR:3.1900 R:7.0 loss:0.0602 exploreP:0.0100\n",
      "Episode:976 meanR:3.2600 R:6.0 loss:0.0949 exploreP:0.0100\n",
      "Episode:977 meanR:3.2800 R:3.0 loss:0.1084 exploreP:0.0100\n",
      "Episode:978 meanR:3.3700 R:7.0 loss:0.1591 exploreP:0.0100\n",
      "Episode:979 meanR:3.3700 R:2.0 loss:0.1353 exploreP:0.0100\n",
      "Episode:980 meanR:3.3800 R:2.0 loss:0.0566 exploreP:0.0100\n",
      "Episode:981 meanR:3.4200 R:5.0 loss:0.0776 exploreP:0.0100\n",
      "Episode:982 meanR:3.4800 R:7.0 loss:0.0765 exploreP:0.0100\n",
      "Episode:983 meanR:3.5100 R:2.0 loss:0.0618 exploreP:0.0100\n",
      "Episode:984 meanR:3.4900 R:1.0 loss:0.0259 exploreP:0.0100\n",
      "Episode:985 meanR:3.5000 R:3.0 loss:0.0423 exploreP:0.0100\n",
      "Episode:986 meanR:3.4900 R:2.0 loss:0.0699 exploreP:0.0100\n",
      "Episode:987 meanR:3.5000 R:1.0 loss:0.0314 exploreP:0.0100\n",
      "Episode:988 meanR:3.4800 R:1.0 loss:0.0235 exploreP:0.0100\n",
      "Episode:989 meanR:3.4800 R:-1.0 loss:0.0270 exploreP:0.0100\n",
      "Episode:990 meanR:3.4500 R:1.0 loss:0.0251 exploreP:0.0100\n",
      "Episode:991 meanR:3.4800 R:2.0 loss:0.0446 exploreP:0.0100\n",
      "Episode:992 meanR:3.4700 R:1.0 loss:0.0349 exploreP:0.0100\n",
      "Episode:993 meanR:3.4700 R:3.0 loss:0.0410 exploreP:0.0100\n",
      "Episode:994 meanR:3.4300 R:0.0 loss:0.0324 exploreP:0.0100\n",
      "Episode:995 meanR:3.4000 R:0.0 loss:0.0355 exploreP:0.0100\n",
      "Episode:996 meanR:3.4900 R:6.0 loss:0.0301 exploreP:0.0100\n",
      "Episode:997 meanR:3.4800 R:1.0 loss:0.0402 exploreP:0.0100\n",
      "Episode:998 meanR:3.4500 R:1.0 loss:0.0210 exploreP:0.0100\n",
      "Episode:999 meanR:3.4800 R:4.0 loss:0.0344 exploreP:0.0100\n",
      "Episode:1000 meanR:3.5000 R:7.0 loss:0.0328 exploreP:0.0100\n",
      "Episode:1001 meanR:3.5600 R:10.0 loss:0.0855 exploreP:0.0100\n",
      "Episode:1002 meanR:3.6100 R:7.0 loss:0.0693 exploreP:0.0100\n",
      "Episode:1003 meanR:3.5500 R:1.0 loss:0.0683 exploreP:0.0100\n",
      "Episode:1004 meanR:3.5600 R:3.0 loss:0.0457 exploreP:0.0100\n",
      "Episode:1005 meanR:3.6000 R:6.0 loss:0.0367 exploreP:0.0100\n",
      "Episode:1006 meanR:3.6500 R:8.0 loss:0.0626 exploreP:0.0100\n",
      "Episode:1007 meanR:3.6300 R:3.0 loss:0.1240 exploreP:0.0100\n",
      "Episode:1008 meanR:3.6700 R:5.0 loss:0.1004 exploreP:0.0100\n",
      "Episode:1009 meanR:3.7300 R:8.0 loss:0.1087 exploreP:0.0100\n",
      "Episode:1010 meanR:3.7700 R:3.0 loss:0.0565 exploreP:0.0100\n",
      "Episode:1011 meanR:3.7900 R:2.0 loss:0.0814 exploreP:0.0100\n",
      "Episode:1012 meanR:3.8500 R:6.0 loss:0.0613 exploreP:0.0100\n",
      "Episode:1013 meanR:3.8600 R:3.0 loss:0.0831 exploreP:0.0100\n",
      "Episode:1014 meanR:3.8800 R:3.0 loss:0.0407 exploreP:0.0100\n",
      "Episode:1015 meanR:3.9100 R:3.0 loss:0.0463 exploreP:0.0100\n",
      "Episode:1016 meanR:3.9600 R:6.0 loss:0.0465 exploreP:0.0100\n",
      "Episode:1017 meanR:3.9600 R:1.0 loss:0.0652 exploreP:0.0100\n",
      "Episode:1018 meanR:4.0000 R:3.0 loss:0.0267 exploreP:0.0100\n",
      "Episode:1019 meanR:4.1000 R:13.0 loss:0.0729 exploreP:0.0100\n",
      "Episode:1020 meanR:4.1300 R:7.0 loss:0.1039 exploreP:0.0100\n",
      "Episode:1021 meanR:4.1300 R:3.0 loss:0.0695 exploreP:0.0100\n",
      "Episode:1022 meanR:4.1200 R:4.0 loss:0.0755 exploreP:0.0100\n",
      "Episode:1023 meanR:4.0500 R:0.0 loss:0.0469 exploreP:0.0100\n",
      "Episode:1024 meanR:3.9900 R:3.0 loss:0.0582 exploreP:0.0100\n",
      "Episode:1025 meanR:3.9900 R:0.0 loss:0.0649 exploreP:0.0100\n",
      "Episode:1026 meanR:3.9500 R:1.0 loss:0.0461 exploreP:0.0100\n",
      "Episode:1027 meanR:3.9300 R:2.0 loss:0.0482 exploreP:0.0100\n",
      "Episode:1028 meanR:3.8600 R:2.0 loss:0.0560 exploreP:0.0100\n",
      "Episode:1029 meanR:3.8100 R:3.0 loss:0.0626 exploreP:0.0100\n",
      "Episode:1030 meanR:3.8800 R:8.0 loss:0.0661 exploreP:0.0100\n",
      "Episode:1031 meanR:3.9200 R:10.0 loss:0.0822 exploreP:0.0100\n",
      "Episode:1032 meanR:4.0000 R:8.0 loss:0.0613 exploreP:0.0100\n",
      "Episode:1033 meanR:4.0400 R:4.0 loss:0.0930 exploreP:0.0100\n",
      "Episode:1034 meanR:4.1300 R:5.0 loss:0.0817 exploreP:0.0100\n",
      "Episode:1035 meanR:4.0900 R:2.0 loss:0.0801 exploreP:0.0100\n",
      "Episode:1036 meanR:4.0800 R:1.0 loss:0.0384 exploreP:0.0100\n",
      "Episode:1037 meanR:4.0900 R:2.0 loss:0.0238 exploreP:0.0100\n",
      "Episode:1038 meanR:3.9400 R:-2.0 loss:0.0175 exploreP:0.0100\n",
      "Episode:1039 meanR:3.9000 R:1.0 loss:0.0327 exploreP:0.0100\n",
      "Episode:1040 meanR:3.7900 R:-1.0 loss:0.0121 exploreP:0.0100\n",
      "Episode:1041 meanR:3.7200 R:1.0 loss:0.0163 exploreP:0.0100\n",
      "Episode:1042 meanR:3.6000 R:0.0 loss:0.0214 exploreP:0.0100\n",
      "Episode:1043 meanR:3.5600 R:3.0 loss:0.0230 exploreP:0.0100\n",
      "Episode:1044 meanR:3.4600 R:1.0 loss:0.0309 exploreP:0.0100\n",
      "Episode:1045 meanR:3.4600 R:2.0 loss:0.0175 exploreP:0.0100\n",
      "Episode:1046 meanR:3.4800 R:2.0 loss:0.0215 exploreP:0.0100\n",
      "Episode:1047 meanR:3.5600 R:9.0 loss:0.0531 exploreP:0.0100\n",
      "Episode:1048 meanR:3.6100 R:8.0 loss:0.0733 exploreP:0.0100\n",
      "Episode:1049 meanR:3.5600 R:1.0 loss:0.0786 exploreP:0.0100\n",
      "Episode:1050 meanR:3.5200 R:1.0 loss:0.0680 exploreP:0.0100\n",
      "Episode:1051 meanR:3.5300 R:5.0 loss:0.0624 exploreP:0.0100\n",
      "Episode:1052 meanR:3.5000 R:4.0 loss:0.0582 exploreP:0.0100\n",
      "Episode:1053 meanR:3.5100 R:4.0 loss:0.0656 exploreP:0.0100\n",
      "Episode:1054 meanR:3.5100 R:4.0 loss:0.0443 exploreP:0.0100\n",
      "Episode:1055 meanR:3.5200 R:3.0 loss:0.0732 exploreP:0.0100\n",
      "Episode:1056 meanR:3.5600 R:10.0 loss:0.0626 exploreP:0.0100\n",
      "Episode:1057 meanR:3.5400 R:5.0 loss:0.0860 exploreP:0.0100\n",
      "Episode:1058 meanR:3.6300 R:8.0 loss:0.1254 exploreP:0.0100\n",
      "Episode:1059 meanR:3.6500 R:6.0 loss:0.1110 exploreP:0.0100\n",
      "Episode:1060 meanR:3.6200 R:0.0 loss:0.0932 exploreP:0.0100\n",
      "Episode:1061 meanR:3.5700 R:-1.0 loss:0.0649 exploreP:0.0100\n",
      "Episode:1062 meanR:3.5500 R:5.0 loss:0.0513 exploreP:0.0100\n",
      "Episode:1063 meanR:3.5600 R:2.0 loss:0.0627 exploreP:0.0100\n",
      "Episode:1064 meanR:3.5800 R:2.0 loss:0.0510 exploreP:0.0100\n",
      "Episode:1065 meanR:3.5800 R:5.0 loss:0.0423 exploreP:0.0100\n",
      "Episode:1066 meanR:3.5600 R:0.0 loss:0.0463 exploreP:0.0100\n",
      "Episode:1067 meanR:3.4600 R:2.0 loss:0.0359 exploreP:0.0100\n",
      "Episode:1068 meanR:3.4000 R:0.0 loss:0.0251 exploreP:0.0100\n",
      "Episode:1069 meanR:3.3900 R:2.0 loss:0.0389 exploreP:0.0100\n",
      "Episode:1070 meanR:3.3700 R:0.0 loss:0.0256 exploreP:0.0100\n",
      "Episode:1071 meanR:3.2900 R:-2.0 loss:0.0189 exploreP:0.0100\n",
      "Episode:1072 meanR:3.3000 R:2.0 loss:0.0208 exploreP:0.0100\n",
      "Episode:1073 meanR:3.3400 R:6.0 loss:0.0484 exploreP:0.0100\n",
      "Episode:1074 meanR:3.3200 R:1.0 loss:0.0451 exploreP:0.0100\n",
      "Episode:1075 meanR:3.2500 R:0.0 loss:0.0194 exploreP:0.0100\n",
      "Episode:1076 meanR:3.2200 R:3.0 loss:0.0222 exploreP:0.0100\n",
      "Episode:1077 meanR:3.2000 R:1.0 loss:0.0411 exploreP:0.0100\n",
      "Episode:1078 meanR:3.1500 R:2.0 loss:0.0394 exploreP:0.0100\n",
      "Episode:1079 meanR:3.1500 R:2.0 loss:0.0262 exploreP:0.0100\n",
      "Episode:1080 meanR:3.1200 R:-1.0 loss:0.0146 exploreP:0.0100\n",
      "Episode:1081 meanR:3.0700 R:0.0 loss:0.0153 exploreP:0.0100\n",
      "Episode:1082 meanR:2.9900 R:-1.0 loss:0.0273 exploreP:0.0100\n",
      "Episode:1083 meanR:3.0000 R:3.0 loss:0.0158 exploreP:0.0100\n",
      "Episode:1084 meanR:2.9900 R:0.0 loss:0.0303 exploreP:0.0100\n",
      "Episode:1085 meanR:2.9900 R:3.0 loss:0.0352 exploreP:0.0100\n",
      "Episode:1086 meanR:3.0000 R:3.0 loss:0.0385 exploreP:0.0100\n",
      "Episode:1087 meanR:3.0200 R:3.0 loss:0.0434 exploreP:0.0100\n",
      "Episode:1088 meanR:3.0100 R:0.0 loss:0.0247 exploreP:0.0100\n",
      "Episode:1089 meanR:3.0200 R:0.0 loss:0.0155 exploreP:0.0100\n",
      "Episode:1090 meanR:2.9900 R:-2.0 loss:0.0158 exploreP:0.0100\n",
      "Episode:1091 meanR:2.9900 R:2.0 loss:0.0147 exploreP:0.0100\n",
      "Episode:1092 meanR:3.0000 R:2.0 loss:0.0210 exploreP:0.0100\n",
      "Episode:1093 meanR:2.9900 R:2.0 loss:0.0231 exploreP:0.0100\n",
      "Episode:1094 meanR:3.0000 R:1.0 loss:0.0178 exploreP:0.0100\n",
      "Episode:1095 meanR:3.0200 R:2.0 loss:0.0252 exploreP:0.0100\n",
      "Episode:1096 meanR:3.0300 R:7.0 loss:0.0376 exploreP:0.0100\n",
      "Episode:1097 meanR:3.0500 R:3.0 loss:0.0497 exploreP:0.0100\n",
      "Episode:1098 meanR:3.1100 R:7.0 loss:0.0593 exploreP:0.0100\n",
      "Episode:1099 meanR:3.1500 R:8.0 loss:0.0776 exploreP:0.0100\n",
      "Episode:1100 meanR:3.1400 R:6.0 loss:0.0917 exploreP:0.0100\n",
      "Episode:1101 meanR:3.0600 R:2.0 loss:0.0671 exploreP:0.0100\n",
      "Episode:1102 meanR:3.0400 R:5.0 loss:0.0488 exploreP:0.0100\n",
      "Episode:1103 meanR:3.1000 R:7.0 loss:0.0710 exploreP:0.0100\n",
      "Episode:1104 meanR:3.1100 R:4.0 loss:0.0607 exploreP:0.0100\n",
      "Episode:1105 meanR:3.1200 R:7.0 loss:0.0639 exploreP:0.0100\n",
      "Episode:1106 meanR:3.0900 R:5.0 loss:0.0619 exploreP:0.0100\n",
      "Episode:1107 meanR:3.0800 R:2.0 loss:0.0330 exploreP:0.0100\n",
      "Episode:1108 meanR:3.1100 R:8.0 loss:0.0868 exploreP:0.0100\n",
      "Episode:1109 meanR:3.1000 R:7.0 loss:0.0551 exploreP:0.0100\n",
      "Episode:1110 meanR:3.1500 R:8.0 loss:0.1189 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1111 meanR:3.1800 R:5.0 loss:0.0979 exploreP:0.0100\n",
      "Episode:1112 meanR:3.1900 R:7.0 loss:0.1016 exploreP:0.0100\n",
      "Episode:1113 meanR:3.2200 R:6.0 loss:0.1114 exploreP:0.0100\n",
      "Episode:1114 meanR:3.2600 R:7.0 loss:0.0752 exploreP:0.0100\n",
      "Episode:1115 meanR:3.2700 R:4.0 loss:0.0704 exploreP:0.0100\n",
      "Episode:1116 meanR:3.2700 R:6.0 loss:0.0477 exploreP:0.0100\n",
      "Episode:1117 meanR:3.3400 R:8.0 loss:0.0734 exploreP:0.0100\n",
      "Episode:1118 meanR:3.3600 R:5.0 loss:0.0786 exploreP:0.0100\n",
      "Episode:1119 meanR:3.2400 R:1.0 loss:0.0406 exploreP:0.0100\n",
      "Episode:1120 meanR:3.2000 R:3.0 loss:0.0546 exploreP:0.0100\n",
      "Episode:1121 meanR:3.1800 R:1.0 loss:0.0257 exploreP:0.0100\n",
      "Episode:1122 meanR:3.1700 R:3.0 loss:0.0506 exploreP:0.0100\n",
      "Episode:1123 meanR:3.2300 R:6.0 loss:0.0492 exploreP:0.0100\n",
      "Episode:1124 meanR:3.3100 R:11.0 loss:0.0570 exploreP:0.0100\n",
      "Episode:1125 meanR:3.3300 R:2.0 loss:0.0746 exploreP:0.0100\n",
      "Episode:1126 meanR:3.3700 R:5.0 loss:0.0835 exploreP:0.0100\n",
      "Episode:1127 meanR:3.4000 R:5.0 loss:0.0553 exploreP:0.0100\n",
      "Episode:1128 meanR:3.4200 R:4.0 loss:0.0680 exploreP:0.0100\n",
      "Episode:1129 meanR:3.4100 R:2.0 loss:0.0519 exploreP:0.0100\n",
      "Episode:1130 meanR:3.4000 R:7.0 loss:0.0688 exploreP:0.0100\n",
      "Episode:1131 meanR:3.3400 R:4.0 loss:0.0395 exploreP:0.0100\n",
      "Episode:1132 meanR:3.3200 R:6.0 loss:0.0718 exploreP:0.0100\n",
      "Episode:1133 meanR:3.2800 R:0.0 loss:0.0334 exploreP:0.0100\n",
      "Episode:1134 meanR:3.3300 R:10.0 loss:0.0578 exploreP:0.0100\n",
      "Episode:1135 meanR:3.3200 R:1.0 loss:0.0932 exploreP:0.0100\n",
      "Episode:1136 meanR:3.4000 R:9.0 loss:0.0594 exploreP:0.0100\n",
      "Episode:1137 meanR:3.3900 R:1.0 loss:0.0684 exploreP:0.0100\n",
      "Episode:1138 meanR:3.4100 R:0.0 loss:0.0782 exploreP:0.0100\n",
      "Episode:1139 meanR:3.4500 R:5.0 loss:0.0628 exploreP:0.0100\n",
      "Episode:1140 meanR:3.4800 R:2.0 loss:0.0686 exploreP:0.0100\n",
      "Episode:1141 meanR:3.4800 R:1.0 loss:0.0448 exploreP:0.0100\n",
      "Episode:1142 meanR:3.5100 R:3.0 loss:0.0403 exploreP:0.0100\n",
      "Episode:1143 meanR:3.5000 R:2.0 loss:0.0475 exploreP:0.0100\n",
      "Episode:1144 meanR:3.5200 R:3.0 loss:0.0502 exploreP:0.0100\n",
      "Episode:1145 meanR:3.5600 R:6.0 loss:0.0380 exploreP:0.0100\n",
      "Episode:1146 meanR:3.5800 R:4.0 loss:0.0559 exploreP:0.0100\n",
      "Episode:1147 meanR:3.5400 R:5.0 loss:0.0687 exploreP:0.0100\n",
      "Episode:1148 meanR:3.4800 R:2.0 loss:0.0386 exploreP:0.0100\n",
      "Episode:1149 meanR:3.5000 R:3.0 loss:0.0271 exploreP:0.0100\n",
      "Episode:1150 meanR:3.5600 R:7.0 loss:0.0295 exploreP:0.0100\n",
      "Episode:1151 meanR:3.6000 R:9.0 loss:0.0504 exploreP:0.0100\n",
      "Episode:1152 meanR:3.5900 R:3.0 loss:0.0751 exploreP:0.0100\n",
      "Episode:1153 meanR:3.6200 R:7.0 loss:0.0556 exploreP:0.0100\n",
      "Episode:1154 meanR:3.6400 R:6.0 loss:0.0673 exploreP:0.0100\n",
      "Episode:1155 meanR:3.6500 R:4.0 loss:0.0682 exploreP:0.0100\n",
      "Episode:1156 meanR:3.6000 R:5.0 loss:0.0866 exploreP:0.0100\n",
      "Episode:1157 meanR:3.6200 R:7.0 loss:0.0635 exploreP:0.0100\n",
      "Episode:1158 meanR:3.5500 R:1.0 loss:0.0681 exploreP:0.0100\n",
      "Episode:1159 meanR:3.4900 R:0.0 loss:0.0385 exploreP:0.0100\n",
      "Episode:1160 meanR:3.5000 R:1.0 loss:0.0539 exploreP:0.0100\n",
      "Episode:1161 meanR:3.5500 R:4.0 loss:0.0595 exploreP:0.0100\n",
      "Episode:1162 meanR:3.5300 R:3.0 loss:0.0669 exploreP:0.0100\n",
      "Episode:1163 meanR:3.5700 R:6.0 loss:0.0536 exploreP:0.0100\n",
      "Episode:1164 meanR:3.6300 R:8.0 loss:0.0609 exploreP:0.0100\n",
      "Episode:1165 meanR:3.6500 R:7.0 loss:0.0940 exploreP:0.0100\n",
      "Episode:1166 meanR:3.6800 R:3.0 loss:0.0782 exploreP:0.0100\n",
      "Episode:1167 meanR:3.6900 R:3.0 loss:0.0515 exploreP:0.0100\n",
      "Episode:1168 meanR:3.7600 R:7.0 loss:0.0611 exploreP:0.0100\n",
      "Episode:1169 meanR:3.7400 R:0.0 loss:0.0595 exploreP:0.0100\n",
      "Episode:1170 meanR:3.7700 R:3.0 loss:0.0618 exploreP:0.0100\n",
      "Episode:1171 meanR:3.8200 R:3.0 loss:0.0495 exploreP:0.0100\n",
      "Episode:1172 meanR:3.8400 R:4.0 loss:0.0498 exploreP:0.0100\n",
      "Episode:1173 meanR:3.8300 R:5.0 loss:0.0672 exploreP:0.0100\n",
      "Episode:1174 meanR:3.8400 R:2.0 loss:0.0970 exploreP:0.0100\n",
      "Episode:1175 meanR:3.8900 R:5.0 loss:0.0675 exploreP:0.0100\n",
      "Episode:1176 meanR:3.9400 R:8.0 loss:0.0542 exploreP:0.0100\n",
      "Episode:1177 meanR:3.9900 R:6.0 loss:0.0657 exploreP:0.0100\n",
      "Episode:1178 meanR:4.0300 R:6.0 loss:0.0856 exploreP:0.0100\n",
      "Episode:1179 meanR:4.0900 R:8.0 loss:0.0679 exploreP:0.0100\n",
      "Episode:1180 meanR:4.1500 R:5.0 loss:0.0637 exploreP:0.0100\n",
      "Episode:1181 meanR:4.1800 R:3.0 loss:0.0722 exploreP:0.0100\n",
      "Episode:1182 meanR:4.2000 R:1.0 loss:0.0521 exploreP:0.0100\n",
      "Episode:1183 meanR:4.2300 R:6.0 loss:0.0563 exploreP:0.0100\n",
      "Episode:1184 meanR:4.2600 R:3.0 loss:0.0458 exploreP:0.0100\n",
      "Episode:1185 meanR:4.2400 R:1.0 loss:0.0265 exploreP:0.0100\n",
      "Episode:1186 meanR:4.2200 R:1.0 loss:0.0224 exploreP:0.0100\n",
      "Episode:1187 meanR:4.2400 R:5.0 loss:0.0430 exploreP:0.0100\n",
      "Episode:1188 meanR:4.2600 R:2.0 loss:0.0382 exploreP:0.0100\n",
      "Episode:1189 meanR:4.2700 R:1.0 loss:0.0518 exploreP:0.0100\n",
      "Episode:1190 meanR:4.3100 R:2.0 loss:0.0279 exploreP:0.0100\n",
      "Episode:1191 meanR:4.2700 R:-2.0 loss:0.0336 exploreP:0.0100\n",
      "Episode:1192 meanR:4.2500 R:0.0 loss:0.0110 exploreP:0.0100\n",
      "Episode:1193 meanR:4.2500 R:2.0 loss:0.0299 exploreP:0.0100\n",
      "Episode:1194 meanR:4.2700 R:3.0 loss:0.0374 exploreP:0.0100\n",
      "Episode:1195 meanR:4.3000 R:5.0 loss:0.0599 exploreP:0.0100\n",
      "Episode:1196 meanR:4.2900 R:6.0 loss:0.0789 exploreP:0.0100\n",
      "Episode:1197 meanR:4.3600 R:10.0 loss:0.1088 exploreP:0.0100\n",
      "Episode:1198 meanR:4.3800 R:9.0 loss:0.1037 exploreP:0.0100\n",
      "Episode:1199 meanR:4.3200 R:2.0 loss:0.0827 exploreP:0.0100\n",
      "Episode:1200 meanR:4.3200 R:6.0 loss:0.0627 exploreP:0.0100\n",
      "Episode:1201 meanR:4.3100 R:1.0 loss:0.0510 exploreP:0.0100\n",
      "Episode:1202 meanR:4.3000 R:4.0 loss:0.0325 exploreP:0.0100\n",
      "Episode:1203 meanR:4.2400 R:1.0 loss:0.0465 exploreP:0.0100\n",
      "Episode:1204 meanR:4.2100 R:1.0 loss:0.0369 exploreP:0.0100\n",
      "Episode:1205 meanR:4.1500 R:1.0 loss:0.0479 exploreP:0.0100\n",
      "Episode:1206 meanR:4.1000 R:0.0 loss:0.0163 exploreP:0.0100\n",
      "Episode:1207 meanR:4.0900 R:1.0 loss:0.0161 exploreP:0.0100\n",
      "Episode:1208 meanR:4.0300 R:2.0 loss:0.0484 exploreP:0.0100\n",
      "Episode:1209 meanR:4.0400 R:8.0 loss:0.0788 exploreP:0.0100\n",
      "Episode:1210 meanR:4.0300 R:7.0 loss:0.0514 exploreP:0.0100\n",
      "Episode:1211 meanR:4.0100 R:3.0 loss:0.0888 exploreP:0.0100\n",
      "Episode:1212 meanR:3.9500 R:1.0 loss:0.0550 exploreP:0.0100\n",
      "Episode:1213 meanR:3.8900 R:0.0 loss:0.0251 exploreP:0.0100\n",
      "Episode:1214 meanR:3.8300 R:1.0 loss:0.0219 exploreP:0.0100\n",
      "Episode:1215 meanR:3.7900 R:0.0 loss:0.0225 exploreP:0.0100\n",
      "Episode:1216 meanR:3.7100 R:-2.0 loss:0.0183 exploreP:0.0100\n",
      "Episode:1217 meanR:3.6400 R:1.0 loss:0.0275 exploreP:0.0100\n",
      "Episode:1218 meanR:3.6100 R:2.0 loss:0.0158 exploreP:0.0100\n",
      "Episode:1219 meanR:3.6100 R:1.0 loss:0.0182 exploreP:0.0100\n",
      "Episode:1220 meanR:3.5900 R:1.0 loss:0.0223 exploreP:0.0100\n",
      "Episode:1221 meanR:3.6000 R:2.0 loss:0.0457 exploreP:0.0100\n",
      "Episode:1222 meanR:3.5900 R:2.0 loss:0.0242 exploreP:0.0100\n",
      "Episode:1223 meanR:3.5900 R:6.0 loss:0.0469 exploreP:0.0100\n",
      "Episode:1224 meanR:3.4800 R:0.0 loss:0.0423 exploreP:0.0100\n",
      "Episode:1225 meanR:3.4800 R:2.0 loss:0.0333 exploreP:0.0100\n",
      "Episode:1226 meanR:3.4500 R:2.0 loss:0.0401 exploreP:0.0100\n",
      "Episode:1227 meanR:3.3900 R:-1.0 loss:0.0382 exploreP:0.0100\n",
      "Episode:1228 meanR:3.3800 R:3.0 loss:0.0326 exploreP:0.0100\n",
      "Episode:1229 meanR:3.4000 R:4.0 loss:0.0353 exploreP:0.0100\n",
      "Episode:1230 meanR:3.3500 R:2.0 loss:0.0345 exploreP:0.0100\n",
      "Episode:1231 meanR:3.3100 R:0.0 loss:0.0132 exploreP:0.0100\n",
      "Episode:1232 meanR:3.2500 R:0.0 loss:0.0188 exploreP:0.0100\n",
      "Episode:1233 meanR:3.2500 R:0.0 loss:0.0112 exploreP:0.0100\n",
      "Episode:1234 meanR:3.1500 R:0.0 loss:0.0056 exploreP:0.0100\n",
      "Episode:1235 meanR:3.1500 R:1.0 loss:0.0141 exploreP:0.0100\n",
      "Episode:1236 meanR:3.1400 R:8.0 loss:0.0415 exploreP:0.0100\n",
      "Episode:1237 meanR:3.2000 R:7.0 loss:0.0737 exploreP:0.0100\n",
      "Episode:1238 meanR:3.2800 R:8.0 loss:0.1014 exploreP:0.0100\n",
      "Episode:1239 meanR:3.2500 R:2.0 loss:0.0996 exploreP:0.0100\n",
      "Episode:1240 meanR:3.3100 R:8.0 loss:0.0548 exploreP:0.0100\n",
      "Episode:1241 meanR:3.3800 R:8.0 loss:0.0574 exploreP:0.0100\n",
      "Episode:1242 meanR:3.4300 R:8.0 loss:0.0824 exploreP:0.0100\n",
      "Episode:1243 meanR:3.4400 R:3.0 loss:0.0752 exploreP:0.0100\n",
      "Episode:1244 meanR:3.4600 R:5.0 loss:0.0523 exploreP:0.0100\n",
      "Episode:1245 meanR:3.5000 R:10.0 loss:0.0643 exploreP:0.0100\n",
      "Episode:1246 meanR:3.4700 R:1.0 loss:0.0711 exploreP:0.0100\n",
      "Episode:1247 meanR:3.4800 R:6.0 loss:0.0479 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1248 meanR:3.5400 R:8.0 loss:0.0395 exploreP:0.0100\n",
      "Episode:1249 meanR:3.6000 R:9.0 loss:0.0721 exploreP:0.0100\n",
      "Episode:1250 meanR:3.6800 R:15.0 loss:0.0888 exploreP:0.0100\n",
      "Episode:1251 meanR:3.6800 R:9.0 loss:0.1118 exploreP:0.0100\n",
      "Episode:1252 meanR:3.6700 R:2.0 loss:0.1030 exploreP:0.0100\n",
      "Episode:1253 meanR:3.6000 R:0.0 loss:0.0397 exploreP:0.0100\n",
      "Episode:1254 meanR:3.5600 R:2.0 loss:0.0403 exploreP:0.0100\n",
      "Episode:1255 meanR:3.5300 R:1.0 loss:0.0513 exploreP:0.0100\n",
      "Episode:1256 meanR:3.5000 R:2.0 loss:0.0365 exploreP:0.0100\n",
      "Episode:1257 meanR:3.4500 R:2.0 loss:0.0459 exploreP:0.0100\n",
      "Episode:1258 meanR:3.4500 R:1.0 loss:0.0325 exploreP:0.0100\n",
      "Episode:1259 meanR:3.4800 R:3.0 loss:0.0226 exploreP:0.0100\n",
      "Episode:1260 meanR:3.4900 R:2.0 loss:0.0253 exploreP:0.0100\n",
      "Episode:1261 meanR:3.4700 R:2.0 loss:0.0245 exploreP:0.0100\n",
      "Episode:1262 meanR:3.4500 R:1.0 loss:0.0183 exploreP:0.0100\n",
      "Episode:1263 meanR:3.4200 R:3.0 loss:0.0510 exploreP:0.0100\n",
      "Episode:1264 meanR:3.3900 R:5.0 loss:0.0299 exploreP:0.0100\n",
      "Episode:1265 meanR:3.3300 R:1.0 loss:0.0604 exploreP:0.0100\n",
      "Episode:1266 meanR:3.3500 R:5.0 loss:0.0493 exploreP:0.0100\n",
      "Episode:1267 meanR:3.3400 R:2.0 loss:0.0428 exploreP:0.0100\n",
      "Episode:1268 meanR:3.3100 R:4.0 loss:0.0554 exploreP:0.0100\n",
      "Episode:1269 meanR:3.3400 R:3.0 loss:0.0592 exploreP:0.0100\n",
      "Episode:1270 meanR:3.3600 R:5.0 loss:0.0496 exploreP:0.0100\n",
      "Episode:1271 meanR:3.3800 R:5.0 loss:0.0458 exploreP:0.0100\n",
      "Episode:1272 meanR:3.3700 R:3.0 loss:0.0380 exploreP:0.0100\n",
      "Episode:1273 meanR:3.3200 R:0.0 loss:0.0318 exploreP:0.0100\n",
      "Episode:1274 meanR:3.3000 R:0.0 loss:0.0136 exploreP:0.0100\n",
      "Episode:1275 meanR:3.3100 R:6.0 loss:0.0241 exploreP:0.0100\n",
      "Episode:1276 meanR:3.2600 R:3.0 loss:0.0433 exploreP:0.0100\n",
      "Episode:1277 meanR:3.2100 R:1.0 loss:0.0309 exploreP:0.0100\n",
      "Episode:1278 meanR:3.1800 R:3.0 loss:0.0129 exploreP:0.0100\n",
      "Episode:1279 meanR:3.1200 R:2.0 loss:0.0276 exploreP:0.0100\n",
      "Episode:1280 meanR:3.0700 R:0.0 loss:0.0375 exploreP:0.0100\n",
      "Episode:1281 meanR:3.1000 R:6.0 loss:0.0344 exploreP:0.0100\n",
      "Episode:1282 meanR:3.1000 R:1.0 loss:0.0391 exploreP:0.0100\n",
      "Episode:1283 meanR:3.0600 R:2.0 loss:0.0199 exploreP:0.0100\n",
      "Episode:1284 meanR:3.0900 R:6.0 loss:0.0267 exploreP:0.0100\n",
      "Episode:1285 meanR:3.1800 R:10.0 loss:0.0423 exploreP:0.0100\n",
      "Episode:1286 meanR:3.2100 R:4.0 loss:0.0621 exploreP:0.0100\n",
      "Episode:1287 meanR:3.2000 R:4.0 loss:0.0375 exploreP:0.0100\n",
      "Episode:1288 meanR:3.2200 R:4.0 loss:0.0629 exploreP:0.0100\n",
      "Episode:1289 meanR:3.2900 R:8.0 loss:0.0583 exploreP:0.0100\n",
      "Episode:1290 meanR:3.2700 R:0.0 loss:0.0281 exploreP:0.0100\n",
      "Episode:1291 meanR:3.3200 R:3.0 loss:0.0245 exploreP:0.0100\n",
      "Episode:1292 meanR:3.3600 R:4.0 loss:0.0270 exploreP:0.0100\n",
      "Episode:1293 meanR:3.3800 R:4.0 loss:0.0389 exploreP:0.0100\n",
      "Episode:1294 meanR:3.3700 R:2.0 loss:0.0329 exploreP:0.0100\n",
      "Episode:1295 meanR:3.3500 R:3.0 loss:0.0294 exploreP:0.0100\n",
      "Episode:1296 meanR:3.3300 R:4.0 loss:0.0324 exploreP:0.0100\n",
      "Episode:1297 meanR:3.2600 R:3.0 loss:0.0295 exploreP:0.0100\n",
      "Episode:1298 meanR:3.2100 R:4.0 loss:0.0513 exploreP:0.0100\n",
      "Episode:1299 meanR:3.2100 R:2.0 loss:0.0447 exploreP:0.0100\n",
      "Episode:1300 meanR:3.1800 R:3.0 loss:0.0298 exploreP:0.0100\n",
      "Episode:1301 meanR:3.2300 R:6.0 loss:0.0480 exploreP:0.0100\n",
      "Episode:1302 meanR:3.2500 R:6.0 loss:0.0726 exploreP:0.0100\n",
      "Episode:1303 meanR:3.2600 R:2.0 loss:0.0398 exploreP:0.0100\n",
      "Episode:1304 meanR:3.2900 R:4.0 loss:0.0247 exploreP:0.0100\n",
      "Episode:1305 meanR:3.3200 R:4.0 loss:0.0427 exploreP:0.0100\n",
      "Episode:1306 meanR:3.3500 R:3.0 loss:0.0370 exploreP:0.0100\n",
      "Episode:1307 meanR:3.4500 R:11.0 loss:0.0606 exploreP:0.0100\n",
      "Episode:1308 meanR:3.4600 R:3.0 loss:0.0967 exploreP:0.0100\n",
      "Episode:1309 meanR:3.4400 R:6.0 loss:0.0435 exploreP:0.0100\n",
      "Episode:1310 meanR:3.4200 R:5.0 loss:0.0680 exploreP:0.0100\n",
      "Episode:1311 meanR:3.4600 R:7.0 loss:0.0583 exploreP:0.0100\n",
      "Episode:1312 meanR:3.5200 R:7.0 loss:0.0734 exploreP:0.0100\n",
      "Episode:1313 meanR:3.5700 R:5.0 loss:0.0805 exploreP:0.0100\n",
      "Episode:1314 meanR:3.5900 R:3.0 loss:0.0858 exploreP:0.0100\n",
      "Episode:1315 meanR:3.6000 R:1.0 loss:0.0310 exploreP:0.0100\n",
      "Episode:1316 meanR:3.6100 R:-1.0 loss:0.0294 exploreP:0.0100\n",
      "Episode:1317 meanR:3.6100 R:1.0 loss:0.0125 exploreP:0.0100\n",
      "Episode:1318 meanR:3.6000 R:1.0 loss:0.0186 exploreP:0.0100\n",
      "Episode:1319 meanR:3.6200 R:3.0 loss:0.0250 exploreP:0.0100\n",
      "Episode:1320 meanR:3.6000 R:-1.0 loss:0.0258 exploreP:0.0100\n",
      "Episode:1321 meanR:3.5900 R:1.0 loss:0.0338 exploreP:0.0100\n",
      "Episode:1322 meanR:3.6500 R:8.0 loss:0.0530 exploreP:0.0100\n",
      "Episode:1323 meanR:3.5900 R:0.0 loss:0.0274 exploreP:0.0100\n",
      "Episode:1324 meanR:3.6100 R:2.0 loss:0.0310 exploreP:0.0100\n",
      "Episode:1325 meanR:3.6100 R:2.0 loss:0.0494 exploreP:0.0100\n",
      "Episode:1326 meanR:3.6700 R:8.0 loss:0.0545 exploreP:0.0100\n",
      "Episode:1327 meanR:3.7100 R:3.0 loss:0.0770 exploreP:0.0100\n",
      "Episode:1328 meanR:3.7200 R:4.0 loss:0.0574 exploreP:0.0100\n",
      "Episode:1329 meanR:3.7300 R:5.0 loss:0.0550 exploreP:0.0100\n",
      "Episode:1330 meanR:3.7100 R:0.0 loss:0.0243 exploreP:0.0100\n",
      "Episode:1331 meanR:3.7400 R:3.0 loss:0.0250 exploreP:0.0100\n",
      "Episode:1332 meanR:3.7500 R:1.0 loss:0.0221 exploreP:0.0100\n",
      "Episode:1333 meanR:3.8000 R:5.0 loss:0.0436 exploreP:0.0100\n",
      "Episode:1334 meanR:3.8200 R:2.0 loss:0.0295 exploreP:0.0100\n",
      "Episode:1335 meanR:3.8000 R:-1.0 loss:0.0283 exploreP:0.0100\n",
      "Episode:1336 meanR:3.7100 R:-1.0 loss:0.0080 exploreP:0.0100\n",
      "Episode:1337 meanR:3.6600 R:2.0 loss:0.0199 exploreP:0.0100\n",
      "Episode:1338 meanR:3.6000 R:2.0 loss:0.0274 exploreP:0.0100\n",
      "Episode:1339 meanR:3.5900 R:1.0 loss:0.0223 exploreP:0.0100\n",
      "Episode:1340 meanR:3.5300 R:2.0 loss:0.0149 exploreP:0.0100\n",
      "Episode:1341 meanR:3.4800 R:3.0 loss:0.0157 exploreP:0.0100\n",
      "Episode:1342 meanR:3.4500 R:5.0 loss:0.0275 exploreP:0.0100\n",
      "Episode:1343 meanR:3.4300 R:1.0 loss:0.0512 exploreP:0.0100\n",
      "Episode:1344 meanR:3.3800 R:0.0 loss:0.0449 exploreP:0.0100\n",
      "Episode:1345 meanR:3.2800 R:0.0 loss:0.0135 exploreP:0.0100\n",
      "Episode:1346 meanR:3.2900 R:2.0 loss:0.0218 exploreP:0.0100\n",
      "Episode:1347 meanR:3.2600 R:3.0 loss:0.0182 exploreP:0.0100\n",
      "Episode:1348 meanR:3.2000 R:2.0 loss:0.0258 exploreP:0.0100\n",
      "Episode:1349 meanR:3.1400 R:3.0 loss:0.0320 exploreP:0.0100\n",
      "Episode:1350 meanR:2.9800 R:-1.0 loss:0.0110 exploreP:0.0100\n",
      "Episode:1351 meanR:2.8900 R:0.0 loss:0.0111 exploreP:0.0100\n",
      "Episode:1352 meanR:2.8700 R:0.0 loss:0.0125 exploreP:0.0100\n",
      "Episode:1353 meanR:2.8900 R:2.0 loss:0.0291 exploreP:0.0100\n",
      "Episode:1354 meanR:2.8700 R:0.0 loss:0.0331 exploreP:0.0100\n",
      "Episode:1355 meanR:2.8700 R:1.0 loss:0.0166 exploreP:0.0100\n",
      "Episode:1356 meanR:2.8600 R:1.0 loss:0.0148 exploreP:0.0100\n",
      "Episode:1357 meanR:2.8400 R:0.0 loss:0.0062 exploreP:0.0100\n",
      "Episode:1358 meanR:2.8400 R:1.0 loss:0.0058 exploreP:0.0100\n",
      "Episode:1359 meanR:2.8900 R:8.0 loss:0.0414 exploreP:0.0100\n",
      "Episode:1360 meanR:2.9100 R:4.0 loss:0.0794 exploreP:0.0100\n",
      "Episode:1361 meanR:2.9100 R:2.0 loss:0.0326 exploreP:0.0100\n",
      "Episode:1362 meanR:2.9200 R:2.0 loss:0.0329 exploreP:0.0100\n",
      "Episode:1363 meanR:2.9300 R:4.0 loss:0.0370 exploreP:0.0100\n",
      "Episode:1364 meanR:2.9400 R:6.0 loss:0.0611 exploreP:0.0100\n",
      "Episode:1365 meanR:3.0000 R:7.0 loss:0.0596 exploreP:0.0100\n",
      "Episode:1366 meanR:2.9900 R:4.0 loss:0.0712 exploreP:0.0100\n",
      "Episode:1367 meanR:3.0400 R:7.0 loss:0.0567 exploreP:0.0100\n",
      "Episode:1368 meanR:3.1200 R:12.0 loss:0.0940 exploreP:0.0100\n",
      "Episode:1369 meanR:3.1600 R:7.0 loss:0.0920 exploreP:0.0100\n",
      "Episode:1370 meanR:3.1700 R:6.0 loss:0.1068 exploreP:0.0100\n",
      "Episode:1371 meanR:3.2000 R:8.0 loss:0.0747 exploreP:0.0100\n",
      "Episode:1372 meanR:3.1700 R:0.0 loss:0.0912 exploreP:0.0100\n",
      "Episode:1373 meanR:3.1900 R:2.0 loss:0.1295 exploreP:0.0100\n",
      "Episode:1374 meanR:3.3200 R:13.0 loss:0.0914 exploreP:0.0100\n",
      "Episode:1375 meanR:3.2700 R:1.0 loss:0.0873 exploreP:0.0100\n",
      "Episode:1376 meanR:3.3400 R:10.0 loss:0.0882 exploreP:0.0100\n",
      "Episode:1377 meanR:3.3700 R:4.0 loss:0.1128 exploreP:0.0100\n",
      "Episode:1378 meanR:3.3700 R:3.0 loss:0.0724 exploreP:0.0100\n",
      "Episode:1379 meanR:3.3600 R:1.0 loss:0.0714 exploreP:0.0100\n",
      "Episode:1380 meanR:3.4000 R:4.0 loss:0.0857 exploreP:0.0100\n",
      "Episode:1381 meanR:3.3600 R:2.0 loss:0.1031 exploreP:0.0100\n",
      "Episode:1382 meanR:3.4000 R:5.0 loss:0.0603 exploreP:0.0100\n",
      "Episode:1383 meanR:3.4000 R:2.0 loss:0.0401 exploreP:0.0100\n",
      "Episode:1384 meanR:3.3400 R:0.0 loss:0.0194 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1385 meanR:3.2400 R:0.0 loss:0.0113 exploreP:0.0100\n",
      "Episode:1386 meanR:3.2100 R:1.0 loss:0.0182 exploreP:0.0100\n",
      "Episode:1387 meanR:3.2100 R:4.0 loss:0.0300 exploreP:0.0100\n",
      "Episode:1388 meanR:3.2000 R:3.0 loss:0.0625 exploreP:0.0100\n",
      "Episode:1389 meanR:3.1500 R:3.0 loss:0.0953 exploreP:0.0100\n",
      "Episode:1390 meanR:3.2100 R:6.0 loss:0.0703 exploreP:0.0100\n",
      "Episode:1391 meanR:3.2100 R:3.0 loss:0.0888 exploreP:0.0100\n",
      "Episode:1392 meanR:3.2000 R:3.0 loss:0.0502 exploreP:0.0100\n",
      "Episode:1393 meanR:3.1500 R:-1.0 loss:0.0515 exploreP:0.0100\n",
      "Episode:1394 meanR:3.1300 R:0.0 loss:0.0596 exploreP:0.0100\n",
      "Episode:1395 meanR:3.1000 R:0.0 loss:0.0320 exploreP:0.0100\n",
      "Episode:1396 meanR:3.0600 R:0.0 loss:0.0197 exploreP:0.0100\n",
      "Episode:1397 meanR:3.0300 R:0.0 loss:0.0253 exploreP:0.0100\n",
      "Episode:1398 meanR:3.0000 R:1.0 loss:0.0146 exploreP:0.0100\n",
      "Episode:1399 meanR:2.9800 R:0.0 loss:0.0050 exploreP:0.0100\n",
      "Episode:1400 meanR:2.9800 R:3.0 loss:0.0180 exploreP:0.0100\n",
      "Episode:1401 meanR:2.9100 R:-1.0 loss:0.0156 exploreP:0.0100\n",
      "Episode:1402 meanR:2.8600 R:1.0 loss:0.0204 exploreP:0.0100\n",
      "Episode:1403 meanR:2.8300 R:-1.0 loss:0.0203 exploreP:0.0100\n",
      "Episode:1404 meanR:2.8000 R:1.0 loss:0.0339 exploreP:0.0100\n",
      "Episode:1405 meanR:2.7400 R:-2.0 loss:0.0284 exploreP:0.0100\n",
      "Episode:1406 meanR:2.7100 R:0.0 loss:0.0133 exploreP:0.0100\n",
      "Episode:1407 meanR:2.6100 R:1.0 loss:0.0181 exploreP:0.0100\n",
      "Episode:1408 meanR:2.6000 R:2.0 loss:0.0158 exploreP:0.0100\n",
      "Episode:1409 meanR:2.5500 R:1.0 loss:0.0176 exploreP:0.0100\n",
      "Episode:1410 meanR:2.5000 R:0.0 loss:0.0162 exploreP:0.0100\n",
      "Episode:1411 meanR:2.4400 R:1.0 loss:0.0154 exploreP:0.0100\n",
      "Episode:1412 meanR:2.3700 R:0.0 loss:0.0356 exploreP:0.0100\n",
      "Episode:1413 meanR:2.3200 R:0.0 loss:0.0206 exploreP:0.0100\n",
      "Episode:1414 meanR:2.3000 R:1.0 loss:0.0116 exploreP:0.0100\n",
      "Episode:1415 meanR:2.3100 R:2.0 loss:0.0252 exploreP:0.0100\n",
      "Episode:1416 meanR:2.3400 R:2.0 loss:0.0445 exploreP:0.0100\n",
      "Episode:1417 meanR:2.3600 R:3.0 loss:0.0405 exploreP:0.0100\n",
      "Episode:1418 meanR:2.3500 R:0.0 loss:0.0495 exploreP:0.0100\n",
      "Episode:1419 meanR:2.3400 R:2.0 loss:0.0380 exploreP:0.0100\n",
      "Episode:1420 meanR:2.3800 R:3.0 loss:0.0358 exploreP:0.0100\n",
      "Episode:1421 meanR:2.4300 R:6.0 loss:0.0706 exploreP:0.0100\n",
      "Episode:1422 meanR:2.3800 R:3.0 loss:0.0509 exploreP:0.0100\n",
      "Episode:1423 meanR:2.3800 R:0.0 loss:0.0605 exploreP:0.0100\n",
      "Episode:1424 meanR:2.3700 R:1.0 loss:0.0344 exploreP:0.0100\n",
      "Episode:1425 meanR:2.4100 R:6.0 loss:0.0421 exploreP:0.0100\n",
      "Episode:1426 meanR:2.3300 R:0.0 loss:0.0604 exploreP:0.0100\n",
      "Episode:1427 meanR:2.3600 R:6.0 loss:0.0580 exploreP:0.0100\n",
      "Episode:1428 meanR:2.3100 R:-1.0 loss:0.1011 exploreP:0.0100\n",
      "Episode:1429 meanR:2.2900 R:3.0 loss:0.0462 exploreP:0.0100\n",
      "Episode:1430 meanR:2.3100 R:2.0 loss:0.0569 exploreP:0.0100\n",
      "Episode:1431 meanR:2.3400 R:6.0 loss:0.0621 exploreP:0.0100\n",
      "Episode:1432 meanR:2.3500 R:2.0 loss:0.0970 exploreP:0.0100\n",
      "Episode:1433 meanR:2.3100 R:1.0 loss:0.0650 exploreP:0.0100\n",
      "Episode:1434 meanR:2.3000 R:1.0 loss:0.0583 exploreP:0.0100\n",
      "Episode:1435 meanR:2.4000 R:9.0 loss:0.0781 exploreP:0.0100\n",
      "Episode:1436 meanR:2.4500 R:4.0 loss:0.0777 exploreP:0.0100\n",
      "Episode:1437 meanR:2.4800 R:5.0 loss:0.0940 exploreP:0.0100\n",
      "Episode:1438 meanR:2.4700 R:1.0 loss:0.1303 exploreP:0.0100\n",
      "Episode:1439 meanR:2.4700 R:1.0 loss:0.0596 exploreP:0.0100\n",
      "Episode:1440 meanR:2.5400 R:9.0 loss:0.0656 exploreP:0.0100\n",
      "Episode:1441 meanR:2.5100 R:0.0 loss:0.0413 exploreP:0.0100\n",
      "Episode:1442 meanR:2.5000 R:4.0 loss:0.0378 exploreP:0.0100\n",
      "Episode:1443 meanR:2.5000 R:1.0 loss:0.0221 exploreP:0.0100\n",
      "Episode:1444 meanR:2.5600 R:6.0 loss:0.0380 exploreP:0.0100\n",
      "Episode:1445 meanR:2.5800 R:2.0 loss:0.0452 exploreP:0.0100\n",
      "Episode:1446 meanR:2.6000 R:4.0 loss:0.0408 exploreP:0.0100\n",
      "Episode:1447 meanR:2.5800 R:1.0 loss:0.0380 exploreP:0.0100\n",
      "Episode:1448 meanR:2.5500 R:-1.0 loss:0.0183 exploreP:0.0100\n",
      "Episode:1449 meanR:2.5400 R:2.0 loss:0.0225 exploreP:0.0100\n",
      "Episode:1450 meanR:2.5700 R:2.0 loss:0.0216 exploreP:0.0100\n",
      "Episode:1451 meanR:2.5900 R:2.0 loss:0.0261 exploreP:0.0100\n",
      "Episode:1452 meanR:2.6800 R:9.0 loss:0.0444 exploreP:0.0100\n",
      "Episode:1453 meanR:2.7300 R:7.0 loss:0.0860 exploreP:0.0100\n",
      "Episode:1454 meanR:2.7900 R:6.0 loss:0.0472 exploreP:0.0100\n",
      "Episode:1455 meanR:2.8200 R:4.0 loss:0.0604 exploreP:0.0100\n",
      "Episode:1456 meanR:2.8300 R:2.0 loss:0.0492 exploreP:0.0100\n",
      "Episode:1457 meanR:2.8700 R:4.0 loss:0.0474 exploreP:0.0100\n",
      "Episode:1458 meanR:2.8900 R:3.0 loss:0.0539 exploreP:0.0100\n",
      "Episode:1459 meanR:2.8800 R:7.0 loss:0.0575 exploreP:0.0100\n",
      "Episode:1460 meanR:2.8900 R:5.0 loss:0.1069 exploreP:0.0100\n",
      "Episode:1461 meanR:2.8700 R:0.0 loss:0.0791 exploreP:0.0100\n",
      "Episode:1462 meanR:2.9000 R:5.0 loss:0.0504 exploreP:0.0100\n",
      "Episode:1463 meanR:2.8800 R:2.0 loss:0.0633 exploreP:0.0100\n",
      "Episode:1464 meanR:2.8700 R:5.0 loss:0.0341 exploreP:0.0100\n",
      "Episode:1465 meanR:2.8400 R:4.0 loss:0.0293 exploreP:0.0100\n",
      "Episode:1466 meanR:2.8500 R:5.0 loss:0.0583 exploreP:0.0100\n",
      "Episode:1467 meanR:2.8000 R:2.0 loss:0.0683 exploreP:0.0100\n",
      "Episode:1468 meanR:2.6800 R:0.0 loss:0.0520 exploreP:0.0100\n",
      "Episode:1469 meanR:2.6200 R:1.0 loss:0.0348 exploreP:0.0100\n",
      "Episode:1470 meanR:2.5600 R:0.0 loss:0.0372 exploreP:0.0100\n",
      "Episode:1471 meanR:2.5200 R:4.0 loss:0.0431 exploreP:0.0100\n",
      "Episode:1472 meanR:2.6100 R:9.0 loss:0.0478 exploreP:0.0100\n",
      "Episode:1473 meanR:2.6000 R:1.0 loss:0.0785 exploreP:0.0100\n",
      "Episode:1474 meanR:2.5000 R:3.0 loss:0.0550 exploreP:0.0100\n",
      "Episode:1475 meanR:2.5100 R:2.0 loss:0.0499 exploreP:0.0100\n",
      "Episode:1476 meanR:2.4900 R:8.0 loss:0.0627 exploreP:0.0100\n",
      "Episode:1477 meanR:2.5100 R:6.0 loss:0.0716 exploreP:0.0100\n",
      "Episode:1478 meanR:2.5200 R:4.0 loss:0.0549 exploreP:0.0100\n",
      "Episode:1479 meanR:2.6000 R:9.0 loss:0.0596 exploreP:0.0100\n",
      "Episode:1480 meanR:2.6500 R:9.0 loss:0.0852 exploreP:0.0100\n",
      "Episode:1481 meanR:2.6700 R:4.0 loss:0.0910 exploreP:0.0100\n",
      "Episode:1482 meanR:2.6800 R:6.0 loss:0.0766 exploreP:0.0100\n",
      "Episode:1483 meanR:2.8000 R:14.0 loss:0.0960 exploreP:0.0100\n",
      "Episode:1484 meanR:2.8500 R:5.0 loss:0.1276 exploreP:0.0100\n",
      "Episode:1485 meanR:2.9100 R:6.0 loss:0.1113 exploreP:0.0100\n",
      "Episode:1486 meanR:2.9700 R:7.0 loss:0.0639 exploreP:0.0100\n",
      "Episode:1487 meanR:2.9400 R:1.0 loss:0.0757 exploreP:0.0100\n",
      "Episode:1488 meanR:2.9600 R:5.0 loss:0.0410 exploreP:0.0100\n",
      "Episode:1489 meanR:2.9700 R:4.0 loss:0.0576 exploreP:0.0100\n",
      "Episode:1490 meanR:3.0100 R:10.0 loss:0.0897 exploreP:0.0100\n",
      "Episode:1491 meanR:3.0400 R:6.0 loss:0.0862 exploreP:0.0100\n",
      "Episode:1492 meanR:3.0500 R:4.0 loss:0.0800 exploreP:0.0100\n",
      "Episode:1493 meanR:3.1000 R:4.0 loss:0.0747 exploreP:0.0100\n",
      "Episode:1494 meanR:3.1200 R:2.0 loss:0.0735 exploreP:0.0100\n",
      "Episode:1495 meanR:3.1300 R:1.0 loss:0.0279 exploreP:0.0100\n",
      "Episode:1496 meanR:3.1400 R:1.0 loss:0.0295 exploreP:0.0100\n",
      "Episode:1497 meanR:3.1900 R:5.0 loss:0.0360 exploreP:0.0100\n",
      "Episode:1498 meanR:3.2400 R:6.0 loss:0.0536 exploreP:0.0100\n",
      "Episode:1499 meanR:3.2500 R:1.0 loss:0.0811 exploreP:0.0100\n",
      "Episode:1500 meanR:3.2300 R:1.0 loss:0.0310 exploreP:0.0100\n",
      "Episode:1501 meanR:3.2400 R:0.0 loss:0.0057 exploreP:0.0100\n",
      "Episode:1502 meanR:3.2300 R:0.0 loss:0.0148 exploreP:0.0100\n",
      "Episode:1503 meanR:3.2700 R:3.0 loss:0.0288 exploreP:0.0100\n",
      "Episode:1504 meanR:3.2300 R:-3.0 loss:0.0512 exploreP:0.0100\n",
      "Episode:1505 meanR:3.2300 R:-2.0 loss:0.0312 exploreP:0.0100\n",
      "Episode:1506 meanR:3.2500 R:2.0 loss:0.0296 exploreP:0.0100\n",
      "Episode:1507 meanR:3.2400 R:0.0 loss:0.0202 exploreP:0.0100\n",
      "Episode:1508 meanR:3.2000 R:-2.0 loss:0.0205 exploreP:0.0100\n",
      "Episode:1509 meanR:3.2000 R:1.0 loss:0.0185 exploreP:0.0100\n",
      "Episode:1510 meanR:3.2500 R:5.0 loss:0.0259 exploreP:0.0100\n",
      "Episode:1511 meanR:3.2500 R:1.0 loss:0.0491 exploreP:0.0100\n",
      "Episode:1512 meanR:3.2500 R:0.0 loss:0.0069 exploreP:0.0100\n",
      "Episode:1513 meanR:3.2400 R:-1.0 loss:0.0043 exploreP:0.0100\n",
      "Episode:1514 meanR:3.2400 R:1.0 loss:0.0100 exploreP:0.0100\n",
      "Episode:1515 meanR:3.2200 R:0.0 loss:0.0063 exploreP:0.0100\n",
      "Episode:1516 meanR:3.2100 R:1.0 loss:0.0061 exploreP:0.0100\n",
      "Episode:1517 meanR:3.1700 R:-1.0 loss:0.0114 exploreP:0.0100\n",
      "Episode:1518 meanR:3.1600 R:-1.0 loss:0.0099 exploreP:0.0100\n",
      "Episode:1519 meanR:3.1400 R:0.0 loss:0.0129 exploreP:0.0100\n",
      "Episode:1520 meanR:3.1000 R:-1.0 loss:0.0196 exploreP:0.0100\n",
      "Episode:1521 meanR:3.0400 R:0.0 loss:0.0137 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1522 meanR:3.0300 R:2.0 loss:0.0298 exploreP:0.0100\n",
      "Episode:1523 meanR:3.0400 R:1.0 loss:0.1855 exploreP:0.0100\n",
      "Episode:1524 meanR:3.0300 R:0.0 loss:0.2652 exploreP:0.0100\n",
      "Episode:1525 meanR:2.9700 R:0.0 loss:0.4620 exploreP:0.0100\n",
      "Episode:1526 meanR:2.9600 R:-1.0 loss:0.5227 exploreP:0.0100\n",
      "Episode:1527 meanR:2.9000 R:0.0 loss:0.2315 exploreP:0.0100\n",
      "Episode:1528 meanR:2.9100 R:0.0 loss:0.2416 exploreP:0.0100\n",
      "Episode:1529 meanR:2.8900 R:1.0 loss:0.2956 exploreP:0.0100\n",
      "Episode:1530 meanR:2.8800 R:1.0 loss:0.4353 exploreP:0.0100\n",
      "Episode:1531 meanR:2.8100 R:-1.0 loss:0.6211 exploreP:0.0100\n",
      "Episode:1532 meanR:2.7800 R:-1.0 loss:0.7440 exploreP:0.0100\n",
      "Episode:1533 meanR:2.7800 R:1.0 loss:0.5380 exploreP:0.0100\n",
      "Episode:1534 meanR:2.7700 R:0.0 loss:0.3772 exploreP:0.0100\n",
      "Episode:1535 meanR:2.6800 R:0.0 loss:0.5756 exploreP:0.0100\n",
      "Episode:1536 meanR:2.6300 R:-1.0 loss:0.7468 exploreP:0.0100\n",
      "Episode:1537 meanR:2.5800 R:0.0 loss:0.6362 exploreP:0.0100\n",
      "Episode:1538 meanR:2.5700 R:0.0 loss:0.6820 exploreP:0.0100\n",
      "Episode:1539 meanR:2.5800 R:2.0 loss:0.6560 exploreP:0.0100\n",
      "Episode:1540 meanR:2.5000 R:1.0 loss:0.4818 exploreP:0.0100\n",
      "Episode:1541 meanR:2.5000 R:0.0 loss:0.6459 exploreP:0.0100\n",
      "Episode:1542 meanR:2.4900 R:3.0 loss:0.5570 exploreP:0.0100\n",
      "Episode:1543 meanR:2.4800 R:0.0 loss:0.8828 exploreP:0.0100\n",
      "Episode:1544 meanR:2.4300 R:1.0 loss:0.4133 exploreP:0.0100\n",
      "Episode:1545 meanR:2.4100 R:0.0 loss:0.5665 exploreP:0.0100\n",
      "Episode:1546 meanR:2.4000 R:3.0 loss:0.6473 exploreP:0.0100\n",
      "Episode:1547 meanR:2.4000 R:1.0 loss:0.2955 exploreP:0.0100\n",
      "Episode:1548 meanR:2.4400 R:3.0 loss:1.1456 exploreP:0.0100\n",
      "Episode:1549 meanR:2.4100 R:-1.0 loss:1.4205 exploreP:0.0100\n",
      "Episode:1550 meanR:2.4400 R:5.0 loss:1.2713 exploreP:0.0100\n",
      "Episode:1551 meanR:2.4300 R:1.0 loss:0.7963 exploreP:0.0100\n",
      "Episode:1552 meanR:2.3300 R:-1.0 loss:0.4772 exploreP:0.0100\n",
      "Episode:1553 meanR:2.2700 R:1.0 loss:0.6496 exploreP:0.0100\n",
      "Episode:1554 meanR:2.2100 R:0.0 loss:0.8904 exploreP:0.0100\n",
      "Episode:1555 meanR:2.1400 R:-3.0 loss:0.9490 exploreP:0.0100\n",
      "Episode:1556 meanR:2.1600 R:4.0 loss:1.2191 exploreP:0.0100\n",
      "Episode:1557 meanR:2.1400 R:2.0 loss:1.5698 exploreP:0.0100\n",
      "Episode:1558 meanR:2.1200 R:1.0 loss:1.6880 exploreP:0.0100\n",
      "Episode:1559 meanR:2.0600 R:1.0 loss:1.8954 exploreP:0.0100\n",
      "Episode:1560 meanR:2.0100 R:0.0 loss:1.8648 exploreP:0.0100\n",
      "Episode:1561 meanR:2.0100 R:0.0 loss:1.9360 exploreP:0.0100\n",
      "Episode:1562 meanR:1.9700 R:1.0 loss:2.0397 exploreP:0.0100\n",
      "Episode:1563 meanR:1.9400 R:-1.0 loss:1.8767 exploreP:0.0100\n",
      "Episode:1564 meanR:1.8900 R:0.0 loss:1.9483 exploreP:0.0100\n",
      "Episode:1565 meanR:1.8500 R:0.0 loss:1.6992 exploreP:0.0100\n",
      "Episode:1566 meanR:1.8000 R:0.0 loss:1.9595 exploreP:0.0100\n",
      "Episode:1567 meanR:1.7800 R:0.0 loss:1.9150 exploreP:0.0100\n",
      "Episode:1568 meanR:1.7900 R:1.0 loss:1.8855 exploreP:0.0100\n",
      "Episode:1569 meanR:1.7800 R:0.0 loss:2.0015 exploreP:0.0100\n",
      "Episode:1570 meanR:1.7800 R:0.0 loss:1.9691 exploreP:0.0100\n",
      "Episode:1571 meanR:1.7400 R:0.0 loss:1.8965 exploreP:0.0100\n",
      "Episode:1572 meanR:1.6500 R:0.0 loss:1.9827 exploreP:0.0100\n",
      "Episode:1573 meanR:1.6400 R:0.0 loss:1.8758 exploreP:0.0100\n",
      "Episode:1574 meanR:1.6200 R:1.0 loss:1.7553 exploreP:0.0100\n",
      "Episode:1575 meanR:1.6000 R:0.0 loss:1.8795 exploreP:0.0100\n",
      "Episode:1576 meanR:1.5200 R:0.0 loss:1.6900 exploreP:0.0100\n",
      "Episode:1577 meanR:1.4700 R:1.0 loss:1.7056 exploreP:0.0100\n",
      "Episode:1578 meanR:1.4100 R:-2.0 loss:1.8296 exploreP:0.0100\n",
      "Episode:1579 meanR:1.3100 R:-1.0 loss:1.7129 exploreP:0.0100\n",
      "Episode:1580 meanR:1.2200 R:0.0 loss:1.7747 exploreP:0.0100\n",
      "Episode:1581 meanR:1.1800 R:0.0 loss:1.6994 exploreP:0.0100\n",
      "Episode:1582 meanR:1.1300 R:1.0 loss:1.3295 exploreP:0.0100\n",
      "Episode:1583 meanR:0.9800 R:-1.0 loss:1.6486 exploreP:0.0100\n",
      "Episode:1584 meanR:0.9300 R:0.0 loss:2.0084 exploreP:0.0100\n",
      "Episode:1585 meanR:0.8700 R:0.0 loss:1.9740 exploreP:0.0100\n",
      "Episode:1586 meanR:0.7900 R:-1.0 loss:1.9213 exploreP:0.0100\n",
      "Episode:1587 meanR:0.7800 R:0.0 loss:1.8762 exploreP:0.0100\n",
      "Episode:1588 meanR:0.7200 R:-1.0 loss:1.7954 exploreP:0.0100\n",
      "Episode:1589 meanR:0.6800 R:0.0 loss:2.0254 exploreP:0.0100\n",
      "Episode:1590 meanR:0.5800 R:0.0 loss:2.0969 exploreP:0.0100\n",
      "Episode:1591 meanR:0.5100 R:-1.0 loss:1.4991 exploreP:0.0100\n",
      "Episode:1592 meanR:0.4700 R:0.0 loss:1.4568 exploreP:0.0100\n",
      "Episode:1593 meanR:0.4500 R:2.0 loss:1.8695 exploreP:0.0100\n",
      "Episode:1594 meanR:0.4300 R:0.0 loss:1.8910 exploreP:0.0100\n",
      "Episode:1595 meanR:0.4200 R:0.0 loss:1.8625 exploreP:0.0100\n",
      "Episode:1596 meanR:0.4000 R:-1.0 loss:1.9151 exploreP:0.0100\n",
      "Episode:1597 meanR:0.3500 R:0.0 loss:1.8873 exploreP:0.0100\n",
      "Episode:1598 meanR:0.2900 R:0.0 loss:1.9657 exploreP:0.0100\n",
      "Episode:1599 meanR:0.2700 R:-1.0 loss:1.8518 exploreP:0.0100\n",
      "Episode:1600 meanR:0.2700 R:1.0 loss:1.8345 exploreP:0.0100\n",
      "Episode:1601 meanR:0.2600 R:-1.0 loss:1.9094 exploreP:0.0100\n",
      "Episode:1602 meanR:0.2600 R:0.0 loss:1.8247 exploreP:0.0100\n",
      "Episode:1603 meanR:0.2400 R:1.0 loss:1.8107 exploreP:0.0100\n",
      "Episode:1604 meanR:0.2700 R:0.0 loss:1.7915 exploreP:0.0100\n",
      "Episode:1605 meanR:0.3000 R:1.0 loss:1.8685 exploreP:0.0100\n",
      "Episode:1606 meanR:0.3000 R:2.0 loss:1.8654 exploreP:0.0100\n",
      "Episode:1607 meanR:0.2900 R:-1.0 loss:1.8844 exploreP:0.0100\n",
      "Episode:1608 meanR:0.3200 R:1.0 loss:1.8435 exploreP:0.0100\n",
      "Episode:1609 meanR:0.3200 R:1.0 loss:1.8721 exploreP:0.0100\n",
      "Episode:1610 meanR:0.2500 R:-2.0 loss:1.9118 exploreP:0.0100\n",
      "Episode:1611 meanR:0.2500 R:1.0 loss:1.8555 exploreP:0.0100\n",
      "Episode:1612 meanR:0.2500 R:0.0 loss:1.7513 exploreP:0.0100\n",
      "Episode:1613 meanR:0.2600 R:0.0 loss:1.9005 exploreP:0.0100\n",
      "Episode:1614 meanR:0.2500 R:0.0 loss:1.8567 exploreP:0.0100\n",
      "Episode:1615 meanR:0.2500 R:0.0 loss:1.7384 exploreP:0.0100\n",
      "Episode:1616 meanR:0.2600 R:2.0 loss:1.5132 exploreP:0.0100\n",
      "Episode:1617 meanR:0.2800 R:1.0 loss:1.8354 exploreP:0.0100\n",
      "Episode:1618 meanR:0.3100 R:2.0 loss:1.7165 exploreP:0.0100\n",
      "Episode:1619 meanR:0.3100 R:0.0 loss:2.0874 exploreP:0.0100\n",
      "Episode:1620 meanR:0.3300 R:1.0 loss:1.8240 exploreP:0.0100\n",
      "Episode:1621 meanR:0.3200 R:-1.0 loss:1.8178 exploreP:0.0100\n",
      "Episode:1622 meanR:0.3000 R:0.0 loss:1.9863 exploreP:0.0100\n",
      "Episode:1623 meanR:0.2900 R:0.0 loss:1.8901 exploreP:0.0100\n",
      "Episode:1624 meanR:0.2900 R:0.0 loss:1.8136 exploreP:0.0100\n",
      "Episode:1625 meanR:0.2900 R:0.0 loss:1.8457 exploreP:0.0100\n",
      "Episode:1626 meanR:0.2900 R:-1.0 loss:1.8587 exploreP:0.0100\n",
      "Episode:1627 meanR:0.2900 R:0.0 loss:1.8506 exploreP:0.0100\n",
      "Episode:1628 meanR:0.2900 R:0.0 loss:1.9069 exploreP:0.0100\n",
      "Episode:1629 meanR:0.2800 R:0.0 loss:1.8467 exploreP:0.0100\n",
      "Episode:1630 meanR:0.2700 R:0.0 loss:2.4525 exploreP:0.0100\n",
      "Episode:1631 meanR:0.2800 R:0.0 loss:2.3948 exploreP:0.0100\n",
      "Episode:1632 meanR:0.2900 R:0.0 loss:1.7863 exploreP:0.0100\n",
      "Episode:1633 meanR:0.2900 R:1.0 loss:2.0536 exploreP:0.0100\n",
      "Episode:1634 meanR:0.2900 R:0.0 loss:1.8888 exploreP:0.0100\n",
      "Episode:1635 meanR:0.2800 R:-1.0 loss:1.7478 exploreP:0.0100\n",
      "Episode:1636 meanR:0.3000 R:1.0 loss:1.6554 exploreP:0.0100\n",
      "Episode:1637 meanR:0.3000 R:0.0 loss:1.8115 exploreP:0.0100\n",
      "Episode:1638 meanR:0.3100 R:1.0 loss:1.7513 exploreP:0.0100\n",
      "Episode:1639 meanR:0.2700 R:-2.0 loss:1.8555 exploreP:0.0100\n",
      "Episode:1640 meanR:0.2600 R:0.0 loss:1.8753 exploreP:0.0100\n",
      "Episode:1641 meanR:0.2600 R:0.0 loss:1.8355 exploreP:0.0100\n",
      "Episode:1642 meanR:0.2200 R:-1.0 loss:1.8281 exploreP:0.0100\n",
      "Episode:1643 meanR:0.2100 R:-1.0 loss:1.9377 exploreP:0.0100\n",
      "Episode:1644 meanR:0.1900 R:-1.0 loss:1.8365 exploreP:0.0100\n",
      "Episode:1645 meanR:0.2100 R:2.0 loss:1.8601 exploreP:0.0100\n",
      "Episode:1646 meanR:0.1800 R:0.0 loss:1.8340 exploreP:0.0100\n",
      "Episode:1647 meanR:0.1600 R:-1.0 loss:2.0560 exploreP:0.0100\n",
      "Episode:1648 meanR:0.1500 R:2.0 loss:1.8083 exploreP:0.0100\n",
      "Episode:1649 meanR:0.1600 R:0.0 loss:1.8373 exploreP:0.0100\n",
      "Episode:1650 meanR:0.1100 R:0.0 loss:2.1924 exploreP:0.0100\n",
      "Episode:1651 meanR:0.1000 R:0.0 loss:2.1780 exploreP:0.0100\n",
      "Episode:1652 meanR:0.1000 R:-1.0 loss:1.9120 exploreP:0.0100\n",
      "Episode:1653 meanR:0.0900 R:0.0 loss:1.7088 exploreP:0.0100\n",
      "Episode:1654 meanR:0.0900 R:0.0 loss:1.7505 exploreP:0.0100\n",
      "Episode:1655 meanR:0.1300 R:1.0 loss:1.7773 exploreP:0.0100\n",
      "Episode:1656 meanR:0.1100 R:2.0 loss:2.0440 exploreP:0.0100\n",
      "Episode:1657 meanR:0.0900 R:0.0 loss:2.3158 exploreP:0.0100\n",
      "Episode:1658 meanR:0.0900 R:1.0 loss:2.0799 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1659 meanR:0.0800 R:0.0 loss:1.9532 exploreP:0.0100\n",
      "Episode:1660 meanR:0.0800 R:0.0 loss:1.6676 exploreP:0.0100\n",
      "Episode:1661 meanR:0.0900 R:1.0 loss:1.4550 exploreP:0.0100\n",
      "Episode:1662 meanR:0.0900 R:1.0 loss:1.7424 exploreP:0.0100\n",
      "Episode:1663 meanR:0.1100 R:1.0 loss:1.9016 exploreP:0.0100\n",
      "Episode:1664 meanR:0.1000 R:-1.0 loss:1.8681 exploreP:0.0100\n",
      "Episode:1665 meanR:0.1000 R:0.0 loss:1.7777 exploreP:0.0100\n",
      "Episode:1666 meanR:0.1100 R:1.0 loss:1.7234 exploreP:0.0100\n",
      "Episode:1667 meanR:0.1200 R:1.0 loss:2.0769 exploreP:0.0100\n",
      "Episode:1668 meanR:0.1100 R:0.0 loss:1.8078 exploreP:0.0100\n",
      "Episode:1669 meanR:0.1100 R:0.0 loss:1.8279 exploreP:0.0100\n",
      "Episode:1670 meanR:0.1100 R:0.0 loss:2.2876 exploreP:0.0100\n",
      "Episode:1671 meanR:0.1200 R:1.0 loss:1.9945 exploreP:0.0100\n",
      "Episode:1672 meanR:0.1100 R:-1.0 loss:1.9339 exploreP:0.0100\n",
      "Episode:1673 meanR:0.1100 R:0.0 loss:1.8242 exploreP:0.0100\n",
      "Episode:1674 meanR:0.1200 R:2.0 loss:1.8621 exploreP:0.0100\n",
      "Episode:1675 meanR:0.1200 R:0.0 loss:1.8808 exploreP:0.0100\n",
      "Episode:1676 meanR:0.1200 R:0.0 loss:1.7568 exploreP:0.0100\n",
      "Episode:1677 meanR:0.1100 R:0.0 loss:1.9295 exploreP:0.0100\n",
      "Episode:1678 meanR:0.1200 R:-1.0 loss:2.0797 exploreP:0.0100\n",
      "Episode:1679 meanR:0.1300 R:0.0 loss:1.8802 exploreP:0.0100\n",
      "Episode:1680 meanR:0.1200 R:-1.0 loss:1.8959 exploreP:0.0100\n",
      "Episode:1681 meanR:0.1200 R:0.0 loss:1.8450 exploreP:0.0100\n",
      "Episode:1682 meanR:0.1200 R:1.0 loss:1.6313 exploreP:0.0100\n",
      "Episode:1683 meanR:0.1400 R:1.0 loss:1.9233 exploreP:0.0100\n",
      "Episode:1684 meanR:0.1400 R:0.0 loss:1.8662 exploreP:0.0100\n",
      "Episode:1685 meanR:0.1500 R:1.0 loss:1.7404 exploreP:0.0100\n",
      "Episode:1686 meanR:0.1600 R:0.0 loss:1.9403 exploreP:0.0100\n",
      "Episode:1687 meanR:0.1700 R:1.0 loss:1.8605 exploreP:0.0100\n",
      "Episode:1688 meanR:0.1800 R:0.0 loss:1.8187 exploreP:0.0100\n",
      "Episode:1689 meanR:0.1900 R:1.0 loss:1.8600 exploreP:0.0100\n",
      "Episode:1690 meanR:0.1900 R:0.0 loss:1.9177 exploreP:0.0100\n",
      "Episode:1691 meanR:0.1900 R:-1.0 loss:1.8570 exploreP:0.0100\n",
      "Episode:1692 meanR:0.1900 R:0.0 loss:1.7550 exploreP:0.0100\n",
      "Episode:1693 meanR:0.1600 R:-1.0 loss:2.4715 exploreP:0.0100\n",
      "Episode:1694 meanR:0.1700 R:1.0 loss:1.9759 exploreP:0.0100\n",
      "Episode:1695 meanR:0.1700 R:0.0 loss:1.9321 exploreP:0.0100\n",
      "Episode:1696 meanR:0.1800 R:0.0 loss:1.8895 exploreP:0.0100\n",
      "Episode:1697 meanR:0.1700 R:-1.0 loss:1.8324 exploreP:0.0100\n",
      "Episode:1698 meanR:0.1700 R:0.0 loss:1.8330 exploreP:0.0100\n",
      "Episode:1699 meanR:0.1800 R:0.0 loss:1.8808 exploreP:0.0100\n",
      "Episode:1700 meanR:0.1700 R:0.0 loss:1.8645 exploreP:0.0100\n",
      "Episode:1701 meanR:0.1800 R:0.0 loss:1.8258 exploreP:0.0100\n",
      "Episode:1702 meanR:0.1700 R:-1.0 loss:1.8588 exploreP:0.0100\n",
      "Episode:1703 meanR:0.1600 R:0.0 loss:1.9822 exploreP:0.0100\n",
      "Episode:1704 meanR:0.1600 R:0.0 loss:1.8990 exploreP:0.0100\n",
      "Episode:1705 meanR:0.1500 R:0.0 loss:1.7680 exploreP:0.0100\n",
      "Episode:1706 meanR:0.1300 R:0.0 loss:1.9230 exploreP:0.0100\n",
      "Episode:1707 meanR:0.1400 R:0.0 loss:1.6662 exploreP:0.0100\n",
      "Episode:1708 meanR:0.1200 R:-1.0 loss:1.7336 exploreP:0.0100\n",
      "Episode:1709 meanR:0.1100 R:0.0 loss:1.8556 exploreP:0.0100\n",
      "Episode:1710 meanR:0.1300 R:0.0 loss:1.8786 exploreP:0.0100\n",
      "Episode:1711 meanR:0.1500 R:3.0 loss:1.7747 exploreP:0.0100\n",
      "Episode:1712 meanR:0.1500 R:0.0 loss:2.2321 exploreP:0.0100\n",
      "Episode:1713 meanR:0.1500 R:0.0 loss:1.4077 exploreP:0.0100\n",
      "Episode:1714 meanR:0.1600 R:1.0 loss:1.6790 exploreP:0.0100\n",
      "Episode:1715 meanR:0.1400 R:-2.0 loss:1.8430 exploreP:0.0100\n",
      "Episode:1716 meanR:0.1200 R:0.0 loss:1.6557 exploreP:0.0100\n",
      "Episode:1717 meanR:0.1000 R:-1.0 loss:1.9990 exploreP:0.0100\n",
      "Episode:1718 meanR:0.0900 R:1.0 loss:1.8690 exploreP:0.0100\n",
      "Episode:1719 meanR:0.0800 R:-1.0 loss:1.7183 exploreP:0.0100\n",
      "Episode:1720 meanR:0.0700 R:0.0 loss:1.8031 exploreP:0.0100\n",
      "Episode:1721 meanR:0.0800 R:0.0 loss:1.8086 exploreP:0.0100\n",
      "Episode:1722 meanR:0.0800 R:0.0 loss:1.4989 exploreP:0.0100\n",
      "Episode:1723 meanR:0.0800 R:0.0 loss:2.2858 exploreP:0.0100\n",
      "Episode:1724 meanR:0.0800 R:0.0 loss:1.8419 exploreP:0.0100\n",
      "Episode:1725 meanR:0.0800 R:0.0 loss:1.8006 exploreP:0.0100\n",
      "Episode:1726 meanR:0.0900 R:0.0 loss:2.0659 exploreP:0.0100\n",
      "Episode:1727 meanR:0.0900 R:0.0 loss:1.6201 exploreP:0.0100\n",
      "Episode:1728 meanR:0.0900 R:0.0 loss:1.7262 exploreP:0.0100\n",
      "Episode:1729 meanR:0.0800 R:-1.0 loss:2.2528 exploreP:0.0100\n",
      "Episode:1730 meanR:0.0800 R:0.0 loss:1.9972 exploreP:0.0100\n",
      "Episode:1731 meanR:0.1000 R:2.0 loss:1.9507 exploreP:0.0100\n",
      "Episode:1732 meanR:0.1000 R:0.0 loss:1.9070 exploreP:0.0100\n",
      "Episode:1733 meanR:0.0800 R:-1.0 loss:2.1939 exploreP:0.0100\n",
      "Episode:1734 meanR:0.0800 R:0.0 loss:1.8929 exploreP:0.0100\n",
      "Episode:1735 meanR:0.0900 R:0.0 loss:1.9318 exploreP:0.0100\n",
      "Episode:1736 meanR:0.0700 R:-1.0 loss:1.4367 exploreP:0.0100\n",
      "Episode:1737 meanR:0.0600 R:-1.0 loss:1.7294 exploreP:0.0100\n",
      "Episode:1738 meanR:0.0500 R:0.0 loss:1.8097 exploreP:0.0100\n",
      "Episode:1739 meanR:0.0600 R:-1.0 loss:1.7112 exploreP:0.0100\n",
      "Episode:1740 meanR:0.0600 R:0.0 loss:1.8113 exploreP:0.0100\n",
      "Episode:1741 meanR:0.0600 R:0.0 loss:1.9820 exploreP:0.0100\n",
      "Episode:1742 meanR:0.0700 R:0.0 loss:1.9753 exploreP:0.0100\n",
      "Episode:1743 meanR:0.0700 R:-1.0 loss:1.6688 exploreP:0.0100\n",
      "Episode:1744 meanR:0.0900 R:1.0 loss:1.7663 exploreP:0.0100\n",
      "Episode:1745 meanR:0.0700 R:0.0 loss:1.6841 exploreP:0.0100\n",
      "Episode:1746 meanR:0.0600 R:-1.0 loss:1.9780 exploreP:0.0100\n",
      "Episode:1747 meanR:0.0700 R:0.0 loss:1.8408 exploreP:0.0100\n",
      "Episode:1748 meanR:0.0600 R:1.0 loss:1.8610 exploreP:0.0100\n",
      "Episode:1749 meanR:0.0700 R:1.0 loss:1.7984 exploreP:0.0100\n",
      "Episode:1750 meanR:0.0800 R:1.0 loss:1.7470 exploreP:0.0100\n",
      "Episode:1751 meanR:0.0800 R:0.0 loss:1.7708 exploreP:0.0100\n",
      "Episode:1752 meanR:0.1000 R:1.0 loss:1.7147 exploreP:0.0100\n",
      "Episode:1753 meanR:0.1000 R:0.0 loss:1.7604 exploreP:0.0100\n",
      "Episode:1754 meanR:0.1000 R:0.0 loss:1.9411 exploreP:0.0100\n",
      "Episode:1755 meanR:0.1000 R:1.0 loss:2.0075 exploreP:0.0100\n",
      "Episode:1756 meanR:0.0900 R:1.0 loss:1.7644 exploreP:0.0100\n",
      "Episode:1757 meanR:0.0900 R:0.0 loss:1.8230 exploreP:0.0100\n",
      "Episode:1758 meanR:0.0800 R:0.0 loss:1.7659 exploreP:0.0100\n",
      "Episode:1759 meanR:0.0800 R:0.0 loss:1.7299 exploreP:0.0100\n",
      "Episode:1760 meanR:0.0800 R:0.0 loss:2.0810 exploreP:0.0100\n",
      "Episode:1761 meanR:0.0600 R:-1.0 loss:2.0518 exploreP:0.0100\n",
      "Episode:1762 meanR:0.0500 R:0.0 loss:1.8769 exploreP:0.0100\n",
      "Episode:1763 meanR:0.0400 R:0.0 loss:1.9750 exploreP:0.0100\n",
      "Episode:1764 meanR:0.0500 R:0.0 loss:1.8262 exploreP:0.0100\n",
      "Episode:1765 meanR:0.0400 R:-1.0 loss:1.9128 exploreP:0.0100\n",
      "Episode:1766 meanR:0.0100 R:-2.0 loss:2.7525 exploreP:0.0100\n",
      "Episode:1767 meanR:0.0100 R:1.0 loss:2.0250 exploreP:0.0100\n",
      "Episode:1768 meanR:0.0100 R:0.0 loss:1.7445 exploreP:0.0100\n",
      "Episode:1769 meanR:0.0100 R:0.0 loss:1.8332 exploreP:0.0100\n",
      "Episode:1770 meanR:0.0100 R:0.0 loss:1.7416 exploreP:0.0100\n",
      "Episode:1771 meanR:0.0000 R:0.0 loss:1.7055 exploreP:0.0100\n",
      "Episode:1772 meanR:0.0200 R:1.0 loss:1.7967 exploreP:0.0100\n",
      "Episode:1773 meanR:0.0200 R:0.0 loss:1.8713 exploreP:0.0100\n",
      "Episode:1774 meanR:-0.0100 R:-1.0 loss:2.0223 exploreP:0.0100\n",
      "Episode:1775 meanR:-0.0100 R:0.0 loss:2.4317 exploreP:0.0100\n",
      "Episode:1776 meanR:-0.0100 R:0.0 loss:2.2626 exploreP:0.0100\n",
      "Episode:1777 meanR:-0.0100 R:0.0 loss:1.8425 exploreP:0.0100\n",
      "Episode:1778 meanR:-0.0100 R:-1.0 loss:2.2445 exploreP:0.0100\n",
      "Episode:1779 meanR:0.0000 R:1.0 loss:1.7550 exploreP:0.0100\n",
      "Episode:1780 meanR:0.0100 R:0.0 loss:1.7376 exploreP:0.0100\n",
      "Episode:1781 meanR:0.0000 R:-1.0 loss:1.9484 exploreP:0.0100\n",
      "Episode:1782 meanR:-0.0100 R:0.0 loss:1.8755 exploreP:0.0100\n",
      "Episode:1783 meanR:-0.0100 R:1.0 loss:2.1136 exploreP:0.0100\n",
      "Episode:1784 meanR:0.0000 R:1.0 loss:1.5774 exploreP:0.0100\n",
      "Episode:1785 meanR:-0.0100 R:0.0 loss:1.3088 exploreP:0.0100\n",
      "Episode:1786 meanR:-0.0100 R:0.0 loss:1.6306 exploreP:0.0100\n",
      "Episode:1787 meanR:-0.0100 R:1.0 loss:1.7143 exploreP:0.0100\n",
      "Episode:1788 meanR:-0.0100 R:0.0 loss:1.3545 exploreP:0.0100\n",
      "Episode:1789 meanR:-0.0200 R:0.0 loss:1.7213 exploreP:0.0100\n",
      "Episode:1790 meanR:-0.0200 R:0.0 loss:1.9556 exploreP:0.0100\n",
      "Episode:1791 meanR:-0.0100 R:0.0 loss:1.9600 exploreP:0.0100\n",
      "Episode:1792 meanR:-0.0100 R:0.0 loss:1.8517 exploreP:0.0100\n",
      "Episode:1793 meanR:-0.0200 R:-2.0 loss:1.8192 exploreP:0.0100\n",
      "Episode:1794 meanR:-0.0400 R:-1.0 loss:1.6646 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1795 meanR:-0.0400 R:0.0 loss:1.6479 exploreP:0.0100\n",
      "Episode:1796 meanR:-0.0400 R:0.0 loss:1.8446 exploreP:0.0100\n",
      "Episode:1797 meanR:-0.0300 R:0.0 loss:1.8929 exploreP:0.0100\n",
      "Episode:1798 meanR:-0.0200 R:1.0 loss:2.1121 exploreP:0.0100\n",
      "Episode:1799 meanR:-0.0200 R:0.0 loss:2.1385 exploreP:0.0100\n",
      "Episode:1800 meanR:-0.0200 R:0.0 loss:1.3831 exploreP:0.0100\n",
      "Episode:1801 meanR:0.0000 R:2.0 loss:1.6224 exploreP:0.0100\n",
      "Episode:1802 meanR:0.0100 R:0.0 loss:1.7583 exploreP:0.0100\n",
      "Episode:1803 meanR:0.0100 R:0.0 loss:2.1670 exploreP:0.0100\n",
      "Episode:1804 meanR:0.0100 R:0.0 loss:1.8681 exploreP:0.0100\n",
      "Episode:1805 meanR:0.0100 R:0.0 loss:2.0401 exploreP:0.0100\n",
      "Episode:1806 meanR:-0.0100 R:-2.0 loss:2.1598 exploreP:0.0100\n",
      "Episode:1807 meanR:-0.0100 R:0.0 loss:1.8055 exploreP:0.0100\n",
      "Episode:1808 meanR:0.0000 R:0.0 loss:1.7614 exploreP:0.0100\n",
      "Episode:1809 meanR:-0.0100 R:-1.0 loss:2.1143 exploreP:0.0100\n",
      "Episode:1810 meanR:-0.0100 R:0.0 loss:2.0077 exploreP:0.0100\n",
      "Episode:1811 meanR:-0.0400 R:0.0 loss:1.8231 exploreP:0.0100\n",
      "Episode:1812 meanR:-0.0200 R:2.0 loss:1.7712 exploreP:0.0100\n",
      "Episode:1813 meanR:-0.0300 R:-1.0 loss:1.7750 exploreP:0.0100\n",
      "Episode:1814 meanR:-0.0400 R:0.0 loss:1.8305 exploreP:0.0100\n",
      "Episode:1815 meanR:-0.0100 R:1.0 loss:1.7306 exploreP:0.0100\n",
      "Episode:1816 meanR:-0.0100 R:0.0 loss:1.8238 exploreP:0.0100\n",
      "Episode:1817 meanR:0.0000 R:0.0 loss:1.9581 exploreP:0.0100\n",
      "Episode:1818 meanR:-0.0100 R:0.0 loss:1.2691 exploreP:0.0100\n",
      "Episode:1819 meanR:0.0000 R:0.0 loss:1.5063 exploreP:0.0100\n",
      "Episode:1820 meanR:-0.0100 R:-1.0 loss:1.7905 exploreP:0.0100\n",
      "Episode:1821 meanR:0.0000 R:1.0 loss:1.5551 exploreP:0.0100\n",
      "Episode:1822 meanR:0.0000 R:0.0 loss:1.7458 exploreP:0.0100\n",
      "Episode:1823 meanR:0.0000 R:0.0 loss:1.8910 exploreP:0.0100\n",
      "Episode:1824 meanR:0.0000 R:0.0 loss:1.8276 exploreP:0.0100\n",
      "Episode:1825 meanR:0.0000 R:0.0 loss:1.8959 exploreP:0.0100\n",
      "Episode:1826 meanR:0.0100 R:1.0 loss:1.7331 exploreP:0.0100\n",
      "Episode:1827 meanR:0.0000 R:-1.0 loss:1.9145 exploreP:0.0100\n",
      "Episode:1828 meanR:0.0000 R:0.0 loss:1.7833 exploreP:0.0100\n",
      "Episode:1829 meanR:-0.0100 R:-2.0 loss:1.8070 exploreP:0.0100\n",
      "Episode:1830 meanR:-0.0100 R:0.0 loss:1.7864 exploreP:0.0100\n",
      "Episode:1831 meanR:-0.0400 R:-1.0 loss:2.0388 exploreP:0.0100\n",
      "Episode:1832 meanR:-0.0400 R:0.0 loss:1.7603 exploreP:0.0100\n",
      "Episode:1833 meanR:-0.0400 R:-1.0 loss:2.0214 exploreP:0.0100\n",
      "Episode:1834 meanR:-0.0300 R:1.0 loss:1.7778 exploreP:0.0100\n",
      "Episode:1835 meanR:-0.0300 R:0.0 loss:1.6164 exploreP:0.0100\n",
      "Episode:1836 meanR:0.0000 R:2.0 loss:1.3259 exploreP:0.0100\n",
      "Episode:1837 meanR:0.0100 R:0.0 loss:1.7598 exploreP:0.0100\n",
      "Episode:1838 meanR:0.0100 R:0.0 loss:2.1585 exploreP:0.0100\n",
      "Episode:1839 meanR:0.0300 R:1.0 loss:1.9178 exploreP:0.0100\n",
      "Episode:1840 meanR:0.0300 R:0.0 loss:1.8081 exploreP:0.0100\n",
      "Episode:1841 meanR:0.0300 R:0.0 loss:1.8472 exploreP:0.0100\n",
      "Episode:1842 meanR:0.0300 R:0.0 loss:2.3276 exploreP:0.0100\n",
      "Episode:1843 meanR:0.0400 R:0.0 loss:1.9662 exploreP:0.0100\n",
      "Episode:1844 meanR:0.0400 R:1.0 loss:1.6563 exploreP:0.0100\n",
      "Episode:1845 meanR:0.0500 R:1.0 loss:1.2898 exploreP:0.0100\n",
      "Episode:1846 meanR:0.0600 R:0.0 loss:2.2873 exploreP:0.0100\n",
      "Episode:1847 meanR:0.0600 R:0.0 loss:2.0458 exploreP:0.0100\n",
      "Episode:1848 meanR:0.0600 R:1.0 loss:2.1276 exploreP:0.0100\n",
      "Episode:1849 meanR:0.0500 R:0.0 loss:1.9555 exploreP:0.0100\n",
      "Episode:1850 meanR:0.0200 R:-2.0 loss:1.8631 exploreP:0.0100\n",
      "Episode:1851 meanR:0.0200 R:0.0 loss:1.8876 exploreP:0.0100\n",
      "Episode:1852 meanR:0.0000 R:-1.0 loss:1.7822 exploreP:0.0100\n",
      "Episode:1853 meanR:0.0200 R:2.0 loss:1.6767 exploreP:0.0100\n",
      "Episode:1854 meanR:0.0100 R:-1.0 loss:1.8149 exploreP:0.0100\n",
      "Episode:1855 meanR:-0.0100 R:-1.0 loss:1.9800 exploreP:0.0100\n",
      "Episode:1856 meanR:-0.0300 R:-1.0 loss:1.9768 exploreP:0.0100\n",
      "Episode:1857 meanR:-0.0300 R:0.0 loss:1.9128 exploreP:0.0100\n",
      "Episode:1858 meanR:-0.0100 R:2.0 loss:1.7473 exploreP:0.0100\n",
      "Episode:1859 meanR:-0.0100 R:0.0 loss:1.9175 exploreP:0.0100\n",
      "Episode:1860 meanR:-0.0100 R:0.0 loss:1.8783 exploreP:0.0100\n",
      "Episode:1861 meanR:0.0000 R:0.0 loss:1.2978 exploreP:0.0100\n",
      "Episode:1862 meanR:0.0000 R:0.0 loss:1.8200 exploreP:0.0100\n",
      "Episode:1863 meanR:0.0000 R:0.0 loss:1.8874 exploreP:0.0100\n",
      "Episode:1864 meanR:0.0000 R:0.0 loss:1.0755 exploreP:0.0100\n",
      "Episode:1865 meanR:0.0100 R:0.0 loss:1.7702 exploreP:0.0100\n",
      "Episode:1866 meanR:0.0300 R:0.0 loss:1.5433 exploreP:0.0100\n",
      "Episode:1867 meanR:0.0200 R:0.0 loss:1.8276 exploreP:0.0100\n",
      "Episode:1868 meanR:0.0200 R:0.0 loss:1.8291 exploreP:0.0100\n",
      "Episode:1869 meanR:0.0200 R:0.0 loss:1.5473 exploreP:0.0100\n",
      "Episode:1870 meanR:0.0200 R:0.0 loss:1.4133 exploreP:0.0100\n",
      "Episode:1871 meanR:0.0300 R:1.0 loss:1.7343 exploreP:0.0100\n",
      "Episode:1872 meanR:0.0300 R:1.0 loss:1.7520 exploreP:0.0100\n",
      "Episode:1873 meanR:0.0300 R:0.0 loss:1.7847 exploreP:0.0100\n",
      "Episode:1874 meanR:0.0500 R:1.0 loss:1.7233 exploreP:0.0100\n",
      "Episode:1875 meanR:0.0500 R:0.0 loss:1.8818 exploreP:0.0100\n",
      "Episode:1876 meanR:0.0500 R:0.0 loss:1.9120 exploreP:0.0100\n",
      "Episode:1877 meanR:0.0500 R:0.0 loss:1.8657 exploreP:0.0100\n",
      "Episode:1878 meanR:0.0600 R:0.0 loss:2.0911 exploreP:0.0100\n",
      "Episode:1879 meanR:0.0500 R:0.0 loss:1.9488 exploreP:0.0100\n",
      "Episode:1880 meanR:0.0500 R:0.0 loss:2.0221 exploreP:0.0100\n",
      "Episode:1881 meanR:0.0600 R:0.0 loss:1.7928 exploreP:0.0100\n",
      "Episode:1882 meanR:0.0700 R:1.0 loss:1.8764 exploreP:0.0100\n",
      "Episode:1883 meanR:0.0600 R:0.0 loss:1.8371 exploreP:0.0100\n",
      "Episode:1884 meanR:0.0700 R:2.0 loss:1.7354 exploreP:0.0100\n",
      "Episode:1885 meanR:0.0700 R:0.0 loss:1.9330 exploreP:0.0100\n",
      "Episode:1886 meanR:0.0600 R:-1.0 loss:1.8640 exploreP:0.0100\n",
      "Episode:1887 meanR:0.0400 R:-1.0 loss:1.5717 exploreP:0.0100\n",
      "Episode:1888 meanR:0.0400 R:0.0 loss:2.3747 exploreP:0.0100\n",
      "Episode:1889 meanR:0.0400 R:0.0 loss:1.7247 exploreP:0.0100\n",
      "Episode:1890 meanR:0.0400 R:0.0 loss:2.2534 exploreP:0.0100\n",
      "Episode:1891 meanR:0.0400 R:0.0 loss:1.9587 exploreP:0.0100\n",
      "Episode:1892 meanR:0.0300 R:-1.0 loss:1.8999 exploreP:0.0100\n",
      "Episode:1893 meanR:0.0400 R:-1.0 loss:1.9175 exploreP:0.0100\n",
      "Episode:1894 meanR:0.0400 R:-1.0 loss:2.2980 exploreP:0.0100\n",
      "Episode:1895 meanR:0.0400 R:0.0 loss:1.8728 exploreP:0.0100\n",
      "Episode:1896 meanR:0.0400 R:0.0 loss:1.7194 exploreP:0.0100\n",
      "Episode:1897 meanR:0.0500 R:1.0 loss:1.6355 exploreP:0.0100\n",
      "Episode:1898 meanR:0.0300 R:-1.0 loss:1.8094 exploreP:0.0100\n",
      "Episode:1899 meanR:0.0300 R:0.0 loss:1.0953 exploreP:0.0100\n",
      "Episode:1900 meanR:0.0400 R:1.0 loss:1.5654 exploreP:0.0100\n",
      "Episode:1901 meanR:0.0200 R:0.0 loss:1.7379 exploreP:0.0100\n",
      "Episode:1902 meanR:0.0300 R:1.0 loss:2.1682 exploreP:0.0100\n",
      "Episode:1903 meanR:0.0300 R:0.0 loss:1.8488 exploreP:0.0100\n",
      "Episode:1904 meanR:0.0400 R:1.0 loss:1.8545 exploreP:0.0100\n",
      "Episode:1905 meanR:0.0300 R:-1.0 loss:1.9497 exploreP:0.0100\n",
      "Episode:1906 meanR:0.0400 R:-1.0 loss:1.9070 exploreP:0.0100\n",
      "Episode:1907 meanR:0.0400 R:0.0 loss:1.8424 exploreP:0.0100\n",
      "Episode:1908 meanR:0.0400 R:0.0 loss:1.8267 exploreP:0.0100\n",
      "Episode:1909 meanR:0.0500 R:0.0 loss:1.9296 exploreP:0.0100\n",
      "Episode:1910 meanR:0.0500 R:0.0 loss:1.9356 exploreP:0.0100\n",
      "Episode:1911 meanR:0.0400 R:-1.0 loss:2.1646 exploreP:0.0100\n",
      "Episode:1912 meanR:0.0200 R:0.0 loss:1.9317 exploreP:0.0100\n",
      "Episode:1913 meanR:0.0300 R:0.0 loss:1.7657 exploreP:0.0100\n",
      "Episode:1914 meanR:0.0300 R:0.0 loss:1.7027 exploreP:0.0100\n",
      "Episode:1915 meanR:0.0200 R:0.0 loss:1.9178 exploreP:0.0100\n",
      "Episode:1916 meanR:0.0100 R:-1.0 loss:1.8517 exploreP:0.0100\n",
      "Episode:1917 meanR:-0.0200 R:-3.0 loss:2.1369 exploreP:0.0100\n",
      "Episode:1918 meanR:-0.0300 R:-1.0 loss:1.8625 exploreP:0.0100\n",
      "Episode:1919 meanR:-0.0500 R:-2.0 loss:1.9000 exploreP:0.0100\n",
      "Episode:1920 meanR:-0.0300 R:1.0 loss:1.8180 exploreP:0.0100\n",
      "Episode:1921 meanR:-0.0400 R:0.0 loss:1.8960 exploreP:0.0100\n",
      "Episode:1922 meanR:-0.0400 R:0.0 loss:1.1739 exploreP:0.0100\n",
      "Episode:1923 meanR:-0.0400 R:0.0 loss:1.5942 exploreP:0.0100\n",
      "Episode:1924 meanR:-0.0400 R:0.0 loss:1.3603 exploreP:0.0100\n",
      "Episode:1925 meanR:-0.0400 R:0.0 loss:1.7596 exploreP:0.0100\n",
      "Episode:1926 meanR:-0.0500 R:0.0 loss:1.7524 exploreP:0.0100\n",
      "Episode:1927 meanR:-0.0500 R:-1.0 loss:1.8238 exploreP:0.0100\n",
      "Episode:1928 meanR:-0.0600 R:-1.0 loss:1.8899 exploreP:0.0100\n",
      "Episode:1929 meanR:-0.0300 R:1.0 loss:1.6672 exploreP:0.0100\n",
      "Episode:1930 meanR:-0.0200 R:1.0 loss:1.7565 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1931 meanR:-0.0100 R:0.0 loss:1.7744 exploreP:0.0100\n",
      "Episode:1932 meanR:-0.0100 R:0.0 loss:1.6940 exploreP:0.0100\n",
      "Episode:1933 meanR:-0.0100 R:-1.0 loss:1.4248 exploreP:0.0100\n",
      "Episode:1934 meanR:-0.0200 R:0.0 loss:1.7604 exploreP:0.0100\n",
      "Episode:1935 meanR:0.0000 R:2.0 loss:1.8475 exploreP:0.0100\n",
      "Episode:1936 meanR:-0.0200 R:0.0 loss:1.8518 exploreP:0.0100\n",
      "Episode:1937 meanR:-0.0400 R:-2.0 loss:1.9624 exploreP:0.0100\n",
      "Episode:1938 meanR:-0.0400 R:0.0 loss:1.8162 exploreP:0.0100\n",
      "Episode:1939 meanR:-0.0600 R:-1.0 loss:1.3926 exploreP:0.0100\n",
      "Episode:1940 meanR:-0.0700 R:-1.0 loss:1.8157 exploreP:0.0100\n",
      "Episode:1941 meanR:-0.0700 R:0.0 loss:1.8001 exploreP:0.0100\n",
      "Episode:1942 meanR:-0.0800 R:-1.0 loss:1.9049 exploreP:0.0100\n",
      "Episode:1943 meanR:-0.0700 R:1.0 loss:1.8417 exploreP:0.0100\n",
      "Episode:1944 meanR:-0.0800 R:0.0 loss:1.8413 exploreP:0.0100\n",
      "Episode:1945 meanR:-0.0800 R:1.0 loss:1.3323 exploreP:0.0100\n",
      "Episode:1946 meanR:-0.0800 R:0.0 loss:1.9379 exploreP:0.0100\n",
      "Episode:1947 meanR:-0.0800 R:0.0 loss:1.9381 exploreP:0.0100\n",
      "Episode:1948 meanR:-0.0900 R:0.0 loss:1.6260 exploreP:0.0100\n",
      "Episode:1949 meanR:-0.0800 R:1.0 loss:2.0105 exploreP:0.0100\n",
      "Episode:1950 meanR:-0.0500 R:1.0 loss:1.4639 exploreP:0.0100\n",
      "Episode:1951 meanR:-0.0500 R:0.0 loss:1.7174 exploreP:0.0100\n",
      "Episode:1952 meanR:-0.0500 R:-1.0 loss:2.0070 exploreP:0.0100\n",
      "Episode:1953 meanR:-0.0700 R:0.0 loss:1.9482 exploreP:0.0100\n",
      "Episode:1954 meanR:-0.0600 R:0.0 loss:2.3110 exploreP:0.0100\n",
      "Episode:1955 meanR:-0.0300 R:2.0 loss:1.9730 exploreP:0.0100\n",
      "Episode:1956 meanR:-0.0200 R:0.0 loss:1.8883 exploreP:0.0100\n",
      "Episode:1957 meanR:-0.0200 R:0.0 loss:1.8416 exploreP:0.0100\n",
      "Episode:1958 meanR:-0.0500 R:-1.0 loss:1.8900 exploreP:0.0100\n",
      "Episode:1959 meanR:-0.0500 R:0.0 loss:1.9054 exploreP:0.0100\n",
      "Episode:1960 meanR:-0.0500 R:0.0 loss:2.3692 exploreP:0.0100\n",
      "Episode:1961 meanR:-0.0500 R:0.0 loss:1.9500 exploreP:0.0100\n",
      "Episode:1962 meanR:-0.0500 R:0.0 loss:1.3745 exploreP:0.0100\n",
      "Episode:1963 meanR:-0.0500 R:0.0 loss:1.9423 exploreP:0.0100\n",
      "Episode:1964 meanR:-0.0600 R:-1.0 loss:2.0676 exploreP:0.0100\n",
      "Episode:1965 meanR:-0.0600 R:0.0 loss:2.0319 exploreP:0.0100\n",
      "Episode:1966 meanR:-0.0500 R:1.0 loss:1.4858 exploreP:0.0100\n",
      "Episode:1967 meanR:-0.0400 R:1.0 loss:1.7780 exploreP:0.0100\n",
      "Episode:1968 meanR:-0.0500 R:-1.0 loss:1.8677 exploreP:0.0100\n",
      "Episode:1969 meanR:-0.0500 R:0.0 loss:1.8684 exploreP:0.0100\n",
      "Episode:1970 meanR:-0.0500 R:0.0 loss:1.8466 exploreP:0.0100\n",
      "Episode:1971 meanR:-0.0600 R:0.0 loss:1.2009 exploreP:0.0100\n",
      "Episode:1972 meanR:-0.0700 R:0.0 loss:1.5756 exploreP:0.0100\n",
      "Episode:1973 meanR:-0.0600 R:1.0 loss:1.6903 exploreP:0.0100\n",
      "Episode:1974 meanR:-0.0800 R:-1.0 loss:1.8495 exploreP:0.0100\n",
      "Episode:1975 meanR:-0.0800 R:0.0 loss:2.4586 exploreP:0.0100\n",
      "Episode:1976 meanR:-0.0800 R:0.0 loss:2.0345 exploreP:0.0100\n",
      "Episode:1977 meanR:-0.0800 R:0.0 loss:1.7728 exploreP:0.0100\n",
      "Episode:1978 meanR:-0.0900 R:-1.0 loss:1.9144 exploreP:0.0100\n",
      "Episode:1979 meanR:-0.0800 R:1.0 loss:1.9034 exploreP:0.0100\n",
      "Episode:1980 meanR:-0.0800 R:0.0 loss:1.9392 exploreP:0.0100\n",
      "Episode:1981 meanR:-0.0800 R:0.0 loss:1.8221 exploreP:0.0100\n",
      "Episode:1982 meanR:-0.1000 R:-1.0 loss:1.9559 exploreP:0.0100\n",
      "Episode:1983 meanR:-0.1000 R:0.0 loss:1.7733 exploreP:0.0100\n",
      "Episode:1984 meanR:-0.1200 R:0.0 loss:2.1150 exploreP:0.0100\n",
      "Episode:1985 meanR:-0.1300 R:-1.0 loss:2.1156 exploreP:0.0100\n",
      "Episode:1986 meanR:-0.1400 R:-2.0 loss:1.9860 exploreP:0.0100\n",
      "Episode:1987 meanR:-0.1400 R:-1.0 loss:2.0572 exploreP:0.0100\n",
      "Episode:1988 meanR:-0.1500 R:-1.0 loss:1.7616 exploreP:0.0100\n",
      "Episode:1989 meanR:-0.1500 R:0.0 loss:1.7341 exploreP:0.0100\n",
      "Episode:1990 meanR:-0.1500 R:0.0 loss:1.4153 exploreP:0.0100\n",
      "Episode:1991 meanR:-0.1500 R:0.0 loss:1.7326 exploreP:0.0100\n",
      "Episode:1992 meanR:-0.1400 R:0.0 loss:1.8785 exploreP:0.0100\n",
      "Episode:1993 meanR:-0.1300 R:0.0 loss:2.0712 exploreP:0.0100\n",
      "Episode:1994 meanR:-0.1100 R:1.0 loss:1.8010 exploreP:0.0100\n",
      "Episode:1995 meanR:-0.1200 R:-1.0 loss:1.9637 exploreP:0.0100\n",
      "Episode:1996 meanR:-0.1100 R:1.0 loss:1.8089 exploreP:0.0100\n",
      "Episode:1997 meanR:-0.1200 R:0.0 loss:1.9689 exploreP:0.0100\n",
      "Episode:1998 meanR:-0.1100 R:0.0 loss:1.8206 exploreP:0.0100\n",
      "Episode:1999 meanR:-0.1100 R:0.0 loss:1.7423 exploreP:0.0100\n",
      "Episode:2000 meanR:-0.1300 R:-1.0 loss:1.9391 exploreP:0.0100\n",
      "Episode:2001 meanR:-0.1200 R:1.0 loss:1.7951 exploreP:0.0100\n",
      "Episode:2002 meanR:-0.1400 R:-1.0 loss:1.8191 exploreP:0.0100\n",
      "Episode:2003 meanR:-0.1300 R:1.0 loss:1.8783 exploreP:0.0100\n",
      "Episode:2004 meanR:-0.1500 R:-1.0 loss:1.8026 exploreP:0.0100\n",
      "Episode:2005 meanR:-0.1300 R:1.0 loss:1.9828 exploreP:0.0100\n",
      "Episode:2006 meanR:-0.1300 R:-1.0 loss:1.8579 exploreP:0.0100\n",
      "Episode:2007 meanR:-0.1300 R:0.0 loss:2.1012 exploreP:0.0100\n",
      "Episode:2008 meanR:-0.1300 R:0.0 loss:1.9053 exploreP:0.0100\n",
      "Episode:2009 meanR:-0.1300 R:0.0 loss:1.8697 exploreP:0.0100\n",
      "Episode:2010 meanR:-0.1400 R:-1.0 loss:1.5467 exploreP:0.0100\n",
      "Episode:2011 meanR:-0.1300 R:0.0 loss:1.6824 exploreP:0.0100\n",
      "Episode:2012 meanR:-0.1300 R:0.0 loss:1.9536 exploreP:0.0100\n",
      "Episode:2013 meanR:-0.1300 R:0.0 loss:1.6045 exploreP:0.0100\n",
      "Episode:2014 meanR:-0.1300 R:0.0 loss:1.8946 exploreP:0.0100\n",
      "Episode:2015 meanR:-0.1300 R:0.0 loss:1.1729 exploreP:0.0100\n",
      "Episode:2016 meanR:-0.1200 R:0.0 loss:1.8965 exploreP:0.0100\n",
      "Episode:2017 meanR:-0.0900 R:0.0 loss:2.3822 exploreP:0.0100\n",
      "Episode:2018 meanR:-0.0600 R:2.0 loss:2.1896 exploreP:0.0100\n",
      "Episode:2019 meanR:-0.0300 R:1.0 loss:1.8496 exploreP:0.0100\n",
      "Episode:2020 meanR:-0.0400 R:0.0 loss:1.8316 exploreP:0.0100\n",
      "Episode:2021 meanR:-0.0500 R:-1.0 loss:1.9015 exploreP:0.0100\n",
      "Episode:2022 meanR:-0.0400 R:1.0 loss:1.9483 exploreP:0.0100\n",
      "Episode:2023 meanR:-0.0400 R:0.0 loss:2.2894 exploreP:0.0100\n",
      "Episode:2024 meanR:-0.0300 R:1.0 loss:1.9226 exploreP:0.0100\n",
      "Episode:2025 meanR:-0.0400 R:-1.0 loss:1.8351 exploreP:0.0100\n",
      "Episode:2026 meanR:-0.0300 R:1.0 loss:1.7660 exploreP:0.0100\n",
      "Episode:2027 meanR:-0.0200 R:0.0 loss:1.8338 exploreP:0.0100\n",
      "Episode:2028 meanR:-0.0100 R:0.0 loss:1.8807 exploreP:0.0100\n",
      "Episode:2029 meanR:-0.0400 R:-2.0 loss:1.8345 exploreP:0.0100\n",
      "Episode:2030 meanR:-0.0500 R:0.0 loss:1.9781 exploreP:0.0100\n",
      "Episode:2031 meanR:-0.0500 R:0.0 loss:1.7388 exploreP:0.0100\n",
      "Episode:2032 meanR:-0.0600 R:-1.0 loss:1.8754 exploreP:0.0100\n",
      "Episode:2033 meanR:-0.0600 R:-1.0 loss:1.8992 exploreP:0.0100\n",
      "Episode:2034 meanR:-0.0600 R:0.0 loss:2.0270 exploreP:0.0100\n",
      "Episode:2035 meanR:-0.0900 R:-1.0 loss:1.8343 exploreP:0.0100\n",
      "Episode:2036 meanR:-0.0900 R:0.0 loss:1.9093 exploreP:0.0100\n",
      "Episode:2037 meanR:-0.0800 R:-1.0 loss:1.9154 exploreP:0.0100\n",
      "Episode:2038 meanR:-0.0900 R:-1.0 loss:1.7704 exploreP:0.0100\n",
      "Episode:2039 meanR:-0.0700 R:1.0 loss:1.8866 exploreP:0.0100\n",
      "Episode:2040 meanR:-0.0600 R:0.0 loss:1.7251 exploreP:0.0100\n",
      "Episode:2041 meanR:-0.0600 R:0.0 loss:1.6482 exploreP:0.0100\n",
      "Episode:2042 meanR:-0.0500 R:0.0 loss:1.7397 exploreP:0.0100\n",
      "Episode:2043 meanR:-0.0500 R:1.0 loss:1.9946 exploreP:0.0100\n",
      "Episode:2044 meanR:-0.0500 R:0.0 loss:2.1134 exploreP:0.0100\n",
      "Episode:2045 meanR:-0.0600 R:0.0 loss:1.8440 exploreP:0.0100\n",
      "Episode:2046 meanR:-0.0600 R:0.0 loss:1.9991 exploreP:0.0100\n",
      "Episode:2047 meanR:-0.0500 R:1.0 loss:2.0108 exploreP:0.0100\n",
      "Episode:2048 meanR:-0.0400 R:1.0 loss:1.8767 exploreP:0.0100\n",
      "Episode:2049 meanR:-0.0500 R:0.0 loss:1.6616 exploreP:0.0100\n",
      "Episode:2050 meanR:-0.0600 R:0.0 loss:1.8692 exploreP:0.0100\n",
      "Episode:2051 meanR:-0.0500 R:1.0 loss:1.8301 exploreP:0.0100\n",
      "Episode:2052 meanR:-0.0400 R:0.0 loss:1.6445 exploreP:0.0100\n",
      "Episode:2053 meanR:-0.0200 R:2.0 loss:1.8052 exploreP:0.0100\n",
      "Episode:2054 meanR:-0.0100 R:1.0 loss:1.7112 exploreP:0.0100\n",
      "Episode:2055 meanR:-0.0400 R:-1.0 loss:1.9195 exploreP:0.0100\n",
      "Episode:2056 meanR:-0.0400 R:0.0 loss:1.7088 exploreP:0.0100\n",
      "Episode:2057 meanR:-0.0400 R:0.0 loss:1.7617 exploreP:0.0100\n",
      "Episode:2058 meanR:-0.0300 R:0.0 loss:1.9345 exploreP:0.0100\n",
      "Episode:2059 meanR:-0.0200 R:1.0 loss:1.7978 exploreP:0.0100\n",
      "Episode:2060 meanR:-0.0200 R:0.0 loss:1.5645 exploreP:0.0100\n",
      "Episode:2061 meanR:-0.0200 R:0.0 loss:1.6890 exploreP:0.0100\n",
      "Episode:2062 meanR:-0.0100 R:1.0 loss:1.6815 exploreP:0.0100\n",
      "Episode:2063 meanR:-0.0200 R:-1.0 loss:1.7782 exploreP:0.0100\n",
      "Episode:2064 meanR:0.0000 R:1.0 loss:2.4487 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2065 meanR:0.0000 R:0.0 loss:2.2217 exploreP:0.0100\n",
      "Episode:2066 meanR:0.0000 R:1.0 loss:2.0053 exploreP:0.0100\n",
      "Episode:2067 meanR:-0.0100 R:0.0 loss:1.7809 exploreP:0.0100\n",
      "Episode:2068 meanR:0.0100 R:1.0 loss:1.8351 exploreP:0.0100\n",
      "Episode:2069 meanR:0.0300 R:2.0 loss:1.7192 exploreP:0.0100\n",
      "Episode:2070 meanR:0.0300 R:0.0 loss:2.2946 exploreP:0.0100\n",
      "Episode:2071 meanR:0.0400 R:1.0 loss:1.8679 exploreP:0.0100\n",
      "Episode:2072 meanR:0.0400 R:0.0 loss:1.7854 exploreP:0.0100\n",
      "Episode:2073 meanR:0.0400 R:1.0 loss:1.8096 exploreP:0.0100\n",
      "Episode:2074 meanR:0.0500 R:0.0 loss:2.0625 exploreP:0.0100\n",
      "Episode:2075 meanR:0.0500 R:0.0 loss:2.0929 exploreP:0.0100\n",
      "Episode:2076 meanR:0.0500 R:0.0 loss:1.9020 exploreP:0.0100\n",
      "Episode:2077 meanR:0.0500 R:0.0 loss:2.0081 exploreP:0.0100\n",
      "Episode:2078 meanR:0.0600 R:0.0 loss:1.6817 exploreP:0.0100\n",
      "Episode:2079 meanR:0.0500 R:0.0 loss:1.8530 exploreP:0.0100\n",
      "Episode:2080 meanR:0.0600 R:1.0 loss:1.9948 exploreP:0.0100\n",
      "Episode:2081 meanR:0.0600 R:0.0 loss:1.9692 exploreP:0.0100\n",
      "Episode:2082 meanR:0.0700 R:0.0 loss:1.7697 exploreP:0.0100\n",
      "Episode:2083 meanR:0.0800 R:1.0 loss:1.5554 exploreP:0.0100\n",
      "Episode:2084 meanR:0.0700 R:-1.0 loss:1.7469 exploreP:0.0100\n",
      "Episode:2085 meanR:0.0800 R:0.0 loss:1.9115 exploreP:0.0100\n",
      "Episode:2086 meanR:0.1000 R:0.0 loss:1.9477 exploreP:0.0100\n",
      "Episode:2087 meanR:0.1100 R:0.0 loss:1.7686 exploreP:0.0100\n",
      "Episode:2088 meanR:0.1200 R:0.0 loss:1.8140 exploreP:0.0100\n",
      "Episode:2089 meanR:0.1200 R:0.0 loss:2.0884 exploreP:0.0100\n",
      "Episode:2090 meanR:0.1200 R:0.0 loss:1.8497 exploreP:0.0100\n",
      "Episode:2091 meanR:0.1200 R:0.0 loss:1.7571 exploreP:0.0100\n",
      "Episode:2092 meanR:0.1100 R:-1.0 loss:1.8800 exploreP:0.0100\n",
      "Episode:2093 meanR:0.1100 R:0.0 loss:2.2745 exploreP:0.0100\n",
      "Episode:2094 meanR:0.1000 R:0.0 loss:1.6534 exploreP:0.0100\n",
      "Episode:2095 meanR:0.1100 R:0.0 loss:1.7271 exploreP:0.0100\n",
      "Episode:2096 meanR:0.1100 R:1.0 loss:1.7733 exploreP:0.0100\n",
      "Episode:2097 meanR:0.1000 R:-1.0 loss:1.7537 exploreP:0.0100\n",
      "Episode:2098 meanR:0.0900 R:-1.0 loss:1.4732 exploreP:0.0100\n",
      "Episode:2099 meanR:0.0900 R:0.0 loss:1.8694 exploreP:0.0100\n",
      "Episode:2100 meanR:0.1000 R:0.0 loss:1.8853 exploreP:0.0100\n",
      "Episode:2101 meanR:0.0900 R:0.0 loss:1.9309 exploreP:0.0100\n",
      "Episode:2102 meanR:0.1200 R:2.0 loss:1.8375 exploreP:0.0100\n",
      "Episode:2103 meanR:0.1100 R:0.0 loss:1.7346 exploreP:0.0100\n",
      "Episode:2104 meanR:0.1300 R:1.0 loss:1.7901 exploreP:0.0100\n",
      "Episode:2105 meanR:0.0900 R:-3.0 loss:1.8799 exploreP:0.0100\n",
      "Episode:2106 meanR:0.0900 R:-1.0 loss:1.9085 exploreP:0.0100\n",
      "Episode:2107 meanR:0.0800 R:-1.0 loss:1.9266 exploreP:0.0100\n",
      "Episode:2108 meanR:0.0700 R:-1.0 loss:1.8177 exploreP:0.0100\n",
      "Episode:2109 meanR:0.0600 R:-1.0 loss:1.8319 exploreP:0.0100\n",
      "Episode:2110 meanR:0.0700 R:0.0 loss:1.7404 exploreP:0.0100\n",
      "Episode:2111 meanR:0.0800 R:1.0 loss:1.7989 exploreP:0.0100\n",
      "Episode:2112 meanR:0.0800 R:0.0 loss:1.4120 exploreP:0.0100\n",
      "Episode:2113 meanR:0.0700 R:-1.0 loss:1.7002 exploreP:0.0100\n",
      "Episode:2114 meanR:0.0700 R:0.0 loss:1.8165 exploreP:0.0100\n",
      "Episode:2115 meanR:0.0700 R:0.0 loss:1.7242 exploreP:0.0100\n",
      "Episode:2116 meanR:0.0600 R:-1.0 loss:1.8562 exploreP:0.0100\n",
      "Episode:2117 meanR:0.0700 R:1.0 loss:1.7228 exploreP:0.0100\n",
      "Episode:2118 meanR:0.0500 R:0.0 loss:1.8296 exploreP:0.0100\n",
      "Episode:2119 meanR:0.0300 R:-1.0 loss:1.9419 exploreP:0.0100\n",
      "Episode:2120 meanR:0.0300 R:0.0 loss:1.8463 exploreP:0.0100\n",
      "Episode:2121 meanR:0.0400 R:0.0 loss:2.0652 exploreP:0.0100\n",
      "Episode:2122 meanR:0.0300 R:0.0 loss:1.6015 exploreP:0.0100\n",
      "Episode:2123 meanR:0.0300 R:0.0 loss:1.7581 exploreP:0.0100\n",
      "Episode:2124 meanR:0.0300 R:1.0 loss:1.9582 exploreP:0.0100\n",
      "Episode:2125 meanR:0.0400 R:0.0 loss:1.8095 exploreP:0.0100\n",
      "Episode:2126 meanR:0.0300 R:0.0 loss:1.8239 exploreP:0.0100\n",
      "Episode:2127 meanR:0.0300 R:0.0 loss:1.5586 exploreP:0.0100\n",
      "Episode:2128 meanR:0.0300 R:0.0 loss:2.2333 exploreP:0.0100\n",
      "Episode:2129 meanR:0.0500 R:0.0 loss:2.1062 exploreP:0.0100\n",
      "Episode:2130 meanR:0.0600 R:1.0 loss:1.8814 exploreP:0.0100\n",
      "Episode:2131 meanR:0.0600 R:0.0 loss:1.9848 exploreP:0.0100\n",
      "Episode:2132 meanR:0.0800 R:1.0 loss:2.3244 exploreP:0.0100\n",
      "Episode:2133 meanR:0.1000 R:1.0 loss:1.2838 exploreP:0.0100\n",
      "Episode:2134 meanR:0.1100 R:1.0 loss:1.5992 exploreP:0.0100\n",
      "Episode:2135 meanR:0.1000 R:-2.0 loss:1.9425 exploreP:0.0100\n",
      "Episode:2136 meanR:0.1000 R:0.0 loss:1.7837 exploreP:0.0100\n",
      "Episode:2137 meanR:0.1000 R:-1.0 loss:2.0997 exploreP:0.0100\n",
      "Episode:2138 meanR:0.1100 R:0.0 loss:1.8982 exploreP:0.0100\n",
      "Episode:2139 meanR:0.1000 R:0.0 loss:1.8597 exploreP:0.0100\n",
      "Episode:2140 meanR:0.1000 R:0.0 loss:1.9027 exploreP:0.0100\n",
      "Episode:2141 meanR:0.1000 R:0.0 loss:1.7680 exploreP:0.0100\n",
      "Episode:2142 meanR:0.1100 R:1.0 loss:1.8927 exploreP:0.0100\n",
      "Episode:2143 meanR:0.1000 R:0.0 loss:1.8637 exploreP:0.0100\n",
      "Episode:2144 meanR:0.1000 R:0.0 loss:1.8780 exploreP:0.0100\n",
      "Episode:2145 meanR:0.1000 R:0.0 loss:1.8492 exploreP:0.0100\n",
      "Episode:2146 meanR:0.1000 R:0.0 loss:1.9721 exploreP:0.0100\n",
      "Episode:2147 meanR:0.0900 R:0.0 loss:1.8351 exploreP:0.0100\n",
      "Episode:2148 meanR:0.0800 R:0.0 loss:1.7770 exploreP:0.0100\n",
      "Episode:2149 meanR:0.0800 R:0.0 loss:1.4482 exploreP:0.0100\n",
      "Episode:2150 meanR:0.0800 R:0.0 loss:1.8189 exploreP:0.0100\n",
      "Episode:2151 meanR:0.0700 R:0.0 loss:1.7874 exploreP:0.0100\n",
      "Episode:2152 meanR:0.0500 R:-2.0 loss:1.8339 exploreP:0.0100\n",
      "Episode:2153 meanR:0.0400 R:1.0 loss:1.8215 exploreP:0.0100\n",
      "Episode:2154 meanR:0.0200 R:-1.0 loss:1.8787 exploreP:0.0100\n",
      "Episode:2155 meanR:0.0200 R:-1.0 loss:1.9509 exploreP:0.0100\n",
      "Episode:2156 meanR:0.0200 R:0.0 loss:1.9087 exploreP:0.0100\n",
      "Episode:2157 meanR:0.0200 R:0.0 loss:1.9754 exploreP:0.0100\n",
      "Episode:2158 meanR:0.0200 R:0.0 loss:1.8690 exploreP:0.0100\n",
      "Episode:2159 meanR:0.0100 R:0.0 loss:1.8119 exploreP:0.0100\n",
      "Episode:2160 meanR:0.0000 R:-1.0 loss:1.9149 exploreP:0.0100\n",
      "Episode:2161 meanR:0.0000 R:0.0 loss:1.3462 exploreP:0.0100\n",
      "Episode:2162 meanR:0.0000 R:1.0 loss:1.2744 exploreP:0.0100\n",
      "Episode:2163 meanR:0.0400 R:3.0 loss:1.7424 exploreP:0.0100\n",
      "Episode:2164 meanR:0.0300 R:0.0 loss:1.8405 exploreP:0.0100\n",
      "Episode:2165 meanR:0.0200 R:-1.0 loss:1.8506 exploreP:0.0100\n",
      "Episode:2166 meanR:0.0000 R:-1.0 loss:1.8014 exploreP:0.0100\n",
      "Episode:2167 meanR:0.0100 R:1.0 loss:1.9044 exploreP:0.0100\n",
      "Episode:2168 meanR:0.0000 R:0.0 loss:1.8863 exploreP:0.0100\n",
      "Episode:2169 meanR:-0.0300 R:-1.0 loss:1.8344 exploreP:0.0100\n",
      "Episode:2170 meanR:-0.0300 R:0.0 loss:2.0101 exploreP:0.0100\n",
      "Episode:2171 meanR:-0.0400 R:0.0 loss:1.4896 exploreP:0.0100\n",
      "Episode:2172 meanR:-0.0400 R:0.0 loss:1.5683 exploreP:0.0100\n",
      "Episode:2173 meanR:-0.0500 R:0.0 loss:1.8827 exploreP:0.0100\n",
      "Episode:2174 meanR:-0.0400 R:1.0 loss:1.5362 exploreP:0.0100\n",
      "Episode:2175 meanR:-0.0500 R:-1.0 loss:2.0804 exploreP:0.0100\n",
      "Episode:2176 meanR:-0.0500 R:0.0 loss:2.2670 exploreP:0.0100\n",
      "Episode:2177 meanR:-0.0600 R:-1.0 loss:2.0341 exploreP:0.0100\n",
      "Episode:2178 meanR:-0.0600 R:0.0 loss:1.8696 exploreP:0.0100\n",
      "Episode:2179 meanR:-0.0500 R:1.0 loss:1.8175 exploreP:0.0100\n",
      "Episode:2180 meanR:-0.0600 R:0.0 loss:2.2000 exploreP:0.0100\n",
      "Episode:2181 meanR:-0.0400 R:2.0 loss:1.8970 exploreP:0.0100\n",
      "Episode:2182 meanR:-0.0400 R:0.0 loss:1.7248 exploreP:0.0100\n",
      "Episode:2183 meanR:-0.0600 R:-1.0 loss:1.9601 exploreP:0.0100\n",
      "Episode:2184 meanR:-0.0500 R:0.0 loss:1.7228 exploreP:0.0100\n",
      "Episode:2185 meanR:-0.0500 R:0.0 loss:1.8037 exploreP:0.0100\n",
      "Episode:2186 meanR:-0.0500 R:0.0 loss:1.7594 exploreP:0.0100\n",
      "Episode:2187 meanR:-0.0500 R:0.0 loss:1.6010 exploreP:0.0100\n",
      "Episode:2188 meanR:-0.0500 R:0.0 loss:1.8900 exploreP:0.0100\n",
      "Episode:2189 meanR:-0.0500 R:0.0 loss:1.8184 exploreP:0.0100\n",
      "Episode:2190 meanR:-0.0500 R:0.0 loss:1.4852 exploreP:0.0100\n",
      "Episode:2191 meanR:-0.0500 R:0.0 loss:1.6321 exploreP:0.0100\n",
      "Episode:2192 meanR:-0.0600 R:-2.0 loss:1.9071 exploreP:0.0100\n",
      "Episode:2193 meanR:-0.0600 R:0.0 loss:1.8854 exploreP:0.0100\n",
      "Episode:2194 meanR:-0.0600 R:0.0 loss:1.7345 exploreP:0.0100\n",
      "Episode:2195 meanR:-0.0600 R:0.0 loss:1.9059 exploreP:0.0100\n",
      "Episode:2196 meanR:-0.0800 R:-1.0 loss:1.8404 exploreP:0.0100\n",
      "Episode:2197 meanR:-0.0800 R:-1.0 loss:2.0866 exploreP:0.0100\n",
      "Episode:2198 meanR:-0.0700 R:0.0 loss:1.9342 exploreP:0.0100\n",
      "Episode:2199 meanR:-0.0600 R:1.0 loss:1.7517 exploreP:0.0100\n",
      "Episode:2200 meanR:-0.0700 R:-1.0 loss:1.9666 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2201 meanR:-0.0700 R:0.0 loss:1.8632 exploreP:0.0100\n",
      "Episode:2202 meanR:-0.0900 R:0.0 loss:1.9921 exploreP:0.0100\n",
      "Episode:2203 meanR:-0.0900 R:0.0 loss:1.9160 exploreP:0.0100\n",
      "Episode:2204 meanR:-0.1100 R:-1.0 loss:1.7094 exploreP:0.0100\n",
      "Episode:2205 meanR:-0.0800 R:0.0 loss:2.0058 exploreP:0.0100\n",
      "Episode:2206 meanR:-0.0700 R:0.0 loss:1.8576 exploreP:0.0100\n",
      "Episode:2207 meanR:-0.0600 R:0.0 loss:1.8283 exploreP:0.0100\n",
      "Episode:2208 meanR:-0.0500 R:0.0 loss:1.7886 exploreP:0.0100\n",
      "Episode:2209 meanR:-0.0300 R:1.0 loss:1.9200 exploreP:0.0100\n",
      "Episode:2210 meanR:-0.0300 R:0.0 loss:1.7522 exploreP:0.0100\n",
      "Episode:2211 meanR:-0.0500 R:-1.0 loss:1.7907 exploreP:0.0100\n",
      "Episode:2212 meanR:-0.0400 R:1.0 loss:1.8203 exploreP:0.0100\n",
      "Episode:2213 meanR:-0.0300 R:0.0 loss:2.2734 exploreP:0.0100\n",
      "Episode:2214 meanR:-0.0400 R:-1.0 loss:1.9416 exploreP:0.0100\n",
      "Episode:2215 meanR:-0.0300 R:1.0 loss:1.8093 exploreP:0.0100\n",
      "Episode:2216 meanR:-0.0300 R:-1.0 loss:1.6293 exploreP:0.0100\n",
      "Episode:2217 meanR:-0.0500 R:-1.0 loss:1.7076 exploreP:0.0100\n",
      "Episode:2218 meanR:-0.0500 R:0.0 loss:1.9686 exploreP:0.0100\n",
      "Episode:2219 meanR:-0.0500 R:-1.0 loss:1.7515 exploreP:0.0100\n",
      "Episode:2220 meanR:-0.0500 R:0.0 loss:1.7925 exploreP:0.0100\n",
      "Episode:2221 meanR:-0.0500 R:0.0 loss:1.7654 exploreP:0.0100\n",
      "Episode:2222 meanR:-0.0500 R:0.0 loss:2.2514 exploreP:0.0100\n",
      "Episode:2223 meanR:-0.0600 R:-1.0 loss:1.8319 exploreP:0.0100\n",
      "Episode:2224 meanR:-0.0600 R:1.0 loss:2.0700 exploreP:0.0100\n",
      "Episode:2225 meanR:-0.0600 R:0.0 loss:2.1768 exploreP:0.0100\n",
      "Episode:2226 meanR:-0.0600 R:0.0 loss:1.8721 exploreP:0.0100\n",
      "Episode:2227 meanR:-0.0600 R:0.0 loss:1.9198 exploreP:0.0100\n",
      "Episode:2228 meanR:-0.0500 R:1.0 loss:1.6715 exploreP:0.0100\n",
      "Episode:2229 meanR:-0.0400 R:1.0 loss:1.9050 exploreP:0.0100\n",
      "Episode:2230 meanR:-0.0500 R:0.0 loss:1.8927 exploreP:0.0100\n",
      "Episode:2231 meanR:-0.0500 R:0.0 loss:1.4730 exploreP:0.0100\n",
      "Episode:2232 meanR:-0.0600 R:0.0 loss:1.7246 exploreP:0.0100\n",
      "Episode:2233 meanR:-0.0800 R:-1.0 loss:1.7303 exploreP:0.0100\n",
      "Episode:2234 meanR:-0.0900 R:0.0 loss:1.7216 exploreP:0.0100\n",
      "Episode:2235 meanR:-0.0600 R:1.0 loss:1.7155 exploreP:0.0100\n",
      "Episode:2236 meanR:-0.0600 R:0.0 loss:1.9027 exploreP:0.0100\n",
      "Episode:2237 meanR:-0.0600 R:-1.0 loss:1.8430 exploreP:0.0100\n",
      "Episode:2238 meanR:-0.0600 R:0.0 loss:1.7911 exploreP:0.0100\n",
      "Episode:2239 meanR:-0.0700 R:-1.0 loss:2.0453 exploreP:0.0100\n",
      "Episode:2240 meanR:-0.0700 R:0.0 loss:1.9269 exploreP:0.0100\n",
      "Episode:2241 meanR:-0.0600 R:1.0 loss:1.4959 exploreP:0.0100\n",
      "Episode:2242 meanR:-0.0700 R:0.0 loss:1.6877 exploreP:0.0100\n",
      "Episode:2243 meanR:-0.0800 R:-1.0 loss:1.8039 exploreP:0.0100\n",
      "Episode:2244 meanR:-0.0900 R:-1.0 loss:1.9442 exploreP:0.0100\n",
      "Episode:2245 meanR:-0.0900 R:0.0 loss:1.8797 exploreP:0.0100\n",
      "Episode:2246 meanR:-0.1000 R:-1.0 loss:1.7634 exploreP:0.0100\n",
      "Episode:2247 meanR:-0.1100 R:-1.0 loss:2.5393 exploreP:0.0100\n",
      "Episode:2248 meanR:-0.1200 R:-1.0 loss:2.0614 exploreP:0.0100\n",
      "Episode:2249 meanR:-0.1200 R:0.0 loss:1.3635 exploreP:0.0100\n",
      "Episode:2250 meanR:-0.1300 R:-1.0 loss:1.8481 exploreP:0.0100\n",
      "Episode:2251 meanR:-0.1300 R:0.0 loss:1.8167 exploreP:0.0100\n",
      "Episode:2252 meanR:-0.1000 R:1.0 loss:1.9436 exploreP:0.0100\n",
      "Episode:2253 meanR:-0.1100 R:0.0 loss:1.7848 exploreP:0.0100\n",
      "Episode:2254 meanR:-0.1200 R:-2.0 loss:1.9034 exploreP:0.0100\n",
      "Episode:2255 meanR:-0.1100 R:0.0 loss:1.8107 exploreP:0.0100\n",
      "Episode:2256 meanR:-0.1100 R:0.0 loss:1.8760 exploreP:0.0100\n",
      "Episode:2257 meanR:-0.1100 R:0.0 loss:1.8593 exploreP:0.0100\n",
      "Episode:2258 meanR:-0.1300 R:-2.0 loss:1.8177 exploreP:0.0100\n",
      "Episode:2259 meanR:-0.1300 R:0.0 loss:1.9550 exploreP:0.0100\n",
      "Episode:2260 meanR:-0.1200 R:0.0 loss:1.7815 exploreP:0.0100\n",
      "Episode:2261 meanR:-0.1200 R:0.0 loss:1.8284 exploreP:0.0100\n",
      "Episode:2262 meanR:-0.1300 R:0.0 loss:1.7336 exploreP:0.0100\n",
      "Episode:2263 meanR:-0.1600 R:0.0 loss:1.8882 exploreP:0.0100\n",
      "Episode:2264 meanR:-0.1600 R:0.0 loss:1.7357 exploreP:0.0100\n",
      "Episode:2265 meanR:-0.1400 R:1.0 loss:1.8166 exploreP:0.0100\n",
      "Episode:2266 meanR:-0.1300 R:0.0 loss:2.1390 exploreP:0.0100\n",
      "Episode:2267 meanR:-0.1200 R:2.0 loss:1.5657 exploreP:0.0100\n",
      "Episode:2268 meanR:-0.1200 R:0.0 loss:1.8611 exploreP:0.0100\n",
      "Episode:2269 meanR:-0.1100 R:0.0 loss:2.1470 exploreP:0.0100\n",
      "Episode:2270 meanR:-0.1100 R:0.0 loss:2.2080 exploreP:0.0100\n",
      "Episode:2271 meanR:-0.1100 R:0.0 loss:1.8708 exploreP:0.0100\n",
      "Episode:2272 meanR:-0.1100 R:0.0 loss:1.6982 exploreP:0.0100\n",
      "Episode:2273 meanR:-0.1100 R:0.0 loss:1.8535 exploreP:0.0100\n",
      "Episode:2274 meanR:-0.1200 R:0.0 loss:2.2513 exploreP:0.0100\n",
      "Episode:2275 meanR:-0.0900 R:2.0 loss:1.9288 exploreP:0.0100\n",
      "Episode:2276 meanR:-0.0900 R:0.0 loss:2.0577 exploreP:0.0100\n",
      "Episode:2277 meanR:-0.0700 R:1.0 loss:1.8043 exploreP:0.0100\n",
      "Episode:2278 meanR:-0.0700 R:0.0 loss:1.8994 exploreP:0.0100\n",
      "Episode:2279 meanR:-0.0600 R:2.0 loss:1.9290 exploreP:0.0100\n",
      "Episode:2280 meanR:-0.0600 R:0.0 loss:1.8905 exploreP:0.0100\n",
      "Episode:2281 meanR:-0.0800 R:0.0 loss:2.4808 exploreP:0.0100\n",
      "Episode:2282 meanR:-0.0700 R:1.0 loss:2.1962 exploreP:0.0100\n",
      "Episode:2283 meanR:-0.0600 R:0.0 loss:2.1816 exploreP:0.0100\n",
      "Episode:2284 meanR:-0.0500 R:1.0 loss:1.7706 exploreP:0.0100\n",
      "Episode:2285 meanR:-0.0500 R:0.0 loss:1.6926 exploreP:0.0100\n",
      "Episode:2286 meanR:-0.0400 R:1.0 loss:1.6505 exploreP:0.0100\n",
      "Episode:2287 meanR:-0.0400 R:0.0 loss:1.7478 exploreP:0.0100\n",
      "Episode:2288 meanR:-0.0400 R:0.0 loss:1.9416 exploreP:0.0100\n",
      "Episode:2289 meanR:-0.0400 R:0.0 loss:2.0804 exploreP:0.0100\n",
      "Episode:2290 meanR:-0.0400 R:0.0 loss:1.9391 exploreP:0.0100\n",
      "Episode:2291 meanR:-0.0400 R:0.0 loss:1.7868 exploreP:0.0100\n",
      "Episode:2292 meanR:-0.0200 R:0.0 loss:1.9226 exploreP:0.0100\n",
      "Episode:2293 meanR:-0.0200 R:0.0 loss:1.8755 exploreP:0.0100\n",
      "Episode:2294 meanR:-0.0100 R:1.0 loss:2.0487 exploreP:0.0100\n",
      "Episode:2295 meanR:0.0000 R:1.0 loss:2.1063 exploreP:0.0100\n",
      "Episode:2296 meanR:0.0000 R:-1.0 loss:1.8693 exploreP:0.0100\n",
      "Episode:2297 meanR:0.0300 R:2.0 loss:1.7443 exploreP:0.0100\n",
      "Episode:2298 meanR:0.0300 R:0.0 loss:1.7994 exploreP:0.0100\n",
      "Episode:2299 meanR:0.0200 R:0.0 loss:2.0569 exploreP:0.0100\n",
      "Episode:2300 meanR:0.0200 R:-1.0 loss:1.6677 exploreP:0.0100\n",
      "Episode:2301 meanR:0.0200 R:0.0 loss:1.4497 exploreP:0.0100\n",
      "Episode:2302 meanR:0.0200 R:0.0 loss:1.5595 exploreP:0.0100\n",
      "Episode:2303 meanR:0.0200 R:0.0 loss:1.7233 exploreP:0.0100\n",
      "Episode:2304 meanR:0.0400 R:1.0 loss:1.7614 exploreP:0.0100\n",
      "Episode:2305 meanR:0.0400 R:0.0 loss:1.8828 exploreP:0.0100\n",
      "Episode:2306 meanR:0.0400 R:0.0 loss:1.8481 exploreP:0.0100\n",
      "Episode:2307 meanR:0.0500 R:1.0 loss:1.9162 exploreP:0.0100\n",
      "Episode:2308 meanR:0.0500 R:0.0 loss:2.0435 exploreP:0.0100\n",
      "Episode:2309 meanR:0.0300 R:-1.0 loss:1.7905 exploreP:0.0100\n",
      "Episode:2310 meanR:0.0400 R:1.0 loss:2.1084 exploreP:0.0100\n",
      "Episode:2311 meanR:0.0500 R:0.0 loss:1.9643 exploreP:0.0100\n",
      "Episode:2312 meanR:0.0400 R:0.0 loss:1.7690 exploreP:0.0100\n",
      "Episode:2313 meanR:0.0300 R:-1.0 loss:1.7927 exploreP:0.0100\n",
      "Episode:2314 meanR:0.0400 R:0.0 loss:1.7471 exploreP:0.0100\n",
      "Episode:2315 meanR:0.0300 R:0.0 loss:1.7091 exploreP:0.0100\n",
      "Episode:2316 meanR:0.0400 R:0.0 loss:1.7864 exploreP:0.0100\n",
      "Episode:2317 meanR:0.0400 R:-1.0 loss:1.8472 exploreP:0.0100\n",
      "Episode:2318 meanR:0.0500 R:1.0 loss:2.0138 exploreP:0.0100\n",
      "Episode:2319 meanR:0.0600 R:0.0 loss:1.8745 exploreP:0.0100\n",
      "Episode:2320 meanR:0.0600 R:0.0 loss:1.9317 exploreP:0.0100\n",
      "Episode:2321 meanR:0.0700 R:1.0 loss:1.4016 exploreP:0.0100\n",
      "Episode:2322 meanR:0.0600 R:-1.0 loss:1.6492 exploreP:0.0100\n",
      "Episode:2323 meanR:0.0700 R:0.0 loss:2.1011 exploreP:0.0100\n",
      "Episode:2324 meanR:0.0600 R:0.0 loss:2.0762 exploreP:0.0100\n",
      "Episode:2325 meanR:0.0600 R:0.0 loss:1.8325 exploreP:0.0100\n",
      "Episode:2326 meanR:0.0500 R:-1.0 loss:1.7795 exploreP:0.0100\n",
      "Episode:2327 meanR:0.0600 R:1.0 loss:1.8198 exploreP:0.0100\n",
      "Episode:2328 meanR:0.0400 R:-1.0 loss:1.8951 exploreP:0.0100\n",
      "Episode:2329 meanR:0.0200 R:-1.0 loss:2.0325 exploreP:0.0100\n",
      "Episode:2330 meanR:0.0300 R:1.0 loss:1.8768 exploreP:0.0100\n",
      "Episode:2331 meanR:0.0300 R:0.0 loss:1.8423 exploreP:0.0100\n",
      "Episode:2332 meanR:0.0400 R:1.0 loss:1.9465 exploreP:0.0100\n",
      "Episode:2333 meanR:0.0400 R:-1.0 loss:1.9363 exploreP:0.0100\n",
      "Episode:2334 meanR:0.0500 R:1.0 loss:1.7150 exploreP:0.0100\n",
      "Episode:2335 meanR:0.0400 R:0.0 loss:1.5315 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2336 meanR:0.0300 R:-1.0 loss:1.7864 exploreP:0.0100\n",
      "Episode:2337 meanR:0.0400 R:0.0 loss:1.8491 exploreP:0.0100\n",
      "Episode:2338 meanR:0.0400 R:0.0 loss:1.9557 exploreP:0.0100\n",
      "Episode:2339 meanR:0.0500 R:0.0 loss:2.2960 exploreP:0.0100\n",
      "Episode:2340 meanR:0.0500 R:0.0 loss:1.9366 exploreP:0.0100\n",
      "Episode:2341 meanR:0.0300 R:-1.0 loss:1.8702 exploreP:0.0100\n",
      "Episode:2342 meanR:0.0300 R:0.0 loss:1.7944 exploreP:0.0100\n",
      "Episode:2343 meanR:0.0500 R:1.0 loss:1.7193 exploreP:0.0100\n",
      "Episode:2344 meanR:0.0600 R:0.0 loss:1.7836 exploreP:0.0100\n",
      "Episode:2345 meanR:0.0600 R:0.0 loss:1.7988 exploreP:0.0100\n",
      "Episode:2346 meanR:0.0600 R:-1.0 loss:1.9117 exploreP:0.0100\n",
      "Episode:2347 meanR:0.0600 R:-1.0 loss:1.8982 exploreP:0.0100\n",
      "Episode:2348 meanR:0.0700 R:0.0 loss:1.8113 exploreP:0.0100\n",
      "Episode:2349 meanR:0.0700 R:0.0 loss:1.7892 exploreP:0.0100\n",
      "Episode:2350 meanR:0.0800 R:0.0 loss:1.6144 exploreP:0.0100\n",
      "Episode:2351 meanR:0.0800 R:0.0 loss:1.9677 exploreP:0.0100\n",
      "Episode:2352 meanR:0.0700 R:0.0 loss:1.9755 exploreP:0.0100\n",
      "Episode:2353 meanR:0.0500 R:-2.0 loss:2.3674 exploreP:0.0100\n",
      "Episode:2354 meanR:0.0600 R:-1.0 loss:1.8136 exploreP:0.0100\n",
      "Episode:2355 meanR:0.0600 R:0.0 loss:1.8335 exploreP:0.0100\n",
      "Episode:2356 meanR:0.0600 R:0.0 loss:1.1127 exploreP:0.0100\n",
      "Episode:2357 meanR:0.0600 R:0.0 loss:1.6768 exploreP:0.0100\n",
      "Episode:2358 meanR:0.0900 R:1.0 loss:1.2649 exploreP:0.0100\n",
      "Episode:2359 meanR:0.0900 R:0.0 loss:1.7088 exploreP:0.0100\n",
      "Episode:2360 meanR:0.0900 R:0.0 loss:1.6686 exploreP:0.0100\n",
      "Episode:2361 meanR:0.0800 R:-1.0 loss:1.7473 exploreP:0.0100\n",
      "Episode:2362 meanR:0.0800 R:0.0 loss:1.6998 exploreP:0.0100\n",
      "Episode:2363 meanR:0.0900 R:1.0 loss:2.0151 exploreP:0.0100\n",
      "Episode:2364 meanR:0.0900 R:0.0 loss:1.7659 exploreP:0.0100\n",
      "Episode:2365 meanR:0.0800 R:0.0 loss:1.8477 exploreP:0.0100\n",
      "Episode:2366 meanR:0.0700 R:-1.0 loss:2.0214 exploreP:0.0100\n",
      "Episode:2367 meanR:0.0500 R:0.0 loss:1.8614 exploreP:0.0100\n",
      "Episode:2368 meanR:0.0400 R:-1.0 loss:1.9857 exploreP:0.0100\n",
      "Episode:2369 meanR:0.0300 R:-1.0 loss:2.0305 exploreP:0.0100\n",
      "Episode:2370 meanR:0.0200 R:-1.0 loss:2.4282 exploreP:0.0100\n",
      "Episode:2371 meanR:0.0200 R:0.0 loss:2.0902 exploreP:0.0100\n",
      "Episode:2372 meanR:0.0200 R:0.0 loss:1.8973 exploreP:0.0100\n",
      "Episode:2373 meanR:0.0200 R:0.0 loss:1.8785 exploreP:0.0100\n",
      "Episode:2374 meanR:0.0200 R:0.0 loss:1.8878 exploreP:0.0100\n",
      "Episode:2375 meanR:0.0100 R:1.0 loss:2.1806 exploreP:0.0100\n",
      "Episode:2376 meanR:0.0200 R:1.0 loss:1.8978 exploreP:0.0100\n",
      "Episode:2377 meanR:0.0100 R:0.0 loss:1.8656 exploreP:0.0100\n",
      "Episode:2378 meanR:0.0300 R:2.0 loss:1.7243 exploreP:0.0100\n",
      "Episode:2379 meanR:0.0100 R:0.0 loss:1.8222 exploreP:0.0100\n",
      "Episode:2380 meanR:0.0000 R:-1.0 loss:1.8362 exploreP:0.0100\n",
      "Episode:2381 meanR:0.0000 R:0.0 loss:1.8588 exploreP:0.0100\n",
      "Episode:2382 meanR:0.0000 R:1.0 loss:1.9102 exploreP:0.0100\n",
      "Episode:2383 meanR:0.0000 R:0.0 loss:2.2265 exploreP:0.0100\n",
      "Episode:2384 meanR:-0.0100 R:0.0 loss:1.8972 exploreP:0.0100\n",
      "Episode:2385 meanR:-0.0100 R:0.0 loss:1.6423 exploreP:0.0100\n",
      "Episode:2386 meanR:-0.0200 R:0.0 loss:1.7489 exploreP:0.0100\n",
      "Episode:2387 meanR:0.0000 R:2.0 loss:1.9075 exploreP:0.0100\n",
      "Episode:2388 meanR:0.0000 R:0.0 loss:1.5969 exploreP:0.0100\n",
      "Episode:2389 meanR:0.0000 R:0.0 loss:1.8250 exploreP:0.0100\n",
      "Episode:2390 meanR:0.0100 R:1.0 loss:1.8538 exploreP:0.0100\n",
      "Episode:2391 meanR:0.0200 R:1.0 loss:1.5018 exploreP:0.0100\n",
      "Episode:2392 meanR:0.0200 R:0.0 loss:1.8866 exploreP:0.0100\n",
      "Episode:2393 meanR:0.0200 R:0.0 loss:1.8893 exploreP:0.0100\n",
      "Episode:2394 meanR:0.0000 R:-1.0 loss:1.7935 exploreP:0.0100\n",
      "Episode:2395 meanR:0.0000 R:1.0 loss:1.5580 exploreP:0.0100\n",
      "Episode:2396 meanR:0.0100 R:0.0 loss:1.7417 exploreP:0.0100\n",
      "Episode:2397 meanR:-0.0100 R:0.0 loss:1.7060 exploreP:0.0100\n",
      "Episode:2398 meanR:-0.0100 R:0.0 loss:2.3377 exploreP:0.0100\n",
      "Episode:2399 meanR:-0.0200 R:-1.0 loss:1.9716 exploreP:0.0100\n",
      "Episode:2400 meanR:-0.0100 R:0.0 loss:1.8636 exploreP:0.0100\n",
      "Episode:2401 meanR:-0.0100 R:0.0 loss:2.2244 exploreP:0.0100\n",
      "Episode:2402 meanR:-0.0100 R:0.0 loss:1.9312 exploreP:0.0100\n",
      "Episode:2403 meanR:-0.0100 R:0.0 loss:2.0232 exploreP:0.0100\n",
      "Episode:2404 meanR:-0.0200 R:0.0 loss:2.0174 exploreP:0.0100\n",
      "Episode:2405 meanR:-0.0100 R:1.0 loss:1.8719 exploreP:0.0100\n",
      "Episode:2406 meanR:0.0000 R:1.0 loss:1.0504 exploreP:0.0100\n",
      "Episode:2407 meanR:-0.0100 R:0.0 loss:1.6547 exploreP:0.0100\n",
      "Episode:2408 meanR:-0.0100 R:0.0 loss:1.7789 exploreP:0.0100\n",
      "Episode:2409 meanR:0.0100 R:1.0 loss:1.8260 exploreP:0.0100\n",
      "Episode:2410 meanR:0.0100 R:1.0 loss:1.7541 exploreP:0.0100\n",
      "Episode:2411 meanR:-0.0100 R:-2.0 loss:1.9235 exploreP:0.0100\n",
      "Episode:2412 meanR:0.0000 R:1.0 loss:1.7686 exploreP:0.0100\n",
      "Episode:2413 meanR:0.0100 R:0.0 loss:2.1088 exploreP:0.0100\n",
      "Episode:2414 meanR:0.0100 R:0.0 loss:1.6118 exploreP:0.0100\n",
      "Episode:2415 meanR:0.0300 R:2.0 loss:1.7702 exploreP:0.0100\n",
      "Episode:2416 meanR:0.0100 R:-2.0 loss:1.8317 exploreP:0.0100\n",
      "Episode:2417 meanR:0.0200 R:0.0 loss:1.8719 exploreP:0.0100\n",
      "Episode:2418 meanR:0.0100 R:0.0 loss:2.2596 exploreP:0.0100\n",
      "Episode:2419 meanR:0.0100 R:0.0 loss:1.2201 exploreP:0.0100\n",
      "Episode:2420 meanR:0.0200 R:1.0 loss:1.4919 exploreP:0.0100\n",
      "Episode:2421 meanR:0.0100 R:0.0 loss:1.8920 exploreP:0.0100\n",
      "Episode:2422 meanR:0.0200 R:0.0 loss:1.8772 exploreP:0.0100\n",
      "Episode:2423 meanR:0.0200 R:0.0 loss:1.8455 exploreP:0.0100\n",
      "Episode:2424 meanR:0.0300 R:1.0 loss:1.7631 exploreP:0.0100\n",
      "Episode:2425 meanR:0.0400 R:1.0 loss:1.5783 exploreP:0.0100\n",
      "Episode:2426 meanR:0.0500 R:0.0 loss:2.0349 exploreP:0.0100\n",
      "Episode:2427 meanR:0.0600 R:2.0 loss:1.9659 exploreP:0.0100\n",
      "Episode:2428 meanR:0.0900 R:2.0 loss:1.8237 exploreP:0.0100\n",
      "Episode:2429 meanR:0.1000 R:0.0 loss:1.9638 exploreP:0.0100\n",
      "Episode:2430 meanR:0.0800 R:-1.0 loss:1.9245 exploreP:0.0100\n",
      "Episode:2431 meanR:0.0800 R:0.0 loss:1.9742 exploreP:0.0100\n",
      "Episode:2432 meanR:0.0700 R:0.0 loss:1.9201 exploreP:0.0100\n",
      "Episode:2433 meanR:0.0800 R:0.0 loss:2.1160 exploreP:0.0100\n",
      "Episode:2434 meanR:0.0800 R:1.0 loss:1.9528 exploreP:0.0100\n",
      "Episode:2435 meanR:0.0700 R:-1.0 loss:1.8269 exploreP:0.0100\n",
      "Episode:2436 meanR:0.0800 R:0.0 loss:1.9088 exploreP:0.0100\n",
      "Episode:2437 meanR:0.0900 R:1.0 loss:1.7848 exploreP:0.0100\n",
      "Episode:2438 meanR:0.0900 R:0.0 loss:1.8065 exploreP:0.0100\n",
      "Episode:2439 meanR:0.0900 R:0.0 loss:1.8693 exploreP:0.0100\n",
      "Episode:2440 meanR:0.0900 R:0.0 loss:1.8181 exploreP:0.0100\n",
      "Episode:2441 meanR:0.0900 R:-1.0 loss:1.8989 exploreP:0.0100\n",
      "Episode:2442 meanR:0.0900 R:0.0 loss:1.9824 exploreP:0.0100\n",
      "Episode:2443 meanR:0.0800 R:0.0 loss:1.8742 exploreP:0.0100\n",
      "Episode:2444 meanR:0.0900 R:1.0 loss:1.8898 exploreP:0.0100\n",
      "Episode:2445 meanR:0.0900 R:0.0 loss:1.9610 exploreP:0.0100\n",
      "Episode:2446 meanR:0.0800 R:-2.0 loss:1.8330 exploreP:0.0100\n",
      "Episode:2447 meanR:0.0900 R:0.0 loss:1.8772 exploreP:0.0100\n",
      "Episode:2448 meanR:0.0900 R:0.0 loss:2.2828 exploreP:0.0100\n",
      "Episode:2449 meanR:0.0900 R:0.0 loss:1.7684 exploreP:0.0100\n",
      "Episode:2450 meanR:0.1000 R:1.0 loss:1.7985 exploreP:0.0100\n",
      "Episode:2451 meanR:0.1100 R:1.0 loss:1.9248 exploreP:0.0100\n",
      "Episode:2452 meanR:0.1200 R:1.0 loss:1.5501 exploreP:0.0100\n",
      "Episode:2453 meanR:0.1400 R:0.0 loss:1.8047 exploreP:0.0100\n",
      "Episode:2454 meanR:0.1400 R:-1.0 loss:1.8111 exploreP:0.0100\n",
      "Episode:2455 meanR:0.1400 R:0.0 loss:1.8350 exploreP:0.0100\n",
      "Episode:2456 meanR:0.1400 R:0.0 loss:1.7008 exploreP:0.0100\n",
      "Episode:2457 meanR:0.1500 R:1.0 loss:1.5865 exploreP:0.0100\n",
      "Episode:2458 meanR:0.1400 R:0.0 loss:1.9112 exploreP:0.0100\n",
      "Episode:2459 meanR:0.1400 R:0.0 loss:1.8507 exploreP:0.0100\n",
      "Episode:2460 meanR:0.1400 R:0.0 loss:1.8955 exploreP:0.0100\n",
      "Episode:2461 meanR:0.1500 R:0.0 loss:1.8547 exploreP:0.0100\n",
      "Episode:2462 meanR:0.1500 R:0.0 loss:1.6537 exploreP:0.0100\n",
      "Episode:2463 meanR:0.1500 R:1.0 loss:1.7679 exploreP:0.0100\n",
      "Episode:2464 meanR:0.1400 R:-1.0 loss:1.8120 exploreP:0.0100\n",
      "Episode:2465 meanR:0.1400 R:0.0 loss:1.9084 exploreP:0.0100\n",
      "Episode:2466 meanR:0.1500 R:0.0 loss:1.7692 exploreP:0.0100\n",
      "Episode:2467 meanR:0.1400 R:-1.0 loss:1.9755 exploreP:0.0100\n",
      "Episode:2468 meanR:0.1400 R:-1.0 loss:1.9876 exploreP:0.0100\n",
      "Episode:2469 meanR:0.1500 R:0.0 loss:1.9769 exploreP:0.0100\n",
      "Episode:2470 meanR:0.1500 R:-1.0 loss:1.5363 exploreP:0.0100\n",
      "Episode:2471 meanR:0.1400 R:-1.0 loss:1.9218 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2472 meanR:0.1400 R:0.0 loss:2.0053 exploreP:0.0100\n",
      "Episode:2473 meanR:0.1400 R:0.0 loss:2.2246 exploreP:0.0100\n",
      "Episode:2474 meanR:0.1400 R:0.0 loss:1.8066 exploreP:0.0100\n",
      "Episode:2475 meanR:0.1400 R:1.0 loss:1.8534 exploreP:0.0100\n",
      "Episode:2476 meanR:0.1400 R:1.0 loss:1.6716 exploreP:0.0100\n",
      "Episode:2477 meanR:0.1400 R:0.0 loss:1.7945 exploreP:0.0100\n",
      "Episode:2478 meanR:0.1200 R:0.0 loss:1.9872 exploreP:0.0100\n",
      "Episode:2479 meanR:0.1200 R:0.0 loss:1.9332 exploreP:0.0100\n",
      "Episode:2480 meanR:0.1300 R:0.0 loss:1.9141 exploreP:0.0100\n",
      "Episode:2481 meanR:0.1300 R:0.0 loss:1.6415 exploreP:0.0100\n",
      "Episode:2482 meanR:0.1200 R:0.0 loss:1.7747 exploreP:0.0100\n",
      "Episode:2483 meanR:0.1300 R:1.0 loss:1.6379 exploreP:0.0100\n",
      "Episode:2484 meanR:0.1300 R:0.0 loss:1.8249 exploreP:0.0100\n",
      "Episode:2485 meanR:0.1300 R:0.0 loss:1.8341 exploreP:0.0100\n",
      "Episode:2486 meanR:0.1400 R:1.0 loss:1.3531 exploreP:0.0100\n",
      "Episode:2487 meanR:0.1400 R:2.0 loss:1.8930 exploreP:0.0100\n",
      "Episode:2488 meanR:0.1400 R:0.0 loss:2.0954 exploreP:0.0100\n",
      "Episode:2489 meanR:0.1300 R:-1.0 loss:2.0835 exploreP:0.0100\n",
      "Episode:2490 meanR:0.1200 R:0.0 loss:1.8566 exploreP:0.0100\n",
      "Episode:2491 meanR:0.1100 R:0.0 loss:1.9278 exploreP:0.0100\n",
      "Episode:2492 meanR:0.1100 R:0.0 loss:1.8186 exploreP:0.0100\n",
      "Episode:2493 meanR:0.1100 R:0.0 loss:2.0377 exploreP:0.0100\n",
      "Episode:2494 meanR:0.1400 R:2.0 loss:1.7054 exploreP:0.0100\n",
      "Episode:2495 meanR:0.1300 R:0.0 loss:1.7274 exploreP:0.0100\n",
      "Episode:2496 meanR:0.1300 R:0.0 loss:1.8045 exploreP:0.0100\n",
      "Episode:2497 meanR:0.1200 R:-1.0 loss:2.0739 exploreP:0.0100\n",
      "Episode:2498 meanR:0.1200 R:0.0 loss:1.8751 exploreP:0.0100\n",
      "Episode:2499 meanR:0.1400 R:1.0 loss:1.8295 exploreP:0.0100\n",
      "Episode:2500 meanR:0.1400 R:0.0 loss:2.0793 exploreP:0.0100\n",
      "Episode:2501 meanR:0.1500 R:1.0 loss:1.7574 exploreP:0.0100\n",
      "Episode:2502 meanR:0.1500 R:0.0 loss:1.8058 exploreP:0.0100\n",
      "Episode:2503 meanR:0.1500 R:0.0 loss:1.7614 exploreP:0.0100\n",
      "Episode:2504 meanR:0.1600 R:1.0 loss:1.3536 exploreP:0.0100\n",
      "Episode:2505 meanR:0.1700 R:2.0 loss:1.7942 exploreP:0.0100\n",
      "Episode:2506 meanR:0.1600 R:0.0 loss:1.5111 exploreP:0.0100\n",
      "Episode:2507 meanR:0.1300 R:-3.0 loss:1.8432 exploreP:0.0100\n",
      "Episode:2508 meanR:0.1300 R:0.0 loss:2.4343 exploreP:0.0100\n",
      "Episode:2509 meanR:0.1200 R:0.0 loss:2.1355 exploreP:0.0100\n",
      "Episode:2510 meanR:0.1100 R:0.0 loss:2.0336 exploreP:0.0100\n",
      "Episode:2511 meanR:0.1300 R:0.0 loss:2.1840 exploreP:0.0100\n",
      "Episode:2512 meanR:0.1300 R:1.0 loss:1.7088 exploreP:0.0100\n",
      "Episode:2513 meanR:0.1300 R:0.0 loss:2.1996 exploreP:0.0100\n",
      "Episode:2514 meanR:0.1300 R:0.0 loss:1.7149 exploreP:0.0100\n",
      "Episode:2515 meanR:0.1100 R:0.0 loss:1.9999 exploreP:0.0100\n",
      "Episode:2516 meanR:0.1200 R:-1.0 loss:2.0947 exploreP:0.0100\n",
      "Episode:2517 meanR:0.1200 R:0.0 loss:2.0139 exploreP:0.0100\n",
      "Episode:2518 meanR:0.1100 R:-1.0 loss:1.8301 exploreP:0.0100\n",
      "Episode:2519 meanR:0.1100 R:0.0 loss:2.0426 exploreP:0.0100\n",
      "Episode:2520 meanR:0.1000 R:0.0 loss:1.8748 exploreP:0.0100\n",
      "Episode:2521 meanR:0.1200 R:2.0 loss:1.5393 exploreP:0.0100\n",
      "Episode:2522 meanR:0.1300 R:1.0 loss:1.7088 exploreP:0.0100\n",
      "Episode:2523 meanR:0.1300 R:0.0 loss:1.8131 exploreP:0.0100\n",
      "Episode:2524 meanR:0.1100 R:-1.0 loss:1.9992 exploreP:0.0100\n",
      "Episode:2525 meanR:0.0900 R:-1.0 loss:1.8462 exploreP:0.0100\n",
      "Episode:2526 meanR:0.0800 R:-1.0 loss:1.9558 exploreP:0.0100\n",
      "Episode:2527 meanR:0.0600 R:0.0 loss:1.8128 exploreP:0.0100\n",
      "Episode:2528 meanR:0.0300 R:-1.0 loss:1.8975 exploreP:0.0100\n",
      "Episode:2529 meanR:0.0400 R:1.0 loss:1.8351 exploreP:0.0100\n",
      "Episode:2530 meanR:0.0600 R:1.0 loss:1.3698 exploreP:0.0100\n",
      "Episode:2531 meanR:0.0500 R:-1.0 loss:1.9378 exploreP:0.0100\n",
      "Episode:2532 meanR:0.0500 R:0.0 loss:2.1733 exploreP:0.0100\n",
      "Episode:2533 meanR:0.0500 R:0.0 loss:1.7768 exploreP:0.0100\n",
      "Episode:2534 meanR:0.0400 R:0.0 loss:2.1543 exploreP:0.0100\n",
      "Episode:2535 meanR:0.0500 R:0.0 loss:1.9648 exploreP:0.0100\n",
      "Episode:2536 meanR:0.0600 R:1.0 loss:1.9235 exploreP:0.0100\n",
      "Episode:2537 meanR:0.0700 R:2.0 loss:2.0701 exploreP:0.0100\n",
      "Episode:2538 meanR:0.0800 R:1.0 loss:1.7850 exploreP:0.0100\n",
      "Episode:2539 meanR:0.0900 R:1.0 loss:1.7566 exploreP:0.0100\n",
      "Episode:2540 meanR:0.0900 R:0.0 loss:1.8179 exploreP:0.0100\n",
      "Episode:2541 meanR:0.1100 R:1.0 loss:1.9585 exploreP:0.0100\n",
      "Episode:2542 meanR:0.1100 R:0.0 loss:2.1185 exploreP:0.0100\n",
      "Episode:2543 meanR:0.1100 R:0.0 loss:1.8797 exploreP:0.0100\n",
      "Episode:2544 meanR:0.1000 R:0.0 loss:1.8130 exploreP:0.0100\n",
      "Episode:2545 meanR:0.1000 R:0.0 loss:2.0598 exploreP:0.0100\n",
      "Episode:2546 meanR:0.1200 R:0.0 loss:1.9498 exploreP:0.0100\n",
      "Episode:2547 meanR:0.1300 R:1.0 loss:1.4335 exploreP:0.0100\n",
      "Episode:2548 meanR:0.1200 R:-1.0 loss:1.9670 exploreP:0.0100\n",
      "Episode:2549 meanR:0.1200 R:0.0 loss:1.6860 exploreP:0.0100\n",
      "Episode:2550 meanR:0.1100 R:0.0 loss:2.0337 exploreP:0.0100\n",
      "Episode:2551 meanR:0.1100 R:1.0 loss:2.0271 exploreP:0.0100\n",
      "Episode:2552 meanR:0.1000 R:0.0 loss:2.5968 exploreP:0.0100\n",
      "Episode:2553 meanR:0.0900 R:-1.0 loss:1.9902 exploreP:0.0100\n",
      "Episode:2554 meanR:0.1000 R:0.0 loss:1.9536 exploreP:0.0100\n",
      "Episode:2555 meanR:0.1000 R:0.0 loss:2.1949 exploreP:0.0100\n",
      "Episode:2556 meanR:0.1000 R:0.0 loss:1.9916 exploreP:0.0100\n",
      "Episode:2557 meanR:0.0900 R:0.0 loss:1.7549 exploreP:0.0100\n",
      "Episode:2558 meanR:0.0900 R:0.0 loss:2.1388 exploreP:0.0100\n",
      "Episode:2559 meanR:0.0800 R:-1.0 loss:1.8615 exploreP:0.0100\n",
      "Episode:2560 meanR:0.0900 R:1.0 loss:2.1611 exploreP:0.0100\n",
      "Episode:2561 meanR:0.0800 R:-1.0 loss:1.8847 exploreP:0.0100\n",
      "Episode:2562 meanR:0.0800 R:0.0 loss:1.9499 exploreP:0.0100\n",
      "Episode:2563 meanR:0.0700 R:0.0 loss:1.4371 exploreP:0.0100\n",
      "Episode:2564 meanR:0.0900 R:1.0 loss:1.6337 exploreP:0.0100\n",
      "Episode:2565 meanR:0.0900 R:0.0 loss:1.8751 exploreP:0.0100\n",
      "Episode:2566 meanR:0.0800 R:-1.0 loss:1.7740 exploreP:0.0100\n",
      "Episode:2567 meanR:0.0700 R:-2.0 loss:1.7695 exploreP:0.0100\n",
      "Episode:2568 meanR:0.0800 R:0.0 loss:1.6613 exploreP:0.0100\n",
      "Episode:2569 meanR:0.0800 R:0.0 loss:1.8383 exploreP:0.0100\n",
      "Episode:2570 meanR:0.1000 R:1.0 loss:1.8469 exploreP:0.0100\n",
      "Episode:2571 meanR:0.1100 R:0.0 loss:1.7109 exploreP:0.0100\n",
      "Episode:2572 meanR:0.1100 R:0.0 loss:1.8896 exploreP:0.0100\n",
      "Episode:2573 meanR:0.1000 R:-1.0 loss:1.8931 exploreP:0.0100\n",
      "Episode:2574 meanR:0.1000 R:0.0 loss:1.6639 exploreP:0.0100\n",
      "Episode:2575 meanR:0.0900 R:0.0 loss:1.8489 exploreP:0.0100\n",
      "Episode:2576 meanR:0.0700 R:-1.0 loss:1.8661 exploreP:0.0100\n",
      "Episode:2577 meanR:0.0700 R:0.0 loss:2.1739 exploreP:0.0100\n",
      "Episode:2578 meanR:0.0800 R:1.0 loss:2.0909 exploreP:0.0100\n",
      "Episode:2579 meanR:0.0800 R:0.0 loss:2.1909 exploreP:0.0100\n",
      "Episode:2580 meanR:0.0900 R:1.0 loss:2.0305 exploreP:0.0100\n",
      "Episode:2581 meanR:0.0900 R:0.0 loss:2.4520 exploreP:0.0100\n",
      "Episode:2582 meanR:0.1100 R:2.0 loss:1.8939 exploreP:0.0100\n",
      "Episode:2583 meanR:0.1000 R:0.0 loss:1.7019 exploreP:0.0100\n",
      "Episode:2584 meanR:0.1200 R:2.0 loss:1.8146 exploreP:0.0100\n",
      "Episode:2585 meanR:0.1400 R:2.0 loss:1.6524 exploreP:0.0100\n",
      "Episode:2586 meanR:0.1300 R:0.0 loss:1.8268 exploreP:0.0100\n",
      "Episode:2587 meanR:0.1100 R:0.0 loss:1.8356 exploreP:0.0100\n",
      "Episode:2588 meanR:0.1000 R:-1.0 loss:1.9398 exploreP:0.0100\n",
      "Episode:2589 meanR:0.1100 R:0.0 loss:1.7973 exploreP:0.0100\n",
      "Episode:2590 meanR:0.1100 R:0.0 loss:1.6651 exploreP:0.0100\n",
      "Episode:2591 meanR:0.1200 R:1.0 loss:1.6472 exploreP:0.0100\n",
      "Episode:2592 meanR:0.1100 R:-1.0 loss:2.1366 exploreP:0.0100\n",
      "Episode:2593 meanR:0.1100 R:0.0 loss:1.8616 exploreP:0.0100\n",
      "Episode:2594 meanR:0.1000 R:1.0 loss:1.7118 exploreP:0.0100\n",
      "Episode:2595 meanR:0.1100 R:1.0 loss:1.6899 exploreP:0.0100\n",
      "Episode:2596 meanR:0.1100 R:0.0 loss:2.0404 exploreP:0.0100\n",
      "Episode:2597 meanR:0.1400 R:2.0 loss:1.8907 exploreP:0.0100\n",
      "Episode:2598 meanR:0.1400 R:0.0 loss:2.0961 exploreP:0.0100\n",
      "Episode:2599 meanR:0.1100 R:-2.0 loss:2.0110 exploreP:0.0100\n",
      "Episode:2600 meanR:0.1100 R:0.0 loss:1.7745 exploreP:0.0100\n",
      "Episode:2601 meanR:0.1000 R:0.0 loss:1.9062 exploreP:0.0100\n",
      "Episode:2602 meanR:0.1100 R:1.0 loss:1.8526 exploreP:0.0100\n",
      "Episode:2603 meanR:0.1100 R:0.0 loss:1.8532 exploreP:0.0100\n",
      "Episode:2604 meanR:0.1000 R:0.0 loss:1.2930 exploreP:0.0100\n",
      "Episode:2605 meanR:0.0800 R:0.0 loss:1.7411 exploreP:0.0100\n",
      "Episode:2606 meanR:0.0900 R:1.0 loss:1.8025 exploreP:0.0100\n",
      "Episode:2607 meanR:0.1200 R:0.0 loss:2.0069 exploreP:0.0100\n",
      "Episode:2608 meanR:0.1200 R:0.0 loss:1.8412 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2609 meanR:0.1200 R:0.0 loss:2.0363 exploreP:0.0100\n",
      "Episode:2610 meanR:0.1300 R:1.0 loss:1.7624 exploreP:0.0100\n",
      "Episode:2611 meanR:0.1500 R:2.0 loss:1.9283 exploreP:0.0100\n",
      "Episode:2612 meanR:0.1400 R:0.0 loss:1.0947 exploreP:0.0100\n",
      "Episode:2613 meanR:0.1400 R:0.0 loss:1.6462 exploreP:0.0100\n",
      "Episode:2614 meanR:0.1400 R:0.0 loss:1.6206 exploreP:0.0100\n",
      "Episode:2615 meanR:0.1200 R:-2.0 loss:1.8519 exploreP:0.0100\n",
      "Episode:2616 meanR:0.1300 R:0.0 loss:1.7139 exploreP:0.0100\n",
      "Episode:2617 meanR:0.1400 R:1.0 loss:2.0306 exploreP:0.0100\n",
      "Episode:2618 meanR:0.1500 R:0.0 loss:1.7264 exploreP:0.0100\n",
      "Episode:2619 meanR:0.1500 R:0.0 loss:1.7303 exploreP:0.0100\n",
      "Episode:2620 meanR:0.1600 R:1.0 loss:1.8804 exploreP:0.0100\n",
      "Episode:2621 meanR:0.1400 R:0.0 loss:1.9588 exploreP:0.0100\n",
      "Episode:2622 meanR:0.1200 R:-1.0 loss:1.9020 exploreP:0.0100\n",
      "Episode:2623 meanR:0.1200 R:0.0 loss:2.0338 exploreP:0.0100\n",
      "Episode:2624 meanR:0.1400 R:1.0 loss:1.7522 exploreP:0.0100\n",
      "Episode:2625 meanR:0.1500 R:0.0 loss:1.8047 exploreP:0.0100\n",
      "Episode:2626 meanR:0.1600 R:0.0 loss:1.9870 exploreP:0.0100\n",
      "Episode:2627 meanR:0.1500 R:-1.0 loss:1.7850 exploreP:0.0100\n",
      "Episode:2628 meanR:0.1600 R:0.0 loss:1.7288 exploreP:0.0100\n",
      "Episode:2629 meanR:0.1500 R:0.0 loss:1.7864 exploreP:0.0100\n",
      "Episode:2630 meanR:0.1400 R:0.0 loss:1.9870 exploreP:0.0100\n",
      "Episode:2631 meanR:0.1500 R:0.0 loss:1.9345 exploreP:0.0100\n",
      "Episode:2632 meanR:0.1500 R:0.0 loss:1.8364 exploreP:0.0100\n",
      "Episode:2633 meanR:0.1600 R:1.0 loss:2.0515 exploreP:0.0100\n",
      "Episode:2634 meanR:0.1600 R:0.0 loss:1.8714 exploreP:0.0100\n",
      "Episode:2635 meanR:0.1700 R:1.0 loss:2.0661 exploreP:0.0100\n",
      "Episode:2636 meanR:0.1600 R:0.0 loss:1.9775 exploreP:0.0100\n",
      "Episode:2637 meanR:0.1700 R:3.0 loss:1.7948 exploreP:0.0100\n",
      "Episode:2638 meanR:0.1700 R:1.0 loss:1.7586 exploreP:0.0100\n",
      "Episode:2639 meanR:0.1600 R:0.0 loss:1.8782 exploreP:0.0100\n",
      "Episode:2640 meanR:0.1600 R:0.0 loss:1.8844 exploreP:0.0100\n",
      "Episode:2641 meanR:0.1300 R:-2.0 loss:1.8838 exploreP:0.0100\n",
      "Episode:2642 meanR:0.1300 R:0.0 loss:1.9674 exploreP:0.0100\n",
      "Episode:2643 meanR:0.1500 R:2.0 loss:1.6255 exploreP:0.0100\n",
      "Episode:2644 meanR:0.1500 R:0.0 loss:1.5945 exploreP:0.0100\n",
      "Episode:2645 meanR:0.1500 R:0.0 loss:1.4299 exploreP:0.0100\n",
      "Episode:2646 meanR:0.1400 R:-1.0 loss:1.8557 exploreP:0.0100\n",
      "Episode:2647 meanR:0.1400 R:1.0 loss:1.9713 exploreP:0.0100\n",
      "Episode:2648 meanR:0.1600 R:1.0 loss:2.3729 exploreP:0.0100\n",
      "Episode:2649 meanR:0.1500 R:-1.0 loss:1.9973 exploreP:0.0100\n",
      "Episode:2650 meanR:0.1600 R:1.0 loss:1.8374 exploreP:0.0100\n",
      "Episode:2651 meanR:0.1800 R:3.0 loss:1.8532 exploreP:0.0100\n",
      "Episode:2652 meanR:0.1700 R:-1.0 loss:1.8248 exploreP:0.0100\n",
      "Episode:2653 meanR:0.1800 R:0.0 loss:1.7916 exploreP:0.0100\n",
      "Episode:2654 meanR:0.2000 R:2.0 loss:1.8111 exploreP:0.0100\n",
      "Episode:2655 meanR:0.1900 R:-1.0 loss:1.8405 exploreP:0.0100\n",
      "Episode:2656 meanR:0.2000 R:1.0 loss:1.8078 exploreP:0.0100\n",
      "Episode:2657 meanR:0.2000 R:0.0 loss:1.9946 exploreP:0.0100\n",
      "Episode:2658 meanR:0.2100 R:1.0 loss:1.7880 exploreP:0.0100\n",
      "Episode:2659 meanR:0.2200 R:0.0 loss:1.6466 exploreP:0.0100\n",
      "Episode:2660 meanR:0.2100 R:0.0 loss:1.2172 exploreP:0.0100\n",
      "Episode:2661 meanR:0.2200 R:0.0 loss:1.2168 exploreP:0.0100\n",
      "Episode:2662 meanR:0.2100 R:-1.0 loss:1.7117 exploreP:0.0100\n",
      "Episode:2663 meanR:0.2000 R:-1.0 loss:1.9674 exploreP:0.0100\n",
      "Episode:2664 meanR:0.2000 R:1.0 loss:1.7498 exploreP:0.0100\n",
      "Episode:2665 meanR:0.1900 R:-1.0 loss:2.1350 exploreP:0.0100\n",
      "Episode:2666 meanR:0.2000 R:0.0 loss:1.9445 exploreP:0.0100\n",
      "Episode:2667 meanR:0.2200 R:0.0 loss:2.0710 exploreP:0.0100\n",
      "Episode:2668 meanR:0.2200 R:0.0 loss:1.9350 exploreP:0.0100\n",
      "Episode:2669 meanR:0.2400 R:2.0 loss:1.6629 exploreP:0.0100\n",
      "Episode:2670 meanR:0.2300 R:0.0 loss:1.7395 exploreP:0.0100\n",
      "Episode:2671 meanR:0.2400 R:1.0 loss:1.8796 exploreP:0.0100\n",
      "Episode:2672 meanR:0.2400 R:0.0 loss:1.7993 exploreP:0.0100\n",
      "Episode:2673 meanR:0.2500 R:0.0 loss:1.7729 exploreP:0.0100\n",
      "Episode:2674 meanR:0.2500 R:0.0 loss:2.1643 exploreP:0.0100\n",
      "Episode:2675 meanR:0.2500 R:0.0 loss:1.7553 exploreP:0.0100\n",
      "Episode:2676 meanR:0.2600 R:0.0 loss:1.7455 exploreP:0.0100\n",
      "Episode:2677 meanR:0.2600 R:0.0 loss:1.8629 exploreP:0.0100\n",
      "Episode:2678 meanR:0.2500 R:0.0 loss:2.1006 exploreP:0.0100\n",
      "Episode:2679 meanR:0.2500 R:0.0 loss:2.1138 exploreP:0.0100\n",
      "Episode:2680 meanR:0.2400 R:0.0 loss:1.9121 exploreP:0.0100\n",
      "Episode:2681 meanR:0.2500 R:1.0 loss:1.9197 exploreP:0.0100\n",
      "Episode:2682 meanR:0.2300 R:0.0 loss:1.9741 exploreP:0.0100\n",
      "Episode:2683 meanR:0.2400 R:1.0 loss:1.8420 exploreP:0.0100\n",
      "Episode:2684 meanR:0.2200 R:0.0 loss:1.7759 exploreP:0.0100\n",
      "Episode:2685 meanR:0.2100 R:1.0 loss:1.9416 exploreP:0.0100\n",
      "Episode:2686 meanR:0.2100 R:0.0 loss:1.6823 exploreP:0.0100\n",
      "Episode:2687 meanR:0.2100 R:0.0 loss:1.7382 exploreP:0.0100\n",
      "Episode:2688 meanR:0.2200 R:0.0 loss:2.1907 exploreP:0.0100\n",
      "Episode:2689 meanR:0.2200 R:0.0 loss:2.0101 exploreP:0.0100\n",
      "Episode:2690 meanR:0.2100 R:-1.0 loss:1.7425 exploreP:0.0100\n",
      "Episode:2691 meanR:0.1900 R:-1.0 loss:1.8788 exploreP:0.0100\n",
      "Episode:2692 meanR:0.1900 R:-1.0 loss:2.4874 exploreP:0.0100\n",
      "Episode:2693 meanR:0.1900 R:0.0 loss:2.4915 exploreP:0.0100\n",
      "Episode:2694 meanR:0.1700 R:-1.0 loss:1.7524 exploreP:0.0100\n",
      "Episode:2695 meanR:0.1500 R:-1.0 loss:2.4667 exploreP:0.0100\n",
      "Episode:2696 meanR:0.1500 R:0.0 loss:2.1984 exploreP:0.0100\n",
      "Episode:2697 meanR:0.1300 R:0.0 loss:2.2897 exploreP:0.0100\n",
      "Episode:2698 meanR:0.1300 R:0.0 loss:1.8803 exploreP:0.0100\n",
      "Episode:2699 meanR:0.1500 R:0.0 loss:1.8718 exploreP:0.0100\n",
      "Episode:2700 meanR:0.1500 R:0.0 loss:1.8921 exploreP:0.0100\n",
      "Episode:2701 meanR:0.1500 R:0.0 loss:1.9374 exploreP:0.0100\n",
      "Episode:2702 meanR:0.1500 R:1.0 loss:1.7701 exploreP:0.0100\n",
      "Episode:2703 meanR:0.1400 R:-1.0 loss:1.8772 exploreP:0.0100\n",
      "Episode:2704 meanR:0.1500 R:1.0 loss:1.8758 exploreP:0.0100\n",
      "Episode:2705 meanR:0.1400 R:-1.0 loss:1.9156 exploreP:0.0100\n",
      "Episode:2706 meanR:0.1100 R:-2.0 loss:1.7265 exploreP:0.0100\n",
      "Episode:2707 meanR:0.1100 R:0.0 loss:1.3825 exploreP:0.0100\n",
      "Episode:2708 meanR:0.1300 R:2.0 loss:1.9891 exploreP:0.0100\n",
      "Episode:2709 meanR:0.1300 R:0.0 loss:1.6269 exploreP:0.0100\n",
      "Episode:2710 meanR:0.1200 R:0.0 loss:1.7148 exploreP:0.0100\n",
      "Episode:2711 meanR:0.1000 R:0.0 loss:1.8878 exploreP:0.0100\n",
      "Episode:2712 meanR:0.1000 R:0.0 loss:2.1550 exploreP:0.0100\n",
      "Episode:2713 meanR:0.0900 R:-1.0 loss:1.9786 exploreP:0.0100\n",
      "Episode:2714 meanR:0.1100 R:2.0 loss:1.9130 exploreP:0.0100\n",
      "Episode:2715 meanR:0.1300 R:0.0 loss:1.7300 exploreP:0.0100\n",
      "Episode:2716 meanR:0.1400 R:1.0 loss:1.7608 exploreP:0.0100\n",
      "Episode:2717 meanR:0.1400 R:1.0 loss:1.9269 exploreP:0.0100\n",
      "Episode:2718 meanR:0.1500 R:1.0 loss:1.8372 exploreP:0.0100\n",
      "Episode:2719 meanR:0.1400 R:-1.0 loss:1.8477 exploreP:0.0100\n",
      "Episode:2720 meanR:0.1200 R:-1.0 loss:1.9414 exploreP:0.0100\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        #state = env.reset()\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]   # get the current state\n",
    "        initial_state = sess.run(model.initial_state)\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                #action = env.action_space.sample()\n",
    "                action = np.random.randint(action_size)        # select an action\n",
    "            else:\n",
    "                action = np.argmax(action_logits)\n",
    "            #state, reward, done, _ = env.step(action)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([initial_state, final_state])\n",
    "            total_reward += reward\n",
    "            initial_state = final_state\n",
    "            state = next_state\n",
    "            \n",
    "            # Training\n",
    "            #batch, rnn_states = memory.sample(batch_size)\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            initial_states = np.array([each[0] for each in rnn_states])\n",
    "            final_states = np.array([each[1] for each in rnn_states])\n",
    "            next_actions_logits = sess.run(model.actions_logits, \n",
    "                                           feed_dict = {model.states: next_states, \n",
    "                                                        model.initial_state: final_states[0].reshape([1, -1])})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs,\n",
    "                                                        model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= +13:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model-nav-seq.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Episode rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model-nav.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 14.00\n"
     ]
    }
   ],
   "source": [
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Testing episodes/epochs\n",
    "    for _ in range(1):\n",
    "        total_reward = 0\n",
    "        #state = env.reset()\n",
    "        env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]   # get the current state\n",
    "\n",
    "        # Testing steps/batches\n",
    "        while True:\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            #state, reward, done, _ = env.step(action)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        print('total_reward: {:.2f}'.format(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful!!!!!!!!!!!!!!!!\n",
    "# Closing the env\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

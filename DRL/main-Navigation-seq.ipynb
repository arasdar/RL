{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# env = UnityEnvironment(file_name=\"/home/arasdar/VisualBanana_Linux/Banana.x86\")\n",
    "# env = UnityEnvironment(file_name=\"/home/aras/unity-envs/Banana_Linux/Banana.x86_64\")\n",
    "env = UnityEnvironment(file_name=\"/home/aras/unity-envs/Banana_Linux_NoVis/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "# print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)\n",
    "# print(state.shape, len(env_info.vector_observations), env_info.vector_observations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37,)\n",
      "Score: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "num_steps = 0\n",
    "while True:\n",
    "    num_steps += 1\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        print(state.shape)\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))\n",
    "num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "num_steps = 0\n",
    "while True:\n",
    "    num_steps += 1\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    #print(state)\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))\n",
    "num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aras/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "batch = []\n",
    "num_steps = 0\n",
    "while True: # infinite number of steps\n",
    "    num_steps += 1\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    #print(state, action, reward, done)\n",
    "    batch.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))\n",
    "num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([1.        , 0.        , 0.        , 0.        , 0.20790455,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.01327663,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.1713129 ,\n",
       "         0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.01027161,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.02920904,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.00962341,\n",
       "         0.        , 0.        ]),\n",
       "  1,\n",
       "  array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          2.17450604e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  2.40637325e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.82566360e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  5.29410392e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.92672536e-02, -1.19209290e-07,\n",
       "         -7.81049681e+00]),\n",
       "  0.0,\n",
       "  0.0],\n",
       " 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 0.        , 0.        , 0.        , 0.20790455,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.01327663,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.1713129 ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.01027161,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.02920904,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.00962341,\n",
       "        0.        , 0.        ]),\n",
       " 1,\n",
       " array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.17450604e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  2.40637325e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.82566360e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  5.29410392e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.92672536e-02, -1.19209290e-07,\n",
       "        -7.81049681e+00]),\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([each[1] for each in batch])\n",
    "actions = np.array([each[0] for each in batch])\n",
    "next_states = np.array([each[1] for each in batch])\n",
    "rewards = np.array([each[2] for each in batch])\n",
    "dones = np.array([each[3] for each in batch])\n",
    "# infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 37) (300,) (300, 37) (300,)\n",
      "float64 int64 float64 float64\n",
      "10.42125129699707 -11.176579475402832 22.597830772399902\n",
      "10.42125129699707 -11.176579475402832\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "# print(rewards[:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)), \n",
    "      (np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, hidden_size, batch_size=1):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    # RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(hidden_size)\n",
    "    #cell = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "    cells = tf.nn.rnn_cell.MultiRNNCell([cell], state_is_tuple=True)\n",
    "    initial_state = cells.zero_state(batch_size, tf.float32)\n",
    "    return states, actions, targetQs, cells, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, action_size, initial_state, cells, hidden_size, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size and\n",
    "        # static means can NOT adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, hidden_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cells, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, hidden_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=action_size)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cells, initial_state, actions, targetQs):\n",
    "    actions_logits, final_state = generator(states=states, cells=cells, initial_state=initial_state, \n",
    "                                            hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, final_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize MLP/CNN\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    # # Optimize RNN\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, cells, self.initial_state = model_input(\n",
    "                state_size=state_size, hidden_size=hidden_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, cells=cells, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "action_size = 4\n",
    "state_size = 37\n",
    "hidden_size = 37*2             # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 128            # memory capacity - 1000 DQN\n",
    "batch_size = 128             # experience mini-batch size - 20 DQN\n",
    "gamma = 0.99                 # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 37) (?, 74)\n",
      "(1, ?, 74) (<tf.Tensor 'MultiRNNCellZeroState/GRUCellZeroState/zeros:0' shape=(1, 74) dtype=float32>,)\n",
      "(1, ?, 74) (<tf.Tensor 'generator/rnn/while/Exit_3:0' shape=(1, 74) dtype=float32>,)\n",
      "(?, 74)\n",
      "(?, 4)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MultiRNNCellZeroState/GRUCellZeroState/zeros:0' shape=(1, 74) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initial_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = env.reset()\n",
    "# for _ in range(batch_size):\n",
    "#     action = env.action_space.sample()\n",
    "#     next_state, reward, done, _ = env.step(action)\n",
    "#     memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "#     state = next_state\n",
    "#     if done is True:\n",
    "#         state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]   # get the state\n",
    "for _ in range(memory_size):\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    memory.states.append(np.zeros([1, hidden_size])) # initial_states for rnn/mem\n",
    "    state = next_state\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]   # get the state\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 74), TensorShape([Dimension(1), Dimension(74)]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.states[0].shape, model.initial_state[0].shape # gru\n",
    "# memory.states[0][1].shape, model.initial_state[0][1].shape #lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:2.0000 R:2.0000 loss:0.0565\n",
      "Episode:1 meanR:0.5000 R:-1.0000 loss:0.0721\n",
      "Episode:2 meanR:0.6667 R:1.0000 loss:0.0371\n",
      "Episode:3 meanR:0.5000 R:0.0000 loss:0.0599\n",
      "Episode:4 meanR:0.6000 R:1.0000 loss:0.0772\n",
      "Episode:5 meanR:0.6667 R:1.0000 loss:0.0497\n",
      "Episode:6 meanR:0.7143 R:1.0000 loss:0.0194\n",
      "Episode:7 meanR:0.6250 R:0.0000 loss:0.0324\n",
      "Episode:8 meanR:0.4444 R:-1.0000 loss:0.0143\n",
      "Episode:9 meanR:0.4000 R:0.0000 loss:0.0108\n",
      "Episode:10 meanR:0.2727 R:-1.0000 loss:0.0164\n",
      "Episode:11 meanR:0.1667 R:-1.0000 loss:0.0341\n",
      "Episode:12 meanR:0.3077 R:2.0000 loss:0.0453\n",
      "Episode:13 meanR:0.5714 R:4.0000 loss:0.0789\n",
      "Episode:14 meanR:0.6000 R:1.0000 loss:0.0909\n",
      "Episode:15 meanR:0.5625 R:0.0000 loss:0.0245\n",
      "Episode:16 meanR:0.5882 R:1.0000 loss:0.0243\n",
      "Episode:17 meanR:0.6667 R:2.0000 loss:0.0219\n",
      "Episode:18 meanR:0.6316 R:0.0000 loss:0.0185\n",
      "Episode:19 meanR:0.6500 R:1.0000 loss:0.0092\n",
      "Episode:20 meanR:0.6190 R:0.0000 loss:0.0090\n",
      "Episode:21 meanR:0.5909 R:0.0000 loss:0.0049\n",
      "Episode:22 meanR:0.7826 R:5.0000 loss:0.0143\n",
      "Episode:23 meanR:0.8333 R:2.0000 loss:0.1250\n",
      "Episode:24 meanR:0.9200 R:3.0000 loss:0.2069\n",
      "Episode:25 meanR:0.8846 R:0.0000 loss:0.0651\n",
      "Episode:26 meanR:0.9259 R:2.0000 loss:0.0311\n",
      "Episode:27 meanR:1.1429 R:7.0000 loss:0.0632\n",
      "Episode:28 meanR:1.2069 R:3.0000 loss:0.0571\n",
      "Episode:29 meanR:1.2333 R:2.0000 loss:0.0335\n",
      "Episode:30 meanR:1.3226 R:4.0000 loss:0.0500\n",
      "Episode:31 meanR:1.4688 R:6.0000 loss:0.0290\n",
      "Episode:32 meanR:1.8182 R:13.0000 loss:0.0619\n",
      "Episode:33 meanR:1.8529 R:3.0000 loss:0.0839\n",
      "Episode:34 meanR:2.0857 R:10.0000 loss:0.0771\n",
      "Episode:35 meanR:2.1667 R:5.0000 loss:0.0828\n",
      "Episode:36 meanR:2.3514 R:9.0000 loss:0.0898\n",
      "Episode:37 meanR:2.3684 R:3.0000 loss:0.0352\n",
      "Episode:38 meanR:2.3846 R:3.0000 loss:0.0395\n",
      "Episode:39 meanR:2.3500 R:1.0000 loss:0.0169\n",
      "Episode:40 meanR:2.4146 R:5.0000 loss:0.0824\n",
      "Episode:41 meanR:2.2619 R:-4.0000 loss:0.0688\n",
      "Episode:42 meanR:2.2093 R:0.0000 loss:0.0367\n",
      "Episode:43 meanR:2.1364 R:-1.0000 loss:0.0301\n",
      "Episode:44 meanR:2.1333 R:2.0000 loss:0.0308\n",
      "Episode:45 meanR:1.9783 R:-5.0000 loss:0.0381\n",
      "Episode:46 meanR:2.0213 R:4.0000 loss:0.1673\n",
      "Episode:47 meanR:2.0833 R:5.0000 loss:0.0702\n",
      "Episode:48 meanR:2.0612 R:1.0000 loss:0.0593\n",
      "Episode:49 meanR:2.0400 R:1.0000 loss:0.0252\n",
      "Episode:50 meanR:2.0196 R:1.0000 loss:0.0315\n",
      "Episode:51 meanR:2.1154 R:7.0000 loss:0.0464\n",
      "Episode:52 meanR:2.1887 R:6.0000 loss:0.0629\n",
      "Episode:53 meanR:2.1481 R:0.0000 loss:0.0312\n",
      "Episode:54 meanR:2.1455 R:2.0000 loss:0.0457\n",
      "Episode:55 meanR:2.2500 R:8.0000 loss:0.0470\n",
      "Episode:56 meanR:2.2632 R:3.0000 loss:0.0545\n",
      "Episode:57 meanR:2.2241 R:0.0000 loss:0.0614\n",
      "Episode:58 meanR:2.3390 R:9.0000 loss:0.0462\n",
      "Episode:59 meanR:2.4667 R:10.0000 loss:0.0662\n",
      "Episode:60 meanR:2.5738 R:9.0000 loss:0.0523\n",
      "Episode:61 meanR:2.7258 R:12.0000 loss:0.0448\n",
      "Episode:62 meanR:2.7143 R:2.0000 loss:0.0619\n",
      "Episode:63 meanR:2.7031 R:2.0000 loss:0.0569\n",
      "Episode:64 meanR:2.7077 R:3.0000 loss:0.0547\n",
      "Episode:65 meanR:2.6667 R:0.0000 loss:0.0375\n",
      "Episode:66 meanR:2.7463 R:8.0000 loss:0.0677\n",
      "Episode:67 meanR:2.6912 R:-1.0000 loss:0.0826\n",
      "Episode:68 meanR:2.6377 R:-1.0000 loss:0.0477\n",
      "Episode:69 meanR:2.5571 R:-3.0000 loss:0.0273\n",
      "Episode:70 meanR:2.4930 R:-2.0000 loss:0.0149\n",
      "Episode:71 meanR:2.4306 R:-2.0000 loss:0.0140\n",
      "Episode:72 meanR:2.3836 R:-1.0000 loss:0.0125\n",
      "Episode:73 meanR:2.3378 R:-1.0000 loss:0.0271\n",
      "Episode:74 meanR:2.3733 R:5.0000 loss:0.0302\n",
      "Episode:75 meanR:2.3947 R:4.0000 loss:0.0555\n",
      "Episode:76 meanR:2.4545 R:7.0000 loss:0.0612\n",
      "Episode:77 meanR:2.4487 R:2.0000 loss:0.0696\n",
      "Episode:78 meanR:2.5316 R:9.0000 loss:0.0638\n",
      "Episode:79 meanR:2.5750 R:6.0000 loss:0.0621\n",
      "Episode:80 meanR:2.5802 R:3.0000 loss:0.0662\n",
      "Episode:81 meanR:2.6463 R:8.0000 loss:0.0746\n",
      "Episode:82 meanR:2.7229 R:9.0000 loss:0.0729\n",
      "Episode:83 meanR:2.8571 R:14.0000 loss:0.0472\n",
      "Episode:84 meanR:2.9294 R:9.0000 loss:0.0619\n",
      "Episode:85 meanR:2.9535 R:5.0000 loss:0.0266\n",
      "Episode:86 meanR:2.9770 R:5.0000 loss:0.0321\n",
      "Episode:87 meanR:2.9773 R:3.0000 loss:0.0575\n",
      "Episode:88 meanR:3.0899 R:13.0000 loss:0.0942\n",
      "Episode:89 meanR:3.0778 R:2.0000 loss:0.0871\n",
      "Episode:90 meanR:3.1538 R:10.0000 loss:0.0871\n",
      "Episode:91 meanR:3.1413 R:2.0000 loss:0.0725\n",
      "Episode:92 meanR:3.1183 R:1.0000 loss:0.0574\n",
      "Episode:93 meanR:3.1383 R:5.0000 loss:0.0419\n",
      "Episode:94 meanR:3.2000 R:9.0000 loss:0.0531\n",
      "Episode:95 meanR:3.2812 R:11.0000 loss:0.0789\n",
      "Episode:96 meanR:3.2577 R:1.0000 loss:0.0705\n",
      "Episode:97 meanR:3.2551 R:3.0000 loss:0.0447\n",
      "Episode:98 meanR:3.2222 R:0.0000 loss:0.0197\n",
      "Episode:99 meanR:3.1800 R:-1.0000 loss:0.0258\n",
      "Episode:100 meanR:3.2100 R:5.0000 loss:0.0290\n",
      "Episode:101 meanR:3.2800 R:6.0000 loss:0.0619\n",
      "Episode:102 meanR:3.2700 R:0.0000 loss:0.0430\n",
      "Episode:103 meanR:3.3300 R:6.0000 loss:0.0393\n",
      "Episode:104 meanR:3.3300 R:1.0000 loss:0.0719\n",
      "Episode:105 meanR:3.3800 R:6.0000 loss:0.0353\n",
      "Episode:106 meanR:3.4000 R:3.0000 loss:0.0298\n",
      "Episode:107 meanR:3.4200 R:2.0000 loss:0.0279\n",
      "Episode:108 meanR:3.4300 R:0.0000 loss:0.0279\n",
      "Episode:109 meanR:3.4400 R:1.0000 loss:0.0228\n",
      "Episode:110 meanR:3.5000 R:5.0000 loss:0.0371\n",
      "Episode:111 meanR:3.5600 R:5.0000 loss:0.0320\n",
      "Episode:112 meanR:3.5700 R:3.0000 loss:0.0284\n",
      "Episode:113 meanR:3.5400 R:1.0000 loss:0.0228\n",
      "Episode:114 meanR:3.5900 R:6.0000 loss:0.0340\n",
      "Episode:115 meanR:3.6700 R:8.0000 loss:0.0554\n",
      "Episode:116 meanR:3.7800 R:12.0000 loss:0.0335\n",
      "Episode:117 meanR:3.8500 R:9.0000 loss:0.0600\n",
      "Episode:118 meanR:3.8600 R:1.0000 loss:0.0758\n",
      "Episode:119 meanR:3.9200 R:7.0000 loss:0.0456\n",
      "Episode:120 meanR:4.0400 R:12.0000 loss:0.0589\n",
      "Episode:121 meanR:4.1200 R:8.0000 loss:0.0753\n",
      "Episode:122 meanR:4.1800 R:11.0000 loss:0.0660\n",
      "Episode:123 meanR:4.2900 R:13.0000 loss:0.0458\n",
      "Episode:124 meanR:4.2700 R:1.0000 loss:0.0449\n",
      "Episode:125 meanR:4.3200 R:5.0000 loss:0.0227\n",
      "Episode:126 meanR:4.3600 R:6.0000 loss:0.0414\n",
      "Episode:127 meanR:4.4100 R:12.0000 loss:0.0425\n",
      "Episode:128 meanR:4.4700 R:9.0000 loss:0.0404\n",
      "Episode:129 meanR:4.5000 R:5.0000 loss:0.0527\n",
      "Episode:130 meanR:4.6300 R:17.0000 loss:0.0413\n",
      "Episode:131 meanR:4.5800 R:1.0000 loss:0.0745\n",
      "Episode:132 meanR:4.4600 R:1.0000 loss:0.0670\n",
      "Episode:133 meanR:4.4900 R:6.0000 loss:0.0394\n",
      "Episode:134 meanR:4.4700 R:8.0000 loss:0.0448\n",
      "Episode:135 meanR:4.4500 R:3.0000 loss:0.0508\n",
      "Episode:136 meanR:4.3700 R:1.0000 loss:0.0455\n",
      "Episode:137 meanR:4.3500 R:1.0000 loss:0.0272\n",
      "Episode:138 meanR:4.3200 R:0.0000 loss:0.0239\n",
      "Episode:139 meanR:4.3300 R:2.0000 loss:0.0275\n",
      "Episode:140 meanR:4.3000 R:2.0000 loss:0.0218\n",
      "Episode:141 meanR:4.3600 R:2.0000 loss:0.0264\n",
      "Episode:142 meanR:4.3600 R:0.0000 loss:0.0203\n",
      "Episode:143 meanR:4.5100 R:14.0000 loss:0.0577\n",
      "Episode:144 meanR:4.5800 R:9.0000 loss:0.0643\n",
      "Episode:145 meanR:4.6700 R:4.0000 loss:0.0986\n",
      "Episode:146 meanR:4.7800 R:15.0000 loss:0.0752\n",
      "Episode:147 meanR:4.7500 R:2.0000 loss:0.0881\n",
      "Episode:148 meanR:4.8900 R:15.0000 loss:0.0578\n",
      "Episode:149 meanR:4.9900 R:11.0000 loss:0.0809\n",
      "Episode:150 meanR:4.9800 R:0.0000 loss:0.0555\n",
      "Episode:151 meanR:4.9100 R:0.0000 loss:0.0326\n",
      "Episode:152 meanR:4.9000 R:5.0000 loss:0.0544\n",
      "Episode:153 meanR:4.9500 R:5.0000 loss:0.0324\n",
      "Episode:154 meanR:4.9300 R:0.0000 loss:0.0491\n",
      "Episode:155 meanR:4.9300 R:8.0000 loss:0.0622\n",
      "Episode:156 meanR:4.9500 R:5.0000 loss:0.0561\n",
      "Episode:157 meanR:4.9800 R:3.0000 loss:0.0878\n",
      "Episode:158 meanR:4.8900 R:0.0000 loss:0.0822\n",
      "Episode:159 meanR:4.8400 R:5.0000 loss:0.0684\n",
      "Episode:160 meanR:4.7600 R:1.0000 loss:0.0189\n",
      "Episode:161 meanR:4.7000 R:6.0000 loss:0.0292\n",
      "Episode:162 meanR:4.7200 R:4.0000 loss:0.0666\n",
      "Episode:163 meanR:4.8200 R:12.0000 loss:0.0511\n",
      "Episode:164 meanR:4.8000 R:1.0000 loss:0.0466\n",
      "Episode:165 meanR:4.8500 R:5.0000 loss:0.0412\n",
      "Episode:166 meanR:4.8300 R:6.0000 loss:0.0569\n",
      "Episode:167 meanR:4.8700 R:3.0000 loss:0.0480\n",
      "Episode:168 meanR:4.9100 R:3.0000 loss:0.0658\n",
      "Episode:169 meanR:4.9500 R:1.0000 loss:0.0497\n",
      "Episode:170 meanR:5.1500 R:18.0000 loss:0.0948\n",
      "Episode:171 meanR:5.2300 R:6.0000 loss:0.1580\n",
      "Episode:172 meanR:5.3200 R:8.0000 loss:0.1115\n",
      "Episode:173 meanR:5.4200 R:9.0000 loss:0.0867\n",
      "Episode:174 meanR:5.5100 R:14.0000 loss:0.0929\n",
      "Episode:175 meanR:5.5200 R:5.0000 loss:0.0880\n",
      "Episode:176 meanR:5.5200 R:7.0000 loss:0.0754\n",
      "Episode:177 meanR:5.5100 R:1.0000 loss:0.0579\n",
      "Episode:178 meanR:5.4900 R:7.0000 loss:0.0496\n",
      "Episode:179 meanR:5.5100 R:8.0000 loss:0.0559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:180 meanR:5.5600 R:8.0000 loss:0.0641\n",
      "Episode:181 meanR:5.5900 R:11.0000 loss:0.0575\n",
      "Episode:182 meanR:5.5200 R:2.0000 loss:0.0795\n",
      "Episode:183 meanR:5.3900 R:1.0000 loss:0.0545\n",
      "Episode:184 meanR:5.3900 R:9.0000 loss:0.0493\n",
      "Episode:185 meanR:5.4500 R:11.0000 loss:0.0666\n",
      "Episode:186 meanR:5.4800 R:8.0000 loss:0.0923\n",
      "Episode:187 meanR:5.4500 R:0.0000 loss:0.0491\n",
      "Episode:188 meanR:5.3400 R:2.0000 loss:0.0488\n",
      "Episode:189 meanR:5.3900 R:7.0000 loss:0.0410\n",
      "Episode:190 meanR:5.3700 R:8.0000 loss:0.1086\n",
      "Episode:191 meanR:5.4000 R:5.0000 loss:0.0669\n",
      "Episode:192 meanR:5.4700 R:8.0000 loss:0.0646\n",
      "Episode:193 meanR:5.5500 R:13.0000 loss:0.0458\n",
      "Episode:194 meanR:5.5200 R:6.0000 loss:0.0969\n",
      "Episode:195 meanR:5.4300 R:2.0000 loss:0.0679\n",
      "Episode:196 meanR:5.4700 R:5.0000 loss:0.0461\n",
      "Episode:197 meanR:5.4600 R:2.0000 loss:0.0519\n",
      "Episode:198 meanR:5.5800 R:12.0000 loss:0.0465\n",
      "Episode:199 meanR:5.6700 R:8.0000 loss:0.0874\n",
      "Episode:200 meanR:5.6600 R:4.0000 loss:0.0431\n",
      "Episode:201 meanR:5.6700 R:7.0000 loss:0.0498\n",
      "Episode:202 meanR:5.7200 R:5.0000 loss:0.0520\n",
      "Episode:203 meanR:5.7200 R:6.0000 loss:0.0650\n",
      "Episode:204 meanR:5.7300 R:2.0000 loss:0.0686\n",
      "Episode:205 meanR:5.6700 R:0.0000 loss:0.0618\n",
      "Episode:206 meanR:5.6400 R:0.0000 loss:0.0368\n",
      "Episode:207 meanR:5.6200 R:0.0000 loss:0.0190\n",
      "Episode:208 meanR:5.6200 R:0.0000 loss:0.0190\n",
      "Episode:209 meanR:5.6800 R:7.0000 loss:0.0328\n",
      "Episode:210 meanR:5.6600 R:3.0000 loss:0.0404\n",
      "Episode:211 meanR:5.7100 R:10.0000 loss:0.0494\n",
      "Episode:212 meanR:5.6900 R:1.0000 loss:0.0640\n",
      "Episode:213 meanR:5.6900 R:1.0000 loss:0.0399\n",
      "Episode:214 meanR:5.7100 R:8.0000 loss:0.0344\n",
      "Episode:215 meanR:5.7000 R:7.0000 loss:0.0432\n",
      "Episode:216 meanR:5.6200 R:4.0000 loss:0.0831\n",
      "Episode:217 meanR:5.5900 R:6.0000 loss:0.0669\n",
      "Episode:218 meanR:5.5900 R:1.0000 loss:0.0667\n",
      "Episode:219 meanR:5.5400 R:2.0000 loss:0.0415\n",
      "Episode:220 meanR:5.4300 R:1.0000 loss:0.0329\n",
      "Episode:221 meanR:5.3500 R:0.0000 loss:0.0337\n",
      "Episode:222 meanR:5.2800 R:4.0000 loss:0.0413\n",
      "Episode:223 meanR:5.2400 R:9.0000 loss:0.0336\n",
      "Episode:224 meanR:5.3000 R:7.0000 loss:0.0391\n",
      "Episode:225 meanR:5.2900 R:4.0000 loss:0.0359\n",
      "Episode:226 meanR:5.2900 R:6.0000 loss:0.0567\n",
      "Episode:227 meanR:5.1900 R:2.0000 loss:0.0442\n",
      "Episode:228 meanR:5.1000 R:0.0000 loss:0.0324\n",
      "Episode:229 meanR:5.0500 R:0.0000 loss:0.0204\n",
      "Episode:230 meanR:4.8900 R:1.0000 loss:0.0121\n",
      "Episode:231 meanR:4.8600 R:-2.0000 loss:0.0174\n",
      "Episode:232 meanR:4.8500 R:0.0000 loss:0.0056\n",
      "Episode:233 meanR:4.7800 R:-1.0000 loss:0.0052\n",
      "Episode:234 meanR:4.7400 R:4.0000 loss:0.0204\n",
      "Episode:235 meanR:4.8500 R:14.0000 loss:0.0783\n",
      "Episode:236 meanR:4.9400 R:10.0000 loss:0.0529\n",
      "Episode:237 meanR:4.9500 R:2.0000 loss:0.0547\n",
      "Episode:238 meanR:4.9500 R:0.0000 loss:0.0168\n",
      "Episode:239 meanR:5.0500 R:12.0000 loss:0.0609\n",
      "Episode:240 meanR:5.0900 R:6.0000 loss:0.0771\n",
      "Episode:241 meanR:5.1900 R:12.0000 loss:0.0805\n",
      "Episode:242 meanR:5.2200 R:3.0000 loss:0.1022\n",
      "Episode:243 meanR:5.1500 R:7.0000 loss:0.0526\n",
      "Episode:244 meanR:5.1700 R:11.0000 loss:0.0516\n",
      "Episode:245 meanR:5.1700 R:4.0000 loss:0.0758\n",
      "Episode:246 meanR:5.0900 R:7.0000 loss:0.0420\n",
      "Episode:247 meanR:5.1200 R:5.0000 loss:0.0490\n",
      "Episode:248 meanR:5.0400 R:7.0000 loss:0.0780\n",
      "Episode:249 meanR:4.9800 R:5.0000 loss:0.0564\n",
      "Episode:250 meanR:5.1200 R:14.0000 loss:0.0335\n",
      "Episode:251 meanR:5.1500 R:3.0000 loss:0.0332\n",
      "Episode:252 meanR:5.1500 R:5.0000 loss:0.0739\n",
      "Episode:253 meanR:5.1600 R:6.0000 loss:0.0779\n",
      "Episode:254 meanR:5.2400 R:8.0000 loss:0.0770\n",
      "Episode:255 meanR:5.3000 R:14.0000 loss:0.1058\n",
      "Episode:256 meanR:5.2500 R:0.0000 loss:0.0828\n",
      "Episode:257 meanR:5.2800 R:6.0000 loss:0.0516\n",
      "Episode:258 meanR:5.2800 R:0.0000 loss:0.0619\n",
      "Episode:259 meanR:5.2500 R:2.0000 loss:0.0405\n",
      "Episode:260 meanR:5.2600 R:2.0000 loss:0.0251\n",
      "Episode:261 meanR:5.2200 R:2.0000 loss:0.0301\n",
      "Episode:262 meanR:5.2500 R:7.0000 loss:0.0314\n",
      "Episode:263 meanR:5.2000 R:7.0000 loss:0.0319\n",
      "Episode:264 meanR:5.2000 R:1.0000 loss:0.0398\n",
      "Episode:265 meanR:5.2600 R:11.0000 loss:0.0457\n",
      "Episode:266 meanR:5.2600 R:6.0000 loss:0.0530\n",
      "Episode:267 meanR:5.3400 R:11.0000 loss:0.0502\n",
      "Episode:268 meanR:5.3300 R:2.0000 loss:0.0428\n",
      "Episode:269 meanR:5.3500 R:3.0000 loss:0.0297\n",
      "Episode:270 meanR:5.1800 R:1.0000 loss:0.0413\n",
      "Episode:271 meanR:5.2100 R:9.0000 loss:0.0588\n",
      "Episode:272 meanR:5.1500 R:2.0000 loss:0.0333\n",
      "Episode:273 meanR:5.1600 R:10.0000 loss:0.0703\n",
      "Episode:274 meanR:5.1600 R:14.0000 loss:0.0355\n",
      "Episode:275 meanR:5.2400 R:13.0000 loss:0.0799\n",
      "Episode:276 meanR:5.2100 R:4.0000 loss:0.0588\n",
      "Episode:277 meanR:5.2100 R:1.0000 loss:0.0300\n",
      "Episode:278 meanR:5.1500 R:1.0000 loss:0.0253\n",
      "Episode:279 meanR:5.0700 R:0.0000 loss:0.0188\n",
      "Episode:280 meanR:5.0300 R:4.0000 loss:0.0290\n",
      "Episode:281 meanR:4.9600 R:4.0000 loss:0.0155\n",
      "Episode:282 meanR:4.9500 R:1.0000 loss:0.0365\n",
      "Episode:283 meanR:4.9600 R:2.0000 loss:0.0229\n",
      "Episode:284 meanR:5.0000 R:13.0000 loss:0.0545\n",
      "Episode:285 meanR:4.9200 R:3.0000 loss:0.0733\n",
      "Episode:286 meanR:4.9000 R:6.0000 loss:0.0504\n",
      "Episode:287 meanR:4.9100 R:1.0000 loss:0.0561\n",
      "Episode:288 meanR:4.9300 R:4.0000 loss:0.0455\n",
      "Episode:289 meanR:4.8600 R:0.0000 loss:0.0280\n",
      "Episode:290 meanR:4.7800 R:0.0000 loss:0.0213\n",
      "Episode:291 meanR:4.7600 R:3.0000 loss:0.0362\n",
      "Episode:292 meanR:4.6800 R:0.0000 loss:0.0287\n",
      "Episode:293 meanR:4.5700 R:2.0000 loss:0.0155\n",
      "Episode:294 meanR:4.5300 R:2.0000 loss:0.0343\n",
      "Episode:295 meanR:4.5200 R:1.0000 loss:0.0433\n",
      "Episode:296 meanR:4.4800 R:1.0000 loss:0.0145\n",
      "Episode:297 meanR:4.4600 R:0.0000 loss:0.0293\n",
      "Episode:298 meanR:4.3300 R:-1.0000 loss:0.0122\n",
      "Episode:299 meanR:4.2700 R:2.0000 loss:0.0354\n",
      "Episode:300 meanR:4.3100 R:8.0000 loss:0.0534\n",
      "Episode:301 meanR:4.3500 R:11.0000 loss:0.0519\n",
      "Episode:302 meanR:4.3600 R:6.0000 loss:0.0804\n",
      "Episode:303 meanR:4.3500 R:5.0000 loss:0.0635\n",
      "Episode:304 meanR:4.3600 R:3.0000 loss:0.0765\n",
      "Episode:305 meanR:4.4400 R:8.0000 loss:0.0681\n",
      "Episode:306 meanR:4.5100 R:7.0000 loss:0.0455\n",
      "Episode:307 meanR:4.5800 R:7.0000 loss:0.0457\n",
      "Episode:308 meanR:4.6000 R:2.0000 loss:0.1512\n",
      "Episode:309 meanR:4.6100 R:8.0000 loss:0.1006\n",
      "Episode:310 meanR:4.6100 R:3.0000 loss:0.0932\n",
      "Episode:311 meanR:4.5600 R:5.0000 loss:0.0683\n",
      "Episode:312 meanR:4.5900 R:4.0000 loss:0.0846\n",
      "Episode:313 meanR:4.6300 R:5.0000 loss:0.0654\n",
      "Episode:314 meanR:4.5900 R:4.0000 loss:0.0699\n",
      "Episode:315 meanR:4.6100 R:9.0000 loss:0.1307\n",
      "Episode:316 meanR:4.6200 R:5.0000 loss:0.0847\n",
      "Episode:317 meanR:4.6500 R:9.0000 loss:0.0551\n",
      "Episode:318 meanR:4.6500 R:1.0000 loss:0.0628\n",
      "Episode:319 meanR:4.6300 R:0.0000 loss:0.0412\n",
      "Episode:320 meanR:4.6400 R:2.0000 loss:0.0572\n",
      "Episode:321 meanR:4.6600 R:2.0000 loss:0.0274\n",
      "Episode:322 meanR:4.6700 R:5.0000 loss:0.0396\n",
      "Episode:323 meanR:4.5600 R:-2.0000 loss:0.0208\n",
      "Episode:324 meanR:4.5100 R:2.0000 loss:0.0292\n",
      "Episode:325 meanR:4.4700 R:0.0000 loss:0.0290\n",
      "Episode:326 meanR:4.3700 R:-4.0000 loss:0.0278\n",
      "Episode:327 meanR:4.3500 R:0.0000 loss:0.0124\n",
      "Episode:328 meanR:4.3500 R:0.0000 loss:0.0071\n",
      "Episode:329 meanR:4.4300 R:8.0000 loss:0.0430\n",
      "Episode:330 meanR:4.4700 R:5.0000 loss:0.0477\n",
      "Episode:331 meanR:4.5500 R:6.0000 loss:0.0534\n",
      "Episode:332 meanR:4.5400 R:-1.0000 loss:0.0573\n",
      "Episode:333 meanR:4.5700 R:2.0000 loss:0.0260\n",
      "Episode:334 meanR:4.6100 R:8.0000 loss:0.0368\n",
      "Episode:335 meanR:4.5000 R:3.0000 loss:0.0418\n",
      "Episode:336 meanR:4.4200 R:2.0000 loss:0.0394\n",
      "Episode:337 meanR:4.4300 R:3.0000 loss:0.0482\n",
      "Episode:338 meanR:4.5000 R:7.0000 loss:0.0327\n",
      "Episode:339 meanR:4.3800 R:0.0000 loss:0.0265\n",
      "Episode:340 meanR:4.3400 R:2.0000 loss:0.0107\n",
      "Episode:341 meanR:4.3600 R:14.0000 loss:0.0403\n",
      "Episode:342 meanR:4.3700 R:4.0000 loss:0.0677\n",
      "Episode:343 meanR:4.3200 R:2.0000 loss:0.0208\n",
      "Episode:344 meanR:4.2600 R:5.0000 loss:0.0243\n",
      "Episode:345 meanR:4.2900 R:7.0000 loss:0.0577\n",
      "Episode:346 meanR:4.2600 R:4.0000 loss:0.0370\n",
      "Episode:347 meanR:4.2500 R:4.0000 loss:0.0467\n",
      "Episode:348 meanR:4.2700 R:9.0000 loss:0.0481\n",
      "Episode:349 meanR:4.3100 R:9.0000 loss:0.0709\n",
      "Episode:350 meanR:4.2300 R:6.0000 loss:0.0584\n",
      "Episode:351 meanR:4.2800 R:8.0000 loss:0.0385\n",
      "Episode:352 meanR:4.2900 R:6.0000 loss:0.0388\n",
      "Episode:353 meanR:4.3100 R:8.0000 loss:0.0397\n",
      "Episode:354 meanR:4.2800 R:5.0000 loss:0.0451\n",
      "Episode:355 meanR:4.1600 R:2.0000 loss:0.0385\n",
      "Episode:356 meanR:4.1700 R:1.0000 loss:0.0232\n",
      "Episode:357 meanR:4.1100 R:0.0000 loss:0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:358 meanR:4.1200 R:1.0000 loss:0.0355\n",
      "Episode:359 meanR:4.2200 R:12.0000 loss:0.0519\n",
      "Episode:360 meanR:4.3000 R:10.0000 loss:0.0811\n",
      "Episode:361 meanR:4.2900 R:1.0000 loss:0.0537\n",
      "Episode:362 meanR:4.3100 R:9.0000 loss:0.0314\n",
      "Episode:363 meanR:4.3100 R:7.0000 loss:0.0496\n",
      "Episode:364 meanR:4.4800 R:18.0000 loss:0.0644\n",
      "Episode:365 meanR:4.5200 R:15.0000 loss:0.0710\n",
      "Episode:366 meanR:4.5800 R:12.0000 loss:0.0813\n",
      "Episode:367 meanR:4.5400 R:7.0000 loss:0.0671\n",
      "Episode:368 meanR:4.6300 R:11.0000 loss:0.0522\n",
      "Episode:369 meanR:4.7100 R:11.0000 loss:0.0348\n",
      "Episode:370 meanR:4.7800 R:8.0000 loss:0.0644\n",
      "Episode:371 meanR:4.8000 R:11.0000 loss:0.0812\n",
      "Episode:372 meanR:4.9300 R:15.0000 loss:0.0486\n",
      "Episode:373 meanR:4.8800 R:5.0000 loss:0.1062\n",
      "Episode:374 meanR:4.8600 R:12.0000 loss:0.0488\n",
      "Episode:375 meanR:4.8400 R:11.0000 loss:0.0657\n",
      "Episode:376 meanR:4.9400 R:14.0000 loss:0.0623\n",
      "Episode:377 meanR:5.0200 R:9.0000 loss:0.0506\n",
      "Episode:378 meanR:5.0100 R:0.0000 loss:0.0601\n",
      "Episode:379 meanR:5.0900 R:8.0000 loss:0.0509\n",
      "Episode:380 meanR:5.0500 R:0.0000 loss:0.0308\n",
      "Episode:381 meanR:5.0900 R:8.0000 loss:0.0515\n",
      "Episode:382 meanR:5.1200 R:4.0000 loss:0.0365\n",
      "Episode:383 meanR:5.2200 R:12.0000 loss:0.0459\n",
      "Episode:384 meanR:5.2000 R:11.0000 loss:0.0483\n",
      "Episode:385 meanR:5.3300 R:16.0000 loss:0.0450\n",
      "Episode:386 meanR:5.3300 R:6.0000 loss:0.0614\n",
      "Episode:387 meanR:5.4300 R:11.0000 loss:0.0396\n",
      "Episode:388 meanR:5.4500 R:6.0000 loss:0.0522\n",
      "Episode:389 meanR:5.5500 R:10.0000 loss:0.0435\n",
      "Episode:390 meanR:5.6000 R:5.0000 loss:0.0545\n",
      "Episode:391 meanR:5.6900 R:12.0000 loss:0.0580\n",
      "Episode:392 meanR:5.7300 R:4.0000 loss:0.0645\n",
      "Episode:393 meanR:5.7700 R:6.0000 loss:0.0527\n",
      "Episode:394 meanR:5.8300 R:8.0000 loss:0.0451\n",
      "Episode:395 meanR:5.9500 R:13.0000 loss:0.0572\n",
      "Episode:396 meanR:6.0600 R:12.0000 loss:0.0475\n",
      "Episode:397 meanR:6.2200 R:16.0000 loss:0.0589\n",
      "Episode:398 meanR:6.3200 R:9.0000 loss:0.0729\n",
      "Episode:399 meanR:6.4100 R:11.0000 loss:0.0318\n",
      "Episode:400 meanR:6.3500 R:2.0000 loss:0.0530\n",
      "Episode:401 meanR:6.2900 R:5.0000 loss:0.0406\n",
      "Episode:402 meanR:6.3400 R:11.0000 loss:0.0569\n",
      "Episode:403 meanR:6.4100 R:12.0000 loss:0.0575\n",
      "Episode:404 meanR:6.4800 R:10.0000 loss:0.0656\n",
      "Episode:405 meanR:6.4400 R:4.0000 loss:0.0554\n",
      "Episode:406 meanR:6.4400 R:7.0000 loss:0.0540\n",
      "Episode:407 meanR:6.3700 R:0.0000 loss:0.0342\n",
      "Episode:408 meanR:6.3300 R:-2.0000 loss:0.0478\n",
      "Episode:409 meanR:6.2500 R:0.0000 loss:0.0396\n",
      "Episode:410 meanR:6.2200 R:0.0000 loss:0.0237\n",
      "Episode:411 meanR:6.1600 R:-1.0000 loss:0.0310\n",
      "Episode:412 meanR:6.1200 R:0.0000 loss:0.0208\n",
      "Episode:413 meanR:6.0700 R:0.0000 loss:0.0106\n",
      "Episode:414 meanR:6.0300 R:0.0000 loss:0.0199\n",
      "Episode:415 meanR:5.9500 R:1.0000 loss:0.0198\n",
      "Episode:416 meanR:5.9000 R:0.0000 loss:0.0226\n",
      "Episode:417 meanR:5.8200 R:1.0000 loss:0.0144\n",
      "Episode:418 meanR:5.8100 R:0.0000 loss:0.0170\n",
      "Episode:419 meanR:5.8000 R:-1.0000 loss:0.0244\n",
      "Episode:420 meanR:5.7700 R:-1.0000 loss:0.0124\n",
      "Episode:421 meanR:5.7500 R:0.0000 loss:0.0136\n",
      "Episode:422 meanR:5.7000 R:0.0000 loss:0.0121\n",
      "Episode:423 meanR:5.7200 R:0.0000 loss:0.0157\n",
      "Episode:424 meanR:5.7400 R:4.0000 loss:0.0243\n",
      "Episode:425 meanR:5.8900 R:15.0000 loss:0.0314\n",
      "Episode:426 meanR:5.9300 R:0.0000 loss:0.0278\n",
      "Episode:427 meanR:6.0100 R:8.0000 loss:0.0363\n",
      "Episode:428 meanR:6.0300 R:2.0000 loss:0.0751\n",
      "Episode:429 meanR:5.9900 R:4.0000 loss:0.0242\n",
      "Episode:430 meanR:6.0100 R:7.0000 loss:0.0321\n",
      "Episode:431 meanR:6.0200 R:7.0000 loss:0.0340\n",
      "Episode:432 meanR:6.1100 R:8.0000 loss:0.0327\n",
      "Episode:433 meanR:6.2100 R:12.0000 loss:0.0536\n",
      "Episode:434 meanR:6.2700 R:14.0000 loss:0.0583\n",
      "Episode:435 meanR:6.2800 R:4.0000 loss:0.0548\n",
      "Episode:436 meanR:6.4000 R:14.0000 loss:0.0365\n",
      "Episode:437 meanR:6.4400 R:7.0000 loss:0.0548\n",
      "Episode:438 meanR:6.4400 R:7.0000 loss:0.0437\n",
      "Episode:439 meanR:6.5300 R:9.0000 loss:0.0483\n",
      "Episode:440 meanR:6.5700 R:6.0000 loss:0.0353\n",
      "Episode:441 meanR:6.5100 R:8.0000 loss:0.0277\n",
      "Episode:442 meanR:6.5600 R:9.0000 loss:0.0318\n",
      "Episode:443 meanR:6.5700 R:3.0000 loss:0.0367\n",
      "Episode:444 meanR:6.6700 R:15.0000 loss:0.0362\n",
      "Episode:445 meanR:6.6900 R:9.0000 loss:0.0706\n",
      "Episode:446 meanR:6.7100 R:6.0000 loss:0.0477\n",
      "Episode:447 meanR:6.8300 R:16.0000 loss:0.0702\n",
      "Episode:448 meanR:6.7300 R:-1.0000 loss:0.1144\n",
      "Episode:449 meanR:6.7100 R:7.0000 loss:0.0339\n",
      "Episode:450 meanR:6.6900 R:4.0000 loss:0.0458\n",
      "Episode:451 meanR:6.6700 R:6.0000 loss:0.0407\n",
      "Episode:452 meanR:6.6300 R:2.0000 loss:0.0397\n",
      "Episode:453 meanR:6.6200 R:7.0000 loss:0.0340\n",
      "Episode:454 meanR:6.6500 R:8.0000 loss:0.0666\n",
      "Episode:455 meanR:6.7800 R:15.0000 loss:0.0572\n",
      "Episode:456 meanR:6.8600 R:9.0000 loss:0.0842\n",
      "Episode:457 meanR:6.9200 R:6.0000 loss:0.0523\n",
      "Episode:458 meanR:6.9500 R:4.0000 loss:0.0486\n",
      "Episode:459 meanR:6.9700 R:14.0000 loss:0.0367\n",
      "Episode:460 meanR:6.9600 R:9.0000 loss:0.0650\n",
      "Episode:461 meanR:7.0300 R:8.0000 loss:0.0336\n",
      "Episode:462 meanR:7.0600 R:12.0000 loss:0.0442\n",
      "Episode:463 meanR:7.1100 R:12.0000 loss:0.0704\n",
      "Episode:464 meanR:7.0100 R:8.0000 loss:0.0465\n",
      "Episode:465 meanR:6.8900 R:3.0000 loss:0.0450\n",
      "Episode:466 meanR:6.8200 R:5.0000 loss:0.0452\n",
      "Episode:467 meanR:6.7900 R:4.0000 loss:0.0442\n",
      "Episode:468 meanR:6.7800 R:10.0000 loss:0.0440\n",
      "Episode:469 meanR:6.7700 R:10.0000 loss:0.0531\n",
      "Episode:470 meanR:6.7200 R:3.0000 loss:0.0579\n",
      "Episode:471 meanR:6.7300 R:12.0000 loss:0.0645\n",
      "Episode:472 meanR:6.6300 R:5.0000 loss:0.0752\n",
      "Episode:473 meanR:6.6500 R:7.0000 loss:0.0264\n",
      "Episode:474 meanR:6.5600 R:3.0000 loss:0.0512\n",
      "Episode:475 meanR:6.5700 R:12.0000 loss:0.0338\n",
      "Episode:476 meanR:6.4900 R:6.0000 loss:0.0614\n",
      "Episode:477 meanR:6.4400 R:4.0000 loss:0.0377\n",
      "Episode:478 meanR:6.4900 R:5.0000 loss:0.0554\n",
      "Episode:479 meanR:6.4500 R:4.0000 loss:0.0462\n",
      "Episode:480 meanR:6.5000 R:5.0000 loss:0.0336\n",
      "Episode:481 meanR:6.4500 R:3.0000 loss:0.0364\n",
      "Episode:482 meanR:6.4700 R:6.0000 loss:0.0334\n",
      "Episode:483 meanR:6.4500 R:10.0000 loss:0.0492\n",
      "Episode:484 meanR:6.4700 R:13.0000 loss:0.0609\n",
      "Episode:485 meanR:6.4600 R:15.0000 loss:0.0791\n",
      "Episode:486 meanR:6.4900 R:9.0000 loss:0.0733\n",
      "Episode:487 meanR:6.4600 R:8.0000 loss:0.0986\n",
      "Episode:488 meanR:6.5400 R:14.0000 loss:0.0536\n",
      "Episode:489 meanR:6.4600 R:2.0000 loss:0.0613\n",
      "Episode:490 meanR:6.4100 R:0.0000 loss:0.0365\n",
      "Episode:491 meanR:6.3000 R:1.0000 loss:0.0298\n",
      "Episode:492 meanR:6.3400 R:8.0000 loss:0.0747\n",
      "Episode:493 meanR:6.2900 R:1.0000 loss:0.0886\n",
      "Episode:494 meanR:6.2000 R:-1.0000 loss:0.0438\n",
      "Episode:495 meanR:6.1500 R:8.0000 loss:0.0371\n",
      "Episode:496 meanR:6.1500 R:12.0000 loss:0.0363\n",
      "Episode:497 meanR:5.9900 R:0.0000 loss:0.0394\n",
      "Episode:498 meanR:5.9700 R:7.0000 loss:0.0413\n",
      "Episode:499 meanR:5.9200 R:6.0000 loss:0.0540\n",
      "Episode:500 meanR:6.0000 R:10.0000 loss:0.0370\n",
      "Episode:501 meanR:5.9500 R:0.0000 loss:0.0441\n",
      "Episode:502 meanR:5.9100 R:7.0000 loss:0.0427\n",
      "Episode:503 meanR:5.8700 R:8.0000 loss:0.0447\n",
      "Episode:504 meanR:5.8200 R:5.0000 loss:0.0415\n",
      "Episode:505 meanR:5.8800 R:10.0000 loss:0.0289\n",
      "Episode:506 meanR:5.9300 R:12.0000 loss:0.0498\n",
      "Episode:507 meanR:6.0400 R:11.0000 loss:0.0759\n",
      "Episode:508 meanR:6.1400 R:8.0000 loss:0.0443\n",
      "Episode:509 meanR:6.1600 R:2.0000 loss:0.0435\n",
      "Episode:510 meanR:6.1800 R:2.0000 loss:0.0803\n",
      "Episode:511 meanR:6.1600 R:-3.0000 loss:0.0432\n",
      "Episode:512 meanR:6.1600 R:0.0000 loss:0.0423\n",
      "Episode:513 meanR:6.1700 R:1.0000 loss:0.0098\n",
      "Episode:514 meanR:6.1700 R:0.0000 loss:0.0158\n",
      "Episode:515 meanR:6.1600 R:0.0000 loss:0.0211\n",
      "Episode:516 meanR:6.1600 R:0.0000 loss:0.0221\n",
      "Episode:517 meanR:6.2300 R:8.0000 loss:0.0481\n",
      "Episode:518 meanR:6.2400 R:1.0000 loss:0.0341\n",
      "Episode:519 meanR:6.2500 R:0.0000 loss:0.0365\n",
      "Episode:520 meanR:6.3000 R:4.0000 loss:0.0264\n",
      "Episode:521 meanR:6.3300 R:3.0000 loss:0.0489\n",
      "Episode:522 meanR:6.4200 R:9.0000 loss:0.0320\n",
      "Episode:523 meanR:6.5100 R:9.0000 loss:0.0345\n",
      "Episode:524 meanR:6.5600 R:9.0000 loss:0.0257\n",
      "Episode:525 meanR:6.4900 R:8.0000 loss:0.0517\n",
      "Episode:526 meanR:6.6100 R:12.0000 loss:0.0441\n",
      "Episode:527 meanR:6.6500 R:12.0000 loss:0.0612\n",
      "Episode:528 meanR:6.7700 R:14.0000 loss:0.0695\n",
      "Episode:529 meanR:6.8300 R:10.0000 loss:0.0539\n",
      "Episode:530 meanR:6.8300 R:7.0000 loss:0.0347\n",
      "Episode:531 meanR:6.8500 R:9.0000 loss:0.0491\n",
      "Episode:532 meanR:6.8400 R:7.0000 loss:0.0530\n",
      "Episode:533 meanR:6.7200 R:0.0000 loss:0.0173\n",
      "Episode:534 meanR:6.6700 R:9.0000 loss:0.0387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:535 meanR:6.7200 R:9.0000 loss:0.0655\n",
      "Episode:536 meanR:6.6000 R:2.0000 loss:0.0475\n",
      "Episode:537 meanR:6.5900 R:6.0000 loss:0.0274\n",
      "Episode:538 meanR:6.6300 R:11.0000 loss:0.0501\n",
      "Episode:539 meanR:6.6600 R:12.0000 loss:0.0768\n",
      "Episode:540 meanR:6.7200 R:12.0000 loss:0.0675\n",
      "Episode:541 meanR:6.6700 R:3.0000 loss:0.0465\n",
      "Episode:542 meanR:6.6800 R:10.0000 loss:0.0649\n",
      "Episode:543 meanR:6.6900 R:4.0000 loss:0.0566\n",
      "Episode:544 meanR:6.6300 R:9.0000 loss:0.0528\n",
      "Episode:545 meanR:6.5600 R:2.0000 loss:0.0384\n",
      "Episode:546 meanR:6.5600 R:6.0000 loss:0.0297\n",
      "Episode:547 meanR:6.4700 R:7.0000 loss:0.0408\n",
      "Episode:548 meanR:6.5200 R:4.0000 loss:0.0386\n",
      "Episode:549 meanR:6.5400 R:9.0000 loss:0.0439\n",
      "Episode:550 meanR:6.5400 R:4.0000 loss:0.0318\n",
      "Episode:551 meanR:6.4500 R:-3.0000 loss:0.0359\n",
      "Episode:552 meanR:6.4500 R:2.0000 loss:0.0370\n",
      "Episode:553 meanR:6.4400 R:6.0000 loss:0.0386\n",
      "Episode:554 meanR:6.4000 R:4.0000 loss:0.0449\n",
      "Episode:555 meanR:6.2800 R:3.0000 loss:0.0347\n",
      "Episode:556 meanR:6.2600 R:7.0000 loss:0.0340\n",
      "Episode:557 meanR:6.2200 R:2.0000 loss:0.0434\n",
      "Episode:558 meanR:6.2700 R:9.0000 loss:0.0482\n",
      "Episode:559 meanR:6.1600 R:3.0000 loss:0.0378\n",
      "Episode:560 meanR:6.1100 R:4.0000 loss:0.0331\n",
      "Episode:561 meanR:6.1200 R:9.0000 loss:0.0564\n",
      "Episode:562 meanR:6.0600 R:6.0000 loss:0.0467\n",
      "Episode:563 meanR:6.0200 R:8.0000 loss:0.0346\n",
      "Episode:564 meanR:6.0400 R:10.0000 loss:0.0480\n",
      "Episode:565 meanR:6.1200 R:11.0000 loss:0.0320\n",
      "Episode:566 meanR:6.1500 R:8.0000 loss:0.0589\n",
      "Episode:567 meanR:6.2700 R:16.0000 loss:0.0450\n",
      "Episode:568 meanR:6.3500 R:18.0000 loss:0.0622\n",
      "Episode:569 meanR:6.3000 R:5.0000 loss:0.0546\n",
      "Episode:570 meanR:6.3300 R:6.0000 loss:0.0398\n",
      "Episode:571 meanR:6.3300 R:12.0000 loss:0.0560\n",
      "Episode:572 meanR:6.3800 R:10.0000 loss:0.0567\n",
      "Episode:573 meanR:6.3300 R:2.0000 loss:0.0551\n",
      "Episode:574 meanR:6.3400 R:4.0000 loss:0.0397\n",
      "Episode:575 meanR:6.2300 R:1.0000 loss:0.0217\n",
      "Episode:576 meanR:6.2400 R:7.0000 loss:0.0392\n",
      "Episode:577 meanR:6.2700 R:7.0000 loss:0.0520\n",
      "Episode:578 meanR:6.2400 R:2.0000 loss:0.0383\n",
      "Episode:579 meanR:6.2200 R:2.0000 loss:0.0380\n",
      "Episode:580 meanR:6.1800 R:1.0000 loss:0.0546\n",
      "Episode:581 meanR:6.2600 R:11.0000 loss:0.0439\n",
      "Episode:582 meanR:6.2700 R:7.0000 loss:0.0532\n",
      "Episode:583 meanR:6.2100 R:4.0000 loss:0.0551\n",
      "Episode:584 meanR:6.1000 R:2.0000 loss:0.0262\n",
      "Episode:585 meanR:5.9600 R:1.0000 loss:0.0308\n",
      "Episode:586 meanR:6.0000 R:13.0000 loss:0.0567\n",
      "Episode:587 meanR:6.0000 R:8.0000 loss:0.0611\n",
      "Episode:588 meanR:5.9900 R:13.0000 loss:0.0414\n",
      "Episode:589 meanR:6.0700 R:10.0000 loss:0.0690\n",
      "Episode:590 meanR:6.1000 R:3.0000 loss:0.0466\n",
      "Episode:591 meanR:6.1100 R:2.0000 loss:0.0330\n",
      "Episode:592 meanR:6.1200 R:9.0000 loss:0.0221\n",
      "Episode:593 meanR:6.2000 R:9.0000 loss:0.0401\n",
      "Episode:594 meanR:6.3000 R:9.0000 loss:0.0571\n",
      "Episode:595 meanR:6.3500 R:13.0000 loss:0.0531\n",
      "Episode:596 meanR:6.4100 R:18.0000 loss:0.0677\n",
      "Episode:597 meanR:6.5500 R:14.0000 loss:0.0877\n",
      "Episode:598 meanR:6.6000 R:12.0000 loss:0.0942\n",
      "Episode:599 meanR:6.6200 R:8.0000 loss:0.0658\n",
      "Episode:600 meanR:6.6600 R:14.0000 loss:0.0408\n",
      "Episode:601 meanR:6.7700 R:11.0000 loss:0.0730\n",
      "Episode:602 meanR:6.7700 R:7.0000 loss:0.0397\n",
      "Episode:603 meanR:6.8100 R:12.0000 loss:0.0544\n",
      "Episode:604 meanR:6.8700 R:11.0000 loss:0.0592\n",
      "Episode:605 meanR:6.8400 R:7.0000 loss:0.0675\n",
      "Episode:606 meanR:6.7700 R:5.0000 loss:0.0656\n",
      "Episode:607 meanR:6.6900 R:3.0000 loss:0.0583\n",
      "Episode:608 meanR:6.6400 R:3.0000 loss:0.0216\n",
      "Episode:609 meanR:6.7100 R:9.0000 loss:0.0354\n",
      "Episode:610 meanR:6.8200 R:13.0000 loss:0.0422\n",
      "Episode:611 meanR:6.9300 R:8.0000 loss:0.0709\n",
      "Episode:612 meanR:7.0200 R:9.0000 loss:0.0657\n",
      "Episode:613 meanR:7.2000 R:19.0000 loss:0.0739\n",
      "Episode:614 meanR:7.3500 R:15.0000 loss:0.0531\n",
      "Episode:615 meanR:7.4100 R:6.0000 loss:0.0473\n",
      "Episode:616 meanR:7.4800 R:7.0000 loss:0.0576\n",
      "Episode:617 meanR:7.5500 R:15.0000 loss:0.0517\n",
      "Episode:618 meanR:7.6400 R:10.0000 loss:0.0708\n",
      "Episode:619 meanR:7.6600 R:2.0000 loss:0.0799\n",
      "Episode:620 meanR:7.7400 R:12.0000 loss:0.0457\n",
      "Episode:621 meanR:7.8100 R:10.0000 loss:0.0658\n",
      "Episode:622 meanR:7.8000 R:8.0000 loss:0.0808\n",
      "Episode:623 meanR:7.8100 R:10.0000 loss:0.0479\n",
      "Episode:624 meanR:7.8400 R:12.0000 loss:0.0431\n",
      "Episode:625 meanR:7.8400 R:8.0000 loss:0.0735\n",
      "Episode:626 meanR:7.7800 R:6.0000 loss:0.0511\n",
      "Episode:627 meanR:7.7700 R:11.0000 loss:0.0707\n",
      "Episode:628 meanR:7.7100 R:8.0000 loss:0.0619\n",
      "Episode:629 meanR:7.7000 R:9.0000 loss:0.0720\n",
      "Episode:630 meanR:7.7400 R:11.0000 loss:0.0712\n",
      "Episode:631 meanR:7.7700 R:12.0000 loss:0.0588\n",
      "Episode:632 meanR:7.8300 R:13.0000 loss:0.0557\n",
      "Episode:633 meanR:7.8800 R:5.0000 loss:0.0672\n",
      "Episode:634 meanR:7.8500 R:6.0000 loss:0.0461\n",
      "Episode:635 meanR:7.8600 R:10.0000 loss:0.0395\n",
      "Episode:636 meanR:7.9800 R:14.0000 loss:0.0725\n",
      "Episode:637 meanR:8.0000 R:8.0000 loss:0.0541\n",
      "Episode:638 meanR:8.0300 R:14.0000 loss:0.0548\n",
      "Episode:639 meanR:7.9300 R:2.0000 loss:0.0697\n",
      "Episode:640 meanR:7.8400 R:3.0000 loss:0.0345\n",
      "Episode:641 meanR:7.8600 R:5.0000 loss:0.0662\n",
      "Episode:642 meanR:7.8400 R:8.0000 loss:0.0372\n",
      "Episode:643 meanR:7.8600 R:6.0000 loss:0.0586\n",
      "Episode:644 meanR:7.7900 R:2.0000 loss:0.0546\n",
      "Episode:645 meanR:7.8200 R:5.0000 loss:0.0327\n",
      "Episode:646 meanR:7.8000 R:4.0000 loss:0.0635\n",
      "Episode:647 meanR:7.7600 R:3.0000 loss:0.0235\n",
      "Episode:648 meanR:7.7200 R:0.0000 loss:0.0237\n",
      "Episode:649 meanR:7.6400 R:1.0000 loss:0.0245\n",
      "Episode:650 meanR:7.6000 R:0.0000 loss:0.0143\n",
      "Episode:651 meanR:7.6600 R:3.0000 loss:0.0213\n",
      "Episode:652 meanR:7.7600 R:12.0000 loss:0.0436\n",
      "Episode:653 meanR:7.8000 R:10.0000 loss:0.0652\n",
      "Episode:654 meanR:7.8200 R:6.0000 loss:0.1100\n",
      "Episode:655 meanR:7.8000 R:1.0000 loss:0.0566\n",
      "Episode:656 meanR:7.8600 R:13.0000 loss:0.0344\n",
      "Episode:657 meanR:7.9100 R:7.0000 loss:0.0601\n",
      "Episode:658 meanR:7.8300 R:1.0000 loss:0.0368\n",
      "Episode:659 meanR:7.8500 R:5.0000 loss:0.0220\n",
      "Episode:660 meanR:7.8600 R:5.0000 loss:0.0447\n",
      "Episode:661 meanR:7.8400 R:7.0000 loss:0.0367\n",
      "Episode:662 meanR:7.8400 R:6.0000 loss:0.0577\n",
      "Episode:663 meanR:7.7700 R:1.0000 loss:0.0537\n",
      "Episode:664 meanR:7.6900 R:2.0000 loss:0.0390\n",
      "Episode:665 meanR:7.6300 R:5.0000 loss:0.0246\n",
      "Episode:666 meanR:7.5700 R:2.0000 loss:0.0378\n",
      "Episode:667 meanR:7.4600 R:5.0000 loss:0.0296\n",
      "Episode:668 meanR:7.2800 R:0.0000 loss:0.0246\n",
      "Episode:669 meanR:7.2600 R:3.0000 loss:0.0593\n",
      "Episode:670 meanR:7.2400 R:4.0000 loss:0.0414\n",
      "Episode:671 meanR:7.1200 R:0.0000 loss:0.0250\n",
      "Episode:672 meanR:7.1300 R:11.0000 loss:0.0466\n",
      "Episode:673 meanR:7.2200 R:11.0000 loss:0.0729\n",
      "Episode:674 meanR:7.2400 R:6.0000 loss:0.0464\n",
      "Episode:675 meanR:7.3100 R:8.0000 loss:0.0429\n",
      "Episode:676 meanR:7.2600 R:2.0000 loss:0.0551\n",
      "Episode:677 meanR:7.2400 R:5.0000 loss:0.0481\n",
      "Episode:678 meanR:7.3700 R:15.0000 loss:0.0467\n",
      "Episode:679 meanR:7.4500 R:10.0000 loss:0.0601\n",
      "Episode:680 meanR:7.5000 R:6.0000 loss:0.0512\n",
      "Episode:681 meanR:7.5600 R:17.0000 loss:0.0602\n",
      "Episode:682 meanR:7.7100 R:22.0000 loss:0.0869\n",
      "Episode:683 meanR:7.7400 R:7.0000 loss:0.1100\n",
      "Episode:684 meanR:7.8000 R:8.0000 loss:0.0746\n",
      "Episode:685 meanR:7.8800 R:9.0000 loss:0.0557\n",
      "Episode:686 meanR:7.8600 R:11.0000 loss:0.0705\n",
      "Episode:687 meanR:7.8700 R:9.0000 loss:0.0529\n",
      "Episode:688 meanR:7.8400 R:10.0000 loss:0.0379\n",
      "Episode:689 meanR:7.8500 R:11.0000 loss:0.0610\n",
      "Episode:690 meanR:7.9600 R:14.0000 loss:0.0929\n",
      "Episode:691 meanR:8.0300 R:9.0000 loss:0.0806\n",
      "Episode:692 meanR:8.0000 R:6.0000 loss:0.0521\n",
      "Episode:693 meanR:7.9800 R:7.0000 loss:0.0502\n",
      "Episode:694 meanR:8.0600 R:17.0000 loss:0.0508\n",
      "Episode:695 meanR:7.9900 R:6.0000 loss:0.0756\n",
      "Episode:696 meanR:7.8400 R:3.0000 loss:0.0476\n",
      "Episode:697 meanR:7.8200 R:12.0000 loss:0.0511\n",
      "Episode:698 meanR:7.8100 R:11.0000 loss:0.0684\n",
      "Episode:699 meanR:7.9000 R:17.0000 loss:0.0626\n",
      "Episode:700 meanR:7.8300 R:7.0000 loss:0.0606\n",
      "Episode:701 meanR:7.8200 R:10.0000 loss:0.0596\n",
      "Episode:702 meanR:7.8200 R:7.0000 loss:0.0668\n",
      "Episode:703 meanR:7.7300 R:3.0000 loss:0.0398\n",
      "Episode:704 meanR:7.7100 R:9.0000 loss:0.0356\n",
      "Episode:705 meanR:7.6900 R:5.0000 loss:0.0581\n",
      "Episode:706 meanR:7.6800 R:4.0000 loss:0.0222\n",
      "Episode:707 meanR:7.7800 R:13.0000 loss:0.0459\n",
      "Episode:708 meanR:7.7500 R:0.0000 loss:0.0518\n",
      "Episode:709 meanR:7.6900 R:3.0000 loss:0.0303\n",
      "Episode:710 meanR:7.6500 R:9.0000 loss:0.0455\n",
      "Episode:711 meanR:7.6300 R:6.0000 loss:0.0462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:712 meanR:7.6300 R:9.0000 loss:0.0513\n",
      "Episode:713 meanR:7.4700 R:3.0000 loss:0.0428\n",
      "Episode:714 meanR:7.4300 R:11.0000 loss:0.0562\n",
      "Episode:715 meanR:7.4100 R:4.0000 loss:0.0651\n",
      "Episode:716 meanR:7.4500 R:11.0000 loss:0.0316\n",
      "Episode:717 meanR:7.3800 R:8.0000 loss:0.0537\n",
      "Episode:718 meanR:7.3400 R:6.0000 loss:0.0503\n",
      "Episode:719 meanR:7.3600 R:4.0000 loss:0.0533\n",
      "Episode:720 meanR:7.3300 R:9.0000 loss:0.0443\n",
      "Episode:721 meanR:7.3200 R:9.0000 loss:0.0452\n",
      "Episode:722 meanR:7.2500 R:1.0000 loss:0.0405\n",
      "Episode:723 meanR:7.1500 R:0.0000 loss:0.0195\n",
      "Episode:724 meanR:7.0300 R:0.0000 loss:0.0284\n",
      "Episode:725 meanR:6.9600 R:1.0000 loss:0.0126\n",
      "Episode:726 meanR:6.9200 R:2.0000 loss:0.0270\n",
      "Episode:727 meanR:6.8500 R:4.0000 loss:0.0275\n",
      "Episode:728 meanR:6.8000 R:3.0000 loss:0.0178\n",
      "Episode:729 meanR:6.7300 R:2.0000 loss:0.0237\n",
      "Episode:730 meanR:6.6100 R:-1.0000 loss:0.0083\n",
      "Episode:731 meanR:6.5300 R:4.0000 loss:0.0305\n",
      "Episode:732 meanR:6.4600 R:6.0000 loss:0.0532\n",
      "Episode:733 meanR:6.4400 R:3.0000 loss:0.0234\n",
      "Episode:734 meanR:6.4800 R:10.0000 loss:0.0303\n",
      "Episode:735 meanR:6.4800 R:10.0000 loss:0.0480\n",
      "Episode:736 meanR:6.3800 R:4.0000 loss:0.0376\n",
      "Episode:737 meanR:6.4000 R:10.0000 loss:0.0473\n",
      "Episode:738 meanR:6.2600 R:0.0000 loss:0.0300\n",
      "Episode:739 meanR:6.2900 R:5.0000 loss:0.0445\n",
      "Episode:740 meanR:6.2600 R:0.0000 loss:0.0173\n",
      "Episode:741 meanR:6.2200 R:1.0000 loss:0.0127\n",
      "Episode:742 meanR:6.1500 R:1.0000 loss:0.0194\n",
      "Episode:743 meanR:6.1500 R:6.0000 loss:0.0360\n",
      "Episode:744 meanR:6.1800 R:5.0000 loss:0.0626\n",
      "Episode:745 meanR:6.1700 R:4.0000 loss:0.0569\n",
      "Episode:746 meanR:6.1500 R:2.0000 loss:0.0401\n",
      "Episode:747 meanR:6.1500 R:3.0000 loss:0.0276\n",
      "Episode:748 meanR:6.2000 R:5.0000 loss:0.0232\n",
      "Episode:749 meanR:6.2800 R:9.0000 loss:0.0358\n",
      "Episode:750 meanR:6.3900 R:11.0000 loss:0.0576\n",
      "Episode:751 meanR:6.4900 R:13.0000 loss:0.0598\n",
      "Episode:752 meanR:6.5200 R:15.0000 loss:0.0671\n",
      "Episode:753 meanR:6.5300 R:11.0000 loss:0.0614\n",
      "Episode:754 meanR:6.5400 R:7.0000 loss:0.0664\n",
      "Episode:755 meanR:6.6000 R:7.0000 loss:0.0322\n",
      "Episode:756 meanR:6.6200 R:15.0000 loss:0.0666\n",
      "Episode:757 meanR:6.5900 R:4.0000 loss:0.0688\n",
      "Episode:758 meanR:6.6800 R:10.0000 loss:0.0595\n",
      "Episode:759 meanR:6.7800 R:15.0000 loss:0.0588\n",
      "Episode:760 meanR:6.8300 R:10.0000 loss:0.0691\n",
      "Episode:761 meanR:6.8500 R:9.0000 loss:0.0728\n",
      "Episode:762 meanR:6.9000 R:11.0000 loss:0.0584\n",
      "Episode:763 meanR:6.9300 R:4.0000 loss:0.0771\n",
      "Episode:764 meanR:6.9300 R:2.0000 loss:0.0635\n",
      "Episode:765 meanR:6.9300 R:5.0000 loss:0.0435\n",
      "Episode:766 meanR:6.9800 R:7.0000 loss:0.0609\n",
      "Episode:767 meanR:6.9400 R:1.0000 loss:0.0572\n",
      "Episode:768 meanR:7.0900 R:15.0000 loss:0.0557\n",
      "Episode:769 meanR:7.1800 R:12.0000 loss:0.0865\n",
      "Episode:770 meanR:7.2200 R:8.0000 loss:0.0626\n",
      "Episode:771 meanR:7.2600 R:4.0000 loss:0.0626\n",
      "Episode:772 meanR:7.2100 R:6.0000 loss:0.0522\n",
      "Episode:773 meanR:7.1400 R:4.0000 loss:0.0309\n",
      "Episode:774 meanR:7.1200 R:4.0000 loss:0.0485\n",
      "Episode:775 meanR:7.1200 R:8.0000 loss:0.0372\n",
      "Episode:776 meanR:7.1200 R:2.0000 loss:0.0590\n",
      "Episode:777 meanR:7.1600 R:9.0000 loss:0.0425\n",
      "Episode:778 meanR:7.0600 R:5.0000 loss:0.0502\n",
      "Episode:779 meanR:7.0500 R:9.0000 loss:0.0463\n",
      "Episode:780 meanR:7.0400 R:5.0000 loss:0.0356\n",
      "Episode:781 meanR:6.8700 R:0.0000 loss:0.0488\n",
      "Episode:782 meanR:6.6400 R:-1.0000 loss:0.0280\n",
      "Episode:783 meanR:6.6500 R:8.0000 loss:0.0428\n",
      "Episode:784 meanR:6.6700 R:10.0000 loss:0.0741\n",
      "Episode:785 meanR:6.6400 R:6.0000 loss:0.0684\n",
      "Episode:786 meanR:6.5400 R:1.0000 loss:0.0457\n",
      "Episode:787 meanR:6.5700 R:12.0000 loss:0.0678\n",
      "Episode:788 meanR:6.5100 R:4.0000 loss:0.0754\n",
      "Episode:789 meanR:6.4700 R:7.0000 loss:0.0566\n",
      "Episode:790 meanR:6.4300 R:10.0000 loss:0.0533\n",
      "Episode:791 meanR:6.3400 R:0.0000 loss:0.0369\n",
      "Episode:792 meanR:6.2900 R:1.0000 loss:0.0406\n",
      "Episode:793 meanR:6.2800 R:6.0000 loss:0.0371\n",
      "Episode:794 meanR:6.2100 R:10.0000 loss:0.0256\n",
      "Episode:795 meanR:6.2300 R:8.0000 loss:0.0476\n",
      "Episode:796 meanR:6.2500 R:5.0000 loss:0.0429\n",
      "Episode:797 meanR:6.2200 R:9.0000 loss:0.0520\n",
      "Episode:798 meanR:6.1500 R:4.0000 loss:0.0375\n",
      "Episode:799 meanR:6.0900 R:11.0000 loss:0.0366\n",
      "Episode:800 meanR:6.1500 R:13.0000 loss:0.0644\n",
      "Episode:801 meanR:6.1800 R:13.0000 loss:0.0623\n",
      "Episode:802 meanR:6.2500 R:14.0000 loss:0.0639\n",
      "Episode:803 meanR:6.3400 R:12.0000 loss:0.0780\n",
      "Episode:804 meanR:6.3600 R:11.0000 loss:0.0566\n",
      "Episode:805 meanR:6.4500 R:14.0000 loss:0.0692\n",
      "Episode:806 meanR:6.5100 R:10.0000 loss:0.0559\n",
      "Episode:807 meanR:6.4200 R:4.0000 loss:0.0350\n",
      "Episode:808 meanR:6.5200 R:10.0000 loss:0.0509\n",
      "Episode:809 meanR:6.5600 R:7.0000 loss:0.0596\n",
      "Episode:810 meanR:6.6300 R:16.0000 loss:0.0716\n",
      "Episode:811 meanR:6.7200 R:15.0000 loss:0.0708\n",
      "Episode:812 meanR:6.7300 R:10.0000 loss:0.0832\n",
      "Episode:813 meanR:6.7800 R:8.0000 loss:0.0668\n",
      "Episode:814 meanR:6.7400 R:7.0000 loss:0.0544\n",
      "Episode:815 meanR:6.7400 R:4.0000 loss:0.0471\n",
      "Episode:816 meanR:6.7000 R:7.0000 loss:0.0645\n",
      "Episode:817 meanR:6.6700 R:5.0000 loss:0.0480\n",
      "Episode:818 meanR:6.6500 R:4.0000 loss:0.0339\n",
      "Episode:819 meanR:6.6600 R:5.0000 loss:0.0591\n",
      "Episode:820 meanR:6.6000 R:3.0000 loss:0.0552\n",
      "Episode:821 meanR:6.5500 R:4.0000 loss:0.0271\n",
      "Episode:822 meanR:6.6100 R:7.0000 loss:0.0625\n",
      "Episode:823 meanR:6.7200 R:11.0000 loss:0.0511\n",
      "Episode:824 meanR:6.8000 R:8.0000 loss:0.0849\n",
      "Episode:825 meanR:6.7700 R:-2.0000 loss:0.0519\n",
      "Episode:826 meanR:6.8000 R:5.0000 loss:0.0420\n",
      "Episode:827 meanR:6.8300 R:7.0000 loss:0.0427\n",
      "Episode:828 meanR:6.8000 R:0.0000 loss:0.0282\n",
      "Episode:829 meanR:6.9200 R:14.0000 loss:0.0760\n",
      "Episode:830 meanR:6.9800 R:5.0000 loss:0.0488\n",
      "Episode:831 meanR:6.9900 R:5.0000 loss:0.0768\n",
      "Episode:832 meanR:7.0500 R:12.0000 loss:0.0639\n",
      "Episode:833 meanR:7.1200 R:10.0000 loss:0.0433\n",
      "Episode:834 meanR:7.0700 R:5.0000 loss:0.0649\n",
      "Episode:835 meanR:7.0600 R:9.0000 loss:0.0683\n",
      "Episode:836 meanR:7.1000 R:8.0000 loss:0.0702\n",
      "Episode:837 meanR:7.0400 R:4.0000 loss:0.0783\n",
      "Episode:838 meanR:7.0900 R:5.0000 loss:0.0561\n",
      "Episode:839 meanR:7.0300 R:-1.0000 loss:0.0464\n",
      "Episode:840 meanR:7.1100 R:8.0000 loss:0.0428\n",
      "Episode:841 meanR:7.1600 R:6.0000 loss:0.0401\n",
      "Episode:842 meanR:7.2900 R:14.0000 loss:0.0714\n",
      "Episode:843 meanR:7.2800 R:5.0000 loss:0.0650\n",
      "Episode:844 meanR:7.3800 R:15.0000 loss:0.0818\n",
      "Episode:845 meanR:7.3800 R:4.0000 loss:0.0484\n",
      "Episode:846 meanR:7.4100 R:5.0000 loss:0.0716\n",
      "Episode:847 meanR:7.4400 R:6.0000 loss:0.0391\n",
      "Episode:848 meanR:7.5100 R:12.0000 loss:0.0436\n",
      "Episode:849 meanR:7.5700 R:15.0000 loss:0.0694\n",
      "Episode:850 meanR:7.4900 R:3.0000 loss:0.1033\n",
      "Episode:851 meanR:7.4300 R:7.0000 loss:0.0651\n",
      "Episode:852 meanR:7.3900 R:11.0000 loss:0.0362\n",
      "Episode:853 meanR:7.3400 R:6.0000 loss:0.0643\n",
      "Episode:854 meanR:7.3200 R:5.0000 loss:0.0314\n",
      "Episode:855 meanR:7.3300 R:8.0000 loss:0.0421\n",
      "Episode:856 meanR:7.2300 R:5.0000 loss:0.0679\n",
      "Episode:857 meanR:7.2200 R:3.0000 loss:0.0288\n",
      "Episode:858 meanR:7.2100 R:9.0000 loss:0.0463\n",
      "Episode:859 meanR:7.0900 R:3.0000 loss:0.0310\n",
      "Episode:860 meanR:7.0500 R:6.0000 loss:0.0450\n",
      "Episode:861 meanR:7.0500 R:9.0000 loss:0.0343\n",
      "Episode:862 meanR:7.0800 R:14.0000 loss:0.0351\n",
      "Episode:863 meanR:7.1500 R:11.0000 loss:0.0550\n",
      "Episode:864 meanR:7.1900 R:6.0000 loss:0.0661\n",
      "Episode:865 meanR:7.1600 R:2.0000 loss:0.0450\n",
      "Episode:866 meanR:7.2100 R:12.0000 loss:0.0457\n",
      "Episode:867 meanR:7.2500 R:5.0000 loss:0.0406\n",
      "Episode:868 meanR:7.1500 R:5.0000 loss:0.0500\n",
      "Episode:869 meanR:7.1100 R:8.0000 loss:0.0441\n",
      "Episode:870 meanR:7.1200 R:9.0000 loss:0.0466\n",
      "Episode:871 meanR:7.1200 R:4.0000 loss:0.0435\n",
      "Episode:872 meanR:7.2100 R:15.0000 loss:0.0451\n",
      "Episode:873 meanR:7.2200 R:5.0000 loss:0.0633\n",
      "Episode:874 meanR:7.2000 R:2.0000 loss:0.0236\n",
      "Episode:875 meanR:7.1400 R:2.0000 loss:0.0280\n",
      "Episode:876 meanR:7.1200 R:0.0000 loss:0.0279\n",
      "Episode:877 meanR:7.0200 R:-1.0000 loss:0.0239\n",
      "Episode:878 meanR:6.9800 R:1.0000 loss:0.0245\n",
      "Episode:879 meanR:6.9000 R:1.0000 loss:0.0260\n",
      "Episode:880 meanR:6.8500 R:0.0000 loss:0.0259\n",
      "Episode:881 meanR:6.8400 R:-1.0000 loss:0.0188\n",
      "Episode:882 meanR:6.8900 R:4.0000 loss:0.0186\n",
      "Episode:883 meanR:6.8100 R:0.0000 loss:0.0237\n",
      "Episode:884 meanR:6.7400 R:3.0000 loss:0.0237\n",
      "Episode:885 meanR:6.8000 R:12.0000 loss:0.0354\n",
      "Episode:886 meanR:6.9800 R:19.0000 loss:0.0602\n",
      "Episode:887 meanR:6.9100 R:5.0000 loss:0.0655\n",
      "Episode:888 meanR:6.9000 R:3.0000 loss:0.0404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:889 meanR:6.8900 R:6.0000 loss:0.0213\n",
      "Episode:890 meanR:6.8700 R:8.0000 loss:0.0313\n",
      "Episode:891 meanR:6.9600 R:9.0000 loss:0.0248\n",
      "Episode:892 meanR:7.0700 R:12.0000 loss:0.0568\n",
      "Episode:893 meanR:7.1000 R:9.0000 loss:0.0460\n",
      "Episode:894 meanR:7.1000 R:10.0000 loss:0.0575\n",
      "Episode:895 meanR:7.1100 R:9.0000 loss:0.0490\n",
      "Episode:896 meanR:7.1800 R:12.0000 loss:0.0567\n",
      "Episode:897 meanR:7.1700 R:8.0000 loss:0.0522\n",
      "Episode:898 meanR:7.1900 R:6.0000 loss:0.0457\n",
      "Episode:899 meanR:7.2200 R:14.0000 loss:0.0674\n",
      "Episode:900 meanR:7.2500 R:16.0000 loss:0.0694\n",
      "Episode:901 meanR:7.1900 R:7.0000 loss:0.0823\n",
      "Episode:902 meanR:7.0700 R:2.0000 loss:0.0690\n",
      "Episode:903 meanR:7.0000 R:5.0000 loss:0.0467\n",
      "Episode:904 meanR:6.8900 R:0.0000 loss:0.0420\n",
      "Episode:905 meanR:6.8400 R:9.0000 loss:0.0634\n",
      "Episode:906 meanR:6.7800 R:4.0000 loss:0.0344\n",
      "Episode:907 meanR:6.7800 R:4.0000 loss:0.0336\n",
      "Episode:908 meanR:6.6900 R:1.0000 loss:0.0524\n",
      "Episode:909 meanR:6.6800 R:6.0000 loss:0.0491\n",
      "Episode:910 meanR:6.5300 R:1.0000 loss:0.0438\n",
      "Episode:911 meanR:6.3800 R:0.0000 loss:0.0343\n",
      "Episode:912 meanR:6.2900 R:1.0000 loss:0.0326\n",
      "Episode:913 meanR:6.3200 R:11.0000 loss:0.0481\n",
      "Episode:914 meanR:6.3000 R:5.0000 loss:0.0600\n",
      "Episode:915 meanR:6.3100 R:5.0000 loss:0.0706\n",
      "Episode:916 meanR:6.3300 R:9.0000 loss:0.0416\n",
      "Episode:917 meanR:6.2800 R:0.0000 loss:0.0465\n",
      "Episode:918 meanR:6.2900 R:5.0000 loss:0.0321\n",
      "Episode:919 meanR:6.3700 R:13.0000 loss:0.0447\n",
      "Episode:920 meanR:6.4200 R:8.0000 loss:0.0356\n",
      "Episode:921 meanR:6.4800 R:10.0000 loss:0.0330\n",
      "Episode:922 meanR:6.5300 R:12.0000 loss:0.0468\n",
      "Episode:923 meanR:6.4100 R:-1.0000 loss:0.0519\n",
      "Episode:924 meanR:6.4100 R:8.0000 loss:0.0385\n",
      "Episode:925 meanR:6.5300 R:10.0000 loss:0.0548\n",
      "Episode:926 meanR:6.5900 R:11.0000 loss:0.0567\n",
      "Episode:927 meanR:6.5700 R:5.0000 loss:0.0566\n",
      "Episode:928 meanR:6.6800 R:11.0000 loss:0.0511\n",
      "Episode:929 meanR:6.5900 R:5.0000 loss:0.0629\n",
      "Episode:930 meanR:6.5800 R:4.0000 loss:0.0376\n",
      "Episode:931 meanR:6.6400 R:11.0000 loss:0.0614\n",
      "Episode:932 meanR:6.5400 R:2.0000 loss:0.0641\n",
      "Episode:933 meanR:6.5100 R:7.0000 loss:0.0608\n",
      "Episode:934 meanR:6.4700 R:1.0000 loss:0.0743\n",
      "Episode:935 meanR:6.3900 R:1.0000 loss:0.0379\n",
      "Episode:936 meanR:6.4200 R:11.0000 loss:0.0689\n",
      "Episode:937 meanR:6.4200 R:4.0000 loss:0.0592\n",
      "Episode:938 meanR:6.4500 R:8.0000 loss:0.0494\n",
      "Episode:939 meanR:6.5200 R:6.0000 loss:0.0658\n",
      "Episode:940 meanR:6.6100 R:17.0000 loss:0.0647\n",
      "Episode:941 meanR:6.6600 R:11.0000 loss:0.0739\n",
      "Episode:942 meanR:6.5800 R:6.0000 loss:0.0461\n",
      "Episode:943 meanR:6.6400 R:11.0000 loss:0.0381\n",
      "Episode:944 meanR:6.5300 R:4.0000 loss:0.0637\n",
      "Episode:945 meanR:6.5500 R:6.0000 loss:0.0339\n",
      "Episode:946 meanR:6.6400 R:14.0000 loss:0.0582\n",
      "Episode:947 meanR:6.7200 R:14.0000 loss:0.0523\n",
      "Episode:948 meanR:6.6800 R:8.0000 loss:0.0451\n",
      "Episode:949 meanR:6.5400 R:1.0000 loss:0.0548\n",
      "Episode:950 meanR:6.5700 R:6.0000 loss:0.0415\n",
      "Episode:951 meanR:6.5500 R:5.0000 loss:0.0543\n",
      "Episode:952 meanR:6.4600 R:2.0000 loss:0.0400\n",
      "Episode:953 meanR:6.4200 R:2.0000 loss:0.0189\n",
      "Episode:954 meanR:6.4900 R:12.0000 loss:0.0306\n",
      "Episode:955 meanR:6.4900 R:8.0000 loss:0.0700\n",
      "Episode:956 meanR:6.5800 R:14.0000 loss:0.0929\n",
      "Episode:957 meanR:6.6500 R:10.0000 loss:0.0768\n",
      "Episode:958 meanR:6.7000 R:14.0000 loss:0.0680\n",
      "Episode:959 meanR:6.7800 R:11.0000 loss:0.0821\n",
      "Episode:960 meanR:6.8200 R:10.0000 loss:0.0593\n",
      "Episode:961 meanR:6.7300 R:0.0000 loss:0.0400\n",
      "Episode:962 meanR:6.6900 R:10.0000 loss:0.0565\n",
      "Episode:963 meanR:6.6200 R:4.0000 loss:0.0552\n",
      "Episode:964 meanR:6.5600 R:0.0000 loss:0.0523\n",
      "Episode:965 meanR:6.5400 R:0.0000 loss:0.0313\n",
      "Episode:966 meanR:6.4400 R:2.0000 loss:0.0277\n",
      "Episode:967 meanR:6.4200 R:3.0000 loss:0.0509\n",
      "Episode:968 meanR:6.3700 R:0.0000 loss:0.0346\n",
      "Episode:969 meanR:6.3800 R:9.0000 loss:0.0362\n",
      "Episode:970 meanR:6.3400 R:5.0000 loss:0.0413\n",
      "Episode:971 meanR:6.3600 R:6.0000 loss:0.0302\n",
      "Episode:972 meanR:6.3100 R:10.0000 loss:0.0600\n",
      "Episode:973 meanR:6.3400 R:8.0000 loss:0.0601\n",
      "Episode:974 meanR:6.3300 R:1.0000 loss:0.0501\n",
      "Episode:975 meanR:6.3200 R:1.0000 loss:0.0163\n",
      "Episode:976 meanR:6.3300 R:1.0000 loss:0.0385\n",
      "Episode:977 meanR:6.3500 R:1.0000 loss:0.0572\n",
      "Episode:978 meanR:6.3100 R:-3.0000 loss:0.0307\n",
      "Episode:979 meanR:6.3200 R:2.0000 loss:0.0336\n",
      "Episode:980 meanR:6.4400 R:12.0000 loss:0.0404\n",
      "Episode:981 meanR:6.5600 R:11.0000 loss:0.0630\n",
      "Episode:982 meanR:6.5700 R:5.0000 loss:0.0460\n",
      "Episode:983 meanR:6.5600 R:-1.0000 loss:0.0590\n",
      "Episode:984 meanR:6.5500 R:2.0000 loss:0.0441\n",
      "Episode:985 meanR:6.4300 R:0.0000 loss:0.0579\n",
      "Episode:986 meanR:6.2400 R:0.0000 loss:0.0406\n",
      "Episode:987 meanR:6.1800 R:-1.0000 loss:0.0414\n",
      "Episode:988 meanR:6.1400 R:-1.0000 loss:0.0301\n",
      "Episode:989 meanR:6.0800 R:0.0000 loss:0.0316\n",
      "Episode:990 meanR:5.9900 R:-1.0000 loss:0.0257\n",
      "Episode:991 meanR:5.8900 R:-1.0000 loss:0.0279\n",
      "Episode:992 meanR:5.7700 R:0.0000 loss:0.0222\n",
      "Episode:993 meanR:5.6800 R:0.0000 loss:0.0242\n",
      "Episode:994 meanR:5.5700 R:-1.0000 loss:0.0252\n",
      "Episode:995 meanR:5.4900 R:1.0000 loss:0.0110\n",
      "Episode:996 meanR:5.3700 R:0.0000 loss:0.0144\n",
      "Episode:997 meanR:5.2900 R:0.0000 loss:0.0149\n",
      "Episode:998 meanR:5.2400 R:1.0000 loss:0.0210\n",
      "Episode:999 meanR:5.0900 R:-1.0000 loss:0.0267\n",
      "Episode:1000 meanR:4.9300 R:0.0000 loss:0.0188\n",
      "Episode:1001 meanR:4.8600 R:0.0000 loss:0.0205\n",
      "Episode:1002 meanR:4.8400 R:0.0000 loss:0.0127\n",
      "Episode:1003 meanR:4.8300 R:4.0000 loss:0.0656\n",
      "Episode:1004 meanR:4.8500 R:2.0000 loss:0.0481\n",
      "Episode:1005 meanR:4.7500 R:-1.0000 loss:0.0480\n",
      "Episode:1006 meanR:4.7100 R:0.0000 loss:0.0219\n",
      "Episode:1007 meanR:4.6700 R:0.0000 loss:0.0182\n",
      "Episode:1008 meanR:4.6900 R:3.0000 loss:0.0282\n",
      "Episode:1009 meanR:4.7200 R:9.0000 loss:0.0259\n",
      "Episode:1010 meanR:4.7100 R:0.0000 loss:0.0208\n",
      "Episode:1011 meanR:4.7700 R:6.0000 loss:0.0468\n",
      "Episode:1012 meanR:4.8700 R:11.0000 loss:0.0514\n",
      "Episode:1013 meanR:4.8600 R:10.0000 loss:0.0376\n",
      "Episode:1014 meanR:4.9500 R:14.0000 loss:0.1359\n",
      "Episode:1015 meanR:5.0100 R:11.0000 loss:0.0731\n",
      "Episode:1016 meanR:4.9900 R:7.0000 loss:0.0475\n",
      "Episode:1017 meanR:5.0300 R:4.0000 loss:0.0637\n",
      "Episode:1018 meanR:5.0700 R:9.0000 loss:0.0591\n",
      "Episode:1019 meanR:4.9900 R:5.0000 loss:0.0751\n",
      "Episode:1020 meanR:4.9800 R:7.0000 loss:0.0368\n",
      "Episode:1021 meanR:4.9300 R:5.0000 loss:0.0546\n",
      "Episode:1022 meanR:4.8400 R:3.0000 loss:0.0621\n",
      "Episode:1023 meanR:4.9400 R:9.0000 loss:0.0548\n",
      "Episode:1024 meanR:4.9700 R:11.0000 loss:0.0804\n",
      "Episode:1025 meanR:4.8600 R:-1.0000 loss:0.0718\n",
      "Episode:1026 meanR:4.7800 R:3.0000 loss:0.0647\n",
      "Episode:1027 meanR:4.7200 R:-1.0000 loss:0.0454\n",
      "Episode:1028 meanR:4.6200 R:1.0000 loss:0.0357\n",
      "Episode:1029 meanR:4.6400 R:7.0000 loss:0.0395\n",
      "Episode:1030 meanR:4.6100 R:1.0000 loss:0.0261\n",
      "Episode:1031 meanR:4.5500 R:5.0000 loss:0.0308\n",
      "Episode:1032 meanR:4.5400 R:1.0000 loss:0.0168\n",
      "Episode:1033 meanR:4.5200 R:5.0000 loss:0.0320\n",
      "Episode:1034 meanR:4.5300 R:2.0000 loss:0.0355\n",
      "Episode:1035 meanR:4.5300 R:1.0000 loss:0.0211\n",
      "Episode:1036 meanR:4.5100 R:9.0000 loss:0.0421\n",
      "Episode:1037 meanR:4.5100 R:4.0000 loss:0.0394\n",
      "Episode:1038 meanR:4.4900 R:6.0000 loss:0.0428\n",
      "Episode:1039 meanR:4.4800 R:5.0000 loss:0.0297\n",
      "Episode:1040 meanR:4.3500 R:4.0000 loss:0.0265\n",
      "Episode:1041 meanR:4.4300 R:19.0000 loss:0.0730\n",
      "Episode:1042 meanR:4.4700 R:10.0000 loss:0.0481\n",
      "Episode:1043 meanR:4.4800 R:12.0000 loss:0.0691\n",
      "Episode:1044 meanR:4.5400 R:10.0000 loss:0.0620\n",
      "Episode:1045 meanR:4.5100 R:3.0000 loss:0.0728\n",
      "Episode:1046 meanR:4.3900 R:2.0000 loss:0.0313\n",
      "Episode:1047 meanR:4.3700 R:12.0000 loss:0.0336\n",
      "Episode:1048 meanR:4.3100 R:2.0000 loss:0.0549\n",
      "Episode:1049 meanR:4.4000 R:10.0000 loss:0.0505\n",
      "Episode:1050 meanR:4.4700 R:13.0000 loss:0.0778\n",
      "Episode:1051 meanR:4.6000 R:18.0000 loss:0.0662\n",
      "Episode:1052 meanR:4.7000 R:12.0000 loss:0.0929\n",
      "Episode:1053 meanR:4.7400 R:6.0000 loss:0.0413\n",
      "Episode:1054 meanR:4.7400 R:12.0000 loss:0.0549\n",
      "Episode:1055 meanR:4.7900 R:13.0000 loss:0.1256\n",
      "Episode:1056 meanR:4.6600 R:1.0000 loss:0.0774\n",
      "Episode:1057 meanR:4.6000 R:4.0000 loss:0.0587\n",
      "Episode:1058 meanR:4.5200 R:6.0000 loss:0.0580\n",
      "Episode:1059 meanR:4.4900 R:8.0000 loss:0.0683\n",
      "Episode:1060 meanR:4.4900 R:10.0000 loss:0.0851\n",
      "Episode:1061 meanR:4.5500 R:6.0000 loss:0.0581\n",
      "Episode:1062 meanR:4.4900 R:4.0000 loss:0.0774\n",
      "Episode:1063 meanR:4.5100 R:6.0000 loss:0.0723\n",
      "Episode:1064 meanR:4.5200 R:1.0000 loss:0.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1065 meanR:4.5500 R:3.0000 loss:0.0493\n",
      "Episode:1066 meanR:4.5800 R:5.0000 loss:0.0297\n",
      "Episode:1067 meanR:4.6300 R:8.0000 loss:0.0580\n",
      "Episode:1068 meanR:4.6600 R:3.0000 loss:0.0721\n",
      "Episode:1069 meanR:4.6300 R:6.0000 loss:0.0435\n",
      "Episode:1070 meanR:4.5900 R:1.0000 loss:0.0437\n",
      "Episode:1071 meanR:4.5700 R:4.0000 loss:0.0475\n",
      "Episode:1072 meanR:4.5200 R:5.0000 loss:0.0350\n",
      "Episode:1073 meanR:4.5200 R:8.0000 loss:0.0243\n",
      "Episode:1074 meanR:4.6000 R:9.0000 loss:0.0823\n",
      "Episode:1075 meanR:4.6400 R:5.0000 loss:0.0598\n",
      "Episode:1076 meanR:4.7200 R:9.0000 loss:0.0612\n",
      "Episode:1077 meanR:4.7700 R:6.0000 loss:0.0653\n",
      "Episode:1078 meanR:4.8700 R:7.0000 loss:0.0730\n",
      "Episode:1079 meanR:4.9900 R:14.0000 loss:0.0527\n",
      "Episode:1080 meanR:4.9000 R:3.0000 loss:0.0303\n",
      "Episode:1081 meanR:4.8200 R:3.0000 loss:0.0373\n",
      "Episode:1082 meanR:4.7700 R:0.0000 loss:0.0303\n",
      "Episode:1083 meanR:4.8200 R:4.0000 loss:0.0320\n",
      "Episode:1084 meanR:4.8600 R:6.0000 loss:0.0304\n",
      "Episode:1085 meanR:4.9200 R:6.0000 loss:0.0376\n",
      "Episode:1086 meanR:4.9800 R:6.0000 loss:0.0392\n",
      "Episode:1087 meanR:5.0900 R:10.0000 loss:0.0541\n",
      "Episode:1088 meanR:5.2100 R:11.0000 loss:0.0823\n",
      "Episode:1089 meanR:5.2800 R:7.0000 loss:0.0915\n",
      "Episode:1090 meanR:5.3200 R:3.0000 loss:0.0370\n",
      "Episode:1091 meanR:5.3500 R:2.0000 loss:0.0306\n",
      "Episode:1092 meanR:5.3800 R:3.0000 loss:0.0263\n",
      "Episode:1093 meanR:5.4800 R:10.0000 loss:0.0400\n",
      "Episode:1094 meanR:5.5600 R:7.0000 loss:0.0611\n",
      "Episode:1095 meanR:5.5600 R:1.0000 loss:0.0290\n",
      "Episode:1096 meanR:5.5900 R:3.0000 loss:0.0269\n",
      "Episode:1097 meanR:5.6300 R:4.0000 loss:0.0280\n",
      "Episode:1098 meanR:5.6300 R:1.0000 loss:0.0245\n",
      "Episode:1099 meanR:5.6400 R:0.0000 loss:0.0253\n",
      "Episode:1100 meanR:5.6400 R:0.0000 loss:0.0202\n",
      "Episode:1101 meanR:5.6400 R:0.0000 loss:0.0170\n",
      "Episode:1102 meanR:5.7700 R:13.0000 loss:0.0623\n",
      "Episode:1103 meanR:5.8200 R:9.0000 loss:0.0753\n",
      "Episode:1104 meanR:5.8600 R:6.0000 loss:0.0608\n",
      "Episode:1105 meanR:5.8700 R:0.0000 loss:0.0488\n",
      "Episode:1106 meanR:5.9600 R:9.0000 loss:0.0381\n",
      "Episode:1107 meanR:6.0200 R:6.0000 loss:0.0393\n",
      "Episode:1108 meanR:5.9900 R:0.0000 loss:0.0196\n",
      "Episode:1109 meanR:5.9600 R:6.0000 loss:0.0313\n",
      "Episode:1110 meanR:6.0000 R:4.0000 loss:0.0485\n",
      "Episode:1111 meanR:5.9700 R:3.0000 loss:0.0500\n",
      "Episode:1112 meanR:5.9500 R:9.0000 loss:0.0489\n",
      "Episode:1113 meanR:5.8900 R:4.0000 loss:0.0570\n",
      "Episode:1114 meanR:5.7400 R:-1.0000 loss:0.0304\n",
      "Episode:1115 meanR:5.6700 R:4.0000 loss:0.0408\n",
      "Episode:1116 meanR:5.6000 R:0.0000 loss:0.0387\n",
      "Episode:1117 meanR:5.5700 R:1.0000 loss:0.0174\n",
      "Episode:1118 meanR:5.4800 R:0.0000 loss:0.0156\n",
      "Episode:1119 meanR:5.4200 R:-1.0000 loss:0.0239\n",
      "Episode:1120 meanR:5.3500 R:0.0000 loss:0.0171\n",
      "Episode:1121 meanR:5.2900 R:-1.0000 loss:0.0212\n",
      "Episode:1122 meanR:5.2500 R:-1.0000 loss:0.0181\n",
      "Episode:1123 meanR:5.1500 R:-1.0000 loss:0.0292\n",
      "Episode:1124 meanR:5.0500 R:1.0000 loss:0.0133\n",
      "Episode:1125 meanR:5.0800 R:2.0000 loss:0.0274\n",
      "Episode:1126 meanR:5.0700 R:2.0000 loss:0.0132\n",
      "Episode:1127 meanR:5.0800 R:0.0000 loss:0.0024\n",
      "Episode:1128 meanR:5.0700 R:0.0000 loss:0.0080\n",
      "Episode:1129 meanR:5.0000 R:0.0000 loss:0.0061\n",
      "Episode:1130 meanR:4.9900 R:0.0000 loss:0.0063\n",
      "Episode:1131 meanR:4.9400 R:0.0000 loss:0.0065\n",
      "Episode:1132 meanR:4.9400 R:1.0000 loss:0.0105\n",
      "Episode:1133 meanR:4.8700 R:-2.0000 loss:0.0259\n",
      "Episode:1134 meanR:4.8600 R:1.0000 loss:0.0093\n",
      "Episode:1135 meanR:4.9300 R:8.0000 loss:0.0468\n",
      "Episode:1136 meanR:4.8400 R:0.0000 loss:0.0413\n",
      "Episode:1137 meanR:4.8500 R:5.0000 loss:0.0285\n",
      "Episode:1138 meanR:4.8000 R:1.0000 loss:0.0313\n",
      "Episode:1139 meanR:4.8000 R:5.0000 loss:0.0450\n",
      "Episode:1140 meanR:4.8500 R:9.0000 loss:0.0531\n",
      "Episode:1141 meanR:4.7300 R:7.0000 loss:0.0677\n",
      "Episode:1142 meanR:4.6500 R:2.0000 loss:0.0469\n",
      "Episode:1143 meanR:4.6300 R:10.0000 loss:0.0518\n",
      "Episode:1144 meanR:4.6000 R:7.0000 loss:0.0706\n",
      "Episode:1145 meanR:4.7400 R:17.0000 loss:0.0840\n",
      "Episode:1146 meanR:4.7200 R:0.0000 loss:0.0869\n",
      "Episode:1147 meanR:4.6900 R:9.0000 loss:0.0574\n",
      "Episode:1148 meanR:4.6800 R:1.0000 loss:0.0594\n",
      "Episode:1149 meanR:4.5900 R:1.0000 loss:0.0190\n",
      "Episode:1150 meanR:4.4800 R:2.0000 loss:0.0408\n",
      "Episode:1151 meanR:4.2900 R:-1.0000 loss:0.0190\n",
      "Episode:1152 meanR:4.2600 R:9.0000 loss:0.0489\n",
      "Episode:1153 meanR:4.2400 R:4.0000 loss:0.0779\n",
      "Episode:1154 meanR:4.1500 R:3.0000 loss:0.0303\n",
      "Episode:1155 meanR:4.0700 R:5.0000 loss:0.0483\n",
      "Episode:1156 meanR:4.1100 R:5.0000 loss:0.0605\n",
      "Episode:1157 meanR:4.1100 R:4.0000 loss:0.0539\n",
      "Episode:1158 meanR:4.0800 R:3.0000 loss:0.0293\n",
      "Episode:1159 meanR:4.1400 R:14.0000 loss:0.0537\n",
      "Episode:1160 meanR:4.2200 R:18.0000 loss:0.0592\n",
      "Episode:1161 meanR:4.2800 R:12.0000 loss:0.0631\n",
      "Episode:1162 meanR:4.3800 R:14.0000 loss:0.0791\n",
      "Episode:1163 meanR:4.3200 R:0.0000 loss:0.0516\n",
      "Episode:1164 meanR:4.4300 R:12.0000 loss:0.0797\n",
      "Episode:1165 meanR:4.4200 R:2.0000 loss:0.0604\n",
      "Episode:1166 meanR:4.3800 R:1.0000 loss:0.0492\n",
      "Episode:1167 meanR:4.3200 R:2.0000 loss:0.0494\n",
      "Episode:1168 meanR:4.3200 R:3.0000 loss:0.0571\n",
      "Episode:1169 meanR:4.2700 R:1.0000 loss:0.0161\n",
      "Episode:1170 meanR:4.2700 R:1.0000 loss:0.0264\n",
      "Episode:1171 meanR:4.2200 R:-1.0000 loss:0.0361\n",
      "Episode:1172 meanR:4.2200 R:5.0000 loss:0.0392\n",
      "Episode:1173 meanR:4.2100 R:7.0000 loss:0.0478\n",
      "Episode:1174 meanR:4.1800 R:6.0000 loss:0.0490\n",
      "Episode:1175 meanR:4.1300 R:0.0000 loss:0.0281\n",
      "Episode:1176 meanR:4.0600 R:2.0000 loss:0.0303\n",
      "Episode:1177 meanR:4.0100 R:1.0000 loss:0.0291\n",
      "Episode:1178 meanR:3.9400 R:0.0000 loss:0.0243\n",
      "Episode:1179 meanR:3.8000 R:0.0000 loss:0.0129\n",
      "Episode:1180 meanR:3.7900 R:2.0000 loss:0.0182\n",
      "Episode:1181 meanR:3.8300 R:7.0000 loss:0.1363\n",
      "Episode:1182 meanR:3.8400 R:1.0000 loss:0.0520\n",
      "Episode:1183 meanR:3.8400 R:4.0000 loss:0.0642\n",
      "Episode:1184 meanR:3.8000 R:2.0000 loss:0.0551\n",
      "Episode:1185 meanR:3.7700 R:3.0000 loss:0.0389\n",
      "Episode:1186 meanR:3.7500 R:4.0000 loss:0.0420\n",
      "Episode:1187 meanR:3.6800 R:3.0000 loss:0.0480\n",
      "Episode:1188 meanR:3.6000 R:3.0000 loss:0.0442\n",
      "Episode:1189 meanR:3.5400 R:1.0000 loss:0.0481\n",
      "Episode:1190 meanR:3.5500 R:4.0000 loss:0.0466\n",
      "Episode:1191 meanR:3.5600 R:3.0000 loss:0.0507\n",
      "Episode:1192 meanR:3.5500 R:2.0000 loss:0.0498\n",
      "Episode:1193 meanR:3.4700 R:2.0000 loss:0.0410\n",
      "Episode:1194 meanR:3.4600 R:6.0000 loss:0.0600\n",
      "Episode:1195 meanR:3.4500 R:0.0000 loss:0.0500\n",
      "Episode:1196 meanR:3.4100 R:-1.0000 loss:0.0256\n",
      "Episode:1197 meanR:3.3700 R:0.0000 loss:0.0335\n",
      "Episode:1198 meanR:3.3400 R:-2.0000 loss:0.0249\n",
      "Episode:1199 meanR:3.3400 R:0.0000 loss:0.0178\n",
      "Episode:1200 meanR:3.3700 R:3.0000 loss:0.0406\n",
      "Episode:1201 meanR:3.3700 R:0.0000 loss:0.0471\n",
      "Episode:1202 meanR:3.2800 R:4.0000 loss:0.0524\n",
      "Episode:1203 meanR:3.2200 R:3.0000 loss:0.0572\n",
      "Episode:1204 meanR:3.1700 R:1.0000 loss:0.0267\n",
      "Episode:1205 meanR:3.1700 R:0.0000 loss:0.0307\n",
      "Episode:1206 meanR:3.0700 R:-1.0000 loss:0.0295\n",
      "Episode:1207 meanR:3.0200 R:1.0000 loss:0.0264\n",
      "Episode:1208 meanR:3.0200 R:0.0000 loss:0.0331\n",
      "Episode:1209 meanR:2.9600 R:0.0000 loss:0.0237\n",
      "Episode:1210 meanR:2.9400 R:2.0000 loss:0.0297\n",
      "Episode:1211 meanR:2.9200 R:1.0000 loss:0.0171\n",
      "Episode:1212 meanR:2.8900 R:6.0000 loss:0.0372\n",
      "Episode:1213 meanR:2.9000 R:5.0000 loss:0.0557\n",
      "Episode:1214 meanR:3.0700 R:16.0000 loss:0.0896\n",
      "Episode:1215 meanR:3.0900 R:6.0000 loss:0.0706\n",
      "Episode:1216 meanR:3.1700 R:8.0000 loss:0.1135\n",
      "Episode:1217 meanR:3.1600 R:0.0000 loss:0.0645\n",
      "Episode:1218 meanR:3.2200 R:6.0000 loss:0.0522\n",
      "Episode:1219 meanR:3.2300 R:0.0000 loss:0.0436\n",
      "Episode:1220 meanR:3.3500 R:12.0000 loss:0.0449\n",
      "Episode:1221 meanR:3.4100 R:5.0000 loss:0.0811\n",
      "Episode:1222 meanR:3.4700 R:5.0000 loss:0.0882\n",
      "Episode:1223 meanR:3.5500 R:7.0000 loss:0.0602\n",
      "Episode:1224 meanR:3.5700 R:3.0000 loss:0.0569\n",
      "Episode:1225 meanR:3.5500 R:0.0000 loss:0.0498\n",
      "Episode:1226 meanR:3.5600 R:3.0000 loss:0.0335\n",
      "Episode:1227 meanR:3.5800 R:2.0000 loss:0.0277\n",
      "Episode:1228 meanR:3.5600 R:-2.0000 loss:0.0340\n",
      "Episode:1229 meanR:3.5900 R:3.0000 loss:0.0419\n",
      "Episode:1230 meanR:3.6100 R:2.0000 loss:0.0340\n",
      "Episode:1231 meanR:3.7200 R:11.0000 loss:0.0456\n",
      "Episode:1232 meanR:3.7500 R:4.0000 loss:0.0532\n",
      "Episode:1233 meanR:3.9000 R:13.0000 loss:0.0634\n",
      "Episode:1234 meanR:4.0100 R:12.0000 loss:0.0701\n",
      "Episode:1235 meanR:4.0900 R:16.0000 loss:0.0746\n",
      "Episode:1236 meanR:4.2100 R:12.0000 loss:0.0437\n",
      "Episode:1237 meanR:4.3000 R:14.0000 loss:0.0692\n",
      "Episode:1238 meanR:4.3900 R:10.0000 loss:0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1239 meanR:4.4100 R:7.0000 loss:0.0716\n",
      "Episode:1240 meanR:4.3800 R:6.0000 loss:0.0479\n",
      "Episode:1241 meanR:4.3700 R:6.0000 loss:0.0448\n",
      "Episode:1242 meanR:4.4900 R:14.0000 loss:0.0423\n",
      "Episode:1243 meanR:4.3900 R:0.0000 loss:0.0697\n",
      "Episode:1244 meanR:4.3200 R:0.0000 loss:0.0628\n",
      "Episode:1245 meanR:4.1600 R:1.0000 loss:0.0345\n",
      "Episode:1246 meanR:4.1700 R:1.0000 loss:0.0290\n",
      "Episode:1247 meanR:4.1100 R:3.0000 loss:0.0464\n",
      "Episode:1248 meanR:4.1400 R:4.0000 loss:0.0584\n",
      "Episode:1249 meanR:4.1300 R:0.0000 loss:0.0494\n",
      "Episode:1250 meanR:4.1300 R:2.0000 loss:0.0283\n",
      "Episode:1251 meanR:4.2000 R:6.0000 loss:0.0457\n",
      "Episode:1252 meanR:4.1700 R:6.0000 loss:0.0516\n",
      "Episode:1253 meanR:4.1700 R:4.0000 loss:0.0488\n",
      "Episode:1254 meanR:4.1700 R:3.0000 loss:0.0505\n",
      "Episode:1255 meanR:4.1500 R:3.0000 loss:0.0404\n",
      "Episode:1256 meanR:4.1000 R:0.0000 loss:0.0324\n",
      "Episode:1257 meanR:4.0700 R:1.0000 loss:0.0406\n",
      "Episode:1258 meanR:4.0400 R:0.0000 loss:0.0087\n",
      "Episode:1259 meanR:3.9100 R:1.0000 loss:0.0119\n",
      "Episode:1260 meanR:3.7300 R:0.0000 loss:0.0102\n",
      "Episode:1261 meanR:3.6400 R:3.0000 loss:0.0170\n",
      "Episode:1262 meanR:3.5100 R:1.0000 loss:0.0158\n",
      "Episode:1263 meanR:3.5200 R:1.0000 loss:0.0126\n",
      "Episode:1264 meanR:3.4200 R:2.0000 loss:0.0161\n",
      "Episode:1265 meanR:3.4100 R:1.0000 loss:0.0126\n",
      "Episode:1266 meanR:3.4200 R:2.0000 loss:0.0178\n",
      "Episode:1267 meanR:3.4000 R:0.0000 loss:0.0206\n",
      "Episode:1268 meanR:3.4000 R:3.0000 loss:0.0335\n",
      "Episode:1269 meanR:3.4100 R:2.0000 loss:0.0227\n",
      "Episode:1270 meanR:3.4400 R:4.0000 loss:0.0302\n",
      "Episode:1271 meanR:3.4600 R:1.0000 loss:0.0276\n",
      "Episode:1272 meanR:3.4100 R:0.0000 loss:0.0170\n",
      "Episode:1273 meanR:3.3700 R:3.0000 loss:0.0190\n",
      "Episode:1274 meanR:3.4100 R:10.0000 loss:0.0385\n",
      "Episode:1275 meanR:3.4100 R:0.0000 loss:0.0329\n",
      "Episode:1276 meanR:3.4200 R:3.0000 loss:0.0465\n",
      "Episode:1277 meanR:3.4200 R:1.0000 loss:0.0207\n",
      "Episode:1278 meanR:3.4300 R:1.0000 loss:0.0330\n",
      "Episode:1279 meanR:3.4300 R:0.0000 loss:0.0258\n",
      "Episode:1280 meanR:3.4800 R:7.0000 loss:0.0484\n",
      "Episode:1281 meanR:3.4700 R:6.0000 loss:0.0471\n",
      "Episode:1282 meanR:3.4600 R:0.0000 loss:0.0363\n",
      "Episode:1283 meanR:3.5400 R:12.0000 loss:0.0356\n",
      "Episode:1284 meanR:3.6100 R:9.0000 loss:0.0569\n",
      "Episode:1285 meanR:3.6600 R:8.0000 loss:0.0483\n",
      "Episode:1286 meanR:3.6600 R:4.0000 loss:0.0358\n",
      "Episode:1287 meanR:3.6600 R:3.0000 loss:0.0614\n",
      "Episode:1288 meanR:3.6700 R:4.0000 loss:0.0287\n",
      "Episode:1289 meanR:3.7500 R:9.0000 loss:0.0312\n",
      "Episode:1290 meanR:3.7600 R:5.0000 loss:0.0423\n",
      "Episode:1291 meanR:3.8200 R:9.0000 loss:0.0379\n",
      "Episode:1292 meanR:3.8200 R:2.0000 loss:0.0207\n",
      "Episode:1293 meanR:3.9200 R:12.0000 loss:0.0250\n",
      "Episode:1294 meanR:4.0000 R:14.0000 loss:0.0446\n",
      "Episode:1295 meanR:4.0300 R:3.0000 loss:0.0394\n",
      "Episode:1296 meanR:4.0900 R:5.0000 loss:0.0378\n",
      "Episode:1297 meanR:4.1700 R:8.0000 loss:0.0456\n",
      "Episode:1298 meanR:4.2800 R:9.0000 loss:0.0292\n",
      "Episode:1299 meanR:4.4400 R:16.0000 loss:0.0685\n",
      "Episode:1300 meanR:4.4700 R:6.0000 loss:0.0342\n",
      "Episode:1301 meanR:4.5400 R:7.0000 loss:0.0533\n",
      "Episode:1302 meanR:4.5000 R:0.0000 loss:0.0261\n",
      "Episode:1303 meanR:4.4800 R:1.0000 loss:0.0275\n",
      "Episode:1304 meanR:4.4800 R:1.0000 loss:0.0289\n",
      "Episode:1305 meanR:4.5100 R:3.0000 loss:0.0330\n",
      "Episode:1306 meanR:4.5700 R:5.0000 loss:0.0352\n",
      "Episode:1307 meanR:4.6000 R:4.0000 loss:0.0263\n",
      "Episode:1308 meanR:4.7200 R:12.0000 loss:0.0326\n",
      "Episode:1309 meanR:4.8400 R:12.0000 loss:0.0539\n",
      "Episode:1310 meanR:4.8500 R:3.0000 loss:0.0265\n",
      "Episode:1311 meanR:5.0000 R:16.0000 loss:0.0493\n",
      "Episode:1312 meanR:5.0000 R:6.0000 loss:0.0274\n",
      "Episode:1313 meanR:5.0400 R:9.0000 loss:0.0602\n",
      "Episode:1314 meanR:4.9700 R:9.0000 loss:0.0473\n",
      "Episode:1315 meanR:5.0600 R:15.0000 loss:0.0520\n",
      "Episode:1316 meanR:5.1400 R:16.0000 loss:0.0589\n",
      "Episode:1317 meanR:5.2400 R:10.0000 loss:0.0332\n",
      "Episode:1318 meanR:5.2400 R:6.0000 loss:0.0227\n",
      "Episode:1319 meanR:5.3300 R:9.0000 loss:0.0255\n",
      "Episode:1320 meanR:5.3000 R:9.0000 loss:0.0633\n",
      "Episode:1321 meanR:5.3700 R:12.0000 loss:0.0314\n",
      "Episode:1322 meanR:5.4300 R:11.0000 loss:0.0904\n",
      "Episode:1323 meanR:5.4200 R:6.0000 loss:0.0420\n",
      "Episode:1324 meanR:5.5300 R:14.0000 loss:0.0586\n",
      "Episode:1325 meanR:5.6600 R:13.0000 loss:0.0603\n",
      "Episode:1326 meanR:5.6800 R:5.0000 loss:0.0490\n",
      "Episode:1327 meanR:5.6900 R:3.0000 loss:0.0714\n",
      "Episode:1328 meanR:5.7500 R:4.0000 loss:0.0431\n",
      "Episode:1329 meanR:5.7300 R:1.0000 loss:0.0536\n",
      "Episode:1330 meanR:5.7300 R:2.0000 loss:0.0342\n",
      "Episode:1331 meanR:5.6600 R:4.0000 loss:0.0330\n",
      "Episode:1332 meanR:5.7000 R:8.0000 loss:0.0626\n",
      "Episode:1333 meanR:5.6400 R:7.0000 loss:0.0612\n",
      "Episode:1334 meanR:5.5800 R:6.0000 loss:0.0489\n",
      "Episode:1335 meanR:5.4600 R:4.0000 loss:0.0456\n",
      "Episode:1336 meanR:5.4200 R:8.0000 loss:0.0442\n",
      "Episode:1337 meanR:5.4200 R:14.0000 loss:0.0721\n",
      "Episode:1338 meanR:5.4900 R:17.0000 loss:0.0745\n",
      "Episode:1339 meanR:5.5200 R:10.0000 loss:0.0475\n",
      "Episode:1340 meanR:5.5400 R:8.0000 loss:0.0418\n",
      "Episode:1341 meanR:5.5700 R:9.0000 loss:0.0238\n",
      "Episode:1342 meanR:5.5800 R:15.0000 loss:0.0762\n",
      "Episode:1343 meanR:5.6300 R:5.0000 loss:0.0640\n",
      "Episode:1344 meanR:5.6800 R:5.0000 loss:0.0524\n",
      "Episode:1345 meanR:5.7200 R:5.0000 loss:0.0531\n",
      "Episode:1346 meanR:5.7100 R:0.0000 loss:0.0305\n",
      "Episode:1347 meanR:5.7300 R:5.0000 loss:0.0424\n",
      "Episode:1348 meanR:5.7700 R:8.0000 loss:0.0439\n",
      "Episode:1349 meanR:5.7900 R:2.0000 loss:0.0434\n",
      "Episode:1350 meanR:5.8300 R:6.0000 loss:0.0408\n",
      "Episode:1351 meanR:5.8200 R:5.0000 loss:0.0348\n",
      "Episode:1352 meanR:5.7800 R:2.0000 loss:0.0376\n",
      "Episode:1353 meanR:5.7600 R:2.0000 loss:0.0174\n",
      "Episode:1354 meanR:5.8200 R:9.0000 loss:0.0405\n",
      "Episode:1355 meanR:5.8400 R:5.0000 loss:0.0476\n",
      "Episode:1356 meanR:5.8500 R:1.0000 loss:0.0248\n",
      "Episode:1357 meanR:5.9700 R:13.0000 loss:0.0644\n",
      "Episode:1358 meanR:6.0300 R:6.0000 loss:0.1318\n",
      "Episode:1359 meanR:6.0500 R:3.0000 loss:0.0654\n",
      "Episode:1360 meanR:6.1500 R:10.0000 loss:0.0669\n",
      "Episode:1361 meanR:6.2100 R:9.0000 loss:0.0801\n",
      "Episode:1362 meanR:6.2700 R:7.0000 loss:0.0765\n",
      "Episode:1363 meanR:6.3800 R:12.0000 loss:0.0818\n",
      "Episode:1364 meanR:6.4200 R:6.0000 loss:0.0713\n",
      "Episode:1365 meanR:6.4700 R:6.0000 loss:0.0955\n",
      "Episode:1366 meanR:6.5600 R:11.0000 loss:0.0782\n",
      "Episode:1367 meanR:6.5900 R:3.0000 loss:0.0549\n",
      "Episode:1368 meanR:6.6000 R:4.0000 loss:0.0404\n",
      "Episode:1369 meanR:6.6000 R:2.0000 loss:0.0409\n",
      "Episode:1370 meanR:6.6000 R:4.0000 loss:0.0329\n",
      "Episode:1371 meanR:6.5900 R:0.0000 loss:0.0260\n",
      "Episode:1372 meanR:6.6300 R:4.0000 loss:0.0444\n",
      "Episode:1373 meanR:6.6100 R:1.0000 loss:0.0498\n",
      "Episode:1374 meanR:6.5200 R:1.0000 loss:0.0303\n",
      "Episode:1375 meanR:6.5100 R:-1.0000 loss:0.0311\n",
      "Episode:1376 meanR:6.5300 R:5.0000 loss:0.0294\n",
      "Episode:1377 meanR:6.5200 R:0.0000 loss:0.0529\n",
      "Episode:1378 meanR:6.5800 R:7.0000 loss:0.0406\n",
      "Episode:1379 meanR:6.6800 R:10.0000 loss:0.0450\n",
      "Episode:1380 meanR:6.6400 R:3.0000 loss:0.0483\n",
      "Episode:1381 meanR:6.6400 R:6.0000 loss:0.0442\n",
      "Episode:1382 meanR:6.6400 R:0.0000 loss:0.0350\n",
      "Episode:1383 meanR:6.5100 R:-1.0000 loss:0.0526\n",
      "Episode:1384 meanR:6.4600 R:4.0000 loss:0.0595\n",
      "Episode:1385 meanR:6.3800 R:0.0000 loss:0.0483\n",
      "Episode:1386 meanR:6.3500 R:1.0000 loss:0.0360\n",
      "Episode:1387 meanR:6.3100 R:-1.0000 loss:0.0610\n",
      "Episode:1388 meanR:6.3100 R:4.0000 loss:0.0490\n",
      "Episode:1389 meanR:6.3100 R:9.0000 loss:0.0463\n",
      "Episode:1390 meanR:6.3900 R:13.0000 loss:0.0653\n",
      "Episode:1391 meanR:6.3400 R:4.0000 loss:0.0543\n",
      "Episode:1392 meanR:6.3500 R:3.0000 loss:0.0476\n",
      "Episode:1393 meanR:6.2300 R:0.0000 loss:0.0434\n",
      "Episode:1394 meanR:6.1000 R:1.0000 loss:0.0424\n",
      "Episode:1395 meanR:6.1600 R:9.0000 loss:0.0613\n",
      "Episode:1396 meanR:6.1500 R:4.0000 loss:0.0541\n",
      "Episode:1397 meanR:6.1200 R:5.0000 loss:0.0367\n",
      "Episode:1398 meanR:6.0800 R:5.0000 loss:0.0611\n",
      "Episode:1399 meanR:6.0400 R:12.0000 loss:0.0855\n",
      "Episode:1400 meanR:6.0500 R:7.0000 loss:0.0735\n",
      "Episode:1401 meanR:6.0200 R:4.0000 loss:0.0633\n",
      "Episode:1402 meanR:6.0700 R:5.0000 loss:0.0492\n",
      "Episode:1403 meanR:6.0800 R:2.0000 loss:0.0379\n",
      "Episode:1404 meanR:6.1100 R:4.0000 loss:0.0576\n",
      "Episode:1405 meanR:6.1100 R:3.0000 loss:0.0555\n",
      "Episode:1406 meanR:6.0600 R:0.0000 loss:0.0395\n",
      "Episode:1407 meanR:6.0400 R:2.0000 loss:0.0452\n",
      "Episode:1408 meanR:5.9700 R:5.0000 loss:0.0451\n",
      "Episode:1409 meanR:5.9200 R:7.0000 loss:0.0569\n",
      "Episode:1410 meanR:5.9500 R:6.0000 loss:0.0722\n",
      "Episode:1411 meanR:5.8000 R:1.0000 loss:0.0548\n",
      "Episode:1412 meanR:5.8400 R:10.0000 loss:0.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1413 meanR:5.7400 R:-1.0000 loss:0.0469\n",
      "Episode:1414 meanR:5.6600 R:1.0000 loss:0.0480\n",
      "Episode:1415 meanR:5.5600 R:5.0000 loss:0.0552\n",
      "Episode:1416 meanR:5.4500 R:5.0000 loss:0.0520\n",
      "Episode:1417 meanR:5.3600 R:1.0000 loss:0.0309\n",
      "Episode:1418 meanR:5.3100 R:1.0000 loss:0.0389\n",
      "Episode:1419 meanR:5.2100 R:-1.0000 loss:0.0299\n",
      "Episode:1420 meanR:5.1500 R:3.0000 loss:0.0296\n",
      "Episode:1421 meanR:5.0300 R:0.0000 loss:0.0166\n",
      "Episode:1422 meanR:4.9300 R:1.0000 loss:0.0202\n",
      "Episode:1423 meanR:4.8900 R:2.0000 loss:0.0156\n",
      "Episode:1424 meanR:4.7700 R:2.0000 loss:0.0287\n",
      "Episode:1425 meanR:4.6400 R:0.0000 loss:0.0245\n",
      "Episode:1426 meanR:4.6100 R:2.0000 loss:0.0265\n",
      "Episode:1427 meanR:4.6200 R:4.0000 loss:0.0281\n",
      "Episode:1428 meanR:4.5700 R:-1.0000 loss:0.0269\n",
      "Episode:1429 meanR:4.5700 R:1.0000 loss:0.0216\n",
      "Episode:1430 meanR:4.5900 R:4.0000 loss:0.0229\n",
      "Episode:1431 meanR:4.5600 R:1.0000 loss:0.0325\n",
      "Episode:1432 meanR:4.5000 R:2.0000 loss:0.0278\n",
      "Episode:1433 meanR:4.4300 R:0.0000 loss:0.0446\n",
      "Episode:1434 meanR:4.4500 R:8.0000 loss:0.0428\n",
      "Episode:1435 meanR:4.4600 R:5.0000 loss:0.0519\n",
      "Episode:1436 meanR:4.5100 R:13.0000 loss:0.0473\n",
      "Episode:1437 meanR:4.4000 R:3.0000 loss:0.0614\n",
      "Episode:1438 meanR:4.3200 R:9.0000 loss:0.0475\n",
      "Episode:1439 meanR:4.3300 R:11.0000 loss:0.0604\n",
      "Episode:1440 meanR:4.3500 R:10.0000 loss:0.0539\n",
      "Episode:1441 meanR:4.3900 R:13.0000 loss:0.0633\n",
      "Episode:1442 meanR:4.3200 R:8.0000 loss:0.0704\n",
      "Episode:1443 meanR:4.3200 R:5.0000 loss:0.0652\n",
      "Episode:1444 meanR:4.3100 R:4.0000 loss:0.0435\n",
      "Episode:1445 meanR:4.3200 R:6.0000 loss:0.0441\n",
      "Episode:1446 meanR:4.3400 R:2.0000 loss:0.0290\n",
      "Episode:1447 meanR:4.3600 R:7.0000 loss:0.0565\n",
      "Episode:1448 meanR:4.4000 R:12.0000 loss:0.0584\n",
      "Episode:1449 meanR:4.5000 R:12.0000 loss:0.0941\n",
      "Episode:1450 meanR:4.4600 R:2.0000 loss:0.0929\n",
      "Episode:1451 meanR:4.5500 R:14.0000 loss:0.0488\n",
      "Episode:1452 meanR:4.5900 R:6.0000 loss:0.0665\n",
      "Episode:1453 meanR:4.5900 R:2.0000 loss:0.0539\n",
      "Episode:1454 meanR:4.5100 R:1.0000 loss:0.0266\n",
      "Episode:1455 meanR:4.5900 R:13.0000 loss:0.0610\n",
      "Episode:1456 meanR:4.6000 R:2.0000 loss:0.0479\n",
      "Episode:1457 meanR:4.4700 R:0.0000 loss:0.0326\n",
      "Episode:1458 meanR:4.4600 R:5.0000 loss:0.0305\n",
      "Episode:1459 meanR:4.5000 R:7.0000 loss:0.0404\n",
      "Episode:1460 meanR:4.4500 R:5.0000 loss:0.0615\n",
      "Episode:1461 meanR:4.4100 R:5.0000 loss:0.0395\n",
      "Episode:1462 meanR:4.4900 R:15.0000 loss:0.0696\n",
      "Episode:1463 meanR:4.4600 R:9.0000 loss:0.0568\n",
      "Episode:1464 meanR:4.4800 R:8.0000 loss:0.0381\n",
      "Episode:1465 meanR:4.5800 R:16.0000 loss:0.0624\n",
      "Episode:1466 meanR:4.6200 R:15.0000 loss:0.0595\n",
      "Episode:1467 meanR:4.7100 R:12.0000 loss:0.0819\n",
      "Episode:1468 meanR:4.6800 R:1.0000 loss:0.0603\n",
      "Episode:1469 meanR:4.6700 R:1.0000 loss:0.0397\n",
      "Episode:1470 meanR:4.6200 R:-1.0000 loss:0.0474\n",
      "Episode:1471 meanR:4.6300 R:1.0000 loss:0.0455\n",
      "Episode:1472 meanR:4.6000 R:1.0000 loss:0.0362\n",
      "Episode:1473 meanR:4.6500 R:6.0000 loss:0.0583\n",
      "Episode:1474 meanR:4.6800 R:4.0000 loss:0.0524\n",
      "Episode:1475 meanR:4.7700 R:8.0000 loss:0.0495\n",
      "Episode:1476 meanR:4.8300 R:11.0000 loss:0.0448\n",
      "Episode:1477 meanR:4.8600 R:3.0000 loss:0.0415\n",
      "Episode:1478 meanR:4.8200 R:3.0000 loss:0.0527\n",
      "Episode:1479 meanR:4.9000 R:18.0000 loss:0.0698\n",
      "Episode:1480 meanR:4.9400 R:7.0000 loss:0.0774\n",
      "Episode:1481 meanR:5.1100 R:23.0000 loss:0.0704\n",
      "Episode:1482 meanR:5.1800 R:7.0000 loss:0.1272\n",
      "Episode:1483 meanR:5.2100 R:2.0000 loss:0.0503\n",
      "Episode:1484 meanR:5.2000 R:3.0000 loss:0.0549\n",
      "Episode:1485 meanR:5.2500 R:5.0000 loss:0.0529\n",
      "Episode:1486 meanR:5.3600 R:12.0000 loss:0.0583\n",
      "Episode:1487 meanR:5.4400 R:7.0000 loss:0.0579\n",
      "Episode:1488 meanR:5.5100 R:11.0000 loss:0.0693\n",
      "Episode:1489 meanR:5.4500 R:3.0000 loss:0.0466\n",
      "Episode:1490 meanR:5.3700 R:5.0000 loss:0.0398\n",
      "Episode:1491 meanR:5.3800 R:5.0000 loss:0.0525\n",
      "Episode:1492 meanR:5.4200 R:7.0000 loss:0.0584\n",
      "Episode:1493 meanR:5.5000 R:8.0000 loss:0.0431\n",
      "Episode:1494 meanR:5.5300 R:4.0000 loss:0.0774\n",
      "Episode:1495 meanR:5.5700 R:13.0000 loss:0.0486\n",
      "Episode:1496 meanR:5.5900 R:6.0000 loss:0.0535\n",
      "Episode:1497 meanR:5.5900 R:5.0000 loss:0.0554\n",
      "Episode:1498 meanR:5.5500 R:1.0000 loss:0.0470\n",
      "Episode:1499 meanR:5.4800 R:5.0000 loss:0.0446\n",
      "Episode:1500 meanR:5.4200 R:1.0000 loss:0.0371\n",
      "Episode:1501 meanR:5.3800 R:0.0000 loss:0.0257\n",
      "Episode:1502 meanR:5.3600 R:3.0000 loss:0.0251\n",
      "Episode:1503 meanR:5.3900 R:5.0000 loss:0.0249\n",
      "Episode:1504 meanR:5.4700 R:12.0000 loss:0.0438\n",
      "Episode:1505 meanR:5.5600 R:12.0000 loss:0.0549\n",
      "Episode:1506 meanR:5.5800 R:2.0000 loss:0.0562\n",
      "Episode:1507 meanR:5.6200 R:6.0000 loss:0.0472\n",
      "Episode:1508 meanR:5.6600 R:9.0000 loss:0.0496\n",
      "Episode:1509 meanR:5.6500 R:6.0000 loss:0.0360\n",
      "Episode:1510 meanR:5.6700 R:8.0000 loss:0.0575\n",
      "Episode:1511 meanR:5.7100 R:5.0000 loss:0.0598\n",
      "Episode:1512 meanR:5.6600 R:5.0000 loss:0.0413\n",
      "Episode:1513 meanR:5.7100 R:4.0000 loss:0.0267\n",
      "Episode:1514 meanR:5.7400 R:4.0000 loss:0.0280\n",
      "Episode:1515 meanR:5.7500 R:6.0000 loss:0.0356\n",
      "Episode:1516 meanR:5.7300 R:3.0000 loss:0.0357\n",
      "Episode:1517 meanR:5.7400 R:2.0000 loss:0.0442\n",
      "Episode:1518 meanR:5.8000 R:7.0000 loss:0.0453\n",
      "Episode:1519 meanR:5.8400 R:3.0000 loss:0.0403\n",
      "Episode:1520 meanR:5.8500 R:4.0000 loss:0.0549\n",
      "Episode:1521 meanR:5.9100 R:6.0000 loss:0.0709\n",
      "Episode:1522 meanR:5.9400 R:4.0000 loss:0.0614\n",
      "Episode:1523 meanR:5.9800 R:6.0000 loss:0.0359\n",
      "Episode:1524 meanR:6.0000 R:4.0000 loss:0.0585\n",
      "Episode:1525 meanR:6.0400 R:4.0000 loss:0.0247\n",
      "Episode:1526 meanR:6.0600 R:4.0000 loss:0.0291\n",
      "Episode:1527 meanR:6.0400 R:2.0000 loss:0.0463\n",
      "Episode:1528 meanR:6.1300 R:8.0000 loss:0.0632\n",
      "Episode:1529 meanR:6.2500 R:13.0000 loss:0.0829\n",
      "Episode:1530 meanR:6.3500 R:14.0000 loss:0.0870\n",
      "Episode:1531 meanR:6.3500 R:1.0000 loss:0.0739\n",
      "Episode:1532 meanR:6.3300 R:0.0000 loss:0.0515\n",
      "Episode:1533 meanR:6.3400 R:1.0000 loss:0.0587\n",
      "Episode:1534 meanR:6.2900 R:3.0000 loss:0.0473\n",
      "Episode:1535 meanR:6.2700 R:3.0000 loss:0.0727\n",
      "Episode:1536 meanR:6.2100 R:7.0000 loss:0.0582\n",
      "Episode:1537 meanR:6.2200 R:4.0000 loss:0.0463\n",
      "Episode:1538 meanR:6.1400 R:1.0000 loss:0.0293\n",
      "Episode:1539 meanR:6.0200 R:-1.0000 loss:0.0244\n",
      "Episode:1540 meanR:5.9600 R:4.0000 loss:0.0355\n",
      "Episode:1541 meanR:5.8700 R:4.0000 loss:0.0246\n",
      "Episode:1542 meanR:5.8100 R:2.0000 loss:0.0285\n",
      "Episode:1543 meanR:5.7600 R:0.0000 loss:0.0347\n",
      "Episode:1544 meanR:5.7400 R:2.0000 loss:0.0301\n",
      "Episode:1545 meanR:5.7500 R:7.0000 loss:0.0376\n",
      "Episode:1546 meanR:5.7900 R:6.0000 loss:0.0553\n",
      "Episode:1547 meanR:5.7200 R:0.0000 loss:0.0411\n",
      "Episode:1548 meanR:5.6400 R:4.0000 loss:0.0502\n",
      "Episode:1549 meanR:5.5400 R:2.0000 loss:0.0463\n",
      "Episode:1550 meanR:5.5500 R:3.0000 loss:0.0630\n",
      "Episode:1551 meanR:5.4400 R:3.0000 loss:0.0853\n",
      "Episode:1552 meanR:5.4200 R:4.0000 loss:0.0484\n",
      "Episode:1553 meanR:5.4600 R:6.0000 loss:0.0571\n",
      "Episode:1554 meanR:5.4500 R:0.0000 loss:0.0289\n",
      "Episode:1555 meanR:5.4200 R:10.0000 loss:0.0547\n",
      "Episode:1556 meanR:5.5700 R:17.0000 loss:0.0503\n",
      "Episode:1557 meanR:5.6400 R:7.0000 loss:0.0799\n",
      "Episode:1558 meanR:5.6300 R:4.0000 loss:0.0598\n",
      "Episode:1559 meanR:5.6000 R:4.0000 loss:0.0490\n",
      "Episode:1560 meanR:5.5800 R:3.0000 loss:0.0620\n",
      "Episode:1561 meanR:5.5300 R:0.0000 loss:0.0301\n",
      "Episode:1562 meanR:5.3800 R:0.0000 loss:0.0473\n",
      "Episode:1563 meanR:5.3200 R:3.0000 loss:0.0476\n",
      "Episode:1564 meanR:5.2700 R:3.0000 loss:0.0239\n",
      "Episode:1565 meanR:5.1200 R:1.0000 loss:0.0246\n",
      "Episode:1566 meanR:4.9800 R:1.0000 loss:0.0252\n",
      "Episode:1567 meanR:4.8900 R:3.0000 loss:0.0280\n",
      "Episode:1568 meanR:4.9500 R:7.0000 loss:0.0488\n",
      "Episode:1569 meanR:5.0300 R:9.0000 loss:0.0479\n",
      "Episode:1570 meanR:5.1300 R:9.0000 loss:0.0602\n",
      "Episode:1571 meanR:5.1200 R:0.0000 loss:0.0440\n",
      "Episode:1572 meanR:5.1900 R:8.0000 loss:0.0784\n",
      "Episode:1573 meanR:5.2500 R:12.0000 loss:0.0750\n",
      "Episode:1574 meanR:5.2800 R:7.0000 loss:0.0505\n",
      "Episode:1575 meanR:5.2800 R:8.0000 loss:0.0478\n",
      "Episode:1576 meanR:5.2200 R:5.0000 loss:0.0434\n",
      "Episode:1577 meanR:5.2600 R:7.0000 loss:0.0694\n",
      "Episode:1578 meanR:5.3600 R:13.0000 loss:0.0683\n",
      "Episode:1579 meanR:5.2100 R:3.0000 loss:0.0700\n",
      "Episode:1580 meanR:5.1800 R:4.0000 loss:0.0588\n",
      "Episode:1581 meanR:5.0500 R:10.0000 loss:0.0547\n",
      "Episode:1582 meanR:5.0200 R:4.0000 loss:0.0554\n",
      "Episode:1583 meanR:5.0300 R:3.0000 loss:0.0579\n",
      "Episode:1584 meanR:5.0100 R:1.0000 loss:0.0531\n",
      "Episode:1585 meanR:5.0300 R:7.0000 loss:0.0510\n",
      "Episode:1586 meanR:4.9400 R:3.0000 loss:0.0479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1587 meanR:4.9000 R:3.0000 loss:0.0430\n",
      "Episode:1588 meanR:4.7900 R:0.0000 loss:0.0356\n",
      "Episode:1589 meanR:4.7900 R:3.0000 loss:0.0211\n",
      "Episode:1590 meanR:4.8100 R:7.0000 loss:0.0536\n",
      "Episode:1591 meanR:4.8500 R:9.0000 loss:0.0486\n",
      "Episode:1592 meanR:4.8300 R:5.0000 loss:0.0379\n",
      "Episode:1593 meanR:4.8400 R:9.0000 loss:0.0482\n",
      "Episode:1594 meanR:4.8900 R:9.0000 loss:0.0672\n",
      "Episode:1595 meanR:4.7600 R:0.0000 loss:0.0629\n",
      "Episode:1596 meanR:4.6800 R:-2.0000 loss:0.0235\n",
      "Episode:1597 meanR:4.7000 R:7.0000 loss:0.0390\n",
      "Episode:1598 meanR:4.7700 R:8.0000 loss:0.0598\n",
      "Episode:1599 meanR:4.8300 R:11.0000 loss:0.0545\n",
      "Episode:1600 meanR:4.8900 R:7.0000 loss:0.0711\n",
      "Episode:1601 meanR:5.0000 R:11.0000 loss:0.0554\n",
      "Episode:1602 meanR:5.0100 R:4.0000 loss:0.0555\n",
      "Episode:1603 meanR:5.0700 R:11.0000 loss:0.0553\n",
      "Episode:1604 meanR:5.0600 R:11.0000 loss:0.0660\n",
      "Episode:1605 meanR:5.0000 R:6.0000 loss:0.0653\n",
      "Episode:1606 meanR:5.0500 R:7.0000 loss:0.0573\n",
      "Episode:1607 meanR:5.0500 R:6.0000 loss:0.0782\n",
      "Episode:1608 meanR:4.9700 R:1.0000 loss:0.0673\n",
      "Episode:1609 meanR:4.9800 R:7.0000 loss:0.0590\n",
      "Episode:1610 meanR:4.9800 R:8.0000 loss:0.0458\n",
      "Episode:1611 meanR:5.0800 R:15.0000 loss:0.0562\n",
      "Episode:1612 meanR:5.1500 R:12.0000 loss:0.0512\n",
      "Episode:1613 meanR:5.1800 R:7.0000 loss:0.0624\n",
      "Episode:1614 meanR:5.1500 R:1.0000 loss:0.1106\n",
      "Episode:1615 meanR:5.1300 R:4.0000 loss:0.0996\n",
      "Episode:1616 meanR:5.1300 R:3.0000 loss:0.0764\n",
      "Episode:1617 meanR:5.1100 R:0.0000 loss:0.0474\n",
      "Episode:1618 meanR:5.0500 R:1.0000 loss:0.0419\n",
      "Episode:1619 meanR:5.0400 R:2.0000 loss:0.0557\n",
      "Episode:1620 meanR:5.0500 R:5.0000 loss:0.0393\n",
      "Episode:1621 meanR:5.0400 R:5.0000 loss:0.0328\n",
      "Episode:1622 meanR:5.0500 R:5.0000 loss:0.0506\n",
      "Episode:1623 meanR:5.0600 R:7.0000 loss:0.0502\n",
      "Episode:1624 meanR:5.0600 R:4.0000 loss:0.0511\n",
      "Episode:1625 meanR:5.0300 R:1.0000 loss:0.0324\n",
      "Episode:1626 meanR:5.0600 R:7.0000 loss:0.0491\n",
      "Episode:1627 meanR:5.0600 R:2.0000 loss:0.0343\n",
      "Episode:1628 meanR:5.0800 R:10.0000 loss:0.0567\n",
      "Episode:1629 meanR:5.0300 R:8.0000 loss:0.0652\n",
      "Episode:1630 meanR:4.9500 R:6.0000 loss:0.0360\n",
      "Episode:1631 meanR:5.0300 R:9.0000 loss:0.0471\n",
      "Episode:1632 meanR:5.1000 R:7.0000 loss:0.0469\n",
      "Episode:1633 meanR:5.1900 R:10.0000 loss:0.0541\n",
      "Episode:1634 meanR:5.2100 R:5.0000 loss:0.0333\n",
      "Episode:1635 meanR:5.2200 R:4.0000 loss:0.0338\n",
      "Episode:1636 meanR:5.2900 R:14.0000 loss:0.0470\n",
      "Episode:1637 meanR:5.3600 R:11.0000 loss:0.0516\n",
      "Episode:1638 meanR:5.4500 R:10.0000 loss:0.0856\n",
      "Episode:1639 meanR:5.5600 R:10.0000 loss:0.0642\n",
      "Episode:1640 meanR:5.7000 R:18.0000 loss:0.0947\n",
      "Episode:1641 meanR:5.7000 R:4.0000 loss:0.0697\n",
      "Episode:1642 meanR:5.7500 R:7.0000 loss:0.0555\n",
      "Episode:1643 meanR:5.8500 R:10.0000 loss:0.0613\n",
      "Episode:1644 meanR:5.9000 R:7.0000 loss:0.0286\n",
      "Episode:1645 meanR:5.8400 R:1.0000 loss:0.0681\n",
      "Episode:1646 meanR:5.8500 R:7.0000 loss:0.0441\n",
      "Episode:1647 meanR:5.9900 R:14.0000 loss:0.0846\n",
      "Episode:1648 meanR:6.0400 R:9.0000 loss:0.0670\n",
      "Episode:1649 meanR:6.0400 R:2.0000 loss:0.0862\n",
      "Episode:1650 meanR:6.0500 R:4.0000 loss:0.0460\n",
      "Episode:1651 meanR:6.1400 R:12.0000 loss:0.0630\n",
      "Episode:1652 meanR:6.1300 R:3.0000 loss:0.0987\n",
      "Episode:1653 meanR:6.1800 R:11.0000 loss:0.0765\n",
      "Episode:1654 meanR:6.2300 R:5.0000 loss:0.0481\n",
      "Episode:1655 meanR:6.2600 R:13.0000 loss:0.0465\n",
      "Episode:1656 meanR:6.2200 R:13.0000 loss:0.0695\n",
      "Episode:1657 meanR:6.1300 R:-2.0000 loss:0.0573\n",
      "Episode:1658 meanR:6.1900 R:10.0000 loss:0.0796\n",
      "Episode:1659 meanR:6.2000 R:5.0000 loss:0.0625\n",
      "Episode:1660 meanR:6.2300 R:6.0000 loss:0.0843\n",
      "Episode:1661 meanR:6.2500 R:2.0000 loss:0.0664\n",
      "Episode:1662 meanR:6.3000 R:5.0000 loss:0.0619\n",
      "Episode:1663 meanR:6.3000 R:3.0000 loss:0.0702\n",
      "Episode:1664 meanR:6.2900 R:2.0000 loss:0.0407\n",
      "Episode:1665 meanR:6.3600 R:8.0000 loss:0.0533\n",
      "Episode:1666 meanR:6.4300 R:8.0000 loss:0.0605\n",
      "Episode:1667 meanR:6.4600 R:6.0000 loss:0.0441\n",
      "Episode:1668 meanR:6.4200 R:3.0000 loss:0.0517\n",
      "Episode:1669 meanR:6.3700 R:4.0000 loss:0.0489\n",
      "Episode:1670 meanR:6.3400 R:6.0000 loss:0.0478\n",
      "Episode:1671 meanR:6.3700 R:3.0000 loss:0.0474\n",
      "Episode:1672 meanR:6.3400 R:5.0000 loss:0.0329\n",
      "Episode:1673 meanR:6.2300 R:1.0000 loss:0.0220\n",
      "Episode:1674 meanR:6.1900 R:3.0000 loss:0.0494\n",
      "Episode:1675 meanR:6.1600 R:5.0000 loss:0.0356\n",
      "Episode:1676 meanR:6.1100 R:0.0000 loss:0.0192\n",
      "Episode:1677 meanR:6.0800 R:4.0000 loss:0.0272\n",
      "Episode:1678 meanR:6.0000 R:5.0000 loss:0.0295\n",
      "Episode:1679 meanR:6.0300 R:6.0000 loss:0.0409\n",
      "Episode:1680 meanR:6.0900 R:10.0000 loss:0.0334\n",
      "Episode:1681 meanR:6.1400 R:15.0000 loss:0.0508\n",
      "Episode:1682 meanR:6.1200 R:2.0000 loss:0.0297\n",
      "Episode:1683 meanR:6.1500 R:6.0000 loss:0.0844\n",
      "Episode:1684 meanR:6.2100 R:7.0000 loss:0.0941\n",
      "Episode:1685 meanR:6.2000 R:6.0000 loss:0.0702\n",
      "Episode:1686 meanR:6.2300 R:6.0000 loss:0.0644\n",
      "Episode:1687 meanR:6.2300 R:3.0000 loss:0.0382\n",
      "Episode:1688 meanR:6.2500 R:2.0000 loss:0.0478\n",
      "Episode:1689 meanR:6.2900 R:7.0000 loss:0.0466\n",
      "Episode:1690 meanR:6.2800 R:6.0000 loss:0.0448\n",
      "Episode:1691 meanR:6.2800 R:9.0000 loss:0.0464\n",
      "Episode:1692 meanR:6.2300 R:0.0000 loss:0.0370\n",
      "Episode:1693 meanR:6.1800 R:4.0000 loss:0.0315\n",
      "Episode:1694 meanR:6.1400 R:5.0000 loss:0.0469\n",
      "Episode:1695 meanR:6.2700 R:13.0000 loss:0.0319\n",
      "Episode:1696 meanR:6.3700 R:8.0000 loss:0.0593\n",
      "Episode:1697 meanR:6.3300 R:3.0000 loss:0.0511\n",
      "Episode:1698 meanR:6.2700 R:2.0000 loss:0.0406\n",
      "Episode:1699 meanR:6.1600 R:0.0000 loss:0.0381\n",
      "Episode:1700 meanR:6.1200 R:3.0000 loss:0.0355\n",
      "Episode:1701 meanR:6.0300 R:2.0000 loss:0.0389\n",
      "Episode:1702 meanR:6.0300 R:4.0000 loss:0.0249\n",
      "Episode:1703 meanR:5.9900 R:7.0000 loss:0.0499\n",
      "Episode:1704 meanR:6.0200 R:14.0000 loss:0.0490\n",
      "Episode:1705 meanR:6.1000 R:14.0000 loss:0.0687\n",
      "Episode:1706 meanR:6.0600 R:3.0000 loss:0.0876\n",
      "Episode:1707 meanR:6.0700 R:7.0000 loss:0.0703\n",
      "Episode:1708 meanR:6.1000 R:4.0000 loss:0.0425\n",
      "Episode:1709 meanR:6.0300 R:0.0000 loss:0.0316\n",
      "Episode:1710 meanR:6.0200 R:7.0000 loss:0.0676\n",
      "Episode:1711 meanR:5.9300 R:6.0000 loss:0.0612\n",
      "Episode:1712 meanR:5.8900 R:8.0000 loss:0.0621\n",
      "Episode:1713 meanR:5.8700 R:5.0000 loss:0.0456\n",
      "Episode:1714 meanR:5.8900 R:3.0000 loss:0.0331\n",
      "Episode:1715 meanR:5.9400 R:9.0000 loss:0.0571\n",
      "Episode:1716 meanR:5.9700 R:6.0000 loss:0.0556\n",
      "Episode:1717 meanR:6.0100 R:4.0000 loss:0.0435\n",
      "Episode:1718 meanR:6.0000 R:0.0000 loss:0.0518\n",
      "Episode:1719 meanR:6.0300 R:5.0000 loss:0.0482\n",
      "Episode:1720 meanR:6.0300 R:5.0000 loss:0.0347\n",
      "Episode:1721 meanR:6.0300 R:5.0000 loss:0.0233\n",
      "Episode:1722 meanR:6.0600 R:8.0000 loss:0.0496\n",
      "Episode:1723 meanR:6.0300 R:4.0000 loss:0.0541\n",
      "Episode:1724 meanR:5.9900 R:0.0000 loss:0.0301\n",
      "Episode:1725 meanR:6.0200 R:4.0000 loss:0.0362\n",
      "Episode:1726 meanR:6.0400 R:9.0000 loss:0.0541\n",
      "Episode:1727 meanR:6.1100 R:9.0000 loss:0.0345\n",
      "Episode:1728 meanR:6.0300 R:2.0000 loss:0.0377\n",
      "Episode:1729 meanR:6.0300 R:8.0000 loss:0.0781\n",
      "Episode:1730 meanR:6.0700 R:10.0000 loss:0.0711\n",
      "Episode:1731 meanR:6.0500 R:7.0000 loss:0.0684\n",
      "Episode:1732 meanR:6.0000 R:2.0000 loss:0.0436\n",
      "Episode:1733 meanR:5.9300 R:3.0000 loss:0.0502\n",
      "Episode:1734 meanR:5.9200 R:4.0000 loss:0.0450\n",
      "Episode:1735 meanR:5.9500 R:7.0000 loss:0.0506\n",
      "Episode:1736 meanR:5.9800 R:17.0000 loss:0.0515\n",
      "Episode:1737 meanR:5.9100 R:4.0000 loss:0.0837\n",
      "Episode:1738 meanR:5.8500 R:4.0000 loss:0.0614\n",
      "Episode:1739 meanR:5.8300 R:8.0000 loss:0.0754\n",
      "Episode:1740 meanR:5.6600 R:1.0000 loss:0.0490\n",
      "Episode:1741 meanR:5.6800 R:6.0000 loss:0.0443\n",
      "Episode:1742 meanR:5.6400 R:3.0000 loss:0.0462\n",
      "Episode:1743 meanR:5.6200 R:8.0000 loss:0.0362\n",
      "Episode:1744 meanR:5.6900 R:14.0000 loss:0.0594\n",
      "Episode:1745 meanR:5.7800 R:10.0000 loss:0.0599\n",
      "Episode:1746 meanR:5.8400 R:13.0000 loss:0.0668\n",
      "Episode:1747 meanR:5.7700 R:7.0000 loss:0.0867\n",
      "Episode:1748 meanR:5.7700 R:9.0000 loss:0.0475\n",
      "Episode:1749 meanR:5.9000 R:15.0000 loss:0.0713\n",
      "Episode:1750 meanR:5.9100 R:5.0000 loss:0.0799\n",
      "Episode:1751 meanR:5.7900 R:0.0000 loss:0.0468\n",
      "Episode:1752 meanR:5.8500 R:9.0000 loss:0.0617\n",
      "Episode:1753 meanR:5.8400 R:10.0000 loss:0.0483\n",
      "Episode:1754 meanR:5.8300 R:4.0000 loss:0.0620\n",
      "Episode:1755 meanR:5.7500 R:5.0000 loss:0.0515\n",
      "Episode:1756 meanR:5.6800 R:6.0000 loss:0.0473\n",
      "Episode:1757 meanR:5.8400 R:14.0000 loss:0.0638\n",
      "Episode:1758 meanR:5.8700 R:13.0000 loss:0.0590\n",
      "Episode:1759 meanR:5.9500 R:13.0000 loss:0.0539\n",
      "Episode:1760 meanR:5.9400 R:5.0000 loss:0.0547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1761 meanR:5.9400 R:2.0000 loss:0.0577\n",
      "Episode:1762 meanR:6.0500 R:16.0000 loss:0.0734\n",
      "Episode:1763 meanR:6.1700 R:15.0000 loss:0.0644\n",
      "Episode:1764 meanR:6.2200 R:7.0000 loss:0.0704\n",
      "Episode:1765 meanR:6.2800 R:14.0000 loss:0.0729\n",
      "Episode:1766 meanR:6.2300 R:3.0000 loss:0.0732\n",
      "Episode:1767 meanR:6.2900 R:12.0000 loss:0.0644\n",
      "Episode:1768 meanR:6.3300 R:7.0000 loss:0.0775\n",
      "Episode:1769 meanR:6.3300 R:4.0000 loss:0.0421\n",
      "Episode:1770 meanR:6.3700 R:10.0000 loss:0.0701\n",
      "Episode:1771 meanR:6.4700 R:13.0000 loss:0.0708\n",
      "Episode:1772 meanR:6.5100 R:9.0000 loss:0.0613\n",
      "Episode:1773 meanR:6.5700 R:7.0000 loss:0.0559\n",
      "Episode:1774 meanR:6.6500 R:11.0000 loss:0.0697\n",
      "Episode:1775 meanR:6.6200 R:2.0000 loss:0.0419\n",
      "Episode:1776 meanR:6.6800 R:6.0000 loss:0.0604\n",
      "Episode:1777 meanR:6.6900 R:5.0000 loss:0.0417\n",
      "Episode:1778 meanR:6.7500 R:11.0000 loss:0.0426\n",
      "Episode:1779 meanR:6.8100 R:12.0000 loss:0.0524\n",
      "Episode:1780 meanR:6.8500 R:14.0000 loss:0.0660\n",
      "Episode:1781 meanR:6.8400 R:14.0000 loss:0.0425\n",
      "Episode:1782 meanR:6.9600 R:14.0000 loss:0.0518\n",
      "Episode:1783 meanR:6.9400 R:4.0000 loss:0.0773\n",
      "Episode:1784 meanR:6.9300 R:6.0000 loss:0.0779\n",
      "Episode:1785 meanR:6.9900 R:12.0000 loss:0.0503\n",
      "Episode:1786 meanR:7.0100 R:8.0000 loss:0.0503\n",
      "Episode:1787 meanR:7.0400 R:6.0000 loss:0.0656\n",
      "Episode:1788 meanR:7.0400 R:2.0000 loss:0.0807\n",
      "Episode:1789 meanR:7.0200 R:5.0000 loss:0.0698\n",
      "Episode:1790 meanR:6.9800 R:2.0000 loss:0.0259\n",
      "Episode:1791 meanR:6.9700 R:8.0000 loss:0.0363\n",
      "Episode:1792 meanR:7.1100 R:14.0000 loss:0.0592\n",
      "Episode:1793 meanR:7.1100 R:4.0000 loss:0.0685\n",
      "Episode:1794 meanR:7.1400 R:8.0000 loss:0.0591\n",
      "Episode:1795 meanR:7.1400 R:13.0000 loss:0.0800\n",
      "Episode:1796 meanR:7.1800 R:12.0000 loss:0.0830\n",
      "Episode:1797 meanR:7.2300 R:8.0000 loss:0.0775\n",
      "Episode:1798 meanR:7.2300 R:2.0000 loss:0.0696\n",
      "Episode:1799 meanR:7.2900 R:6.0000 loss:0.0517\n",
      "Episode:1800 meanR:7.2700 R:1.0000 loss:0.0725\n",
      "Episode:1801 meanR:7.3200 R:7.0000 loss:0.0533\n",
      "Episode:1802 meanR:7.3600 R:8.0000 loss:0.0515\n",
      "Episode:1803 meanR:7.3300 R:4.0000 loss:0.0407\n",
      "Episode:1804 meanR:7.2000 R:1.0000 loss:0.0440\n",
      "Episode:1805 meanR:7.2000 R:14.0000 loss:0.0681\n",
      "Episode:1806 meanR:7.3000 R:13.0000 loss:0.0846\n",
      "Episode:1807 meanR:7.2600 R:3.0000 loss:0.0868\n",
      "Episode:1808 meanR:7.3300 R:11.0000 loss:0.0507\n",
      "Episode:1809 meanR:7.4000 R:7.0000 loss:0.0658\n",
      "Episode:1810 meanR:7.3600 R:3.0000 loss:0.0528\n",
      "Episode:1811 meanR:7.4200 R:12.0000 loss:0.0507\n",
      "Episode:1812 meanR:7.4800 R:14.0000 loss:0.0828\n",
      "Episode:1813 meanR:7.5200 R:9.0000 loss:0.0703\n",
      "Episode:1814 meanR:7.5900 R:10.0000 loss:0.0843\n",
      "Episode:1815 meanR:7.5800 R:8.0000 loss:0.0760\n",
      "Episode:1816 meanR:7.5600 R:4.0000 loss:0.0582\n",
      "Episode:1817 meanR:7.6000 R:8.0000 loss:0.0677\n",
      "Episode:1818 meanR:7.6800 R:8.0000 loss:0.0642\n",
      "Episode:1819 meanR:7.7700 R:14.0000 loss:0.0916\n",
      "Episode:1820 meanR:7.7500 R:3.0000 loss:0.0491\n",
      "Episode:1821 meanR:7.7200 R:2.0000 loss:0.0527\n",
      "Episode:1822 meanR:7.6600 R:2.0000 loss:0.0520\n",
      "Episode:1823 meanR:7.6900 R:7.0000 loss:0.0540\n",
      "Episode:1824 meanR:7.7700 R:8.0000 loss:0.0632\n",
      "Episode:1825 meanR:7.8200 R:9.0000 loss:0.0493\n",
      "Episode:1826 meanR:7.8300 R:10.0000 loss:0.0721\n",
      "Episode:1827 meanR:7.7800 R:4.0000 loss:0.0501\n",
      "Episode:1828 meanR:7.8500 R:9.0000 loss:0.0516\n",
      "Episode:1829 meanR:7.8600 R:9.0000 loss:0.0283\n",
      "Episode:1830 meanR:7.7900 R:3.0000 loss:0.0505\n",
      "Episode:1831 meanR:7.8000 R:8.0000 loss:0.0568\n",
      "Episode:1832 meanR:7.8000 R:2.0000 loss:0.0415\n",
      "Episode:1833 meanR:7.8600 R:9.0000 loss:0.0557\n",
      "Episode:1834 meanR:7.8500 R:3.0000 loss:0.0516\n",
      "Episode:1835 meanR:7.8600 R:8.0000 loss:0.0627\n",
      "Episode:1836 meanR:7.6900 R:0.0000 loss:0.0489\n",
      "Episode:1837 meanR:7.6600 R:1.0000 loss:0.0729\n",
      "Episode:1838 meanR:7.6400 R:2.0000 loss:0.0584\n",
      "Episode:1839 meanR:7.5700 R:1.0000 loss:0.0215\n",
      "Episode:1840 meanR:7.5700 R:1.0000 loss:0.0427\n",
      "Episode:1841 meanR:7.5300 R:2.0000 loss:0.0323\n",
      "Episode:1842 meanR:7.5600 R:6.0000 loss:0.0461\n",
      "Episode:1843 meanR:7.5400 R:6.0000 loss:0.0583\n",
      "Episode:1844 meanR:7.4400 R:4.0000 loss:0.0468\n",
      "Episode:1845 meanR:7.4200 R:8.0000 loss:0.0495\n",
      "Episode:1846 meanR:7.3600 R:7.0000 loss:0.0572\n",
      "Episode:1847 meanR:7.3700 R:8.0000 loss:0.0293\n",
      "Episode:1848 meanR:7.3300 R:5.0000 loss:0.0239\n",
      "Episode:1849 meanR:7.2300 R:5.0000 loss:0.0420\n",
      "Episode:1850 meanR:7.2700 R:9.0000 loss:0.0336\n",
      "Episode:1851 meanR:7.3700 R:10.0000 loss:0.0537\n",
      "Episode:1852 meanR:7.3900 R:11.0000 loss:0.0643\n",
      "Episode:1853 meanR:7.3100 R:2.0000 loss:0.0506\n",
      "Episode:1854 meanR:7.2900 R:2.0000 loss:0.0386\n",
      "Episode:1855 meanR:7.2500 R:1.0000 loss:0.0172\n",
      "Episode:1856 meanR:7.2500 R:6.0000 loss:0.0402\n",
      "Episode:1857 meanR:7.1400 R:3.0000 loss:0.0436\n",
      "Episode:1858 meanR:7.0900 R:8.0000 loss:0.0502\n",
      "Episode:1859 meanR:6.9700 R:1.0000 loss:0.0369\n",
      "Episode:1860 meanR:6.9800 R:6.0000 loss:0.0544\n",
      "Episode:1861 meanR:6.9600 R:0.0000 loss:0.0293\n",
      "Episode:1862 meanR:6.8500 R:5.0000 loss:0.1864\n",
      "Episode:1863 meanR:6.7500 R:5.0000 loss:0.1032\n",
      "Episode:1864 meanR:6.7000 R:2.0000 loss:0.0886\n",
      "Episode:1865 meanR:6.5800 R:2.0000 loss:0.0780\n",
      "Episode:1866 meanR:6.6600 R:11.0000 loss:0.0791\n",
      "Episode:1867 meanR:6.6200 R:8.0000 loss:0.0904\n",
      "Episode:1868 meanR:6.6300 R:8.0000 loss:0.0631\n",
      "Episode:1869 meanR:6.6400 R:5.0000 loss:0.0469\n",
      "Episode:1870 meanR:6.6500 R:11.0000 loss:0.0385\n",
      "Episode:1871 meanR:6.6500 R:13.0000 loss:0.0679\n",
      "Episode:1872 meanR:6.5900 R:3.0000 loss:0.0598\n",
      "Episode:1873 meanR:6.5900 R:7.0000 loss:0.0467\n",
      "Episode:1874 meanR:6.5800 R:10.0000 loss:0.0425\n",
      "Episode:1875 meanR:6.6100 R:5.0000 loss:0.0262\n",
      "Episode:1876 meanR:6.6000 R:5.0000 loss:0.0474\n",
      "Episode:1877 meanR:6.6200 R:7.0000 loss:0.0357\n",
      "Episode:1878 meanR:6.5600 R:5.0000 loss:0.0337\n",
      "Episode:1879 meanR:6.5000 R:6.0000 loss:0.0541\n",
      "Episode:1880 meanR:6.4700 R:11.0000 loss:0.0550\n",
      "Episode:1881 meanR:6.4000 R:7.0000 loss:0.0524\n",
      "Episode:1882 meanR:6.3100 R:5.0000 loss:0.0645\n",
      "Episode:1883 meanR:6.4100 R:14.0000 loss:0.0662\n",
      "Episode:1884 meanR:6.5200 R:17.0000 loss:0.0781\n",
      "Episode:1885 meanR:6.4900 R:9.0000 loss:0.0738\n",
      "Episode:1886 meanR:6.4800 R:7.0000 loss:0.0424\n",
      "Episode:1887 meanR:6.4600 R:4.0000 loss:0.0528\n",
      "Episode:1888 meanR:6.5700 R:13.0000 loss:0.0523\n",
      "Episode:1889 meanR:6.6300 R:11.0000 loss:0.0438\n",
      "Episode:1890 meanR:6.6600 R:5.0000 loss:0.0389\n",
      "Episode:1891 meanR:6.6600 R:8.0000 loss:0.0474\n",
      "Episode:1892 meanR:6.5700 R:5.0000 loss:0.0584\n",
      "Episode:1893 meanR:6.6100 R:8.0000 loss:0.0504\n",
      "Episode:1894 meanR:6.6500 R:12.0000 loss:0.0471\n",
      "Episode:1895 meanR:6.6400 R:12.0000 loss:0.0586\n",
      "Episode:1896 meanR:6.6100 R:9.0000 loss:0.0398\n",
      "Episode:1897 meanR:6.5900 R:6.0000 loss:0.0648\n",
      "Episode:1898 meanR:6.6200 R:5.0000 loss:0.0431\n",
      "Episode:1899 meanR:6.6900 R:13.0000 loss:0.0649\n",
      "Episode:1900 meanR:6.7400 R:6.0000 loss:0.0470\n",
      "Episode:1901 meanR:6.7200 R:5.0000 loss:0.0644\n",
      "Episode:1902 meanR:6.6700 R:3.0000 loss:0.0542\n",
      "Episode:1903 meanR:6.6800 R:5.0000 loss:0.0631\n",
      "Episode:1904 meanR:6.7000 R:3.0000 loss:0.0415\n",
      "Episode:1905 meanR:6.6200 R:6.0000 loss:0.0593\n",
      "Episode:1906 meanR:6.5300 R:4.0000 loss:0.0439\n",
      "Episode:1907 meanR:6.5800 R:8.0000 loss:0.0471\n",
      "Episode:1908 meanR:6.5900 R:12.0000 loss:0.0448\n",
      "Episode:1909 meanR:6.6400 R:12.0000 loss:0.0787\n",
      "Episode:1910 meanR:6.7300 R:12.0000 loss:0.0438\n",
      "Episode:1911 meanR:6.6700 R:6.0000 loss:0.0675\n",
      "Episode:1912 meanR:6.6000 R:7.0000 loss:0.0481\n",
      "Episode:1913 meanR:6.6300 R:12.0000 loss:0.0674\n",
      "Episode:1914 meanR:6.6100 R:8.0000 loss:0.0889\n",
      "Episode:1915 meanR:6.6300 R:10.0000 loss:0.0526\n",
      "Episode:1916 meanR:6.6900 R:10.0000 loss:0.0679\n",
      "Episode:1917 meanR:6.6500 R:4.0000 loss:0.0498\n",
      "Episode:1918 meanR:6.6900 R:12.0000 loss:0.0524\n",
      "Episode:1919 meanR:6.6000 R:5.0000 loss:0.0400\n",
      "Episode:1920 meanR:6.7100 R:14.0000 loss:0.0735\n",
      "Episode:1921 meanR:6.7700 R:8.0000 loss:0.0664\n",
      "Episode:1922 meanR:6.7600 R:1.0000 loss:0.0315\n",
      "Episode:1923 meanR:6.8100 R:12.0000 loss:0.0620\n",
      "Episode:1924 meanR:6.8300 R:10.0000 loss:0.0762\n",
      "Episode:1925 meanR:6.8400 R:10.0000 loss:0.0957\n",
      "Episode:1926 meanR:6.7900 R:5.0000 loss:0.0489\n",
      "Episode:1927 meanR:6.7600 R:1.0000 loss:0.0403\n",
      "Episode:1928 meanR:6.7200 R:5.0000 loss:0.0439\n",
      "Episode:1929 meanR:6.7200 R:9.0000 loss:0.0624\n",
      "Episode:1930 meanR:6.7000 R:1.0000 loss:0.0336\n",
      "Episode:1931 meanR:6.6700 R:5.0000 loss:0.0454\n",
      "Episode:1932 meanR:6.7300 R:8.0000 loss:0.0333\n",
      "Episode:1933 meanR:6.6900 R:5.0000 loss:0.0357\n",
      "Episode:1934 meanR:6.7000 R:4.0000 loss:0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1935 meanR:6.7100 R:9.0000 loss:0.0648\n",
      "Episode:1936 meanR:6.8100 R:10.0000 loss:0.0560\n",
      "Episode:1937 meanR:6.8600 R:6.0000 loss:0.0412\n",
      "Episode:1938 meanR:6.9300 R:9.0000 loss:0.0649\n",
      "Episode:1939 meanR:6.9900 R:7.0000 loss:0.0819\n",
      "Episode:1940 meanR:7.0800 R:10.0000 loss:0.0742\n",
      "Episode:1941 meanR:7.1100 R:5.0000 loss:0.0774\n",
      "Episode:1942 meanR:7.1300 R:8.0000 loss:0.0850\n",
      "Episode:1943 meanR:7.1000 R:3.0000 loss:0.0732\n",
      "Episode:1944 meanR:7.0900 R:3.0000 loss:0.0413\n",
      "Episode:1945 meanR:7.0600 R:5.0000 loss:0.0518\n",
      "Episode:1946 meanR:7.0200 R:3.0000 loss:0.0318\n",
      "Episode:1947 meanR:6.9900 R:5.0000 loss:0.0414\n",
      "Episode:1948 meanR:7.0200 R:8.0000 loss:0.0478\n",
      "Episode:1949 meanR:7.0600 R:9.0000 loss:0.0421\n",
      "Episode:1950 meanR:6.9900 R:2.0000 loss:0.0405\n",
      "Episode:1951 meanR:6.9500 R:6.0000 loss:0.0429\n",
      "Episode:1952 meanR:6.9200 R:8.0000 loss:0.0599\n",
      "Episode:1953 meanR:6.9800 R:8.0000 loss:0.0562\n",
      "Episode:1954 meanR:7.0500 R:9.0000 loss:0.0706\n",
      "Episode:1955 meanR:7.1300 R:9.0000 loss:0.0613\n",
      "Episode:1956 meanR:7.1500 R:8.0000 loss:0.0567\n",
      "Episode:1957 meanR:7.2300 R:11.0000 loss:0.0517\n",
      "Episode:1958 meanR:7.1600 R:1.0000 loss:0.0461\n",
      "Episode:1959 meanR:7.1600 R:1.0000 loss:0.0408\n",
      "Episode:1960 meanR:7.1600 R:6.0000 loss:0.0307\n",
      "Episode:1961 meanR:7.1900 R:3.0000 loss:0.0365\n",
      "Episode:1962 meanR:7.1900 R:5.0000 loss:0.0420\n",
      "Episode:1963 meanR:7.1600 R:2.0000 loss:0.0322\n",
      "Episode:1964 meanR:7.1400 R:0.0000 loss:0.0495\n",
      "Episode:1965 meanR:7.1400 R:2.0000 loss:0.0292\n",
      "Episode:1966 meanR:7.0600 R:3.0000 loss:0.0326\n",
      "Episode:1967 meanR:7.0300 R:5.0000 loss:0.0356\n",
      "Episode:1968 meanR:6.9400 R:-1.0000 loss:0.0300\n",
      "Episode:1969 meanR:6.9500 R:6.0000 loss:0.0289\n",
      "Episode:1970 meanR:6.8500 R:1.0000 loss:0.0318\n",
      "Episode:1971 meanR:6.7400 R:2.0000 loss:0.0436\n",
      "Episode:1972 meanR:6.7200 R:1.0000 loss:0.0282\n",
      "Episode:1973 meanR:6.6300 R:-2.0000 loss:0.0169\n",
      "Episode:1974 meanR:6.5900 R:6.0000 loss:0.0244\n",
      "Episode:1975 meanR:6.6000 R:6.0000 loss:0.0524\n",
      "Episode:1976 meanR:6.6300 R:8.0000 loss:0.0567\n",
      "Episode:1977 meanR:6.5800 R:2.0000 loss:0.0330\n",
      "Episode:1978 meanR:6.6000 R:7.0000 loss:0.0426\n",
      "Episode:1979 meanR:6.5800 R:4.0000 loss:0.0650\n",
      "Episode:1980 meanR:6.5100 R:4.0000 loss:0.0266\n",
      "Episode:1981 meanR:6.4800 R:4.0000 loss:0.0335\n",
      "Episode:1982 meanR:6.4500 R:2.0000 loss:0.0135\n",
      "Episode:1983 meanR:6.3800 R:7.0000 loss:0.0252\n",
      "Episode:1984 meanR:6.2600 R:5.0000 loss:0.0355\n",
      "Episode:1985 meanR:6.1800 R:1.0000 loss:0.0333\n",
      "Episode:1986 meanR:6.1300 R:2.0000 loss:0.0173\n",
      "Episode:1987 meanR:6.1700 R:8.0000 loss:0.0355\n",
      "Episode:1988 meanR:6.0600 R:2.0000 loss:0.0428\n",
      "Episode:1989 meanR:5.9700 R:2.0000 loss:0.0335\n",
      "Episode:1990 meanR:5.9600 R:4.0000 loss:0.0243\n",
      "Episode:1991 meanR:5.8800 R:0.0000 loss:0.0155\n",
      "Episode:1992 meanR:5.8400 R:1.0000 loss:0.0224\n",
      "Episode:1993 meanR:5.7500 R:-1.0000 loss:0.0179\n",
      "Episode:1994 meanR:5.7000 R:7.0000 loss:0.0258\n",
      "Episode:1995 meanR:5.6100 R:3.0000 loss:0.0238\n",
      "Episode:1996 meanR:5.5900 R:7.0000 loss:0.0506\n",
      "Episode:1997 meanR:5.6800 R:15.0000 loss:0.0547\n",
      "Episode:1998 meanR:5.7300 R:10.0000 loss:0.0636\n",
      "Episode:1999 meanR:5.6400 R:4.0000 loss:0.0394\n",
      "Episode:2000 meanR:5.5900 R:1.0000 loss:0.0223\n",
      "Episode:2001 meanR:5.6500 R:11.0000 loss:0.0562\n",
      "Episode:2002 meanR:5.6700 R:5.0000 loss:0.0603\n",
      "Episode:2003 meanR:5.7400 R:12.0000 loss:0.0206\n",
      "Episode:2004 meanR:5.7600 R:5.0000 loss:0.0233\n",
      "Episode:2005 meanR:5.7800 R:8.0000 loss:0.0312\n",
      "Episode:2006 meanR:5.7500 R:1.0000 loss:0.0614\n",
      "Episode:2007 meanR:5.7300 R:6.0000 loss:0.0387\n",
      "Episode:2008 meanR:5.7000 R:9.0000 loss:0.0420\n",
      "Episode:2009 meanR:5.6200 R:4.0000 loss:0.0534\n",
      "Episode:2010 meanR:5.5300 R:3.0000 loss:0.0472\n",
      "Episode:2011 meanR:5.5800 R:11.0000 loss:0.0590\n",
      "Episode:2012 meanR:5.6400 R:13.0000 loss:0.0620\n",
      "Episode:2013 meanR:5.6700 R:15.0000 loss:0.0864\n",
      "Episode:2014 meanR:5.6100 R:2.0000 loss:0.0628\n",
      "Episode:2015 meanR:5.5900 R:8.0000 loss:0.0453\n",
      "Episode:2016 meanR:5.6000 R:11.0000 loss:0.0687\n",
      "Episode:2017 meanR:5.6900 R:13.0000 loss:0.0651\n",
      "Episode:2018 meanR:5.6800 R:11.0000 loss:0.0769\n",
      "Episode:2019 meanR:5.7500 R:12.0000 loss:0.0973\n",
      "Episode:2020 meanR:5.7100 R:10.0000 loss:0.0840\n",
      "Episode:2021 meanR:5.6600 R:3.0000 loss:0.0846\n",
      "Episode:2022 meanR:5.7200 R:7.0000 loss:0.0555\n",
      "Episode:2023 meanR:5.6500 R:5.0000 loss:0.0350\n",
      "Episode:2024 meanR:5.5900 R:4.0000 loss:0.0392\n",
      "Episode:2025 meanR:5.5600 R:7.0000 loss:0.0361\n",
      "Episode:2026 meanR:5.6100 R:10.0000 loss:0.0543\n",
      "Episode:2027 meanR:5.6400 R:4.0000 loss:0.0342\n",
      "Episode:2028 meanR:5.6600 R:7.0000 loss:0.0367\n",
      "Episode:2029 meanR:5.5600 R:-1.0000 loss:0.0503\n",
      "Episode:2030 meanR:5.6200 R:7.0000 loss:0.0398\n",
      "Episode:2031 meanR:5.6800 R:11.0000 loss:0.0529\n",
      "Episode:2032 meanR:5.6200 R:2.0000 loss:0.0581\n",
      "Episode:2033 meanR:5.5900 R:2.0000 loss:0.0385\n",
      "Episode:2034 meanR:5.6500 R:10.0000 loss:0.0585\n",
      "Episode:2035 meanR:5.6500 R:9.0000 loss:0.0848\n",
      "Episode:2036 meanR:5.7100 R:16.0000 loss:0.0437\n",
      "Episode:2037 meanR:5.7400 R:9.0000 loss:0.0958\n",
      "Episode:2038 meanR:5.7400 R:9.0000 loss:0.0915\n",
      "Episode:2039 meanR:5.7000 R:3.0000 loss:0.0548\n",
      "Episode:2040 meanR:5.7100 R:11.0000 loss:0.0503\n",
      "Episode:2041 meanR:5.7900 R:13.0000 loss:0.0645\n",
      "Episode:2042 meanR:5.8000 R:9.0000 loss:0.0384\n",
      "Episode:2043 meanR:5.8400 R:7.0000 loss:0.0548\n",
      "Episode:2044 meanR:5.9200 R:11.0000 loss:0.0546\n",
      "Episode:2045 meanR:5.9300 R:6.0000 loss:0.0566\n",
      "Episode:2046 meanR:6.0000 R:10.0000 loss:0.0517\n",
      "Episode:2047 meanR:6.0900 R:14.0000 loss:0.0537\n",
      "Episode:2048 meanR:6.0600 R:5.0000 loss:0.0436\n",
      "Episode:2049 meanR:6.0900 R:12.0000 loss:0.0495\n",
      "Episode:2050 meanR:6.2200 R:15.0000 loss:0.0626\n",
      "Episode:2051 meanR:6.2000 R:4.0000 loss:0.0565\n",
      "Episode:2052 meanR:6.1300 R:1.0000 loss:0.0701\n",
      "Episode:2053 meanR:6.1200 R:7.0000 loss:0.0507\n",
      "Episode:2054 meanR:6.0900 R:6.0000 loss:0.0583\n",
      "Episode:2055 meanR:6.0400 R:4.0000 loss:0.0532\n",
      "Episode:2056 meanR:6.0800 R:12.0000 loss:0.0597\n",
      "Episode:2057 meanR:6.1000 R:13.0000 loss:0.0678\n",
      "Episode:2058 meanR:6.1700 R:8.0000 loss:0.0589\n",
      "Episode:2059 meanR:6.2000 R:4.0000 loss:0.0527\n",
      "Episode:2060 meanR:6.2200 R:8.0000 loss:0.0526\n",
      "Episode:2061 meanR:6.2600 R:7.0000 loss:0.0583\n",
      "Episode:2062 meanR:6.3000 R:9.0000 loss:0.0499\n",
      "Episode:2063 meanR:6.4300 R:15.0000 loss:0.0735\n",
      "Episode:2064 meanR:6.5600 R:13.0000 loss:0.0861\n",
      "Episode:2065 meanR:6.6000 R:6.0000 loss:0.0906\n",
      "Episode:2066 meanR:6.7200 R:15.0000 loss:0.0638\n",
      "Episode:2067 meanR:6.7600 R:9.0000 loss:0.1003\n",
      "Episode:2068 meanR:6.8900 R:12.0000 loss:0.0797\n",
      "Episode:2069 meanR:6.9300 R:10.0000 loss:0.0672\n",
      "Episode:2070 meanR:7.0100 R:9.0000 loss:0.0418\n",
      "Episode:2071 meanR:7.1000 R:11.0000 loss:0.0783\n",
      "Episode:2072 meanR:7.1400 R:5.0000 loss:0.0607\n",
      "Episode:2073 meanR:7.3000 R:14.0000 loss:0.0524\n",
      "Episode:2074 meanR:7.3500 R:11.0000 loss:0.0711\n",
      "Episode:2075 meanR:7.4300 R:14.0000 loss:0.0777\n",
      "Episode:2076 meanR:7.4500 R:10.0000 loss:0.0629\n",
      "Episode:2077 meanR:7.5100 R:8.0000 loss:0.0601\n",
      "Episode:2078 meanR:7.5600 R:12.0000 loss:0.0627\n",
      "Episode:2079 meanR:7.6300 R:11.0000 loss:0.1001\n",
      "Episode:2080 meanR:7.6900 R:10.0000 loss:0.0621\n",
      "Episode:2081 meanR:7.7500 R:10.0000 loss:0.0749\n",
      "Episode:2082 meanR:7.8400 R:11.0000 loss:0.0768\n",
      "Episode:2083 meanR:7.8200 R:5.0000 loss:0.0821\n",
      "Episode:2084 meanR:7.7900 R:2.0000 loss:0.0578\n",
      "Episode:2085 meanR:7.8200 R:4.0000 loss:0.0452\n",
      "Episode:2086 meanR:7.8400 R:4.0000 loss:0.0408\n",
      "Episode:2087 meanR:7.8500 R:9.0000 loss:0.0470\n",
      "Episode:2088 meanR:7.8600 R:3.0000 loss:0.0841\n",
      "Episode:2089 meanR:7.8700 R:3.0000 loss:0.0277\n",
      "Episode:2090 meanR:7.9600 R:13.0000 loss:0.0662\n",
      "Episode:2091 meanR:8.0700 R:11.0000 loss:0.0413\n",
      "Episode:2092 meanR:8.1200 R:6.0000 loss:0.0336\n",
      "Episode:2093 meanR:8.1400 R:1.0000 loss:0.0556\n",
      "Episode:2094 meanR:8.0600 R:-1.0000 loss:0.0375\n",
      "Episode:2095 meanR:8.1300 R:10.0000 loss:0.0448\n",
      "Episode:2096 meanR:8.1700 R:11.0000 loss:0.0674\n",
      "Episode:2097 meanR:8.1200 R:10.0000 loss:0.0476\n",
      "Episode:2098 meanR:8.0700 R:5.0000 loss:0.0306\n",
      "Episode:2099 meanR:8.1200 R:9.0000 loss:0.0459\n",
      "Episode:2100 meanR:8.2200 R:11.0000 loss:0.0506\n",
      "Episode:2101 meanR:8.1700 R:6.0000 loss:0.0478\n",
      "Episode:2102 meanR:8.1600 R:4.0000 loss:0.0429\n",
      "Episode:2103 meanR:8.1000 R:6.0000 loss:0.0343\n",
      "Episode:2104 meanR:8.0500 R:0.0000 loss:0.0220\n",
      "Episode:2105 meanR:7.9800 R:1.0000 loss:0.0339\n",
      "Episode:2106 meanR:8.0600 R:9.0000 loss:0.0533\n",
      "Episode:2107 meanR:8.0400 R:4.0000 loss:0.0633\n",
      "Episode:2108 meanR:8.0000 R:5.0000 loss:0.0484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2109 meanR:8.0200 R:6.0000 loss:0.0365\n",
      "Episode:2110 meanR:8.0800 R:9.0000 loss:0.0470\n",
      "Episode:2111 meanR:8.0300 R:6.0000 loss:0.0496\n",
      "Episode:2112 meanR:7.9400 R:4.0000 loss:0.0409\n",
      "Episode:2113 meanR:7.8300 R:4.0000 loss:0.0445\n",
      "Episode:2114 meanR:7.8300 R:2.0000 loss:0.0391\n",
      "Episode:2115 meanR:7.7600 R:1.0000 loss:0.0223\n",
      "Episode:2116 meanR:7.7200 R:7.0000 loss:0.0415\n",
      "Episode:2117 meanR:7.6200 R:3.0000 loss:0.0390\n",
      "Episode:2118 meanR:7.5300 R:2.0000 loss:0.0566\n",
      "Episode:2119 meanR:7.4400 R:3.0000 loss:0.0529\n",
      "Episode:2120 meanR:7.3900 R:5.0000 loss:0.0504\n",
      "Episode:2121 meanR:7.4600 R:10.0000 loss:0.0465\n",
      "Episode:2122 meanR:7.5400 R:15.0000 loss:0.0722\n",
      "Episode:2123 meanR:7.5700 R:8.0000 loss:0.0361\n",
      "Episode:2124 meanR:7.5800 R:5.0000 loss:0.0799\n",
      "Episode:2125 meanR:7.5100 R:0.0000 loss:0.0402\n",
      "Episode:2126 meanR:7.5000 R:9.0000 loss:0.0498\n",
      "Episode:2127 meanR:7.6100 R:15.0000 loss:0.0708\n",
      "Episode:2128 meanR:7.6100 R:7.0000 loss:0.1018\n",
      "Episode:2129 meanR:7.6200 R:0.0000 loss:0.0310\n",
      "Episode:2130 meanR:7.5300 R:-2.0000 loss:0.0249\n",
      "Episode:2131 meanR:7.4500 R:3.0000 loss:0.0240\n",
      "Episode:2132 meanR:7.4700 R:4.0000 loss:0.0283\n",
      "Episode:2133 meanR:7.4800 R:3.0000 loss:0.0257\n",
      "Episode:2134 meanR:7.3900 R:1.0000 loss:0.0143\n",
      "Episode:2135 meanR:7.2900 R:-1.0000 loss:0.0193\n",
      "Episode:2136 meanR:7.1500 R:2.0000 loss:0.0242\n",
      "Episode:2137 meanR:7.1200 R:6.0000 loss:0.0239\n",
      "Episode:2138 meanR:7.0500 R:2.0000 loss:0.0214\n",
      "Episode:2139 meanR:7.0400 R:2.0000 loss:0.0220\n",
      "Episode:2140 meanR:6.9500 R:2.0000 loss:0.0228\n",
      "Episode:2141 meanR:6.8400 R:2.0000 loss:0.0286\n",
      "Episode:2142 meanR:6.7500 R:0.0000 loss:0.0202\n",
      "Episode:2143 meanR:6.6800 R:0.0000 loss:0.0210\n",
      "Episode:2144 meanR:6.5900 R:2.0000 loss:0.0199\n",
      "Episode:2145 meanR:6.5300 R:0.0000 loss:0.0286\n",
      "Episode:2146 meanR:6.4200 R:-1.0000 loss:0.0202\n",
      "Episode:2147 meanR:6.2900 R:1.0000 loss:0.0125\n",
      "Episode:2148 meanR:6.2500 R:1.0000 loss:0.0337\n",
      "Episode:2149 meanR:6.1900 R:6.0000 loss:0.0276\n",
      "Episode:2150 meanR:6.0500 R:1.0000 loss:0.0514\n",
      "Episode:2151 meanR:6.0800 R:7.0000 loss:0.0384\n",
      "Episode:2152 meanR:6.1800 R:11.0000 loss:0.0674\n",
      "Episode:2153 meanR:6.1100 R:0.0000 loss:0.0490\n",
      "Episode:2154 meanR:6.0600 R:1.0000 loss:0.0506\n",
      "Episode:2155 meanR:6.0400 R:2.0000 loss:0.0234\n",
      "Episode:2156 meanR:5.9800 R:6.0000 loss:0.0310\n",
      "Episode:2157 meanR:5.8500 R:0.0000 loss:0.0364\n",
      "Episode:2158 meanR:5.7500 R:-2.0000 loss:0.0237\n",
      "Episode:2159 meanR:5.7100 R:0.0000 loss:0.0240\n",
      "Episode:2160 meanR:5.6600 R:3.0000 loss:0.0266\n",
      "Episode:2161 meanR:5.6100 R:2.0000 loss:0.0273\n",
      "Episode:2162 meanR:5.5800 R:6.0000 loss:0.0375\n",
      "Episode:2163 meanR:5.5000 R:7.0000 loss:0.0333\n",
      "Episode:2164 meanR:5.4600 R:9.0000 loss:0.0458\n",
      "Episode:2165 meanR:5.4500 R:5.0000 loss:0.0478\n",
      "Episode:2166 meanR:5.3500 R:5.0000 loss:0.0481\n",
      "Episode:2167 meanR:5.3600 R:10.0000 loss:0.0333\n",
      "Episode:2168 meanR:5.3900 R:15.0000 loss:0.0709\n",
      "Episode:2169 meanR:5.3600 R:7.0000 loss:0.0653\n",
      "Episode:2170 meanR:5.3600 R:9.0000 loss:0.0739\n",
      "Episode:2171 meanR:5.2600 R:1.0000 loss:0.0567\n",
      "Episode:2172 meanR:5.3200 R:11.0000 loss:0.0539\n",
      "Episode:2173 meanR:5.2400 R:6.0000 loss:0.0802\n",
      "Episode:2174 meanR:5.1700 R:4.0000 loss:0.0339\n",
      "Episode:2175 meanR:5.0700 R:4.0000 loss:0.0269\n",
      "Episode:2176 meanR:4.9800 R:1.0000 loss:0.0276\n",
      "Episode:2177 meanR:4.9000 R:0.0000 loss:0.0233\n",
      "Episode:2178 meanR:4.8700 R:9.0000 loss:0.0441\n",
      "Episode:2179 meanR:4.7700 R:1.0000 loss:0.0282\n",
      "Episode:2180 meanR:4.7400 R:7.0000 loss:0.0322\n",
      "Episode:2181 meanR:4.7400 R:10.0000 loss:0.0580\n",
      "Episode:2182 meanR:4.6900 R:6.0000 loss:0.0376\n",
      "Episode:2183 meanR:4.6500 R:1.0000 loss:0.0236\n",
      "Episode:2184 meanR:4.6500 R:2.0000 loss:0.0302\n",
      "Episode:2185 meanR:4.6600 R:5.0000 loss:0.0359\n",
      "Episode:2186 meanR:4.7100 R:9.0000 loss:0.0468\n",
      "Episode:2187 meanR:4.6800 R:6.0000 loss:0.0446\n",
      "Episode:2188 meanR:4.7700 R:12.0000 loss:0.0501\n",
      "Episode:2189 meanR:4.8000 R:6.0000 loss:0.0429\n",
      "Episode:2190 meanR:4.7400 R:7.0000 loss:0.0512\n",
      "Episode:2191 meanR:4.6400 R:1.0000 loss:0.0358\n",
      "Episode:2192 meanR:4.7200 R:14.0000 loss:0.0476\n",
      "Episode:2193 meanR:4.7300 R:2.0000 loss:0.0478\n",
      "Episode:2194 meanR:4.7400 R:0.0000 loss:0.0252\n",
      "Episode:2195 meanR:4.6300 R:-1.0000 loss:0.0427\n",
      "Episode:2196 meanR:4.5900 R:7.0000 loss:0.0425\n",
      "Episode:2197 meanR:4.5200 R:3.0000 loss:0.0289\n",
      "Episode:2198 meanR:4.4800 R:1.0000 loss:0.0319\n",
      "Episode:2199 meanR:4.4800 R:9.0000 loss:0.0337\n",
      "Episode:2200 meanR:4.4200 R:5.0000 loss:0.0537\n",
      "Episode:2201 meanR:4.3800 R:2.0000 loss:0.0329\n",
      "Episode:2202 meanR:4.3400 R:0.0000 loss:0.0258\n",
      "Episode:2203 meanR:4.3200 R:4.0000 loss:0.0244\n",
      "Episode:2204 meanR:4.3400 R:2.0000 loss:0.0325\n",
      "Episode:2205 meanR:4.3200 R:-1.0000 loss:0.0311\n",
      "Episode:2206 meanR:4.2300 R:0.0000 loss:0.0278\n",
      "Episode:2207 meanR:4.2000 R:1.0000 loss:0.0208\n",
      "Episode:2208 meanR:4.1600 R:1.0000 loss:0.0143\n",
      "Episode:2209 meanR:4.1000 R:0.0000 loss:0.0216\n",
      "Episode:2210 meanR:4.0300 R:2.0000 loss:0.0111\n",
      "Episode:2211 meanR:4.0800 R:11.0000 loss:0.0398\n",
      "Episode:2212 meanR:4.1700 R:13.0000 loss:0.0582\n",
      "Episode:2213 meanR:4.2600 R:13.0000 loss:0.0695\n",
      "Episode:2214 meanR:4.3400 R:10.0000 loss:0.0470\n",
      "Episode:2215 meanR:4.4000 R:7.0000 loss:0.0372\n",
      "Episode:2216 meanR:4.3600 R:3.0000 loss:0.0587\n",
      "Episode:2217 meanR:4.4100 R:8.0000 loss:0.0493\n",
      "Episode:2218 meanR:4.4800 R:9.0000 loss:0.0431\n",
      "Episode:2219 meanR:4.5600 R:11.0000 loss:0.0604\n",
      "Episode:2220 meanR:4.6600 R:15.0000 loss:0.0606\n",
      "Episode:2221 meanR:4.6300 R:7.0000 loss:0.0579\n",
      "Episode:2222 meanR:4.5700 R:9.0000 loss:0.0657\n",
      "Episode:2223 meanR:4.5200 R:3.0000 loss:0.0358\n",
      "Episode:2224 meanR:4.5900 R:12.0000 loss:0.0590\n",
      "Episode:2225 meanR:4.5800 R:-1.0000 loss:0.0650\n",
      "Episode:2226 meanR:4.5700 R:8.0000 loss:0.0441\n",
      "Episode:2227 meanR:4.5900 R:17.0000 loss:0.0486\n",
      "Episode:2228 meanR:4.6600 R:14.0000 loss:0.0756\n",
      "Episode:2229 meanR:4.7800 R:12.0000 loss:0.0640\n",
      "Episode:2230 meanR:4.9300 R:13.0000 loss:0.0865\n",
      "Episode:2231 meanR:5.0600 R:16.0000 loss:0.0501\n",
      "Episode:2232 meanR:5.1200 R:10.0000 loss:0.0713\n",
      "Episode:2233 meanR:5.2000 R:11.0000 loss:0.0543\n",
      "Episode:2234 meanR:5.2900 R:10.0000 loss:0.0850\n",
      "Episode:2235 meanR:5.3800 R:8.0000 loss:0.0731\n",
      "Episode:2236 meanR:5.4400 R:8.0000 loss:0.0673\n",
      "Episode:2237 meanR:5.4300 R:5.0000 loss:0.0399\n",
      "Episode:2238 meanR:5.5300 R:12.0000 loss:0.0450\n",
      "Episode:2239 meanR:5.6000 R:9.0000 loss:0.0558\n",
      "Episode:2240 meanR:5.7200 R:14.0000 loss:0.0520\n",
      "Episode:2241 meanR:5.8200 R:12.0000 loss:0.0499\n",
      "Episode:2242 meanR:5.8800 R:6.0000 loss:0.0588\n",
      "Episode:2243 meanR:5.9000 R:2.0000 loss:0.0346\n",
      "Episode:2244 meanR:5.9200 R:4.0000 loss:0.0354\n",
      "Episode:2245 meanR:6.0100 R:9.0000 loss:0.0315\n",
      "Episode:2246 meanR:6.0900 R:7.0000 loss:0.0383\n",
      "Episode:2247 meanR:6.1000 R:2.0000 loss:0.0386\n",
      "Episode:2248 meanR:6.1500 R:6.0000 loss:0.0539\n",
      "Episode:2249 meanR:6.1500 R:6.0000 loss:0.0468\n",
      "Episode:2250 meanR:6.2000 R:6.0000 loss:0.0552\n",
      "Episode:2251 meanR:6.1900 R:6.0000 loss:0.0503\n",
      "Episode:2252 meanR:6.1000 R:2.0000 loss:0.0615\n",
      "Episode:2253 meanR:6.1300 R:3.0000 loss:0.0347\n",
      "Episode:2254 meanR:6.1300 R:1.0000 loss:0.0440\n",
      "Episode:2255 meanR:6.1400 R:3.0000 loss:0.0342\n",
      "Episode:2256 meanR:6.1600 R:8.0000 loss:0.0423\n",
      "Episode:2257 meanR:6.1800 R:2.0000 loss:0.0472\n",
      "Episode:2258 meanR:6.2800 R:8.0000 loss:0.0489\n",
      "Episode:2259 meanR:6.3500 R:7.0000 loss:0.0436\n",
      "Episode:2260 meanR:6.3900 R:7.0000 loss:0.0319\n",
      "Episode:2261 meanR:6.4100 R:4.0000 loss:0.0378\n",
      "Episode:2262 meanR:6.3600 R:1.0000 loss:0.0322\n",
      "Episode:2263 meanR:6.3000 R:1.0000 loss:0.0330\n",
      "Episode:2264 meanR:6.2500 R:4.0000 loss:0.0440\n",
      "Episode:2265 meanR:6.2800 R:8.0000 loss:0.0433\n",
      "Episode:2266 meanR:6.2400 R:1.0000 loss:0.0243\n",
      "Episode:2267 meanR:6.1600 R:2.0000 loss:0.0321\n",
      "Episode:2268 meanR:6.0200 R:1.0000 loss:0.0194\n",
      "Episode:2269 meanR:5.9400 R:-1.0000 loss:0.0262\n",
      "Episode:2270 meanR:5.8600 R:1.0000 loss:0.0299\n",
      "Episode:2271 meanR:5.8600 R:1.0000 loss:0.0268\n",
      "Episode:2272 meanR:5.7400 R:-1.0000 loss:0.0256\n",
      "Episode:2273 meanR:5.7100 R:3.0000 loss:0.0250\n",
      "Episode:2274 meanR:5.6900 R:2.0000 loss:0.0391\n",
      "Episode:2275 meanR:5.6900 R:4.0000 loss:0.0521\n",
      "Episode:2276 meanR:5.6800 R:0.0000 loss:0.0302\n",
      "Episode:2277 meanR:5.7100 R:3.0000 loss:0.0241\n",
      "Episode:2278 meanR:5.6700 R:5.0000 loss:0.0423\n",
      "Episode:2279 meanR:5.7100 R:5.0000 loss:0.0440\n",
      "Episode:2280 meanR:5.6600 R:2.0000 loss:0.0188\n",
      "Episode:2281 meanR:5.5900 R:3.0000 loss:0.0310\n",
      "Episode:2282 meanR:5.5900 R:6.0000 loss:0.0409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2283 meanR:5.6000 R:2.0000 loss:0.0381\n",
      "Episode:2284 meanR:5.6400 R:6.0000 loss:0.0374\n",
      "Episode:2285 meanR:5.6700 R:8.0000 loss:0.0361\n",
      "Episode:2286 meanR:5.6700 R:9.0000 loss:0.0350\n",
      "Episode:2287 meanR:5.7200 R:11.0000 loss:0.0509\n",
      "Episode:2288 meanR:5.6400 R:4.0000 loss:0.0335\n",
      "Episode:2289 meanR:5.6200 R:4.0000 loss:0.0453\n",
      "Episode:2290 meanR:5.6200 R:7.0000 loss:0.0441\n",
      "Episode:2291 meanR:5.6900 R:8.0000 loss:0.0529\n",
      "Episode:2292 meanR:5.6000 R:5.0000 loss:0.0366\n",
      "Episode:2293 meanR:5.6300 R:5.0000 loss:0.0399\n",
      "Episode:2294 meanR:5.7100 R:8.0000 loss:0.0413\n",
      "Episode:2295 meanR:5.7900 R:7.0000 loss:0.0605\n",
      "Episode:2296 meanR:5.7400 R:2.0000 loss:0.0562\n",
      "Episode:2297 meanR:5.7600 R:5.0000 loss:0.0301\n",
      "Episode:2298 meanR:5.8000 R:5.0000 loss:0.0428\n",
      "Episode:2299 meanR:5.7800 R:7.0000 loss:0.0632\n",
      "Episode:2300 meanR:5.8100 R:8.0000 loss:0.0458\n",
      "Episode:2301 meanR:5.8600 R:7.0000 loss:0.0720\n",
      "Episode:2302 meanR:5.9100 R:5.0000 loss:0.0610\n",
      "Episode:2303 meanR:5.9300 R:6.0000 loss:0.0391\n",
      "Episode:2304 meanR:5.9800 R:7.0000 loss:0.0548\n",
      "Episode:2305 meanR:6.1200 R:13.0000 loss:0.0592\n",
      "Episode:2306 meanR:6.2000 R:8.0000 loss:0.0713\n",
      "Episode:2307 meanR:6.2800 R:9.0000 loss:0.0760\n",
      "Episode:2308 meanR:6.3400 R:7.0000 loss:0.0724\n",
      "Episode:2309 meanR:6.4900 R:15.0000 loss:0.0911\n",
      "Episode:2310 meanR:6.5000 R:3.0000 loss:0.0715\n",
      "Episode:2311 meanR:6.3900 R:0.0000 loss:0.0658\n",
      "Episode:2312 meanR:6.2800 R:2.0000 loss:0.0406\n",
      "Episode:2313 meanR:6.2600 R:11.0000 loss:0.0488\n",
      "Episode:2314 meanR:6.2200 R:6.0000 loss:0.0695\n",
      "Episode:2315 meanR:6.2300 R:8.0000 loss:0.0801\n",
      "Episode:2316 meanR:6.2200 R:2.0000 loss:0.0475\n",
      "Episode:2317 meanR:6.1800 R:4.0000 loss:0.0726\n",
      "Episode:2318 meanR:6.0800 R:-1.0000 loss:0.0225\n",
      "Episode:2319 meanR:6.0800 R:11.0000 loss:0.0553\n",
      "Episode:2320 meanR:5.9600 R:3.0000 loss:0.0589\n",
      "Episode:2321 meanR:5.9800 R:9.0000 loss:0.0555\n",
      "Episode:2322 meanR:5.9600 R:7.0000 loss:0.0736\n",
      "Episode:2323 meanR:6.0100 R:8.0000 loss:0.0479\n",
      "Episode:2324 meanR:5.9000 R:1.0000 loss:0.0565\n",
      "Episode:2325 meanR:5.9500 R:4.0000 loss:0.0468\n",
      "Episode:2326 meanR:5.9400 R:7.0000 loss:0.0507\n",
      "Episode:2327 meanR:5.8900 R:12.0000 loss:0.0574\n",
      "Episode:2328 meanR:5.8200 R:7.0000 loss:0.0379\n",
      "Episode:2329 meanR:5.8100 R:11.0000 loss:0.0491\n",
      "Episode:2330 meanR:5.7800 R:10.0000 loss:0.0776\n",
      "Episode:2331 meanR:5.6400 R:2.0000 loss:0.0665\n",
      "Episode:2332 meanR:5.5900 R:5.0000 loss:0.0311\n",
      "Episode:2333 meanR:5.4500 R:-3.0000 loss:0.1587\n",
      "Episode:2334 meanR:5.3700 R:2.0000 loss:0.1654\n",
      "Episode:2335 meanR:5.3500 R:6.0000 loss:0.3062\n",
      "Episode:2336 meanR:5.3100 R:4.0000 loss:0.0716\n",
      "Episode:2337 meanR:5.2900 R:3.0000 loss:0.0344\n",
      "Episode:2338 meanR:5.1800 R:1.0000 loss:0.0374\n",
      "Episode:2339 meanR:5.1300 R:4.0000 loss:0.0618\n",
      "Episode:2340 meanR:5.0400 R:5.0000 loss:0.0509\n",
      "Episode:2341 meanR:4.9600 R:4.0000 loss:0.0269\n",
      "Episode:2342 meanR:4.9700 R:7.0000 loss:0.0344\n",
      "Episode:2343 meanR:5.0200 R:7.0000 loss:0.0306\n",
      "Episode:2344 meanR:5.0600 R:8.0000 loss:0.0322\n",
      "Episode:2345 meanR:5.0000 R:3.0000 loss:0.0387\n",
      "Episode:2346 meanR:4.9200 R:-1.0000 loss:0.0260\n",
      "Episode:2347 meanR:4.9000 R:0.0000 loss:0.0137\n",
      "Episode:2348 meanR:4.8600 R:2.0000 loss:0.0149\n",
      "Episode:2349 meanR:4.8900 R:9.0000 loss:0.0291\n",
      "Episode:2350 meanR:4.8600 R:3.0000 loss:0.0410\n",
      "Episode:2351 meanR:4.8500 R:5.0000 loss:0.0283\n",
      "Episode:2352 meanR:4.8500 R:2.0000 loss:0.0255\n",
      "Episode:2353 meanR:4.8800 R:6.0000 loss:0.0391\n",
      "Episode:2354 meanR:4.9200 R:5.0000 loss:0.0329\n",
      "Episode:2355 meanR:4.9900 R:10.0000 loss:0.0309\n",
      "Episode:2356 meanR:4.9300 R:2.0000 loss:0.0235\n",
      "Episode:2357 meanR:4.9400 R:3.0000 loss:0.0351\n",
      "Episode:2358 meanR:4.9100 R:5.0000 loss:0.0426\n",
      "Episode:2359 meanR:4.8800 R:4.0000 loss:0.0364\n",
      "Episode:2360 meanR:4.8200 R:1.0000 loss:0.0218\n",
      "Episode:2361 meanR:4.8000 R:2.0000 loss:0.0204\n",
      "Episode:2362 meanR:4.8600 R:7.0000 loss:0.0259\n",
      "Episode:2363 meanR:4.9200 R:7.0000 loss:0.0240\n",
      "Episode:2364 meanR:4.9500 R:7.0000 loss:0.0420\n",
      "Episode:2365 meanR:4.9600 R:9.0000 loss:0.0500\n",
      "Episode:2366 meanR:5.0000 R:5.0000 loss:0.0420\n",
      "Episode:2367 meanR:5.0300 R:5.0000 loss:0.0462\n",
      "Episode:2368 meanR:5.0700 R:5.0000 loss:0.0430\n",
      "Episode:2369 meanR:5.1500 R:7.0000 loss:0.0460\n",
      "Episode:2370 meanR:5.1700 R:3.0000 loss:0.0538\n",
      "Episode:2371 meanR:5.2400 R:8.0000 loss:0.0343\n",
      "Episode:2372 meanR:5.3000 R:5.0000 loss:0.0451\n",
      "Episode:2373 meanR:5.2500 R:-2.0000 loss:0.0483\n",
      "Episode:2374 meanR:5.2700 R:4.0000 loss:0.0327\n",
      "Episode:2375 meanR:5.2700 R:4.0000 loss:0.0345\n",
      "Episode:2376 meanR:5.4400 R:17.0000 loss:0.0426\n",
      "Episode:2377 meanR:5.5000 R:9.0000 loss:0.0604\n",
      "Episode:2378 meanR:5.5900 R:14.0000 loss:0.0620\n",
      "Episode:2379 meanR:5.6200 R:8.0000 loss:0.0602\n",
      "Episode:2380 meanR:5.7400 R:14.0000 loss:0.0663\n",
      "Episode:2381 meanR:5.8600 R:15.0000 loss:0.0334\n",
      "Episode:2382 meanR:5.9300 R:13.0000 loss:0.0873\n",
      "Episode:2383 meanR:5.9600 R:5.0000 loss:0.0971\n",
      "Episode:2384 meanR:5.9700 R:7.0000 loss:0.0648\n",
      "Episode:2385 meanR:6.0200 R:13.0000 loss:0.0740\n",
      "Episode:2386 meanR:5.9700 R:4.0000 loss:0.0472\n",
      "Episode:2387 meanR:5.9500 R:9.0000 loss:0.0459\n",
      "Episode:2388 meanR:6.0000 R:9.0000 loss:0.0613\n",
      "Episode:2389 meanR:6.1100 R:15.0000 loss:0.0668\n",
      "Episode:2390 meanR:6.1700 R:13.0000 loss:0.0743\n",
      "Episode:2391 meanR:6.1600 R:7.0000 loss:0.0581\n",
      "Episode:2392 meanR:6.1800 R:7.0000 loss:0.0701\n",
      "Episode:2393 meanR:6.1800 R:5.0000 loss:0.0597\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        #state = env.reset()\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]   # get the current state\n",
    "        initial_state = sess.run(model.initial_state)\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            action = np.argmax(action_logits)\n",
    "            #state, reward, done, _ = env.step(action)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append(initial_state)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            initial_state = final_state\n",
    "            \n",
    "            # Training\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            initial_states = memory.states\n",
    "            next_actions_logits = sess.run(model.actions_logits, \n",
    "                                           feed_dict = {model.states: next_states,\n",
    "                                                        model.initial_state: initial_states[1]})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs,\n",
    "                                                                     model.initial_state: initial_states[0]})\n",
    "            # End of training\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        # Outputing: priting out/Potting\n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= +13:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Episode rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 2.00\n"
     ]
    }
   ],
   "source": [
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Testing episodes/epochs\n",
    "    for _ in range(1):\n",
    "        total_reward = 0\n",
    "        #state = env.reset()\n",
    "        env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]   # get the current state\n",
    "\n",
    "        # Testing steps/batches\n",
    "        while True:\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            #state, reward, done, _ = env.step(action)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        print('total_reward: {:.2f}'.format(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful!!!!!!!!!!!!!!!!\n",
    "# Closing the env\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

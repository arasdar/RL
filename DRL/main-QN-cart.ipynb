{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "rewards = []\n",
    "for _ in range(100):\n",
    "    #env.render()\n",
    "    state, reward, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        rewards = []\n",
    "        env.reset()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, learning_rate, state_size, action_size, hidden_size):\n",
    "        # Model input\n",
    "        self.inputs = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "        self.actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "        self.targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "\n",
    "        # Model output\n",
    "        fc1 = tf.contrib.layers.fully_connected(self.inputs, hidden_size)\n",
    "        fc2 = tf.contrib.layers.fully_connected(fc1, hidden_size)\n",
    "        self.actions_logits = tf.contrib.layers.fully_connected(fc2, action_size, activation_fn=None)\n",
    "\n",
    "        # Model loss\n",
    "        actions_labels = tf.one_hot(self.actions, action_size)\n",
    "        Q = tf.reduce_max(self.actions_logits*actions_labels, axis=1)\n",
    "        self.loss = tf.reduce_mean(tf.square(Q - self.targetQs))\n",
    "\n",
    "        # Model update\n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "action_size = 2\n",
    "state_size = 4\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.reset_default_graph()\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size, learning_rate=learning_rate)\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.add([state, action, reward, next_state, float(done)])\n",
    "    state = next_state\n",
    "    if done:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 MeanR:15.0000 R:15.0 Loss:1.2776 ExploreP:0.9985\n",
      "Episode:1 MeanR:36.5000 R:58.0 Loss:1.3697 ExploreP:0.9928\n",
      "Episode:2 MeanR:31.0000 R:20.0 Loss:1.0164 ExploreP:0.9908\n",
      "Episode:3 MeanR:29.0000 R:23.0 Loss:1.6375 ExploreP:0.9886\n",
      "Episode:4 MeanR:30.4000 R:36.0 Loss:1.7714 ExploreP:0.9851\n",
      "Episode:5 MeanR:33.5000 R:49.0 Loss:1.7270 ExploreP:0.9803\n",
      "Episode:6 MeanR:32.1429 R:24.0 Loss:1.9787 ExploreP:0.9780\n",
      "Episode:7 MeanR:29.8750 R:14.0 Loss:1.2731 ExploreP:0.9766\n",
      "Episode:8 MeanR:29.8889 R:30.0 Loss:1.3357 ExploreP:0.9737\n",
      "Episode:9 MeanR:29.1000 R:22.0 Loss:1.0870 ExploreP:0.9716\n",
      "Episode:10 MeanR:28.0909 R:18.0 Loss:1.5011 ExploreP:0.9699\n",
      "Episode:11 MeanR:27.1667 R:17.0 Loss:1.4852 ExploreP:0.9682\n",
      "Episode:12 MeanR:26.0769 R:13.0 Loss:1.2022 ExploreP:0.9670\n",
      "Episode:13 MeanR:25.3571 R:16.0 Loss:1.5702 ExploreP:0.9655\n",
      "Episode:14 MeanR:25.5333 R:28.0 Loss:1.5831 ExploreP:0.9628\n",
      "Episode:15 MeanR:24.6250 R:11.0 Loss:1.8559 ExploreP:0.9618\n",
      "Episode:16 MeanR:26.9412 R:64.0 Loss:1.6367 ExploreP:0.9557\n",
      "Episode:17 MeanR:26.4444 R:18.0 Loss:1.5926 ExploreP:0.9540\n",
      "Episode:18 MeanR:26.5263 R:28.0 Loss:1.7806 ExploreP:0.9513\n",
      "Episode:19 MeanR:26.2000 R:20.0 Loss:3.1094 ExploreP:0.9495\n",
      "Episode:20 MeanR:27.1905 R:47.0 Loss:1.9203 ExploreP:0.9451\n",
      "Episode:21 MeanR:26.7273 R:17.0 Loss:5.3527 ExploreP:0.9435\n",
      "Episode:22 MeanR:26.3478 R:18.0 Loss:3.0662 ExploreP:0.9418\n",
      "Episode:23 MeanR:25.8333 R:14.0 Loss:3.9745 ExploreP:0.9405\n",
      "Episode:24 MeanR:25.6400 R:21.0 Loss:2.4403 ExploreP:0.9385\n",
      "Episode:25 MeanR:26.3846 R:45.0 Loss:1.7589 ExploreP:0.9344\n",
      "Episode:26 MeanR:26.0000 R:16.0 Loss:2.0388 ExploreP:0.9329\n",
      "Episode:27 MeanR:25.7143 R:18.0 Loss:7.9881 ExploreP:0.9312\n",
      "Episode:28 MeanR:25.2414 R:12.0 Loss:6.8317 ExploreP:0.9301\n",
      "Episode:29 MeanR:24.8333 R:13.0 Loss:2.5369 ExploreP:0.9289\n",
      "Episode:30 MeanR:24.5806 R:17.0 Loss:2.7051 ExploreP:0.9274\n",
      "Episode:31 MeanR:24.1562 R:11.0 Loss:2.8538 ExploreP:0.9264\n",
      "Episode:32 MeanR:24.0000 R:19.0 Loss:3.1408 ExploreP:0.9246\n",
      "Episode:33 MeanR:24.8529 R:53.0 Loss:6.0423 ExploreP:0.9198\n",
      "Episode:34 MeanR:24.6286 R:17.0 Loss:17.4174 ExploreP:0.9182\n",
      "Episode:35 MeanR:24.3889 R:16.0 Loss:7.6033 ExploreP:0.9168\n",
      "Episode:36 MeanR:24.1622 R:16.0 Loss:14.5289 ExploreP:0.9153\n",
      "Episode:37 MeanR:24.4737 R:36.0 Loss:11.1573 ExploreP:0.9121\n",
      "Episode:38 MeanR:24.5128 R:26.0 Loss:4.5426 ExploreP:0.9097\n",
      "Episode:39 MeanR:24.4000 R:20.0 Loss:2.6482 ExploreP:0.9079\n",
      "Episode:40 MeanR:24.4634 R:27.0 Loss:4.2060 ExploreP:0.9055\n",
      "Episode:41 MeanR:24.2143 R:14.0 Loss:3.7416 ExploreP:0.9043\n",
      "Episode:42 MeanR:23.8837 R:10.0 Loss:3.3433 ExploreP:0.9034\n",
      "Episode:43 MeanR:23.6136 R:12.0 Loss:3.5454 ExploreP:0.9023\n",
      "Episode:44 MeanR:23.3333 R:11.0 Loss:4.1030 ExploreP:0.9013\n",
      "Episode:45 MeanR:23.2174 R:18.0 Loss:10.9476 ExploreP:0.8997\n",
      "Episode:46 MeanR:23.3191 R:28.0 Loss:4.7349 ExploreP:0.8972\n",
      "Episode:47 MeanR:23.2292 R:19.0 Loss:18.8375 ExploreP:0.8955\n",
      "Episode:48 MeanR:23.1837 R:21.0 Loss:38.1904 ExploreP:0.8937\n",
      "Episode:49 MeanR:23.0000 R:14.0 Loss:36.5034 ExploreP:0.8925\n",
      "Episode:50 MeanR:22.7255 R:9.0 Loss:4.0082 ExploreP:0.8917\n",
      "Episode:51 MeanR:22.5385 R:13.0 Loss:11.7676 ExploreP:0.8905\n",
      "Episode:52 MeanR:22.3396 R:12.0 Loss:3.5937 ExploreP:0.8895\n",
      "Episode:53 MeanR:22.2222 R:16.0 Loss:20.8526 ExploreP:0.8881\n",
      "Episode:54 MeanR:22.0182 R:11.0 Loss:12.3049 ExploreP:0.8871\n",
      "Episode:55 MeanR:21.9821 R:20.0 Loss:29.0667 ExploreP:0.8853\n",
      "Episode:56 MeanR:21.7719 R:10.0 Loss:10.2004 ExploreP:0.8845\n",
      "Episode:57 MeanR:21.5345 R:8.0 Loss:4.2226 ExploreP:0.8838\n",
      "Episode:58 MeanR:21.3559 R:11.0 Loss:30.9261 ExploreP:0.8828\n",
      "Episode:59 MeanR:21.2667 R:16.0 Loss:3.9696 ExploreP:0.8814\n",
      "Episode:60 MeanR:21.1639 R:15.0 Loss:5.2911 ExploreP:0.8801\n",
      "Episode:61 MeanR:21.3548 R:33.0 Loss:34.7550 ExploreP:0.8772\n",
      "Episode:62 MeanR:21.1746 R:10.0 Loss:4.0531 ExploreP:0.8764\n",
      "Episode:63 MeanR:21.2969 R:29.0 Loss:16.7192 ExploreP:0.8739\n",
      "Episode:64 MeanR:21.2615 R:19.0 Loss:4.6102 ExploreP:0.8722\n",
      "Episode:65 MeanR:21.1515 R:14.0 Loss:44.6486 ExploreP:0.8710\n",
      "Episode:66 MeanR:20.9552 R:8.0 Loss:5.3039 ExploreP:0.8703\n",
      "Episode:67 MeanR:21.4559 R:55.0 Loss:19.9412 ExploreP:0.8656\n",
      "Episode:68 MeanR:21.3913 R:17.0 Loss:67.9230 ExploreP:0.8641\n",
      "Episode:69 MeanR:21.3714 R:20.0 Loss:6.0287 ExploreP:0.8624\n",
      "Episode:70 MeanR:21.4930 R:30.0 Loss:18.5842 ExploreP:0.8599\n",
      "Episode:71 MeanR:21.3472 R:11.0 Loss:27.1061 ExploreP:0.8590\n",
      "Episode:72 MeanR:21.2055 R:11.0 Loss:50.7796 ExploreP:0.8580\n",
      "Episode:73 MeanR:21.0811 R:12.0 Loss:48.5999 ExploreP:0.8570\n",
      "Episode:74 MeanR:20.9600 R:12.0 Loss:53.8119 ExploreP:0.8560\n",
      "Episode:75 MeanR:20.8158 R:10.0 Loss:6.2201 ExploreP:0.8551\n",
      "Episode:76 MeanR:20.7403 R:15.0 Loss:47.5883 ExploreP:0.8539\n",
      "Episode:77 MeanR:20.7564 R:22.0 Loss:5.3473 ExploreP:0.8520\n",
      "Episode:78 MeanR:20.9747 R:38.0 Loss:6.4693 ExploreP:0.8488\n",
      "Episode:79 MeanR:21.0250 R:25.0 Loss:68.1395 ExploreP:0.8467\n",
      "Episode:80 MeanR:20.9383 R:14.0 Loss:5.6601 ExploreP:0.8456\n",
      "Episode:81 MeanR:20.9756 R:24.0 Loss:5.7586 ExploreP:0.8436\n",
      "Episode:82 MeanR:20.9759 R:21.0 Loss:83.1371 ExploreP:0.8418\n",
      "Episode:83 MeanR:20.8571 R:11.0 Loss:5.4730 ExploreP:0.8409\n",
      "Episode:84 MeanR:20.8000 R:16.0 Loss:92.1660 ExploreP:0.8396\n",
      "Episode:85 MeanR:20.7093 R:13.0 Loss:108.8841 ExploreP:0.8385\n",
      "Episode:86 MeanR:20.9080 R:38.0 Loss:7.0584 ExploreP:0.8353\n",
      "Episode:87 MeanR:20.9091 R:21.0 Loss:6.2533 ExploreP:0.8336\n",
      "Episode:88 MeanR:21.0225 R:31.0 Loss:40.2240 ExploreP:0.8311\n",
      "Episode:89 MeanR:20.9111 R:11.0 Loss:4.5097 ExploreP:0.8302\n",
      "Episode:90 MeanR:20.8791 R:18.0 Loss:5.3469 ExploreP:0.8287\n",
      "Episode:91 MeanR:20.7717 R:11.0 Loss:43.4771 ExploreP:0.8278\n",
      "Episode:92 MeanR:20.6882 R:13.0 Loss:34.0210 ExploreP:0.8267\n",
      "Episode:93 MeanR:20.6809 R:20.0 Loss:108.1045 ExploreP:0.8251\n",
      "Episode:94 MeanR:20.5789 R:11.0 Loss:199.2902 ExploreP:0.8242\n",
      "Episode:95 MeanR:20.4688 R:10.0 Loss:46.9928 ExploreP:0.8234\n",
      "Episode:96 MeanR:20.5052 R:24.0 Loss:5.8024 ExploreP:0.8214\n",
      "Episode:97 MeanR:20.4082 R:11.0 Loss:50.8952 ExploreP:0.8205\n",
      "Episode:98 MeanR:20.3232 R:12.0 Loss:5.1024 ExploreP:0.8196\n",
      "Episode:99 MeanR:20.4000 R:28.0 Loss:5.5892 ExploreP:0.8173\n",
      "Episode:100 MeanR:20.4800 R:23.0 Loss:5.7434 ExploreP:0.8155\n",
      "Episode:101 MeanR:20.0800 R:18.0 Loss:56.6705 ExploreP:0.8140\n",
      "Episode:102 MeanR:19.9900 R:11.0 Loss:56.9951 ExploreP:0.8131\n",
      "Episode:103 MeanR:19.8900 R:13.0 Loss:4.7555 ExploreP:0.8121\n",
      "Episode:104 MeanR:19.6300 R:10.0 Loss:213.8778 ExploreP:0.8113\n",
      "Episode:105 MeanR:19.3200 R:18.0 Loss:4.2777 ExploreP:0.8098\n",
      "Episode:106 MeanR:19.2700 R:19.0 Loss:56.5887 ExploreP:0.8083\n",
      "Episode:107 MeanR:19.3500 R:22.0 Loss:75.0227 ExploreP:0.8066\n",
      "Episode:108 MeanR:19.4000 R:35.0 Loss:4.2523 ExploreP:0.8038\n",
      "Episode:109 MeanR:19.3200 R:14.0 Loss:60.2933 ExploreP:0.8027\n",
      "Episode:110 MeanR:19.2500 R:11.0 Loss:39.1342 ExploreP:0.8018\n",
      "Episode:111 MeanR:19.2100 R:13.0 Loss:40.9953 ExploreP:0.8008\n",
      "Episode:112 MeanR:19.3200 R:24.0 Loss:5.1388 ExploreP:0.7989\n",
      "Episode:113 MeanR:19.3000 R:14.0 Loss:44.7866 ExploreP:0.7978\n",
      "Episode:114 MeanR:19.1900 R:17.0 Loss:108.0333 ExploreP:0.7964\n",
      "Episode:115 MeanR:19.2300 R:15.0 Loss:130.5133 ExploreP:0.7953\n",
      "Episode:116 MeanR:18.7400 R:15.0 Loss:46.7254 ExploreP:0.7941\n",
      "Episode:117 MeanR:18.9400 R:38.0 Loss:4.4488 ExploreP:0.7911\n",
      "Episode:118 MeanR:18.8800 R:22.0 Loss:54.9262 ExploreP:0.7894\n",
      "Episode:119 MeanR:18.7600 R:8.0 Loss:69.5555 ExploreP:0.7888\n",
      "Episode:120 MeanR:18.4200 R:13.0 Loss:3.4519 ExploreP:0.7877\n",
      "Episode:121 MeanR:18.4700 R:22.0 Loss:3.7318 ExploreP:0.7860\n",
      "Episode:122 MeanR:18.3900 R:10.0 Loss:4.7987 ExploreP:0.7853\n",
      "Episode:123 MeanR:18.3500 R:10.0 Loss:3.2928 ExploreP:0.7845\n",
      "Episode:124 MeanR:18.2900 R:15.0 Loss:3.4838 ExploreP:0.7833\n",
      "Episode:125 MeanR:17.9500 R:11.0 Loss:109.0565 ExploreP:0.7825\n",
      "Episode:126 MeanR:17.9400 R:15.0 Loss:42.9970 ExploreP:0.7813\n",
      "Episode:127 MeanR:18.0200 R:26.0 Loss:66.1615 ExploreP:0.7793\n",
      "Episode:128 MeanR:18.0000 R:10.0 Loss:3.0438 ExploreP:0.7785\n",
      "Episode:129 MeanR:17.9900 R:12.0 Loss:133.8420 ExploreP:0.7776\n",
      "Episode:130 MeanR:17.9500 R:13.0 Loss:3.1795 ExploreP:0.7766\n",
      "Episode:131 MeanR:18.0000 R:16.0 Loss:86.7142 ExploreP:0.7754\n",
      "Episode:132 MeanR:18.0400 R:23.0 Loss:51.1424 ExploreP:0.7736\n",
      "Episode:133 MeanR:17.6100 R:10.0 Loss:150.1289 ExploreP:0.7729\n",
      "Episode:134 MeanR:17.6300 R:19.0 Loss:105.8043 ExploreP:0.7714\n",
      "Episode:135 MeanR:17.5700 R:10.0 Loss:3.0091 ExploreP:0.7707\n",
      "Episode:136 MeanR:17.6100 R:20.0 Loss:2.9192 ExploreP:0.7692\n",
      "Episode:137 MeanR:17.3700 R:12.0 Loss:2.6968 ExploreP:0.7682\n",
      "Episode:138 MeanR:17.2200 R:11.0 Loss:41.1146 ExploreP:0.7674\n",
      "Episode:139 MeanR:17.1600 R:14.0 Loss:110.5226 ExploreP:0.7664\n",
      "Episode:140 MeanR:17.1000 R:21.0 Loss:166.2831 ExploreP:0.7648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:141 MeanR:17.1300 R:17.0 Loss:132.8625 ExploreP:0.7635\n",
      "Episode:142 MeanR:17.1800 R:15.0 Loss:101.1411 ExploreP:0.7624\n",
      "Episode:143 MeanR:17.1600 R:10.0 Loss:94.6447 ExploreP:0.7616\n",
      "Episode:144 MeanR:17.1900 R:14.0 Loss:80.1917 ExploreP:0.7605\n",
      "Episode:145 MeanR:17.1000 R:9.0 Loss:3.3447 ExploreP:0.7599\n",
      "Episode:146 MeanR:17.0200 R:20.0 Loss:132.8218 ExploreP:0.7584\n",
      "Episode:147 MeanR:16.9700 R:14.0 Loss:3.2490 ExploreP:0.7573\n",
      "Episode:148 MeanR:16.9000 R:14.0 Loss:45.8725 ExploreP:0.7563\n",
      "Episode:149 MeanR:16.8700 R:11.0 Loss:2.7721 ExploreP:0.7555\n",
      "Episode:150 MeanR:16.9000 R:12.0 Loss:1.7710 ExploreP:0.7546\n",
      "Episode:151 MeanR:16.9500 R:18.0 Loss:96.2721 ExploreP:0.7532\n",
      "Episode:152 MeanR:16.9700 R:14.0 Loss:133.1580 ExploreP:0.7522\n",
      "Episode:153 MeanR:17.0300 R:22.0 Loss:90.5473 ExploreP:0.7506\n",
      "Episode:154 MeanR:17.2100 R:29.0 Loss:38.0978 ExploreP:0.7484\n",
      "Episode:155 MeanR:17.1500 R:14.0 Loss:183.3531 ExploreP:0.7474\n",
      "Episode:156 MeanR:17.2600 R:21.0 Loss:47.2075 ExploreP:0.7458\n",
      "Episode:157 MeanR:17.3900 R:21.0 Loss:86.6454 ExploreP:0.7443\n",
      "Episode:158 MeanR:17.4100 R:13.0 Loss:3.1179 ExploreP:0.7433\n",
      "Episode:159 MeanR:17.5400 R:29.0 Loss:45.6564 ExploreP:0.7412\n",
      "Episode:160 MeanR:17.5300 R:14.0 Loss:40.1111 ExploreP:0.7402\n",
      "Episode:161 MeanR:17.3600 R:16.0 Loss:43.7312 ExploreP:0.7390\n",
      "Episode:162 MeanR:17.4800 R:22.0 Loss:1.5829 ExploreP:0.7374\n",
      "Episode:163 MeanR:17.4200 R:23.0 Loss:2.6916 ExploreP:0.7357\n",
      "Episode:164 MeanR:17.3400 R:11.0 Loss:58.4555 ExploreP:0.7350\n",
      "Episode:165 MeanR:17.3900 R:19.0 Loss:1.8618 ExploreP:0.7336\n",
      "Episode:166 MeanR:17.5200 R:21.0 Loss:37.2851 ExploreP:0.7321\n",
      "Episode:167 MeanR:17.0900 R:12.0 Loss:93.6600 ExploreP:0.7312\n",
      "Episode:168 MeanR:17.0600 R:14.0 Loss:85.2651 ExploreP:0.7302\n",
      "Episode:169 MeanR:16.9800 R:12.0 Loss:110.3559 ExploreP:0.7293\n",
      "Episode:170 MeanR:16.8200 R:14.0 Loss:35.8121 ExploreP:0.7283\n",
      "Episode:171 MeanR:16.9100 R:20.0 Loss:2.6715 ExploreP:0.7269\n",
      "Episode:172 MeanR:16.9400 R:14.0 Loss:2.3725 ExploreP:0.7259\n",
      "Episode:173 MeanR:16.9800 R:16.0 Loss:74.5253 ExploreP:0.7247\n",
      "Episode:174 MeanR:16.9600 R:10.0 Loss:120.0249 ExploreP:0.7240\n",
      "Episode:175 MeanR:17.0900 R:23.0 Loss:32.5873 ExploreP:0.7224\n",
      "Episode:176 MeanR:17.1900 R:25.0 Loss:70.2511 ExploreP:0.7206\n",
      "Episode:177 MeanR:17.3300 R:36.0 Loss:2.6184 ExploreP:0.7180\n",
      "Episode:178 MeanR:17.1400 R:19.0 Loss:34.6519 ExploreP:0.7167\n",
      "Episode:179 MeanR:17.0100 R:12.0 Loss:102.4313 ExploreP:0.7159\n",
      "Episode:180 MeanR:17.1000 R:23.0 Loss:47.6437 ExploreP:0.7142\n",
      "Episode:181 MeanR:17.1100 R:25.0 Loss:47.5971 ExploreP:0.7125\n",
      "Episode:182 MeanR:17.1900 R:29.0 Loss:29.7404 ExploreP:0.7104\n",
      "Episode:183 MeanR:17.3300 R:25.0 Loss:3.3990 ExploreP:0.7087\n",
      "Episode:184 MeanR:17.2800 R:11.0 Loss:1.8030 ExploreP:0.7079\n",
      "Episode:185 MeanR:17.2900 R:14.0 Loss:105.7494 ExploreP:0.7069\n",
      "Episode:186 MeanR:17.3700 R:46.0 Loss:1.6102 ExploreP:0.7037\n",
      "Episode:187 MeanR:17.2700 R:11.0 Loss:25.3943 ExploreP:0.7030\n",
      "Episode:188 MeanR:17.1700 R:21.0 Loss:1.3409 ExploreP:0.7015\n",
      "Episode:189 MeanR:17.2100 R:15.0 Loss:140.8177 ExploreP:0.7005\n",
      "Episode:190 MeanR:17.1900 R:16.0 Loss:68.2904 ExploreP:0.6994\n",
      "Episode:191 MeanR:17.2500 R:17.0 Loss:1.1781 ExploreP:0.6982\n",
      "Episode:192 MeanR:17.2600 R:14.0 Loss:26.8612 ExploreP:0.6973\n",
      "Episode:193 MeanR:17.3400 R:28.0 Loss:1.6833 ExploreP:0.6953\n",
      "Episode:194 MeanR:17.7000 R:47.0 Loss:33.2096 ExploreP:0.6921\n",
      "Episode:195 MeanR:17.7800 R:18.0 Loss:34.2853 ExploreP:0.6909\n",
      "Episode:196 MeanR:17.6500 R:11.0 Loss:80.0451 ExploreP:0.6901\n",
      "Episode:197 MeanR:17.7500 R:21.0 Loss:52.8767 ExploreP:0.6887\n",
      "Episode:198 MeanR:17.7600 R:13.0 Loss:39.6533 ExploreP:0.6878\n",
      "Episode:199 MeanR:17.5900 R:11.0 Loss:2.0195 ExploreP:0.6871\n",
      "Episode:200 MeanR:17.5300 R:17.0 Loss:26.2900 ExploreP:0.6859\n",
      "Episode:201 MeanR:17.5000 R:15.0 Loss:3.0012 ExploreP:0.6849\n",
      "Episode:202 MeanR:17.5000 R:11.0 Loss:30.7858 ExploreP:0.6842\n",
      "Episode:203 MeanR:17.5200 R:15.0 Loss:37.8467 ExploreP:0.6832\n",
      "Episode:204 MeanR:17.5400 R:12.0 Loss:72.8769 ExploreP:0.6824\n",
      "Episode:205 MeanR:17.4900 R:13.0 Loss:2.0600 ExploreP:0.6815\n",
      "Episode:206 MeanR:17.4300 R:13.0 Loss:86.3651 ExploreP:0.6806\n",
      "Episode:207 MeanR:17.3900 R:18.0 Loss:2.3106 ExploreP:0.6794\n",
      "Episode:208 MeanR:17.1300 R:9.0 Loss:40.0528 ExploreP:0.6788\n",
      "Episode:209 MeanR:17.1300 R:14.0 Loss:34.5162 ExploreP:0.6779\n",
      "Episode:210 MeanR:17.1500 R:13.0 Loss:1.9096 ExploreP:0.6770\n",
      "Episode:211 MeanR:17.1500 R:13.0 Loss:1.9005 ExploreP:0.6761\n",
      "Episode:212 MeanR:17.0200 R:11.0 Loss:39.5379 ExploreP:0.6754\n",
      "Episode:213 MeanR:17.0000 R:12.0 Loss:1.9297 ExploreP:0.6746\n",
      "Episode:214 MeanR:16.9400 R:11.0 Loss:52.2682 ExploreP:0.6739\n",
      "Episode:215 MeanR:16.9500 R:16.0 Loss:44.6159 ExploreP:0.6728\n",
      "Episode:216 MeanR:16.9300 R:13.0 Loss:42.5327 ExploreP:0.6720\n",
      "Episode:217 MeanR:16.6600 R:11.0 Loss:32.3880 ExploreP:0.6712\n",
      "Episode:218 MeanR:16.6200 R:18.0 Loss:94.9156 ExploreP:0.6700\n",
      "Episode:219 MeanR:16.6400 R:10.0 Loss:1.7665 ExploreP:0.6694\n",
      "Episode:220 MeanR:16.7200 R:21.0 Loss:1.6765 ExploreP:0.6680\n",
      "Episode:221 MeanR:16.7600 R:26.0 Loss:26.3388 ExploreP:0.6663\n",
      "Episode:222 MeanR:16.8100 R:15.0 Loss:100.8703 ExploreP:0.6653\n",
      "Episode:223 MeanR:16.8400 R:13.0 Loss:1.4303 ExploreP:0.6645\n",
      "Episode:224 MeanR:16.9600 R:27.0 Loss:68.1864 ExploreP:0.6627\n",
      "Episode:225 MeanR:17.0700 R:22.0 Loss:1.7825 ExploreP:0.6613\n",
      "Episode:226 MeanR:17.0700 R:15.0 Loss:34.1256 ExploreP:0.6603\n",
      "Episode:227 MeanR:16.9200 R:11.0 Loss:29.3296 ExploreP:0.6596\n",
      "Episode:228 MeanR:17.1300 R:31.0 Loss:28.6901 ExploreP:0.6576\n",
      "Episode:229 MeanR:17.1500 R:14.0 Loss:58.8463 ExploreP:0.6566\n",
      "Episode:230 MeanR:17.1400 R:12.0 Loss:27.7025 ExploreP:0.6559\n",
      "Episode:231 MeanR:17.0900 R:11.0 Loss:1.4663 ExploreP:0.6552\n",
      "Episode:232 MeanR:16.9600 R:10.0 Loss:31.9975 ExploreP:0.6545\n",
      "Episode:233 MeanR:17.2200 R:36.0 Loss:1.6658 ExploreP:0.6522\n",
      "Episode:234 MeanR:17.1400 R:11.0 Loss:1.5220 ExploreP:0.6515\n",
      "Episode:235 MeanR:17.2100 R:17.0 Loss:1.3093 ExploreP:0.6504\n",
      "Episode:236 MeanR:17.1700 R:16.0 Loss:1.1677 ExploreP:0.6494\n",
      "Episode:237 MeanR:17.1600 R:11.0 Loss:48.6953 ExploreP:0.6487\n",
      "Episode:238 MeanR:17.1500 R:10.0 Loss:51.0646 ExploreP:0.6480\n",
      "Episode:239 MeanR:17.3200 R:31.0 Loss:24.0052 ExploreP:0.6461\n",
      "Episode:240 MeanR:17.2100 R:10.0 Loss:30.6792 ExploreP:0.6454\n",
      "Episode:241 MeanR:17.1600 R:12.0 Loss:1.1584 ExploreP:0.6447\n",
      "Episode:242 MeanR:17.2600 R:25.0 Loss:24.8260 ExploreP:0.6431\n",
      "Episode:243 MeanR:17.2700 R:11.0 Loss:27.8388 ExploreP:0.6424\n",
      "Episode:244 MeanR:17.4700 R:34.0 Loss:0.9009 ExploreP:0.6402\n",
      "Episode:245 MeanR:17.5400 R:16.0 Loss:0.9387 ExploreP:0.6392\n",
      "Episode:246 MeanR:17.5600 R:22.0 Loss:0.8444 ExploreP:0.6379\n",
      "Episode:247 MeanR:17.5600 R:14.0 Loss:24.4008 ExploreP:0.6370\n",
      "Episode:248 MeanR:17.5900 R:17.0 Loss:27.0297 ExploreP:0.6359\n",
      "Episode:249 MeanR:17.6900 R:21.0 Loss:0.9503 ExploreP:0.6346\n",
      "Episode:250 MeanR:17.7500 R:18.0 Loss:47.8043 ExploreP:0.6335\n",
      "Episode:251 MeanR:18.0600 R:49.0 Loss:0.8898 ExploreP:0.6304\n",
      "Episode:252 MeanR:18.0400 R:12.0 Loss:45.0984 ExploreP:0.6297\n",
      "Episode:253 MeanR:17.9300 R:11.0 Loss:44.5505 ExploreP:0.6290\n",
      "Episode:254 MeanR:17.7400 R:10.0 Loss:0.9226 ExploreP:0.6284\n",
      "Episode:255 MeanR:17.7100 R:11.0 Loss:1.0383 ExploreP:0.6277\n",
      "Episode:256 MeanR:17.6500 R:15.0 Loss:0.6126 ExploreP:0.6268\n",
      "Episode:257 MeanR:17.5900 R:15.0 Loss:0.8860 ExploreP:0.6259\n",
      "Episode:258 MeanR:17.7200 R:26.0 Loss:0.9405 ExploreP:0.6243\n",
      "Episode:259 MeanR:17.5500 R:12.0 Loss:0.7815 ExploreP:0.6235\n",
      "Episode:260 MeanR:17.7500 R:34.0 Loss:44.0108 ExploreP:0.6214\n",
      "Episode:261 MeanR:17.7400 R:15.0 Loss:22.4114 ExploreP:0.6205\n",
      "Episode:262 MeanR:17.6200 R:10.0 Loss:46.8812 ExploreP:0.6199\n",
      "Episode:263 MeanR:17.5100 R:12.0 Loss:0.9565 ExploreP:0.6192\n",
      "Episode:264 MeanR:17.6100 R:21.0 Loss:81.6068 ExploreP:0.6179\n",
      "Episode:265 MeanR:17.6000 R:18.0 Loss:62.4883 ExploreP:0.6168\n",
      "Episode:266 MeanR:17.8500 R:46.0 Loss:20.5986 ExploreP:0.6140\n",
      "Episode:267 MeanR:17.8900 R:16.0 Loss:0.7067 ExploreP:0.6131\n",
      "Episode:268 MeanR:17.8800 R:13.0 Loss:60.1183 ExploreP:0.6123\n",
      "Episode:269 MeanR:17.9300 R:17.0 Loss:1.0471 ExploreP:0.6112\n",
      "Episode:270 MeanR:17.9300 R:14.0 Loss:41.8898 ExploreP:0.6104\n",
      "Episode:271 MeanR:17.9000 R:17.0 Loss:19.9805 ExploreP:0.6094\n",
      "Episode:272 MeanR:18.1200 R:36.0 Loss:19.1800 ExploreP:0.6072\n",
      "Episode:273 MeanR:18.3300 R:37.0 Loss:37.6497 ExploreP:0.6050\n",
      "Episode:274 MeanR:18.5600 R:33.0 Loss:19.3568 ExploreP:0.6031\n",
      "Episode:275 MeanR:18.5200 R:19.0 Loss:39.1280 ExploreP:0.6019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:276 MeanR:18.5500 R:28.0 Loss:0.6906 ExploreP:0.6003\n",
      "Episode:277 MeanR:18.5200 R:33.0 Loss:17.8088 ExploreP:0.5983\n",
      "Episode:278 MeanR:18.8500 R:52.0 Loss:18.7954 ExploreP:0.5953\n",
      "Episode:279 MeanR:18.8700 R:14.0 Loss:16.0681 ExploreP:0.5945\n",
      "Episode:280 MeanR:19.1400 R:50.0 Loss:49.7976 ExploreP:0.5916\n",
      "Episode:281 MeanR:19.2300 R:34.0 Loss:17.6562 ExploreP:0.5896\n",
      "Episode:282 MeanR:19.4500 R:51.0 Loss:32.9374 ExploreP:0.5866\n",
      "Episode:283 MeanR:19.5400 R:34.0 Loss:13.8839 ExploreP:0.5847\n",
      "Episode:284 MeanR:19.5700 R:14.0 Loss:54.1393 ExploreP:0.5839\n",
      "Episode:285 MeanR:19.5400 R:11.0 Loss:0.9259 ExploreP:0.5832\n",
      "Episode:286 MeanR:19.2200 R:14.0 Loss:33.5690 ExploreP:0.5824\n",
      "Episode:287 MeanR:19.2400 R:13.0 Loss:14.4738 ExploreP:0.5817\n",
      "Episode:288 MeanR:19.2400 R:21.0 Loss:50.1080 ExploreP:0.5805\n",
      "Episode:289 MeanR:19.8200 R:73.0 Loss:40.4426 ExploreP:0.5763\n",
      "Episode:290 MeanR:19.8000 R:14.0 Loss:28.6577 ExploreP:0.5756\n",
      "Episode:291 MeanR:19.7300 R:10.0 Loss:1.5068 ExploreP:0.5750\n",
      "Episode:292 MeanR:19.9100 R:32.0 Loss:14.6618 ExploreP:0.5732\n",
      "Episode:293 MeanR:19.8000 R:17.0 Loss:19.0733 ExploreP:0.5722\n",
      "Episode:294 MeanR:19.4900 R:16.0 Loss:25.1179 ExploreP:0.5713\n",
      "Episode:295 MeanR:19.4400 R:13.0 Loss:50.7558 ExploreP:0.5706\n",
      "Episode:296 MeanR:19.5000 R:17.0 Loss:14.9686 ExploreP:0.5696\n",
      "Episode:297 MeanR:19.4000 R:11.0 Loss:18.6755 ExploreP:0.5690\n",
      "Episode:298 MeanR:19.4400 R:17.0 Loss:27.2506 ExploreP:0.5681\n",
      "Episode:299 MeanR:19.6100 R:28.0 Loss:12.6063 ExploreP:0.5665\n",
      "Episode:300 MeanR:19.6100 R:17.0 Loss:34.8433 ExploreP:0.5656\n",
      "Episode:301 MeanR:19.8900 R:43.0 Loss:41.9569 ExploreP:0.5632\n",
      "Episode:302 MeanR:20.0000 R:22.0 Loss:18.2875 ExploreP:0.5620\n",
      "Episode:303 MeanR:20.0000 R:15.0 Loss:1.1873 ExploreP:0.5611\n",
      "Episode:304 MeanR:20.4700 R:59.0 Loss:0.7340 ExploreP:0.5579\n",
      "Episode:305 MeanR:20.5400 R:20.0 Loss:1.2230 ExploreP:0.5568\n",
      "Episode:306 MeanR:20.7300 R:32.0 Loss:31.9057 ExploreP:0.5551\n",
      "Episode:307 MeanR:20.6900 R:14.0 Loss:12.1486 ExploreP:0.5543\n",
      "Episode:308 MeanR:20.7300 R:13.0 Loss:17.6194 ExploreP:0.5536\n",
      "Episode:309 MeanR:20.8300 R:24.0 Loss:40.4082 ExploreP:0.5523\n",
      "Episode:310 MeanR:20.8600 R:16.0 Loss:35.9183 ExploreP:0.5514\n",
      "Episode:311 MeanR:20.9600 R:23.0 Loss:1.0001 ExploreP:0.5502\n",
      "Episode:312 MeanR:21.5800 R:73.0 Loss:1.0143 ExploreP:0.5463\n",
      "Episode:313 MeanR:21.6400 R:18.0 Loss:49.2088 ExploreP:0.5453\n",
      "Episode:314 MeanR:21.6700 R:14.0 Loss:13.0848 ExploreP:0.5445\n",
      "Episode:315 MeanR:21.7300 R:22.0 Loss:1.4746 ExploreP:0.5434\n",
      "Episode:316 MeanR:21.8000 R:20.0 Loss:1.0345 ExploreP:0.5423\n",
      "Episode:317 MeanR:21.8500 R:16.0 Loss:20.9879 ExploreP:0.5414\n",
      "Episode:318 MeanR:21.8300 R:16.0 Loss:13.3154 ExploreP:0.5406\n",
      "Episode:319 MeanR:21.9400 R:21.0 Loss:19.7894 ExploreP:0.5395\n",
      "Episode:320 MeanR:21.9500 R:22.0 Loss:1.1005 ExploreP:0.5383\n",
      "Episode:321 MeanR:22.0400 R:35.0 Loss:1.1434 ExploreP:0.5365\n",
      "Episode:322 MeanR:22.0300 R:14.0 Loss:37.0978 ExploreP:0.5357\n",
      "Episode:323 MeanR:22.0000 R:10.0 Loss:1.5658 ExploreP:0.5352\n",
      "Episode:324 MeanR:21.9300 R:20.0 Loss:16.4885 ExploreP:0.5342\n",
      "Episode:325 MeanR:21.8600 R:15.0 Loss:19.3035 ExploreP:0.5334\n",
      "Episode:326 MeanR:22.0300 R:32.0 Loss:33.5864 ExploreP:0.5317\n",
      "Episode:327 MeanR:22.2100 R:29.0 Loss:1.1471 ExploreP:0.5302\n",
      "Episode:328 MeanR:22.1000 R:20.0 Loss:15.5280 ExploreP:0.5292\n",
      "Episode:329 MeanR:22.3200 R:36.0 Loss:32.1591 ExploreP:0.5273\n",
      "Episode:330 MeanR:22.4100 R:21.0 Loss:1.1543 ExploreP:0.5262\n",
      "Episode:331 MeanR:22.4600 R:16.0 Loss:21.0637 ExploreP:0.5254\n",
      "Episode:332 MeanR:22.6700 R:31.0 Loss:21.6141 ExploreP:0.5238\n",
      "Episode:333 MeanR:22.5000 R:19.0 Loss:18.0962 ExploreP:0.5228\n",
      "Episode:334 MeanR:22.5700 R:18.0 Loss:1.3074 ExploreP:0.5219\n",
      "Episode:335 MeanR:22.5800 R:18.0 Loss:40.0722 ExploreP:0.5210\n",
      "Episode:336 MeanR:22.5600 R:14.0 Loss:14.5728 ExploreP:0.5203\n",
      "Episode:337 MeanR:22.5800 R:13.0 Loss:37.5270 ExploreP:0.5196\n",
      "Episode:338 MeanR:22.6700 R:19.0 Loss:1.4586 ExploreP:0.5186\n",
      "Episode:339 MeanR:22.5500 R:19.0 Loss:30.6001 ExploreP:0.5177\n",
      "Episode:340 MeanR:22.7500 R:30.0 Loss:1.5805 ExploreP:0.5161\n",
      "Episode:341 MeanR:22.7600 R:13.0 Loss:30.0927 ExploreP:0.5155\n",
      "Episode:342 MeanR:22.8200 R:31.0 Loss:17.2117 ExploreP:0.5139\n",
      "Episode:343 MeanR:22.8300 R:12.0 Loss:1.0513 ExploreP:0.5133\n",
      "Episode:344 MeanR:22.6400 R:15.0 Loss:1.5558 ExploreP:0.5126\n",
      "Episode:345 MeanR:22.6500 R:17.0 Loss:0.9962 ExploreP:0.5117\n",
      "Episode:346 MeanR:22.7400 R:31.0 Loss:0.9875 ExploreP:0.5101\n",
      "Episode:347 MeanR:22.7800 R:18.0 Loss:37.3690 ExploreP:0.5092\n",
      "Episode:348 MeanR:22.7300 R:12.0 Loss:19.0191 ExploreP:0.5087\n",
      "Episode:349 MeanR:22.7800 R:26.0 Loss:35.3938 ExploreP:0.5074\n",
      "Episode:350 MeanR:22.8600 R:26.0 Loss:31.1339 ExploreP:0.5061\n",
      "Episode:351 MeanR:22.5200 R:15.0 Loss:38.3817 ExploreP:0.5053\n",
      "Episode:352 MeanR:22.8900 R:49.0 Loss:47.6504 ExploreP:0.5029\n",
      "Episode:353 MeanR:23.7200 R:94.0 Loss:59.6377 ExploreP:0.4983\n",
      "Episode:354 MeanR:24.0100 R:39.0 Loss:1.3479 ExploreP:0.4964\n",
      "Episode:355 MeanR:24.1600 R:26.0 Loss:1.3888 ExploreP:0.4951\n",
      "Episode:356 MeanR:24.2200 R:21.0 Loss:33.7174 ExploreP:0.4941\n",
      "Episode:357 MeanR:24.2300 R:16.0 Loss:17.7202 ExploreP:0.4933\n",
      "Episode:358 MeanR:24.1400 R:17.0 Loss:23.5595 ExploreP:0.4925\n",
      "Episode:359 MeanR:24.2400 R:22.0 Loss:13.3954 ExploreP:0.4915\n",
      "Episode:360 MeanR:24.2100 R:31.0 Loss:1.2715 ExploreP:0.4900\n",
      "Episode:361 MeanR:24.3100 R:25.0 Loss:1.3195 ExploreP:0.4888\n",
      "Episode:362 MeanR:24.4300 R:22.0 Loss:1.1696 ExploreP:0.4877\n",
      "Episode:363 MeanR:24.6000 R:29.0 Loss:22.3020 ExploreP:0.4863\n",
      "Episode:364 MeanR:24.5900 R:20.0 Loss:1.0299 ExploreP:0.4854\n",
      "Episode:365 MeanR:25.2600 R:85.0 Loss:77.2975 ExploreP:0.4814\n",
      "Episode:366 MeanR:24.9600 R:16.0 Loss:1.1683 ExploreP:0.4806\n",
      "Episode:367 MeanR:24.9700 R:17.0 Loss:22.8331 ExploreP:0.4798\n",
      "Episode:368 MeanR:25.3100 R:47.0 Loss:22.2649 ExploreP:0.4776\n",
      "Episode:369 MeanR:25.4600 R:32.0 Loss:1.1789 ExploreP:0.4761\n",
      "Episode:370 MeanR:25.5100 R:19.0 Loss:23.5160 ExploreP:0.4752\n",
      "Episode:371 MeanR:25.5200 R:18.0 Loss:1.6015 ExploreP:0.4744\n",
      "Episode:372 MeanR:25.4000 R:24.0 Loss:1.2030 ExploreP:0.4733\n",
      "Episode:373 MeanR:25.1500 R:12.0 Loss:1.7480 ExploreP:0.4727\n",
      "Episode:374 MeanR:24.9400 R:12.0 Loss:1.1017 ExploreP:0.4722\n",
      "Episode:375 MeanR:24.9100 R:16.0 Loss:1.1978 ExploreP:0.4714\n",
      "Episode:376 MeanR:25.3900 R:76.0 Loss:1.1847 ExploreP:0.4679\n",
      "Episode:377 MeanR:25.2800 R:22.0 Loss:58.1790 ExploreP:0.4669\n",
      "Episode:378 MeanR:24.9000 R:14.0 Loss:1.6808 ExploreP:0.4663\n",
      "Episode:379 MeanR:24.8800 R:12.0 Loss:1.3063 ExploreP:0.4657\n",
      "Episode:380 MeanR:24.5700 R:19.0 Loss:22.1531 ExploreP:0.4649\n",
      "Episode:381 MeanR:24.4800 R:25.0 Loss:14.8034 ExploreP:0.4637\n",
      "Episode:382 MeanR:24.1800 R:21.0 Loss:17.3851 ExploreP:0.4628\n",
      "Episode:383 MeanR:24.0900 R:25.0 Loss:1.2334 ExploreP:0.4616\n",
      "Episode:384 MeanR:24.3200 R:37.0 Loss:0.6183 ExploreP:0.4600\n",
      "Episode:385 MeanR:24.4200 R:21.0 Loss:27.9488 ExploreP:0.4590\n",
      "Episode:386 MeanR:24.5000 R:22.0 Loss:1.5933 ExploreP:0.4581\n",
      "Episode:387 MeanR:24.7000 R:33.0 Loss:29.1276 ExploreP:0.4566\n",
      "Episode:388 MeanR:24.6300 R:14.0 Loss:24.2343 ExploreP:0.4559\n",
      "Episode:389 MeanR:24.2400 R:34.0 Loss:66.7698 ExploreP:0.4544\n",
      "Episode:390 MeanR:24.2900 R:19.0 Loss:20.7285 ExploreP:0.4536\n",
      "Episode:391 MeanR:24.3700 R:18.0 Loss:1.0063 ExploreP:0.4528\n",
      "Episode:392 MeanR:24.2700 R:22.0 Loss:48.8655 ExploreP:0.4518\n",
      "Episode:393 MeanR:24.4000 R:30.0 Loss:16.7667 ExploreP:0.4505\n",
      "Episode:394 MeanR:24.8100 R:57.0 Loss:45.0167 ExploreP:0.4480\n",
      "Episode:395 MeanR:25.5500 R:87.0 Loss:23.5252 ExploreP:0.4442\n",
      "Episode:396 MeanR:26.1600 R:78.0 Loss:23.8407 ExploreP:0.4408\n",
      "Episode:397 MeanR:26.3600 R:31.0 Loss:1.4660 ExploreP:0.4395\n",
      "Episode:398 MeanR:26.3500 R:16.0 Loss:1.5065 ExploreP:0.4388\n",
      "Episode:399 MeanR:26.2900 R:22.0 Loss:1.5285 ExploreP:0.4379\n",
      "Episode:400 MeanR:26.4400 R:32.0 Loss:21.8674 ExploreP:0.4365\n",
      "Episode:401 MeanR:26.6500 R:64.0 Loss:19.8895 ExploreP:0.4338\n",
      "Episode:402 MeanR:26.7000 R:27.0 Loss:0.7766 ExploreP:0.4326\n",
      "Episode:403 MeanR:27.2600 R:71.0 Loss:1.7445 ExploreP:0.4296\n",
      "Episode:404 MeanR:27.0400 R:37.0 Loss:1.2479 ExploreP:0.4281\n",
      "Episode:405 MeanR:26.9800 R:14.0 Loss:1.2142 ExploreP:0.4275\n",
      "Episode:406 MeanR:26.9100 R:25.0 Loss:1.1194 ExploreP:0.4265\n",
      "Episode:407 MeanR:26.8900 R:12.0 Loss:19.7978 ExploreP:0.4260\n",
      "Episode:408 MeanR:26.9800 R:22.0 Loss:1.1324 ExploreP:0.4251\n",
      "Episode:409 MeanR:27.4300 R:69.0 Loss:35.2360 ExploreP:0.4222\n",
      "Episode:410 MeanR:27.4200 R:15.0 Loss:1.8579 ExploreP:0.4216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:411 MeanR:27.5000 R:31.0 Loss:18.7211 ExploreP:0.4203\n",
      "Episode:412 MeanR:27.1700 R:40.0 Loss:1.2300 ExploreP:0.4187\n",
      "Episode:413 MeanR:27.2300 R:24.0 Loss:1.6036 ExploreP:0.4177\n",
      "Episode:414 MeanR:27.2400 R:15.0 Loss:21.4667 ExploreP:0.4171\n",
      "Episode:415 MeanR:27.2000 R:18.0 Loss:20.7246 ExploreP:0.4163\n",
      "Episode:416 MeanR:27.3500 R:35.0 Loss:1.5559 ExploreP:0.4149\n",
      "Episode:417 MeanR:27.4900 R:30.0 Loss:40.1087 ExploreP:0.4137\n",
      "Episode:418 MeanR:27.6800 R:35.0 Loss:25.6769 ExploreP:0.4123\n",
      "Episode:419 MeanR:28.2700 R:80.0 Loss:1.1665 ExploreP:0.4091\n",
      "Episode:420 MeanR:28.2800 R:23.0 Loss:19.8593 ExploreP:0.4082\n",
      "Episode:421 MeanR:28.7400 R:81.0 Loss:16.0471 ExploreP:0.4050\n",
      "Episode:422 MeanR:28.8900 R:29.0 Loss:49.2613 ExploreP:0.4038\n",
      "Episode:423 MeanR:29.0400 R:25.0 Loss:1.1913 ExploreP:0.4028\n",
      "Episode:424 MeanR:29.4900 R:65.0 Loss:52.4274 ExploreP:0.4003\n",
      "Episode:425 MeanR:29.7000 R:36.0 Loss:20.3484 ExploreP:0.3989\n",
      "Episode:426 MeanR:29.7800 R:40.0 Loss:1.2676 ExploreP:0.3973\n",
      "Episode:427 MeanR:29.7800 R:29.0 Loss:32.7913 ExploreP:0.3962\n",
      "Episode:428 MeanR:29.9800 R:40.0 Loss:1.3112 ExploreP:0.3947\n",
      "Episode:429 MeanR:30.3100 R:69.0 Loss:1.5952 ExploreP:0.3920\n",
      "Episode:430 MeanR:30.7800 R:68.0 Loss:0.9198 ExploreP:0.3894\n",
      "Episode:431 MeanR:31.0100 R:39.0 Loss:38.4120 ExploreP:0.3880\n",
      "Episode:432 MeanR:31.0700 R:37.0 Loss:27.5002 ExploreP:0.3866\n",
      "Episode:433 MeanR:31.3400 R:46.0 Loss:42.9660 ExploreP:0.3848\n",
      "Episode:434 MeanR:31.4500 R:29.0 Loss:23.6565 ExploreP:0.3838\n",
      "Episode:435 MeanR:31.9900 R:72.0 Loss:49.1607 ExploreP:0.3811\n",
      "Episode:436 MeanR:32.2400 R:39.0 Loss:81.4286 ExploreP:0.3796\n",
      "Episode:437 MeanR:32.7700 R:66.0 Loss:49.5870 ExploreP:0.3772\n",
      "Episode:438 MeanR:33.7300 R:115.0 Loss:28.0441 ExploreP:0.3730\n",
      "Episode:439 MeanR:33.7900 R:25.0 Loss:1.2302 ExploreP:0.3721\n",
      "Episode:440 MeanR:33.7500 R:26.0 Loss:23.3904 ExploreP:0.3712\n",
      "Episode:441 MeanR:33.9800 R:36.0 Loss:21.8740 ExploreP:0.3699\n",
      "Episode:442 MeanR:34.3000 R:63.0 Loss:26.4364 ExploreP:0.3676\n",
      "Episode:443 MeanR:34.8800 R:70.0 Loss:46.1688 ExploreP:0.3651\n",
      "Episode:444 MeanR:35.1500 R:42.0 Loss:1.1019 ExploreP:0.3636\n",
      "Episode:445 MeanR:35.3600 R:38.0 Loss:48.3657 ExploreP:0.3623\n",
      "Episode:446 MeanR:35.3800 R:33.0 Loss:1.5358 ExploreP:0.3611\n",
      "Episode:447 MeanR:36.1000 R:90.0 Loss:27.4386 ExploreP:0.3580\n",
      "Episode:448 MeanR:36.5400 R:56.0 Loss:1.5966 ExploreP:0.3560\n",
      "Episode:449 MeanR:36.6400 R:36.0 Loss:47.8513 ExploreP:0.3548\n",
      "Episode:450 MeanR:36.7000 R:32.0 Loss:1.7019 ExploreP:0.3537\n",
      "Episode:451 MeanR:37.2900 R:74.0 Loss:34.2109 ExploreP:0.3511\n",
      "Episode:452 MeanR:38.2500 R:145.0 Loss:1.5169 ExploreP:0.3462\n",
      "Episode:453 MeanR:37.7300 R:42.0 Loss:1.1746 ExploreP:0.3448\n",
      "Episode:454 MeanR:37.7200 R:38.0 Loss:54.4705 ExploreP:0.3436\n",
      "Episode:455 MeanR:38.2900 R:83.0 Loss:0.9006 ExploreP:0.3408\n",
      "Episode:456 MeanR:38.5100 R:43.0 Loss:19.2122 ExploreP:0.3394\n",
      "Episode:457 MeanR:38.6800 R:33.0 Loss:17.6137 ExploreP:0.3383\n",
      "Episode:458 MeanR:38.9600 R:45.0 Loss:53.3654 ExploreP:0.3368\n",
      "Episode:459 MeanR:39.3500 R:61.0 Loss:26.4866 ExploreP:0.3348\n",
      "Episode:460 MeanR:39.4600 R:42.0 Loss:31.7503 ExploreP:0.3335\n",
      "Episode:461 MeanR:39.5500 R:34.0 Loss:43.1367 ExploreP:0.3324\n",
      "Episode:462 MeanR:39.9000 R:57.0 Loss:24.9448 ExploreP:0.3305\n",
      "Episode:463 MeanR:40.3500 R:74.0 Loss:27.1848 ExploreP:0.3282\n",
      "Episode:464 MeanR:40.7300 R:58.0 Loss:1.7227 ExploreP:0.3263\n",
      "Episode:465 MeanR:40.5200 R:64.0 Loss:1.7840 ExploreP:0.3243\n",
      "Episode:466 MeanR:41.0900 R:73.0 Loss:1.5731 ExploreP:0.3220\n",
      "Episode:467 MeanR:41.5600 R:64.0 Loss:78.7199 ExploreP:0.3200\n",
      "Episode:468 MeanR:41.6300 R:54.0 Loss:30.5010 ExploreP:0.3184\n",
      "Episode:469 MeanR:42.0700 R:76.0 Loss:1.6057 ExploreP:0.3160\n",
      "Episode:470 MeanR:42.7600 R:88.0 Loss:1.3784 ExploreP:0.3134\n",
      "Episode:471 MeanR:43.1700 R:59.0 Loss:32.3676 ExploreP:0.3116\n",
      "Episode:472 MeanR:43.3700 R:44.0 Loss:0.8204 ExploreP:0.3102\n",
      "Episode:473 MeanR:43.9600 R:71.0 Loss:1.1106 ExploreP:0.3081\n",
      "Episode:474 MeanR:44.3000 R:46.0 Loss:28.8502 ExploreP:0.3068\n",
      "Episode:475 MeanR:44.5400 R:40.0 Loss:37.2043 ExploreP:0.3056\n",
      "Episode:476 MeanR:44.4400 R:66.0 Loss:76.3201 ExploreP:0.3036\n",
      "Episode:477 MeanR:45.4000 R:118.0 Loss:43.5976 ExploreP:0.3002\n",
      "Episode:478 MeanR:45.6300 R:37.0 Loss:101.9141 ExploreP:0.2991\n",
      "Episode:479 MeanR:46.1100 R:60.0 Loss:22.9070 ExploreP:0.2974\n",
      "Episode:480 MeanR:46.9800 R:106.0 Loss:1.4242 ExploreP:0.2943\n",
      "Episode:481 MeanR:47.6800 R:95.0 Loss:1.9311 ExploreP:0.2917\n",
      "Episode:482 MeanR:48.8100 R:134.0 Loss:1.9033 ExploreP:0.2879\n",
      "Episode:483 MeanR:49.4500 R:89.0 Loss:65.5748 ExploreP:0.2854\n",
      "Episode:484 MeanR:49.4700 R:39.0 Loss:0.8011 ExploreP:0.2844\n",
      "Episode:485 MeanR:50.7200 R:146.0 Loss:0.9577 ExploreP:0.2804\n",
      "Episode:486 MeanR:51.4900 R:99.0 Loss:38.1573 ExploreP:0.2777\n",
      "Episode:487 MeanR:52.1000 R:94.0 Loss:37.0395 ExploreP:0.2752\n",
      "Episode:488 MeanR:52.4400 R:48.0 Loss:1.0457 ExploreP:0.2740\n",
      "Episode:489 MeanR:53.3000 R:120.0 Loss:1.1042 ExploreP:0.2708\n",
      "Episode:490 MeanR:53.7700 R:66.0 Loss:35.4393 ExploreP:0.2691\n",
      "Episode:491 MeanR:54.1500 R:56.0 Loss:39.7185 ExploreP:0.2677\n",
      "Episode:492 MeanR:54.2700 R:34.0 Loss:58.5126 ExploreP:0.2668\n",
      "Episode:493 MeanR:54.4100 R:44.0 Loss:1.3783 ExploreP:0.2656\n",
      "Episode:494 MeanR:55.2100 R:137.0 Loss:38.2035 ExploreP:0.2622\n",
      "Episode:495 MeanR:55.4800 R:114.0 Loss:1.5913 ExploreP:0.2593\n",
      "Episode:496 MeanR:55.3800 R:68.0 Loss:2.1316 ExploreP:0.2576\n",
      "Episode:497 MeanR:55.6500 R:58.0 Loss:1.2365 ExploreP:0.2562\n",
      "Episode:498 MeanR:56.5100 R:102.0 Loss:0.9779 ExploreP:0.2537\n",
      "Episode:499 MeanR:56.8300 R:54.0 Loss:41.2612 ExploreP:0.2524\n",
      "Episode:500 MeanR:57.5900 R:108.0 Loss:1.0520 ExploreP:0.2498\n",
      "Episode:501 MeanR:57.9100 R:96.0 Loss:26.3488 ExploreP:0.2475\n",
      "Episode:502 MeanR:58.3100 R:67.0 Loss:26.7071 ExploreP:0.2459\n",
      "Episode:503 MeanR:58.0400 R:44.0 Loss:40.1134 ExploreP:0.2449\n",
      "Episode:504 MeanR:58.2700 R:60.0 Loss:1.1888 ExploreP:0.2435\n",
      "Episode:505 MeanR:58.4900 R:36.0 Loss:34.4831 ExploreP:0.2426\n",
      "Episode:506 MeanR:59.2800 R:104.0 Loss:33.8221 ExploreP:0.2402\n",
      "Episode:507 MeanR:59.8300 R:67.0 Loss:2.2852 ExploreP:0.2387\n",
      "Episode:508 MeanR:60.2000 R:59.0 Loss:28.5000 ExploreP:0.2373\n",
      "Episode:509 MeanR:60.1200 R:61.0 Loss:37.7271 ExploreP:0.2359\n",
      "Episode:510 MeanR:60.4400 R:47.0 Loss:24.3927 ExploreP:0.2349\n",
      "Episode:511 MeanR:60.5800 R:45.0 Loss:0.8812 ExploreP:0.2339\n",
      "Episode:512 MeanR:60.9900 R:81.0 Loss:0.8511 ExploreP:0.2321\n",
      "Episode:513 MeanR:61.1000 R:35.0 Loss:0.2942 ExploreP:0.2313\n",
      "Episode:514 MeanR:61.4600 R:51.0 Loss:1.0127 ExploreP:0.2302\n",
      "Episode:515 MeanR:61.6900 R:41.0 Loss:2.1063 ExploreP:0.2293\n",
      "Episode:516 MeanR:61.6900 R:35.0 Loss:33.7520 ExploreP:0.2285\n",
      "Episode:517 MeanR:61.7100 R:32.0 Loss:1.1585 ExploreP:0.2278\n",
      "Episode:518 MeanR:62.3200 R:96.0 Loss:0.7069 ExploreP:0.2257\n",
      "Episode:519 MeanR:62.5100 R:99.0 Loss:0.9889 ExploreP:0.2236\n",
      "Episode:520 MeanR:62.7600 R:48.0 Loss:32.6900 ExploreP:0.2226\n",
      "Episode:521 MeanR:62.8100 R:86.0 Loss:1.5035 ExploreP:0.2208\n",
      "Episode:522 MeanR:62.7300 R:21.0 Loss:1.3625 ExploreP:0.2203\n",
      "Episode:523 MeanR:62.7400 R:26.0 Loss:1.9084 ExploreP:0.2198\n",
      "Episode:524 MeanR:62.2500 R:16.0 Loss:79.1252 ExploreP:0.2194\n",
      "Episode:525 MeanR:62.2100 R:32.0 Loss:1.0015 ExploreP:0.2188\n",
      "Episode:526 MeanR:61.9700 R:16.0 Loss:1.3647 ExploreP:0.2184\n",
      "Episode:527 MeanR:62.1900 R:51.0 Loss:1.1556 ExploreP:0.2174\n",
      "Episode:528 MeanR:62.1500 R:36.0 Loss:28.9503 ExploreP:0.2166\n",
      "Episode:529 MeanR:61.7700 R:31.0 Loss:1.5832 ExploreP:0.2160\n",
      "Episode:530 MeanR:61.3800 R:29.0 Loss:1.5078 ExploreP:0.2154\n",
      "Episode:531 MeanR:61.2300 R:24.0 Loss:160.2020 ExploreP:0.2149\n",
      "Episode:532 MeanR:61.0500 R:19.0 Loss:1.6826 ExploreP:0.2145\n",
      "Episode:533 MeanR:60.8000 R:21.0 Loss:49.2380 ExploreP:0.2141\n",
      "Episode:534 MeanR:60.7000 R:19.0 Loss:1.7084 ExploreP:0.2137\n",
      "Episode:535 MeanR:60.1700 R:19.0 Loss:183.2734 ExploreP:0.2133\n",
      "Episode:536 MeanR:60.0100 R:23.0 Loss:1.9066 ExploreP:0.2128\n",
      "Episode:537 MeanR:59.5300 R:18.0 Loss:1.8220 ExploreP:0.2125\n",
      "Episode:538 MeanR:58.7100 R:33.0 Loss:82.0453 ExploreP:0.2118\n",
      "Episode:539 MeanR:58.7300 R:27.0 Loss:1.3627 ExploreP:0.2113\n",
      "Episode:540 MeanR:58.7400 R:27.0 Loss:1.3938 ExploreP:0.2107\n",
      "Episode:541 MeanR:58.8700 R:49.0 Loss:1.4136 ExploreP:0.2097\n",
      "Episode:542 MeanR:58.4600 R:22.0 Loss:46.0378 ExploreP:0.2093\n",
      "Episode:543 MeanR:57.9500 R:19.0 Loss:30.6998 ExploreP:0.2089\n",
      "Episode:544 MeanR:57.8100 R:28.0 Loss:1.7444 ExploreP:0.2084\n",
      "Episode:545 MeanR:57.7100 R:28.0 Loss:1.2655 ExploreP:0.2078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:546 MeanR:57.6600 R:28.0 Loss:37.3399 ExploreP:0.2073\n",
      "Episode:547 MeanR:57.0300 R:27.0 Loss:1.3272 ExploreP:0.2067\n",
      "Episode:548 MeanR:56.7300 R:26.0 Loss:1.7869 ExploreP:0.2062\n",
      "Episode:549 MeanR:57.2900 R:92.0 Loss:1.3746 ExploreP:0.2044\n",
      "Episode:550 MeanR:57.3000 R:33.0 Loss:29.5448 ExploreP:0.2038\n",
      "Episode:551 MeanR:56.9600 R:40.0 Loss:1.2241 ExploreP:0.2030\n",
      "Episode:552 MeanR:55.8100 R:30.0 Loss:1.6069 ExploreP:0.2024\n",
      "Episode:553 MeanR:55.7200 R:33.0 Loss:29.8192 ExploreP:0.2018\n",
      "Episode:554 MeanR:55.6700 R:33.0 Loss:1.0257 ExploreP:0.2012\n",
      "Episode:555 MeanR:55.2000 R:36.0 Loss:1.7925 ExploreP:0.2005\n",
      "Episode:556 MeanR:55.0000 R:23.0 Loss:47.1555 ExploreP:0.2000\n",
      "Episode:557 MeanR:55.0000 R:33.0 Loss:1.0977 ExploreP:0.1994\n",
      "Episode:558 MeanR:54.8000 R:25.0 Loss:104.4055 ExploreP:0.1989\n",
      "Episode:559 MeanR:54.4900 R:30.0 Loss:1.2450 ExploreP:0.1984\n",
      "Episode:560 MeanR:54.2300 R:16.0 Loss:1.8093 ExploreP:0.1981\n",
      "Episode:561 MeanR:54.1500 R:26.0 Loss:1.7163 ExploreP:0.1976\n",
      "Episode:562 MeanR:53.8300 R:25.0 Loss:83.7624 ExploreP:0.1971\n",
      "Episode:563 MeanR:53.5300 R:44.0 Loss:156.0144 ExploreP:0.1963\n",
      "Episode:564 MeanR:53.3600 R:41.0 Loss:1.7575 ExploreP:0.1955\n",
      "Episode:565 MeanR:52.9800 R:26.0 Loss:133.7564 ExploreP:0.1950\n",
      "Episode:566 MeanR:52.5300 R:28.0 Loss:2.1682 ExploreP:0.1945\n",
      "Episode:567 MeanR:52.1100 R:22.0 Loss:1.7771 ExploreP:0.1941\n",
      "Episode:568 MeanR:51.9500 R:38.0 Loss:1.5146 ExploreP:0.1934\n",
      "Episode:569 MeanR:51.4400 R:25.0 Loss:1.6433 ExploreP:0.1930\n",
      "Episode:570 MeanR:50.8600 R:30.0 Loss:31.5309 ExploreP:0.1924\n",
      "Episode:571 MeanR:50.5600 R:29.0 Loss:31.1145 ExploreP:0.1919\n",
      "Episode:572 MeanR:50.5500 R:43.0 Loss:1.5741 ExploreP:0.1911\n",
      "Episode:573 MeanR:50.1900 R:35.0 Loss:1.3105 ExploreP:0.1905\n",
      "Episode:574 MeanR:50.1000 R:37.0 Loss:1.1540 ExploreP:0.1898\n",
      "Episode:575 MeanR:50.0100 R:31.0 Loss:160.2585 ExploreP:0.1893\n",
      "Episode:576 MeanR:49.6100 R:26.0 Loss:2.0897 ExploreP:0.1888\n",
      "Episode:577 MeanR:48.7100 R:28.0 Loss:1.1690 ExploreP:0.1883\n",
      "Episode:578 MeanR:48.5800 R:24.0 Loss:182.3073 ExploreP:0.1879\n",
      "Episode:579 MeanR:48.1900 R:21.0 Loss:1.6755 ExploreP:0.1875\n",
      "Episode:580 MeanR:47.5100 R:38.0 Loss:1.1375 ExploreP:0.1868\n",
      "Episode:581 MeanR:46.9800 R:42.0 Loss:2.3897 ExploreP:0.1861\n",
      "Episode:582 MeanR:45.9100 R:27.0 Loss:191.3301 ExploreP:0.1856\n",
      "Episode:583 MeanR:45.4000 R:38.0 Loss:39.7285 ExploreP:0.1849\n",
      "Episode:584 MeanR:45.5900 R:58.0 Loss:1.9066 ExploreP:0.1839\n",
      "Episode:585 MeanR:45.1800 R:105.0 Loss:1.9133 ExploreP:0.1821\n",
      "Episode:586 MeanR:44.5900 R:40.0 Loss:1.5826 ExploreP:0.1814\n",
      "Episode:587 MeanR:44.0600 R:41.0 Loss:1.5064 ExploreP:0.1807\n",
      "Episode:588 MeanR:44.5100 R:93.0 Loss:144.1380 ExploreP:0.1791\n",
      "Episode:589 MeanR:44.1000 R:79.0 Loss:1.0755 ExploreP:0.1778\n",
      "Episode:590 MeanR:43.9600 R:52.0 Loss:111.5309 ExploreP:0.1769\n",
      "Episode:591 MeanR:43.9300 R:53.0 Loss:1.0876 ExploreP:0.1761\n",
      "Episode:592 MeanR:44.4300 R:84.0 Loss:1.4636 ExploreP:0.1747\n",
      "Episode:593 MeanR:44.4200 R:43.0 Loss:40.2727 ExploreP:0.1740\n",
      "Episode:594 MeanR:43.5500 R:50.0 Loss:1.1407 ExploreP:0.1731\n",
      "Episode:595 MeanR:42.7800 R:37.0 Loss:1.4339 ExploreP:0.1725\n",
      "Episode:596 MeanR:42.5400 R:44.0 Loss:1.8712 ExploreP:0.1718\n",
      "Episode:597 MeanR:42.6800 R:72.0 Loss:1.0582 ExploreP:0.1707\n",
      "Episode:598 MeanR:43.0200 R:136.0 Loss:91.4247 ExploreP:0.1685\n",
      "Episode:599 MeanR:43.3300 R:85.0 Loss:1.0299 ExploreP:0.1672\n",
      "Episode:600 MeanR:43.8000 R:155.0 Loss:0.9515 ExploreP:0.1647\n",
      "Episode:601 MeanR:43.9100 R:107.0 Loss:1.1026 ExploreP:0.1631\n",
      "Episode:602 MeanR:44.1400 R:90.0 Loss:95.0905 ExploreP:0.1617\n",
      "Episode:603 MeanR:44.0400 R:34.0 Loss:1.2991 ExploreP:0.1612\n",
      "Episode:604 MeanR:44.3000 R:86.0 Loss:1.0246 ExploreP:0.1599\n",
      "Episode:605 MeanR:44.9200 R:98.0 Loss:201.8146 ExploreP:0.1584\n",
      "Episode:606 MeanR:44.6200 R:74.0 Loss:0.9647 ExploreP:0.1573\n",
      "Episode:607 MeanR:45.1800 R:123.0 Loss:1.2248 ExploreP:0.1555\n",
      "Episode:608 MeanR:45.3300 R:74.0 Loss:84.8497 ExploreP:0.1545\n",
      "Episode:609 MeanR:45.8400 R:112.0 Loss:1.3414 ExploreP:0.1529\n",
      "Episode:610 MeanR:46.4100 R:104.0 Loss:1.2732 ExploreP:0.1514\n",
      "Episode:611 MeanR:47.0700 R:111.0 Loss:1.2936 ExploreP:0.1498\n",
      "Episode:612 MeanR:47.0900 R:83.0 Loss:89.1319 ExploreP:0.1487\n",
      "Episode:613 MeanR:47.5600 R:82.0 Loss:1.0763 ExploreP:0.1475\n",
      "Episode:614 MeanR:49.7700 R:272.0 Loss:1.4121 ExploreP:0.1438\n",
      "Episode:615 MeanR:50.2200 R:86.0 Loss:0.7858 ExploreP:0.1427\n",
      "Episode:616 MeanR:50.6300 R:76.0 Loss:93.8806 ExploreP:0.1417\n",
      "Episode:617 MeanR:51.2200 R:91.0 Loss:1.1280 ExploreP:0.1405\n",
      "Episode:618 MeanR:50.6500 R:39.0 Loss:1.5943 ExploreP:0.1400\n",
      "Episode:619 MeanR:50.3500 R:69.0 Loss:1.1594 ExploreP:0.1391\n",
      "Episode:620 MeanR:50.3500 R:48.0 Loss:176.4491 ExploreP:0.1385\n",
      "Episode:621 MeanR:50.4500 R:96.0 Loss:95.7559 ExploreP:0.1373\n",
      "Episode:622 MeanR:50.8400 R:60.0 Loss:1.0948 ExploreP:0.1365\n",
      "Episode:623 MeanR:51.8900 R:131.0 Loss:0.9275 ExploreP:0.1348\n",
      "Episode:624 MeanR:52.5200 R:79.0 Loss:71.5583 ExploreP:0.1339\n",
      "Episode:625 MeanR:52.8100 R:61.0 Loss:1.0736 ExploreP:0.1331\n",
      "Episode:626 MeanR:54.0300 R:138.0 Loss:0.7393 ExploreP:0.1314\n",
      "Episode:627 MeanR:54.2900 R:77.0 Loss:1.1040 ExploreP:0.1305\n",
      "Episode:628 MeanR:54.9400 R:101.0 Loss:1.0750 ExploreP:0.1293\n",
      "Episode:629 MeanR:55.6100 R:98.0 Loss:0.6100 ExploreP:0.1281\n",
      "Episode:630 MeanR:56.0700 R:75.0 Loss:0.8824 ExploreP:0.1272\n",
      "Episode:631 MeanR:56.5800 R:75.0 Loss:1.0625 ExploreP:0.1264\n",
      "Episode:632 MeanR:57.3800 R:99.0 Loss:1.3377 ExploreP:0.1252\n",
      "Episode:633 MeanR:58.0300 R:86.0 Loss:0.8766 ExploreP:0.1242\n",
      "Episode:634 MeanR:58.6800 R:84.0 Loss:50.1680 ExploreP:0.1233\n",
      "Episode:635 MeanR:59.3400 R:85.0 Loss:1.3737 ExploreP:0.1223\n",
      "Episode:636 MeanR:61.5100 R:240.0 Loss:1.1689 ExploreP:0.1197\n",
      "Episode:637 MeanR:62.4500 R:112.0 Loss:119.0902 ExploreP:0.1184\n",
      "Episode:638 MeanR:63.4600 R:134.0 Loss:0.5449 ExploreP:0.1170\n",
      "Episode:639 MeanR:64.1100 R:92.0 Loss:0.6753 ExploreP:0.1160\n",
      "Episode:640 MeanR:67.4500 R:361.0 Loss:53.7265 ExploreP:0.1122\n",
      "Episode:641 MeanR:67.6600 R:70.0 Loss:1.0740 ExploreP:0.1115\n",
      "Episode:642 MeanR:68.5500 R:111.0 Loss:0.4621 ExploreP:0.1104\n",
      "Episode:643 MeanR:69.3600 R:100.0 Loss:0.7349 ExploreP:0.1094\n",
      "Episode:644 MeanR:72.6000 R:352.0 Loss:0.6883 ExploreP:0.1060\n",
      "Episode:645 MeanR:73.2900 R:97.0 Loss:0.5096 ExploreP:0.1051\n",
      "Episode:646 MeanR:74.5100 R:150.0 Loss:0.7111 ExploreP:0.1036\n",
      "Episode:647 MeanR:75.3500 R:111.0 Loss:0.4824 ExploreP:0.1026\n",
      "Episode:648 MeanR:77.3300 R:224.0 Loss:66.2792 ExploreP:0.1006\n",
      "Episode:649 MeanR:78.7000 R:229.0 Loss:49.3212 ExploreP:0.0985\n",
      "Episode:650 MeanR:79.3500 R:98.0 Loss:84.2119 ExploreP:0.0976\n",
      "Episode:651 MeanR:79.6000 R:65.0 Loss:36.2482 ExploreP:0.0971\n",
      "Episode:652 MeanR:82.4800 R:318.0 Loss:1.0319 ExploreP:0.0943\n",
      "Episode:653 MeanR:87.0700 R:492.0 Loss:203.5578 ExploreP:0.0903\n",
      "Episode:654 MeanR:89.3300 R:259.0 Loss:0.6745 ExploreP:0.0882\n",
      "Episode:655 MeanR:90.1800 R:121.0 Loss:0.7096 ExploreP:0.0873\n",
      "Episode:656 MeanR:91.1200 R:117.0 Loss:0.7425 ExploreP:0.0864\n",
      "Episode:657 MeanR:91.8900 R:110.0 Loss:0.6134 ExploreP:0.0856\n",
      "Episode:658 MeanR:93.1000 R:146.0 Loss:0.9674 ExploreP:0.0845\n",
      "Episode:659 MeanR:94.2400 R:144.0 Loss:0.5721 ExploreP:0.0834\n",
      "Episode:660 MeanR:95.5300 R:145.0 Loss:0.8226 ExploreP:0.0823\n",
      "Episode:661 MeanR:97.2500 R:198.0 Loss:0.6426 ExploreP:0.0809\n",
      "Episode:662 MeanR:98.8100 R:181.0 Loss:0.6546 ExploreP:0.0797\n",
      "Episode:663 MeanR:100.1700 R:180.0 Loss:303.9481 ExploreP:0.0784\n",
      "Episode:664 MeanR:103.3300 R:357.0 Loss:0.8476 ExploreP:0.0760\n",
      "Episode:665 MeanR:107.3500 R:428.0 Loss:0.2282 ExploreP:0.0733\n",
      "Episode:666 MeanR:108.5400 R:147.0 Loss:0.9253 ExploreP:0.0723\n",
      "Episode:667 MeanR:110.3800 R:206.0 Loss:0.5142 ExploreP:0.0711\n",
      "Episode:668 MeanR:111.7200 R:172.0 Loss:13.8335 ExploreP:0.0700\n",
      "Episode:669 MeanR:113.0900 R:162.0 Loss:0.2459 ExploreP:0.0691\n",
      "Episode:670 MeanR:114.6000 R:181.0 Loss:1.0691 ExploreP:0.0680\n",
      "Episode:671 MeanR:116.0700 R:176.0 Loss:0.5063 ExploreP:0.0670\n",
      "Episode:672 MeanR:117.7400 R:210.0 Loss:0.2958 ExploreP:0.0658\n",
      "Episode:673 MeanR:119.7100 R:232.0 Loss:0.5104 ExploreP:0.0645\n",
      "Episode:674 MeanR:121.0700 R:173.0 Loss:0.4551 ExploreP:0.0636\n",
      "Episode:675 MeanR:122.9300 R:217.0 Loss:0.3837 ExploreP:0.0624\n",
      "Episode:676 MeanR:125.0200 R:235.0 Loss:0.3849 ExploreP:0.0612\n",
      "Episode:677 MeanR:126.7000 R:196.0 Loss:0.5177 ExploreP:0.0602\n",
      "Episode:678 MeanR:128.1800 R:172.0 Loss:0.4151 ExploreP:0.0594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:679 MeanR:129.8000 R:183.0 Loss:0.4111 ExploreP:0.0585\n",
      "Episode:680 MeanR:131.4600 R:204.0 Loss:0.3681 ExploreP:0.0575\n",
      "Episode:681 MeanR:132.9700 R:193.0 Loss:0.3120 ExploreP:0.0566\n",
      "Episode:682 MeanR:134.7400 R:204.0 Loss:0.4504 ExploreP:0.0556\n",
      "Episode:683 MeanR:135.9800 R:162.0 Loss:30.8518 ExploreP:0.0549\n",
      "Episode:684 MeanR:137.5600 R:216.0 Loss:0.2271 ExploreP:0.0539\n",
      "Episode:685 MeanR:138.6900 R:218.0 Loss:1.1957 ExploreP:0.0530\n",
      "Episode:686 MeanR:139.9600 R:167.0 Loss:0.3900 ExploreP:0.0523\n",
      "Episode:687 MeanR:141.7000 R:215.0 Loss:0.7637 ExploreP:0.0514\n",
      "Episode:688 MeanR:142.3800 R:161.0 Loss:0.3820 ExploreP:0.0507\n",
      "Episode:689 MeanR:143.4900 R:190.0 Loss:0.6298 ExploreP:0.0500\n",
      "Episode:690 MeanR:145.0300 R:206.0 Loss:0.5061 ExploreP:0.0491\n",
      "Episode:691 MeanR:146.1900 R:169.0 Loss:0.6080 ExploreP:0.0485\n",
      "Episode:692 MeanR:147.2700 R:192.0 Loss:0.3965 ExploreP:0.0478\n",
      "Episode:693 MeanR:148.4100 R:157.0 Loss:0.1629 ExploreP:0.0472\n",
      "Episode:694 MeanR:149.9600 R:205.0 Loss:0.3711 ExploreP:0.0464\n",
      "Episode:695 MeanR:151.4700 R:188.0 Loss:0.3559 ExploreP:0.0457\n",
      "Episode:696 MeanR:152.5800 R:155.0 Loss:0.1708 ExploreP:0.0452\n",
      "Episode:697 MeanR:153.5700 R:171.0 Loss:0.6989 ExploreP:0.0446\n",
      "Episode:698 MeanR:153.9200 R:171.0 Loss:0.7847 ExploreP:0.0440\n",
      "Episode:699 MeanR:154.3600 R:129.0 Loss:0.2086 ExploreP:0.0436\n",
      "Episode:700 MeanR:154.5500 R:174.0 Loss:0.2678 ExploreP:0.0430\n",
      "Episode:701 MeanR:154.9600 R:148.0 Loss:0.4115 ExploreP:0.0425\n",
      "Episode:702 MeanR:155.2100 R:115.0 Loss:0.2883 ExploreP:0.0421\n",
      "Episode:703 MeanR:156.2000 R:133.0 Loss:0.1972 ExploreP:0.0417\n",
      "Episode:704 MeanR:156.8500 R:151.0 Loss:0.1304 ExploreP:0.0412\n",
      "Episode:705 MeanR:157.2500 R:138.0 Loss:0.1606 ExploreP:0.0408\n",
      "Episode:706 MeanR:158.0300 R:152.0 Loss:0.3171 ExploreP:0.0403\n",
      "Episode:707 MeanR:158.5300 R:173.0 Loss:0.1831 ExploreP:0.0398\n",
      "Episode:708 MeanR:159.5000 R:171.0 Loss:0.2222 ExploreP:0.0393\n",
      "Episode:709 MeanR:160.5000 R:212.0 Loss:0.2230 ExploreP:0.0387\n",
      "Episode:710 MeanR:161.7100 R:225.0 Loss:0.1888 ExploreP:0.0381\n",
      "Episode:711 MeanR:163.1400 R:254.0 Loss:0.1846 ExploreP:0.0374\n",
      "Episode:712 MeanR:165.3000 R:299.0 Loss:0.1520 ExploreP:0.0366\n",
      "Episode:713 MeanR:167.8100 R:333.0 Loss:0.1277 ExploreP:0.0357\n",
      "Episode:714 MeanR:169.4200 R:433.0 Loss:0.1125 ExploreP:0.0346\n",
      "Episode:715 MeanR:173.5600 R:500.0 Loss:0.2090 ExploreP:0.0334\n",
      "Episode:716 MeanR:177.8000 R:500.0 Loss:0.0881 ExploreP:0.0323\n",
      "Episode:717 MeanR:181.8900 R:500.0 Loss:0.0626 ExploreP:0.0312\n",
      "Episode:718 MeanR:182.4500 R:95.0 Loss:0.2097 ExploreP:0.0310\n",
      "Episode:719 MeanR:182.7600 R:100.0 Loss:6.3956 ExploreP:0.0308\n",
      "Episode:720 MeanR:183.7400 R:146.0 Loss:0.1648 ExploreP:0.0305\n",
      "Episode:721 MeanR:183.5200 R:74.0 Loss:0.2408 ExploreP:0.0303\n",
      "Episode:722 MeanR:183.6900 R:77.0 Loss:0.6471 ExploreP:0.0302\n",
      "Episode:723 MeanR:187.3800 R:500.0 Loss:0.4605 ExploreP:0.0292\n",
      "Episode:724 MeanR:191.5900 R:500.0 Loss:0.1207 ExploreP:0.0282\n",
      "Episode:725 MeanR:195.2400 R:426.0 Loss:0.5278 ExploreP:0.0275\n",
      "Episode:726 MeanR:198.8600 R:500.0 Loss:0.3976 ExploreP:0.0266\n",
      "Episode:727 MeanR:203.0600 R:497.0 Loss:0.1082 ExploreP:0.0258\n",
      "Episode:728 MeanR:207.0500 R:500.0 Loss:0.0320 ExploreP:0.0250\n",
      "Episode:729 MeanR:211.0700 R:500.0 Loss:0.2069 ExploreP:0.0243\n",
      "Episode:730 MeanR:215.3200 R:500.0 Loss:0.2348 ExploreP:0.0236\n",
      "Episode:731 MeanR:219.5700 R:500.0 Loss:0.1704 ExploreP:0.0229\n",
      "Episode:732 MeanR:223.5800 R:500.0 Loss:0.0752 ExploreP:0.0223\n",
      "Episode:733 MeanR:227.7200 R:500.0 Loss:0.2057 ExploreP:0.0217\n",
      "Episode:734 MeanR:231.8800 R:500.0 Loss:0.3138 ExploreP:0.0211\n",
      "Episode:735 MeanR:236.0300 R:500.0 Loss:6.9664 ExploreP:0.0206\n",
      "Episode:736 MeanR:238.6300 R:500.0 Loss:0.0993 ExploreP:0.0201\n",
      "Episode:737 MeanR:242.5100 R:500.0 Loss:0.2927 ExploreP:0.0196\n",
      "Episode:738 MeanR:246.1700 R:500.0 Loss:0.2444 ExploreP:0.0191\n",
      "Episode:739 MeanR:250.2500 R:500.0 Loss:0.1333 ExploreP:0.0187\n",
      "Episode:740 MeanR:251.6400 R:500.0 Loss:0.1847 ExploreP:0.0183\n",
      "Episode:741 MeanR:255.9400 R:500.0 Loss:0.1085 ExploreP:0.0179\n",
      "Episode:742 MeanR:259.8300 R:500.0 Loss:0.3168 ExploreP:0.0175\n",
      "Episode:743 MeanR:263.8300 R:500.0 Loss:0.1279 ExploreP:0.0171\n",
      "Episode:744 MeanR:265.3100 R:500.0 Loss:0.0886 ExploreP:0.0168\n",
      "Episode:745 MeanR:269.3400 R:500.0 Loss:0.4988 ExploreP:0.0164\n",
      "Episode:746 MeanR:272.8400 R:500.0 Loss:0.1201 ExploreP:0.0161\n",
      "Episode:747 MeanR:276.7300 R:500.0 Loss:0.1366 ExploreP:0.0158\n",
      "Episode:748 MeanR:279.4900 R:500.0 Loss:0.1772 ExploreP:0.0155\n",
      "Episode:749 MeanR:282.2000 R:500.0 Loss:0.1508 ExploreP:0.0153\n",
      "Episode:750 MeanR:286.2200 R:500.0 Loss:0.1339 ExploreP:0.0150\n",
      "Episode:751 MeanR:290.5700 R:500.0 Loss:0.4614 ExploreP:0.0148\n",
      "Episode:752 MeanR:292.3900 R:500.0 Loss:0.1638 ExploreP:0.0145\n",
      "Episode:753 MeanR:292.4700 R:500.0 Loss:0.1703 ExploreP:0.0143\n",
      "Episode:754 MeanR:294.8800 R:500.0 Loss:0.1464 ExploreP:0.0141\n",
      "Episode:755 MeanR:298.6700 R:500.0 Loss:0.1165 ExploreP:0.0139\n",
      "Episode:756 MeanR:302.5000 R:500.0 Loss:0.1563 ExploreP:0.0137\n",
      "Episode:757 MeanR:301.8600 R:46.0 Loss:0.3221 ExploreP:0.0137\n",
      "Episode:758 MeanR:305.4000 R:500.0 Loss:0.1130 ExploreP:0.0135\n",
      "Episode:759 MeanR:308.9600 R:500.0 Loss:0.1764 ExploreP:0.0133\n",
      "Episode:760 MeanR:312.5100 R:500.0 Loss:0.1050 ExploreP:0.0132\n",
      "Episode:761 MeanR:315.5300 R:500.0 Loss:0.1552 ExploreP:0.0130\n",
      "Episode:762 MeanR:316.6100 R:289.0 Loss:0.0814 ExploreP:0.0129\n",
      "Episode:763 MeanR:319.8100 R:500.0 Loss:0.0853 ExploreP:0.0128\n",
      "Episode:764 MeanR:321.2400 R:500.0 Loss:0.0848 ExploreP:0.0127\n",
      "Episode:765 MeanR:321.9600 R:500.0 Loss:0.0523 ExploreP:0.0125\n",
      "Episode:766 MeanR:325.4900 R:500.0 Loss:0.0743 ExploreP:0.0124\n",
      "Episode:767 MeanR:328.4300 R:500.0 Loss:0.1074 ExploreP:0.0123\n",
      "Episode:768 MeanR:331.7100 R:500.0 Loss:0.1310 ExploreP:0.0122\n",
      "Episode:769 MeanR:334.9600 R:487.0 Loss:0.1882 ExploreP:0.0121\n",
      "Episode:770 MeanR:338.1500 R:500.0 Loss:0.1328 ExploreP:0.0120\n",
      "Episode:771 MeanR:341.3900 R:500.0 Loss:0.0700 ExploreP:0.0119\n",
      "Episode:772 MeanR:344.2900 R:500.0 Loss:0.1513 ExploreP:0.0118\n",
      "Episode:773 MeanR:346.9700 R:500.0 Loss:0.1045 ExploreP:0.0117\n",
      "Episode:774 MeanR:350.2400 R:500.0 Loss:0.1309 ExploreP:0.0116\n",
      "Episode:775 MeanR:353.0700 R:500.0 Loss:287.4411 ExploreP:0.0115\n",
      "Episode:776 MeanR:355.1900 R:447.0 Loss:0.0624 ExploreP:0.0115\n",
      "Episode:777 MeanR:356.7300 R:350.0 Loss:0.0840 ExploreP:0.0114\n",
      "Episode:778 MeanR:358.4000 R:339.0 Loss:0.1801 ExploreP:0.0114\n",
      "Episode:779 MeanR:359.1000 R:253.0 Loss:0.0674 ExploreP:0.0113\n",
      "Episode:780 MeanR:360.3300 R:327.0 Loss:0.1436 ExploreP:0.0113\n",
      "Episode:781 MeanR:360.8500 R:245.0 Loss:0.1296 ExploreP:0.0113\n",
      "Episode:782 MeanR:360.9400 R:213.0 Loss:0.1663 ExploreP:0.0112\n",
      "Episode:783 MeanR:361.7500 R:243.0 Loss:0.2354 ExploreP:0.0112\n",
      "Episode:784 MeanR:362.0900 R:250.0 Loss:0.0689 ExploreP:0.0112\n",
      "Episode:785 MeanR:361.8300 R:192.0 Loss:0.2549 ExploreP:0.0112\n",
      "Episode:786 MeanR:360.9600 R:80.0 Loss:0.1822 ExploreP:0.0111\n",
      "Episode:787 MeanR:359.5700 R:76.0 Loss:0.1936 ExploreP:0.0111\n",
      "Episode:788 MeanR:359.6900 R:173.0 Loss:0.1352 ExploreP:0.0111\n",
      "Episode:789 MeanR:359.1000 R:131.0 Loss:0.2451 ExploreP:0.0111\n",
      "Episode:790 MeanR:358.9000 R:186.0 Loss:0.1403 ExploreP:0.0111\n",
      "Episode:791 MeanR:358.5500 R:134.0 Loss:0.1619 ExploreP:0.0111\n",
      "Episode:792 MeanR:358.0200 R:139.0 Loss:0.2118 ExploreP:0.0111\n",
      "Episode:793 MeanR:358.7700 R:232.0 Loss:0.1675 ExploreP:0.0110\n",
      "Episode:794 MeanR:359.5900 R:287.0 Loss:0.3275 ExploreP:0.0110\n",
      "Episode:795 MeanR:362.7100 R:500.0 Loss:0.1351 ExploreP:0.0110\n",
      "Episode:796 MeanR:366.1600 R:500.0 Loss:0.1213 ExploreP:0.0109\n",
      "Episode:797 MeanR:368.9000 R:445.0 Loss:0.3943 ExploreP:0.0109\n",
      "Episode:798 MeanR:368.4700 R:128.0 Loss:0.6921 ExploreP:0.0109\n",
      "Episode:799 MeanR:367.2800 R:10.0 Loss:0.8921 ExploreP:0.0109\n",
      "Episode:800 MeanR:365.6600 R:12.0 Loss:1.2248 ExploreP:0.0109\n",
      "Episode:801 MeanR:364.3000 R:12.0 Loss:1.3445 ExploreP:0.0109\n",
      "Episode:802 MeanR:363.2400 R:9.0 Loss:1.7150 ExploreP:0.0109\n",
      "Episode:803 MeanR:362.0000 R:9.0 Loss:1.6363 ExploreP:0.0108\n",
      "Episode:804 MeanR:360.5900 R:10.0 Loss:589.6235 ExploreP:0.0108\n",
      "Episode:805 MeanR:359.3100 R:10.0 Loss:2.3034 ExploreP:0.0108\n",
      "Episode:806 MeanR:357.8800 R:9.0 Loss:3.7654 ExploreP:0.0108\n",
      "Episode:807 MeanR:356.2300 R:8.0 Loss:100.6499 ExploreP:0.0108\n",
      "Episode:808 MeanR:354.6200 R:10.0 Loss:3.3690 ExploreP:0.0108\n",
      "Episode:809 MeanR:352.5900 R:9.0 Loss:3.1258 ExploreP:0.0108\n",
      "Episode:810 MeanR:350.4300 R:9.0 Loss:2.3062 ExploreP:0.0108\n",
      "Episode:811 MeanR:348.0100 R:12.0 Loss:1.1334 ExploreP:0.0108\n",
      "Episode:812 MeanR:345.1300 R:11.0 Loss:1.0556 ExploreP:0.0108\n",
      "Episode:813 MeanR:341.8900 R:9.0 Loss:1.3450 ExploreP:0.0108\n",
      "Episode:814 MeanR:337.6700 R:11.0 Loss:1.9476 ExploreP:0.0108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:815 MeanR:332.7600 R:9.0 Loss:1.8742 ExploreP:0.0108\n",
      "Episode:816 MeanR:327.8500 R:9.0 Loss:2.0621 ExploreP:0.0108\n",
      "Episode:817 MeanR:322.9600 R:11.0 Loss:1.7683 ExploreP:0.0108\n",
      "Episode:818 MeanR:322.1000 R:9.0 Loss:2.2566 ExploreP:0.0108\n",
      "Episode:819 MeanR:321.2000 R:10.0 Loss:1.7103 ExploreP:0.0108\n",
      "Episode:820 MeanR:319.8400 R:10.0 Loss:1.0368 ExploreP:0.0108\n",
      "Episode:821 MeanR:319.2200 R:12.0 Loss:1.3913 ExploreP:0.0108\n",
      "Episode:822 MeanR:318.5700 R:12.0 Loss:2.2937 ExploreP:0.0108\n",
      "Episode:823 MeanR:313.7000 R:13.0 Loss:0.9163 ExploreP:0.0108\n",
      "Episode:824 MeanR:308.8500 R:15.0 Loss:1.6313 ExploreP:0.0108\n",
      "Episode:825 MeanR:307.8900 R:330.0 Loss:0.2666 ExploreP:0.0108\n",
      "Episode:826 MeanR:305.9500 R:306.0 Loss:0.3051 ExploreP:0.0108\n",
      "Episode:827 MeanR:301.1700 R:19.0 Loss:0.6204 ExploreP:0.0108\n",
      "Episode:828 MeanR:296.4200 R:25.0 Loss:0.2522 ExploreP:0.0108\n",
      "Episode:829 MeanR:291.5800 R:16.0 Loss:0.3680 ExploreP:0.0108\n",
      "Episode:830 MeanR:286.7400 R:16.0 Loss:0.2292 ExploreP:0.0108\n",
      "Episode:831 MeanR:281.8900 R:15.0 Loss:0.7310 ExploreP:0.0108\n",
      "Episode:832 MeanR:277.0400 R:15.0 Loss:0.5830 ExploreP:0.0108\n",
      "Episode:833 MeanR:272.1600 R:12.0 Loss:1.3428 ExploreP:0.0108\n",
      "Episode:834 MeanR:267.2900 R:13.0 Loss:0.4150 ExploreP:0.0108\n",
      "Episode:835 MeanR:262.4300 R:14.0 Loss:0.4506 ExploreP:0.0108\n",
      "Episode:836 MeanR:257.5600 R:13.0 Loss:0.3856 ExploreP:0.0108\n",
      "Episode:837 MeanR:252.7400 R:18.0 Loss:0.5995 ExploreP:0.0108\n",
      "Episode:838 MeanR:247.9000 R:16.0 Loss:0.3424 ExploreP:0.0108\n",
      "Episode:839 MeanR:243.0600 R:16.0 Loss:0.5167 ExploreP:0.0108\n",
      "Episode:840 MeanR:238.2200 R:16.0 Loss:0.4376 ExploreP:0.0108\n",
      "Episode:841 MeanR:233.3600 R:14.0 Loss:0.6406 ExploreP:0.0108\n",
      "Episode:842 MeanR:228.4800 R:12.0 Loss:0.6798 ExploreP:0.0108\n",
      "Episode:843 MeanR:223.6100 R:13.0 Loss:0.5878 ExploreP:0.0108\n",
      "Episode:844 MeanR:218.7400 R:13.0 Loss:0.5505 ExploreP:0.0108\n",
      "Episode:845 MeanR:213.8700 R:13.0 Loss:0.6749 ExploreP:0.0108\n",
      "Episode:846 MeanR:208.9700 R:10.0 Loss:483.6784 ExploreP:0.0108\n",
      "Episode:847 MeanR:204.0700 R:10.0 Loss:1.2342 ExploreP:0.0108\n",
      "Episode:848 MeanR:199.1900 R:12.0 Loss:0.9140 ExploreP:0.0108\n",
      "Episode:849 MeanR:194.3000 R:11.0 Loss:1.5076 ExploreP:0.0108\n",
      "Episode:850 MeanR:189.3900 R:9.0 Loss:1.0050 ExploreP:0.0108\n",
      "Episode:851 MeanR:184.5000 R:11.0 Loss:1.2811 ExploreP:0.0108\n",
      "Episode:852 MeanR:179.6100 R:11.0 Loss:510.1800 ExploreP:0.0108\n",
      "Episode:853 MeanR:174.7300 R:12.0 Loss:582.4119 ExploreP:0.0108\n",
      "Episode:854 MeanR:169.9000 R:17.0 Loss:1.3942 ExploreP:0.0107\n",
      "Episode:855 MeanR:165.0300 R:13.0 Loss:624.8021 ExploreP:0.0107\n",
      "Episode:856 MeanR:160.1400 R:11.0 Loss:1.0320 ExploreP:0.0107\n",
      "Episode:857 MeanR:159.7800 R:10.0 Loss:0.9755 ExploreP:0.0107\n",
      "Episode:858 MeanR:154.8800 R:10.0 Loss:0.9958 ExploreP:0.0107\n",
      "Episode:859 MeanR:149.9900 R:11.0 Loss:1.8217 ExploreP:0.0107\n",
      "Episode:860 MeanR:145.0900 R:10.0 Loss:1.1112 ExploreP:0.0107\n",
      "Episode:861 MeanR:140.1700 R:8.0 Loss:1.2891 ExploreP:0.0107\n",
      "Episode:862 MeanR:137.3900 R:11.0 Loss:0.9614 ExploreP:0.0107\n",
      "Episode:863 MeanR:132.4800 R:9.0 Loss:0.8254 ExploreP:0.0107\n",
      "Episode:864 MeanR:127.5700 R:9.0 Loss:0.8290 ExploreP:0.0107\n",
      "Episode:865 MeanR:122.6700 R:10.0 Loss:1.6416 ExploreP:0.0107\n",
      "Episode:866 MeanR:117.7500 R:8.0 Loss:1.3796 ExploreP:0.0107\n",
      "Episode:867 MeanR:112.8500 R:10.0 Loss:1.5384 ExploreP:0.0107\n",
      "Episode:868 MeanR:107.9400 R:9.0 Loss:620.1977 ExploreP:0.0107\n",
      "Episode:869 MeanR:103.1600 R:9.0 Loss:0.9500 ExploreP:0.0107\n",
      "Episode:870 MeanR:98.2500 R:9.0 Loss:0.6645 ExploreP:0.0107\n",
      "Episode:871 MeanR:93.3600 R:11.0 Loss:1.2549 ExploreP:0.0107\n",
      "Episode:872 MeanR:88.4400 R:8.0 Loss:115.4459 ExploreP:0.0107\n",
      "Episode:873 MeanR:83.5400 R:10.0 Loss:616.0912 ExploreP:0.0107\n",
      "Episode:874 MeanR:78.6400 R:10.0 Loss:658.7378 ExploreP:0.0107\n",
      "Episode:875 MeanR:73.7400 R:10.0 Loss:628.1633 ExploreP:0.0107\n",
      "Episode:876 MeanR:69.3500 R:8.0 Loss:2.7079 ExploreP:0.0107\n",
      "Episode:877 MeanR:65.9500 R:10.0 Loss:2.9088 ExploreP:0.0107\n",
      "Episode:878 MeanR:62.6600 R:10.0 Loss:4.9782 ExploreP:0.0107\n",
      "Episode:879 MeanR:60.2300 R:10.0 Loss:44.6563 ExploreP:0.0107\n",
      "Episode:880 MeanR:57.0600 R:10.0 Loss:2.6271 ExploreP:0.0107\n",
      "Episode:881 MeanR:54.7000 R:9.0 Loss:2.2517 ExploreP:0.0107\n",
      "Episode:882 MeanR:52.6800 R:11.0 Loss:2.3284 ExploreP:0.0107\n",
      "Episode:883 MeanR:50.3500 R:10.0 Loss:503.9649 ExploreP:0.0107\n",
      "Episode:884 MeanR:47.9500 R:10.0 Loss:1.7669 ExploreP:0.0107\n",
      "Episode:885 MeanR:46.1400 R:11.0 Loss:1.5008 ExploreP:0.0107\n",
      "Episode:886 MeanR:45.4400 R:10.0 Loss:2.2664 ExploreP:0.0107\n",
      "Episode:887 MeanR:44.7700 R:9.0 Loss:1.4984 ExploreP:0.0107\n",
      "Episode:888 MeanR:43.1200 R:8.0 Loss:1.8974 ExploreP:0.0107\n",
      "Episode:889 MeanR:41.9100 R:10.0 Loss:1.7605 ExploreP:0.0107\n",
      "Episode:890 MeanR:40.1400 R:9.0 Loss:1.5345 ExploreP:0.0107\n",
      "Episode:891 MeanR:38.8800 R:8.0 Loss:1.7734 ExploreP:0.0107\n",
      "Episode:892 MeanR:37.5900 R:10.0 Loss:2.0351 ExploreP:0.0107\n",
      "Episode:893 MeanR:35.3600 R:9.0 Loss:2.1705 ExploreP:0.0107\n",
      "Episode:894 MeanR:32.6000 R:11.0 Loss:1.9529 ExploreP:0.0107\n",
      "Episode:895 MeanR:27.6900 R:9.0 Loss:1.1399 ExploreP:0.0107\n",
      "Episode:896 MeanR:22.7900 R:10.0 Loss:1.2096 ExploreP:0.0107\n",
      "Episode:897 MeanR:18.4500 R:11.0 Loss:1.7756 ExploreP:0.0107\n",
      "Episode:898 MeanR:17.3100 R:14.0 Loss:1.0268 ExploreP:0.0107\n",
      "Episode:899 MeanR:22.2100 R:500.0 Loss:1.7455 ExploreP:0.0107\n",
      "Episode:900 MeanR:23.4200 R:133.0 Loss:2.8520 ExploreP:0.0107\n",
      "Episode:901 MeanR:23.4300 R:13.0 Loss:2.1087 ExploreP:0.0107\n",
      "Episode:902 MeanR:23.4800 R:14.0 Loss:3.3647 ExploreP:0.0107\n",
      "Episode:903 MeanR:23.5100 R:12.0 Loss:4.0516 ExploreP:0.0107\n",
      "Episode:904 MeanR:23.5400 R:13.0 Loss:218.4052 ExploreP:0.0107\n",
      "Episode:905 MeanR:23.5600 R:12.0 Loss:27.7752 ExploreP:0.0107\n",
      "Episode:906 MeanR:23.6100 R:14.0 Loss:2.8279 ExploreP:0.0107\n",
      "Episode:907 MeanR:23.6300 R:10.0 Loss:4.2486 ExploreP:0.0107\n",
      "Episode:908 MeanR:23.6300 R:10.0 Loss:1.0646 ExploreP:0.0107\n",
      "Episode:909 MeanR:23.6500 R:11.0 Loss:437.5154 ExploreP:0.0107\n",
      "Episode:910 MeanR:23.6700 R:11.0 Loss:4.8068 ExploreP:0.0107\n",
      "Episode:911 MeanR:23.6600 R:11.0 Loss:3.1853 ExploreP:0.0107\n",
      "Episode:912 MeanR:23.6400 R:9.0 Loss:284.6505 ExploreP:0.0107\n",
      "Episode:913 MeanR:23.6700 R:12.0 Loss:169.6475 ExploreP:0.0107\n",
      "Episode:914 MeanR:23.6500 R:9.0 Loss:3.8636 ExploreP:0.0107\n",
      "Episode:915 MeanR:23.6500 R:9.0 Loss:3.5832 ExploreP:0.0107\n",
      "Episode:916 MeanR:23.6500 R:9.0 Loss:459.9710 ExploreP:0.0107\n",
      "Episode:917 MeanR:23.6500 R:11.0 Loss:501.7868 ExploreP:0.0107\n",
      "Episode:918 MeanR:23.6600 R:10.0 Loss:4.3508 ExploreP:0.0107\n",
      "Episode:919 MeanR:23.6500 R:9.0 Loss:4.2578 ExploreP:0.0107\n",
      "Episode:920 MeanR:23.6600 R:11.0 Loss:652.2802 ExploreP:0.0107\n",
      "Episode:921 MeanR:23.6400 R:10.0 Loss:6.1468 ExploreP:0.0107\n",
      "Episode:922 MeanR:23.6100 R:9.0 Loss:6.0851 ExploreP:0.0107\n",
      "Episode:923 MeanR:23.5800 R:10.0 Loss:5.0615 ExploreP:0.0107\n",
      "Episode:924 MeanR:23.5200 R:9.0 Loss:6.2564 ExploreP:0.0107\n",
      "Episode:925 MeanR:20.3100 R:9.0 Loss:3.8115 ExploreP:0.0107\n",
      "Episode:926 MeanR:17.3500 R:10.0 Loss:484.8150 ExploreP:0.0107\n",
      "Episode:927 MeanR:17.2500 R:9.0 Loss:158.7344 ExploreP:0.0107\n",
      "Episode:928 MeanR:17.0800 R:8.0 Loss:196.0620 ExploreP:0.0107\n",
      "Episode:929 MeanR:17.0100 R:9.0 Loss:372.8168 ExploreP:0.0107\n",
      "Episode:930 MeanR:16.9600 R:11.0 Loss:7.6580 ExploreP:0.0107\n",
      "Episode:931 MeanR:16.8900 R:8.0 Loss:224.4049 ExploreP:0.0107\n",
      "Episode:932 MeanR:16.8200 R:8.0 Loss:8.8505 ExploreP:0.0107\n",
      "Episode:933 MeanR:16.8000 R:10.0 Loss:6.9207 ExploreP:0.0107\n",
      "Episode:934 MeanR:16.7500 R:8.0 Loss:3.6886 ExploreP:0.0107\n",
      "Episode:935 MeanR:16.7000 R:9.0 Loss:5.4947 ExploreP:0.0107\n",
      "Episode:936 MeanR:16.6700 R:10.0 Loss:6.7810 ExploreP:0.0106\n",
      "Episode:937 MeanR:16.6000 R:11.0 Loss:7.3544 ExploreP:0.0106\n",
      "Episode:938 MeanR:16.5200 R:8.0 Loss:6.1864 ExploreP:0.0106\n",
      "Episode:939 MeanR:16.4400 R:8.0 Loss:8.3248 ExploreP:0.0106\n",
      "Episode:940 MeanR:16.3600 R:8.0 Loss:8.8966 ExploreP:0.0106\n",
      "Episode:941 MeanR:16.3100 R:9.0 Loss:8.4735 ExploreP:0.0106\n",
      "Episode:942 MeanR:16.2800 R:9.0 Loss:5.4941 ExploreP:0.0106\n",
      "Episode:943 MeanR:16.2300 R:8.0 Loss:9.4698 ExploreP:0.0106\n",
      "Episode:944 MeanR:16.2000 R:10.0 Loss:12.0246 ExploreP:0.0106\n",
      "Episode:945 MeanR:16.1700 R:10.0 Loss:7.6888 ExploreP:0.0106\n",
      "Episode:946 MeanR:16.1700 R:10.0 Loss:520.5120 ExploreP:0.0106\n",
      "Episode:947 MeanR:16.1700 R:10.0 Loss:8.0708 ExploreP:0.0106\n",
      "Episode:948 MeanR:16.1500 R:10.0 Loss:10.4737 ExploreP:0.0106\n",
      "Episode:949 MeanR:16.1300 R:9.0 Loss:7.4397 ExploreP:0.0106\n",
      "Episode:950 MeanR:16.1300 R:9.0 Loss:9.3905 ExploreP:0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:951 MeanR:16.1200 R:10.0 Loss:7.9347 ExploreP:0.0106\n",
      "Episode:952 MeanR:16.1000 R:9.0 Loss:9.0243 ExploreP:0.0106\n",
      "Episode:953 MeanR:16.0600 R:8.0 Loss:6.5015 ExploreP:0.0106\n",
      "Episode:954 MeanR:15.9800 R:9.0 Loss:9.7835 ExploreP:0.0106\n",
      "Episode:955 MeanR:15.9500 R:10.0 Loss:7.6360 ExploreP:0.0106\n",
      "Episode:956 MeanR:15.9200 R:8.0 Loss:7.4785 ExploreP:0.0106\n",
      "Episode:957 MeanR:15.9000 R:8.0 Loss:10.0670 ExploreP:0.0106\n",
      "Episode:958 MeanR:15.8900 R:9.0 Loss:7.7663 ExploreP:0.0106\n",
      "Episode:959 MeanR:15.8800 R:10.0 Loss:7.7830 ExploreP:0.0106\n",
      "Episode:960 MeanR:15.8800 R:10.0 Loss:8.5516 ExploreP:0.0106\n",
      "Episode:961 MeanR:15.9000 R:10.0 Loss:403.8188 ExploreP:0.0106\n",
      "Episode:962 MeanR:15.8800 R:9.0 Loss:7.1573 ExploreP:0.0106\n",
      "Episode:963 MeanR:15.8800 R:9.0 Loss:750.4870 ExploreP:0.0106\n",
      "Episode:964 MeanR:15.8800 R:9.0 Loss:9.4633 ExploreP:0.0106\n",
      "Episode:965 MeanR:15.8800 R:10.0 Loss:9.0526 ExploreP:0.0106\n",
      "Episode:966 MeanR:15.9000 R:10.0 Loss:10.5154 ExploreP:0.0106\n",
      "Episode:967 MeanR:15.9000 R:10.0 Loss:822.7372 ExploreP:0.0106\n",
      "Episode:968 MeanR:15.9200 R:11.0 Loss:6.5685 ExploreP:0.0106\n",
      "Episode:969 MeanR:15.9200 R:9.0 Loss:941.9912 ExploreP:0.0106\n",
      "Episode:970 MeanR:15.9200 R:9.0 Loss:8.8026 ExploreP:0.0106\n",
      "Episode:971 MeanR:15.9000 R:9.0 Loss:497.4780 ExploreP:0.0106\n",
      "Episode:972 MeanR:15.9200 R:10.0 Loss:9.8897 ExploreP:0.0106\n",
      "Episode:973 MeanR:15.9200 R:10.0 Loss:6.2586 ExploreP:0.0106\n",
      "Episode:974 MeanR:15.9000 R:8.0 Loss:8.2556 ExploreP:0.0106\n",
      "Episode:975 MeanR:15.8900 R:9.0 Loss:9.2250 ExploreP:0.0106\n",
      "Episode:976 MeanR:15.9100 R:10.0 Loss:7.1883 ExploreP:0.0106\n",
      "Episode:977 MeanR:15.9000 R:9.0 Loss:8.4181 ExploreP:0.0106\n",
      "Episode:978 MeanR:15.8800 R:8.0 Loss:450.8158 ExploreP:0.0106\n",
      "Episode:979 MeanR:15.8700 R:9.0 Loss:6.4450 ExploreP:0.0106\n",
      "Episode:980 MeanR:15.8700 R:10.0 Loss:4.9889 ExploreP:0.0106\n",
      "Episode:981 MeanR:15.8800 R:10.0 Loss:9.8220 ExploreP:0.0106\n",
      "Episode:982 MeanR:15.8600 R:9.0 Loss:9.5250 ExploreP:0.0106\n",
      "Episode:983 MeanR:15.8600 R:10.0 Loss:7.3470 ExploreP:0.0106\n",
      "Episode:984 MeanR:15.8700 R:11.0 Loss:331.7748 ExploreP:0.0106\n",
      "Episode:985 MeanR:15.8600 R:10.0 Loss:458.1536 ExploreP:0.0106\n",
      "Episode:986 MeanR:15.8600 R:10.0 Loss:455.2112 ExploreP:0.0106\n",
      "Episode:987 MeanR:15.8700 R:10.0 Loss:7.1060 ExploreP:0.0106\n",
      "Episode:988 MeanR:15.9100 R:12.0 Loss:7.2927 ExploreP:0.0106\n",
      "Episode:989 MeanR:15.9300 R:12.0 Loss:408.2927 ExploreP:0.0106\n",
      "Episode:990 MeanR:15.9400 R:10.0 Loss:232.5534 ExploreP:0.0106\n",
      "Episode:991 MeanR:15.9800 R:12.0 Loss:5.5512 ExploreP:0.0106\n",
      "Episode:992 MeanR:16.0100 R:13.0 Loss:6.6494 ExploreP:0.0106\n",
      "Episode:993 MeanR:16.0700 R:15.0 Loss:674.1000 ExploreP:0.0106\n",
      "Episode:994 MeanR:16.0900 R:13.0 Loss:4.1122 ExploreP:0.0106\n",
      "Episode:995 MeanR:16.1300 R:13.0 Loss:5.9527 ExploreP:0.0106\n",
      "Episode:996 MeanR:16.1400 R:11.0 Loss:254.0772 ExploreP:0.0106\n",
      "Episode:997 MeanR:16.1700 R:14.0 Loss:5.3431 ExploreP:0.0106\n",
      "Episode:998 MeanR:16.1700 R:14.0 Loss:433.6714 ExploreP:0.0106\n",
      "Episode:999 MeanR:11.3000 R:13.0 Loss:5.0362 ExploreP:0.0106\n",
      "Episode:1000 MeanR:10.1200 R:15.0 Loss:607.5709 ExploreP:0.0106\n",
      "Episode:1001 MeanR:10.1200 R:13.0 Loss:5.9579 ExploreP:0.0106\n",
      "Episode:1002 MeanR:10.1100 R:13.0 Loss:393.1473 ExploreP:0.0106\n",
      "Episode:1003 MeanR:14.9900 R:500.0 Loss:4.3954 ExploreP:0.0106\n",
      "Episode:1004 MeanR:19.8600 R:500.0 Loss:5.4535 ExploreP:0.0105\n",
      "Episode:1005 MeanR:24.7400 R:500.0 Loss:7.1975 ExploreP:0.0105\n",
      "Episode:1006 MeanR:29.6000 R:500.0 Loss:2.3860 ExploreP:0.0105\n",
      "Episode:1007 MeanR:34.5000 R:500.0 Loss:3.7146 ExploreP:0.0105\n",
      "Episode:1008 MeanR:39.4000 R:500.0 Loss:85.5320 ExploreP:0.0105\n",
      "Episode:1009 MeanR:43.3000 R:401.0 Loss:6.2193 ExploreP:0.0104\n",
      "Episode:1010 MeanR:46.6900 R:350.0 Loss:7.5954 ExploreP:0.0104\n",
      "Episode:1011 MeanR:50.0000 R:342.0 Loss:49.1876 ExploreP:0.0104\n",
      "Episode:1012 MeanR:52.6600 R:275.0 Loss:112.8901 ExploreP:0.0104\n",
      "Episode:1013 MeanR:55.0900 R:255.0 Loss:3.1447 ExploreP:0.0104\n",
      "Episode:1014 MeanR:57.5100 R:251.0 Loss:22.4104 ExploreP:0.0104\n",
      "Episode:1015 MeanR:59.9000 R:248.0 Loss:79.5020 ExploreP:0.0104\n",
      "Episode:1016 MeanR:62.0900 R:228.0 Loss:5.5448 ExploreP:0.0104\n",
      "Episode:1017 MeanR:64.6100 R:263.0 Loss:7.2639 ExploreP:0.0103\n",
      "Episode:1018 MeanR:67.1400 R:263.0 Loss:117.2114 ExploreP:0.0103\n",
      "Episode:1019 MeanR:69.8300 R:278.0 Loss:2.2328 ExploreP:0.0103\n",
      "Episode:1020 MeanR:72.6300 R:291.0 Loss:5.2621 ExploreP:0.0103\n",
      "Episode:1021 MeanR:76.0700 R:354.0 Loss:5.7847 ExploreP:0.0103\n",
      "Episode:1022 MeanR:79.6800 R:370.0 Loss:2.7898 ExploreP:0.0103\n",
      "Episode:1023 MeanR:83.4100 R:383.0 Loss:2.5228 ExploreP:0.0103\n",
      "Episode:1024 MeanR:85.9900 R:267.0 Loss:7.3488 ExploreP:0.0103\n",
      "Episode:1025 MeanR:88.5000 R:260.0 Loss:286.8534 ExploreP:0.0103\n",
      "Episode:1026 MeanR:90.8300 R:243.0 Loss:3.5696 ExploreP:0.0103\n",
      "Episode:1027 MeanR:93.0500 R:231.0 Loss:5.3599 ExploreP:0.0103\n",
      "Episode:1028 MeanR:95.0900 R:212.0 Loss:2.8767 ExploreP:0.0103\n",
      "Episode:1029 MeanR:97.2400 R:224.0 Loss:3.1866 ExploreP:0.0102\n",
      "Episode:1030 MeanR:99.1000 R:197.0 Loss:2.5705 ExploreP:0.0102\n",
      "Episode:1031 MeanR:100.9100 R:189.0 Loss:4.7900 ExploreP:0.0102\n",
      "Episode:1032 MeanR:102.5900 R:176.0 Loss:2.1139 ExploreP:0.0102\n",
      "Episode:1033 MeanR:104.2300 R:174.0 Loss:2.8888 ExploreP:0.0102\n",
      "Episode:1034 MeanR:105.9400 R:179.0 Loss:1.7145 ExploreP:0.0102\n",
      "Episode:1035 MeanR:107.8600 R:201.0 Loss:1.0703 ExploreP:0.0102\n",
      "Episode:1036 MeanR:109.8100 R:205.0 Loss:0.7984 ExploreP:0.0102\n",
      "Episode:1037 MeanR:112.2500 R:255.0 Loss:1.2476 ExploreP:0.0102\n",
      "Episode:1038 MeanR:114.6400 R:247.0 Loss:0.6572 ExploreP:0.0102\n",
      "Episode:1039 MeanR:117.1000 R:254.0 Loss:0.6152 ExploreP:0.0102\n",
      "Episode:1040 MeanR:119.8200 R:280.0 Loss:1.6919 ExploreP:0.0102\n",
      "Episode:1041 MeanR:122.1400 R:241.0 Loss:0.8544 ExploreP:0.0102\n",
      "Episode:1042 MeanR:124.8700 R:282.0 Loss:0.4686 ExploreP:0.0102\n",
      "Episode:1043 MeanR:127.4300 R:264.0 Loss:0.7308 ExploreP:0.0102\n",
      "Episode:1044 MeanR:129.7400 R:241.0 Loss:0.6436 ExploreP:0.0102\n",
      "Episode:1045 MeanR:132.3000 R:266.0 Loss:0.4737 ExploreP:0.0102\n",
      "Episode:1046 MeanR:134.7000 R:250.0 Loss:0.3655 ExploreP:0.0102\n",
      "Episode:1047 MeanR:137.2800 R:268.0 Loss:1.1189 ExploreP:0.0102\n",
      "Episode:1048 MeanR:139.4500 R:227.0 Loss:1.3175 ExploreP:0.0102\n",
      "Episode:1049 MeanR:141.8000 R:244.0 Loss:0.3783 ExploreP:0.0102\n",
      "Episode:1050 MeanR:144.9000 R:319.0 Loss:1.2355 ExploreP:0.0102\n",
      "Episode:1051 MeanR:147.3600 R:256.0 Loss:0.1983 ExploreP:0.0101\n",
      "Episode:1052 MeanR:150.0900 R:282.0 Loss:0.3767 ExploreP:0.0101\n",
      "Episode:1053 MeanR:152.3800 R:237.0 Loss:84.6402 ExploreP:0.0101\n",
      "Episode:1054 MeanR:154.7400 R:245.0 Loss:0.1511 ExploreP:0.0101\n",
      "Episode:1055 MeanR:157.1600 R:252.0 Loss:0.2893 ExploreP:0.0101\n",
      "Episode:1056 MeanR:159.1300 R:205.0 Loss:60.4519 ExploreP:0.0101\n",
      "Episode:1057 MeanR:161.8100 R:276.0 Loss:0.1795 ExploreP:0.0101\n",
      "Episode:1058 MeanR:164.1400 R:242.0 Loss:58.4313 ExploreP:0.0101\n",
      "Episode:1059 MeanR:166.6800 R:264.0 Loss:0.2115 ExploreP:0.0101\n",
      "Episode:1060 MeanR:168.7200 R:214.0 Loss:0.3996 ExploreP:0.0101\n",
      "Episode:1061 MeanR:170.8800 R:226.0 Loss:54.6882 ExploreP:0.0101\n",
      "Episode:1062 MeanR:173.0200 R:223.0 Loss:0.3115 ExploreP:0.0101\n",
      "Episode:1063 MeanR:175.5600 R:263.0 Loss:0.2392 ExploreP:0.0101\n",
      "Episode:1064 MeanR:177.5000 R:203.0 Loss:0.2531 ExploreP:0.0101\n",
      "Episode:1065 MeanR:179.9200 R:252.0 Loss:0.3016 ExploreP:0.0101\n",
      "Episode:1066 MeanR:182.4000 R:258.0 Loss:0.4380 ExploreP:0.0101\n",
      "Episode:1067 MeanR:184.5800 R:228.0 Loss:35.3080 ExploreP:0.0101\n",
      "Episode:1068 MeanR:186.7800 R:231.0 Loss:0.2320 ExploreP:0.0101\n",
      "Episode:1069 MeanR:189.1700 R:248.0 Loss:0.2212 ExploreP:0.0101\n",
      "Episode:1070 MeanR:191.4000 R:232.0 Loss:0.2622 ExploreP:0.0101\n",
      "Episode:1071 MeanR:194.1200 R:281.0 Loss:0.0736 ExploreP:0.0101\n",
      "Episode:1072 MeanR:196.2300 R:221.0 Loss:0.1161 ExploreP:0.0101\n",
      "Episode:1073 MeanR:198.5000 R:237.0 Loss:0.1217 ExploreP:0.0101\n",
      "Episode:1074 MeanR:201.2500 R:283.0 Loss:0.1890 ExploreP:0.0101\n",
      "Episode:1075 MeanR:204.1200 R:296.0 Loss:0.2625 ExploreP:0.0101\n",
      "Episode:1076 MeanR:206.5000 R:248.0 Loss:0.2399 ExploreP:0.0101\n",
      "Episode:1077 MeanR:209.3700 R:296.0 Loss:0.1080 ExploreP:0.0101\n",
      "Episode:1078 MeanR:211.7000 R:241.0 Loss:0.2609 ExploreP:0.0101\n",
      "Episode:1079 MeanR:214.0100 R:240.0 Loss:0.2254 ExploreP:0.0101\n",
      "Episode:1080 MeanR:216.5900 R:268.0 Loss:44.4520 ExploreP:0.0101\n",
      "Episode:1081 MeanR:219.2800 R:279.0 Loss:0.0874 ExploreP:0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1082 MeanR:221.7800 R:259.0 Loss:0.0697 ExploreP:0.0101\n",
      "Episode:1083 MeanR:224.3900 R:271.0 Loss:0.1949 ExploreP:0.0101\n",
      "Episode:1084 MeanR:226.8600 R:258.0 Loss:0.2219 ExploreP:0.0101\n",
      "Episode:1085 MeanR:229.2400 R:248.0 Loss:0.1185 ExploreP:0.0101\n",
      "Episode:1086 MeanR:232.0400 R:290.0 Loss:0.1346 ExploreP:0.0101\n",
      "Episode:1087 MeanR:234.6200 R:268.0 Loss:0.0807 ExploreP:0.0101\n",
      "Episode:1088 MeanR:237.2800 R:278.0 Loss:0.1643 ExploreP:0.0101\n",
      "Episode:1089 MeanR:239.8100 R:265.0 Loss:0.1839 ExploreP:0.0101\n",
      "Episode:1090 MeanR:242.6400 R:293.0 Loss:0.1806 ExploreP:0.0101\n",
      "Episode:1091 MeanR:245.6100 R:309.0 Loss:0.0952 ExploreP:0.0101\n",
      "Episode:1092 MeanR:248.6000 R:312.0 Loss:0.2360 ExploreP:0.0101\n",
      "Episode:1093 MeanR:251.8700 R:342.0 Loss:0.2912 ExploreP:0.0100\n",
      "Episode:1094 MeanR:255.2700 R:353.0 Loss:41.8954 ExploreP:0.0100\n",
      "Episode:1095 MeanR:259.0800 R:394.0 Loss:0.1994 ExploreP:0.0100\n",
      "Episode:1096 MeanR:261.7900 R:282.0 Loss:0.1449 ExploreP:0.0100\n",
      "Episode:1097 MeanR:264.4200 R:277.0 Loss:0.0543 ExploreP:0.0100\n",
      "Episode:1098 MeanR:267.8400 R:356.0 Loss:0.1343 ExploreP:0.0100\n",
      "Episode:1099 MeanR:270.5600 R:285.0 Loss:0.0797 ExploreP:0.0100\n",
      "Episode:1100 MeanR:274.0100 R:360.0 Loss:0.1215 ExploreP:0.0100\n",
      "Episode:1101 MeanR:277.3400 R:346.0 Loss:0.0914 ExploreP:0.0100\n",
      "Episode:1102 MeanR:280.7100 R:350.0 Loss:0.1312 ExploreP:0.0100\n",
      "Episode:1103 MeanR:279.9600 R:425.0 Loss:0.2293 ExploreP:0.0100\n",
      "Episode:1104 MeanR:278.1700 R:321.0 Loss:0.0543 ExploreP:0.0100\n",
      "Episode:1105 MeanR:278.1700 R:500.0 Loss:0.1917 ExploreP:0.0100\n",
      "Episode:1106 MeanR:278.0200 R:485.0 Loss:0.1387 ExploreP:0.0100\n",
      "Episode:1107 MeanR:276.9700 R:395.0 Loss:0.2144 ExploreP:0.0100\n",
      "Episode:1108 MeanR:275.5800 R:361.0 Loss:0.1658 ExploreP:0.0100\n",
      "Episode:1109 MeanR:276.5700 R:500.0 Loss:0.1462 ExploreP:0.0100\n",
      "Episode:1110 MeanR:277.2400 R:417.0 Loss:0.1732 ExploreP:0.0100\n",
      "Episode:1111 MeanR:278.8200 R:500.0 Loss:0.1889 ExploreP:0.0100\n",
      "Episode:1112 MeanR:281.0700 R:500.0 Loss:0.1498 ExploreP:0.0100\n",
      "Episode:1113 MeanR:283.5200 R:500.0 Loss:0.1181 ExploreP:0.0100\n",
      "Episode:1114 MeanR:286.0100 R:500.0 Loss:0.1413 ExploreP:0.0100\n",
      "Episode:1115 MeanR:287.1500 R:362.0 Loss:0.0789 ExploreP:0.0100\n",
      "Episode:1116 MeanR:289.8700 R:500.0 Loss:0.2007 ExploreP:0.0100\n",
      "Episode:1117 MeanR:291.0200 R:378.0 Loss:0.1087 ExploreP:0.0100\n",
      "Episode:1118 MeanR:293.3900 R:500.0 Loss:0.1373 ExploreP:0.0100\n",
      "Episode:1119 MeanR:295.6100 R:500.0 Loss:0.1394 ExploreP:0.0100\n",
      "Episode:1120 MeanR:297.7000 R:500.0 Loss:0.1905 ExploreP:0.0100\n",
      "Episode:1121 MeanR:299.1600 R:500.0 Loss:0.1445 ExploreP:0.0100\n",
      "Episode:1122 MeanR:300.4600 R:500.0 Loss:0.2121 ExploreP:0.0100\n",
      "Episode:1123 MeanR:301.6300 R:500.0 Loss:0.1604 ExploreP:0.0100\n",
      "Episode:1124 MeanR:303.9600 R:500.0 Loss:0.2725 ExploreP:0.0100\n",
      "Episode:1125 MeanR:306.3600 R:500.0 Loss:0.3095 ExploreP:0.0100\n",
      "Episode:1126 MeanR:308.9300 R:500.0 Loss:0.1773 ExploreP:0.0100\n",
      "Episode:1127 MeanR:311.6200 R:500.0 Loss:0.1938 ExploreP:0.0100\n",
      "Episode:1128 MeanR:314.5000 R:500.0 Loss:0.1290 ExploreP:0.0100\n",
      "Episode:1129 MeanR:317.2600 R:500.0 Loss:0.1688 ExploreP:0.0100\n",
      "Episode:1130 MeanR:320.2900 R:500.0 Loss:0.1443 ExploreP:0.0100\n",
      "Episode:1131 MeanR:323.4000 R:500.0 Loss:0.1825 ExploreP:0.0100\n",
      "Episode:1132 MeanR:326.6400 R:500.0 Loss:0.3293 ExploreP:0.0100\n",
      "Episode:1133 MeanR:329.9000 R:500.0 Loss:0.1338 ExploreP:0.0100\n",
      "Episode:1134 MeanR:333.1100 R:500.0 Loss:0.1555 ExploreP:0.0100\n",
      "Episode:1135 MeanR:336.1000 R:500.0 Loss:0.2270 ExploreP:0.0100\n",
      "Episode:1136 MeanR:339.0500 R:500.0 Loss:0.1164 ExploreP:0.0100\n",
      "Episode:1137 MeanR:341.5000 R:500.0 Loss:0.2083 ExploreP:0.0100\n",
      "Episode:1138 MeanR:344.0300 R:500.0 Loss:0.2074 ExploreP:0.0100\n",
      "Episode:1139 MeanR:346.4900 R:500.0 Loss:0.0857 ExploreP:0.0100\n",
      "Episode:1140 MeanR:348.6900 R:500.0 Loss:0.2008 ExploreP:0.0100\n",
      "Episode:1141 MeanR:351.2800 R:500.0 Loss:0.2065 ExploreP:0.0100\n",
      "Episode:1142 MeanR:353.4600 R:500.0 Loss:0.1833 ExploreP:0.0100\n",
      "Episode:1143 MeanR:355.8200 R:500.0 Loss:0.2218 ExploreP:0.0100\n",
      "Episode:1144 MeanR:358.4100 R:500.0 Loss:0.0929 ExploreP:0.0100\n",
      "Episode:1145 MeanR:360.7500 R:500.0 Loss:0.1793 ExploreP:0.0100\n",
      "Episode:1146 MeanR:363.2500 R:500.0 Loss:0.1384 ExploreP:0.0100\n",
      "Episode:1147 MeanR:365.5700 R:500.0 Loss:0.1096 ExploreP:0.0100\n",
      "Episode:1148 MeanR:368.3000 R:500.0 Loss:0.0836 ExploreP:0.0100\n",
      "Episode:1149 MeanR:370.8600 R:500.0 Loss:0.2588 ExploreP:0.0100\n",
      "Episode:1150 MeanR:372.6700 R:500.0 Loss:0.2212 ExploreP:0.0100\n",
      "Episode:1151 MeanR:375.1100 R:500.0 Loss:0.0452 ExploreP:0.0100\n",
      "Episode:1152 MeanR:377.2900 R:500.0 Loss:0.0286 ExploreP:0.0100\n",
      "Episode:1153 MeanR:379.9200 R:500.0 Loss:0.1296 ExploreP:0.0100\n",
      "Episode:1154 MeanR:382.4700 R:500.0 Loss:0.1406 ExploreP:0.0100\n",
      "Episode:1155 MeanR:384.9500 R:500.0 Loss:0.1809 ExploreP:0.0100\n",
      "Episode:1156 MeanR:387.9000 R:500.0 Loss:0.1174 ExploreP:0.0100\n",
      "Episode:1157 MeanR:390.1400 R:500.0 Loss:0.0411 ExploreP:0.0100\n",
      "Episode:1158 MeanR:392.7200 R:500.0 Loss:0.0775 ExploreP:0.0100\n",
      "Episode:1159 MeanR:395.0800 R:500.0 Loss:0.1412 ExploreP:0.0100\n",
      "Episode:1160 MeanR:397.9400 R:500.0 Loss:0.2043 ExploreP:0.0100\n",
      "Episode:1161 MeanR:400.6800 R:500.0 Loss:0.0381 ExploreP:0.0100\n",
      "Episode:1162 MeanR:403.4500 R:500.0 Loss:0.0905 ExploreP:0.0100\n",
      "Episode:1163 MeanR:405.8200 R:500.0 Loss:387.3963 ExploreP:0.0100\n",
      "Episode:1164 MeanR:408.7900 R:500.0 Loss:0.0880 ExploreP:0.0100\n",
      "Episode:1165 MeanR:411.2700 R:500.0 Loss:0.0818 ExploreP:0.0100\n",
      "Episode:1166 MeanR:413.6900 R:500.0 Loss:0.1344 ExploreP:0.0100\n",
      "Episode:1167 MeanR:416.4100 R:500.0 Loss:0.2541 ExploreP:0.0100\n",
      "Episode:1168 MeanR:419.1000 R:500.0 Loss:0.0811 ExploreP:0.0100\n",
      "Episode:1169 MeanR:421.6200 R:500.0 Loss:0.0367 ExploreP:0.0100\n",
      "Episode:1170 MeanR:424.3000 R:500.0 Loss:0.1028 ExploreP:0.0100\n",
      "Episode:1171 MeanR:426.4900 R:500.0 Loss:0.2851 ExploreP:0.0100\n",
      "Episode:1172 MeanR:429.2800 R:500.0 Loss:0.1113 ExploreP:0.0100\n",
      "Episode:1173 MeanR:431.9100 R:500.0 Loss:0.1295 ExploreP:0.0100\n",
      "Episode:1174 MeanR:434.0800 R:500.0 Loss:0.1156 ExploreP:0.0100\n",
      "Episode:1175 MeanR:436.1200 R:500.0 Loss:0.1033 ExploreP:0.0100\n",
      "Episode:1176 MeanR:438.6400 R:500.0 Loss:0.3163 ExploreP:0.0100\n",
      "Episode:1177 MeanR:440.6800 R:500.0 Loss:0.1798 ExploreP:0.0100\n",
      "Episode:1178 MeanR:443.2700 R:500.0 Loss:0.1399 ExploreP:0.0100\n",
      "Episode:1179 MeanR:445.8700 R:500.0 Loss:0.2266 ExploreP:0.0100\n",
      "Episode:1180 MeanR:448.1900 R:500.0 Loss:0.0658 ExploreP:0.0100\n",
      "Episode:1181 MeanR:450.4000 R:500.0 Loss:0.1166 ExploreP:0.0100\n",
      "Episode:1182 MeanR:452.8100 R:500.0 Loss:0.0588 ExploreP:0.0100\n",
      "Episode:1183 MeanR:455.1000 R:500.0 Loss:0.0767 ExploreP:0.0100\n",
      "Episode:1184 MeanR:457.5200 R:500.0 Loss:0.0920 ExploreP:0.0100\n",
      "Episode:1185 MeanR:460.0400 R:500.0 Loss:0.0898 ExploreP:0.0100\n",
      "Episode:1186 MeanR:462.1400 R:500.0 Loss:0.1786 ExploreP:0.0100\n",
      "Episode:1187 MeanR:464.4600 R:500.0 Loss:0.1634 ExploreP:0.0100\n",
      "Episode:1188 MeanR:466.6800 R:500.0 Loss:0.2114 ExploreP:0.0100\n",
      "Episode:1189 MeanR:469.0300 R:500.0 Loss:0.1071 ExploreP:0.0100\n",
      "Episode:1190 MeanR:471.1000 R:500.0 Loss:0.0732 ExploreP:0.0100\n",
      "Episode:1191 MeanR:473.0100 R:500.0 Loss:0.1797 ExploreP:0.0100\n",
      "Episode:1192 MeanR:474.8900 R:500.0 Loss:0.2245 ExploreP:0.0100\n",
      "Episode:1193 MeanR:476.4700 R:500.0 Loss:0.0939 ExploreP:0.0100\n",
      "Episode:1194 MeanR:477.9400 R:500.0 Loss:0.0592 ExploreP:0.0100\n",
      "Episode:1195 MeanR:479.0000 R:500.0 Loss:0.2096 ExploreP:0.0100\n",
      "Episode:1196 MeanR:481.1800 R:500.0 Loss:0.0908 ExploreP:0.0100\n",
      "Episode:1197 MeanR:483.4100 R:500.0 Loss:0.0442 ExploreP:0.0100\n",
      "Episode:1198 MeanR:484.8500 R:500.0 Loss:0.1039 ExploreP:0.0100\n",
      "Episode:1199 MeanR:487.0000 R:500.0 Loss:0.0540 ExploreP:0.0100\n",
      "Episode:1200 MeanR:488.4000 R:500.0 Loss:0.0599 ExploreP:0.0100\n",
      "Episode:1201 MeanR:489.9400 R:500.0 Loss:0.1018 ExploreP:0.0100\n",
      "Episode:1202 MeanR:491.4400 R:500.0 Loss:0.1056 ExploreP:0.0100\n",
      "Episode:1203 MeanR:492.1900 R:500.0 Loss:0.0646 ExploreP:0.0100\n",
      "Episode:1204 MeanR:493.9800 R:500.0 Loss:0.1192 ExploreP:0.0100\n",
      "Episode:1205 MeanR:493.9800 R:500.0 Loss:0.0376 ExploreP:0.0100\n",
      "Episode:1206 MeanR:494.1300 R:500.0 Loss:371.3622 ExploreP:0.0100\n",
      "Episode:1207 MeanR:495.1800 R:500.0 Loss:0.0696 ExploreP:0.0100\n",
      "Episode:1208 MeanR:496.5700 R:500.0 Loss:0.0822 ExploreP:0.0100\n",
      "Episode:1209 MeanR:496.5700 R:500.0 Loss:0.1103 ExploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1210 MeanR:497.4000 R:500.0 Loss:0.1618 ExploreP:0.0100\n",
      "Episode:1211 MeanR:497.4000 R:500.0 Loss:0.1944 ExploreP:0.0100\n",
      "Episode:1212 MeanR:497.4000 R:500.0 Loss:0.0593 ExploreP:0.0100\n",
      "Episode:1213 MeanR:497.4000 R:500.0 Loss:0.0813 ExploreP:0.0100\n",
      "Episode:1214 MeanR:497.4000 R:500.0 Loss:0.0795 ExploreP:0.0100\n",
      "Episode:1215 MeanR:498.7800 R:500.0 Loss:0.0614 ExploreP:0.0100\n",
      "Episode:1216 MeanR:498.7800 R:500.0 Loss:0.1034 ExploreP:0.0100\n",
      "Episode:1217 MeanR:500.0000 R:500.0 Loss:0.1244 ExploreP:0.0100\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "episode_rewards_list = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    episode_reward = deque(maxlen=100) # running average    \n",
    "    total_step = 0\n",
    "    \n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        state = env.reset()\n",
    "        \n",
    "        while True:\n",
    "            # env.render() #to watch the training\n",
    "            # Explore or Exploit\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits,\n",
    "                                         feed_dict={model.inputs: state.reshape([1, -1])})\n",
    "                                          #feed_dict={model.inputs: state.reshape([1, *state.shape])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.add([state, action, reward, next_state, float(done)])\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict={model.inputs: next_states})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt],\n",
    "                               feed_dict={model.inputs: states,\n",
    "                                          model.targetQs: targetQs,\n",
    "                                          model.actions: actions})\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        # After each episode\n",
    "        episode_reward.append(total_reward)\n",
    "        episode_rewards_list.append((ep, np.mean(episode_reward)))\n",
    "        rewards_list.append((ep, total_reward))\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'MeanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'Loss:{:.4f}'.format(loss),\n",
    "              'ExploreP:{:.4f}'.format(explore_p))\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # save the model at the end of all training episodes\n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total Reward')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cartpole.ckpt\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, \n",
    "                           feed_dict={model.inputs: state.reshape([1, -1])})\n",
    "                           #feed_dict={model.inputs: state.reshape((1, *state.shape))})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        print('total_reward:{}'.format(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep cortical reinforcement learning: Policy gradients + Q-learning + GAN\n",
    "\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "batch = []\n",
    "for _ in range(1111):\n",
    "    #env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    batch.append([action, state, reward, done, info])\n",
    "    #print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4,), (4,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], \n",
    "batch[0][1].shape, state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "actions = np.array([each[0] for each in batch])\n",
    "states = np.array([each[1] for each in batch])\n",
    "rewards = np.array([each[2] for each in batch])\n",
    "dones = np.array([each[3] for each in batch])\n",
    "infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (1111,) (1111, 4) (1111,) (1111,)\n",
      "dtypes: float64 float64 int64 bool\n",
      "states: 2.4041488323398097 -2.748127398357479\n",
      "actions: 1 0\n",
      "rewards: 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# print(rewards[-20:])\n",
    "print('shapes:', np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print('dtypes:', np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print('states:', np.max(np.array(states)), np.min(np.array(states)))\n",
    "print('actions:', np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print('rewards:', np.max(np.array(rewards)), np.min(np.array(rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7310585786300049, 0.7310585786300049)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.max(np.array(rewards))), sigmoid(np.min(np.array(rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards: 0.01 0.01\n"
     ]
    }
   ],
   "source": [
    "print('rewards:', np.max(np.array(rewards))/100, np.min(np.array(rewards))/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    reward = tf.placeholder(tf.float32, [], name='reward')\n",
    "    # GRU: Gated Recurrent Units\n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size) # hidden size\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    g_initial_state = cell.zero_state(batch_size, tf.float32) # feedback or lateral/recurrent connection from output\n",
    "    d_initial_state = cell.zero_state(batch_size, tf.float32) # feedback or lateral/recurrent connection from output\n",
    "    return states, actions, targetQs, reward, cell, g_initial_state, d_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use batch-norm\n",
    "#   x_norm = tf.layers.batch_normalization(x, training=training)\n",
    "\n",
    "#   # ...\n",
    "\n",
    "#   update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "#   with tf.control_dependencies(update_ops):\n",
    "#     train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training: Either a Python boolean, or a TensorFlow boolean scalar tensor (e.g. a placeholder). \n",
    "# Whether to return the output in: \n",
    "# training mode (normalized with statistics of the current batch) or \n",
    "# inference mode (normalized with moving statistics). \n",
    "# NOTE: make sure to set this parameter correctly, or else your training/inference will not work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP & Conv\n",
    "# # Generator/Controller: Generating/prediting the actions\n",
    "# def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "#     with tf.variable_scope('generator', reuse=reuse):\n",
    "#         # First fully connected layer\n",
    "#         h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "#         bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "#         nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "#         # Second fully connected layer\n",
    "#         h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "#         bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "#         nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "#         # Output layer\n",
    "#         logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "#         #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "#         # return actions logits\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP & Conv\n",
    "# # Discriminator/Dopamine: Reward function/planner/naviator/advisor/supervisor/cortical columns\n",
    "# def discriminator(states, actions, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "#     with tf.variable_scope('discriminator', reuse=reuse):\n",
    "#         # Fusion/merge states and actions/ SA/ SM\n",
    "#         x_fused = tf.concat(axis=1, values=[states, actions])\n",
    "        \n",
    "#         # First fully connected layer\n",
    "#         h1 = tf.layers.dense(inputs=x_fused, units=hidden_size)\n",
    "#         bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "#         nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "#         # Second fully connected layer\n",
    "#         h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "#         bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "#         nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "#         # Output layer\n",
    "#         logits = tf.layers.dense(inputs=nl2, units=1)        \n",
    "#         #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "#         # return rewards logits\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def discriminator(states, actions, initial_state, cell, lstm_size, reuse=False): \n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Fusion/merge states and actions/ SA/ SM\n",
    "        x_fused = tf.concat(axis=1, values=[states, actions])\n",
    "        \n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=x_fused, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=1)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, actions, targetQs, reward,\n",
    "               cell, g_initial_state, d_initial_state):\n",
    "    # G/Actor\n",
    "    #actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_logits, g_final_state = generator(states=states, num_classes=action_size, \n",
    "                                              cell=cell, initial_state=g_initial_state, lstm_size=hidden_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    neg_log_prob_actions = tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                      labels=actions_labels)\n",
    "    g_loss = tf.reduce_mean(neg_log_prob_actions * targetQs)\n",
    "    \n",
    "    # D/Critic\n",
    "    #Qs_logits = discriminator(actions=actions_logits, hidden_size=hidden_size, states=states)\n",
    "    Qs_logits, d_final_state = discriminator(states=states, actions=actions_logits, \n",
    "                                             cell=cell, initial_state=d_initial_state, lstm_size=hidden_size)\n",
    "    rewards = reward * tf.ones_like(targetQs)\n",
    "    d_lossR = tf.reduce_mean(tf.square(tf.nn.sigmoid(tf.reshape(Qs_logits, [-1])) - rewards))\n",
    "    d_lossR_sigm = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.reshape(Qs_logits, [-1]),\n",
    "                                                                          labels=rewards))\n",
    "    d_lossQ = tf.reduce_mean(tf.square(tf.reshape(Qs_logits, [-1]) - targetQs))\n",
    "    d_lossQ_sigm = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.reshape(Qs_logits, [-1]),\n",
    "                                                                          labels=tf.nn.sigmoid(targetQs)))\n",
    "    d_loss = d_lossQ_sigm + d_lossQ #+ d_lossR_sigm + d_lossR\n",
    "\n",
    "    return actions_logits, Qs_logits, g_final_state, d_final_state, g_loss, d_loss, d_lossR, d_lossQ, d_lossR_sigm, d_lossQ_sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizating/training/learning G & D\n",
    "def model_opt(g_loss, d_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param g_loss: Generator loss Tensor for action prediction\n",
    "    :param d_loss: Discriminator loss Tensor for reward prediction for generated/prob/logits action\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize RNN\n",
    "    # g_grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(g_loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    # d_grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(d_loss, d_vars), clip_norm=5) # usually around 1-5\n",
    "    g_grads=tf.gradients(g_loss, g_vars)\n",
    "    d_grads=tf.gradients(d_loss, d_vars)\n",
    "    g_opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(g_grads, g_vars))\n",
    "    d_opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(d_grads, d_vars))\n",
    "    \n",
    "    # # Optimize MLP & CNN\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    #     g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "    #     d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, self.reward, cell, self.g_initial_state, self.d_initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.Qs_logits, self.g_final_state, self.d_final_state, self.g_loss, self.d_loss, self.d_lossR, self.d_lossQ, self.d_lossR_sigm, self.d_lossQ_sigm = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size,\n",
    "            states=self.states, actions=self.actions, cell=cell,\n",
    "            targetQs=self.targetQs, reward=self.reward,  \n",
    "            g_initial_state=self.g_initial_state, d_initial_state=self.d_initial_state)\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_opt, self.d_opt = model_opt(g_loss=self.g_loss, d_loss=self.d_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size:(1111, 4) actions:(1111,)\n",
      "action size:2\n"
     ]
    }
   ],
   "source": [
    "print('state size:{}'.format(states.shape), \n",
    "      'actions:{}'.format(actions.shape)) \n",
    "print('action size:{}'.format(np.max(actions) - np.min(actions)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation\n",
    "batch_size = 32                # number of samples in the memory/ experience as mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n",
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.01858505, -0.01960784,  0.02470401, -0.02137975]),\n",
       " 0,\n",
       " array([ 0.01819289, -0.21507521,  0.02427642,  0.27899407]),\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:25.0000 rate:0.0500 gloss:0.6189 dloss:1.6211 dlossR:0.1952 dlossQsigm:0.6357\n",
      "Episode:1 meanR:32.5000 rate:0.0800 gloss:0.2741 dloss:1.3121 dlossR:0.0352 dlossQsigm:0.3193\n",
      "Episode:2 meanR:36.3333 rate:0.0880 gloss:0.0562 dloss:2.3809 dlossR:0.0001 dlossQsigm:0.0698\n",
      "Episode:3 meanR:33.0000 rate:0.0460 gloss:0.0637 dloss:4.8319 dlossR:0.0000 dlossQsigm:0.1474\n",
      "Episode:4 meanR:34.0000 rate:0.0760 gloss:0.0816 dloss:4.9760 dlossR:0.0000 dlossQsigm:0.0999\n",
      "Episode:5 meanR:35.5000 rate:0.0860 gloss:0.5439 dloss:6.5101 dlossR:0.0000 dlossQsigm:0.1182\n",
      "Episode:6 meanR:35.0000 rate:0.0640 gloss:0.6628 dloss:10.0301 dlossR:0.0001 dlossQsigm:0.1458\n",
      "Episode:7 meanR:35.3750 rate:0.0760 gloss:0.2767 dloss:11.8986 dlossR:0.0000 dlossQsigm:0.1602\n",
      "Episode:8 meanR:35.6667 rate:0.0760 gloss:0.2681 dloss:13.1699 dlossR:0.0000 dlossQsigm:0.1671\n",
      "Episode:9 meanR:35.9000 rate:0.0760 gloss:0.6855 dloss:16.0877 dlossR:0.0000 dlossQsigm:0.1885\n",
      "Episode:10 meanR:38.5455 rate:0.1300 gloss:0.5599 dloss:20.0611 dlossR:0.0000 dlossQsigm:0.2144\n",
      "Episode:11 meanR:37.8333 rate:0.0600 gloss:0.4052 dloss:37.1748 dlossR:0.0000 dlossQsigm:0.4215\n",
      "Episode:12 meanR:37.3077 rate:0.0620 gloss:0.3373 dloss:26.5122 dlossR:0.0000 dlossQsigm:0.3515\n",
      "Episode:13 meanR:36.9286 rate:0.0640 gloss:0.4791 dloss:5.9763 dlossR:0.0015 dlossQsigm:0.0689\n",
      "Episode:14 meanR:37.0000 rate:0.0760 gloss:0.1530 dloss:5.9225 dlossR:0.0393 dlossQsigm:0.2269\n",
      "Episode:15 meanR:37.1875 rate:0.0800 gloss:0.2756 dloss:4.7917 dlossR:0.0000 dlossQsigm:0.0982\n",
      "Episode:16 meanR:37.5882 rate:0.0880 gloss:0.1265 dloss:3.2061 dlossR:0.0000 dlossQsigm:0.0705\n",
      "Episode:17 meanR:39.6111 rate:0.1480 gloss:0.1050 dloss:4.9699 dlossR:0.0000 dlossQsigm:0.0881\n",
      "Episode:18 meanR:39.3158 rate:0.0680 gloss:0.6298 dloss:5.0799 dlossR:0.0000 dlossQsigm:0.0608\n",
      "Episode:19 meanR:39.1000 rate:0.0700 gloss:0.0448 dloss:17.9345 dlossR:0.3137 dlossQsigm:0.6276\n",
      "Episode:20 meanR:38.8095 rate:0.0660 gloss:0.1270 dloss:3.7488 dlossR:0.0346 dlossQsigm:0.1361\n",
      "Episode:21 meanR:39.0909 rate:0.0900 gloss:0.0947 dloss:2.2439 dlossR:0.0002 dlossQsigm:0.0310\n",
      "Episode:22 meanR:46.0870 rate:0.4000 gloss:0.3570 dloss:54.8651 dlossR:0.0000 dlossQsigm:0.3517\n",
      "Episode:23 meanR:47.8750 rate:0.1780 gloss:0.1622 dloss:41.6373 dlossR:0.0000 dlossQsigm:0.3077\n",
      "Episode:24 meanR:47.6800 rate:0.0860 gloss:0.0152 dloss:12.6589 dlossR:0.0000 dlossQsigm:0.1005\n",
      "Episode:25 meanR:49.1154 rate:0.1700 gloss:0.0091 dloss:34.1514 dlossR:0.0000 dlossQsigm:0.2748\n",
      "Episode:26 meanR:48.6296 rate:0.0720 gloss:0.1273 dloss:5.6069 dlossR:0.0128 dlossQsigm:0.1180\n",
      "Episode:27 meanR:51.2500 rate:0.2440 gloss:0.1331 dloss:5.1422 dlossR:0.0137 dlossQsigm:0.1637\n",
      "Episode:28 meanR:51.8276 rate:0.1360 gloss:0.1061 dloss:9.6028 dlossR:0.0288 dlossQsigm:0.3287\n",
      "Episode:29 meanR:51.2667 rate:0.0700 gloss:0.0022 dloss:10.7543 dlossR:0.0970 dlossQsigm:0.2759\n",
      "Episode:30 meanR:50.7419 rate:0.0700 gloss:0.0496 dloss:5.7029 dlossR:0.0309 dlossQsigm:0.2605\n",
      "Episode:31 meanR:50.1875 rate:0.0660 gloss:0.0092 dloss:5.3237 dlossR:0.0316 dlossQsigm:0.2287\n",
      "Episode:32 meanR:50.7576 rate:0.1380 gloss:0.0145 dloss:3.3735 dlossR:0.0048 dlossQsigm:0.0743\n",
      "Episode:33 meanR:50.4706 rate:0.0820 gloss:0.0163 dloss:6.1380 dlossR:0.0440 dlossQsigm:0.3372\n",
      "Episode:34 meanR:50.2286 rate:0.0840 gloss:0.0007 dloss:3.2560 dlossR:0.0399 dlossQsigm:0.1802\n",
      "Episode:35 meanR:50.3889 rate:0.1120 gloss:0.0017 dloss:3.3601 dlossR:0.0094 dlossQsigm:0.1043\n",
      "Episode:36 meanR:50.6216 rate:0.1180 gloss:0.0002 dloss:1.4250 dlossR:0.0021 dlossQsigm:0.0374\n",
      "Episode:37 meanR:50.2895 rate:0.0760 gloss:0.0008 dloss:1.2466 dlossR:0.0131 dlossQsigm:0.0914\n",
      "Episode:38 meanR:50.0000 rate:0.0780 gloss:0.0006 dloss:2.2003 dlossR:0.0300 dlossQsigm:0.1492\n",
      "Episode:39 meanR:49.5250 rate:0.0620 gloss:0.0006 dloss:3.6047 dlossR:0.0374 dlossQsigm:0.1773\n",
      "Episode:40 meanR:49.5122 rate:0.0980 gloss:0.0010 dloss:1.5927 dlossR:0.0000 dlossQsigm:0.0462\n",
      "Episode:41 meanR:49.5714 rate:0.1040 gloss:0.0052 dloss:4.1223 dlossR:0.0000 dlossQsigm:0.0758\n",
      "Episode:42 meanR:49.4419 rate:0.0880 gloss:0.0014 dloss:5.1990 dlossR:0.0179 dlossQsigm:0.1805\n",
      "Episode:43 meanR:49.2727 rate:0.0840 gloss:0.0098 dloss:3.3589 dlossR:0.0000 dlossQsigm:0.0558\n",
      "Episode:44 meanR:48.8889 rate:0.0640 gloss:0.0151 dloss:9.2075 dlossR:0.0000 dlossQsigm:0.0353\n",
      "Episode:45 meanR:48.9565 rate:0.1040 gloss:0.0209 dloss:1.8847 dlossR:0.0000 dlossQsigm:0.0366\n",
      "Episode:46 meanR:48.5745 rate:0.0620 gloss:0.0245 dloss:2.5122 dlossR:0.0116 dlossQsigm:0.1210\n",
      "Episode:47 meanR:48.1458 rate:0.0560 gloss:0.0316 dloss:11.0945 dlossR:0.0135 dlossQsigm:0.4855\n",
      "Episode:48 meanR:47.7755 rate:0.0600 gloss:0.0137 dloss:3.5174 dlossR:0.0314 dlossQsigm:0.2579\n",
      "Episode:49 meanR:47.4600 rate:0.0640 gloss:0.0023 dloss:13.2315 dlossR:0.0024 dlossQsigm:0.0649\n",
      "Episode:50 meanR:47.4706 rate:0.0960 gloss:0.0003 dloss:3.2848 dlossR:0.0000 dlossQsigm:0.0563\n",
      "Episode:51 meanR:47.1346 rate:0.0600 gloss:0.0152 dloss:1.7580 dlossR:0.0066 dlossQsigm:0.1178\n",
      "Episode:52 meanR:46.7736 rate:0.0560 gloss:0.0009 dloss:1.9504 dlossR:0.0277 dlossQsigm:0.1532\n",
      "Episode:53 meanR:46.4259 rate:0.0560 gloss:0.0054 dloss:3.3235 dlossR:0.0331 dlossQsigm:0.1919\n",
      "Episode:54 meanR:46.2000 rate:0.0680 gloss:0.0002 dloss:2.6606 dlossR:0.0001 dlossQsigm:0.0369\n",
      "Episode:55 meanR:45.9821 rate:0.0680 gloss:0.0006 dloss:1.8788 dlossR:0.0261 dlossQsigm:0.1360\n",
      "Episode:56 meanR:45.7193 rate:0.0620 gloss:0.0009 dloss:2.0212 dlossR:0.0525 dlossQsigm:0.1740\n",
      "Episode:57 meanR:45.7931 rate:0.1000 gloss:0.0061 dloss:4.4598 dlossR:0.0064 dlossQsigm:0.0818\n",
      "Episode:58 meanR:45.7288 rate:0.0840 gloss:0.0005 dloss:1.4809 dlossR:0.0000 dlossQsigm:0.0522\n",
      "Episode:59 meanR:45.4000 rate:0.0520 gloss:0.0019 dloss:2.2664 dlossR:0.0009 dlossQsigm:0.0923\n",
      "Episode:60 meanR:45.2459 rate:0.0720 gloss:0.0017 dloss:1.5779 dlossR:0.0455 dlossQsigm:0.1908\n",
      "Episode:61 meanR:45.8387 rate:0.1640 gloss:0.0206 dloss:6.7536 dlossR:0.0000 dlossQsigm:0.0853\n",
      "Episode:62 meanR:45.5397 rate:0.0540 gloss:0.0022 dloss:2.5499 dlossR:0.0052 dlossQsigm:0.1075\n",
      "Episode:63 meanR:47.8906 rate:0.3920 gloss:0.0155 dloss:3.9004 dlossR:0.0511 dlossQsigm:0.2385\n",
      "Episode:64 meanR:48.3385 rate:0.1540 gloss:0.0021 dloss:6.7551 dlossR:0.0000 dlossQsigm:0.0555\n",
      "Episode:65 meanR:48.1818 rate:0.0760 gloss:0.0050 dloss:4.4835 dlossR:0.0461 dlossQsigm:0.2585\n",
      "Episode:66 meanR:48.0448 rate:0.0780 gloss:0.0543 dloss:2.8096 dlossR:0.0266 dlossQsigm:0.1464\n",
      "Episode:67 meanR:47.9118 rate:0.0780 gloss:0.0022 dloss:2.6307 dlossR:0.0392 dlossQsigm:0.2034\n",
      "Episode:68 meanR:49.4928 rate:0.3140 gloss:0.0011 dloss:6.6558 dlossR:0.0000 dlossQsigm:0.0502\n",
      "Episode:69 meanR:49.2857 rate:0.0700 gloss:0.0002 dloss:3.0415 dlossR:0.0195 dlossQsigm:0.1199\n",
      "Episode:70 meanR:49.4930 rate:0.1280 gloss:0.0017 dloss:4.5133 dlossR:0.0022 dlossQsigm:0.0614\n",
      "Episode:71 meanR:49.2917 rate:0.0700 gloss:0.0071 dloss:9.0595 dlossR:0.0306 dlossQsigm:0.2225\n",
      "Episode:72 meanR:49.4110 rate:0.1160 gloss:0.0043 dloss:8.5685 dlossR:0.0631 dlossQsigm:0.2397\n",
      "Episode:73 meanR:49.4459 rate:0.1040 gloss:0.0004 dloss:3.3940 dlossR:0.0038 dlossQsigm:0.0782\n",
      "Episode:74 meanR:49.3600 rate:0.0860 gloss:0.0001 dloss:1.6667 dlossR:0.0169 dlossQsigm:0.0858\n",
      "Episode:75 meanR:49.1184 rate:0.0620 gloss:0.0001 dloss:2.8153 dlossR:0.0385 dlossQsigm:0.1621\n",
      "Episode:76 meanR:49.1688 rate:0.1060 gloss:0.0076 dloss:2.2095 dlossR:0.0000 dlossQsigm:0.0446\n",
      "Episode:77 meanR:48.9231 rate:0.0600 gloss:0.0036 dloss:1.9570 dlossR:0.0004 dlossQsigm:0.0854\n",
      "Episode:78 meanR:48.8608 rate:0.0880 gloss:0.0091 dloss:2.3114 dlossR:0.0003 dlossQsigm:0.0522\n",
      "Episode:79 meanR:48.6250 rate:0.0600 gloss:0.0022 dloss:1.8484 dlossR:0.0022 dlossQsigm:0.0968\n",
      "Episode:80 meanR:48.6914 rate:0.1080 gloss:0.0019 dloss:3.6372 dlossR:0.0002 dlossQsigm:0.0478\n",
      "Episode:81 meanR:48.5244 rate:0.0700 gloss:0.0005 dloss:3.3544 dlossR:0.0000 dlossQsigm:0.0608\n",
      "Episode:82 meanR:48.5301 rate:0.0980 gloss:0.0060 dloss:6.6960 dlossR:0.0122 dlossQsigm:0.1305\n",
      "Episode:83 meanR:48.5357 rate:0.0980 gloss:0.0002 dloss:3.4767 dlossR:0.0227 dlossQsigm:0.1625\n",
      "Episode:84 meanR:48.4471 rate:0.0820 gloss:0.0005 dloss:3.0178 dlossR:0.0109 dlossQsigm:0.1155\n",
      "Episode:85 meanR:48.4186 rate:0.0920 gloss:0.0012 dloss:9.4593 dlossR:0.0003 dlossQsigm:0.0399\n",
      "Episode:86 meanR:48.3678 rate:0.0880 gloss:0.0001 dloss:2.6177 dlossR:0.0000 dlossQsigm:0.0520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:87 meanR:48.3409 rate:0.0920 gloss:0.0012 dloss:15.3593 dlossR:0.0000 dlossQsigm:0.0937\n",
      "Episode:88 meanR:48.1461 rate:0.0620 gloss:0.0472 dloss:7.8674 dlossR:0.0000 dlossQsigm:0.1652\n",
      "Episode:89 meanR:47.9556 rate:0.0620 gloss:0.0000 dloss:4.5460 dlossR:0.0000 dlossQsigm:0.1332\n",
      "Episode:90 meanR:47.7802 rate:0.0640 gloss:0.0005 dloss:8.5777 dlossR:0.0000 dlossQsigm:0.0451\n",
      "Episode:91 meanR:47.7609 rate:0.0920 gloss:0.0026 dloss:3.1801 dlossR:0.0000 dlossQsigm:0.0476\n",
      "Episode:92 meanR:47.7634 rate:0.0960 gloss:0.0046 dloss:4.6769 dlossR:0.0000 dlossQsigm:0.0439\n",
      "Episode:93 meanR:47.6809 rate:0.0800 gloss:0.0001 dloss:6.1572 dlossR:0.0828 dlossQsigm:0.2780\n",
      "Episode:94 meanR:47.5158 rate:0.0640 gloss:0.0021 dloss:11.7020 dlossR:0.0001 dlossQsigm:0.0440\n",
      "Episode:95 meanR:47.5833 rate:0.1080 gloss:0.0053 dloss:15.4754 dlossR:0.0000 dlossQsigm:0.0654\n",
      "Episode:96 meanR:47.4948 rate:0.0780 gloss:0.0012 dloss:6.1742 dlossR:0.0000 dlossQsigm:0.0510\n",
      "Episode:97 meanR:47.4082 rate:0.0780 gloss:0.0006 dloss:2.5890 dlossR:0.0111 dlossQsigm:0.0920\n",
      "Episode:98 meanR:47.2323 rate:0.0600 gloss:0.0558 dloss:4.2564 dlossR:0.0036 dlossQsigm:0.1116\n",
      "Episode:99 meanR:47.1000 rate:0.0680 gloss:0.0032 dloss:2.2538 dlossR:0.0015 dlossQsigm:0.0517\n",
      "Episode:100 meanR:47.1300 rate:0.0560 gloss:0.0009 dloss:2.7188 dlossR:0.0026 dlossQsigm:0.0915\n",
      "Episode:101 meanR:47.1500 rate:0.0840 gloss:0.0038 dloss:2.3271 dlossR:0.0042 dlossQsigm:0.0721\n",
      "Episode:102 meanR:47.2500 rate:0.1080 gloss:0.0009 dloss:3.5791 dlossR:0.0000 dlossQsigm:0.0612\n",
      "Episode:103 meanR:47.3100 rate:0.0580 gloss:0.0029 dloss:5.0847 dlossR:0.0000 dlossQsigm:0.1183\n",
      "Episode:104 meanR:47.4700 rate:0.1080 gloss:0.0005 dloss:4.5798 dlossR:0.0000 dlossQsigm:0.0862\n",
      "Episode:105 meanR:47.4500 rate:0.0820 gloss:0.0000 dloss:3.9696 dlossR:0.0000 dlossQsigm:0.0558\n",
      "Episode:106 meanR:47.5100 rate:0.0760 gloss:0.0004 dloss:7.4691 dlossR:0.0000 dlossQsigm:0.0484\n",
      "Episode:107 meanR:47.9000 rate:0.1540 gloss:0.0007 dloss:6.6601 dlossR:0.0001 dlossQsigm:0.0626\n",
      "Episode:108 meanR:47.8200 rate:0.0600 gloss:0.0007 dloss:2.6420 dlossR:0.0000 dlossQsigm:0.0927\n",
      "Episode:109 meanR:47.9000 rate:0.0920 gloss:0.0019 dloss:3.2032 dlossR:0.0017 dlossQsigm:0.0750\n",
      "Episode:110 meanR:47.5400 rate:0.0580 gloss:0.0003 dloss:3.3278 dlossR:0.0016 dlossQsigm:0.0839\n",
      "Episode:111 meanR:47.8900 rate:0.1300 gloss:0.0018 dloss:17.2704 dlossR:0.0000 dlossQsigm:0.1297\n",
      "Episode:112 meanR:48.0900 rate:0.1020 gloss:0.0032 dloss:4.2272 dlossR:0.0026 dlossQsigm:0.0588\n",
      "Episode:113 meanR:48.2700 rate:0.1000 gloss:0.0019 dloss:3.5221 dlossR:0.0322 dlossQsigm:0.1534\n",
      "Episode:114 meanR:48.1900 rate:0.0600 gloss:0.0003 dloss:2.4724 dlossR:0.0340 dlossQsigm:0.1865\n",
      "Episode:115 meanR:48.1400 rate:0.0700 gloss:0.0019 dloss:0.7814 dlossR:0.0032 dlossQsigm:0.0495\n",
      "Episode:116 meanR:48.1100 rate:0.0820 gloss:0.0016 dloss:1.6671 dlossR:0.0001 dlossQsigm:0.0378\n",
      "Episode:117 meanR:47.7100 rate:0.0680 gloss:0.0029 dloss:1.3802 dlossR:0.0015 dlossQsigm:0.0449\n",
      "Episode:118 meanR:47.9200 rate:0.1100 gloss:0.0001 dloss:3.0509 dlossR:0.0001 dlossQsigm:0.0493\n",
      "Episode:119 meanR:47.9200 rate:0.0700 gloss:0.0028 dloss:2.1204 dlossR:0.0001 dlossQsigm:0.0462\n",
      "Episode:120 meanR:48.1000 rate:0.1020 gloss:0.0011 dloss:2.4048 dlossR:0.0001 dlossQsigm:0.0517\n",
      "Episode:121 meanR:48.4500 rate:0.1600 gloss:0.0091 dloss:3.0019 dlossR:0.0000 dlossQsigm:0.0529\n",
      "Episode:122 meanR:47.1200 rate:0.1340 gloss:0.0201 dloss:1.5377 dlossR:0.0001 dlossQsigm:0.0382\n",
      "Episode:123 meanR:46.7200 rate:0.0980 gloss:0.0264 dloss:3.9247 dlossR:0.0000 dlossQsigm:0.0523\n",
      "Episode:124 meanR:46.7300 rate:0.0880 gloss:0.0027 dloss:0.8355 dlossR:0.0007 dlossQsigm:0.0368\n",
      "Episode:125 meanR:46.4000 rate:0.1040 gloss:0.0244 dloss:1.1728 dlossR:0.0036 dlossQsigm:0.0622\n",
      "Episode:126 meanR:46.4400 rate:0.0800 gloss:0.0000 dloss:1.0993 dlossR:0.0005 dlossQsigm:0.0393\n",
      "Episode:127 meanR:45.6000 rate:0.0760 gloss:0.0000 dloss:0.5744 dlossR:0.0008 dlossQsigm:0.0370\n",
      "Episode:128 meanR:45.4000 rate:0.0960 gloss:0.0001 dloss:1.3382 dlossR:0.0000 dlossQsigm:0.0376\n",
      "Episode:129 meanR:45.4700 rate:0.0840 gloss:0.0001 dloss:0.9597 dlossR:0.0001 dlossQsigm:0.0345\n",
      "Episode:130 meanR:45.4300 rate:0.0620 gloss:0.0023 dloss:1.3963 dlossR:0.0001 dlossQsigm:0.0712\n",
      "Episode:131 meanR:45.4300 rate:0.0660 gloss:0.0001 dloss:0.9101 dlossR:0.0000 dlossQsigm:0.0383\n",
      "Episode:132 meanR:45.0500 rate:0.0620 gloss:0.0002 dloss:1.3398 dlossR:0.0007 dlossQsigm:0.0756\n",
      "Episode:133 meanR:45.1800 rate:0.1080 gloss:0.0072 dloss:2.1890 dlossR:0.0002 dlossQsigm:0.0390\n",
      "Episode:134 meanR:45.3200 rate:0.1120 gloss:0.0031 dloss:10.0381 dlossR:0.0000 dlossQsigm:0.0445\n",
      "Episode:135 meanR:45.1700 rate:0.0820 gloss:0.0025 dloss:1.8951 dlossR:0.0000 dlossQsigm:0.0557\n",
      "Episode:136 meanR:44.9000 rate:0.0640 gloss:0.0027 dloss:4.1153 dlossR:0.0000 dlossQsigm:0.0355\n",
      "Episode:137 meanR:44.8600 rate:0.0680 gloss:0.0026 dloss:0.8375 dlossR:0.0019 dlossQsigm:0.0428\n",
      "Episode:138 meanR:45.1900 rate:0.1440 gloss:0.0011 dloss:6.5733 dlossR:0.0000 dlossQsigm:0.0655\n",
      "Episode:139 meanR:45.3400 rate:0.0920 gloss:0.0000 dloss:10.5929 dlossR:0.0000 dlossQsigm:0.0724\n",
      "Episode:140 meanR:45.1100 rate:0.0520 gloss:0.0014 dloss:3.3520 dlossR:0.0017 dlossQsigm:0.0943\n",
      "Episode:141 meanR:45.0900 rate:0.1000 gloss:0.0001 dloss:6.7506 dlossR:0.0000 dlossQsigm:0.0474\n",
      "Episode:142 meanR:44.9700 rate:0.0640 gloss:0.0023 dloss:6.7281 dlossR:0.0002 dlossQsigm:0.0337\n",
      "Episode:143 meanR:45.7600 rate:0.2420 gloss:0.0305 dloss:7.9543 dlossR:0.0001 dlossQsigm:0.0544\n",
      "Episode:144 meanR:46.1500 rate:0.1420 gloss:0.0094 dloss:3.9457 dlossR:0.0000 dlossQsigm:0.0364\n",
      "Episode:145 meanR:45.9500 rate:0.0640 gloss:0.0062 dloss:14.9594 dlossR:0.0000 dlossQsigm:0.0507\n",
      "Episode:146 meanR:45.9700 rate:0.0660 gloss:0.0042 dloss:2.4089 dlossR:0.0055 dlossQsigm:0.0582\n",
      "Episode:147 meanR:45.9900 rate:0.0600 gloss:0.0002 dloss:2.6127 dlossR:0.0013 dlossQsigm:0.0749\n",
      "Episode:148 meanR:46.1200 rate:0.0860 gloss:0.0000 dloss:2.1741 dlossR:0.0000 dlossQsigm:0.0401\n",
      "Episode:149 meanR:46.1000 rate:0.0600 gloss:0.0015 dloss:3.2918 dlossR:0.0012 dlossQsigm:0.0905\n",
      "Episode:150 meanR:45.9000 rate:0.0560 gloss:0.0002 dloss:2.4591 dlossR:0.0023 dlossQsigm:0.0730\n",
      "Episode:151 meanR:45.9500 rate:0.0700 gloss:0.0000 dloss:2.0347 dlossR:0.0000 dlossQsigm:0.0346\n",
      "Episode:152 meanR:45.9900 rate:0.0640 gloss:0.0011 dloss:14.9125 dlossR:0.0000 dlossQsigm:0.0377\n",
      "Episode:153 meanR:46.1200 rate:0.0820 gloss:0.0032 dloss:2.7215 dlossR:0.0000 dlossQsigm:0.0369\n",
      "Episode:154 meanR:46.1500 rate:0.0740 gloss:0.0025 dloss:1.7372 dlossR:0.0184 dlossQsigm:0.0868\n",
      "Episode:155 meanR:46.4400 rate:0.1260 gloss:0.0011 dloss:2.5460 dlossR:0.0004 dlossQsigm:0.0574\n",
      "Episode:156 meanR:46.4800 rate:0.0700 gloss:0.0008 dloss:1.9135 dlossR:0.0032 dlossQsigm:0.0583\n",
      "Episode:157 meanR:46.6700 rate:0.1380 gloss:0.0211 dloss:8.4799 dlossR:0.0043 dlossQsigm:0.0830\n",
      "Episode:158 meanR:46.6000 rate:0.0700 gloss:-0.1922 dloss:8.4388 dlossR:0.1011 dlossQsigm:0.3329\n",
      "Episode:159 meanR:46.7000 rate:0.0720 gloss:0.0944 dloss:1.9301 dlossR:0.0068 dlossQsigm:0.0928\n",
      "Episode:160 meanR:46.7900 rate:0.0900 gloss:-0.0027 dloss:2.8709 dlossR:0.0283 dlossQsigm:0.1754\n",
      "Episode:161 meanR:46.3800 rate:0.0820 gloss:0.0041 dloss:2.8000 dlossR:0.0001 dlossQsigm:0.0610\n",
      "Episode:162 meanR:46.4500 rate:0.0680 gloss:0.0029 dloss:2.2693 dlossR:0.0000 dlossQsigm:0.0399\n",
      "Episode:163 meanR:45.0600 rate:0.1140 gloss:0.0302 dloss:2.8298 dlossR:0.0015 dlossQsigm:0.0579\n",
      "Episode:164 meanR:44.6900 rate:0.0800 gloss:0.0004 dloss:1.1265 dlossR:0.0010 dlossQsigm:0.0431\n",
      "Episode:165 meanR:44.8800 rate:0.1140 gloss:0.0000 dloss:1.3910 dlossR:0.0000 dlossQsigm:0.0335\n",
      "Episode:166 meanR:44.8300 rate:0.0680 gloss:0.0027 dloss:1.7858 dlossR:0.0000 dlossQsigm:0.0376\n",
      "Episode:167 meanR:44.8900 rate:0.0900 gloss:0.0081 dloss:3.0828 dlossR:0.0000 dlossQsigm:0.0428\n",
      "Episode:168 meanR:43.6900 rate:0.0740 gloss:0.0000 dloss:1.1088 dlossR:0.0018 dlossQsigm:0.0354\n",
      "Episode:169 meanR:43.6800 rate:0.0680 gloss:0.0478 dloss:2.0964 dlossR:0.0000 dlossQsigm:0.0491\n",
      "Episode:170 meanR:43.5800 rate:0.1080 gloss:0.0000 dloss:2.2898 dlossR:0.0011 dlossQsigm:0.0325\n",
      "Episode:171 meanR:43.6300 rate:0.0800 gloss:0.0136 dloss:1.0295 dlossR:0.0006 dlossQsigm:0.0304\n",
      "Episode:172 meanR:43.5400 rate:0.0980 gloss:0.0001 dloss:1.9053 dlossR:0.0000 dlossQsigm:0.0499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:173 meanR:43.4900 rate:0.0940 gloss:0.0029 dloss:2.0470 dlossR:0.0000 dlossQsigm:0.0425\n",
      "Episode:174 meanR:44.0900 rate:0.2060 gloss:0.0000 dloss:4.1254 dlossR:0.0001 dlossQsigm:0.0329\n",
      "Episode:175 meanR:44.7700 rate:0.1980 gloss:0.0010 dloss:6.7854 dlossR:0.0000 dlossQsigm:0.1130\n",
      "Episode:176 meanR:44.6300 rate:0.0780 gloss:0.0004 dloss:3.9098 dlossR:0.0000 dlossQsigm:0.0646\n",
      "Episode:177 meanR:44.7200 rate:0.0780 gloss:0.0024 dloss:6.3407 dlossR:0.0004 dlossQsigm:0.0484\n",
      "Episode:178 meanR:44.7400 rate:0.0920 gloss:0.0052 dloss:0.8704 dlossR:0.0029 dlossQsigm:0.0433\n",
      "Episode:179 meanR:45.0300 rate:0.1180 gloss:0.0051 dloss:32.5792 dlossR:0.0002 dlossQsigm:0.0371\n",
      "Episode:180 meanR:44.8200 rate:0.0660 gloss:0.0067 dloss:25.5364 dlossR:0.0004 dlossQsigm:0.0331\n",
      "Episode:181 meanR:44.7800 rate:0.0620 gloss:0.0000 dloss:2.0447 dlossR:0.0009 dlossQsigm:0.0612\n",
      "Episode:182 meanR:44.6800 rate:0.0780 gloss:0.0017 dloss:1.4886 dlossR:0.0006 dlossQsigm:0.0411\n",
      "Episode:183 meanR:44.5300 rate:0.0680 gloss:0.0006 dloss:2.7209 dlossR:0.0012 dlossQsigm:0.0484\n",
      "Episode:184 meanR:44.4700 rate:0.0700 gloss:0.0089 dloss:2.2945 dlossR:0.0090 dlossQsigm:0.0608\n",
      "Episode:185 meanR:44.4300 rate:0.0840 gloss:0.0093 dloss:1.6837 dlossR:0.0046 dlossQsigm:0.0659\n",
      "Episode:186 meanR:44.3100 rate:0.0640 gloss:0.0050 dloss:2.6652 dlossR:0.0348 dlossQsigm:0.1030\n",
      "Episode:187 meanR:44.5700 rate:0.1440 gloss:0.0003 dloss:2.0120 dlossR:0.0001 dlossQsigm:0.0315\n",
      "Episode:188 meanR:44.6400 rate:0.0760 gloss:0.0000 dloss:1.2648 dlossR:0.0059 dlossQsigm:0.0529\n",
      "Episode:189 meanR:44.6100 rate:0.0560 gloss:0.0002 dloss:0.9274 dlossR:0.0042 dlossQsigm:0.0790\n",
      "Episode:190 meanR:44.7500 rate:0.0920 gloss:0.0001 dloss:0.7765 dlossR:0.0003 dlossQsigm:0.0321\n",
      "Episode:191 meanR:44.6000 rate:0.0620 gloss:0.0141 dloss:1.1785 dlossR:0.0017 dlossQsigm:0.0576\n",
      "Episode:192 meanR:44.4900 rate:0.0740 gloss:0.0147 dloss:1.1414 dlossR:0.0033 dlossQsigm:0.0396\n",
      "Episode:193 meanR:44.3700 rate:0.0560 gloss:0.0009 dloss:0.9858 dlossR:0.0005 dlossQsigm:0.0665\n",
      "Episode:194 meanR:44.3900 rate:0.0680 gloss:0.0000 dloss:1.2953 dlossR:0.0030 dlossQsigm:0.0496\n",
      "Episode:195 meanR:44.4500 rate:0.1200 gloss:0.0002 dloss:0.7040 dlossR:0.0001 dlossQsigm:0.0367\n",
      "Episode:196 meanR:45.9700 rate:0.3820 gloss:0.0143 dloss:125.4444 dlossR:0.0000 dlossQsigm:0.5067\n",
      "Episode:197 meanR:46.0800 rate:0.1000 gloss:0.0009 dloss:14.5953 dlossR:0.0299 dlossQsigm:0.1751\n",
      "Episode:198 meanR:46.3500 rate:0.1140 gloss:0.0077 dloss:6.4678 dlossR:0.0259 dlossQsigm:0.1746\n",
      "Episode:199 meanR:46.5800 rate:0.1140 gloss:0.0025 dloss:5.1711 dlossR:0.1125 dlossQsigm:0.2894\n",
      "Episode:200 meanR:46.8000 rate:0.1000 gloss:0.0005 dloss:3.8793 dlossR:0.0905 dlossQsigm:0.3479\n",
      "Episode:201 meanR:47.2300 rate:0.1700 gloss:0.0023 dloss:1.5021 dlossR:0.0002 dlossQsigm:0.0421\n",
      "Episode:202 meanR:47.3400 rate:0.1300 gloss:0.0003 dloss:3.4933 dlossR:0.0000 dlossQsigm:0.0496\n",
      "Episode:203 meanR:48.3500 rate:0.2600 gloss:0.0130 dloss:2.4948 dlossR:0.0000 dlossQsigm:0.0548\n",
      "Episode:204 meanR:48.3200 rate:0.1020 gloss:0.0047 dloss:2.9422 dlossR:0.0000 dlossQsigm:0.0561\n",
      "Episode:205 meanR:48.7600 rate:0.1700 gloss:0.0004 dloss:4.5360 dlossR:0.0000 dlossQsigm:0.0468\n",
      "Episode:206 meanR:48.6800 rate:0.0600 gloss:0.0001 dloss:2.9606 dlossR:0.0000 dlossQsigm:0.1040\n",
      "Episode:207 meanR:48.2800 rate:0.0740 gloss:0.0021 dloss:0.9870 dlossR:0.0000 dlossQsigm:0.0365\n",
      "Episode:208 meanR:48.7500 rate:0.1540 gloss:0.0005 dloss:1.9084 dlossR:0.0000 dlossQsigm:0.0437\n",
      "Episode:209 meanR:48.7000 rate:0.0820 gloss:0.0030 dloss:1.8736 dlossR:0.0000 dlossQsigm:0.0415\n",
      "Episode:210 meanR:48.8300 rate:0.0840 gloss:0.0024 dloss:1.7276 dlossR:0.0000 dlossQsigm:0.0532\n",
      "Episode:211 meanR:48.4900 rate:0.0620 gloss:0.0176 dloss:3.7751 dlossR:0.0000 dlossQsigm:0.0971\n",
      "Episode:212 meanR:48.4600 rate:0.0960 gloss:0.0013 dloss:2.9898 dlossR:0.0000 dlossQsigm:0.0536\n",
      "Episode:213 meanR:48.8200 rate:0.1720 gloss:0.0032 dloss:7.8038 dlossR:0.0000 dlossQsigm:0.0575\n",
      "Episode:214 meanR:48.9100 rate:0.0780 gloss:0.0006 dloss:1.2852 dlossR:0.0000 dlossQsigm:0.0439\n",
      "Episode:215 meanR:49.6700 rate:0.2220 gloss:0.0016 dloss:8.5562 dlossR:0.0000 dlossQsigm:0.0445\n",
      "Episode:216 meanR:49.8200 rate:0.1120 gloss:0.0043 dloss:7.8061 dlossR:0.0000 dlossQsigm:0.0531\n",
      "Episode:217 meanR:49.8500 rate:0.0740 gloss:0.0006 dloss:11.9615 dlossR:0.0001 dlossQsigm:0.0434\n",
      "Episode:218 meanR:49.6100 rate:0.0620 gloss:0.0005 dloss:4.3786 dlossR:0.0000 dlossQsigm:0.0881\n",
      "Episode:219 meanR:49.7000 rate:0.0880 gloss:0.0133 dloss:4.4647 dlossR:0.0016 dlossQsigm:0.0633\n",
      "Episode:220 meanR:49.5800 rate:0.0780 gloss:0.0018 dloss:1.3072 dlossR:0.0008 dlossQsigm:0.0474\n",
      "Episode:221 meanR:49.2100 rate:0.0860 gloss:0.0315 dloss:1.2082 dlossR:0.0001 dlossQsigm:0.0408\n",
      "Episode:222 meanR:49.1100 rate:0.1140 gloss:0.0019 dloss:25.9030 dlossR:0.0000 dlossQsigm:0.0442\n",
      "Episode:223 meanR:48.9600 rate:0.0680 gloss:0.0001 dloss:6.9026 dlossR:0.0000 dlossQsigm:0.0478\n",
      "Episode:224 meanR:48.9200 rate:0.0800 gloss:0.0004 dloss:1.4985 dlossR:0.0000 dlossQsigm:0.0450\n",
      "Episode:225 meanR:48.8400 rate:0.0880 gloss:0.0035 dloss:1.5163 dlossR:0.0000 dlossQsigm:0.0446\n",
      "Episode:226 meanR:49.0300 rate:0.1180 gloss:0.0009 dloss:1.6720 dlossR:0.0000 dlossQsigm:0.0506\n",
      "Episode:227 meanR:49.1200 rate:0.0940 gloss:0.0010 dloss:2.2256 dlossR:0.0000 dlossQsigm:0.0550\n",
      "Episode:228 meanR:49.6800 rate:0.2080 gloss:0.0012 dloss:57.3819 dlossR:0.0000 dlossQsigm:0.3144\n",
      "Episode:229 meanR:49.5600 rate:0.0600 gloss:0.0011 dloss:33.2313 dlossR:0.0000 dlossQsigm:0.3490\n",
      "Episode:230 meanR:49.5600 rate:0.0620 gloss:0.0028 dloss:5.4945 dlossR:0.0000 dlossQsigm:0.1508\n",
      "Episode:231 meanR:49.6100 rate:0.0760 gloss:0.0017 dloss:3.3591 dlossR:0.0000 dlossQsigm:0.0785\n",
      "Episode:232 meanR:49.7400 rate:0.0880 gloss:0.0049 dloss:3.3970 dlossR:0.0000 dlossQsigm:0.0741\n",
      "Episode:233 meanR:50.1800 rate:0.1960 gloss:0.0003 dloss:3.5641 dlossR:0.0000 dlossQsigm:0.0573\n",
      "Episode:234 meanR:49.9500 rate:0.0660 gloss:0.0002 dloss:7.9590 dlossR:0.0000 dlossQsigm:0.1077\n",
      "Episode:235 meanR:50.6700 rate:0.2260 gloss:0.0146 dloss:7.3780 dlossR:0.0000 dlossQsigm:0.0724\n",
      "Episode:236 meanR:50.8200 rate:0.0940 gloss:0.0002 dloss:6.0810 dlossR:0.0000 dlossQsigm:0.0853\n",
      "Episode:237 meanR:51.8000 rate:0.2640 gloss:0.0002 dloss:5.3974 dlossR:0.0000 dlossQsigm:0.0960\n",
      "Episode:238 meanR:51.4200 rate:0.0680 gloss:0.0254 dloss:9.4536 dlossR:0.0000 dlossQsigm:0.1369\n",
      "Episode:239 meanR:51.5300 rate:0.1140 gloss:0.0001 dloss:5.7415 dlossR:0.0000 dlossQsigm:0.0884\n",
      "Episode:240 meanR:51.7400 rate:0.0940 gloss:0.0009 dloss:3.1226 dlossR:0.0000 dlossQsigm:0.0705\n",
      "Episode:241 meanR:51.6000 rate:0.0720 gloss:0.0002 dloss:5.2925 dlossR:0.0000 dlossQsigm:0.0652\n",
      "Episode:242 meanR:51.7800 rate:0.1000 gloss:0.0366 dloss:2.3101 dlossR:0.0000 dlossQsigm:0.0557\n",
      "Episode:243 meanR:50.9100 rate:0.0680 gloss:0.0016 dloss:4.2588 dlossR:0.0000 dlossQsigm:0.0585\n",
      "Episode:244 meanR:50.9600 rate:0.1520 gloss:0.0010 dloss:1.7635 dlossR:0.0000 dlossQsigm:0.0434\n",
      "Episode:245 meanR:51.1700 rate:0.1060 gloss:0.0004 dloss:2.2160 dlossR:0.0000 dlossQsigm:0.0395\n",
      "Episode:246 meanR:51.1900 rate:0.0700 gloss:0.0142 dloss:3.1825 dlossR:0.0000 dlossQsigm:0.0491\n",
      "Episode:247 meanR:51.3800 rate:0.0980 gloss:0.0021 dloss:1.5595 dlossR:0.0000 dlossQsigm:0.0435\n",
      "Episode:248 meanR:51.3100 rate:0.0720 gloss:0.0064 dloss:3.0816 dlossR:0.0000 dlossQsigm:0.0634\n",
      "Episode:249 meanR:51.3900 rate:0.0760 gloss:0.0000 dloss:1.9955 dlossR:0.0000 dlossQsigm:0.0487\n",
      "Episode:250 meanR:51.9200 rate:0.1620 gloss:0.0005 dloss:3.6432 dlossR:0.0000 dlossQsigm:0.0696\n",
      "Episode:251 meanR:51.9300 rate:0.0720 gloss:0.0000 dloss:4.1716 dlossR:0.0000 dlossQsigm:0.0858\n",
      "Episode:252 meanR:52.0700 rate:0.0920 gloss:0.0007 dloss:3.6936 dlossR:0.0000 dlossQsigm:0.0696\n",
      "Episode:253 meanR:53.0700 rate:0.2820 gloss:0.0002 dloss:11.3641 dlossR:0.0000 dlossQsigm:0.1297\n",
      "Episode:254 meanR:53.3000 rate:0.1200 gloss:0.0001 dloss:5.1829 dlossR:0.0000 dlossQsigm:0.0657\n",
      "Episode:255 meanR:53.3200 rate:0.1300 gloss:0.0026 dloss:11.1244 dlossR:0.0000 dlossQsigm:0.0790\n",
      "Episode:256 meanR:54.0200 rate:0.2100 gloss:0.0005 dloss:84.9897 dlossR:0.0000 dlossQsigm:0.3934\n",
      "Episode:257 meanR:53.6400 rate:0.0620 gloss:0.0001 dloss:58.3332 dlossR:0.0000 dlossQsigm:0.4379\n",
      "Episode:258 meanR:53.7800 rate:0.0980 gloss:0.0005 dloss:7.6994 dlossR:0.0000 dlossQsigm:0.0971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:259 meanR:53.7800 rate:0.0720 gloss:0.0014 dloss:4.6687 dlossR:0.0000 dlossQsigm:0.0882\n",
      "Episode:260 meanR:53.7100 rate:0.0760 gloss:0.0017 dloss:1.8621 dlossR:0.0000 dlossQsigm:0.0479\n",
      "Episode:261 meanR:53.6700 rate:0.0740 gloss:0.0008 dloss:3.5490 dlossR:0.0000 dlossQsigm:0.0521\n",
      "Episode:262 meanR:53.7200 rate:0.0780 gloss:0.0000 dloss:2.9076 dlossR:0.0000 dlossQsigm:0.0660\n",
      "Episode:263 meanR:53.5100 rate:0.0720 gloss:0.0005 dloss:2.4179 dlossR:0.0000 dlossQsigm:0.0435\n",
      "Episode:264 meanR:53.7400 rate:0.1260 gloss:0.0000 dloss:2.0998 dlossR:0.0000 dlossQsigm:0.0510\n",
      "Episode:265 meanR:53.9700 rate:0.1600 gloss:0.0024 dloss:2.4127 dlossR:0.0000 dlossQsigm:0.0437\n",
      "Episode:266 meanR:53.9300 rate:0.0600 gloss:0.0000 dloss:2.4179 dlossR:0.0000 dlossQsigm:0.0868\n",
      "Episode:267 meanR:53.8000 rate:0.0640 gloss:0.0754 dloss:9.3861 dlossR:0.0000 dlossQsigm:0.0588\n",
      "Episode:268 meanR:53.9400 rate:0.1020 gloss:0.0039 dloss:1.9232 dlossR:0.0000 dlossQsigm:0.0478\n",
      "Episode:269 meanR:54.1100 rate:0.1020 gloss:0.0004 dloss:1.7890 dlossR:0.0000 dlossQsigm:0.0566\n",
      "Episode:270 meanR:54.0400 rate:0.0940 gloss:0.0000 dloss:1.8834 dlossR:0.0000 dlossQsigm:0.0522\n",
      "Episode:271 meanR:54.0900 rate:0.0900 gloss:0.0160 dloss:1.1339 dlossR:0.0001 dlossQsigm:0.0314\n",
      "Episode:272 meanR:53.9700 rate:0.0740 gloss:0.0004 dloss:2.0127 dlossR:0.0001 dlossQsigm:0.0419\n",
      "Episode:273 meanR:53.8000 rate:0.0600 gloss:0.0023 dloss:2.9792 dlossR:0.0000 dlossQsigm:0.0806\n",
      "Episode:274 meanR:53.1900 rate:0.0840 gloss:0.0000 dloss:1.9509 dlossR:0.0000 dlossQsigm:0.0470\n",
      "Episode:275 meanR:52.5100 rate:0.0620 gloss:0.0008 dloss:1.7913 dlossR:0.0004 dlossQsigm:0.0701\n",
      "Episode:276 meanR:52.7300 rate:0.1220 gloss:0.0000 dloss:1.8636 dlossR:0.0001 dlossQsigm:0.0439\n",
      "Episode:277 meanR:52.8200 rate:0.0960 gloss:0.0006 dloss:1.4237 dlossR:0.0000 dlossQsigm:0.0408\n",
      "Episode:278 meanR:52.8300 rate:0.0940 gloss:0.0016 dloss:2.7110 dlossR:0.0000 dlossQsigm:0.0473\n",
      "Episode:279 meanR:53.0600 rate:0.1640 gloss:0.0378 dloss:4.8697 dlossR:0.0000 dlossQsigm:0.0795\n",
      "Episode:280 meanR:53.0400 rate:0.0620 gloss:0.0006 dloss:6.1794 dlossR:0.0000 dlossQsigm:0.1644\n",
      "Episode:281 meanR:53.2800 rate:0.1100 gloss:0.0002 dloss:2.9890 dlossR:0.0000 dlossQsigm:0.0666\n",
      "Episode:282 meanR:53.4300 rate:0.1080 gloss:0.0000 dloss:2.5781 dlossR:0.0000 dlossQsigm:0.0768\n",
      "Episode:283 meanR:53.4100 rate:0.0640 gloss:0.0271 dloss:7.4612 dlossR:0.0000 dlossQsigm:0.0771\n",
      "Episode:284 meanR:53.3600 rate:0.0600 gloss:0.0120 dloss:2.9994 dlossR:0.0000 dlossQsigm:0.1141\n",
      "Episode:285 meanR:53.2900 rate:0.0700 gloss:0.0000 dloss:3.2330 dlossR:0.0000 dlossQsigm:0.0707\n",
      "Episode:286 meanR:53.2800 rate:0.0620 gloss:0.0000 dloss:2.4604 dlossR:0.0000 dlossQsigm:0.1002\n",
      "Episode:287 meanR:52.8900 rate:0.0660 gloss:0.0000 dloss:1.7425 dlossR:0.0000 dlossQsigm:0.0511\n",
      "Episode:288 meanR:53.7600 rate:0.2500 gloss:0.0000 dloss:10.0677 dlossR:0.0000 dlossQsigm:0.0566\n",
      "Episode:289 meanR:53.8100 rate:0.0660 gloss:0.1053 dloss:3.5925 dlossR:0.0000 dlossQsigm:0.0423\n",
      "Episode:290 meanR:53.8400 rate:0.0980 gloss:0.0002 dloss:1.9237 dlossR:0.0002 dlossQsigm:0.0311\n",
      "Episode:291 meanR:53.8800 rate:0.0700 gloss:0.0687 dloss:3.3166 dlossR:0.0000 dlossQsigm:0.0451\n",
      "Episode:292 meanR:54.0800 rate:0.1140 gloss:0.0006 dloss:2.0448 dlossR:0.0001 dlossQsigm:0.0336\n",
      "Episode:293 meanR:55.1600 rate:0.2720 gloss:0.0017 dloss:2.9498 dlossR:0.0000 dlossQsigm:0.0631\n",
      "Episode:294 meanR:55.8600 rate:0.2080 gloss:0.0001 dloss:58.0612 dlossR:0.0000 dlossQsigm:0.3168\n",
      "Episode:295 meanR:55.7100 rate:0.0900 gloss:0.0000 dloss:15.6495 dlossR:0.0000 dlossQsigm:0.1818\n",
      "Episode:296 meanR:54.3200 rate:0.1040 gloss:0.0000 dloss:11.7204 dlossR:0.0000 dlossQsigm:0.1477\n",
      "Episode:297 meanR:54.4900 rate:0.1340 gloss:0.0004 dloss:2.4922 dlossR:0.0000 dlossQsigm:0.0436\n",
      "Episode:298 meanR:54.5700 rate:0.1300 gloss:0.0003 dloss:1.2342 dlossR:0.0000 dlossQsigm:0.0381\n",
      "Episode:299 meanR:54.9900 rate:0.1980 gloss:0.0004 dloss:59.9245 dlossR:0.0000 dlossQsigm:0.3284\n",
      "Episode:300 meanR:54.8800 rate:0.0780 gloss:0.0000 dloss:6.4265 dlossR:0.0000 dlossQsigm:0.1027\n",
      "Episode:301 meanR:55.3000 rate:0.2540 gloss:0.0000 dloss:4.1211 dlossR:0.0000 dlossQsigm:0.0753\n",
      "Episode:302 meanR:55.4900 rate:0.1680 gloss:0.0004 dloss:4.0191 dlossR:0.0000 dlossQsigm:0.0550\n",
      "Episode:303 meanR:54.5800 rate:0.0780 gloss:0.0000 dloss:3.1653 dlossR:0.0000 dlossQsigm:0.0550\n",
      "Episode:304 meanR:54.4800 rate:0.0820 gloss:0.0001 dloss:1.4307 dlossR:0.0000 dlossQsigm:0.0387\n",
      "Episode:305 meanR:54.2000 rate:0.1140 gloss:0.0000 dloss:1.1222 dlossR:0.0000 dlossQsigm:0.0347\n",
      "Episode:306 meanR:54.2100 rate:0.0620 gloss:0.0003 dloss:1.3733 dlossR:0.0001 dlossQsigm:0.0638\n",
      "Episode:307 meanR:54.1500 rate:0.0620 gloss:0.0000 dloss:1.1670 dlossR:0.0005 dlossQsigm:0.0551\n",
      "Episode:308 meanR:53.9400 rate:0.1120 gloss:0.0000 dloss:2.4187 dlossR:0.0000 dlossQsigm:0.0376\n",
      "Episode:309 meanR:53.8800 rate:0.0700 gloss:0.0002 dloss:1.3500 dlossR:0.0001 dlossQsigm:0.0383\n",
      "Episode:310 meanR:53.8900 rate:0.0860 gloss:0.0000 dloss:2.7616 dlossR:0.0000 dlossQsigm:0.0447\n",
      "Episode:311 meanR:53.9900 rate:0.0820 gloss:0.0069 dloss:2.0234 dlossR:0.0000 dlossQsigm:0.0443\n",
      "Episode:312 meanR:53.9000 rate:0.0780 gloss:0.0012 dloss:1.6340 dlossR:0.0000 dlossQsigm:0.0420\n",
      "Episode:313 meanR:53.3800 rate:0.0680 gloss:0.0007 dloss:1.6434 dlossR:0.0000 dlossQsigm:0.0389\n",
      "Episode:314 meanR:53.4600 rate:0.0940 gloss:0.0001 dloss:2.0772 dlossR:0.0000 dlossQsigm:0.0465\n",
      "Episode:315 meanR:52.6800 rate:0.0660 gloss:0.0021 dloss:1.3255 dlossR:0.0000 dlossQsigm:0.0401\n",
      "Episode:316 meanR:52.5500 rate:0.0860 gloss:0.0003 dloss:1.0636 dlossR:0.0001 dlossQsigm:0.0323\n",
      "Episode:317 meanR:52.6000 rate:0.0840 gloss:0.0118 dloss:2.7834 dlossR:0.0000 dlossQsigm:0.0545\n",
      "Episode:318 meanR:52.6800 rate:0.0780 gloss:0.0002 dloss:2.3931 dlossR:0.0000 dlossQsigm:0.0514\n",
      "Episode:319 meanR:52.5900 rate:0.0700 gloss:0.0001 dloss:3.1604 dlossR:0.0001 dlossQsigm:0.0355\n",
      "Episode:320 meanR:52.5400 rate:0.0680 gloss:0.0000 dloss:1.8128 dlossR:0.0000 dlossQsigm:0.0437\n",
      "Episode:321 meanR:52.4300 rate:0.0640 gloss:0.0001 dloss:12.1886 dlossR:0.0000 dlossQsigm:0.0663\n",
      "Episode:322 meanR:52.4100 rate:0.1100 gloss:0.0003 dloss:1.1543 dlossR:0.0000 dlossQsigm:0.0377\n",
      "Episode:323 meanR:52.4900 rate:0.0840 gloss:0.0007 dloss:2.5058 dlossR:0.0000 dlossQsigm:0.0636\n",
      "Episode:324 meanR:52.4300 rate:0.0680 gloss:0.0003 dloss:2.4572 dlossR:0.0000 dlossQsigm:0.0598\n",
      "Episode:325 meanR:52.7900 rate:0.1600 gloss:0.0003 dloss:44.3937 dlossR:0.0000 dlossQsigm:0.2519\n",
      "Episode:326 meanR:53.0600 rate:0.1720 gloss:0.0142 dloss:5.0522 dlossR:0.0000 dlossQsigm:0.0986\n",
      "Episode:327 meanR:53.3400 rate:0.1500 gloss:0.0000 dloss:3.5034 dlossR:0.0000 dlossQsigm:0.0503\n",
      "Episode:328 meanR:52.6600 rate:0.0720 gloss:0.0001 dloss:3.7667 dlossR:0.0000 dlossQsigm:0.0699\n",
      "Episode:329 meanR:52.8500 rate:0.0980 gloss:0.0001 dloss:3.9015 dlossR:0.0000 dlossQsigm:0.0688\n",
      "Episode:330 meanR:53.6200 rate:0.2160 gloss:0.0017 dloss:4.3197 dlossR:0.0000 dlossQsigm:0.0758\n",
      "Episode:331 meanR:53.5800 rate:0.0680 gloss:0.0002 dloss:2.6069 dlossR:0.0000 dlossQsigm:0.0571\n",
      "Episode:332 meanR:54.4600 rate:0.2640 gloss:0.0044 dloss:4.9583 dlossR:0.0000 dlossQsigm:0.0827\n",
      "Episode:333 meanR:53.8100 rate:0.0660 gloss:0.0007 dloss:8.3544 dlossR:0.0000 dlossQsigm:0.1317\n",
      "Episode:334 meanR:53.7700 rate:0.0580 gloss:0.0056 dloss:5.6640 dlossR:0.0000 dlossQsigm:0.1488\n",
      "Episode:335 meanR:53.2300 rate:0.1180 gloss:0.0000 dloss:1.5238 dlossR:0.0002 dlossQsigm:0.0389\n",
      "Episode:336 meanR:53.2500 rate:0.0980 gloss:0.0000 dloss:3.5605 dlossR:0.0000 dlossQsigm:0.0670\n",
      "Episode:337 meanR:52.2800 rate:0.0700 gloss:0.0007 dloss:6.0060 dlossR:0.0000 dlossQsigm:0.0810\n",
      "Episode:338 meanR:52.3800 rate:0.0880 gloss:0.0002 dloss:4.4329 dlossR:0.0000 dlossQsigm:0.0725\n",
      "Episode:339 meanR:52.1300 rate:0.0640 gloss:0.0024 dloss:6.7344 dlossR:0.0000 dlossQsigm:0.0589\n",
      "Episode:340 meanR:52.2000 rate:0.1080 gloss:0.0000 dloss:2.4578 dlossR:0.0000 dlossQsigm:0.0501\n",
      "Episode:341 meanR:52.3900 rate:0.1100 gloss:0.0015 dloss:1.3949 dlossR:0.0000 dlossQsigm:0.0385\n",
      "Episode:342 meanR:52.3500 rate:0.0920 gloss:0.0000 dloss:2.6297 dlossR:0.0000 dlossQsigm:0.0507\n",
      "Episode:343 meanR:53.0000 rate:0.1980 gloss:0.0000 dloss:3.9719 dlossR:0.0000 dlossQsigm:0.0470\n",
      "Episode:344 meanR:53.2700 rate:0.2060 gloss:0.0000 dloss:38.7665 dlossR:0.0000 dlossQsigm:0.2487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:345 meanR:53.3300 rate:0.1180 gloss:0.0159 dloss:4.0860 dlossR:0.0000 dlossQsigm:0.0746\n",
      "Episode:346 meanR:53.8900 rate:0.1820 gloss:0.0000 dloss:5.9204 dlossR:0.0000 dlossQsigm:0.0719\n",
      "Episode:347 meanR:54.4700 rate:0.2140 gloss:0.0000 dloss:23.1967 dlossR:0.0000 dlossQsigm:0.1976\n",
      "Episode:348 meanR:54.5600 rate:0.0900 gloss:0.0001 dloss:12.7233 dlossR:0.0000 dlossQsigm:0.1160\n",
      "Episode:349 meanR:54.5300 rate:0.0700 gloss:0.0020 dloss:4.7866 dlossR:0.0000 dlossQsigm:0.0628\n",
      "Episode:350 meanR:54.2100 rate:0.0980 gloss:0.0000 dloss:2.5960 dlossR:0.0000 dlossQsigm:0.0468\n",
      "Episode:351 meanR:54.6700 rate:0.1640 gloss:0.0005 dloss:7.3748 dlossR:0.0000 dlossQsigm:0.1098\n",
      "Episode:352 meanR:55.4200 rate:0.2420 gloss:0.0000 dloss:5.9671 dlossR:0.0000 dlossQsigm:0.0886\n",
      "Episode:353 meanR:54.4200 rate:0.0820 gloss:0.0040 dloss:4.0189 dlossR:0.0000 dlossQsigm:0.0779\n",
      "Episode:354 meanR:54.3300 rate:0.1020 gloss:0.0025 dloss:3.1692 dlossR:0.0000 dlossQsigm:0.0643\n",
      "Episode:355 meanR:54.0700 rate:0.0780 gloss:0.0001 dloss:3.0164 dlossR:0.0000 dlossQsigm:0.0532\n",
      "Episode:356 meanR:53.6700 rate:0.1300 gloss:0.0001 dloss:2.7803 dlossR:0.0000 dlossQsigm:0.0466\n",
      "Episode:357 meanR:53.8300 rate:0.0940 gloss:0.0000 dloss:1.6363 dlossR:0.0000 dlossQsigm:0.0396\n",
      "Episode:358 meanR:54.6800 rate:0.2680 gloss:0.0000 dloss:6.4394 dlossR:0.0000 dlossQsigm:0.0819\n",
      "Episode:359 meanR:54.6600 rate:0.0680 gloss:0.0000 dloss:12.0570 dlossR:0.0000 dlossQsigm:0.0647\n",
      "Episode:360 meanR:54.7700 rate:0.0980 gloss:0.0001 dloss:2.1791 dlossR:0.0000 dlossQsigm:0.0333\n",
      "Episode:361 meanR:54.9200 rate:0.1040 gloss:0.0001 dloss:2.6255 dlossR:0.0001 dlossQsigm:0.0503\n",
      "Episode:362 meanR:55.5800 rate:0.2100 gloss:0.0000 dloss:31.0475 dlossR:0.0000 dlossQsigm:0.2341\n",
      "Episode:363 meanR:55.5500 rate:0.0660 gloss:0.0000 dloss:1.9961 dlossR:0.0000 dlossQsigm:0.0383\n",
      "Episode:364 meanR:55.2200 rate:0.0600 gloss:0.0000 dloss:3.1898 dlossR:0.0000 dlossQsigm:0.1023\n",
      "Episode:365 meanR:55.0700 rate:0.1300 gloss:0.0223 dloss:6.5935 dlossR:0.0000 dlossQsigm:0.1038\n",
      "Episode:366 meanR:56.3300 rate:0.3120 gloss:0.0000 dloss:40.5775 dlossR:0.0000 dlossQsigm:0.2656\n",
      "Episode:367 meanR:56.7800 rate:0.1540 gloss:0.0002 dloss:3.0686 dlossR:0.0000 dlossQsigm:0.0706\n",
      "Episode:368 meanR:56.5300 rate:0.0520 gloss:0.0000 dloss:4.3988 dlossR:0.0000 dlossQsigm:0.1266\n",
      "Episode:369 meanR:56.3500 rate:0.0660 gloss:0.0000 dloss:4.2201 dlossR:0.0000 dlossQsigm:0.0590\n",
      "Episode:370 meanR:56.9600 rate:0.2160 gloss:0.0000 dloss:28.7662 dlossR:0.0000 dlossQsigm:0.2385\n",
      "Episode:371 meanR:56.8300 rate:0.0640 gloss:0.0000 dloss:7.8796 dlossR:0.0000 dlossQsigm:0.0963\n",
      "Episode:372 meanR:57.1400 rate:0.1360 gloss:0.0120 dloss:5.7893 dlossR:0.0000 dlossQsigm:0.0889\n",
      "Episode:373 meanR:57.3300 rate:0.0980 gloss:0.0166 dloss:5.5329 dlossR:0.0000 dlossQsigm:0.0665\n",
      "Episode:374 meanR:57.5300 rate:0.1240 gloss:0.0001 dloss:3.9734 dlossR:0.0000 dlossQsigm:0.0489\n",
      "Episode:375 meanR:57.8400 rate:0.1240 gloss:0.0000 dloss:1.2801 dlossR:0.0000 dlossQsigm:0.0422\n",
      "Episode:376 meanR:58.0100 rate:0.1560 gloss:0.0006 dloss:16.3894 dlossR:0.0000 dlossQsigm:0.1362\n",
      "Episode:377 meanR:58.0600 rate:0.1060 gloss:0.0007 dloss:3.2851 dlossR:0.0000 dlossQsigm:0.0487\n",
      "Episode:378 meanR:58.1100 rate:0.1040 gloss:0.0004 dloss:4.1479 dlossR:0.0000 dlossQsigm:0.0757\n",
      "Episode:379 meanR:57.9000 rate:0.1220 gloss:0.0005 dloss:5.5016 dlossR:0.0000 dlossQsigm:0.0991\n",
      "Episode:380 meanR:58.1000 rate:0.1020 gloss:0.0000 dloss:3.2234 dlossR:0.0000 dlossQsigm:0.0600\n",
      "Episode:381 meanR:59.1300 rate:0.3160 gloss:0.0012 dloss:11.2752 dlossR:0.0000 dlossQsigm:0.1207\n",
      "Episode:382 meanR:59.6200 rate:0.2060 gloss:0.0002 dloss:27.0105 dlossR:0.0000 dlossQsigm:0.2269\n",
      "Episode:383 meanR:60.1900 rate:0.1780 gloss:0.0057 dloss:20.9060 dlossR:0.0000 dlossQsigm:0.1970\n",
      "Episode:384 meanR:60.4900 rate:0.1200 gloss:0.0001 dloss:4.5456 dlossR:0.0000 dlossQsigm:0.0866\n",
      "Episode:385 meanR:60.6100 rate:0.0940 gloss:0.0000 dloss:3.4418 dlossR:0.0000 dlossQsigm:0.0780\n",
      "Episode:386 meanR:61.2900 rate:0.1980 gloss:0.1252 dloss:23.8790 dlossR:0.0000 dlossQsigm:0.2047\n",
      "Episode:387 meanR:61.4700 rate:0.1020 gloss:0.0000 dloss:10.7315 dlossR:0.0000 dlossQsigm:0.1384\n",
      "Episode:388 meanR:61.0400 rate:0.1640 gloss:0.1153 dloss:9.0157 dlossR:0.0000 dlossQsigm:0.0890\n",
      "Episode:389 meanR:61.2300 rate:0.1040 gloss:0.0004 dloss:6.4585 dlossR:0.0000 dlossQsigm:0.0576\n",
      "Episode:390 meanR:61.4300 rate:0.1380 gloss:0.0000 dloss:6.0691 dlossR:0.0000 dlossQsigm:0.0664\n",
      "Episode:391 meanR:61.4900 rate:0.0820 gloss:0.0003 dloss:3.4333 dlossR:0.0001 dlossQsigm:0.0309\n",
      "Episode:392 meanR:61.5300 rate:0.1220 gloss:0.0017 dloss:6.9158 dlossR:0.0000 dlossQsigm:0.0910\n",
      "Episode:393 meanR:60.9200 rate:0.1500 gloss:0.0004 dloss:3.8271 dlossR:0.0000 dlossQsigm:0.0557\n",
      "Episode:394 meanR:60.5300 rate:0.1300 gloss:0.0000 dloss:3.6195 dlossR:0.0003 dlossQsigm:0.0503\n",
      "Episode:395 meanR:60.5900 rate:0.1020 gloss:0.0011 dloss:2.7748 dlossR:0.0000 dlossQsigm:0.0449\n",
      "Episode:396 meanR:60.6400 rate:0.1140 gloss:0.0000 dloss:2.3913 dlossR:0.0000 dlossQsigm:0.0456\n",
      "Episode:397 meanR:61.0000 rate:0.2060 gloss:0.0000 dloss:21.2142 dlossR:0.0000 dlossQsigm:0.2062\n",
      "Episode:398 meanR:60.9400 rate:0.1180 gloss:0.0000 dloss:2.4478 dlossR:0.0000 dlossQsigm:0.0548\n",
      "Episode:399 meanR:60.7100 rate:0.1520 gloss:0.0004 dloss:5.0114 dlossR:0.0000 dlossQsigm:0.0640\n",
      "Episode:400 meanR:60.9500 rate:0.1260 gloss:0.0000 dloss:3.2560 dlossR:0.0000 dlossQsigm:0.0610\n",
      "Episode:401 meanR:60.3100 rate:0.1260 gloss:0.0000 dloss:3.4615 dlossR:0.0000 dlossQsigm:0.0627\n",
      "Episode:402 meanR:60.0400 rate:0.1140 gloss:0.0026 dloss:2.7844 dlossR:0.0000 dlossQsigm:0.0462\n",
      "Episode:403 meanR:60.3300 rate:0.1360 gloss:0.0419 dloss:3.6477 dlossR:0.0000 dlossQsigm:0.0587\n",
      "Episode:404 meanR:60.4700 rate:0.1100 gloss:0.0001 dloss:5.2877 dlossR:0.0000 dlossQsigm:0.0791\n",
      "Episode:405 meanR:60.3200 rate:0.0840 gloss:0.0000 dloss:3.3351 dlossR:0.0000 dlossQsigm:0.0671\n",
      "Episode:406 meanR:60.4800 rate:0.0940 gloss:0.0000 dloss:3.1462 dlossR:0.0000 dlossQsigm:0.0706\n",
      "Episode:407 meanR:60.7500 rate:0.1160 gloss:0.0194 dloss:4.1033 dlossR:0.0000 dlossQsigm:0.0782\n",
      "Episode:408 meanR:60.7600 rate:0.1140 gloss:0.0000 dloss:1.4804 dlossR:0.0001 dlossQsigm:0.0442\n",
      "Episode:409 meanR:60.8600 rate:0.0900 gloss:0.0000 dloss:2.0592 dlossR:0.0000 dlossQsigm:0.0438\n",
      "Episode:410 meanR:61.3800 rate:0.1900 gloss:0.0001 dloss:2.6518 dlossR:0.0000 dlossQsigm:0.0608\n",
      "Episode:411 meanR:61.4200 rate:0.0900 gloss:0.0000 dloss:2.7587 dlossR:0.0000 dlossQsigm:0.0642\n",
      "Episode:412 meanR:61.6200 rate:0.1180 gloss:0.0001 dloss:1.9297 dlossR:0.0000 dlossQsigm:0.0605\n",
      "Episode:413 meanR:61.9000 rate:0.1240 gloss:0.0133 dloss:3.2388 dlossR:0.0000 dlossQsigm:0.0775\n",
      "Episode:414 meanR:61.9400 rate:0.1020 gloss:0.0005 dloss:3.9497 dlossR:0.0000 dlossQsigm:0.0552\n",
      "Episode:415 meanR:62.2100 rate:0.1200 gloss:0.0000 dloss:4.6875 dlossR:0.0000 dlossQsigm:0.0752\n",
      "Episode:416 meanR:62.3200 rate:0.1080 gloss:0.0002 dloss:4.1682 dlossR:0.0000 dlossQsigm:0.0719\n",
      "Episode:417 meanR:62.4800 rate:0.1160 gloss:0.0006 dloss:3.7145 dlossR:0.0000 dlossQsigm:0.0655\n",
      "Episode:418 meanR:62.6700 rate:0.1160 gloss:0.0000 dloss:1.8843 dlossR:0.0000 dlossQsigm:0.0564\n",
      "Episode:419 meanR:62.8600 rate:0.1080 gloss:0.0002 dloss:2.1428 dlossR:0.0000 dlossQsigm:0.0501\n",
      "Episode:420 meanR:62.9600 rate:0.0880 gloss:0.0000 dloss:2.3345 dlossR:0.0000 dlossQsigm:0.0497\n",
      "Episode:421 meanR:63.1000 rate:0.0920 gloss:0.0000 dloss:3.1052 dlossR:0.0000 dlossQsigm:0.0433\n",
      "Episode:422 meanR:62.9500 rate:0.0800 gloss:0.0000 dloss:2.5673 dlossR:0.0000 dlossQsigm:0.0533\n",
      "Episode:423 meanR:62.9700 rate:0.0880 gloss:0.0000 dloss:2.3732 dlossR:0.0000 dlossQsigm:0.0378\n",
      "Episode:424 meanR:63.5200 rate:0.1780 gloss:0.0000 dloss:8.4646 dlossR:0.0000 dlossQsigm:0.0794\n",
      "Episode:425 meanR:63.4300 rate:0.1420 gloss:0.0001 dloss:2.4022 dlossR:0.0000 dlossQsigm:0.0680\n",
      "Episode:426 meanR:62.9000 rate:0.0660 gloss:0.0010 dloss:3.0406 dlossR:0.0000 dlossQsigm:0.0762\n",
      "Episode:427 meanR:62.9700 rate:0.1640 gloss:0.0000 dloss:2.4153 dlossR:0.0000 dlossQsigm:0.0635\n",
      "Episode:428 meanR:63.0100 rate:0.0800 gloss:0.0000 dloss:3.1309 dlossR:0.0000 dlossQsigm:0.0767\n",
      "Episode:429 meanR:62.8900 rate:0.0740 gloss:0.0051 dloss:3.2003 dlossR:0.0000 dlossQsigm:0.0773\n",
      "Episode:430 meanR:62.5200 rate:0.1420 gloss:0.0058 dloss:3.0893 dlossR:0.0000 dlossQsigm:0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:431 meanR:62.5700 rate:0.0780 gloss:0.0018 dloss:2.8764 dlossR:0.0000 dlossQsigm:0.0644\n",
      "Episode:432 meanR:61.7200 rate:0.0940 gloss:0.0000 dloss:2.4951 dlossR:0.0000 dlossQsigm:0.0582\n",
      "Episode:433 meanR:61.7300 rate:0.0680 gloss:0.0000 dloss:2.0041 dlossR:0.0000 dlossQsigm:0.0551\n",
      "Episode:434 meanR:61.8800 rate:0.0880 gloss:0.0000 dloss:3.4748 dlossR:0.0000 dlossQsigm:0.0734\n",
      "Episode:435 meanR:61.7100 rate:0.0840 gloss:0.0000 dloss:2.4669 dlossR:0.0000 dlossQsigm:0.0606\n",
      "Episode:436 meanR:61.6800 rate:0.0920 gloss:0.0000 dloss:2.7972 dlossR:0.0000 dlossQsigm:0.0709\n",
      "Episode:437 meanR:61.8800 rate:0.1100 gloss:0.0000 dloss:1.7448 dlossR:0.0000 dlossQsigm:0.0462\n",
      "Episode:438 meanR:61.7500 rate:0.0620 gloss:0.0000 dloss:2.3500 dlossR:0.0000 dlossQsigm:0.0793\n",
      "Episode:439 meanR:61.7500 rate:0.0640 gloss:0.0000 dloss:2.6423 dlossR:0.0000 dlossQsigm:0.0481\n",
      "Episode:440 meanR:61.9900 rate:0.1560 gloss:0.0002 dloss:4.4265 dlossR:0.0000 dlossQsigm:0.0682\n",
      "Episode:441 meanR:61.7600 rate:0.0640 gloss:0.0000 dloss:2.9907 dlossR:0.0000 dlossQsigm:0.0483\n",
      "Episode:442 meanR:61.9700 rate:0.1340 gloss:0.0000 dloss:3.1838 dlossR:0.0000 dlossQsigm:0.0562\n",
      "Episode:443 meanR:61.3100 rate:0.0660 gloss:0.0000 dloss:1.5264 dlossR:0.0000 dlossQsigm:0.0341\n",
      "Episode:444 meanR:60.6200 rate:0.0680 gloss:0.0007 dloss:1.8204 dlossR:0.0000 dlossQsigm:0.0449\n",
      "Episode:445 meanR:60.3800 rate:0.0700 gloss:0.0000 dloss:1.5943 dlossR:0.0000 dlossQsigm:0.0471\n",
      "Episode:446 meanR:59.8000 rate:0.0660 gloss:0.0001 dloss:1.6554 dlossR:0.0000 dlossQsigm:0.0333\n",
      "Episode:447 meanR:59.0800 rate:0.0700 gloss:0.0000 dloss:1.3729 dlossR:0.0000 dlossQsigm:0.0482\n",
      "Episode:448 meanR:59.1200 rate:0.0980 gloss:0.0002 dloss:1.9212 dlossR:0.0000 dlossQsigm:0.0618\n",
      "Episode:449 meanR:59.4500 rate:0.1360 gloss:0.0000 dloss:2.0200 dlossR:0.0000 dlossQsigm:0.0404\n",
      "Episode:450 meanR:59.3600 rate:0.0800 gloss:0.0013 dloss:1.5265 dlossR:0.0000 dlossQsigm:0.0480\n",
      "Episode:451 meanR:58.8600 rate:0.0640 gloss:0.0000 dloss:2.4331 dlossR:0.0000 dlossQsigm:0.0447\n",
      "Episode:452 meanR:58.0200 rate:0.0740 gloss:0.0000 dloss:1.1284 dlossR:0.0000 dlossQsigm:0.0374\n",
      "Episode:453 meanR:58.1300 rate:0.1040 gloss:0.0001 dloss:1.9315 dlossR:0.0000 dlossQsigm:0.0559\n",
      "Episode:454 meanR:57.9900 rate:0.0740 gloss:0.0000 dloss:1.1978 dlossR:0.0000 dlossQsigm:0.0373\n",
      "Episode:455 meanR:58.7000 rate:0.2200 gloss:0.0054 dloss:3.0097 dlossR:0.0000 dlossQsigm:0.0587\n",
      "Episode:456 meanR:58.5200 rate:0.0940 gloss:0.0000 dloss:1.4730 dlossR:0.0000 dlossQsigm:0.0486\n",
      "Episode:457 meanR:58.4600 rate:0.0820 gloss:0.0002 dloss:3.6062 dlossR:0.0000 dlossQsigm:0.0543\n",
      "Episode:458 meanR:57.8300 rate:0.1420 gloss:0.0001 dloss:4.6794 dlossR:0.0000 dlossQsigm:0.0569\n",
      "Episode:459 meanR:57.8700 rate:0.0760 gloss:0.0000 dloss:2.6682 dlossR:0.0000 dlossQsigm:0.0639\n",
      "Episode:460 meanR:58.1800 rate:0.1600 gloss:0.0001 dloss:3.9457 dlossR:0.0000 dlossQsigm:0.0705\n",
      "Episode:461 meanR:58.1900 rate:0.1060 gloss:0.0000 dloss:8.7298 dlossR:0.0000 dlossQsigm:0.0955\n",
      "Episode:462 meanR:57.5200 rate:0.0760 gloss:0.0000 dloss:3.0867 dlossR:0.0000 dlossQsigm:0.0708\n",
      "Episode:463 meanR:58.0000 rate:0.1620 gloss:0.0000 dloss:2.7391 dlossR:0.0000 dlossQsigm:0.0635\n",
      "Episode:464 meanR:58.4300 rate:0.1460 gloss:0.0003 dloss:4.2884 dlossR:0.0000 dlossQsigm:0.0563\n",
      "Episode:465 meanR:58.5400 rate:0.1520 gloss:0.0000 dloss:3.3103 dlossR:0.0000 dlossQsigm:0.0727\n",
      "Episode:466 meanR:57.3000 rate:0.0640 gloss:0.0002 dloss:5.6348 dlossR:0.0000 dlossQsigm:0.0741\n",
      "Episode:467 meanR:57.1100 rate:0.1160 gloss:0.0000 dloss:2.7317 dlossR:0.0000 dlossQsigm:0.0501\n",
      "Episode:468 meanR:57.2000 rate:0.0700 gloss:0.0241 dloss:1.3717 dlossR:0.0000 dlossQsigm:0.0394\n",
      "Episode:469 meanR:57.5100 rate:0.1280 gloss:0.0000 dloss:1.5770 dlossR:0.0000 dlossQsigm:0.0428\n",
      "Episode:470 meanR:57.2800 rate:0.1700 gloss:0.0000 dloss:2.4324 dlossR:0.0000 dlossQsigm:0.0597\n",
      "Episode:471 meanR:57.3100 rate:0.0700 gloss:0.0126 dloss:1.7137 dlossR:0.0000 dlossQsigm:0.0510\n",
      "Episode:472 meanR:57.1500 rate:0.1040 gloss:0.0008 dloss:2.2431 dlossR:0.0000 dlossQsigm:0.0600\n",
      "Episode:473 meanR:57.0000 rate:0.0680 gloss:0.0000 dloss:1.7896 dlossR:0.0000 dlossQsigm:0.0467\n",
      "Episode:474 meanR:56.7700 rate:0.0780 gloss:0.0002 dloss:1.4554 dlossR:0.0000 dlossQsigm:0.0427\n",
      "Episode:475 meanR:56.8000 rate:0.1300 gloss:0.0000 dloss:1.5407 dlossR:0.0000 dlossQsigm:0.0455\n",
      "Episode:476 meanR:57.1200 rate:0.2200 gloss:0.0001 dloss:2.8990 dlossR:0.0000 dlossQsigm:0.0498\n",
      "Episode:477 meanR:57.0500 rate:0.0920 gloss:0.0003 dloss:2.7254 dlossR:0.0000 dlossQsigm:0.0583\n",
      "Episode:478 meanR:57.2500 rate:0.1440 gloss:0.0002 dloss:2.4351 dlossR:0.0000 dlossQsigm:0.0526\n",
      "Episode:479 meanR:57.4200 rate:0.1560 gloss:0.0001 dloss:5.7025 dlossR:0.0000 dlossQsigm:0.0684\n",
      "Episode:480 meanR:57.2400 rate:0.0660 gloss:0.0002 dloss:1.9427 dlossR:0.0000 dlossQsigm:0.0409\n",
      "Episode:481 meanR:56.1000 rate:0.0880 gloss:0.0000 dloss:2.2170 dlossR:0.0000 dlossQsigm:0.0562\n",
      "Episode:482 meanR:55.4900 rate:0.0840 gloss:0.0000 dloss:1.3626 dlossR:0.0000 dlossQsigm:0.0423\n",
      "Episode:483 meanR:54.9400 rate:0.0680 gloss:0.0000 dloss:1.9336 dlossR:0.0000 dlossQsigm:0.0377\n",
      "Episode:484 meanR:54.8700 rate:0.1060 gloss:0.0000 dloss:0.9734 dlossR:0.0000 dlossQsigm:0.0372\n",
      "Episode:485 meanR:54.7300 rate:0.0660 gloss:0.0006 dloss:1.9084 dlossR:0.0001 dlossQsigm:0.0330\n",
      "Episode:486 meanR:54.1500 rate:0.0820 gloss:0.0000 dloss:1.4397 dlossR:0.0000 dlossQsigm:0.0409\n",
      "Episode:487 meanR:53.9800 rate:0.0680 gloss:0.0000 dloss:2.6174 dlossR:0.0000 dlossQsigm:0.0522\n",
      "Episode:488 meanR:53.8300 rate:0.1340 gloss:0.0004 dloss:6.5434 dlossR:0.0000 dlossQsigm:0.0790\n",
      "Episode:489 meanR:53.8900 rate:0.1160 gloss:0.0000 dloss:3.3242 dlossR:0.0000 dlossQsigm:0.0442\n",
      "Episode:490 meanR:53.5500 rate:0.0700 gloss:0.0000 dloss:3.2974 dlossR:0.0000 dlossQsigm:0.0341\n",
      "Episode:491 meanR:53.4500 rate:0.0620 gloss:0.0001 dloss:2.3328 dlossR:0.0000 dlossQsigm:0.0665\n",
      "Episode:492 meanR:53.2500 rate:0.0820 gloss:0.0002 dloss:1.0957 dlossR:0.0000 dlossQsigm:0.0333\n",
      "Episode:493 meanR:52.9300 rate:0.0860 gloss:0.0002 dloss:1.7969 dlossR:0.0000 dlossQsigm:0.0391\n",
      "Episode:494 meanR:52.6200 rate:0.0680 gloss:0.0002 dloss:1.7046 dlossR:0.0000 dlossQsigm:0.0423\n",
      "Episode:495 meanR:52.6800 rate:0.1140 gloss:0.0000 dloss:0.9834 dlossR:0.0000 dlossQsigm:0.0382\n",
      "Episode:496 meanR:52.4100 rate:0.0600 gloss:0.0000 dloss:2.8600 dlossR:0.0000 dlossQsigm:0.0864\n",
      "Episode:497 meanR:51.7500 rate:0.0740 gloss:0.0004 dloss:1.1304 dlossR:0.0000 dlossQsigm:0.0381\n",
      "Episode:498 meanR:51.6500 rate:0.0980 gloss:0.0000 dloss:1.9977 dlossR:0.0000 dlossQsigm:0.0394\n",
      "Episode:499 meanR:51.2700 rate:0.0760 gloss:0.0000 dloss:1.5661 dlossR:0.0000 dlossQsigm:0.0533\n",
      "Episode:500 meanR:51.2800 rate:0.1280 gloss:0.0000 dloss:2.5171 dlossR:0.0000 dlossQsigm:0.0522\n",
      "Episode:501 meanR:50.9800 rate:0.0660 gloss:0.0000 dloss:4.1254 dlossR:0.0000 dlossQsigm:0.0645\n",
      "Episode:502 meanR:50.8600 rate:0.0900 gloss:0.0000 dloss:2.1495 dlossR:0.0000 dlossQsigm:0.0568\n",
      "Episode:503 meanR:50.5500 rate:0.0740 gloss:0.0000 dloss:3.8657 dlossR:0.0000 dlossQsigm:0.0376\n",
      "Episode:504 meanR:50.4500 rate:0.0900 gloss:0.0000 dloss:1.6127 dlossR:0.0000 dlossQsigm:0.0416\n",
      "Episode:505 meanR:50.3700 rate:0.0680 gloss:0.0073 dloss:1.5162 dlossR:0.0000 dlossQsigm:0.0448\n",
      "Episode:506 meanR:50.3700 rate:0.0940 gloss:0.0001 dloss:1.1147 dlossR:0.0000 dlossQsigm:0.0419\n",
      "Episode:507 meanR:50.2200 rate:0.0860 gloss:0.0000 dloss:0.5615 dlossR:0.0004 dlossQsigm:0.0350\n",
      "Episode:508 meanR:49.9500 rate:0.0600 gloss:0.0000 dloss:1.7683 dlossR:0.0008 dlossQsigm:0.0735\n",
      "Episode:509 meanR:49.8500 rate:0.0700 gloss:0.0001 dloss:1.1164 dlossR:0.0043 dlossQsigm:0.0510\n",
      "Episode:510 meanR:49.3200 rate:0.0840 gloss:0.0000 dloss:1.4725 dlossR:0.0001 dlossQsigm:0.0432\n",
      "Episode:511 meanR:49.2800 rate:0.0820 gloss:0.0006 dloss:1.1531 dlossR:0.0000 dlossQsigm:0.0370\n",
      "Episode:512 meanR:49.0700 rate:0.0760 gloss:0.0015 dloss:1.6296 dlossR:0.0000 dlossQsigm:0.0487\n",
      "Episode:513 meanR:48.9100 rate:0.0920 gloss:0.0000 dloss:1.6103 dlossR:0.0000 dlossQsigm:0.0442\n",
      "Episode:514 meanR:48.7100 rate:0.0620 gloss:0.0000 dloss:1.3265 dlossR:0.0001 dlossQsigm:0.0700\n",
      "Episode:515 meanR:48.4800 rate:0.0740 gloss:0.0020 dloss:1.6119 dlossR:0.0009 dlossQsigm:0.0399\n",
      "Episode:516 meanR:48.2700 rate:0.0660 gloss:0.0000 dloss:1.4643 dlossR:0.0003 dlossQsigm:0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:517 meanR:48.0100 rate:0.0640 gloss:0.0000 dloss:2.7913 dlossR:0.0004 dlossQsigm:0.0441\n",
      "Episode:518 meanR:47.7400 rate:0.0620 gloss:0.0000 dloss:1.6531 dlossR:0.0000 dlossQsigm:0.0737\n",
      "Episode:519 meanR:48.0800 rate:0.1760 gloss:0.0000 dloss:3.1018 dlossR:0.0000 dlossQsigm:0.0761\n",
      "Episode:520 meanR:48.4300 rate:0.1580 gloss:0.0000 dloss:1.5430 dlossR:0.0002 dlossQsigm:0.0337\n",
      "Episode:521 meanR:48.3800 rate:0.0820 gloss:0.0001 dloss:2.1235 dlossR:0.0001 dlossQsigm:0.0348\n",
      "Episode:522 meanR:48.3400 rate:0.0720 gloss:0.0000 dloss:1.6633 dlossR:0.0013 dlossQsigm:0.0513\n",
      "Episode:523 meanR:48.7500 rate:0.1700 gloss:0.0020 dloss:3.9396 dlossR:0.0000 dlossQsigm:0.0329\n",
      "Episode:524 meanR:48.3400 rate:0.0960 gloss:0.0003 dloss:1.8004 dlossR:0.0000 dlossQsigm:0.0375\n",
      "Episode:525 meanR:48.3200 rate:0.1380 gloss:0.0000 dloss:5.9621 dlossR:0.0000 dlossQsigm:0.0859\n",
      "Episode:526 meanR:48.4000 rate:0.0820 gloss:0.0000 dloss:4.6207 dlossR:0.0000 dlossQsigm:0.0460\n",
      "Episode:527 meanR:47.9600 rate:0.0760 gloss:0.0000 dloss:1.2547 dlossR:0.0003 dlossQsigm:0.0316\n",
      "Episode:528 meanR:48.0700 rate:0.1020 gloss:0.0002 dloss:2.9524 dlossR:0.0000 dlossQsigm:0.0510\n",
      "Episode:529 meanR:48.1300 rate:0.0860 gloss:0.0000 dloss:5.3309 dlossR:0.0000 dlossQsigm:0.0829\n",
      "Episode:530 meanR:48.1800 rate:0.1520 gloss:0.0000 dloss:3.1488 dlossR:0.0000 dlossQsigm:0.0541\n",
      "Episode:531 meanR:48.2600 rate:0.0940 gloss:0.0002 dloss:2.7045 dlossR:0.0000 dlossQsigm:0.0580\n",
      "Episode:532 meanR:48.1200 rate:0.0660 gloss:0.0000 dloss:1.4680 dlossR:0.0000 dlossQsigm:0.0428\n",
      "Episode:533 meanR:48.5200 rate:0.1480 gloss:0.0001 dloss:3.4982 dlossR:0.0000 dlossQsigm:0.0651\n",
      "Episode:534 meanR:48.5100 rate:0.0860 gloss:0.0000 dloss:1.6864 dlossR:0.0005 dlossQsigm:0.0297\n",
      "Episode:535 meanR:48.4300 rate:0.0680 gloss:0.0000 dloss:1.9753 dlossR:0.0001 dlossQsigm:0.0405\n",
      "Episode:536 meanR:48.3400 rate:0.0740 gloss:0.0000 dloss:1.5011 dlossR:0.0001 dlossQsigm:0.0319\n",
      "Episode:537 meanR:48.1500 rate:0.0720 gloss:0.0000 dloss:3.0798 dlossR:0.0000 dlossQsigm:0.0381\n",
      "Episode:538 meanR:48.1300 rate:0.0580 gloss:0.0000 dloss:3.6056 dlossR:0.0000 dlossQsigm:0.1271\n",
      "Episode:539 meanR:48.4400 rate:0.1260 gloss:0.0000 dloss:10.6027 dlossR:0.0000 dlossQsigm:0.0504\n",
      "Episode:540 meanR:48.0000 rate:0.0680 gloss:0.0001 dloss:2.4964 dlossR:0.0000 dlossQsigm:0.0522\n",
      "Episode:541 meanR:48.4300 rate:0.1500 gloss:0.0001 dloss:4.5559 dlossR:0.0000 dlossQsigm:0.0754\n",
      "Episode:542 meanR:48.0800 rate:0.0640 gloss:0.0000 dloss:4.1363 dlossR:0.0000 dlossQsigm:0.0554\n",
      "Episode:543 meanR:48.0500 rate:0.0600 gloss:0.0000 dloss:3.6636 dlossR:0.0000 dlossQsigm:0.1050\n",
      "Episode:544 meanR:48.0200 rate:0.0620 gloss:0.0000 dloss:1.8075 dlossR:0.0000 dlossQsigm:0.0830\n",
      "Episode:545 meanR:48.1000 rate:0.0860 gloss:0.0000 dloss:1.3959 dlossR:0.0000 dlossQsigm:0.0442\n",
      "Episode:546 meanR:48.1000 rate:0.0660 gloss:0.0000 dloss:2.7491 dlossR:0.0000 dlossQsigm:0.0663\n",
      "Episode:547 meanR:48.0400 rate:0.0580 gloss:0.0000 dloss:3.4787 dlossR:0.0000 dlossQsigm:0.1181\n",
      "Episode:548 meanR:47.9200 rate:0.0740 gloss:0.0000 dloss:1.4596 dlossR:0.0000 dlossQsigm:0.0551\n",
      "Episode:549 meanR:47.6500 rate:0.0820 gloss:0.0004 dloss:2.1810 dlossR:0.0000 dlossQsigm:0.0364\n",
      "Episode:550 meanR:47.6200 rate:0.0740 gloss:0.0000 dloss:2.2856 dlossR:0.0000 dlossQsigm:0.0473\n",
      "Episode:551 meanR:47.6200 rate:0.0640 gloss:0.0000 dloss:5.5732 dlossR:0.0000 dlossQsigm:0.0538\n",
      "Episode:552 meanR:47.6100 rate:0.0720 gloss:0.0000 dloss:1.9074 dlossR:0.0000 dlossQsigm:0.0470\n",
      "Episode:553 meanR:47.4200 rate:0.0660 gloss:0.0000 dloss:1.4571 dlossR:0.0000 dlossQsigm:0.0388\n",
      "Episode:554 meanR:47.5800 rate:0.1060 gloss:0.0000 dloss:10.8415 dlossR:0.0000 dlossQsigm:0.1143\n",
      "Episode:555 meanR:46.7700 rate:0.0580 gloss:0.0001 dloss:10.2618 dlossR:0.0000 dlossQsigm:0.1791\n",
      "Episode:556 meanR:46.6200 rate:0.0640 gloss:0.0000 dloss:9.3255 dlossR:0.0000 dlossQsigm:0.1292\n",
      "Episode:557 meanR:46.5600 rate:0.0700 gloss:0.0000 dloss:4.2562 dlossR:0.0000 dlossQsigm:0.0910\n",
      "Episode:558 meanR:46.1400 rate:0.0580 gloss:0.0000 dloss:8.7729 dlossR:0.0000 dlossQsigm:0.1864\n",
      "Episode:559 meanR:46.0500 rate:0.0580 gloss:0.0012 dloss:7.7571 dlossR:0.0000 dlossQsigm:0.1797\n",
      "Episode:560 meanR:45.5500 rate:0.0600 gloss:0.0000 dloss:8.4170 dlossR:0.0000 dlossQsigm:0.1882\n",
      "Episode:561 meanR:45.4000 rate:0.0760 gloss:0.0000 dloss:1.9683 dlossR:0.0000 dlossQsigm:0.0383\n",
      "Episode:562 meanR:45.3300 rate:0.0620 gloss:0.0000 dloss:4.3337 dlossR:0.0003 dlossQsigm:0.1084\n",
      "Episode:563 meanR:44.8400 rate:0.0640 gloss:0.0002 dloss:3.0006 dlossR:0.0000 dlossQsigm:0.0515\n",
      "Episode:564 meanR:44.4100 rate:0.0600 gloss:0.0000 dloss:1.9890 dlossR:0.0000 dlossQsigm:0.0746\n",
      "Episode:565 meanR:44.2400 rate:0.1180 gloss:0.0000 dloss:3.8406 dlossR:0.0000 dlossQsigm:0.0698\n",
      "Episode:566 meanR:44.2100 rate:0.0580 gloss:0.0000 dloss:4.0295 dlossR:0.0049 dlossQsigm:0.1058\n",
      "Episode:567 meanR:43.9900 rate:0.0720 gloss:0.0061 dloss:3.2225 dlossR:0.0000 dlossQsigm:0.0599\n",
      "Episode:568 meanR:44.2500 rate:0.1220 gloss:0.0056 dloss:3.7666 dlossR:0.0000 dlossQsigm:0.0782\n",
      "Episode:569 meanR:44.4500 rate:0.1680 gloss:0.0000 dloss:8.0092 dlossR:0.0000 dlossQsigm:0.1180\n",
      "Episode:570 meanR:43.8800 rate:0.0560 gloss:0.0000 dloss:6.4789 dlossR:0.0000 dlossQsigm:0.1536\n",
      "Episode:571 meanR:44.0000 rate:0.0940 gloss:0.0004 dloss:5.6145 dlossR:0.0000 dlossQsigm:0.1042\n",
      "Episode:572 meanR:43.9000 rate:0.0840 gloss:0.0000 dloss:2.3516 dlossR:0.0000 dlossQsigm:0.0490\n",
      "Episode:573 meanR:43.9200 rate:0.0720 gloss:0.0006 dloss:2.6662 dlossR:0.0000 dlossQsigm:0.0393\n",
      "Episode:574 meanR:43.9900 rate:0.0920 gloss:0.0001 dloss:3.5141 dlossR:0.0000 dlossQsigm:0.0374\n",
      "Episode:575 meanR:43.7200 rate:0.0760 gloss:0.0003 dloss:1.6424 dlossR:0.0000 dlossQsigm:0.0470\n",
      "Episode:576 meanR:42.9000 rate:0.0560 gloss:0.0001 dloss:4.2397 dlossR:0.0006 dlossQsigm:0.0827\n",
      "Episode:577 meanR:42.8500 rate:0.0820 gloss:0.0000 dloss:1.1056 dlossR:0.0015 dlossQsigm:0.0385\n",
      "Episode:578 meanR:42.4700 rate:0.0680 gloss:0.0022 dloss:1.1017 dlossR:0.0000 dlossQsigm:0.0328\n",
      "Episode:579 meanR:42.1700 rate:0.0960 gloss:0.0000 dloss:1.3171 dlossR:0.0089 dlossQsigm:0.0814\n",
      "Episode:580 meanR:42.1200 rate:0.0560 gloss:0.0000 dloss:1.6136 dlossR:0.0013 dlossQsigm:0.0639\n",
      "Episode:581 meanR:42.0700 rate:0.0780 gloss:0.0001 dloss:0.9044 dlossR:0.0117 dlossQsigm:0.0721\n",
      "Episode:582 meanR:41.9600 rate:0.0620 gloss:0.0000 dloss:1.2944 dlossR:0.0003 dlossQsigm:0.0576\n",
      "Episode:583 meanR:42.2800 rate:0.1320 gloss:0.0000 dloss:2.0314 dlossR:0.0002 dlossQsigm:0.0360\n",
      "Episode:584 meanR:42.0500 rate:0.0600 gloss:0.0001 dloss:1.2082 dlossR:0.0011 dlossQsigm:0.0601\n",
      "Episode:585 meanR:42.0100 rate:0.0580 gloss:0.0000 dloss:1.1118 dlossR:0.0047 dlossQsigm:0.0785\n",
      "Episode:586 meanR:42.0100 rate:0.0820 gloss:0.0000 dloss:2.2378 dlossR:0.0000 dlossQsigm:0.0344\n",
      "Episode:587 meanR:42.1000 rate:0.0860 gloss:0.0012 dloss:1.1563 dlossR:0.0000 dlossQsigm:0.0344\n",
      "Episode:588 meanR:41.7300 rate:0.0600 gloss:0.0000 dloss:1.4588 dlossR:0.0002 dlossQsigm:0.0601\n",
      "Episode:589 meanR:41.4900 rate:0.0680 gloss:0.0002 dloss:2.1520 dlossR:0.0019 dlossQsigm:0.0533\n",
      "Episode:590 meanR:41.4300 rate:0.0580 gloss:0.0007 dloss:1.3387 dlossR:0.0090 dlossQsigm:0.0844\n",
      "Episode:591 meanR:41.5000 rate:0.0760 gloss:0.0063 dloss:1.2270 dlossR:0.0013 dlossQsigm:0.0415\n",
      "Episode:592 meanR:41.3800 rate:0.0580 gloss:0.0085 dloss:1.4765 dlossR:0.0043 dlossQsigm:0.0729\n",
      "Episode:593 meanR:41.4000 rate:0.0900 gloss:0.0000 dloss:1.2473 dlossR:0.0001 dlossQsigm:0.0337\n",
      "Episode:594 meanR:41.6200 rate:0.1120 gloss:0.0287 dloss:5.7171 dlossR:0.0000 dlossQsigm:0.0569\n",
      "Episode:595 meanR:41.3200 rate:0.0540 gloss:0.0018 dloss:2.4093 dlossR:0.0007 dlossQsigm:0.0735\n",
      "Episode:596 meanR:41.3200 rate:0.0600 gloss:0.0005 dloss:1.0397 dlossR:0.0019 dlossQsigm:0.0629\n",
      "Episode:597 meanR:41.2500 rate:0.0600 gloss:0.0000 dloss:2.7307 dlossR:0.0395 dlossQsigm:0.1528\n",
      "Episode:598 meanR:41.3100 rate:0.1100 gloss:0.0000 dloss:1.8801 dlossR:0.0129 dlossQsigm:0.1016\n",
      "Episode:599 meanR:41.2400 rate:0.0620 gloss:0.0000 dloss:2.2285 dlossR:0.0085 dlossQsigm:0.0826\n",
      "Episode:600 meanR:40.9200 rate:0.0640 gloss:0.0000 dloss:3.7568 dlossR:0.0166 dlossQsigm:0.1026\n",
      "Episode:601 meanR:41.1900 rate:0.1200 gloss:0.0000 dloss:1.8283 dlossR:0.0002 dlossQsigm:0.0293\n",
      "Episode:602 meanR:41.0600 rate:0.0640 gloss:0.0008 dloss:3.4584 dlossR:0.0309 dlossQsigm:0.1544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:603 meanR:41.0400 rate:0.0700 gloss:0.0000 dloss:1.3719 dlossR:0.0005 dlossQsigm:0.0372\n",
      "Episode:604 meanR:41.3100 rate:0.1440 gloss:0.0000 dloss:4.6723 dlossR:0.0000 dlossQsigm:0.0777\n",
      "Episode:605 meanR:41.4900 rate:0.1040 gloss:0.0000 dloss:2.2147 dlossR:0.0000 dlossQsigm:0.0340\n",
      "Episode:606 meanR:41.9500 rate:0.1860 gloss:0.0035 dloss:3.5707 dlossR:0.0000 dlossQsigm:0.0629\n",
      "Episode:607 meanR:42.2000 rate:0.1360 gloss:0.0000 dloss:1.8466 dlossR:0.0000 dlossQsigm:0.0428\n",
      "Episode:608 meanR:42.2900 rate:0.0780 gloss:0.0000 dloss:1.2084 dlossR:0.0000 dlossQsigm:0.0366\n",
      "Episode:609 meanR:42.6800 rate:0.1480 gloss:0.0000 dloss:1.7887 dlossR:0.0000 dlossQsigm:0.0439\n",
      "Episode:610 meanR:42.6200 rate:0.0720 gloss:0.0000 dloss:1.5753 dlossR:0.0001 dlossQsigm:0.0312\n",
      "Episode:611 meanR:42.5500 rate:0.0680 gloss:0.0000 dloss:1.8479 dlossR:0.0013 dlossQsigm:0.0452\n",
      "Episode:612 meanR:42.5100 rate:0.0680 gloss:0.0000 dloss:1.3145 dlossR:0.0028 dlossQsigm:0.0525\n",
      "Episode:613 meanR:42.4100 rate:0.0720 gloss:0.0000 dloss:1.3928 dlossR:0.0032 dlossQsigm:0.0366\n",
      "Episode:614 meanR:42.4000 rate:0.0600 gloss:0.0000 dloss:2.0531 dlossR:0.0119 dlossQsigm:0.0821\n",
      "Episode:615 meanR:42.4500 rate:0.0840 gloss:0.0000 dloss:1.7269 dlossR:0.0001 dlossQsigm:0.0321\n",
      "Episode:616 meanR:42.4900 rate:0.0740 gloss:0.0000 dloss:1.0045 dlossR:0.0001 dlossQsigm:0.0435\n",
      "Episode:617 meanR:42.6700 rate:0.1000 gloss:0.0002 dloss:1.5469 dlossR:0.0000 dlossQsigm:0.0535\n",
      "Episode:618 meanR:42.7200 rate:0.0720 gloss:0.0000 dloss:1.1366 dlossR:0.0000 dlossQsigm:0.0326\n",
      "Episode:619 meanR:42.2400 rate:0.0800 gloss:0.0000 dloss:1.0055 dlossR:0.0001 dlossQsigm:0.0316\n",
      "Episode:620 meanR:41.7400 rate:0.0580 gloss:0.0014 dloss:2.0545 dlossR:0.0000 dlossQsigm:0.0738\n",
      "Episode:621 meanR:41.9200 rate:0.1180 gloss:0.0002 dloss:2.4909 dlossR:0.0000 dlossQsigm:0.0367\n",
      "Episode:622 meanR:41.9800 rate:0.0840 gloss:0.0000 dloss:1.6735 dlossR:0.0000 dlossQsigm:0.0373\n",
      "Episode:623 meanR:41.4200 rate:0.0580 gloss:0.0000 dloss:1.5989 dlossR:0.0017 dlossQsigm:0.0794\n",
      "Episode:624 meanR:41.3800 rate:0.0880 gloss:0.0000 dloss:2.4932 dlossR:0.0001 dlossQsigm:0.0400\n",
      "Episode:625 meanR:41.1600 rate:0.0940 gloss:0.0000 dloss:1.1633 dlossR:0.0003 dlossQsigm:0.0422\n",
      "Episode:626 meanR:41.2700 rate:0.1040 gloss:0.0000 dloss:3.4903 dlossR:0.0000 dlossQsigm:0.0705\n",
      "Episode:627 meanR:41.2300 rate:0.0680 gloss:0.0000 dloss:1.2563 dlossR:0.0492 dlossQsigm:0.1292\n",
      "Episode:628 meanR:41.1100 rate:0.0780 gloss:0.0001 dloss:1.5223 dlossR:0.0002 dlossQsigm:0.0453\n",
      "Episode:629 meanR:40.9900 rate:0.0620 gloss:0.0002 dloss:5.3319 dlossR:0.0000 dlossQsigm:0.0849\n",
      "Episode:630 meanR:40.6400 rate:0.0820 gloss:0.0000 dloss:2.3961 dlossR:0.0000 dlossQsigm:0.0411\n",
      "Episode:631 meanR:40.6400 rate:0.0940 gloss:0.0000 dloss:1.9959 dlossR:0.0000 dlossQsigm:0.0567\n",
      "Episode:632 meanR:40.5900 rate:0.0560 gloss:0.0000 dloss:1.7314 dlossR:0.0003 dlossQsigm:0.0696\n",
      "Episode:633 meanR:40.4300 rate:0.1160 gloss:0.0000 dloss:1.5727 dlossR:0.0001 dlossQsigm:0.0349\n",
      "Episode:634 meanR:40.3000 rate:0.0600 gloss:0.0264 dloss:0.7812 dlossR:0.0012 dlossQsigm:0.0580\n",
      "Episode:635 meanR:40.2600 rate:0.0600 gloss:0.0000 dloss:2.0780 dlossR:0.0153 dlossQsigm:0.1011\n",
      "Episode:636 meanR:40.4500 rate:0.1120 gloss:0.0000 dloss:6.4299 dlossR:0.0000 dlossQsigm:0.0917\n",
      "Episode:637 meanR:40.6000 rate:0.1020 gloss:0.0001 dloss:2.9485 dlossR:0.0000 dlossQsigm:0.0736\n",
      "Episode:638 meanR:41.1300 rate:0.1640 gloss:0.0036 dloss:4.7319 dlossR:0.0000 dlossQsigm:0.0621\n",
      "Episode:639 meanR:40.9700 rate:0.0940 gloss:0.0000 dloss:1.5527 dlossR:0.0000 dlossQsigm:0.0468\n",
      "Episode:640 meanR:41.1800 rate:0.1100 gloss:0.0000 dloss:3.4613 dlossR:0.0000 dlossQsigm:0.0577\n",
      "Episode:641 meanR:40.7600 rate:0.0660 gloss:0.0000 dloss:1.7437 dlossR:0.0000 dlossQsigm:0.0390\n",
      "Episode:642 meanR:40.7800 rate:0.0680 gloss:0.0150 dloss:4.2978 dlossR:0.0000 dlossQsigm:0.0381\n",
      "Episode:643 meanR:40.8100 rate:0.0660 gloss:0.0000 dloss:1.3853 dlossR:0.0186 dlossQsigm:0.1201\n",
      "Episode:644 meanR:41.1100 rate:0.1220 gloss:0.0000 dloss:5.0414 dlossR:0.0000 dlossQsigm:0.0583\n",
      "Episode:645 meanR:40.9700 rate:0.0580 gloss:0.0000 dloss:2.8880 dlossR:0.0002 dlossQsigm:0.0822\n",
      "Episode:646 meanR:41.0100 rate:0.0740 gloss:0.0000 dloss:1.4824 dlossR:0.0006 dlossQsigm:0.0415\n",
      "Episode:647 meanR:41.0400 rate:0.0640 gloss:0.0000 dloss:2.3694 dlossR:0.0005 dlossQsigm:0.0525\n",
      "Episode:648 meanR:41.3400 rate:0.1340 gloss:0.0000 dloss:3.4226 dlossR:0.0000 dlossQsigm:0.0633\n",
      "Episode:649 meanR:41.3200 rate:0.0780 gloss:0.0000 dloss:1.6746 dlossR:0.0006 dlossQsigm:0.0342\n",
      "Episode:650 meanR:41.2900 rate:0.0680 gloss:0.0000 dloss:2.5039 dlossR:0.0038 dlossQsigm:0.0731\n",
      "Episode:651 meanR:41.2800 rate:0.0620 gloss:0.0000 dloss:2.3960 dlossR:0.0000 dlossQsigm:0.0876\n",
      "Episode:652 meanR:41.2600 rate:0.0680 gloss:0.0000 dloss:2.5002 dlossR:0.0000 dlossQsigm:0.0550\n",
      "Episode:653 meanR:41.3900 rate:0.0920 gloss:0.0002 dloss:1.7020 dlossR:0.0000 dlossQsigm:0.0532\n",
      "Episode:654 meanR:41.2300 rate:0.0740 gloss:0.0000 dloss:1.6642 dlossR:0.0000 dlossQsigm:0.0523\n",
      "Episode:655 meanR:41.2900 rate:0.0700 gloss:0.0003 dloss:1.5607 dlossR:0.0000 dlossQsigm:0.0433\n",
      "Episode:656 meanR:41.5300 rate:0.1120 gloss:0.0000 dloss:2.0469 dlossR:0.0000 dlossQsigm:0.0473\n",
      "Episode:657 meanR:41.7100 rate:0.1060 gloss:0.0000 dloss:1.2872 dlossR:0.0002 dlossQsigm:0.0342\n",
      "Episode:658 meanR:41.9100 rate:0.0980 gloss:0.0000 dloss:2.7773 dlossR:0.0000 dlossQsigm:0.0563\n",
      "Episode:659 meanR:42.0400 rate:0.0840 gloss:0.0106 dloss:1.6644 dlossR:0.0000 dlossQsigm:0.0463\n",
      "Episode:660 meanR:42.0200 rate:0.0560 gloss:0.0001 dloss:4.1662 dlossR:0.0002 dlossQsigm:0.0944\n",
      "Episode:661 meanR:41.9300 rate:0.0580 gloss:0.0000 dloss:2.2993 dlossR:0.0116 dlossQsigm:0.1370\n",
      "Episode:662 meanR:42.3800 rate:0.1520 gloss:0.0000 dloss:6.1645 dlossR:0.0000 dlossQsigm:0.0956\n",
      "Episode:663 meanR:42.4500 rate:0.0780 gloss:0.0001 dloss:7.1658 dlossR:0.0000 dlossQsigm:0.1202\n",
      "Episode:664 meanR:42.8200 rate:0.1340 gloss:0.0001 dloss:13.1765 dlossR:0.0000 dlossQsigm:0.1419\n",
      "Episode:665 meanR:42.6400 rate:0.0820 gloss:0.0000 dloss:5.9956 dlossR:0.0000 dlossQsigm:0.0637\n",
      "Episode:666 meanR:42.6700 rate:0.0640 gloss:0.0000 dloss:7.9879 dlossR:0.0000 dlossQsigm:0.0545\n",
      "Episode:667 meanR:42.7400 rate:0.0860 gloss:0.0000 dloss:6.5129 dlossR:0.0000 dlossQsigm:0.1069\n",
      "Episode:668 meanR:42.5200 rate:0.0780 gloss:0.0000 dloss:4.3620 dlossR:0.0000 dlossQsigm:0.0604\n",
      "Episode:669 meanR:42.1300 rate:0.0900 gloss:0.0001 dloss:3.0830 dlossR:0.0003 dlossQsigm:0.0368\n",
      "Episode:670 meanR:42.1800 rate:0.0660 gloss:0.0000 dloss:3.2130 dlossR:0.0000 dlossQsigm:0.0485\n",
      "Episode:671 meanR:42.0600 rate:0.0700 gloss:0.0000 dloss:4.0241 dlossR:0.0000 dlossQsigm:0.0350\n",
      "Episode:672 meanR:42.2200 rate:0.1160 gloss:0.0000 dloss:6.3044 dlossR:0.0000 dlossQsigm:0.0346\n",
      "Episode:673 meanR:42.4900 rate:0.1260 gloss:0.0000 dloss:3.4891 dlossR:0.0000 dlossQsigm:0.0455\n",
      "Episode:674 meanR:42.3800 rate:0.0700 gloss:0.0000 dloss:3.1701 dlossR:0.0006 dlossQsigm:0.0349\n",
      "Episode:675 meanR:42.6300 rate:0.1260 gloss:0.0000 dloss:12.0597 dlossR:0.0000 dlossQsigm:0.1293\n",
      "Episode:676 meanR:42.7200 rate:0.0740 gloss:0.0000 dloss:2.3802 dlossR:0.0000 dlossQsigm:0.0445\n",
      "Episode:677 meanR:42.7400 rate:0.0860 gloss:0.0004 dloss:3.4376 dlossR:0.0000 dlossQsigm:0.0356\n",
      "Episode:678 meanR:42.8700 rate:0.0940 gloss:0.0001 dloss:3.3700 dlossR:0.0000 dlossQsigm:0.0393\n",
      "Episode:679 meanR:42.7500 rate:0.0720 gloss:0.0000 dloss:4.1602 dlossR:0.0000 dlossQsigm:0.0762\n",
      "Episode:680 meanR:43.0900 rate:0.1240 gloss:0.0869 dloss:6.4340 dlossR:0.0000 dlossQsigm:0.0718\n",
      "Episode:681 meanR:43.1900 rate:0.0980 gloss:0.0097 dloss:7.3387 dlossR:0.0002 dlossQsigm:0.0409\n",
      "Episode:682 meanR:43.3300 rate:0.0900 gloss:0.0000 dloss:2.0441 dlossR:0.0000 dlossQsigm:0.0491\n",
      "Episode:683 meanR:42.9500 rate:0.0560 gloss:0.0000 dloss:5.8009 dlossR:0.0000 dlossQsigm:0.1106\n",
      "Episode:684 meanR:42.9800 rate:0.0660 gloss:0.0034 dloss:2.8315 dlossR:0.0000 dlossQsigm:0.0389\n",
      "Episode:685 meanR:43.0900 rate:0.0800 gloss:0.0000 dloss:2.9837 dlossR:0.0000 dlossQsigm:0.0499\n",
      "Episode:686 meanR:43.0200 rate:0.0680 gloss:0.0000 dloss:3.6647 dlossR:0.0000 dlossQsigm:0.0720\n",
      "Episode:687 meanR:42.8500 rate:0.0520 gloss:0.0000 dloss:5.1043 dlossR:0.0000 dlossQsigm:0.1013\n",
      "Episode:688 meanR:43.0300 rate:0.0960 gloss:0.0000 dloss:2.2918 dlossR:0.0009 dlossQsigm:0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:689 meanR:43.0100 rate:0.0640 gloss:0.0000 dloss:10.7501 dlossR:0.0012 dlossQsigm:0.0617\n",
      "Episode:690 meanR:43.1200 rate:0.0800 gloss:0.0000 dloss:1.9868 dlossR:0.0001 dlossQsigm:0.0310\n",
      "Episode:691 meanR:43.2400 rate:0.1000 gloss:0.0119 dloss:9.1351 dlossR:0.0000 dlossQsigm:0.0575\n",
      "Episode:692 meanR:43.3900 rate:0.0880 gloss:0.0004 dloss:10.9536 dlossR:0.0000 dlossQsigm:0.0656\n",
      "Episode:693 meanR:43.4600 rate:0.1040 gloss:0.0000 dloss:4.8768 dlossR:0.0000 dlossQsigm:0.0527\n",
      "Episode:694 meanR:43.4500 rate:0.1100 gloss:0.0006 dloss:7.9817 dlossR:0.0000 dlossQsigm:0.0710\n",
      "Episode:695 meanR:43.4600 rate:0.0560 gloss:0.0001 dloss:6.1136 dlossR:0.0000 dlossQsigm:0.1423\n",
      "Episode:696 meanR:43.4900 rate:0.0660 gloss:0.0000 dloss:3.8920 dlossR:0.0000 dlossQsigm:0.0658\n",
      "Episode:697 meanR:43.7100 rate:0.1040 gloss:0.0000 dloss:3.8904 dlossR:0.0000 dlossQsigm:0.0724\n",
      "Episode:698 meanR:43.5500 rate:0.0780 gloss:0.0000 dloss:5.1965 dlossR:0.0000 dlossQsigm:0.0671\n",
      "Episode:699 meanR:43.7900 rate:0.1100 gloss:0.0000 dloss:5.5597 dlossR:0.0000 dlossQsigm:0.0939\n",
      "Episode:700 meanR:44.0600 rate:0.1180 gloss:0.0018 dloss:2.6837 dlossR:0.0000 dlossQsigm:0.0600\n",
      "Episode:701 meanR:43.8500 rate:0.0780 gloss:0.0000 dloss:2.2916 dlossR:0.0000 dlossQsigm:0.0642\n",
      "Episode:702 meanR:43.8800 rate:0.0700 gloss:0.0000 dloss:3.9640 dlossR:0.0000 dlossQsigm:0.0469\n",
      "Episode:703 meanR:44.2800 rate:0.1500 gloss:0.0000 dloss:5.9127 dlossR:0.0000 dlossQsigm:0.0605\n",
      "Episode:704 meanR:43.8900 rate:0.0660 gloss:0.0000 dloss:3.0181 dlossR:0.0000 dlossQsigm:0.0615\n",
      "Episode:705 meanR:43.8900 rate:0.1040 gloss:0.0033 dloss:9.5497 dlossR:0.0000 dlossQsigm:0.1336\n",
      "Episode:706 meanR:43.5600 rate:0.1200 gloss:0.0000 dloss:7.7026 dlossR:0.0000 dlossQsigm:0.1222\n",
      "Episode:707 meanR:43.2200 rate:0.0680 gloss:0.0000 dloss:6.6146 dlossR:0.0000 dlossQsigm:0.1096\n",
      "Episode:708 meanR:43.3100 rate:0.0960 gloss:0.0000 dloss:11.1636 dlossR:0.0000 dlossQsigm:0.1276\n",
      "Episode:709 meanR:43.1000 rate:0.1060 gloss:0.0000 dloss:10.1134 dlossR:0.0000 dlossQsigm:0.1283\n",
      "Episode:710 meanR:43.3100 rate:0.1140 gloss:0.0000 dloss:7.0836 dlossR:0.0000 dlossQsigm:0.0891\n",
      "Episode:711 meanR:43.4500 rate:0.0960 gloss:0.0000 dloss:10.4133 dlossR:0.0000 dlossQsigm:0.1274\n",
      "Episode:712 meanR:43.5600 rate:0.0900 gloss:0.0002 dloss:9.7320 dlossR:0.0000 dlossQsigm:0.1224\n",
      "Episode:713 meanR:43.6400 rate:0.0880 gloss:0.0000 dloss:8.1358 dlossR:0.0000 dlossQsigm:0.1243\n",
      "Episode:714 meanR:43.8100 rate:0.0940 gloss:0.0002 dloss:9.3417 dlossR:0.0000 dlossQsigm:0.1173\n",
      "Episode:715 meanR:43.9600 rate:0.1140 gloss:0.0000 dloss:7.4376 dlossR:0.0000 dlossQsigm:0.0972\n",
      "Episode:716 meanR:43.9000 rate:0.0620 gloss:0.0000 dloss:8.1267 dlossR:0.0000 dlossQsigm:0.1775\n",
      "Episode:717 meanR:43.7100 rate:0.0620 gloss:0.0000 dloss:6.7060 dlossR:0.0000 dlossQsigm:0.1465\n",
      "Episode:718 meanR:43.9000 rate:0.1100 gloss:0.0002 dloss:4.0799 dlossR:0.0000 dlossQsigm:0.0679\n",
      "Episode:719 meanR:43.9900 rate:0.0980 gloss:0.0002 dloss:3.1534 dlossR:0.0000 dlossQsigm:0.0577\n",
      "Episode:720 meanR:44.0200 rate:0.0640 gloss:0.0000 dloss:8.0104 dlossR:0.0000 dlossQsigm:0.0800\n",
      "Episode:721 meanR:43.7200 rate:0.0580 gloss:0.0000 dloss:6.5381 dlossR:0.0000 dlossQsigm:0.1546\n",
      "Episode:722 meanR:43.5900 rate:0.0580 gloss:0.0000 dloss:5.8471 dlossR:0.0000 dlossQsigm:0.1495\n",
      "Episode:723 meanR:43.7400 rate:0.0880 gloss:0.0003 dloss:2.8349 dlossR:0.0000 dlossQsigm:0.0753\n",
      "Episode:724 meanR:43.6300 rate:0.0660 gloss:0.0001 dloss:4.8016 dlossR:0.0000 dlossQsigm:0.0778\n",
      "Episode:725 meanR:43.7100 rate:0.1100 gloss:0.0000 dloss:3.1867 dlossR:0.0000 dlossQsigm:0.0670\n",
      "Episode:726 meanR:43.6600 rate:0.0940 gloss:0.0000 dloss:3.5450 dlossR:0.0000 dlossQsigm:0.0405\n",
      "Episode:727 meanR:43.8200 rate:0.1000 gloss:0.0000 dloss:2.2078 dlossR:0.0000 dlossQsigm:0.0457\n",
      "Episode:728 meanR:43.8800 rate:0.0900 gloss:0.0000 dloss:1.8669 dlossR:0.0000 dlossQsigm:0.0346\n",
      "Episode:729 meanR:44.4600 rate:0.1780 gloss:0.0001 dloss:7.2214 dlossR:0.0000 dlossQsigm:0.0995\n",
      "Episode:730 meanR:44.7200 rate:0.1340 gloss:0.0000 dloss:3.2955 dlossR:0.0000 dlossQsigm:0.0813\n",
      "Episode:731 meanR:44.6600 rate:0.0820 gloss:0.0000 dloss:4.8549 dlossR:0.0000 dlossQsigm:0.0861\n",
      "Episode:732 meanR:44.6800 rate:0.0600 gloss:0.0000 dloss:8.5751 dlossR:0.0000 dlossQsigm:0.1799\n",
      "Episode:733 meanR:44.5800 rate:0.0960 gloss:0.0000 dloss:4.3270 dlossR:0.0000 dlossQsigm:0.0905\n",
      "Episode:734 meanR:44.7700 rate:0.0980 gloss:0.0000 dloss:6.8422 dlossR:0.0000 dlossQsigm:0.0985\n",
      "Episode:735 meanR:44.8300 rate:0.0720 gloss:0.0001 dloss:4.5613 dlossR:0.0000 dlossQsigm:0.0891\n",
      "Episode:736 meanR:44.5600 rate:0.0580 gloss:0.0000 dloss:4.6804 dlossR:0.0000 dlossQsigm:0.1309\n",
      "Episode:737 meanR:44.3500 rate:0.0600 gloss:0.0019 dloss:3.7925 dlossR:0.0000 dlossQsigm:0.1007\n",
      "Episode:738 meanR:44.2200 rate:0.1380 gloss:0.0000 dloss:4.5285 dlossR:0.0000 dlossQsigm:0.0359\n",
      "Episode:739 meanR:44.0900 rate:0.0680 gloss:0.0000 dloss:3.7386 dlossR:0.0000 dlossQsigm:0.0839\n",
      "Episode:740 meanR:44.0700 rate:0.1060 gloss:0.0000 dloss:4.0217 dlossR:0.0000 dlossQsigm:0.0602\n",
      "Episode:741 meanR:44.0700 rate:0.0660 gloss:0.0000 dloss:4.2908 dlossR:0.0000 dlossQsigm:0.0457\n",
      "Episode:742 meanR:44.0100 rate:0.0560 gloss:0.0000 dloss:3.6796 dlossR:0.0000 dlossQsigm:0.1205\n",
      "Episode:743 meanR:43.9900 rate:0.0620 gloss:0.0000 dloss:1.9366 dlossR:0.0001 dlossQsigm:0.0682\n",
      "Episode:744 meanR:43.6800 rate:0.0600 gloss:0.0000 dloss:3.4781 dlossR:0.0000 dlossQsigm:0.1067\n",
      "Episode:745 meanR:43.8900 rate:0.1000 gloss:0.0039 dloss:6.6579 dlossR:0.0000 dlossQsigm:0.0886\n",
      "Episode:746 meanR:44.0200 rate:0.1000 gloss:0.0000 dloss:3.4538 dlossR:0.0000 dlossQsigm:0.0835\n",
      "Episode:747 meanR:44.0800 rate:0.0760 gloss:0.0000 dloss:3.2817 dlossR:0.0000 dlossQsigm:0.0343\n",
      "Episode:748 meanR:43.8900 rate:0.0960 gloss:0.0000 dloss:3.9290 dlossR:0.0000 dlossQsigm:0.0775\n",
      "Episode:749 meanR:43.9600 rate:0.0920 gloss:0.0013 dloss:3.8996 dlossR:0.0000 dlossQsigm:0.0396\n",
      "Episode:750 meanR:43.9200 rate:0.0600 gloss:0.0000 dloss:3.1159 dlossR:0.0000 dlossQsigm:0.0827\n",
      "Episode:751 meanR:43.9700 rate:0.0720 gloss:0.0020 dloss:2.4404 dlossR:0.0000 dlossQsigm:0.0432\n",
      "Episode:752 meanR:44.0900 rate:0.0920 gloss:0.0000 dloss:4.7397 dlossR:0.0000 dlossQsigm:0.0514\n",
      "Episode:753 meanR:44.0400 rate:0.0820 gloss:0.0000 dloss:3.5379 dlossR:0.0000 dlossQsigm:0.0822\n",
      "Episode:754 meanR:43.9700 rate:0.0600 gloss:0.0001 dloss:3.3122 dlossR:0.0000 dlossQsigm:0.1081\n",
      "Episode:755 meanR:44.1000 rate:0.0960 gloss:0.0000 dloss:5.0797 dlossR:0.0000 dlossQsigm:0.0760\n",
      "Episode:756 meanR:43.8500 rate:0.0620 gloss:0.0000 dloss:2.6846 dlossR:0.0000 dlossQsigm:0.0903\n",
      "Episode:757 meanR:43.7100 rate:0.0780 gloss:0.0000 dloss:1.7402 dlossR:0.0000 dlossQsigm:0.0497\n",
      "Episode:758 meanR:43.7100 rate:0.0980 gloss:0.0002 dloss:1.7492 dlossR:0.0000 dlossQsigm:0.0507\n",
      "Episode:759 meanR:43.7400 rate:0.0900 gloss:0.0000 dloss:1.3255 dlossR:0.0000 dlossQsigm:0.0471\n",
      "Episode:760 meanR:44.0500 rate:0.1180 gloss:0.0000 dloss:1.6238 dlossR:0.0000 dlossQsigm:0.0397\n",
      "Episode:761 meanR:44.0900 rate:0.0660 gloss:0.0004 dloss:1.7260 dlossR:0.0021 dlossQsigm:0.0381\n",
      "Episode:762 meanR:43.7600 rate:0.0860 gloss:0.0005 dloss:1.3556 dlossR:0.0002 dlossQsigm:0.0325\n",
      "Episode:763 meanR:43.8800 rate:0.1020 gloss:0.0000 dloss:0.5471 dlossR:0.0003 dlossQsigm:0.0291\n",
      "Episode:764 meanR:43.5200 rate:0.0620 gloss:0.0008 dloss:1.3337 dlossR:0.0013 dlossQsigm:0.0496\n",
      "Episode:765 meanR:43.4200 rate:0.0620 gloss:0.0000 dloss:1.9773 dlossR:0.0003 dlossQsigm:0.0807\n",
      "Episode:766 meanR:43.4200 rate:0.0640 gloss:0.0000 dloss:6.0587 dlossR:0.0000 dlossQsigm:0.0434\n",
      "Episode:767 meanR:43.5600 rate:0.1140 gloss:0.0000 dloss:0.7527 dlossR:0.0001 dlossQsigm:0.0295\n",
      "Episode:768 meanR:43.5200 rate:0.0700 gloss:0.0000 dloss:1.5342 dlossR:0.0000 dlossQsigm:0.0326\n",
      "Episode:769 meanR:43.3700 rate:0.0600 gloss:0.0007 dloss:2.6357 dlossR:0.0014 dlossQsigm:0.0996\n",
      "Episode:770 meanR:43.5300 rate:0.0980 gloss:0.0002 dloss:1.7962 dlossR:0.0001 dlossQsigm:0.0344\n",
      "Episode:771 meanR:43.6900 rate:0.1020 gloss:0.0000 dloss:1.9937 dlossR:0.0000 dlossQsigm:0.0447\n",
      "Episode:772 meanR:43.5300 rate:0.0840 gloss:0.0025 dloss:2.7896 dlossR:0.0000 dlossQsigm:0.0437\n",
      "Episode:773 meanR:43.1800 rate:0.0560 gloss:0.0000 dloss:3.7883 dlossR:0.0000 dlossQsigm:0.0952\n",
      "Episode:774 meanR:43.0900 rate:0.0520 gloss:0.0000 dloss:5.5037 dlossR:0.0000 dlossQsigm:0.1418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:775 meanR:42.8700 rate:0.0820 gloss:0.0004 dloss:1.2211 dlossR:0.0000 dlossQsigm:0.0521\n",
      "Episode:776 meanR:42.9500 rate:0.0900 gloss:0.0000 dloss:3.6701 dlossR:0.0000 dlossQsigm:0.0829\n",
      "Episode:777 meanR:43.2600 rate:0.1480 gloss:0.0013 dloss:14.2559 dlossR:0.0000 dlossQsigm:0.1233\n",
      "Episode:778 meanR:43.1200 rate:0.0660 gloss:0.0002 dloss:2.5055 dlossR:0.0001 dlossQsigm:0.0369\n",
      "Episode:779 meanR:43.0700 rate:0.0620 gloss:0.0002 dloss:3.7949 dlossR:0.0000 dlossQsigm:0.1122\n",
      "Episode:780 meanR:42.9600 rate:0.1020 gloss:0.0002 dloss:3.1906 dlossR:0.0000 dlossQsigm:0.0684\n",
      "Episode:781 meanR:42.8800 rate:0.0820 gloss:0.0000 dloss:1.0283 dlossR:0.0000 dlossQsigm:0.0385\n",
      "Episode:782 meanR:42.8100 rate:0.0760 gloss:0.0000 dloss:1.7227 dlossR:0.0000 dlossQsigm:0.0392\n",
      "Episode:783 meanR:42.9800 rate:0.0900 gloss:0.0000 dloss:1.7844 dlossR:0.0000 dlossQsigm:0.0563\n",
      "Episode:784 meanR:43.1900 rate:0.1080 gloss:0.0000 dloss:6.8430 dlossR:0.0000 dlossQsigm:0.1151\n",
      "Episode:785 meanR:43.3400 rate:0.1100 gloss:0.0000 dloss:2.3795 dlossR:0.0000 dlossQsigm:0.0630\n",
      "Episode:786 meanR:43.3100 rate:0.0620 gloss:0.0000 dloss:3.1711 dlossR:0.0000 dlossQsigm:0.1120\n",
      "Episode:787 meanR:43.6200 rate:0.1140 gloss:0.0000 dloss:5.2248 dlossR:0.0000 dlossQsigm:0.0736\n",
      "Episode:788 meanR:43.6400 rate:0.1000 gloss:0.0000 dloss:2.0602 dlossR:0.0000 dlossQsigm:0.0494\n",
      "Episode:789 meanR:43.7100 rate:0.0780 gloss:0.0003 dloss:3.0907 dlossR:0.0000 dlossQsigm:0.0650\n",
      "Episode:790 meanR:43.7900 rate:0.0960 gloss:0.0001 dloss:1.9917 dlossR:0.0000 dlossQsigm:0.0507\n",
      "Episode:791 meanR:43.7800 rate:0.0980 gloss:0.0006 dloss:2.6542 dlossR:0.0000 dlossQsigm:0.0569\n",
      "Episode:792 meanR:43.7900 rate:0.0900 gloss:0.0000 dloss:0.7409 dlossR:0.0000 dlossQsigm:0.0373\n",
      "Episode:793 meanR:43.7800 rate:0.1020 gloss:0.0000 dloss:2.0308 dlossR:0.0000 dlossQsigm:0.0605\n",
      "Episode:794 meanR:43.6100 rate:0.0760 gloss:0.0000 dloss:0.9883 dlossR:0.0000 dlossQsigm:0.0429\n",
      "Episode:795 meanR:43.8300 rate:0.1000 gloss:0.0037 dloss:1.4469 dlossR:0.0001 dlossQsigm:0.0318\n",
      "Episode:796 meanR:43.8300 rate:0.0660 gloss:0.0003 dloss:0.9159 dlossR:0.0000 dlossQsigm:0.0383\n",
      "Episode:797 meanR:43.7400 rate:0.0860 gloss:0.0003 dloss:0.6584 dlossR:0.0000 dlossQsigm:0.0409\n",
      "Episode:798 meanR:43.8600 rate:0.1020 gloss:0.0001 dloss:4.0175 dlossR:0.0000 dlossQsigm:0.0642\n",
      "Episode:799 meanR:43.6700 rate:0.0720 gloss:0.0001 dloss:3.5656 dlossR:0.0000 dlossQsigm:0.0512\n",
      "Episode:800 meanR:43.3900 rate:0.0620 gloss:0.0012 dloss:3.1154 dlossR:0.0000 dlossQsigm:0.0922\n",
      "Episode:801 meanR:43.3500 rate:0.0700 gloss:0.0000 dloss:2.1702 dlossR:0.0000 dlossQsigm:0.0462\n",
      "Episode:802 meanR:43.4500 rate:0.0900 gloss:0.0000 dloss:1.9196 dlossR:0.0000 dlossQsigm:0.0557\n",
      "Episode:803 meanR:43.0500 rate:0.0700 gloss:0.0328 dloss:1.9889 dlossR:0.0000 dlossQsigm:0.0475\n",
      "Episode:804 meanR:43.1400 rate:0.0840 gloss:0.0000 dloss:1.7445 dlossR:0.0000 dlossQsigm:0.0542\n",
      "Episode:805 meanR:42.9900 rate:0.0740 gloss:0.0000 dloss:2.5500 dlossR:0.0000 dlossQsigm:0.0394\n",
      "Episode:806 meanR:42.8300 rate:0.0880 gloss:0.0001 dloss:2.3527 dlossR:0.0002 dlossQsigm:0.0320\n",
      "Episode:807 meanR:42.8400 rate:0.0700 gloss:0.0000 dloss:3.4561 dlossR:0.0000 dlossQsigm:0.0446\n",
      "Episode:808 meanR:42.9300 rate:0.1140 gloss:0.0000 dloss:9.5781 dlossR:0.0000 dlossQsigm:0.0579\n",
      "Episode:809 meanR:42.8800 rate:0.0960 gloss:0.0152 dloss:4.3735 dlossR:0.0000 dlossQsigm:0.0750\n",
      "Episode:810 meanR:42.7800 rate:0.0940 gloss:0.0000 dloss:4.4560 dlossR:0.0000 dlossQsigm:0.0859\n",
      "Episode:811 meanR:42.5900 rate:0.0580 gloss:0.0000 dloss:3.8757 dlossR:0.0000 dlossQsigm:0.1222\n",
      "Episode:812 meanR:42.4300 rate:0.0580 gloss:0.0000 dloss:3.2594 dlossR:0.0000 dlossQsigm:0.1148\n",
      "Episode:813 meanR:42.4400 rate:0.0900 gloss:0.0000 dloss:2.4451 dlossR:0.0000 dlossQsigm:0.0712\n",
      "Episode:814 meanR:42.4900 rate:0.1040 gloss:0.0001 dloss:2.2675 dlossR:0.0000 dlossQsigm:0.0563\n",
      "Episode:815 meanR:42.3700 rate:0.0900 gloss:0.0004 dloss:2.6917 dlossR:0.0000 dlossQsigm:0.0538\n",
      "Episode:816 meanR:42.3800 rate:0.0640 gloss:0.0000 dloss:9.8850 dlossR:0.0000 dlossQsigm:0.0749\n",
      "Episode:817 meanR:42.7000 rate:0.1260 gloss:0.0005 dloss:4.8461 dlossR:0.0000 dlossQsigm:0.0849\n",
      "Episode:818 meanR:42.5000 rate:0.0700 gloss:0.0000 dloss:2.7624 dlossR:0.0000 dlossQsigm:0.0661\n",
      "Episode:819 meanR:42.4000 rate:0.0780 gloss:0.0000 dloss:2.0188 dlossR:0.0000 dlossQsigm:0.0581\n",
      "Episode:820 meanR:42.4500 rate:0.0740 gloss:0.0000 dloss:2.2247 dlossR:0.0000 dlossQsigm:0.0691\n",
      "Episode:821 meanR:42.6100 rate:0.0900 gloss:0.0001 dloss:5.2017 dlossR:0.0000 dlossQsigm:0.0605\n",
      "Episode:822 meanR:42.6900 rate:0.0740 gloss:0.0005 dloss:1.4797 dlossR:0.0000 dlossQsigm:0.0403\n",
      "Episode:823 meanR:42.6400 rate:0.0780 gloss:0.0000 dloss:2.1097 dlossR:0.0000 dlossQsigm:0.0442\n",
      "Episode:824 meanR:42.8500 rate:0.1080 gloss:0.0000 dloss:6.6253 dlossR:0.0000 dlossQsigm:0.0576\n",
      "Episode:825 meanR:42.6600 rate:0.0720 gloss:0.0000 dloss:4.5801 dlossR:0.0000 dlossQsigm:0.0589\n",
      "Episode:826 meanR:42.9000 rate:0.1420 gloss:0.0001 dloss:5.4921 dlossR:0.0000 dlossQsigm:0.0625\n",
      "Episode:827 meanR:42.7900 rate:0.0780 gloss:0.0003 dloss:2.7594 dlossR:0.0000 dlossQsigm:0.0587\n",
      "Episode:828 meanR:42.8200 rate:0.0960 gloss:0.0000 dloss:3.8852 dlossR:0.0000 dlossQsigm:0.0555\n",
      "Episode:829 meanR:42.2400 rate:0.0620 gloss:0.0000 dloss:4.1724 dlossR:0.0000 dlossQsigm:0.0939\n",
      "Episode:830 meanR:41.9800 rate:0.0820 gloss:0.0000 dloss:3.2043 dlossR:0.0000 dlossQsigm:0.0585\n",
      "Episode:831 meanR:41.8900 rate:0.0640 gloss:0.0000 dloss:5.5773 dlossR:0.0000 dlossQsigm:0.0703\n",
      "Episode:832 meanR:42.1900 rate:0.1200 gloss:0.0000 dloss:4.5123 dlossR:0.0000 dlossQsigm:0.0873\n",
      "Episode:833 meanR:42.0700 rate:0.0720 gloss:0.0000 dloss:4.3006 dlossR:0.0000 dlossQsigm:0.0911\n",
      "Episode:834 meanR:42.0900 rate:0.1020 gloss:0.0000 dloss:7.2935 dlossR:0.0000 dlossQsigm:0.0921\n",
      "Episode:835 meanR:42.0300 rate:0.0600 gloss:0.0000 dloss:6.2516 dlossR:0.0000 dlossQsigm:0.1664\n",
      "Episode:836 meanR:42.0800 rate:0.0680 gloss:0.0000 dloss:5.1780 dlossR:0.0000 dlossQsigm:0.0943\n",
      "Episode:837 meanR:42.0800 rate:0.0600 gloss:0.0061 dloss:6.3425 dlossR:0.0000 dlossQsigm:0.1012\n",
      "Episode:838 meanR:41.7400 rate:0.0700 gloss:0.0000 dloss:2.5120 dlossR:0.0000 dlossQsigm:0.0716\n",
      "Episode:839 meanR:41.6900 rate:0.0580 gloss:0.0000 dloss:2.7644 dlossR:0.0000 dlossQsigm:0.0998\n",
      "Episode:840 meanR:41.7300 rate:0.1140 gloss:0.0010 dloss:6.2812 dlossR:0.0000 dlossQsigm:0.0942\n",
      "Episode:841 meanR:41.7100 rate:0.0620 gloss:0.0110 dloss:4.8613 dlossR:0.0000 dlossQsigm:0.1476\n",
      "Episode:842 meanR:41.7700 rate:0.0680 gloss:0.0001 dloss:2.1926 dlossR:0.0000 dlossQsigm:0.0588\n",
      "Episode:843 meanR:41.7500 rate:0.0580 gloss:0.0000 dloss:2.0355 dlossR:0.0003 dlossQsigm:0.0983\n",
      "Episode:844 meanR:41.8000 rate:0.0700 gloss:0.0000 dloss:4.7830 dlossR:0.0000 dlossQsigm:0.0863\n",
      "Episode:845 meanR:41.6600 rate:0.0720 gloss:0.0001 dloss:3.4903 dlossR:0.0000 dlossQsigm:0.0814\n",
      "Episode:846 meanR:41.7500 rate:0.1180 gloss:0.0002 dloss:6.9294 dlossR:0.0000 dlossQsigm:0.1022\n",
      "Episode:847 meanR:42.1700 rate:0.1600 gloss:0.0000 dloss:6.2688 dlossR:0.0000 dlossQsigm:0.0740\n",
      "Episode:848 meanR:42.1900 rate:0.1000 gloss:0.0000 dloss:3.6731 dlossR:0.0000 dlossQsigm:0.0819\n",
      "Episode:849 meanR:42.2400 rate:0.1020 gloss:0.0000 dloss:4.6557 dlossR:0.0000 dlossQsigm:0.0720\n",
      "Episode:850 meanR:42.3300 rate:0.0780 gloss:0.0000 dloss:2.6415 dlossR:0.0000 dlossQsigm:0.0783\n",
      "Episode:851 meanR:42.4100 rate:0.0880 gloss:0.0000 dloss:2.5975 dlossR:0.0000 dlossQsigm:0.0709\n",
      "Episode:852 meanR:42.4500 rate:0.1000 gloss:0.0000 dloss:2.7359 dlossR:0.0000 dlossQsigm:0.0697\n",
      "Episode:853 meanR:42.6300 rate:0.1180 gloss:0.0000 dloss:5.5306 dlossR:0.0000 dlossQsigm:0.0892\n",
      "Episode:854 meanR:42.8200 rate:0.0980 gloss:0.0001 dloss:3.5008 dlossR:0.0000 dlossQsigm:0.0557\n",
      "Episode:855 meanR:42.8900 rate:0.1100 gloss:0.0000 dloss:2.1151 dlossR:0.0000 dlossQsigm:0.0679\n",
      "Episode:856 meanR:43.2500 rate:0.1340 gloss:0.0001 dloss:4.0601 dlossR:0.0000 dlossQsigm:0.0887\n",
      "Episode:857 meanR:43.5100 rate:0.1300 gloss:0.0002 dloss:3.4513 dlossR:0.0000 dlossQsigm:0.0788\n",
      "Episode:858 meanR:43.4900 rate:0.0940 gloss:0.0000 dloss:3.2077 dlossR:0.0004 dlossQsigm:0.0542\n",
      "Episode:859 meanR:43.9700 rate:0.1860 gloss:0.0000 dloss:5.5144 dlossR:0.0000 dlossQsigm:0.0870\n",
      "Episode:860 meanR:43.7200 rate:0.0680 gloss:0.0002 dloss:4.8953 dlossR:0.0000 dlossQsigm:0.0358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:861 meanR:43.8300 rate:0.0880 gloss:0.0000 dloss:2.9242 dlossR:0.0000 dlossQsigm:0.0528\n",
      "Episode:862 meanR:44.0500 rate:0.1300 gloss:0.0000 dloss:9.0083 dlossR:0.0000 dlossQsigm:0.1434\n",
      "Episode:863 meanR:44.0200 rate:0.0960 gloss:0.0004 dloss:10.8139 dlossR:0.0000 dlossQsigm:0.1478\n",
      "Episode:864 meanR:44.5900 rate:0.1760 gloss:0.0000 dloss:13.1632 dlossR:0.0000 dlossQsigm:0.1623\n",
      "Episode:865 meanR:45.0400 rate:0.1520 gloss:0.0001 dloss:15.0355 dlossR:0.0000 dlossQsigm:0.1431\n",
      "Episode:866 meanR:45.1600 rate:0.0880 gloss:0.0004 dloss:2.5360 dlossR:0.0000 dlossQsigm:0.0651\n",
      "Episode:867 meanR:45.5000 rate:0.1820 gloss:0.0000 dloss:14.9422 dlossR:0.0000 dlossQsigm:0.1613\n",
      "Episode:868 meanR:45.5600 rate:0.0820 gloss:0.0000 dloss:2.5487 dlossR:0.0000 dlossQsigm:0.0499\n",
      "Episode:869 meanR:46.1200 rate:0.1720 gloss:0.0000 dloss:6.3854 dlossR:0.0000 dlossQsigm:0.1171\n",
      "Episode:870 meanR:46.0100 rate:0.0760 gloss:0.0000 dloss:3.2661 dlossR:0.0003 dlossQsigm:0.0385\n",
      "Episode:871 meanR:46.4400 rate:0.1880 gloss:0.0000 dloss:3.1664 dlossR:0.0000 dlossQsigm:0.0557\n",
      "Episode:872 meanR:47.1000 rate:0.2160 gloss:0.0027 dloss:8.1619 dlossR:0.0000 dlossQsigm:0.0929\n",
      "Episode:873 meanR:47.3000 rate:0.0960 gloss:0.0012 dloss:7.8107 dlossR:0.0000 dlossQsigm:0.0969\n",
      "Episode:874 meanR:47.5200 rate:0.0960 gloss:0.0000 dloss:3.1451 dlossR:0.0000 dlossQsigm:0.0632\n",
      "Episode:875 meanR:47.4800 rate:0.0740 gloss:0.0000 dloss:3.4733 dlossR:0.0000 dlossQsigm:0.0787\n",
      "Episode:876 meanR:47.4200 rate:0.0780 gloss:0.0001 dloss:5.7599 dlossR:0.0000 dlossQsigm:0.0888\n",
      "Episode:877 meanR:47.5200 rate:0.1680 gloss:0.0001 dloss:11.7546 dlossR:0.0000 dlossQsigm:0.1313\n",
      "Episode:878 meanR:47.7700 rate:0.1160 gloss:0.0000 dloss:13.7056 dlossR:0.0000 dlossQsigm:0.1421\n",
      "Episode:879 meanR:48.0300 rate:0.1140 gloss:0.0001 dloss:11.3216 dlossR:0.0000 dlossQsigm:0.1530\n",
      "Episode:880 meanR:48.0200 rate:0.1000 gloss:0.0110 dloss:6.7996 dlossR:0.0000 dlossQsigm:0.1069\n",
      "Episode:881 meanR:48.2500 rate:0.1280 gloss:0.0000 dloss:10.3989 dlossR:0.0000 dlossQsigm:0.1225\n",
      "Episode:882 meanR:48.3100 rate:0.0880 gloss:0.0000 dloss:24.4251 dlossR:0.0000 dlossQsigm:0.1340\n",
      "Episode:883 meanR:48.6000 rate:0.1480 gloss:0.0002 dloss:8.0744 dlossR:0.0000 dlossQsigm:0.0883\n",
      "Episode:884 meanR:48.6600 rate:0.1200 gloss:0.0000 dloss:5.2207 dlossR:0.0000 dlossQsigm:0.0743\n",
      "Episode:885 meanR:48.6900 rate:0.1160 gloss:0.0016 dloss:4.6166 dlossR:0.0000 dlossQsigm:0.0887\n",
      "Episode:886 meanR:48.7900 rate:0.0820 gloss:0.0003 dloss:3.5791 dlossR:0.0000 dlossQsigm:0.0687\n",
      "Episode:887 meanR:48.6600 rate:0.0880 gloss:0.0099 dloss:2.6055 dlossR:0.0000 dlossQsigm:0.0628\n",
      "Episode:888 meanR:48.5800 rate:0.0840 gloss:0.0000 dloss:3.9193 dlossR:0.0000 dlossQsigm:0.0546\n",
      "Episode:889 meanR:49.1200 rate:0.1860 gloss:0.0000 dloss:5.3832 dlossR:0.0000 dlossQsigm:0.0892\n",
      "Episode:890 meanR:49.0800 rate:0.0880 gloss:0.0000 dloss:3.5964 dlossR:0.0000 dlossQsigm:0.0703\n",
      "Episode:891 meanR:49.2200 rate:0.1260 gloss:0.0000 dloss:4.1995 dlossR:0.0000 dlossQsigm:0.0816\n",
      "Episode:892 meanR:49.2600 rate:0.0980 gloss:0.0001 dloss:3.5884 dlossR:0.0000 dlossQsigm:0.0714\n",
      "Episode:893 meanR:49.1900 rate:0.0880 gloss:0.0009 dloss:3.0904 dlossR:0.0000 dlossQsigm:0.0640\n",
      "Episode:894 meanR:49.3600 rate:0.1100 gloss:0.0000 dloss:5.7707 dlossR:0.0000 dlossQsigm:0.1057\n",
      "Episode:895 meanR:49.3200 rate:0.0920 gloss:0.0000 dloss:3.6616 dlossR:0.0000 dlossQsigm:0.0653\n",
      "Episode:896 meanR:49.5100 rate:0.1040 gloss:0.0002 dloss:3.5808 dlossR:0.0000 dlossQsigm:0.0834\n",
      "Episode:897 meanR:49.5200 rate:0.0880 gloss:0.0001 dloss:1.9014 dlossR:0.0000 dlossQsigm:0.0529\n",
      "Episode:898 meanR:49.5300 rate:0.1040 gloss:0.0002 dloss:3.2468 dlossR:0.0000 dlossQsigm:0.0679\n",
      "Episode:899 meanR:49.6300 rate:0.0920 gloss:0.0012 dloss:2.8524 dlossR:0.0000 dlossQsigm:0.0747\n",
      "Episode:900 meanR:49.7400 rate:0.0840 gloss:0.0000 dloss:2.8864 dlossR:0.0000 dlossQsigm:0.0636\n",
      "Episode:901 meanR:49.9200 rate:0.1060 gloss:0.0000 dloss:18.2611 dlossR:0.0000 dlossQsigm:0.1151\n",
      "Episode:902 meanR:49.8500 rate:0.0760 gloss:0.0000 dloss:11.2184 dlossR:0.0000 dlossQsigm:0.1278\n",
      "Episode:903 meanR:50.1600 rate:0.1320 gloss:0.0000 dloss:7.6858 dlossR:0.0000 dlossQsigm:0.1211\n",
      "Episode:904 meanR:50.2900 rate:0.1100 gloss:0.0001 dloss:3.8796 dlossR:0.0000 dlossQsigm:0.0640\n",
      "Episode:905 meanR:50.5400 rate:0.1240 gloss:0.0000 dloss:5.8983 dlossR:0.0000 dlossQsigm:0.0967\n",
      "Episode:906 meanR:50.5900 rate:0.0980 gloss:0.0001 dloss:6.3695 dlossR:0.0000 dlossQsigm:0.1003\n",
      "Episode:907 meanR:50.5900 rate:0.0700 gloss:0.0000 dloss:5.0471 dlossR:0.0000 dlossQsigm:0.0663\n",
      "Episode:908 meanR:50.6900 rate:0.1340 gloss:0.0002 dloss:4.2584 dlossR:0.0000 dlossQsigm:0.0692\n",
      "Episode:909 meanR:50.6900 rate:0.0960 gloss:0.0000 dloss:2.4810 dlossR:0.0000 dlossQsigm:0.0586\n",
      "Episode:910 meanR:50.6600 rate:0.0880 gloss:0.0001 dloss:1.8899 dlossR:0.0000 dlossQsigm:0.0501\n",
      "Episode:911 meanR:50.9500 rate:0.1160 gloss:0.0000 dloss:2.9865 dlossR:0.0000 dlossQsigm:0.0725\n",
      "Episode:912 meanR:50.9700 rate:0.0620 gloss:0.0000 dloss:3.9187 dlossR:0.0000 dlossQsigm:0.1274\n",
      "Episode:913 meanR:51.1600 rate:0.1280 gloss:0.0000 dloss:6.8001 dlossR:0.0000 dlossQsigm:0.0853\n",
      "Episode:914 meanR:51.0100 rate:0.0740 gloss:0.0000 dloss:3.5779 dlossR:0.0000 dlossQsigm:0.0418\n",
      "Episode:915 meanR:50.9400 rate:0.0760 gloss:0.0006 dloss:1.6022 dlossR:0.0001 dlossQsigm:0.0346\n",
      "Episode:916 meanR:51.0500 rate:0.0860 gloss:0.0000 dloss:1.7432 dlossR:0.0002 dlossQsigm:0.0435\n",
      "Episode:917 meanR:51.1400 rate:0.1440 gloss:0.0000 dloss:1.4786 dlossR:0.0000 dlossQsigm:0.0485\n",
      "Episode:918 meanR:51.1700 rate:0.0760 gloss:0.0001 dloss:2.1867 dlossR:0.0000 dlossQsigm:0.0519\n",
      "Episode:919 meanR:51.6100 rate:0.1660 gloss:0.0000 dloss:2.2747 dlossR:0.0000 dlossQsigm:0.0510\n",
      "Episode:920 meanR:51.7400 rate:0.1000 gloss:0.0000 dloss:2.6713 dlossR:0.0000 dlossQsigm:0.0510\n",
      "Episode:921 meanR:51.7300 rate:0.0880 gloss:0.0021 dloss:5.5080 dlossR:0.0000 dlossQsigm:0.0507\n",
      "Episode:922 meanR:51.9900 rate:0.1260 gloss:0.0148 dloss:11.4979 dlossR:0.0000 dlossQsigm:0.0972\n",
      "Episode:923 meanR:52.0500 rate:0.0900 gloss:0.0000 dloss:3.9628 dlossR:0.0000 dlossQsigm:0.0472\n",
      "Episode:924 meanR:51.9600 rate:0.0900 gloss:0.0003 dloss:3.2393 dlossR:0.0000 dlossQsigm:0.0444\n",
      "Episode:925 meanR:51.9300 rate:0.0660 gloss:0.0000 dloss:7.2697 dlossR:0.0000 dlossQsigm:0.0636\n",
      "Episode:926 meanR:51.5300 rate:0.0620 gloss:0.0006 dloss:2.4703 dlossR:0.0000 dlossQsigm:0.1002\n",
      "Episode:927 meanR:51.4900 rate:0.0700 gloss:0.0000 dloss:1.4143 dlossR:0.0000 dlossQsigm:0.0434\n",
      "Episode:928 meanR:51.4900 rate:0.0960 gloss:0.0017 dloss:1.4572 dlossR:0.0000 dlossQsigm:0.0399\n",
      "Episode:929 meanR:51.5100 rate:0.0660 gloss:0.0005 dloss:1.7333 dlossR:0.0002 dlossQsigm:0.0416\n",
      "Episode:930 meanR:51.7700 rate:0.1340 gloss:0.0002 dloss:1.6456 dlossR:0.0000 dlossQsigm:0.0478\n",
      "Episode:931 meanR:51.8300 rate:0.0760 gloss:0.0000 dloss:0.8917 dlossR:0.0000 dlossQsigm:0.0378\n",
      "Episode:932 meanR:51.9000 rate:0.1340 gloss:0.0049 dloss:1.8817 dlossR:0.0000 dlossQsigm:0.0466\n",
      "Episode:933 meanR:51.8800 rate:0.0680 gloss:0.0000 dloss:3.0347 dlossR:0.0000 dlossQsigm:0.0387\n",
      "Episode:934 meanR:51.7000 rate:0.0660 gloss:0.0001 dloss:2.8748 dlossR:0.0000 dlossQsigm:0.0588\n",
      "Episode:935 meanR:51.9700 rate:0.1140 gloss:0.0001 dloss:4.1562 dlossR:0.0000 dlossQsigm:0.0710\n",
      "Episode:936 meanR:52.2600 rate:0.1260 gloss:0.0000 dloss:1.5246 dlossR:0.0000 dlossQsigm:0.0516\n",
      "Episode:937 meanR:52.4000 rate:0.0880 gloss:0.0583 dloss:9.3013 dlossR:0.0000 dlossQsigm:0.0626\n",
      "Episode:938 meanR:52.4000 rate:0.0700 gloss:0.0000 dloss:2.1089 dlossR:0.0000 dlossQsigm:0.0539\n",
      "Episode:939 meanR:52.5300 rate:0.0840 gloss:0.0006 dloss:2.7111 dlossR:0.0000 dlossQsigm:0.0639\n",
      "Episode:940 meanR:52.2900 rate:0.0660 gloss:0.0000 dloss:1.3802 dlossR:0.0000 dlossQsigm:0.0368\n",
      "Episode:941 meanR:52.4400 rate:0.0920 gloss:0.0002 dloss:0.6305 dlossR:0.0001 dlossQsigm:0.0322\n",
      "Episode:942 meanR:52.4900 rate:0.0780 gloss:0.0000 dloss:0.8279 dlossR:0.0000 dlossQsigm:0.0371\n",
      "Episode:943 meanR:52.5800 rate:0.0760 gloss:0.0000 dloss:1.6939 dlossR:0.0000 dlossQsigm:0.0565\n",
      "Episode:944 meanR:52.7400 rate:0.1020 gloss:0.0108 dloss:3.1598 dlossR:0.0000 dlossQsigm:0.0621\n",
      "Episode:945 meanR:52.9200 rate:0.1080 gloss:0.0001 dloss:6.0469 dlossR:0.0000 dlossQsigm:0.0430\n",
      "Episode:946 meanR:52.6400 rate:0.0620 gloss:0.0020 dloss:4.2644 dlossR:0.0000 dlossQsigm:0.1165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:947 meanR:52.1700 rate:0.0660 gloss:0.0001 dloss:5.7201 dlossR:0.0000 dlossQsigm:0.0734\n",
      "Episode:948 meanR:52.2000 rate:0.1060 gloss:0.0000 dloss:4.7129 dlossR:0.0000 dlossQsigm:0.0685\n",
      "Episode:949 meanR:52.1000 rate:0.0820 gloss:0.0001 dloss:3.2351 dlossR:0.0000 dlossQsigm:0.0416\n",
      "Episode:950 meanR:52.1800 rate:0.0940 gloss:0.0002 dloss:2.4595 dlossR:0.0000 dlossQsigm:0.0381\n",
      "Episode:951 meanR:52.4700 rate:0.1460 gloss:0.0001 dloss:4.4150 dlossR:0.0000 dlossQsigm:0.0448\n",
      "Episode:952 meanR:52.3700 rate:0.0800 gloss:0.0001 dloss:0.7178 dlossR:0.0000 dlossQsigm:0.0328\n",
      "Episode:953 meanR:52.4100 rate:0.1260 gloss:0.0000 dloss:2.0357 dlossR:0.0000 dlossQsigm:0.0478\n",
      "Episode:954 meanR:52.2300 rate:0.0620 gloss:0.0000 dloss:1.8212 dlossR:0.0000 dlossQsigm:0.0805\n",
      "Episode:955 meanR:52.0800 rate:0.0800 gloss:0.0000 dloss:0.9885 dlossR:0.0011 dlossQsigm:0.0344\n",
      "Episode:956 meanR:51.8200 rate:0.0820 gloss:0.0000 dloss:1.2671 dlossR:0.0000 dlossQsigm:0.0414\n",
      "Episode:957 meanR:51.6700 rate:0.1000 gloss:0.0031 dloss:3.3198 dlossR:0.0000 dlossQsigm:0.0552\n",
      "Episode:958 meanR:51.7500 rate:0.1100 gloss:0.0000 dloss:1.9970 dlossR:0.0047 dlossQsigm:0.0535\n",
      "Episode:959 meanR:51.2300 rate:0.0820 gloss:0.0000 dloss:0.6224 dlossR:0.0003 dlossQsigm:0.0358\n",
      "Episode:960 meanR:51.4800 rate:0.1180 gloss:0.0000 dloss:2.1959 dlossR:0.0000 dlossQsigm:0.0449\n",
      "Episode:961 meanR:51.5600 rate:0.1040 gloss:0.0000 dloss:5.4490 dlossR:0.0000 dlossQsigm:0.0735\n",
      "Episode:962 meanR:51.4200 rate:0.1020 gloss:0.0000 dloss:4.2234 dlossR:0.0000 dlossQsigm:0.0919\n",
      "Episode:963 meanR:51.2000 rate:0.0520 gloss:0.0000 dloss:7.3969 dlossR:0.0000 dlossQsigm:0.1124\n",
      "Episode:964 meanR:50.9100 rate:0.1180 gloss:0.0000 dloss:4.3162 dlossR:0.0000 dlossQsigm:0.0412\n",
      "Episode:965 meanR:50.5600 rate:0.0820 gloss:0.0000 dloss:2.8157 dlossR:0.0056 dlossQsigm:0.0642\n",
      "Episode:966 meanR:51.2100 rate:0.2180 gloss:0.0000 dloss:20.7714 dlossR:0.0000 dlossQsigm:0.1702\n",
      "Episode:967 meanR:50.6500 rate:0.0700 gloss:0.0003 dloss:5.1675 dlossR:0.0000 dlossQsigm:0.0830\n",
      "Episode:968 meanR:50.7800 rate:0.1080 gloss:0.0106 dloss:3.6462 dlossR:0.0000 dlossQsigm:0.0765\n",
      "Episode:969 meanR:50.3700 rate:0.0900 gloss:0.0000 dloss:6.5356 dlossR:0.0000 dlossQsigm:0.0587\n",
      "Episode:970 meanR:50.6000 rate:0.1220 gloss:0.0000 dloss:9.0410 dlossR:0.0000 dlossQsigm:0.0959\n",
      "Episode:971 meanR:50.2200 rate:0.1120 gloss:0.0000 dloss:5.7688 dlossR:0.0000 dlossQsigm:0.0822\n",
      "Episode:972 meanR:49.6700 rate:0.1060 gloss:0.0000 dloss:4.5355 dlossR:0.0211 dlossQsigm:0.1391\n",
      "Episode:973 meanR:49.7400 rate:0.1100 gloss:0.0000 dloss:3.8866 dlossR:0.0015 dlossQsigm:0.0624\n",
      "Episode:974 meanR:49.6900 rate:0.0860 gloss:0.0001 dloss:4.7783 dlossR:0.0000 dlossQsigm:0.0493\n",
      "Episode:975 meanR:49.6300 rate:0.0620 gloss:0.0000 dloss:4.6613 dlossR:0.0000 dlossQsigm:0.0912\n",
      "Episode:976 meanR:49.6100 rate:0.0740 gloss:0.0000 dloss:2.9815 dlossR:0.0000 dlossQsigm:0.0526\n",
      "Episode:977 meanR:49.2900 rate:0.1040 gloss:0.0000 dloss:1.8723 dlossR:0.0042 dlossQsigm:0.0435\n",
      "Episode:978 meanR:49.2900 rate:0.1160 gloss:0.0000 dloss:4.3055 dlossR:0.0000 dlossQsigm:0.0705\n",
      "Episode:979 meanR:49.0300 rate:0.0620 gloss:0.0000 dloss:5.0723 dlossR:0.0280 dlossQsigm:0.2613\n",
      "Episode:980 meanR:48.8700 rate:0.0680 gloss:0.0063 dloss:2.7030 dlossR:0.0000 dlossQsigm:0.0462\n",
      "Episode:981 meanR:48.6000 rate:0.0740 gloss:0.0000 dloss:1.8531 dlossR:0.0001 dlossQsigm:0.0364\n",
      "Episode:982 meanR:48.7800 rate:0.1240 gloss:0.0129 dloss:4.9809 dlossR:0.0000 dlossQsigm:0.0411\n",
      "Episode:983 meanR:48.3900 rate:0.0700 gloss:0.0000 dloss:2.7631 dlossR:0.0000 dlossQsigm:0.0359\n",
      "Episode:984 meanR:48.3200 rate:0.1060 gloss:0.0001 dloss:1.5210 dlossR:0.0000 dlossQsigm:0.0364\n",
      "Episode:985 meanR:48.0200 rate:0.0560 gloss:0.0002 dloss:3.0314 dlossR:0.0000 dlossQsigm:0.0989\n",
      "Episode:986 meanR:48.0800 rate:0.0940 gloss:0.0000 dloss:2.7477 dlossR:0.0000 dlossQsigm:0.0340\n",
      "Episode:987 meanR:47.9300 rate:0.0580 gloss:0.0000 dloss:2.9529 dlossR:0.0089 dlossQsigm:0.1518\n",
      "Episode:988 meanR:48.3000 rate:0.1580 gloss:0.0000 dloss:2.9701 dlossR:0.0001 dlossQsigm:0.0301\n",
      "Episode:989 meanR:47.6600 rate:0.0580 gloss:0.0025 dloss:1.4666 dlossR:0.0009 dlossQsigm:0.0696\n",
      "Episode:990 meanR:47.6500 rate:0.0860 gloss:0.0000 dloss:1.4067 dlossR:0.0000 dlossQsigm:0.0404\n",
      "Episode:991 meanR:47.4200 rate:0.0800 gloss:0.0000 dloss:4.3616 dlossR:0.0000 dlossQsigm:0.0583\n",
      "Episode:992 meanR:47.3900 rate:0.0920 gloss:0.0000 dloss:2.2018 dlossR:0.0000 dlossQsigm:0.0600\n",
      "Episode:993 meanR:47.3800 rate:0.0860 gloss:0.0000 dloss:7.7282 dlossR:0.0000 dlossQsigm:0.0498\n",
      "Episode:994 meanR:47.3000 rate:0.0940 gloss:0.0000 dloss:2.5088 dlossR:0.0000 dlossQsigm:0.0576\n",
      "Episode:995 meanR:47.2600 rate:0.0840 gloss:0.0002 dloss:3.5516 dlossR:0.0000 dlossQsigm:0.0757\n",
      "Episode:996 meanR:47.0500 rate:0.0620 gloss:0.0001 dloss:5.1137 dlossR:0.0000 dlossQsigm:0.1508\n",
      "Episode:997 meanR:47.0200 rate:0.0820 gloss:0.0001 dloss:2.8980 dlossR:0.0000 dlossQsigm:0.0620\n",
      "Episode:998 meanR:46.9400 rate:0.0880 gloss:0.0000 dloss:4.2920 dlossR:0.0000 dlossQsigm:0.0695\n",
      "Episode:999 meanR:46.7800 rate:0.0600 gloss:0.0023 dloss:2.9718 dlossR:0.0008 dlossQsigm:0.1017\n",
      "Episode:1000 meanR:46.9600 rate:0.1200 gloss:0.0000 dloss:1.7878 dlossR:0.0000 dlossQsigm:0.0535\n",
      "Episode:1001 meanR:46.7800 rate:0.0700 gloss:0.0000 dloss:7.1799 dlossR:0.0000 dlossQsigm:0.0543\n",
      "Episode:1002 meanR:46.7500 rate:0.0700 gloss:0.0000 dloss:4.0358 dlossR:0.0000 dlossQsigm:0.0594\n",
      "Episode:1003 meanR:46.7500 rate:0.1320 gloss:0.0000 dloss:4.6462 dlossR:0.0000 dlossQsigm:0.0786\n",
      "Episode:1004 meanR:46.5900 rate:0.0780 gloss:0.0000 dloss:4.7066 dlossR:0.0000 dlossQsigm:0.0766\n",
      "Episode:1005 meanR:46.3500 rate:0.0760 gloss:0.0000 dloss:4.9836 dlossR:0.0000 dlossQsigm:0.0767\n",
      "Episode:1006 meanR:46.4900 rate:0.1260 gloss:0.0000 dloss:3.8671 dlossR:0.0000 dlossQsigm:0.0763\n",
      "Episode:1007 meanR:46.6600 rate:0.1040 gloss:0.0000 dloss:4.8985 dlossR:0.0000 dlossQsigm:0.0757\n",
      "Episode:1008 meanR:46.3700 rate:0.0760 gloss:0.0001 dloss:5.4581 dlossR:0.0000 dlossQsigm:0.0809\n",
      "Episode:1009 meanR:46.2900 rate:0.0800 gloss:0.0000 dloss:4.0334 dlossR:0.0000 dlossQsigm:0.0790\n",
      "Episode:1010 meanR:46.2200 rate:0.0740 gloss:0.0000 dloss:4.3885 dlossR:0.0000 dlossQsigm:0.0790\n",
      "Episode:1011 meanR:46.4600 rate:0.1640 gloss:0.0005 dloss:4.7425 dlossR:0.0000 dlossQsigm:0.0784\n",
      "Episode:1012 meanR:46.5300 rate:0.0760 gloss:0.0000 dloss:3.9885 dlossR:0.0000 dlossQsigm:0.0771\n",
      "Episode:1013 meanR:46.3200 rate:0.0860 gloss:0.0020 dloss:3.4202 dlossR:0.0000 dlossQsigm:0.0654\n",
      "Episode:1014 meanR:46.3500 rate:0.0800 gloss:0.0000 dloss:3.7735 dlossR:0.0000 dlossQsigm:0.0669\n",
      "Episode:1015 meanR:46.4300 rate:0.0920 gloss:0.0002 dloss:3.4297 dlossR:0.0000 dlossQsigm:0.0655\n",
      "Episode:1016 meanR:46.5800 rate:0.1160 gloss:0.0002 dloss:3.0589 dlossR:0.0000 dlossQsigm:0.0635\n",
      "Episode:1017 meanR:46.2200 rate:0.0720 gloss:0.0001 dloss:2.2660 dlossR:0.0000 dlossQsigm:0.0665\n",
      "Episode:1018 meanR:46.4600 rate:0.1240 gloss:0.0000 dloss:3.9873 dlossR:0.0000 dlossQsigm:0.0640\n",
      "Episode:1019 meanR:45.9900 rate:0.0720 gloss:0.0000 dloss:2.7869 dlossR:0.0000 dlossQsigm:0.0663\n",
      "Episode:1020 meanR:46.0300 rate:0.1080 gloss:0.0001 dloss:4.2124 dlossR:0.0000 dlossQsigm:0.0767\n",
      "Episode:1021 meanR:46.1300 rate:0.1080 gloss:0.0000 dloss:4.6861 dlossR:0.0000 dlossQsigm:0.0872\n",
      "Episode:1022 meanR:46.2400 rate:0.1480 gloss:0.0000 dloss:4.7214 dlossR:0.0000 dlossQsigm:0.1007\n",
      "Episode:1023 meanR:46.4700 rate:0.1360 gloss:0.0000 dloss:4.5924 dlossR:0.0000 dlossQsigm:0.0892\n",
      "Episode:1024 meanR:46.4800 rate:0.0920 gloss:0.0000 dloss:3.0452 dlossR:0.0000 dlossQsigm:0.0686\n",
      "Episode:1025 meanR:46.5900 rate:0.0880 gloss:0.0000 dloss:3.8575 dlossR:0.0000 dlossQsigm:0.0698\n",
      "Episode:1026 meanR:46.8300 rate:0.1100 gloss:0.0000 dloss:6.8494 dlossR:0.0000 dlossQsigm:0.1033\n",
      "Episode:1027 meanR:46.9300 rate:0.0900 gloss:0.0000 dloss:7.0998 dlossR:0.0000 dlossQsigm:0.1025\n",
      "Episode:1028 meanR:47.1400 rate:0.1380 gloss:0.0001 dloss:5.1835 dlossR:0.0000 dlossQsigm:0.1013\n",
      "Episode:1029 meanR:47.2000 rate:0.0780 gloss:0.0001 dloss:4.2540 dlossR:0.0000 dlossQsigm:0.0766\n",
      "Episode:1030 meanR:47.2500 rate:0.1440 gloss:0.0000 dloss:2.5037 dlossR:0.0000 dlossQsigm:0.0691\n",
      "Episode:1031 meanR:47.4800 rate:0.1220 gloss:0.0000 dloss:3.8787 dlossR:0.0000 dlossQsigm:0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1032 meanR:47.2500 rate:0.0880 gloss:0.0000 dloss:4.5887 dlossR:0.0000 dlossQsigm:0.0780\n",
      "Episode:1033 meanR:47.2800 rate:0.0740 gloss:0.0047 dloss:14.7022 dlossR:0.0000 dlossQsigm:0.0605\n",
      "Episode:1034 meanR:47.4100 rate:0.0920 gloss:0.0000 dloss:3.7284 dlossR:0.0000 dlossQsigm:0.0611\n",
      "Episode:1035 meanR:47.3400 rate:0.1000 gloss:0.0000 dloss:2.8938 dlossR:0.0000 dlossQsigm:0.0566\n",
      "Episode:1036 meanR:47.0600 rate:0.0700 gloss:0.0000 dloss:2.4953 dlossR:0.0000 dlossQsigm:0.0696\n",
      "Episode:1037 meanR:46.9800 rate:0.0720 gloss:0.0002 dloss:2.6915 dlossR:0.0000 dlossQsigm:0.0619\n",
      "Episode:1038 meanR:47.2200 rate:0.1180 gloss:0.0000 dloss:3.6603 dlossR:0.0000 dlossQsigm:0.0707\n",
      "Episode:1039 meanR:47.1400 rate:0.0680 gloss:0.0001 dloss:2.2953 dlossR:0.0000 dlossQsigm:0.0490\n",
      "Episode:1040 meanR:47.2000 rate:0.0780 gloss:0.0000 dloss:2.1660 dlossR:0.0000 dlossQsigm:0.0488\n",
      "Episode:1041 meanR:47.2000 rate:0.0920 gloss:0.0000 dloss:1.5135 dlossR:0.0000 dlossQsigm:0.0442\n",
      "Episode:1042 meanR:47.6300 rate:0.1640 gloss:0.0000 dloss:2.6890 dlossR:0.0000 dlossQsigm:0.0413\n",
      "Episode:1043 meanR:47.5600 rate:0.0620 gloss:0.0000 dloss:2.5446 dlossR:0.0000 dlossQsigm:0.0867\n",
      "Episode:1044 meanR:47.4700 rate:0.0840 gloss:0.0003 dloss:3.3298 dlossR:0.0001 dlossQsigm:0.0380\n",
      "Episode:1045 meanR:47.2900 rate:0.0720 gloss:0.0000 dloss:3.5592 dlossR:0.0000 dlossQsigm:0.0483\n",
      "Episode:1046 meanR:47.5300 rate:0.1100 gloss:0.0001 dloss:3.1598 dlossR:0.0000 dlossQsigm:0.0811\n",
      "Episode:1047 meanR:47.5500 rate:0.0700 gloss:0.0010 dloss:3.3473 dlossR:0.0000 dlossQsigm:0.0604\n",
      "Episode:1048 meanR:47.4800 rate:0.0920 gloss:0.0000 dloss:5.4627 dlossR:0.0000 dlossQsigm:0.0818\n",
      "Episode:1049 meanR:47.4300 rate:0.0720 gloss:0.0002 dloss:2.0201 dlossR:0.0000 dlossQsigm:0.0500\n",
      "Episode:1050 meanR:47.5900 rate:0.1260 gloss:0.0000 dloss:5.8928 dlossR:0.0000 dlossQsigm:0.1031\n",
      "Episode:1051 meanR:47.2400 rate:0.0760 gloss:0.0000 dloss:2.0948 dlossR:0.0000 dlossQsigm:0.0570\n",
      "Episode:1052 meanR:47.2700 rate:0.0860 gloss:0.0000 dloss:2.8948 dlossR:0.0000 dlossQsigm:0.0613\n",
      "Episode:1053 meanR:47.2500 rate:0.1220 gloss:0.0005 dloss:4.2138 dlossR:0.0000 dlossQsigm:0.0672\n",
      "Episode:1054 meanR:47.3800 rate:0.0880 gloss:0.0000 dloss:3.9009 dlossR:0.0000 dlossQsigm:0.0852\n",
      "Episode:1055 meanR:47.6200 rate:0.1280 gloss:0.0001 dloss:3.3705 dlossR:0.0000 dlossQsigm:0.0591\n",
      "Episode:1056 meanR:47.5900 rate:0.0760 gloss:0.0000 dloss:3.3246 dlossR:0.0000 dlossQsigm:0.0638\n",
      "Episode:1057 meanR:47.5600 rate:0.0940 gloss:0.0000 dloss:4.4373 dlossR:0.0000 dlossQsigm:0.0672\n",
      "Episode:1058 meanR:47.5900 rate:0.1160 gloss:0.0000 dloss:7.2336 dlossR:0.0000 dlossQsigm:0.1062\n",
      "Episode:1059 meanR:47.7000 rate:0.1040 gloss:0.0000 dloss:5.5873 dlossR:0.0000 dlossQsigm:0.0982\n",
      "Episode:1060 meanR:47.7100 rate:0.1200 gloss:0.0000 dloss:11.1072 dlossR:0.0000 dlossQsigm:0.1055\n",
      "Episode:1061 meanR:47.7500 rate:0.1120 gloss:0.0000 dloss:3.8636 dlossR:0.0000 dlossQsigm:0.0860\n",
      "Episode:1062 meanR:47.6600 rate:0.0840 gloss:0.0000 dloss:4.2718 dlossR:0.0000 dlossQsigm:0.0733\n",
      "Episode:1063 meanR:47.8000 rate:0.0800 gloss:0.0000 dloss:4.3628 dlossR:0.0000 dlossQsigm:0.0697\n",
      "Episode:1064 meanR:47.6300 rate:0.0840 gloss:0.0000 dloss:3.0572 dlossR:0.0000 dlossQsigm:0.0479\n",
      "Episode:1065 meanR:47.8000 rate:0.1160 gloss:0.0000 dloss:5.9452 dlossR:0.0000 dlossQsigm:0.0521\n",
      "Episode:1066 meanR:47.8500 rate:0.2280 gloss:0.0000 dloss:3.8585 dlossR:0.0000 dlossQsigm:0.0594\n",
      "Episode:1067 meanR:47.9400 rate:0.0880 gloss:0.0000 dloss:2.6376 dlossR:0.0000 dlossQsigm:0.0690\n",
      "Episode:1068 meanR:48.0200 rate:0.1240 gloss:0.0000 dloss:5.1409 dlossR:0.0000 dlossQsigm:0.0483\n",
      "Episode:1069 meanR:48.0000 rate:0.0860 gloss:0.0002 dloss:4.6499 dlossR:0.0001 dlossQsigm:0.0610\n",
      "Episode:1070 meanR:47.7700 rate:0.0760 gloss:0.0000 dloss:2.6086 dlossR:0.0000 dlossQsigm:0.0478\n",
      "Episode:1071 meanR:47.5900 rate:0.0760 gloss:0.0001 dloss:2.0473 dlossR:0.0000 dlossQsigm:0.0471\n",
      "Episode:1072 meanR:47.4600 rate:0.0800 gloss:0.0001 dloss:2.8524 dlossR:0.0000 dlossQsigm:0.0686\n",
      "Episode:1073 meanR:47.3900 rate:0.0960 gloss:0.0000 dloss:2.1176 dlossR:0.0000 dlossQsigm:0.0493\n",
      "Episode:1074 meanR:47.5200 rate:0.1120 gloss:0.0000 dloss:3.4680 dlossR:0.0000 dlossQsigm:0.0508\n",
      "Episode:1075 meanR:47.5900 rate:0.0760 gloss:0.0001 dloss:1.9090 dlossR:0.0000 dlossQsigm:0.0464\n",
      "Episode:1076 meanR:47.7600 rate:0.1080 gloss:0.1396 dloss:2.8637 dlossR:0.0000 dlossQsigm:0.0362\n",
      "Episode:1077 meanR:47.7000 rate:0.0920 gloss:0.0000 dloss:1.8695 dlossR:0.0000 dlossQsigm:0.0330\n",
      "Episode:1078 meanR:47.5300 rate:0.0820 gloss:0.0000 dloss:2.1684 dlossR:0.0008 dlossQsigm:0.0490\n",
      "Episode:1079 meanR:47.7500 rate:0.1060 gloss:0.0001 dloss:2.3288 dlossR:0.0005 dlossQsigm:0.0450\n",
      "Episode:1080 meanR:48.0200 rate:0.1220 gloss:0.0000 dloss:4.5767 dlossR:0.0000 dlossQsigm:0.0533\n",
      "Episode:1081 meanR:48.4700 rate:0.1640 gloss:0.0000 dloss:8.6608 dlossR:0.0000 dlossQsigm:0.0596\n",
      "Episode:1082 meanR:48.2700 rate:0.0840 gloss:0.0002 dloss:4.5842 dlossR:0.0011 dlossQsigm:0.0459\n",
      "Episode:1083 meanR:48.3800 rate:0.0920 gloss:0.0001 dloss:3.0972 dlossR:0.0000 dlossQsigm:0.0643\n",
      "Episode:1084 meanR:48.3300 rate:0.0960 gloss:0.0001 dloss:14.2523 dlossR:0.0000 dlossQsigm:0.1691\n",
      "Episode:1085 meanR:48.5700 rate:0.1040 gloss:0.0006 dloss:13.3619 dlossR:0.0000 dlossQsigm:0.1337\n",
      "Episode:1086 meanR:48.7000 rate:0.1200 gloss:0.0001 dloss:12.0622 dlossR:0.0000 dlossQsigm:0.1270\n",
      "Episode:1087 meanR:49.1400 rate:0.1460 gloss:0.0000 dloss:3.3104 dlossR:0.0000 dlossQsigm:0.0430\n",
      "Episode:1088 meanR:48.9000 rate:0.1100 gloss:0.0000 dloss:3.7976 dlossR:0.0013 dlossQsigm:0.0373\n",
      "Episode:1089 meanR:49.1400 rate:0.1060 gloss:0.0000 dloss:3.0200 dlossR:0.0001 dlossQsigm:0.0337\n",
      "Episode:1090 meanR:49.2500 rate:0.1080 gloss:0.0000 dloss:3.3238 dlossR:0.0010 dlossQsigm:0.0450\n",
      "Episode:1091 meanR:49.5600 rate:0.1420 gloss:0.0402 dloss:4.6150 dlossR:0.0000 dlossQsigm:0.0364\n",
      "Episode:1092 meanR:49.6700 rate:0.1140 gloss:0.0000 dloss:4.6994 dlossR:0.0001 dlossQsigm:0.0348\n",
      "Episode:1093 meanR:50.4000 rate:0.2320 gloss:0.0000 dloss:5.2289 dlossR:0.0002 dlossQsigm:0.0417\n",
      "Episode:1094 meanR:50.5200 rate:0.1180 gloss:0.0000 dloss:3.4134 dlossR:0.0000 dlossQsigm:0.0464\n",
      "Episode:1095 meanR:50.8600 rate:0.1520 gloss:0.0000 dloss:5.6305 dlossR:0.0000 dlossQsigm:0.0471\n",
      "Episode:1096 meanR:51.2600 rate:0.1420 gloss:0.0021 dloss:2.8407 dlossR:0.0000 dlossQsigm:0.0467\n",
      "Episode:1097 meanR:52.0300 rate:0.2360 gloss:0.0000 dloss:16.0257 dlossR:0.0000 dlossQsigm:0.0740\n",
      "Episode:1098 meanR:52.6800 rate:0.2180 gloss:0.0000 dloss:9.6585 dlossR:0.0000 dlossQsigm:0.0669\n",
      "Episode:1099 meanR:52.9600 rate:0.1160 gloss:0.0000 dloss:3.0865 dlossR:0.0000 dlossQsigm:0.0370\n",
      "Episode:1100 meanR:53.6400 rate:0.2560 gloss:0.0000 dloss:7.3173 dlossR:0.0000 dlossQsigm:0.0722\n",
      "Episode:1101 meanR:53.9500 rate:0.1320 gloss:0.0000 dloss:4.3625 dlossR:0.0000 dlossQsigm:0.0836\n",
      "Episode:1102 meanR:54.1600 rate:0.1120 gloss:0.1157 dloss:3.2955 dlossR:0.0000 dlossQsigm:0.0433\n",
      "Episode:1103 meanR:53.9700 rate:0.0940 gloss:0.0016 dloss:7.5928 dlossR:0.0006 dlossQsigm:0.0331\n",
      "Episode:1104 meanR:54.0500 rate:0.0940 gloss:0.0001 dloss:3.3326 dlossR:0.0185 dlossQsigm:0.1264\n",
      "Episode:1105 meanR:54.4200 rate:0.1500 gloss:0.0000 dloss:13.4660 dlossR:0.0000 dlossQsigm:0.0504\n",
      "Episode:1106 meanR:54.5400 rate:0.1500 gloss:0.0000 dloss:5.1076 dlossR:0.0000 dlossQsigm:0.0652\n",
      "Episode:1107 meanR:54.5300 rate:0.1020 gloss:0.0037 dloss:3.0608 dlossR:0.0000 dlossQsigm:0.0535\n",
      "Episode:1108 meanR:54.6200 rate:0.0940 gloss:0.0000 dloss:6.8012 dlossR:0.0000 dlossQsigm:0.0728\n",
      "Episode:1109 meanR:54.8700 rate:0.1300 gloss:0.0000 dloss:7.6495 dlossR:0.0000 dlossQsigm:0.0465\n",
      "Episode:1110 meanR:55.2500 rate:0.1500 gloss:0.0000 dloss:2.2518 dlossR:0.0000 dlossQsigm:0.0407\n",
      "Episode:1111 meanR:55.0400 rate:0.1220 gloss:0.0000 dloss:3.1875 dlossR:0.0000 dlossQsigm:0.0412\n",
      "Episode:1112 meanR:55.1100 rate:0.0900 gloss:0.0000 dloss:3.1594 dlossR:0.0001 dlossQsigm:0.0344\n",
      "Episode:1113 meanR:55.1900 rate:0.1020 gloss:0.0000 dloss:3.2169 dlossR:0.0027 dlossQsigm:0.0506\n",
      "Episode:1114 meanR:55.3600 rate:0.1140 gloss:0.0000 dloss:5.2396 dlossR:0.0006 dlossQsigm:0.0520\n",
      "Episode:1115 meanR:55.3300 rate:0.0860 gloss:0.0000 dloss:1.8124 dlossR:0.0003 dlossQsigm:0.0489\n",
      "Episode:1116 meanR:55.3200 rate:0.1140 gloss:0.0000 dloss:6.0724 dlossR:0.0002 dlossQsigm:0.0449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1117 meanR:55.6900 rate:0.1460 gloss:0.0000 dloss:8.6104 dlossR:0.0011 dlossQsigm:0.0592\n",
      "Episode:1118 meanR:55.5000 rate:0.0860 gloss:0.0002 dloss:4.9548 dlossR:0.0000 dlossQsigm:0.0655\n",
      "Episode:1119 meanR:56.4100 rate:0.2540 gloss:0.0000 dloss:9.7114 dlossR:0.0000 dlossQsigm:0.0780\n",
      "Episode:1120 meanR:56.4400 rate:0.1140 gloss:0.0000 dloss:4.9224 dlossR:0.0000 dlossQsigm:0.0764\n",
      "Episode:1121 meanR:56.4500 rate:0.1100 gloss:0.0000 dloss:5.5307 dlossR:0.0000 dlossQsigm:0.0631\n",
      "Episode:1122 meanR:56.4700 rate:0.1520 gloss:0.0000 dloss:7.6744 dlossR:0.0000 dlossQsigm:0.0993\n",
      "Episode:1123 meanR:56.6800 rate:0.1780 gloss:0.0000 dloss:3.6458 dlossR:0.0000 dlossQsigm:0.0656\n",
      "Episode:1124 meanR:56.8600 rate:0.1280 gloss:0.0003 dloss:4.9045 dlossR:0.0000 dlossQsigm:0.0631\n",
      "Episode:1125 meanR:57.0900 rate:0.1340 gloss:0.0000 dloss:8.0955 dlossR:0.0000 dlossQsigm:0.0808\n",
      "Episode:1126 meanR:57.5100 rate:0.1940 gloss:0.0000 dloss:4.4585 dlossR:0.0000 dlossQsigm:0.0953\n",
      "Episode:1127 meanR:57.5100 rate:0.0900 gloss:0.0000 dloss:5.2143 dlossR:0.0008 dlossQsigm:0.0366\n",
      "Episode:1128 meanR:57.7500 rate:0.1860 gloss:0.0000 dloss:8.0583 dlossR:0.0000 dlossQsigm:0.0770\n",
      "Episode:1129 meanR:57.7600 rate:0.0800 gloss:0.0000 dloss:1.9112 dlossR:0.0006 dlossQsigm:0.0313\n",
      "Episode:1130 meanR:57.8000 rate:0.1520 gloss:0.0208 dloss:4.8332 dlossR:0.0005 dlossQsigm:0.0503\n",
      "Episode:1131 meanR:57.8100 rate:0.1240 gloss:0.0000 dloss:4.3379 dlossR:0.0011 dlossQsigm:0.0719\n",
      "Episode:1132 meanR:58.2800 rate:0.1820 gloss:0.0000 dloss:6.2167 dlossR:0.0000 dlossQsigm:0.0766\n",
      "Episode:1133 meanR:58.3800 rate:0.0940 gloss:0.0002 dloss:2.8013 dlossR:0.0000 dlossQsigm:0.0606\n",
      "Episode:1134 meanR:58.4100 rate:0.0980 gloss:0.0000 dloss:1.8875 dlossR:0.0000 dlossQsigm:0.0479\n",
      "Episode:1135 meanR:58.4600 rate:0.1100 gloss:0.0000 dloss:2.6835 dlossR:0.0000 dlossQsigm:0.0561\n",
      "Episode:1136 meanR:58.6000 rate:0.0980 gloss:0.0000 dloss:3.5700 dlossR:0.0000 dlossQsigm:0.0702\n",
      "Episode:1137 meanR:58.8100 rate:0.1140 gloss:0.0000 dloss:2.4517 dlossR:0.0001 dlossQsigm:0.0319\n",
      "Episode:1138 meanR:58.6500 rate:0.0860 gloss:0.0000 dloss:3.1752 dlossR:0.0000 dlossQsigm:0.0472\n",
      "Episode:1139 meanR:58.8200 rate:0.1020 gloss:0.0000 dloss:2.3286 dlossR:0.0003 dlossQsigm:0.0368\n",
      "Episode:1140 meanR:58.9800 rate:0.1100 gloss:0.0000 dloss:3.9662 dlossR:0.0000 dlossQsigm:0.0643\n",
      "Episode:1141 meanR:59.2000 rate:0.1360 gloss:0.0022 dloss:3.2452 dlossR:0.0000 dlossQsigm:0.0625\n",
      "Episode:1142 meanR:59.3100 rate:0.1860 gloss:0.0000 dloss:6.3302 dlossR:0.0000 dlossQsigm:0.0845\n",
      "Episode:1143 meanR:59.7100 rate:0.1420 gloss:0.0000 dloss:10.5776 dlossR:0.0000 dlossQsigm:0.0428\n",
      "Episode:1144 meanR:59.8800 rate:0.1180 gloss:0.0002 dloss:5.4555 dlossR:0.0000 dlossQsigm:0.0498\n",
      "Episode:1145 meanR:60.1300 rate:0.1220 gloss:0.0000 dloss:8.1009 dlossR:0.0000 dlossQsigm:0.0876\n",
      "Episode:1146 meanR:60.0300 rate:0.0900 gloss:0.0000 dloss:3.8157 dlossR:0.0000 dlossQsigm:0.0541\n",
      "Episode:1147 meanR:60.0400 rate:0.0720 gloss:0.0000 dloss:2.4730 dlossR:0.0000 dlossQsigm:0.0526\n",
      "Episode:1148 meanR:60.0200 rate:0.0880 gloss:0.0000 dloss:2.3048 dlossR:0.0000 dlossQsigm:0.0411\n",
      "Episode:1149 meanR:60.5000 rate:0.1680 gloss:0.0001 dloss:3.7184 dlossR:0.0000 dlossQsigm:0.0493\n",
      "Episode:1150 meanR:60.4100 rate:0.1080 gloss:0.0004 dloss:4.8897 dlossR:0.0000 dlossQsigm:0.0488\n",
      "Episode:1151 meanR:60.6600 rate:0.1260 gloss:0.0000 dloss:4.1545 dlossR:0.0000 dlossQsigm:0.0462\n",
      "Episode:1152 meanR:60.6400 rate:0.0820 gloss:0.0000 dloss:4.3941 dlossR:0.0000 dlossQsigm:0.0599\n",
      "Episode:1153 meanR:60.3900 rate:0.0720 gloss:0.0000 dloss:6.1412 dlossR:0.0000 dlossQsigm:0.0598\n",
      "Episode:1154 meanR:60.4900 rate:0.1080 gloss:0.0000 dloss:3.1815 dlossR:0.0000 dlossQsigm:0.0731\n",
      "Episode:1155 meanR:60.5800 rate:0.1460 gloss:0.0000 dloss:10.3361 dlossR:0.0000 dlossQsigm:0.0895\n",
      "Episode:1156 meanR:60.5600 rate:0.0720 gloss:0.0000 dloss:6.9054 dlossR:0.0000 dlossQsigm:0.0843\n",
      "Episode:1157 meanR:60.7500 rate:0.1320 gloss:0.0000 dloss:4.6012 dlossR:0.0000 dlossQsigm:0.0706\n",
      "Episode:1158 meanR:60.5300 rate:0.0720 gloss:0.0006 dloss:3.6661 dlossR:0.0000 dlossQsigm:0.0606\n",
      "Episode:1159 meanR:60.4000 rate:0.0780 gloss:0.0003 dloss:4.7875 dlossR:0.0000 dlossQsigm:0.0919\n",
      "Episode:1160 meanR:60.3200 rate:0.1040 gloss:0.0000 dloss:12.2027 dlossR:0.0000 dlossQsigm:0.1188\n",
      "Episode:1161 meanR:60.2000 rate:0.0880 gloss:0.0000 dloss:6.0855 dlossR:0.0000 dlossQsigm:0.0758\n",
      "Episode:1162 meanR:60.2500 rate:0.0940 gloss:0.0000 dloss:5.4422 dlossR:0.0000 dlossQsigm:0.0978\n",
      "Episode:1163 meanR:60.5000 rate:0.1300 gloss:0.0000 dloss:6.1978 dlossR:0.0000 dlossQsigm:0.0974\n",
      "Episode:1164 meanR:60.5100 rate:0.0860 gloss:0.0000 dloss:5.7132 dlossR:0.0000 dlossQsigm:0.1056\n",
      "Episode:1165 meanR:60.3900 rate:0.0920 gloss:0.0018 dloss:12.7811 dlossR:0.0000 dlossQsigm:0.1424\n",
      "Episode:1166 meanR:59.9000 rate:0.1300 gloss:0.0000 dloss:7.1069 dlossR:0.0000 dlossQsigm:0.1057\n",
      "Episode:1167 meanR:59.8200 rate:0.0720 gloss:0.0000 dloss:13.1442 dlossR:0.0000 dlossQsigm:0.0578\n",
      "Episode:1168 meanR:59.5800 rate:0.0760 gloss:0.0000 dloss:4.8398 dlossR:0.0000 dlossQsigm:0.0529\n",
      "Episode:1169 meanR:59.4900 rate:0.0680 gloss:0.0189 dloss:6.5347 dlossR:0.0000 dlossQsigm:0.0384\n",
      "Episode:1170 meanR:59.5700 rate:0.0920 gloss:0.0002 dloss:4.7453 dlossR:0.0000 dlossQsigm:0.0567\n",
      "Episode:1171 meanR:59.5400 rate:0.0700 gloss:0.0003 dloss:2.3160 dlossR:0.0000 dlossQsigm:0.0383\n",
      "Episode:1172 meanR:59.6600 rate:0.1040 gloss:0.0000 dloss:2.2256 dlossR:0.0000 dlossQsigm:0.0534\n",
      "Episode:1173 meanR:59.8600 rate:0.1360 gloss:0.0000 dloss:3.0884 dlossR:0.0000 dlossQsigm:0.0718\n",
      "Episode:1174 meanR:59.7200 rate:0.0840 gloss:0.0000 dloss:3.3515 dlossR:0.0000 dlossQsigm:0.0536\n",
      "Episode:1175 meanR:60.0000 rate:0.1320 gloss:0.0000 dloss:4.1924 dlossR:0.0000 dlossQsigm:0.0589\n",
      "Episode:1176 meanR:59.8100 rate:0.0700 gloss:0.0019 dloss:3.0622 dlossR:0.0000 dlossQsigm:0.0604\n",
      "Episode:1177 meanR:59.9300 rate:0.1160 gloss:0.0001 dloss:4.6807 dlossR:0.0000 dlossQsigm:0.0703\n",
      "Episode:1178 meanR:59.9600 rate:0.0880 gloss:0.0000 dloss:3.9285 dlossR:0.0000 dlossQsigm:0.0535\n",
      "Episode:1179 meanR:59.8300 rate:0.0800 gloss:0.0003 dloss:2.4115 dlossR:0.0000 dlossQsigm:0.0475\n",
      "Episode:1180 meanR:59.6800 rate:0.0920 gloss:0.0000 dloss:2.5849 dlossR:0.0000 dlossQsigm:0.0478\n",
      "Episode:1181 meanR:59.2200 rate:0.0720 gloss:0.0000 dloss:2.1193 dlossR:0.0001 dlossQsigm:0.0389\n",
      "Episode:1182 meanR:59.2000 rate:0.0800 gloss:0.0000 dloss:2.1089 dlossR:0.0000 dlossQsigm:0.0385\n",
      "Episode:1183 meanR:59.4900 rate:0.1500 gloss:0.0001 dloss:3.7955 dlossR:0.0000 dlossQsigm:0.0872\n",
      "Episode:1184 meanR:59.5300 rate:0.1040 gloss:0.0000 dloss:5.9565 dlossR:0.0000 dlossQsigm:0.0923\n",
      "Episode:1185 meanR:59.4300 rate:0.0840 gloss:0.0000 dloss:2.9564 dlossR:0.0000 dlossQsigm:0.0564\n",
      "Episode:1186 meanR:59.3700 rate:0.1080 gloss:0.0000 dloss:3.6792 dlossR:0.0000 dlossQsigm:0.0778\n",
      "Episode:1187 meanR:59.3500 rate:0.1420 gloss:0.0000 dloss:5.9834 dlossR:0.0000 dlossQsigm:0.0930\n",
      "Episode:1188 meanR:59.3600 rate:0.1120 gloss:0.0001 dloss:4.9000 dlossR:0.0000 dlossQsigm:0.0718\n",
      "Episode:1189 meanR:59.3000 rate:0.0940 gloss:0.0006 dloss:5.4204 dlossR:0.0000 dlossQsigm:0.1009\n",
      "Episode:1190 meanR:59.2600 rate:0.1000 gloss:0.0029 dloss:3.8888 dlossR:0.0000 dlossQsigm:0.0725\n",
      "Episode:1191 meanR:58.9500 rate:0.0800 gloss:0.0000 dloss:4.0285 dlossR:0.0000 dlossQsigm:0.0862\n",
      "Episode:1192 meanR:58.7800 rate:0.0800 gloss:0.0000 dloss:3.1994 dlossR:0.0000 dlossQsigm:0.0669\n",
      "Episode:1193 meanR:58.2300 rate:0.1220 gloss:0.0000 dloss:5.6282 dlossR:0.0000 dlossQsigm:0.0987\n",
      "Episode:1194 meanR:58.0200 rate:0.0760 gloss:0.0000 dloss:5.3425 dlossR:0.0000 dlossQsigm:0.1052\n",
      "Episode:1195 meanR:57.7400 rate:0.0960 gloss:0.0000 dloss:3.9639 dlossR:0.0000 dlossQsigm:0.0796\n",
      "Episode:1196 meanR:57.6500 rate:0.1240 gloss:0.0000 dloss:3.1956 dlossR:0.0000 dlossQsigm:0.0809\n",
      "Episode:1197 meanR:56.8800 rate:0.0820 gloss:0.0007 dloss:7.5615 dlossR:0.0000 dlossQsigm:0.1078\n",
      "Episode:1198 meanR:56.3500 rate:0.1120 gloss:0.0000 dloss:6.0664 dlossR:0.0000 dlossQsigm:0.1132\n",
      "Episode:1199 meanR:56.6100 rate:0.1680 gloss:0.0000 dloss:8.2684 dlossR:0.0000 dlossQsigm:0.1063\n",
      "Episode:1200 meanR:55.9600 rate:0.1260 gloss:0.0000 dloss:8.7565 dlossR:0.0000 dlossQsigm:0.1071\n",
      "Episode:1201 meanR:55.7600 rate:0.0920 gloss:0.0000 dloss:6.7825 dlossR:0.0000 dlossQsigm:0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1202 meanR:55.6100 rate:0.0820 gloss:0.0000 dloss:5.3540 dlossR:0.0000 dlossQsigm:0.1005\n",
      "Episode:1203 meanR:55.5200 rate:0.0760 gloss:0.0000 dloss:3.0062 dlossR:0.0000 dlossQsigm:0.0710\n",
      "Episode:1204 meanR:55.9400 rate:0.1780 gloss:0.0000 dloss:4.0076 dlossR:0.0000 dlossQsigm:0.0843\n",
      "Episode:1205 meanR:55.8900 rate:0.1400 gloss:0.0000 dloss:7.7698 dlossR:0.0000 dlossQsigm:0.0900\n",
      "Episode:1206 meanR:55.6500 rate:0.1020 gloss:0.0000 dloss:13.4361 dlossR:0.0000 dlossQsigm:0.1299\n",
      "Episode:1207 meanR:55.7300 rate:0.1180 gloss:0.0000 dloss:4.8187 dlossR:0.0000 dlossQsigm:0.0818\n",
      "Episode:1208 meanR:55.8300 rate:0.1140 gloss:0.0000 dloss:5.4511 dlossR:0.0000 dlossQsigm:0.1017\n",
      "Episode:1209 meanR:55.7800 rate:0.1200 gloss:0.0000 dloss:6.3556 dlossR:0.0000 dlossQsigm:0.1159\n",
      "Episode:1210 meanR:55.6000 rate:0.1140 gloss:0.0000 dloss:10.2749 dlossR:0.0000 dlossQsigm:0.1403\n",
      "Episode:1211 meanR:55.5400 rate:0.1100 gloss:0.0000 dloss:6.5198 dlossR:0.0000 dlossQsigm:0.1152\n",
      "Episode:1212 meanR:55.6200 rate:0.1060 gloss:0.0353 dloss:9.8456 dlossR:0.0000 dlossQsigm:0.1007\n",
      "Episode:1213 meanR:55.9400 rate:0.1660 gloss:0.0000 dloss:5.4508 dlossR:0.0000 dlossQsigm:0.0964\n",
      "Episode:1214 meanR:55.8100 rate:0.0880 gloss:0.0000 dloss:7.0950 dlossR:0.0000 dlossQsigm:0.1146\n",
      "Episode:1215 meanR:55.9100 rate:0.1060 gloss:0.0000 dloss:6.5429 dlossR:0.0000 dlossQsigm:0.1022\n",
      "Episode:1216 meanR:55.7600 rate:0.0840 gloss:0.0000 dloss:5.8243 dlossR:0.0000 dlossQsigm:0.1090\n",
      "Episode:1217 meanR:56.0300 rate:0.2000 gloss:0.0020 dloss:11.4984 dlossR:0.0000 dlossQsigm:0.1179\n",
      "Episode:1218 meanR:56.1200 rate:0.1040 gloss:0.0000 dloss:8.9896 dlossR:0.0000 dlossQsigm:0.1175\n",
      "Episode:1219 meanR:55.4200 rate:0.1140 gloss:0.0002 dloss:7.5964 dlossR:0.0000 dlossQsigm:0.1252\n",
      "Episode:1220 meanR:55.2800 rate:0.0860 gloss:0.0000 dloss:7.4756 dlossR:0.0000 dlossQsigm:0.1081\n",
      "Episode:1221 meanR:55.3200 rate:0.1180 gloss:0.0000 dloss:8.8321 dlossR:0.0000 dlossQsigm:0.0650\n",
      "Episode:1222 meanR:55.5500 rate:0.1980 gloss:0.0000 dloss:8.5863 dlossR:0.0000 dlossQsigm:0.1173\n",
      "Episode:1223 meanR:55.3600 rate:0.1400 gloss:0.0000 dloss:9.5116 dlossR:0.0000 dlossQsigm:0.0907\n",
      "Episode:1224 meanR:55.3000 rate:0.1160 gloss:0.0000 dloss:7.6637 dlossR:0.0000 dlossQsigm:0.1122\n",
      "Episode:1225 meanR:55.4000 rate:0.1540 gloss:0.0000 dloss:4.0251 dlossR:0.0000 dlossQsigm:0.0408\n",
      "Episode:1226 meanR:55.2000 rate:0.1540 gloss:0.0000 dloss:5.5336 dlossR:0.0000 dlossQsigm:0.0528\n",
      "Episode:1227 meanR:55.1300 rate:0.0760 gloss:0.0000 dloss:4.4606 dlossR:0.0000 dlossQsigm:0.0376\n",
      "Episode:1228 meanR:54.6700 rate:0.0940 gloss:0.0000 dloss:8.0599 dlossR:0.0002 dlossQsigm:0.0890\n",
      "Episode:1229 meanR:54.7500 rate:0.0960 gloss:0.0000 dloss:5.5113 dlossR:0.0000 dlossQsigm:0.0641\n",
      "Episode:1230 meanR:54.3700 rate:0.0760 gloss:0.0000 dloss:7.0538 dlossR:0.0000 dlossQsigm:0.0784\n",
      "Episode:1231 meanR:54.1700 rate:0.0840 gloss:0.0000 dloss:8.9197 dlossR:0.0000 dlossQsigm:0.0470\n",
      "Episode:1232 meanR:53.6500 rate:0.0780 gloss:0.0000 dloss:5.0395 dlossR:0.0181 dlossQsigm:0.1673\n",
      "Episode:1233 meanR:53.6100 rate:0.0860 gloss:0.0001 dloss:2.6843 dlossR:0.0009 dlossQsigm:0.0297\n",
      "Episode:1234 meanR:53.9400 rate:0.1640 gloss:0.0000 dloss:6.1073 dlossR:0.0000 dlossQsigm:0.0673\n",
      "Episode:1235 meanR:53.8000 rate:0.0820 gloss:0.0000 dloss:4.7641 dlossR:0.0000 dlossQsigm:0.0642\n",
      "Episode:1236 meanR:53.7600 rate:0.0900 gloss:0.0000 dloss:3.3937 dlossR:0.0000 dlossQsigm:0.0340\n",
      "Episode:1237 meanR:54.0000 rate:0.1620 gloss:0.0000 dloss:4.7363 dlossR:0.0000 dlossQsigm:0.0799\n",
      "Episode:1238 meanR:54.1800 rate:0.1220 gloss:0.0000 dloss:17.8424 dlossR:0.0045 dlossQsigm:0.0841\n",
      "Episode:1239 meanR:54.1800 rate:0.1020 gloss:0.0003 dloss:10.6993 dlossR:0.0290 dlossQsigm:0.1895\n",
      "Episode:1240 meanR:54.4500 rate:0.1640 gloss:-0.0001 dloss:22.9881 dlossR:0.0576 dlossQsigm:0.3196\n",
      "Episode:1241 meanR:54.5300 rate:0.1520 gloss:0.0000 dloss:14.1347 dlossR:0.0000 dlossQsigm:0.1441\n",
      "Episode:1242 meanR:54.0400 rate:0.0880 gloss:0.0000 dloss:9.6330 dlossR:0.0000 dlossQsigm:0.0682\n",
      "Episode:1243 meanR:53.7900 rate:0.0920 gloss:0.0000 dloss:13.4026 dlossR:0.0000 dlossQsigm:0.1441\n",
      "Episode:1244 meanR:54.0900 rate:0.1780 gloss:0.0000 dloss:4.5203 dlossR:0.0004 dlossQsigm:0.0407\n",
      "Episode:1245 meanR:54.2900 rate:0.1620 gloss:0.0000 dloss:5.8870 dlossR:0.0028 dlossQsigm:0.0403\n",
      "Episode:1246 meanR:54.2400 rate:0.0800 gloss:0.0000 dloss:6.5743 dlossR:0.0000 dlossQsigm:0.0544\n",
      "Episode:1247 meanR:54.3400 rate:0.0920 gloss:0.0000 dloss:9.5080 dlossR:0.0008 dlossQsigm:0.0462\n",
      "Episode:1248 meanR:54.3700 rate:0.0940 gloss:0.0000 dloss:6.4943 dlossR:0.0044 dlossQsigm:0.0579\n",
      "Episode:1249 meanR:53.9300 rate:0.0800 gloss:0.0001 dloss:9.4749 dlossR:0.0000 dlossQsigm:0.0813\n",
      "Episode:1250 meanR:54.1300 rate:0.1480 gloss:0.0001 dloss:7.4355 dlossR:0.0000 dlossQsigm:0.0494\n",
      "Episode:1251 meanR:54.1100 rate:0.1220 gloss:0.0000 dloss:4.7188 dlossR:0.0000 dlossQsigm:0.0754\n",
      "Episode:1252 meanR:54.4300 rate:0.1460 gloss:0.0000 dloss:8.0303 dlossR:0.0000 dlossQsigm:0.0761\n",
      "Episode:1253 meanR:54.9200 rate:0.1700 gloss:0.0000 dloss:8.8215 dlossR:0.0000 dlossQsigm:0.0696\n",
      "Episode:1254 meanR:54.8100 rate:0.0860 gloss:0.0008 dloss:4.2364 dlossR:0.0000 dlossQsigm:0.0674\n",
      "Episode:1255 meanR:54.4800 rate:0.0800 gloss:0.0000 dloss:3.5695 dlossR:0.0000 dlossQsigm:0.0386\n",
      "Episode:1256 meanR:54.5600 rate:0.0880 gloss:0.0000 dloss:7.6987 dlossR:0.0001 dlossQsigm:0.0361\n",
      "Episode:1257 meanR:54.6000 rate:0.1400 gloss:0.0000 dloss:4.3135 dlossR:0.0000 dlossQsigm:0.0393\n",
      "Episode:1258 meanR:54.7600 rate:0.1040 gloss:0.0000 dloss:3.9944 dlossR:0.0000 dlossQsigm:0.0492\n",
      "Episode:1259 meanR:54.8500 rate:0.0960 gloss:0.0001 dloss:3.3464 dlossR:0.0000 dlossQsigm:0.0443\n",
      "Episode:1260 meanR:54.8500 rate:0.1040 gloss:0.0000 dloss:1.9270 dlossR:0.0000 dlossQsigm:0.0467\n",
      "Episode:1261 meanR:55.0800 rate:0.1340 gloss:0.0000 dloss:4.7872 dlossR:0.0000 dlossQsigm:0.0636\n",
      "Episode:1262 meanR:55.0300 rate:0.0840 gloss:0.0000 dloss:6.1494 dlossR:0.0000 dlossQsigm:0.0806\n",
      "Episode:1263 meanR:55.1600 rate:0.1560 gloss:0.0000 dloss:8.3875 dlossR:0.0000 dlossQsigm:0.0798\n",
      "Episode:1264 meanR:55.1800 rate:0.0900 gloss:0.0000 dloss:10.3211 dlossR:0.0000 dlossQsigm:0.1339\n",
      "Episode:1265 meanR:55.2600 rate:0.1080 gloss:0.0000 dloss:11.3345 dlossR:0.0000 dlossQsigm:0.1291\n",
      "Episode:1266 meanR:54.9400 rate:0.0660 gloss:0.0000 dloss:10.5003 dlossR:0.0000 dlossQsigm:0.0916\n",
      "Episode:1267 meanR:55.4000 rate:0.1640 gloss:0.0000 dloss:13.3438 dlossR:0.0000 dlossQsigm:0.1312\n",
      "Episode:1268 meanR:55.7000 rate:0.1360 gloss:0.0000 dloss:14.8978 dlossR:0.0000 dlossQsigm:0.1479\n",
      "Episode:1269 meanR:55.9200 rate:0.1120 gloss:0.0002 dloss:16.0343 dlossR:0.0000 dlossQsigm:0.1658\n",
      "Episode:1270 meanR:56.1900 rate:0.1460 gloss:0.0000 dloss:18.7439 dlossR:0.0000 dlossQsigm:0.1936\n",
      "Episode:1271 meanR:56.2600 rate:0.0840 gloss:0.0001 dloss:14.7734 dlossR:0.0000 dlossQsigm:0.1524\n",
      "Episode:1272 meanR:56.1600 rate:0.0840 gloss:0.0001 dloss:7.4253 dlossR:0.0000 dlossQsigm:0.1032\n",
      "Episode:1273 meanR:55.9600 rate:0.0960 gloss:0.0000 dloss:8.2397 dlossR:0.0000 dlossQsigm:0.1101\n",
      "Episode:1274 meanR:56.0100 rate:0.0940 gloss:0.0000 dloss:8.9007 dlossR:0.0000 dlossQsigm:0.1131\n",
      "Episode:1275 meanR:55.8400 rate:0.0980 gloss:0.0000 dloss:14.3188 dlossR:0.0000 dlossQsigm:0.1511\n",
      "Episode:1276 meanR:56.1000 rate:0.1220 gloss:0.0000 dloss:11.3152 dlossR:0.0000 dlossQsigm:0.1273\n",
      "Episode:1277 meanR:56.0200 rate:0.1000 gloss:0.0000 dloss:14.7436 dlossR:0.0000 dlossQsigm:0.1662\n",
      "Episode:1278 meanR:56.0500 rate:0.0940 gloss:0.0000 dloss:18.8733 dlossR:0.0000 dlossQsigm:0.1683\n",
      "Episode:1279 meanR:56.0200 rate:0.0740 gloss:0.0000 dloss:12.0836 dlossR:0.0000 dlossQsigm:0.1510\n",
      "Episode:1280 meanR:56.0800 rate:0.1040 gloss:0.0003 dloss:14.4430 dlossR:0.0000 dlossQsigm:0.1613\n",
      "Episode:1281 meanR:56.1500 rate:0.0860 gloss:0.0000 dloss:20.8633 dlossR:0.0000 dlossQsigm:0.2046\n",
      "Episode:1282 meanR:56.4300 rate:0.1360 gloss:0.0000 dloss:23.6107 dlossR:0.0000 dlossQsigm:0.2255\n",
      "Episode:1283 meanR:56.8700 rate:0.2380 gloss:0.0000 dloss:21.8207 dlossR:0.0000 dlossQsigm:0.2014\n",
      "Episode:1284 meanR:56.8500 rate:0.1000 gloss:0.0002 dloss:14.4880 dlossR:0.0000 dlossQsigm:0.1372\n",
      "Episode:1285 meanR:57.1800 rate:0.1500 gloss:0.0000 dloss:10.2394 dlossR:0.0000 dlossQsigm:0.1159\n",
      "Episode:1286 meanR:57.2900 rate:0.1300 gloss:0.0000 dloss:13.6294 dlossR:0.0000 dlossQsigm:0.1519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1287 meanR:57.2200 rate:0.1280 gloss:0.0000 dloss:25.6460 dlossR:0.0000 dlossQsigm:0.1816\n",
      "Episode:1288 meanR:57.0600 rate:0.0800 gloss:0.0000 dloss:8.1636 dlossR:0.0000 dlossQsigm:0.0960\n",
      "Episode:1289 meanR:57.0600 rate:0.0940 gloss:0.0000 dloss:6.0554 dlossR:0.0000 dlossQsigm:0.0791\n",
      "Episode:1290 meanR:57.1500 rate:0.1180 gloss:0.0000 dloss:6.9173 dlossR:0.0000 dlossQsigm:0.0847\n",
      "Episode:1291 meanR:57.2300 rate:0.0960 gloss:0.0000 dloss:9.2237 dlossR:0.0000 dlossQsigm:0.0786\n",
      "Episode:1292 meanR:57.3400 rate:0.1020 gloss:0.0000 dloss:7.5559 dlossR:0.0000 dlossQsigm:0.0763\n",
      "Episode:1293 meanR:57.3100 rate:0.1160 gloss:0.0000 dloss:12.8940 dlossR:0.0000 dlossQsigm:0.1196\n",
      "Episode:1294 meanR:57.4700 rate:0.1080 gloss:0.0000 dloss:27.7566 dlossR:0.0000 dlossQsigm:0.1609\n",
      "Episode:1295 meanR:57.6800 rate:0.1380 gloss:0.0000 dloss:8.7608 dlossR:0.0000 dlossQsigm:0.0853\n",
      "Episode:1296 meanR:57.5400 rate:0.0960 gloss:0.0000 dloss:12.1965 dlossR:0.0000 dlossQsigm:0.1174\n",
      "Episode:1297 meanR:58.0400 rate:0.1820 gloss:0.0000 dloss:8.3052 dlossR:0.0000 dlossQsigm:0.1090\n",
      "Episode:1298 meanR:58.6100 rate:0.2260 gloss:0.0041 dloss:12.9554 dlossR:0.0000 dlossQsigm:0.1239\n",
      "Episode:1299 meanR:58.8800 rate:0.2220 gloss:0.0000 dloss:6.6435 dlossR:0.0000 dlossQsigm:0.0843\n",
      "Episode:1300 meanR:58.8400 rate:0.1180 gloss:0.0000 dloss:8.9480 dlossR:0.0000 dlossQsigm:0.0869\n",
      "Episode:1301 meanR:59.0900 rate:0.1420 gloss:0.0000 dloss:6.8422 dlossR:0.0000 dlossQsigm:0.0784\n",
      "Episode:1302 meanR:59.1500 rate:0.0940 gloss:0.0000 dloss:10.1214 dlossR:0.0002 dlossQsigm:0.0345\n",
      "Episode:1303 meanR:59.2200 rate:0.0900 gloss:0.0000 dloss:7.6431 dlossR:0.0000 dlossQsigm:0.0361\n",
      "Episode:1304 meanR:59.1500 rate:0.1640 gloss:0.0000 dloss:10.1389 dlossR:0.0000 dlossQsigm:0.0396\n",
      "Episode:1305 meanR:59.0000 rate:0.1100 gloss:0.0000 dloss:9.4246 dlossR:0.0000 dlossQsigm:0.0551\n",
      "Episode:1306 meanR:58.9600 rate:0.0940 gloss:0.0000 dloss:5.8688 dlossR:0.0002 dlossQsigm:0.0855\n",
      "Episode:1307 meanR:58.8600 rate:0.0980 gloss:0.0000 dloss:3.9146 dlossR:0.0001 dlossQsigm:0.0407\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "saver = tf.train.Saver()\n",
    "rewards_list, g_loss_list, d_loss_list = [], [], []\n",
    "rates_list, d_lossR_list, d_lossQ_list = [], [], []\n",
    "d_lossRsigm_list, d_lossQsigm_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        batch = [] # every data batch\n",
    "        total_reward = 0\n",
    "        state = env.reset() # env first state\n",
    "        g_initial_state = sess.run(model.g_initial_state)\n",
    "        d_initial_state = sess.run(model.d_initial_state)\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Testing/inference\n",
    "            action_logits, g_final_state, d_final_state = sess.run(\n",
    "                fetches=[model.actions_logits, model.g_final_state, model.d_final_state], \n",
    "                feed_dict={model.states: np.reshape(state, [1, -1]),\n",
    "                           model.g_initial_state: g_initial_state,\n",
    "                           model.d_initial_state: d_initial_state})\n",
    "            action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([g_initial_state, g_final_state,\n",
    "                                  d_initial_state, d_final_state])\n",
    "            total_reward += reward\n",
    "            g_initial_state = g_final_state\n",
    "            d_initial_state = d_final_state\n",
    "            state = next_state\n",
    "            \n",
    "            # Training\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            g_initial_states = np.array([each[0] for each in rnn_states])\n",
    "            g_final_states = np.array([each[1] for each in rnn_states])\n",
    "            d_initial_states = np.array([each[2] for each in rnn_states])\n",
    "            d_final_states = np.array([each[3] for each in rnn_states])\n",
    "            nextQs_logits = sess.run(fetches = model.Qs_logits,\n",
    "                                     feed_dict = {model.states: next_states, \n",
    "                                                  model.g_initial_state: g_final_states[0].reshape([1, -1]),\n",
    "                                                  model.d_initial_state: d_final_states[0].reshape([1, -1])})\n",
    "            nextQs = nextQs_logits.reshape([-1]) * (1-dones) # exploit\n",
    "            #print(nextQs.shape, nextQs_logits.shape, dones.shape, rewards.shape)\n",
    "            targetQs = rewards + (0.99 * nextQs)\n",
    "            #print(targetQs.shape, rewards.shape, nextQs.shape)\n",
    "            g_loss, d_loss, d_lossR, d_lossQ, d_lossRsigm, d_lossQsigm, _, _ = sess.run(\n",
    "                fetches=[model.g_loss, model.d_loss, \n",
    "                         model.d_lossR, model.d_lossQ, \n",
    "                         model.d_lossR_sigm, model.d_lossQ_sigm,\n",
    "                         model.g_opt, model.d_opt], \n",
    "                feed_dict = {model.states: states, model.actions: actions,\n",
    "                             model.reward: 1.0, \n",
    "                             model.targetQs: targetQs,\n",
    "                             model.g_initial_state: g_initial_states[0].reshape([1, -1]),\n",
    "                             model.d_initial_state: d_initial_states[0].reshape([1, -1])})\n",
    "\n",
    "            if done is True:\n",
    "                break\n",
    "\n",
    "        # Episode total reward and success rate/prob\n",
    "        episode_reward.append(total_reward) # stopping criteria\n",
    "        rate = total_reward/ 500 # success is 500 points: 0-1\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'gloss:{:.4f}'.format(g_loss),\n",
    "              'dloss:{:.4f}'.format(d_loss),\n",
    "#               'dlossR:{:.4f}'.format(d_lossR),\n",
    "              'dlossQ:{:.4f}'.format(d_lossQ),\n",
    "#               'dlossRsigm:{:.4f}'.format(d_lossRsigm),\n",
    "              'dlossQsigm:{:.4f}'.format(d_lossQsigm))\n",
    "        # Ploting out\n",
    "        rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rates_list.append([ep, rate])\n",
    "        g_loss_list.append([ep, g_loss])\n",
    "        d_loss_list.append([ep, d_loss])\n",
    "        d_lossR_list.append([ep, d_lossR])\n",
    "        d_lossQ_list.append([ep, d_lossQ])\n",
    "        d_lossRsigm_list.append([ep, d_lossRsigm])\n",
    "        d_lossQsigm_list.append([ep, d_lossQsigm])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(d_lossR_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(d_lossQ_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses Q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(100):\n",
    "    #while True:\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        #for _ in range(111111111111111111):\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Print and break condition\n",
    "        print('total_reward: {}'.format(total_reward))\n",
    "        # if total_reward == 500:\n",
    "        #     break\n",
    "                \n",
    "# Closing the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info: [ 0.02803708 -0.22961454 -0.02932536  0.24674302] 0 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02344479 -0.0340863  -0.0243905  -0.05504365] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02276307  0.16137673 -0.02549138 -0.35532109] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.0259906  -0.03337368 -0.0325978  -0.07078404] 0 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02532313  0.16220008 -0.03401348 -0.37357088] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02856713  0.35778828 -0.0414849  -0.67678152] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.03572289  0.55346134 -0.05502053 -0.98223165] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.04679212  0.74927568 -0.07466516 -1.29167656] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.06177763  0.94526325 -0.10049869 -1.60677   ] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.0806829   1.14141963 -0.13263409 -1.92901684] 1 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    #labelQs = tf.placeholder(tf.float32, [None], name='labelQs')\n",
    "        \n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return actions, states, targetQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_outputs(action_size, hidden_size, states, cell, initial_state):\n",
    "#     actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "#                                             lstm_size=hidden_size, num_classes=action_size)\n",
    "#     return actions_logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "#     loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Qs_logits, \n",
    "#                                                                   labels=tf.nn.sigmoid(targetQs[1:])))\n",
    "    return actions_logits, final_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.actions, self.states, self.targetQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "#         # Output of the Model: calculating the loss and forwad pass\n",
    "#         self.actions_logits, self.final_state = model_outputs(\n",
    "#             action_size=action_size, hidden_size=hidden_size, \n",
    "#             states=self.states, cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs, \n",
    "            cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_total_reward = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state:', np.array(states).shape[1], \n",
    "#       'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32                # number of samples in the memory/ experience as mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.03167448, 0.01401935, 0.02102474, 0.04001393]),\n",
       " 0,\n",
       " array([ 0.03195487, -0.18139769,  0.02182502,  0.33925552]),\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states, rewards, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 meanReward: 19.0000 meanLoss: 1.8555 ExploreP: 0.9981\n",
      "Episode: 1 meanReward: 14.5000 meanLoss: 7.7982 ExploreP: 0.9971\n",
      "Episode: 2 meanReward: 13.0000 meanLoss: 11.7375 ExploreP: 0.9961\n",
      "Episode: 3 meanReward: 18.7500 meanLoss: 7.2698 ExploreP: 0.9926\n",
      "Episode: 4 meanReward: 19.4000 meanLoss: 5.4157 ExploreP: 0.9904\n",
      "Episode: 5 meanReward: 18.5000 meanLoss: 9.0220 ExploreP: 0.9891\n",
      "Episode: 6 meanReward: 18.2857 meanLoss: 11.4750 ExploreP: 0.9874\n",
      "Episode: 7 meanReward: 19.2500 meanLoss: 9.4785 ExploreP: 0.9849\n",
      "Episode: 8 meanReward: 18.5556 meanLoss: 9.8010 ExploreP: 0.9836\n",
      "Episode: 9 meanReward: 18.9000 meanLoss: 12.5939 ExploreP: 0.9815\n",
      "Episode: 10 meanReward: 20.2727 meanLoss: 9.7284 ExploreP: 0.9782\n",
      "Episode: 11 meanReward: 19.5833 meanLoss: 9.8080 ExploreP: 0.9770\n",
      "Episode: 12 meanReward: 20.3846 meanLoss: 7.2012 ExploreP: 0.9741\n",
      "Episode: 13 meanReward: 21.0000 meanLoss: 11.8704 ExploreP: 0.9713\n",
      "Episode: 14 meanReward: 21.2667 meanLoss: 13.9603 ExploreP: 0.9689\n",
      "Episode: 15 meanReward: 20.8750 meanLoss: 17.2782 ExploreP: 0.9675\n",
      "Episode: 16 meanReward: 21.3529 meanLoss: 10.7348 ExploreP: 0.9647\n",
      "Episode: 17 meanReward: 21.6667 meanLoss: 7.5907 ExploreP: 0.9621\n",
      "Episode: 18 meanReward: 21.3684 meanLoss: 14.2639 ExploreP: 0.9606\n",
      "Episode: 19 meanReward: 21.5000 meanLoss: 7.5093 ExploreP: 0.9583\n",
      "Episode: 20 meanReward: 21.1905 meanLoss: 20.1576 ExploreP: 0.9569\n",
      "Episode: 21 meanReward: 21.1364 meanLoss: 34.1169 ExploreP: 0.9550\n",
      "Episode: 22 meanReward: 21.1304 meanLoss: 19.5405 ExploreP: 0.9530\n",
      "Episode: 23 meanReward: 20.8750 meanLoss: 11.8032 ExploreP: 0.9516\n",
      "Episode: 24 meanReward: 21.5600 meanLoss: 8.6690 ExploreP: 0.9481\n",
      "Episode: 25 meanReward: 22.7308 meanLoss: 9.2424 ExploreP: 0.9432\n",
      "Episode: 26 meanReward: 22.8148 meanLoss: 13.7920 ExploreP: 0.9409\n",
      "Episode: 27 meanReward: 23.2857 meanLoss: 13.5488 ExploreP: 0.9375\n",
      "Episode: 28 meanReward: 23.2759 meanLoss: 10.3741 ExploreP: 0.9354\n",
      "Episode: 29 meanReward: 22.8667 meanLoss: 16.8156 ExploreP: 0.9344\n",
      "Episode: 30 meanReward: 23.4194 meanLoss: 8.2917 ExploreP: 0.9307\n",
      "Episode: 31 meanReward: 23.0625 meanLoss: 5.3542 ExploreP: 0.9296\n",
      "Episode: 32 meanReward: 23.8125 meanLoss: 5.2536 ExploreP: 0.9256\n",
      "Episode: 33 meanReward: 23.9688 meanLoss: 9.8608 ExploreP: 0.9243\n",
      "Episode: 34 meanReward: 24.5938 meanLoss: 11.7941 ExploreP: 0.9215\n",
      "Episode: 35 meanReward: 24.1250 meanLoss: 44.3304 ExploreP: 0.9196\n",
      "Episode: 36 meanReward: 24.0938 meanLoss: 32.3644 ExploreP: 0.9177\n",
      "Episode: 37 meanReward: 23.9688 meanLoss: 41.0123 ExploreP: 0.9168\n",
      "Episode: 38 meanReward: 24.0938 meanLoss: 14.3635 ExploreP: 0.9149\n",
      "Episode: 39 meanReward: 23.6250 meanLoss: 4.5226 ExploreP: 0.9139\n",
      "Episode: 40 meanReward: 24.1250 meanLoss: 5.1634 ExploreP: 0.9113\n",
      "Episode: 41 meanReward: 23.9688 meanLoss: 7.7743 ExploreP: 0.9097\n",
      "Episode: 42 meanReward: 23.3438 meanLoss: 10.6569 ExploreP: 0.9085\n",
      "Episode: 43 meanReward: 24.0312 meanLoss: 7.9648 ExploreP: 0.9054\n",
      "Episode: 44 meanReward: 23.6250 meanLoss: 9.9642 ExploreP: 0.9039\n",
      "Episode: 45 meanReward: 23.4062 meanLoss: 11.3934 ExploreP: 0.9019\n",
      "Episode: 46 meanReward: 22.9062 meanLoss: 15.8594 ExploreP: 0.9011\n",
      "Episode: 47 meanReward: 22.8438 meanLoss: 15.9910 ExploreP: 0.9000\n",
      "Episode: 48 meanReward: 22.8750 meanLoss: 19.0231 ExploreP: 0.8973\n",
      "Episode: 49 meanReward: 23.0312 meanLoss: 25.8656 ExploreP: 0.8945\n",
      "Episode: 50 meanReward: 23.9062 meanLoss: 23.2721 ExploreP: 0.8906\n",
      "Episode: 51 meanReward: 23.9688 meanLoss: 7.8333 ExploreP: 0.8883\n",
      "Episode: 52 meanReward: 25.1562 meanLoss: 14.0566 ExploreP: 0.8837\n",
      "Episode: 53 meanReward: 24.9375 meanLoss: 6.6516 ExploreP: 0.8825\n",
      "Episode: 54 meanReward: 24.9688 meanLoss: 19.6241 ExploreP: 0.8806\n",
      "Episode: 55 meanReward: 25.3125 meanLoss: 48.1997 ExploreP: 0.8784\n",
      "Episode: 56 meanReward: 25.1562 meanLoss: 16.5508 ExploreP: 0.8755\n",
      "Episode: 57 meanReward: 24.7812 meanLoss: 8.0744 ExploreP: 0.8720\n",
      "Episode: 58 meanReward: 25.4375 meanLoss: 4.4441 ExploreP: 0.8681\n",
      "Episode: 59 meanReward: 25.3438 meanLoss: 7.1127 ExploreP: 0.8653\n",
      "Episode: 60 meanReward: 25.1875 meanLoss: 84.1994 ExploreP: 0.8637\n",
      "Episode: 61 meanReward: 25.2812 meanLoss: 91.0816 ExploreP: 0.8625\n",
      "Episode: 62 meanReward: 24.4688 meanLoss: 16.0143 ExploreP: 0.8613\n",
      "Episode: 63 meanReward: 26.5000 meanLoss: 4.3057 ExploreP: 0.8548\n",
      "Episode: 64 meanReward: 25.6250 meanLoss: 9.0866 ExploreP: 0.8535\n",
      "Episode: 65 meanReward: 25.5938 meanLoss: 21.5287 ExploreP: 0.8524\n",
      "Episode: 66 meanReward: 25.7500 meanLoss: 16.8652 ExploreP: 0.8494\n",
      "Episode: 67 meanReward: 26.3750 meanLoss: 7.7234 ExploreP: 0.8460\n",
      "Episode: 68 meanReward: 26.3125 meanLoss: 29.1072 ExploreP: 0.8444\n",
      "Episode: 69 meanReward: 27.0312 meanLoss: 15.5638 ExploreP: 0.8416\n",
      "Episode: 70 meanReward: 27.6250 meanLoss: 48.2838 ExploreP: 0.8383\n",
      "Episode: 71 meanReward: 27.6875 meanLoss: 10.7596 ExploreP: 0.8372\n",
      "Episode: 72 meanReward: 27.6562 meanLoss: 29.5319 ExploreP: 0.8349\n",
      "Episode: 73 meanReward: 27.4375 meanLoss: 25.9692 ExploreP: 0.8341\n",
      "Episode: 74 meanReward: 27.8750 meanLoss: 28.5861 ExploreP: 0.8318\n",
      "Episode: 75 meanReward: 28.7812 meanLoss: 15.7488 ExploreP: 0.8266\n",
      "Episode: 76 meanReward: 29.3438 meanLoss: 10.1423 ExploreP: 0.8238\n",
      "Episode: 77 meanReward: 29.1562 meanLoss: 22.4987 ExploreP: 0.8225\n",
      "Episode: 78 meanReward: 29.2188 meanLoss: 31.2294 ExploreP: 0.8216\n",
      "Episode: 79 meanReward: 29.5938 meanLoss: 26.0192 ExploreP: 0.8196\n",
      "Episode: 80 meanReward: 29.3125 meanLoss: 28.3115 ExploreP: 0.8179\n",
      "Episode: 81 meanReward: 29.2188 meanLoss: 29.2813 ExploreP: 0.8155\n",
      "Episode: 82 meanReward: 29.8750 meanLoss: 17.8204 ExploreP: 0.8103\n",
      "Episode: 83 meanReward: 30.1562 meanLoss: 16.6692 ExploreP: 0.8075\n",
      "Episode: 84 meanReward: 29.1562 meanLoss: 16.9930 ExploreP: 0.8058\n",
      "Episode: 85 meanReward: 31.3125 meanLoss: 8.5387 ExploreP: 0.7993\n",
      "Episode: 86 meanReward: 32.6250 meanLoss: 32.7064 ExploreP: 0.7943\n",
      "Episode: 87 meanReward: 34.6562 meanLoss: 7.2745 ExploreP: 0.7872\n",
      "Episode: 88 meanReward: 34.7812 meanLoss: 12.6698 ExploreP: 0.7843\n",
      "Episode: 89 meanReward: 34.9062 meanLoss: 10.6481 ExploreP: 0.7809\n",
      "Episode: 90 meanReward: 33.9062 meanLoss: 15.5486 ExploreP: 0.7799\n",
      "Episode: 91 meanReward: 33.6250 meanLoss: 17.2844 ExploreP: 0.7780\n",
      "Episode: 92 meanReward: 33.7188 meanLoss: 22.8149 ExploreP: 0.7764\n",
      "Episode: 93 meanReward: 33.8750 meanLoss: 19.9833 ExploreP: 0.7749\n",
      "Episode: 94 meanReward: 34.3438 meanLoss: 12.3170 ExploreP: 0.7727\n",
      "Episode: 95 meanReward: 32.4688 meanLoss: 21.6375 ExploreP: 0.7714\n",
      "Episode: 96 meanReward: 32.9062 meanLoss: 17.0448 ExploreP: 0.7692\n",
      "Episode: 97 meanReward: 33.1875 meanLoss: 18.8216 ExploreP: 0.7675\n",
      "Episode: 98 meanReward: 32.8750 meanLoss: 15.7559 ExploreP: 0.7656\n",
      "Episode: 99 meanReward: 34.9375 meanLoss: 3.9299 ExploreP: 0.7576\n",
      "Episode: 100 meanReward: 35.3125 meanLoss: 33.1861 ExploreP: 0.7552\n",
      "Episode: 101 meanReward: 37.3438 meanLoss: 9.5613 ExploreP: 0.7480\n",
      "Episode: 102 meanReward: 37.3750 meanLoss: 16.7651 ExploreP: 0.7450\n",
      "Episode: 103 meanReward: 37.6875 meanLoss: 26.4745 ExploreP: 0.7433\n",
      "Episode: 104 meanReward: 37.8750 meanLoss: 34.5555 ExploreP: 0.7408\n",
      "Episode: 105 meanReward: 38.8125 meanLoss: 20.9825 ExploreP: 0.7379\n",
      "Episode: 106 meanReward: 41.6562 meanLoss: 11.7607 ExploreP: 0.7292\n",
      "Episode: 107 meanReward: 40.4688 meanLoss: 28.5881 ExploreP: 0.7275\n",
      "Episode: 108 meanReward: 40.0625 meanLoss: 29.6452 ExploreP: 0.7259\n",
      "Episode: 109 meanReward: 40.1875 meanLoss: 35.2352 ExploreP: 0.7244\n",
      "Episode: 110 meanReward: 40.4062 meanLoss: 50.3685 ExploreP: 0.7232\n",
      "Episode: 111 meanReward: 40.5312 meanLoss: 26.5036 ExploreP: 0.7211\n",
      "Episode: 112 meanReward: 40.7812 meanLoss: 58.5253 ExploreP: 0.7190\n",
      "Episode: 113 meanReward: 40.6250 meanLoss: 66.7309 ExploreP: 0.7173\n",
      "Episode: 114 meanReward: 39.8438 meanLoss: 55.8513 ExploreP: 0.7145\n",
      "Episode: 115 meanReward: 39.2812 meanLoss: 46.0295 ExploreP: 0.7133\n",
      "Episode: 116 meanReward: 39.2500 meanLoss: 66.2344 ExploreP: 0.7119\n",
      "Episode: 117 meanReward: 37.6562 meanLoss: 56.3316 ExploreP: 0.7097\n",
      "Episode: 118 meanReward: 36.2188 meanLoss: 36.1714 ExploreP: 0.7085\n",
      "Episode: 119 meanReward: 34.4688 meanLoss: 23.7393 ExploreP: 0.7060\n",
      "Episode: 120 meanReward: 34.1875 meanLoss: 12.8253 ExploreP: 0.7041\n",
      "Episode: 121 meanReward: 36.1562 meanLoss: 10.7669 ExploreP: 0.6967\n",
      "Episode: 122 meanReward: 36.3438 meanLoss: 35.2643 ExploreP: 0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 123 meanReward: 36.2188 meanLoss: 44.1763 ExploreP: 0.6940\n",
      "Episode: 124 meanReward: 36.6562 meanLoss: 30.0719 ExploreP: 0.6916\n",
      "Episode: 125 meanReward: 37.3750 meanLoss: 29.7347 ExploreP: 0.6887\n",
      "Episode: 126 meanReward: 37.5938 meanLoss: 8.4834 ExploreP: 0.6863\n",
      "Episode: 127 meanReward: 37.7812 meanLoss: 20.2507 ExploreP: 0.6847\n",
      "Episode: 128 meanReward: 37.4375 meanLoss: 32.5105 ExploreP: 0.6835\n",
      "Episode: 129 meanReward: 38.3125 meanLoss: 18.2685 ExploreP: 0.6801\n",
      "Episode: 130 meanReward: 37.8750 meanLoss: 22.4417 ExploreP: 0.6793\n",
      "Episode: 131 meanReward: 35.0938 meanLoss: 42.0542 ExploreP: 0.6781\n",
      "Episode: 132 meanReward: 36.5312 meanLoss: 16.3450 ExploreP: 0.6730\n",
      "Episode: 133 meanReward: 33.9375 meanLoss: 20.9813 ExploreP: 0.6720\n",
      "Episode: 134 meanReward: 33.0000 meanLoss: 19.8883 ExploreP: 0.6713\n",
      "Episode: 135 meanReward: 38.3125 meanLoss: 7.9742 ExploreP: 0.6587\n",
      "Episode: 136 meanReward: 37.6562 meanLoss: 87.7673 ExploreP: 0.6578\n",
      "Episode: 137 meanReward: 37.0625 meanLoss: 77.3160 ExploreP: 0.6565\n",
      "Episode: 138 meanReward: 35.0312 meanLoss: 27.5345 ExploreP: 0.6530\n",
      "Episode: 139 meanReward: 34.8125 meanLoss: 24.6662 ExploreP: 0.6518\n",
      "Episode: 140 meanReward: 35.0625 meanLoss: 47.9932 ExploreP: 0.6499\n",
      "Episode: 141 meanReward: 35.0000 meanLoss: 123.9969 ExploreP: 0.6487\n",
      "Episode: 142 meanReward: 37.0938 meanLoss: 29.4527 ExploreP: 0.6433\n",
      "Episode: 143 meanReward: 37.9375 meanLoss: 97.2083 ExploreP: 0.6398\n",
      "Episode: 144 meanReward: 37.5938 meanLoss: 31.4633 ExploreP: 0.6387\n",
      "Episode: 145 meanReward: 39.5938 meanLoss: 22.3080 ExploreP: 0.6332\n",
      "Episode: 146 meanReward: 39.5938 meanLoss: 324.8968 ExploreP: 0.6307\n",
      "Episode: 147 meanReward: 39.7188 meanLoss: 149.1318 ExploreP: 0.6294\n",
      "Episode: 148 meanReward: 39.8750 meanLoss: 81.6485 ExploreP: 0.6278\n",
      "Episode: 149 meanReward: 41.3125 meanLoss: 18.4204 ExploreP: 0.6231\n",
      "Episode: 150 meanReward: 41.8125 meanLoss: 22.2456 ExploreP: 0.6210\n",
      "Episode: 151 meanReward: 41.1875 meanLoss: 55.9441 ExploreP: 0.6201\n",
      "Episode: 152 meanReward: 40.6562 meanLoss: 101.8513 ExploreP: 0.6194\n",
      "Episode: 153 meanReward: 39.2188 meanLoss: 50.8967 ExploreP: 0.6157\n",
      "Episode: 154 meanReward: 39.8125 meanLoss: 52.0389 ExploreP: 0.6134\n",
      "Episode: 155 meanReward: 39.7188 meanLoss: 229.2308 ExploreP: 0.6123\n",
      "Episode: 156 meanReward: 40.9062 meanLoss: 66.0127 ExploreP: 0.6079\n",
      "Episode: 157 meanReward: 40.0625 meanLoss: 52.5215 ExploreP: 0.6071\n",
      "Episode: 158 meanReward: 40.5312 meanLoss: 13.9424 ExploreP: 0.6040\n",
      "Episode: 159 meanReward: 41.4688 meanLoss: 43.4590 ExploreP: 0.6009\n",
      "Episode: 160 meanReward: 41.2188 meanLoss: 279.4912 ExploreP: 0.6003\n",
      "Episode: 161 meanReward: 40.6562 meanLoss: 90.0123 ExploreP: 0.5983\n",
      "Episode: 162 meanReward: 42.3438 meanLoss: 10.2938 ExploreP: 0.5945\n",
      "Episode: 163 meanReward: 42.6250 meanLoss: 19.2132 ExploreP: 0.5930\n",
      "Episode: 164 meanReward: 40.7812 meanLoss: 21.2807 ExploreP: 0.5919\n",
      "Episode: 165 meanReward: 40.6875 meanLoss: 31.6780 ExploreP: 0.5912\n",
      "Episode: 166 meanReward: 41.9062 meanLoss: 47.3128 ExploreP: 0.5883\n",
      "Episode: 167 meanReward: 36.9062 meanLoss: 26.9938 ExploreP: 0.5864\n",
      "Episode: 168 meanReward: 37.0625 meanLoss: 44.8406 ExploreP: 0.5854\n",
      "Episode: 169 meanReward: 39.9688 meanLoss: 18.4718 ExploreP: 0.5788\n",
      "Episode: 170 meanReward: 40.8750 meanLoss: 157.6893 ExploreP: 0.5741\n",
      "Episode: 171 meanReward: 41.8438 meanLoss: 26.1591 ExploreP: 0.5714\n",
      "Episode: 172 meanReward: 41.4062 meanLoss: 54.1715 ExploreP: 0.5705\n",
      "Episode: 173 meanReward: 43.9688 meanLoss: 24.3391 ExploreP: 0.5649\n",
      "Episode: 174 meanReward: 42.1562 meanLoss: 223.8487 ExploreP: 0.5634\n",
      "Episode: 175 meanReward: 41.2188 meanLoss: 89.2424 ExploreP: 0.5620\n",
      "Episode: 176 meanReward: 41.1875 meanLoss: 74.9088 ExploreP: 0.5610\n",
      "Episode: 177 meanReward: 40.0625 meanLoss: 31.0688 ExploreP: 0.5582\n",
      "Episode: 178 meanReward: 39.5625 meanLoss: 80.2781 ExploreP: 0.5569\n",
      "Episode: 179 meanReward: 41.2188 meanLoss: 37.0139 ExploreP: 0.5528\n",
      "Episode: 180 meanReward: 42.3750 meanLoss: 37.5419 ExploreP: 0.5495\n",
      "Episode: 181 meanReward: 41.3438 meanLoss: 33.7767 ExploreP: 0.5471\n",
      "Episode: 182 meanReward: 40.8750 meanLoss: 34.5708 ExploreP: 0.5461\n",
      "Episode: 183 meanReward: 40.8750 meanLoss: 264.5787 ExploreP: 0.5453\n",
      "Episode: 184 meanReward: 41.0938 meanLoss: 180.5320 ExploreP: 0.5443\n",
      "Episode: 185 meanReward: 40.2188 meanLoss: 82.1422 ExploreP: 0.5426\n",
      "Episode: 186 meanReward: 39.3125 meanLoss: 99.8285 ExploreP: 0.5420\n",
      "Episode: 187 meanReward: 40.3750 meanLoss: 62.9519 ExploreP: 0.5393\n",
      "Episode: 188 meanReward: 38.7812 meanLoss: 359.4457 ExploreP: 0.5382\n",
      "Episode: 189 meanReward: 38.9688 meanLoss: 169.8988 ExploreP: 0.5371\n",
      "Episode: 190 meanReward: 39.5312 meanLoss: 22.6613 ExploreP: 0.5334\n",
      "Episode: 191 meanReward: 38.6562 meanLoss: 12.4911 ExploreP: 0.5321\n",
      "Episode: 192 meanReward: 42.5938 meanLoss: 20.9632 ExploreP: 0.5251\n",
      "Episode: 193 meanReward: 45.3438 meanLoss: 45.7999 ExploreP: 0.5189\n",
      "Episode: 194 meanReward: 44.3125 meanLoss: 122.9969 ExploreP: 0.5173\n",
      "Episode: 195 meanReward: 44.5625 meanLoss: 28.3675 ExploreP: 0.5155\n",
      "Episode: 196 meanReward: 44.5312 meanLoss: 90.9787 ExploreP: 0.5146\n",
      "Episode: 197 meanReward: 45.1562 meanLoss: 185.1976 ExploreP: 0.5130\n",
      "Episode: 198 meanReward: 44.6875 meanLoss: 42.7183 ExploreP: 0.5112\n",
      "Episode: 199 meanReward: 45.9375 meanLoss: 31.7150 ExploreP: 0.5076\n",
      "Episode: 200 meanReward: 47.0000 meanLoss: 199.6785 ExploreP: 0.5050\n",
      "Episode: 201 meanReward: 46.4688 meanLoss: 44.6983 ExploreP: 0.5002\n",
      "Episode: 202 meanReward: 44.6250 meanLoss: 473.2101 ExploreP: 0.4991\n",
      "Episode: 203 meanReward: 43.6562 meanLoss: 532.9238 ExploreP: 0.4982\n",
      "Episode: 204 meanReward: 43.8125 meanLoss: 534.5204 ExploreP: 0.4972\n",
      "Episode: 205 meanReward: 41.0938 meanLoss: 403.4536 ExploreP: 0.4965\n",
      "Episode: 206 meanReward: 49.5625 meanLoss: 21.5175 ExploreP: 0.4822\n",
      "Episode: 207 meanReward: 49.0625 meanLoss: 406.5055 ExploreP: 0.4818\n",
      "Episode: 208 meanReward: 52.6562 meanLoss: 113.8967 ExploreP: 0.4756\n",
      "Episode: 209 meanReward: 52.4375 meanLoss: 29.0369 ExploreP: 0.4735\n",
      "Episode: 210 meanReward: 54.7812 meanLoss: 85.4350 ExploreP: 0.4689\n",
      "Episode: 211 meanReward: 56.2812 meanLoss: 84.7867 ExploreP: 0.4634\n",
      "Episode: 212 meanReward: 55.2500 meanLoss: 311.1227 ExploreP: 0.4621\n",
      "Episode: 213 meanReward: 59.5312 meanLoss: 26.7991 ExploreP: 0.4539\n",
      "Episode: 214 meanReward: 63.0625 meanLoss: 45.8141 ExploreP: 0.4481\n",
      "Episode: 215 meanReward: 63.4375 meanLoss: 42.8749 ExploreP: 0.4469\n",
      "Episode: 216 meanReward: 67.9375 meanLoss: 20.9639 ExploreP: 0.4399\n",
      "Episode: 217 meanReward: 67.7500 meanLoss: 64.5866 ExploreP: 0.4388\n",
      "Episode: 218 meanReward: 68.1875 meanLoss: 133.8896 ExploreP: 0.4377\n",
      "Episode: 219 meanReward: 72.6875 meanLoss: 8.9177 ExploreP: 0.4295\n",
      "Episode: 220 meanReward: 73.3750 meanLoss: 185.9654 ExploreP: 0.4276\n",
      "Episode: 221 meanReward: 78.4062 meanLoss: 157.8504 ExploreP: 0.4201\n",
      "Episode: 222 meanReward: 80.5000 meanLoss: 413.2466 ExploreP: 0.4146\n",
      "Episode: 223 meanReward: 81.1875 meanLoss: 161.3173 ExploreP: 0.4127\n",
      "Episode: 224 meanReward: 77.6562 meanLoss: 22.7874 ExploreP: 0.4117\n",
      "Episode: 225 meanReward: 76.3125 meanLoss: 141.4816 ExploreP: 0.4086\n",
      "Episode: 226 meanReward: 80.6250 meanLoss: 403.2274 ExploreP: 0.4019\n",
      "Episode: 227 meanReward: 83.0312 meanLoss: 442.4873 ExploreP: 0.3975\n",
      "Episode: 228 meanReward: 84.1250 meanLoss: 558.5098 ExploreP: 0.3955\n",
      "Episode: 229 meanReward: 83.4688 meanLoss: 241.4137 ExploreP: 0.3951\n",
      "Episode: 230 meanReward: 82.7188 meanLoss: 399.7965 ExploreP: 0.3947\n",
      "Episode: 231 meanReward: 80.7500 meanLoss: 592.5994 ExploreP: 0.3943\n",
      "Episode: 232 meanReward: 79.4688 meanLoss: 668.4283 ExploreP: 0.3939\n",
      "Episode: 233 meanReward: 76.7500 meanLoss: 669.3016 ExploreP: 0.3935\n",
      "Episode: 234 meanReward: 76.4688 meanLoss: 610.3356 ExploreP: 0.3929\n",
      "Episode: 235 meanReward: 76.1875 meanLoss: 725.2821 ExploreP: 0.3926\n",
      "Episode: 236 meanReward: 75.8125 meanLoss: 900.1379 ExploreP: 0.3922\n",
      "Episode: 237 meanReward: 75.9375 meanLoss: 1091.9515 ExploreP: 0.3916\n",
      "Episode: 238 meanReward: 67.0000 meanLoss: 1143.0785 ExploreP: 0.3911\n",
      "Episode: 239 meanReward: 67.2500 meanLoss: 1140.4746 ExploreP: 0.3904\n",
      "Episode: 240 meanReward: 63.5625 meanLoss: 1060.9053 ExploreP: 0.3899\n",
      "Episode: 241 meanReward: 62.5625 meanLoss: 1185.6405 ExploreP: 0.3894\n",
      "Episode: 242 meanReward: 59.7500 meanLoss: 1375.1522 ExploreP: 0.3891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 243 meanReward: 56.4375 meanLoss: 1528.9994 ExploreP: 0.3885\n",
      "Episode: 244 meanReward: 55.8438 meanLoss: 1521.2595 ExploreP: 0.3881\n",
      "Episode: 245 meanReward: 50.5000 meanLoss: 1475.2307 ExploreP: 0.3877\n",
      "Episode: 246 meanReward: 46.8125 meanLoss: 1482.5260 ExploreP: 0.3872\n",
      "Episode: 247 meanReward: 46.2812 meanLoss: 1465.4651 ExploreP: 0.3868\n",
      "Episode: 248 meanReward: 41.5625 meanLoss: 1482.1561 ExploreP: 0.3864\n",
      "Episode: 249 meanReward: 41.0938 meanLoss: 1405.7157 ExploreP: 0.3859\n",
      "Episode: 250 meanReward: 40.6875 meanLoss: 1368.0604 ExploreP: 0.3855\n",
      "Episode: 251 meanReward: 34.8750 meanLoss: 1355.4873 ExploreP: 0.3852\n",
      "Episode: 252 meanReward: 33.8125 meanLoss: 1407.3969 ExploreP: 0.3848\n",
      "Episode: 253 meanReward: 28.5625 meanLoss: 1408.3229 ExploreP: 0.3843\n",
      "Episode: 254 meanReward: 24.6562 meanLoss: 1398.8888 ExploreP: 0.3839\n",
      "Episode: 255 meanReward: 23.7500 meanLoss: 1356.2793 ExploreP: 0.3832\n",
      "Episode: 256 meanReward: 23.3438 meanLoss: 1307.8210 ExploreP: 0.3828\n",
      "Episode: 257 meanReward: 21.2188 meanLoss: 1274.4108 ExploreP: 0.3825\n",
      "Episode: 258 meanReward: 16.9688 meanLoss: 1188.6632 ExploreP: 0.3812\n",
      "Episode: 259 meanReward: 13.7500 meanLoss: 1222.9546 ExploreP: 0.3809\n",
      "Episode: 260 meanReward: 12.6250 meanLoss: 1387.0533 ExploreP: 0.3803\n",
      "Episode: 261 meanReward: 12.8438 meanLoss: 1461.5612 ExploreP: 0.3796\n",
      "Episode: 262 meanReward: 12.9062 meanLoss: 1466.0706 ExploreP: 0.3791\n",
      "Episode: 263 meanReward: 13.0000 meanLoss: 1535.0747 ExploreP: 0.3786\n",
      "Episode: 264 meanReward: 13.0625 meanLoss: 1598.8394 ExploreP: 0.3782\n",
      "Episode: 265 meanReward: 13.0625 meanLoss: 1605.2039 ExploreP: 0.3778\n",
      "Episode: 266 meanReward: 13.0938 meanLoss: 1530.8011 ExploreP: 0.3772\n",
      "Episode: 267 meanReward: 13.4375 meanLoss: 1458.8604 ExploreP: 0.3765\n",
      "Episode: 268 meanReward: 13.4688 meanLoss: 1497.2677 ExploreP: 0.3761\n",
      "Episode: 269 meanReward: 13.5938 meanLoss: 1436.6862 ExploreP: 0.3753\n",
      "Episode: 270 meanReward: 13.5625 meanLoss: 1411.5819 ExploreP: 0.3749\n",
      "Episode: 271 meanReward: 13.2812 meanLoss: 1471.9661 ExploreP: 0.3746\n",
      "Episode: 272 meanReward: 13.2188 meanLoss: 1360.0757 ExploreP: 0.3742\n",
      "Episode: 273 meanReward: 13.1875 meanLoss: 1296.0533 ExploreP: 0.3737\n",
      "Episode: 274 meanReward: 13.2812 meanLoss: 1243.5516 ExploreP: 0.3733\n",
      "Episode: 275 meanReward: 13.2188 meanLoss: 1264.9219 ExploreP: 0.3728\n",
      "Episode: 276 meanReward: 13.5312 meanLoss: 1260.9745 ExploreP: 0.3721\n",
      "Episode: 277 meanReward: 13.7812 meanLoss: 1266.0935 ExploreP: 0.3714\n",
      "Episode: 278 meanReward: 13.8125 meanLoss: 1129.3724 ExploreP: 0.3709\n",
      "Episode: 279 meanReward: 13.7812 meanLoss: 1242.2594 ExploreP: 0.3705\n",
      "Episode: 280 meanReward: 13.8125 meanLoss: 1568.9854 ExploreP: 0.3701\n",
      "Episode: 281 meanReward: 13.8125 meanLoss: 2036.2733 ExploreP: 0.3697\n",
      "Episode: 282 meanReward: 13.9688 meanLoss: 2067.0327 ExploreP: 0.3691\n",
      "Episode: 283 meanReward: 14.0312 meanLoss: 2062.8435 ExploreP: 0.3687\n",
      "Episode: 284 meanReward: 14.0312 meanLoss: 2088.6685 ExploreP: 0.3683\n",
      "Episode: 285 meanReward: 14.0000 meanLoss: 2166.4834 ExploreP: 0.3679\n",
      "Episode: 286 meanReward: 14.4688 meanLoss: 2058.5315 ExploreP: 0.3670\n",
      "Episode: 287 meanReward: 15.2500 meanLoss: 2018.9709 ExploreP: 0.3654\n",
      "Episode: 288 meanReward: 15.2500 meanLoss: 2080.9438 ExploreP: 0.3651\n",
      "Episode: 289 meanReward: 17.8125 meanLoss: 669.9951 ExploreP: 0.3618\n",
      "Episode: 290 meanReward: 17.1875 meanLoss: 681.7584 ExploreP: 0.3613\n",
      "Episode: 291 meanReward: 17.2812 meanLoss: 539.8002 ExploreP: 0.3609\n",
      "Episode: 292 meanReward: 17.0938 meanLoss: 380.3273 ExploreP: 0.3606\n",
      "Episode: 293 meanReward: 17.4375 meanLoss: 245.4908 ExploreP: 0.3595\n",
      "Episode: 294 meanReward: 20.5938 meanLoss: 52.8645 ExploreP: 0.3556\n",
      "Episode: 295 meanReward: 24.0625 meanLoss: 73.3614 ExploreP: 0.3513\n",
      "Episode: 296 meanReward: 28.0938 meanLoss: 62.1990 ExploreP: 0.3465\n",
      "Episode: 297 meanReward: 35.6250 meanLoss: 21.4638 ExploreP: 0.3382\n",
      "Episode: 298 meanReward: 45.0938 meanLoss: 31.0913 ExploreP: 0.3279\n",
      "Episode: 299 meanReward: 60.0938 meanLoss: 10.6315 ExploreP: 0.3124\n",
      "Episode: 300 meanReward: 74.1250 meanLoss: 12.9174 ExploreP: 0.2988\n",
      "Episode: 301 meanReward: 76.5625 meanLoss: 107.3897 ExploreP: 0.2959\n",
      "Episode: 302 meanReward: 76.5625 meanLoss: 241.1614 ExploreP: 0.2956\n",
      "Episode: 303 meanReward: 76.6875 meanLoss: 305.7688 ExploreP: 0.2953\n",
      "Episode: 304 meanReward: 76.6562 meanLoss: 215.1841 ExploreP: 0.2949\n",
      "Episode: 305 meanReward: 76.8125 meanLoss: 244.0030 ExploreP: 0.2945\n",
      "Episode: 306 meanReward: 80.3438 meanLoss: 43.7634 ExploreP: 0.2909\n",
      "Episode: 307 meanReward: 83.7188 meanLoss: 12.6287 ExploreP: 0.2875\n",
      "Episode: 308 meanReward: 83.8438 meanLoss: 57.1735 ExploreP: 0.2869\n",
      "Episode: 309 meanReward: 83.7812 meanLoss: 269.4912 ExploreP: 0.2864\n",
      "Episode: 310 meanReward: 83.8125 meanLoss: 431.5717 ExploreP: 0.2860\n",
      "Episode: 311 meanReward: 83.9375 meanLoss: 254.8009 ExploreP: 0.2856\n",
      "Episode: 312 meanReward: 84.4062 meanLoss: 89.5068 ExploreP: 0.2849\n",
      "Episode: 313 meanReward: 91.3125 meanLoss: 8.1387 ExploreP: 0.2785\n",
      "Episode: 314 meanReward: 99.0000 meanLoss: 17.8290 ExploreP: 0.2716\n",
      "Episode: 315 meanReward: 104.6250 meanLoss: 19.1386 ExploreP: 0.2666\n",
      "Episode: 316 meanReward: 112.7188 meanLoss: 14.7313 ExploreP: 0.2598\n",
      "Episode: 317 meanReward: 126.1562 meanLoss: 10.4161 ExploreP: 0.2490\n",
      "Episode: 318 meanReward: 129.0000 meanLoss: 69.0881 ExploreP: 0.2462\n",
      "Episode: 319 meanReward: 131.0625 meanLoss: 102.3576 ExploreP: 0.2437\n",
      "Episode: 320 meanReward: 137.6562 meanLoss: 37.5534 ExploreP: 0.2386\n",
      "Episode: 321 meanReward: 135.5000 meanLoss: 327.7982 ExploreP: 0.2380\n",
      "Episode: 322 meanReward: 143.2500 meanLoss: 29.2804 ExploreP: 0.2321\n",
      "Episode: 323 meanReward: 145.6562 meanLoss: 42.0132 ExploreP: 0.2302\n",
      "Episode: 324 meanReward: 147.0312 meanLoss: 112.2785 ExploreP: 0.2290\n",
      "Episode: 325 meanReward: 146.9062 meanLoss: 60.6619 ExploreP: 0.2284\n",
      "Episode: 326 meanReward: 144.9062 meanLoss: 159.3951 ExploreP: 0.2273\n",
      "Episode: 327 meanReward: 148.1875 meanLoss: 8.2257 ExploreP: 0.2224\n",
      "Episode: 328 meanReward: 147.1562 meanLoss: 26.3424 ExploreP: 0.2201\n",
      "Episode: 329 meanReward: 145.8438 meanLoss: 9.1684 ExploreP: 0.2158\n",
      "Episode: 330 meanReward: 144.5312 meanLoss: 14.2928 ExploreP: 0.2102\n",
      "Episode: 331 meanReward: 140.8750 meanLoss: 11.0937 ExploreP: 0.2026\n",
      "Episode: 332 meanReward: 131.0000 meanLoss: 39.7819 ExploreP: 0.1999\n",
      "Episode: 333 meanReward: 132.8125 meanLoss: 30.3356 ExploreP: 0.1969\n",
      "Episode: 334 meanReward: 135.3125 meanLoss: 84.7542 ExploreP: 0.1952\n",
      "Episode: 335 meanReward: 141.8125 meanLoss: 10.2800 ExploreP: 0.1912\n",
      "Episode: 336 meanReward: 157.0938 meanLoss: 4.3698 ExploreP: 0.1824\n",
      "Episode: 337 meanReward: 166.7188 meanLoss: 29.9253 ExploreP: 0.1769\n",
      "Episode: 338 meanReward: 170.2812 meanLoss: 32.9688 ExploreP: 0.1729\n",
      "Episode: 339 meanReward: 172.1562 meanLoss: 28.4836 ExploreP: 0.1700\n",
      "Episode: 340 meanReward: 176.2188 meanLoss: 37.0113 ExploreP: 0.1675\n",
      "Episode: 341 meanReward: 181.7812 meanLoss: 32.9142 ExploreP: 0.1645\n",
      "Episode: 342 meanReward: 186.5625 meanLoss: 37.3855 ExploreP: 0.1619\n",
      "Episode: 343 meanReward: 201.7812 meanLoss: 5.6533 ExploreP: 0.1545\n",
      "Episode: 344 meanReward: 204.8750 meanLoss: 70.1346 ExploreP: 0.1527\n",
      "Episode: 345 meanReward: 199.0625 meanLoss: 80.5710 ExploreP: 0.1520\n",
      "Episode: 346 meanReward: 192.0000 meanLoss: 200.5753 ExploreP: 0.1515\n",
      "Episode: 347 meanReward: 186.4375 meanLoss: 220.9424 ExploreP: 0.1513\n",
      "Episode: 348 meanReward: 178.3438 meanLoss: 386.3871 ExploreP: 0.1512\n",
      "Episode: 349 meanReward: 164.7812 meanLoss: 331.7462 ExploreP: 0.1511\n",
      "Episode: 350 meanReward: 161.4062 meanLoss: 159.5136 ExploreP: 0.1509\n",
      "Episode: 351 meanReward: 159.3750 meanLoss: 56.0848 ExploreP: 0.1503\n",
      "Episode: 352 meanReward: 155.2188 meanLoss: 62.6010 ExploreP: 0.1491\n",
      "Episode: 353 meanReward: 160.0000 meanLoss: 10.2273 ExploreP: 0.1467\n",
      "Episode: 354 meanReward: 158.0000 meanLoss: 11.3761 ExploreP: 0.1440\n",
      "Episode: 355 meanReward: 170.8438 meanLoss: 6.4191 ExploreP: 0.1374\n",
      "Episode: 356 meanReward: 182.3750 meanLoss: 18.2637 ExploreP: 0.1322\n",
      "Episode: 357 meanReward: 186.8438 meanLoss: 45.0056 ExploreP: 0.1301\n",
      "Episode: 358 meanReward: 200.9062 meanLoss: 12.1237 ExploreP: 0.1243\n",
      "Episode: 359 meanReward: 196.9062 meanLoss: 75.1324 ExploreP: 0.1231\n",
      "Episode: 360 meanReward: 197.5000 meanLoss: 13.5213 ExploreP: 0.1217\n",
      "Episode: 361 meanReward: 201.9062 meanLoss: 8.2755 ExploreP: 0.1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 362 meanReward: 208.8750 meanLoss: 1.4039 ExploreP: 0.1126\n",
      "Episode: 363 meanReward: 212.5312 meanLoss: 17.3541 ExploreP: 0.1076\n",
      "Episode: 364 meanReward: 208.4688 meanLoss: 276.4479 ExploreP: 0.1075\n",
      "Episode: 365 meanReward: 204.0312 meanLoss: 444.3580 ExploreP: 0.1073\n",
      "Episode: 366 meanReward: 209.9375 meanLoss: 17.6224 ExploreP: 0.1046\n",
      "Episode: 367 meanReward: 218.6562 meanLoss: 13.1574 ExploreP: 0.1000\n",
      "Episode: 368 meanReward: 203.6250 meanLoss: 247.1835 ExploreP: 0.0998\n",
      "Episode: 369 meanReward: 206.2188 meanLoss: 10.8975 ExploreP: 0.0962\n",
      "Episode: 370 meanReward: 204.6875 meanLoss: 32.8970 ExploreP: 0.0946\n",
      "Episode: 371 meanReward: 214.6250 meanLoss: 3.2934 ExploreP: 0.0905\n",
      "Episode: 372 meanReward: 215.5312 meanLoss: 45.7641 ExploreP: 0.0890\n",
      "Episode: 373 meanReward: 214.5312 meanLoss: 46.8563 ExploreP: 0.0878\n",
      "Episode: 374 meanReward: 215.5312 meanLoss: 50.6885 ExploreP: 0.0862\n",
      "Episode: 375 meanReward: 207.0625 meanLoss: 154.1705 ExploreP: 0.0845\n",
      "Episode: 376 meanReward: 216.1250 meanLoss: 38.5206 ExploreP: 0.0815\n",
      "Episode: 377 meanReward: 230.2812 meanLoss: 7.5582 ExploreP: 0.0780\n",
      "Episode: 378 meanReward: 232.8438 meanLoss: 34.6008 ExploreP: 0.0772\n",
      "Episode: 379 meanReward: 236.4688 meanLoss: 38.3715 ExploreP: 0.0763\n",
      "Episode: 380 meanReward: 240.4375 meanLoss: 43.5880 ExploreP: 0.0754\n",
      "Episode: 381 meanReward: 244.3750 meanLoss: 41.6684 ExploreP: 0.0745\n",
      "Episode: 382 meanReward: 248.8750 meanLoss: 24.3868 ExploreP: 0.0736\n",
      "Episode: 383 meanReward: 252.9062 meanLoss: 24.7703 ExploreP: 0.0725\n",
      "Episode: 384 meanReward: 265.7812 meanLoss: 8.8788 ExploreP: 0.0694\n",
      "Episode: 385 meanReward: 265.1250 meanLoss: 30.4703 ExploreP: 0.0685\n",
      "Episode: 386 meanReward: 264.0625 meanLoss: 154.0327 ExploreP: 0.0676\n",
      "Episode: 387 meanReward: 248.6875 meanLoss: 605.3443 ExploreP: 0.0675\n",
      "Episode: 388 meanReward: 235.7500 meanLoss: 528.5632 ExploreP: 0.0675\n",
      "Episode: 389 meanReward: 246.1250 meanLoss: 14.8334 ExploreP: 0.0647\n",
      "Episode: 390 meanReward: 246.1250 meanLoss: 6.8940 ExploreP: 0.0620\n",
      "Episode: 391 meanReward: 247.4688 meanLoss: 53.9737 ExploreP: 0.0612\n",
      "Episode: 392 meanReward: 259.0938 meanLoss: 9.8475 ExploreP: 0.0587\n",
      "Episode: 393 meanReward: 263.7812 meanLoss: 15.8907 ExploreP: 0.0564\n",
      "Episode: 394 meanReward: 263.7812 meanLoss: 10.9371 ExploreP: 0.0541\n",
      "Episode: 395 meanReward: 250.6562 meanLoss: 73.4271 ExploreP: 0.0538\n",
      "Episode: 396 meanReward: 250.8125 meanLoss: 276.5094 ExploreP: 0.0537\n",
      "Episode: 397 meanReward: 250.6562 meanLoss: 499.7895 ExploreP: 0.0536\n",
      "Episode: 398 meanReward: 242.2500 meanLoss: 357.0692 ExploreP: 0.0536\n",
      "Episode: 399 meanReward: 228.4062 meanLoss: 90.1695 ExploreP: 0.0533\n",
      "Episode: 400 meanReward: 232.7188 meanLoss: 53.5715 ExploreP: 0.0527\n",
      "Episode: 401 meanReward: 235.5938 meanLoss: 121.5213 ExploreP: 0.0506\n",
      "Episode: 402 meanReward: 245.2812 meanLoss: 10.9681 ExploreP: 0.0486\n",
      "Episode: 403 meanReward: 245.2812 meanLoss: 15.9103 ExploreP: 0.0467\n",
      "Episode: 404 meanReward: 253.5625 meanLoss: 20.0879 ExploreP: 0.0451\n",
      "Episode: 405 meanReward: 258.6875 meanLoss: 20.1986 ExploreP: 0.0440\n",
      "Episode: 406 meanReward: 261.0938 meanLoss: 20.2932 ExploreP: 0.0431\n",
      "Episode: 407 meanReward: 269.5625 meanLoss: 12.0116 ExploreP: 0.0414\n",
      "Episode: 408 meanReward: 272.1875 meanLoss: 16.1983 ExploreP: 0.0399\n",
      "Episode: 409 meanReward: 272.1875 meanLoss: 16.9799 ExploreP: 0.0384\n",
      "Episode: 410 meanReward: 284.1250 meanLoss: 17.0718 ExploreP: 0.0371\n",
      "Episode: 411 meanReward: 293.9688 meanLoss: 19.4839 ExploreP: 0.0359\n",
      "Episode: 412 meanReward: 301.7188 meanLoss: 17.1234 ExploreP: 0.0349\n",
      "Episode: 413 meanReward: 304.9688 meanLoss: 22.6743 ExploreP: 0.0343\n",
      "Episode: 414 meanReward: 315.8125 meanLoss: 9.4161 ExploreP: 0.0331\n",
      "Episode: 415 meanReward: 326.0312 meanLoss: 17.2388 ExploreP: 0.0320\n",
      "Episode: 416 meanReward: 315.5625 meanLoss: 53.2858 ExploreP: 0.0316\n",
      "Episode: 417 meanReward: 315.7188 meanLoss: 374.1765 ExploreP: 0.0313\n",
      "Episode: 418 meanReward: 310.8750 meanLoss: 1481.9462 ExploreP: 0.0313\n",
      "Episode: 419 meanReward: 317.5938 meanLoss: 204.4522 ExploreP: 0.0308\n",
      "Episode: 420 meanReward: 332.9375 meanLoss: 40.3155 ExploreP: 0.0298\n",
      "Episode: 421 meanReward: 332.9375 meanLoss: 60.5595 ExploreP: 0.0288\n",
      "Episode: 422 meanReward: 325.4688 meanLoss: 31.5864 ExploreP: 0.0283\n",
      "Episode: 423 meanReward: 328.6562 meanLoss: 22.0077 ExploreP: 0.0279\n",
      "Episode: 424 meanReward: 323.5000 meanLoss: 12.6136 ExploreP: 0.0273\n",
      "Episode: 425 meanReward: 311.8750 meanLoss: 23.2501 ExploreP: 0.0271\n",
      "Episode: 426 meanReward: 299.3125 meanLoss: 24.2325 ExploreP: 0.0269\n",
      "Episode: 427 meanReward: 302.3125 meanLoss: 12.5150 ExploreP: 0.0266\n",
      "Episode: 428 meanReward: 305.0000 meanLoss: 31.1562 ExploreP: 0.0265\n",
      "Episode: 429 meanReward: 308.1875 meanLoss: 20.7573 ExploreP: 0.0263\n",
      "Episode: 430 meanReward: 308.6875 meanLoss: 58.7401 ExploreP: 0.0262\n",
      "Episode: 431 meanReward: 307.8438 meanLoss: 139.3977 ExploreP: 0.0262\n",
      "Episode: 432 meanReward: 306.6875 meanLoss: 27.8924 ExploreP: 0.0260\n",
      "Episode: 433 meanReward: 306.6875 meanLoss: 2.5685 ExploreP: 0.0252\n",
      "Episode: 434 meanReward: 295.8125 meanLoss: 45.3081 ExploreP: 0.0250\n",
      "Episode: 435 meanReward: 288.9688 meanLoss: 7.4368 ExploreP: 0.0246\n",
      "Episode: 436 meanReward: 279.5312 meanLoss: 22.6370 ExploreP: 0.0244\n",
      "Episode: 437 meanReward: 275.5312 meanLoss: 15.7968 ExploreP: 0.0241\n",
      "Episode: 438 meanReward: 278.8125 meanLoss: 7.4553 ExploreP: 0.0235\n",
      "Episode: 439 meanReward: 278.8125 meanLoss: 6.0862 ExploreP: 0.0229\n",
      "Episode: 440 meanReward: 269.5938 meanLoss: 38.8262 ExploreP: 0.0226\n",
      "Episode: 441 meanReward: 264.7812 meanLoss: 8.5031 ExploreP: 0.0222\n",
      "Episode: 442 meanReward: 264.7812 meanLoss: 8.4163 ExploreP: 0.0216\n",
      "Episode: 443 meanReward: 266.5312 meanLoss: 10.8136 ExploreP: 0.0210\n",
      "Episode: 444 meanReward: 270.1250 meanLoss: 16.6615 ExploreP: 0.0205\n",
      "Episode: 445 meanReward: 278.2812 meanLoss: 9.8022 ExploreP: 0.0200\n",
      "Episode: 446 meanReward: 278.2812 meanLoss: 17.3639 ExploreP: 0.0195\n",
      "Episode: 447 meanReward: 278.2812 meanLoss: 12.7799 ExploreP: 0.0190\n",
      "Episode: 448 meanReward: 288.7500 meanLoss: 16.8009 ExploreP: 0.0186\n",
      "Episode: 449 meanReward: 299.3750 meanLoss: 15.3576 ExploreP: 0.0182\n",
      "Episode: 450 meanReward: 314.7188 meanLoss: 16.3945 ExploreP: 0.0178\n",
      "Episode: 451 meanReward: 323.3750 meanLoss: 22.6752 ExploreP: 0.0174\n",
      "Episode: 452 meanReward: 323.3750 meanLoss: 16.0989 ExploreP: 0.0170\n",
      "Episode: 453 meanReward: 323.3750 meanLoss: 16.1081 ExploreP: 0.0167\n",
      "Episode: 454 meanReward: 330.8438 meanLoss: 16.5173 ExploreP: 0.0164\n",
      "Episode: 455 meanReward: 325.3750 meanLoss: 114.0165 ExploreP: 0.0163\n",
      "Episode: 456 meanReward: 315.9062 meanLoss: 181.4962 ExploreP: 0.0163\n",
      "Episode: 457 meanReward: 327.5312 meanLoss: 11.3699 ExploreP: 0.0160\n",
      "Episode: 458 meanReward: 324.8750 meanLoss: 263.6846 ExploreP: 0.0160\n",
      "Episode: 459 meanReward: 319.8125 meanLoss: 471.8708 ExploreP: 0.0160\n",
      "Episode: 460 meanReward: 316.9062 meanLoss: 400.4555 ExploreP: 0.0160\n",
      "Episode: 461 meanReward: 313.7812 meanLoss: 158.9798 ExploreP: 0.0160\n",
      "Episode: 462 meanReward: 314.0625 meanLoss: 43.7909 ExploreP: 0.0159\n",
      "Episode: 463 meanReward: 328.7500 meanLoss: 3.2609 ExploreP: 0.0157\n",
      "Episode: 464 meanReward: 340.6250 meanLoss: 12.7842 ExploreP: 0.0154\n",
      "Episode: 465 meanReward: 340.6250 meanLoss: 13.3955 ExploreP: 0.0151\n",
      "Episode: 466 meanReward: 351.5000 meanLoss: 12.1086 ExploreP: 0.0149\n",
      "Episode: 467 meanReward: 358.3438 meanLoss: 12.7993 ExploreP: 0.0146\n",
      "Episode: 468 meanReward: 369.4062 meanLoss: 16.5551 ExploreP: 0.0144\n",
      "Episode: 469 meanReward: 366.5938 meanLoss: 66.5997 ExploreP: 0.0144\n",
      "Episode: 470 meanReward: 361.4375 meanLoss: 30.4885 ExploreP: 0.0143\n",
      "Episode: 471 meanReward: 348.6875 meanLoss: 59.2955 ExploreP: 0.0142\n",
      "Episode: 472 meanReward: 344.7188 meanLoss: 20.1039 ExploreP: 0.0142\n",
      "Episode: 473 meanReward: 336.6875 meanLoss: 18.8458 ExploreP: 0.0142\n",
      "Episode: 474 meanReward: 321.9375 meanLoss: 16.3571 ExploreP: 0.0141\n",
      "Episode: 475 meanReward: 309.4375 meanLoss: 44.2834 ExploreP: 0.0141\n",
      "Episode: 476 meanReward: 295.5625 meanLoss: 15.1199 ExploreP: 0.0141\n",
      "Episode: 477 meanReward: 282.3750 meanLoss: 6.2581 ExploreP: 0.0140\n",
      "Episode: 478 meanReward: 269.5625 meanLoss: 6.4608 ExploreP: 0.0140\n",
      "Episode: 479 meanReward: 255.6562 meanLoss: 5.9709 ExploreP: 0.0140\n",
      "Episode: 480 meanReward: 240.8750 meanLoss: 19.1113 ExploreP: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 481 meanReward: 226.7500 meanLoss: 25.0663 ExploreP: 0.0140\n",
      "Episode: 482 meanReward: 213.2812 meanLoss: 42.5829 ExploreP: 0.0139\n",
      "Episode: 483 meanReward: 200.4688 meanLoss: 11.6991 ExploreP: 0.0139\n",
      "Episode: 484 meanReward: 189.5938 meanLoss: 5.0247 ExploreP: 0.0138\n",
      "Episode: 485 meanReward: 189.5938 meanLoss: 1.3832 ExploreP: 0.0136\n",
      "Episode: 486 meanReward: 179.3438 meanLoss: 29.6784 ExploreP: 0.0136\n",
      "Episode: 487 meanReward: 192.7500 meanLoss: 1.1867 ExploreP: 0.0134\n",
      "Episode: 488 meanReward: 207.3750 meanLoss: 2.1987 ExploreP: 0.0132\n",
      "Episode: 489 meanReward: 207.3750 meanLoss: 15.2709 ExploreP: 0.0131\n",
      "Episode: 490 meanReward: 211.4375 meanLoss: 14.4314 ExploreP: 0.0130\n",
      "Episode: 491 meanReward: 215.0938 meanLoss: 43.2845 ExploreP: 0.0130\n",
      "Episode: 492 meanReward: 220.2188 meanLoss: 20.5609 ExploreP: 0.0130\n",
      "Episode: 493 meanReward: 223.7500 meanLoss: 12.6692 ExploreP: 0.0129\n",
      "Episode: 494 meanReward: 238.2500 meanLoss: 3.6229 ExploreP: 0.0128\n",
      "Episode: 495 meanReward: 225.5312 meanLoss: 50.8353 ExploreP: 0.0127\n",
      "Episode: 496 meanReward: 210.4062 meanLoss: 63.1453 ExploreP: 0.0127\n",
      "Episode: 497 meanReward: 195.5000 meanLoss: 461.4634 ExploreP: 0.0127\n",
      "Episode: 498 meanReward: 180.2812 meanLoss: 305.8294 ExploreP: 0.0127\n",
      "Episode: 499 meanReward: 165.0312 meanLoss: 70.7050 ExploreP: 0.0127\n",
      "Episode: 500 meanReward: 149.7500 meanLoss: 32.0603 ExploreP: 0.0127\n",
      "Episode: 501 meanReward: 146.7812 meanLoss: 20.7343 ExploreP: 0.0127\n",
      "Episode: 502 meanReward: 146.5312 meanLoss: 37.0489 ExploreP: 0.0127\n",
      "Episode: 503 meanReward: 158.0938 meanLoss: 7.9965 ExploreP: 0.0125\n",
      "Episode: 504 meanReward: 171.2812 meanLoss: 8.0038 ExploreP: 0.0124\n",
      "Episode: 505 meanReward: 171.2188 meanLoss: 69.3821 ExploreP: 0.0124\n",
      "Episode: 506 meanReward: 185.9688 meanLoss: 3.8292 ExploreP: 0.0123\n",
      "Episode: 507 meanReward: 183.9375 meanLoss: 147.1010 ExploreP: 0.0123\n",
      "Episode: 508 meanReward: 189.7812 meanLoss: 10.0182 ExploreP: 0.0122\n",
      "Episode: 509 meanReward: 191.7812 meanLoss: 15.9256 ExploreP: 0.0122\n",
      "Episode: 510 meanReward: 194.7500 meanLoss: 12.0406 ExploreP: 0.0121\n",
      "Episode: 511 meanReward: 197.5000 meanLoss: 11.8072 ExploreP: 0.0121\n",
      "Episode: 512 meanReward: 200.4688 meanLoss: 7.8668 ExploreP: 0.0121\n",
      "Episode: 513 meanReward: 214.5938 meanLoss: 3.2677 ExploreP: 0.0120\n",
      "Episode: 514 meanReward: 228.0625 meanLoss: 18.6064 ExploreP: 0.0119\n",
      "Episode: 515 meanReward: 228.7812 meanLoss: 68.4923 ExploreP: 0.0119\n",
      "Episode: 516 meanReward: 228.8438 meanLoss: 67.5478 ExploreP: 0.0118\n",
      "Episode: 517 meanReward: 228.8438 meanLoss: 4.1461 ExploreP: 0.0118\n",
      "Episode: 518 meanReward: 227.0312 meanLoss: 67.3768 ExploreP: 0.0117\n",
      "Episode: 519 meanReward: 215.5000 meanLoss: 16.9841 ExploreP: 0.0117\n",
      "Episode: 520 meanReward: 203.6562 meanLoss: 15.0677 ExploreP: 0.0117\n",
      "Episode: 521 meanReward: 191.9375 meanLoss: 8.8983 ExploreP: 0.0117\n",
      "Episode: 522 meanReward: 187.8125 meanLoss: 42.6619 ExploreP: 0.0117\n",
      "Episode: 523 meanReward: 184.0000 meanLoss: 186.3269 ExploreP: 0.0117\n",
      "Episode: 524 meanReward: 178.8438 meanLoss: 223.0066 ExploreP: 0.0117\n",
      "Episode: 525 meanReward: 175.2500 meanLoss: 774.3193 ExploreP: 0.0117\n",
      "Episode: 526 meanReward: 159.9062 meanLoss: 1236.3748 ExploreP: 0.0117\n",
      "Episode: 527 meanReward: 157.2812 meanLoss: 1521.7935 ExploreP: 0.0117\n",
      "Episode: 528 meanReward: 157.0312 meanLoss: 1699.0471 ExploreP: 0.0117\n",
      "Episode: 529 meanReward: 156.6250 meanLoss: 1812.1047 ExploreP: 0.0117\n",
      "Episode: 530 meanReward: 156.5312 meanLoss: 1922.4397 ExploreP: 0.0117\n",
      "Episode: 531 meanReward: 156.4062 meanLoss: 1983.9736 ExploreP: 0.0117\n",
      "Episode: 532 meanReward: 156.3750 meanLoss: 2026.9769 ExploreP: 0.0117\n",
      "Episode: 533 meanReward: 156.2188 meanLoss: 2058.0845 ExploreP: 0.0117\n",
      "Episode: 534 meanReward: 149.9688 meanLoss: 2076.5750 ExploreP: 0.0116\n",
      "Episode: 535 meanReward: 135.8750 meanLoss: 2132.4041 ExploreP: 0.0116\n",
      "Episode: 536 meanReward: 120.5625 meanLoss: 2175.8164 ExploreP: 0.0116\n",
      "Episode: 537 meanReward: 118.1875 meanLoss: 2212.7783 ExploreP: 0.0116\n",
      "Episode: 538 meanReward: 102.9062 meanLoss: 2233.0322 ExploreP: 0.0116\n",
      "Episode: 539 meanReward: 102.2188 meanLoss: 2259.6267 ExploreP: 0.0116\n",
      "Episode: 540 meanReward: 95.0625 meanLoss: 2287.1243 ExploreP: 0.0116\n",
      "Episode: 541 meanReward: 90.9688 meanLoss: 2327.5576 ExploreP: 0.0116\n",
      "Episode: 542 meanReward: 85.5000 meanLoss: 2349.1892 ExploreP: 0.0116\n",
      "Episode: 543 meanReward: 81.3750 meanLoss: 2363.1772 ExploreP: 0.0116\n",
      "Episode: 544 meanReward: 77.9375 meanLoss: 2343.3284 ExploreP: 0.0116\n",
      "Episode: 545 meanReward: 62.6562 meanLoss: 2347.9634 ExploreP: 0.0116\n",
      "Episode: 546 meanReward: 47.4062 meanLoss: 2374.5994 ExploreP: 0.0116\n",
      "Episode: 547 meanReward: 44.2188 meanLoss: 2422.6538 ExploreP: 0.0116\n",
      "Episode: 548 meanReward: 39.7500 meanLoss: 2449.6575 ExploreP: 0.0116\n",
      "Episode: 549 meanReward: 24.5312 meanLoss: 2439.1672 ExploreP: 0.0116\n",
      "Episode: 550 meanReward: 21.3438 meanLoss: 2429.9563 ExploreP: 0.0116\n",
      "Episode: 551 meanReward: 17.5938 meanLoss: 2449.6240 ExploreP: 0.0116\n",
      "Episode: 552 meanReward: 14.1562 meanLoss: 2456.7773 ExploreP: 0.0116\n",
      "Episode: 553 meanReward: 10.6562 meanLoss: 2425.4353 ExploreP: 0.0116\n",
      "Episode: 554 meanReward: 10.6562 meanLoss: 2416.7646 ExploreP: 0.0116\n",
      "Episode: 555 meanReward: 10.8125 meanLoss: 2422.4185 ExploreP: 0.0116\n",
      "Episode: 556 meanReward: 10.8438 meanLoss: 2433.1406 ExploreP: 0.0116\n",
      "Episode: 557 meanReward: 10.9062 meanLoss: 2449.7021 ExploreP: 0.0116\n",
      "Episode: 558 meanReward: 11.0312 meanLoss: 2427.5557 ExploreP: 0.0116\n",
      "Episode: 559 meanReward: 11.1562 meanLoss: 2398.1133 ExploreP: 0.0116\n",
      "Episode: 560 meanReward: 11.3438 meanLoss: 2410.4421 ExploreP: 0.0116\n",
      "Episode: 561 meanReward: 11.4062 meanLoss: 2446.6140 ExploreP: 0.0116\n",
      "Episode: 562 meanReward: 11.5000 meanLoss: 2467.5718 ExploreP: 0.0116\n",
      "Episode: 563 meanReward: 11.6875 meanLoss: 2459.2512 ExploreP: 0.0116\n",
      "Episode: 564 meanReward: 11.8125 meanLoss: 2431.6101 ExploreP: 0.0116\n",
      "Episode: 565 meanReward: 12.0000 meanLoss: 2432.0349 ExploreP: 0.0116\n",
      "Episode: 566 meanReward: 12.0625 meanLoss: 2460.2349 ExploreP: 0.0116\n",
      "Episode: 567 meanReward: 12.1562 meanLoss: 2451.1289 ExploreP: 0.0116\n",
      "Episode: 568 meanReward: 12.3438 meanLoss: 2419.0835 ExploreP: 0.0116\n",
      "Episode: 569 meanReward: 12.5000 meanLoss: 2437.9102 ExploreP: 0.0116\n",
      "Episode: 570 meanReward: 12.5938 meanLoss: 2475.8391 ExploreP: 0.0116\n",
      "Episode: 571 meanReward: 12.6250 meanLoss: 2459.8247 ExploreP: 0.0116\n",
      "Episode: 572 meanReward: 12.6250 meanLoss: 2426.9280 ExploreP: 0.0116\n",
      "Episode: 573 meanReward: 12.7500 meanLoss: 2466.3135 ExploreP: 0.0116\n",
      "Episode: 574 meanReward: 12.8750 meanLoss: 2506.7273 ExploreP: 0.0116\n",
      "Episode: 575 meanReward: 12.9375 meanLoss: 2503.9634 ExploreP: 0.0116\n",
      "Episode: 576 meanReward: 13.0938 meanLoss: 2477.3833 ExploreP: 0.0116\n",
      "Episode: 577 meanReward: 13.2812 meanLoss: 2508.1621 ExploreP: 0.0116\n",
      "Episode: 578 meanReward: 13.4375 meanLoss: 2533.6699 ExploreP: 0.0116\n",
      "Episode: 579 meanReward: 13.5625 meanLoss: 2546.7424 ExploreP: 0.0116\n",
      "Episode: 580 meanReward: 13.6875 meanLoss: 2585.5369 ExploreP: 0.0116\n",
      "Episode: 581 meanReward: 13.8125 meanLoss: 2582.6011 ExploreP: 0.0116\n",
      "Episode: 582 meanReward: 13.9375 meanLoss: 2547.9324 ExploreP: 0.0115\n",
      "Episode: 583 meanReward: 14.0938 meanLoss: 2551.8240 ExploreP: 0.0115\n",
      "Episode: 584 meanReward: 14.1562 meanLoss: 2593.7422 ExploreP: 0.0115\n",
      "Episode: 585 meanReward: 14.8438 meanLoss: 2429.4375 ExploreP: 0.0115\n",
      "Episode: 586 meanReward: 14.8125 meanLoss: 1161.7418 ExploreP: 0.0115\n",
      "Episode: 587 meanReward: 14.6562 meanLoss: 472.4554 ExploreP: 0.0115\n",
      "Episode: 588 meanReward: 14.7188 meanLoss: 423.3875 ExploreP: 0.0115\n",
      "Episode: 589 meanReward: 14.6875 meanLoss: 827.5623 ExploreP: 0.0115\n",
      "Episode: 590 meanReward: 14.6562 meanLoss: 1182.8253 ExploreP: 0.0115\n",
      "Episode: 591 meanReward: 14.5312 meanLoss: 1346.1038 ExploreP: 0.0115\n",
      "Episode: 592 meanReward: 14.4688 meanLoss: 1383.9214 ExploreP: 0.0115\n",
      "Episode: 593 meanReward: 14.4688 meanLoss: 1439.8037 ExploreP: 0.0115\n",
      "Episode: 594 meanReward: 14.4375 meanLoss: 1458.3558 ExploreP: 0.0115\n",
      "Episode: 595 meanReward: 14.4062 meanLoss: 1489.1173 ExploreP: 0.0115\n",
      "Episode: 596 meanReward: 14.3750 meanLoss: 1511.4839 ExploreP: 0.0115\n",
      "Episode: 597 meanReward: 14.2812 meanLoss: 1542.8257 ExploreP: 0.0115\n",
      "Episode: 598 meanReward: 14.3438 meanLoss: 1542.7067 ExploreP: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 599 meanReward: 14.3438 meanLoss: 1498.0432 ExploreP: 0.0115\n",
      "Episode: 600 meanReward: 14.2812 meanLoss: 1467.5280 ExploreP: 0.0115\n",
      "Episode: 601 meanReward: 14.1875 meanLoss: 1463.2268 ExploreP: 0.0115\n",
      "Episode: 602 meanReward: 14.1875 meanLoss: 1510.8684 ExploreP: 0.0115\n",
      "Episode: 603 meanReward: 14.1250 meanLoss: 1567.5067 ExploreP: 0.0115\n",
      "Episode: 604 meanReward: 14.1562 meanLoss: 1570.2809 ExploreP: 0.0115\n",
      "Episode: 605 meanReward: 14.0938 meanLoss: 1518.1061 ExploreP: 0.0115\n",
      "Episode: 606 meanReward: 14.0938 meanLoss: 1526.1163 ExploreP: 0.0115\n",
      "Episode: 607 meanReward: 14.1250 meanLoss: 1531.3870 ExploreP: 0.0115\n",
      "Episode: 608 meanReward: 14.0625 meanLoss: 1528.2032 ExploreP: 0.0115\n",
      "Episode: 609 meanReward: 13.8750 meanLoss: 1561.2769 ExploreP: 0.0115\n",
      "Episode: 610 meanReward: 13.7812 meanLoss: 1590.7172 ExploreP: 0.0115\n",
      "Episode: 611 meanReward: 13.7812 meanLoss: 1553.5946 ExploreP: 0.0115\n",
      "Episode: 612 meanReward: 13.7500 meanLoss: 1570.7556 ExploreP: 0.0115\n",
      "Episode: 613 meanReward: 13.5938 meanLoss: 1630.6182 ExploreP: 0.0115\n",
      "Episode: 614 meanReward: 13.5625 meanLoss: 1626.8445 ExploreP: 0.0115\n",
      "Episode: 615 meanReward: 13.4688 meanLoss: 1588.4966 ExploreP: 0.0115\n",
      "Episode: 616 meanReward: 13.4375 meanLoss: 1593.2388 ExploreP: 0.0115\n",
      "Episode: 617 meanReward: 12.8438 meanLoss: 1570.9368 ExploreP: 0.0115\n",
      "Episode: 618 meanReward: 12.9375 meanLoss: 1627.3391 ExploreP: 0.0115\n",
      "Episode: 619 meanReward: 13.0938 meanLoss: 1725.7825 ExploreP: 0.0115\n",
      "Episode: 620 meanReward: 13.2812 meanLoss: 1652.6285 ExploreP: 0.0115\n",
      "Episode: 621 meanReward: 13.4062 meanLoss: 1692.4187 ExploreP: 0.0115\n",
      "Episode: 622 meanReward: 13.5312 meanLoss: 1723.8125 ExploreP: 0.0115\n",
      "Episode: 623 meanReward: 13.8750 meanLoss: 1721.4358 ExploreP: 0.0115\n",
      "Episode: 624 meanReward: 14.0000 meanLoss: 1809.5167 ExploreP: 0.0115\n",
      "Episode: 625 meanReward: 14.1875 meanLoss: 1832.7048 ExploreP: 0.0115\n",
      "Episode: 626 meanReward: 14.3125 meanLoss: 1824.3390 ExploreP: 0.0115\n",
      "Episode: 627 meanReward: 14.4062 meanLoss: 1822.7554 ExploreP: 0.0115\n",
      "Episode: 628 meanReward: 14.6250 meanLoss: 1796.5154 ExploreP: 0.0115\n",
      "Episode: 629 meanReward: 14.7812 meanLoss: 1845.6986 ExploreP: 0.0114\n",
      "Episode: 630 meanReward: 15.0312 meanLoss: 1862.7001 ExploreP: 0.0114\n",
      "Episode: 631 meanReward: 15.0938 meanLoss: 1930.0651 ExploreP: 0.0114\n",
      "Episode: 632 meanReward: 15.2500 meanLoss: 1907.1497 ExploreP: 0.0114\n",
      "Episode: 633 meanReward: 15.3438 meanLoss: 1948.3856 ExploreP: 0.0114\n",
      "Episode: 634 meanReward: 15.5000 meanLoss: 2002.5851 ExploreP: 0.0114\n",
      "Episode: 635 meanReward: 15.5625 meanLoss: 2053.6672 ExploreP: 0.0114\n",
      "Episode: 636 meanReward: 15.5625 meanLoss: 2060.4602 ExploreP: 0.0114\n",
      "Episode: 637 meanReward: 15.6250 meanLoss: 1965.5598 ExploreP: 0.0114\n",
      "Episode: 638 meanReward: 15.7812 meanLoss: 1985.8824 ExploreP: 0.0114\n",
      "Episode: 639 meanReward: 16.7812 meanLoss: 1358.3562 ExploreP: 0.0114\n",
      "Episode: 640 meanReward: 25.4062 meanLoss: 19.0733 ExploreP: 0.0114\n",
      "Episode: 641 meanReward: 30.4688 meanLoss: 8.0827 ExploreP: 0.0114\n",
      "Episode: 642 meanReward: 45.6562 meanLoss: 2.5721 ExploreP: 0.0113\n",
      "Episode: 643 meanReward: 47.7500 meanLoss: 113.6227 ExploreP: 0.0113\n",
      "Episode: 644 meanReward: 48.4062 meanLoss: 54.4541 ExploreP: 0.0113\n",
      "Episode: 645 meanReward: 53.2500 meanLoss: 269.4841 ExploreP: 0.0113\n",
      "Episode: 646 meanReward: 64.8125 meanLoss: 6.2663 ExploreP: 0.0112\n",
      "Episode: 647 meanReward: 69.3125 meanLoss: 21.0122 ExploreP: 0.0112\n",
      "Episode: 648 meanReward: 76.7500 meanLoss: 4.9638 ExploreP: 0.0112\n",
      "Episode: 649 meanReward: 84.4688 meanLoss: 3.9036 ExploreP: 0.0111\n",
      "Episode: 650 meanReward: 94.2500 meanLoss: 1.7194 ExploreP: 0.0111\n",
      "Episode: 651 meanReward: 104.0625 meanLoss: 2.8477 ExploreP: 0.0111\n",
      "Episode: 652 meanReward: 114.3125 meanLoss: 4.2178 ExploreP: 0.0110\n",
      "Episode: 653 meanReward: 123.9375 meanLoss: 3.8951 ExploreP: 0.0110\n",
      "Episode: 654 meanReward: 135.6875 meanLoss: 2.3116 ExploreP: 0.0109\n",
      "Episode: 655 meanReward: 150.6875 meanLoss: 1.3502 ExploreP: 0.0109\n",
      "Episode: 656 meanReward: 159.6875 meanLoss: 10.6509 ExploreP: 0.0109\n",
      "Episode: 657 meanReward: 159.4062 meanLoss: 117.9130 ExploreP: 0.0109\n",
      "Episode: 658 meanReward: 159.1875 meanLoss: 491.6247 ExploreP: 0.0109\n",
      "Episode: 659 meanReward: 159.0000 meanLoss: 920.3625 ExploreP: 0.0109\n",
      "Episode: 660 meanReward: 158.6875 meanLoss: 1166.8724 ExploreP: 0.0109\n",
      "Episode: 661 meanReward: 158.5312 meanLoss: 1135.3168 ExploreP: 0.0109\n",
      "Episode: 662 meanReward: 158.1562 meanLoss: 1015.5047 ExploreP: 0.0109\n",
      "Episode: 663 meanReward: 157.9688 meanLoss: 1159.1624 ExploreP: 0.0109\n",
      "Episode: 664 meanReward: 157.6875 meanLoss: 1150.1733 ExploreP: 0.0109\n",
      "Episode: 665 meanReward: 157.5625 meanLoss: 1176.7792 ExploreP: 0.0109\n",
      "Episode: 666 meanReward: 157.2812 meanLoss: 1283.8375 ExploreP: 0.0109\n",
      "Episode: 667 meanReward: 157.1875 meanLoss: 1371.3119 ExploreP: 0.0109\n",
      "Episode: 668 meanReward: 157.0312 meanLoss: 1381.5011 ExploreP: 0.0109\n",
      "Episode: 669 meanReward: 156.8750 meanLoss: 1159.7937 ExploreP: 0.0109\n",
      "Episode: 670 meanReward: 156.6250 meanLoss: 1200.0840 ExploreP: 0.0109\n",
      "Episode: 671 meanReward: 155.5000 meanLoss: 1126.4368 ExploreP: 0.0109\n",
      "Episode: 672 meanReward: 146.7500 meanLoss: 1276.1603 ExploreP: 0.0109\n",
      "Episode: 673 meanReward: 141.6250 meanLoss: 1325.3881 ExploreP: 0.0109\n",
      "Episode: 674 meanReward: 126.3125 meanLoss: 1156.5557 ExploreP: 0.0109\n",
      "Episode: 675 meanReward: 124.1250 meanLoss: 1281.2355 ExploreP: 0.0109\n",
      "Episode: 676 meanReward: 123.3438 meanLoss: 1292.1454 ExploreP: 0.0109\n",
      "Episode: 677 meanReward: 118.5312 meanLoss: 1375.1431 ExploreP: 0.0109\n",
      "Episode: 678 meanReward: 106.7812 meanLoss: 1307.7639 ExploreP: 0.0109\n",
      "Episode: 679 meanReward: 102.2812 meanLoss: 1279.9857 ExploreP: 0.0109\n",
      "Episode: 680 meanReward: 94.8750 meanLoss: 1416.3169 ExploreP: 0.0109\n",
      "Episode: 681 meanReward: 86.9375 meanLoss: 1494.3265 ExploreP: 0.0109\n",
      "Episode: 682 meanReward: 77.1250 meanLoss: 1426.0380 ExploreP: 0.0109\n",
      "Episode: 683 meanReward: 67.1875 meanLoss: 1331.4926 ExploreP: 0.0109\n",
      "Episode: 684 meanReward: 56.7812 meanLoss: 1354.9122 ExploreP: 0.0109\n",
      "Episode: 685 meanReward: 47.0000 meanLoss: 1269.3289 ExploreP: 0.0108\n",
      "Episode: 686 meanReward: 35.1250 meanLoss: 1289.3439 ExploreP: 0.0108\n",
      "Episode: 687 meanReward: 19.7812 meanLoss: 1185.0889 ExploreP: 0.0108\n",
      "Episode: 688 meanReward: 10.6562 meanLoss: 1174.6569 ExploreP: 0.0108\n",
      "Episode: 689 meanReward: 10.6875 meanLoss: 1181.5256 ExploreP: 0.0108\n",
      "Episode: 690 meanReward: 10.7188 meanLoss: 1113.6793 ExploreP: 0.0108\n",
      "Episode: 691 meanReward: 10.6875 meanLoss: 1081.2554 ExploreP: 0.0108\n",
      "Episode: 692 meanReward: 10.6875 meanLoss: 996.6639 ExploreP: 0.0108\n",
      "Episode: 693 meanReward: 10.6562 meanLoss: 1147.2823 ExploreP: 0.0108\n",
      "Episode: 694 meanReward: 10.7188 meanLoss: 1143.0758 ExploreP: 0.0108\n",
      "Episode: 695 meanReward: 10.7812 meanLoss: 1220.7899 ExploreP: 0.0108\n",
      "Episode: 696 meanReward: 10.7812 meanLoss: 1267.4305 ExploreP: 0.0108\n",
      "Episode: 697 meanReward: 10.8125 meanLoss: 1331.7361 ExploreP: 0.0108\n",
      "Episode: 698 meanReward: 10.8125 meanLoss: 1272.4427 ExploreP: 0.0108\n",
      "Episode: 699 meanReward: 10.8438 meanLoss: 1260.7303 ExploreP: 0.0108\n",
      "Episode: 700 meanReward: 10.8438 meanLoss: 1149.1569 ExploreP: 0.0108\n",
      "Episode: 701 meanReward: 10.8750 meanLoss: 1168.5986 ExploreP: 0.0108\n",
      "Episode: 702 meanReward: 10.8125 meanLoss: 1116.5304 ExploreP: 0.0108\n",
      "Episode: 703 meanReward: 10.8125 meanLoss: 1093.9309 ExploreP: 0.0108\n",
      "Episode: 704 meanReward: 10.7500 meanLoss: 1245.4532 ExploreP: 0.0108\n",
      "Episode: 705 meanReward: 10.8750 meanLoss: 1178.1185 ExploreP: 0.0108\n",
      "Episode: 706 meanReward: 10.8750 meanLoss: 1256.4189 ExploreP: 0.0108\n",
      "Episode: 707 meanReward: 10.8750 meanLoss: 1270.0441 ExploreP: 0.0108\n",
      "Episode: 708 meanReward: 10.9062 meanLoss: 1234.0178 ExploreP: 0.0108\n",
      "Episode: 709 meanReward: 10.9375 meanLoss: 1324.5330 ExploreP: 0.0108\n",
      "Episode: 710 meanReward: 10.9375 meanLoss: 1283.3730 ExploreP: 0.0108\n",
      "Episode: 711 meanReward: 10.8438 meanLoss: 1284.0900 ExploreP: 0.0108\n",
      "Episode: 712 meanReward: 10.7500 meanLoss: 1216.3214 ExploreP: 0.0108\n",
      "Episode: 713 meanReward: 10.7500 meanLoss: 927.1711 ExploreP: 0.0108\n",
      "Episode: 714 meanReward: 10.7188 meanLoss: 912.0208 ExploreP: 0.0108\n",
      "Episode: 715 meanReward: 10.7188 meanLoss: 793.6478 ExploreP: 0.0108\n",
      "Episode: 716 meanReward: 10.5938 meanLoss: 1064.8311 ExploreP: 0.0108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 717 meanReward: 10.5938 meanLoss: 1222.9071 ExploreP: 0.0108\n",
      "Episode: 718 meanReward: 10.5938 meanLoss: 1315.0004 ExploreP: 0.0108\n",
      "Episode: 719 meanReward: 10.6250 meanLoss: 1295.7953 ExploreP: 0.0108\n",
      "Episode: 720 meanReward: 10.6250 meanLoss: 1252.3107 ExploreP: 0.0108\n",
      "Episode: 721 meanReward: 10.5938 meanLoss: 1228.5435 ExploreP: 0.0108\n",
      "Episode: 722 meanReward: 10.5938 meanLoss: 1172.8031 ExploreP: 0.0108\n",
      "Episode: 723 meanReward: 10.6562 meanLoss: 1262.5013 ExploreP: 0.0108\n",
      "Episode: 724 meanReward: 10.6562 meanLoss: 1070.5933 ExploreP: 0.0108\n",
      "Episode: 725 meanReward: 10.6562 meanLoss: 1073.2683 ExploreP: 0.0108\n",
      "Episode: 726 meanReward: 10.5938 meanLoss: 967.4330 ExploreP: 0.0108\n",
      "Episode: 727 meanReward: 10.5312 meanLoss: 1123.0015 ExploreP: 0.0108\n",
      "Episode: 728 meanReward: 10.5000 meanLoss: 1002.4890 ExploreP: 0.0108\n",
      "Episode: 729 meanReward: 10.4375 meanLoss: 1072.6544 ExploreP: 0.0108\n",
      "Episode: 730 meanReward: 10.3750 meanLoss: 1013.4668 ExploreP: 0.0108\n",
      "Episode: 731 meanReward: 10.3438 meanLoss: 1140.6984 ExploreP: 0.0108\n",
      "Episode: 732 meanReward: 10.3750 meanLoss: 1494.5262 ExploreP: 0.0108\n",
      "Episode: 733 meanReward: 10.3438 meanLoss: 1489.8344 ExploreP: 0.0108\n",
      "Episode: 734 meanReward: 10.4062 meanLoss: 1500.0571 ExploreP: 0.0108\n",
      "Episode: 735 meanReward: 10.3750 meanLoss: 1288.5110 ExploreP: 0.0108\n",
      "Episode: 736 meanReward: 10.3750 meanLoss: 1153.1533 ExploreP: 0.0108\n",
      "Episode: 737 meanReward: 10.2500 meanLoss: 1224.9010 ExploreP: 0.0108\n",
      "Episode: 738 meanReward: 10.3438 meanLoss: 1053.4640 ExploreP: 0.0108\n",
      "Episode: 739 meanReward: 10.2500 meanLoss: 1105.9918 ExploreP: 0.0108\n",
      "Episode: 740 meanReward: 10.2500 meanLoss: 1106.4943 ExploreP: 0.0108\n",
      "Episode: 741 meanReward: 10.0938 meanLoss: 1095.4121 ExploreP: 0.0108\n",
      "Episode: 742 meanReward: 10.2500 meanLoss: 1218.6263 ExploreP: 0.0108\n",
      "Episode: 743 meanReward: 10.4375 meanLoss: 1738.8307 ExploreP: 0.0108\n",
      "Episode: 744 meanReward: 10.4688 meanLoss: 2223.9829 ExploreP: 0.0108\n",
      "Episode: 745 meanReward: 10.5000 meanLoss: 2002.2312 ExploreP: 0.0108\n",
      "Episode: 746 meanReward: 10.4688 meanLoss: 1606.3655 ExploreP: 0.0108\n",
      "Episode: 747 meanReward: 10.4062 meanLoss: 1266.9570 ExploreP: 0.0108\n",
      "Episode: 748 meanReward: 10.5312 meanLoss: 1041.6156 ExploreP: 0.0108\n",
      "Episode: 749 meanReward: 10.5625 meanLoss: 1009.8358 ExploreP: 0.0108\n",
      "Episode: 750 meanReward: 10.5625 meanLoss: 1100.7343 ExploreP: 0.0108\n",
      "Episode: 751 meanReward: 10.5000 meanLoss: 1012.2678 ExploreP: 0.0108\n",
      "Episode: 752 meanReward: 10.5312 meanLoss: 1023.5031 ExploreP: 0.0108\n",
      "Episode: 753 meanReward: 10.6250 meanLoss: 1100.0878 ExploreP: 0.0108\n",
      "Episode: 754 meanReward: 10.5938 meanLoss: 1104.0685 ExploreP: 0.0108\n",
      "Episode: 755 meanReward: 10.5625 meanLoss: 1063.2957 ExploreP: 0.0108\n",
      "Episode: 756 meanReward: 16.7188 meanLoss: 111.5382 ExploreP: 0.0108\n",
      "Episode: 757 meanReward: 32.0312 meanLoss: 4.4294 ExploreP: 0.0107\n",
      "Episode: 758 meanReward: 47.3438 meanLoss: 15.6577 ExploreP: 0.0107\n",
      "Episode: 759 meanReward: 47.5625 meanLoss: 292.5078 ExploreP: 0.0107\n",
      "Episode: 760 meanReward: 53.2188 meanLoss: 40.2794 ExploreP: 0.0107\n",
      "Episode: 761 meanReward: 68.5000 meanLoss: 5.2131 ExploreP: 0.0107\n",
      "Episode: 762 meanReward: 83.8750 meanLoss: 14.4827 ExploreP: 0.0106\n",
      "Episode: 763 meanReward: 99.1562 meanLoss: 20.0726 ExploreP: 0.0106\n",
      "Episode: 764 meanReward: 114.4375 meanLoss: 13.3294 ExploreP: 0.0106\n",
      "Episode: 765 meanReward: 129.4688 meanLoss: 19.4325 ExploreP: 0.0105\n",
      "Episode: 766 meanReward: 136.5000 meanLoss: 24.2694 ExploreP: 0.0105\n",
      "Episode: 767 meanReward: 151.8438 meanLoss: 6.7691 ExploreP: 0.0105\n",
      "Episode: 768 meanReward: 167.1875 meanLoss: 13.2829 ExploreP: 0.0105\n",
      "Episode: 769 meanReward: 182.5312 meanLoss: 13.0657 ExploreP: 0.0104\n",
      "Episode: 770 meanReward: 197.7500 meanLoss: 12.5842 ExploreP: 0.0104\n",
      "Episode: 771 meanReward: 213.0938 meanLoss: 21.0385 ExploreP: 0.0104\n",
      "Episode: 772 meanReward: 228.3750 meanLoss: 18.2835 ExploreP: 0.0104\n",
      "Episode: 773 meanReward: 231.8125 meanLoss: 76.4649 ExploreP: 0.0104\n",
      "Episode: 774 meanReward: 247.0000 meanLoss: 17.2121 ExploreP: 0.0104\n",
      "Episode: 775 meanReward: 260.2500 meanLoss: 19.9181 ExploreP: 0.0103\n",
      "Episode: 776 meanReward: 264.8750 meanLoss: 43.8110 ExploreP: 0.0103\n",
      "Episode: 777 meanReward: 265.2188 meanLoss: 221.7044 ExploreP: 0.0103\n",
      "Episode: 778 meanReward: 267.5625 meanLoss: 98.0977 ExploreP: 0.0103\n",
      "Episode: 779 meanReward: 282.9375 meanLoss: 12.0177 ExploreP: 0.0103\n",
      "Episode: 780 meanReward: 286.3750 meanLoss: 64.5137 ExploreP: 0.0103\n",
      "Episode: 781 meanReward: 301.6562 meanLoss: 8.4747 ExploreP: 0.0103\n",
      "Episode: 782 meanReward: 316.9062 meanLoss: 20.1852 ExploreP: 0.0103\n",
      "Episode: 783 meanReward: 317.0312 meanLoss: 321.1022 ExploreP: 0.0103\n",
      "Episode: 784 meanReward: 317.0000 meanLoss: 468.7227 ExploreP: 0.0103\n",
      "Episode: 785 meanReward: 318.2812 meanLoss: 120.2440 ExploreP: 0.0103\n",
      "Episode: 786 meanReward: 320.5000 meanLoss: 84.1286 ExploreP: 0.0103\n",
      "Episode: 787 meanReward: 320.8750 meanLoss: 81.8141 ExploreP: 0.0103\n",
      "Episode: 788 meanReward: 330.0312 meanLoss: 8.2681 ExploreP: 0.0103\n",
      "Episode: 789 meanReward: 328.1250 meanLoss: 19.1671 ExploreP: 0.0103\n",
      "Episode: 790 meanReward: 316.2500 meanLoss: 68.7599 ExploreP: 0.0103\n",
      "Episode: 791 meanReward: 329.3125 meanLoss: 12.0143 ExploreP: 0.0102\n",
      "Episode: 792 meanReward: 323.9375 meanLoss: 162.2857 ExploreP: 0.0102\n",
      "Episode: 793 meanReward: 320.4688 meanLoss: 11.4692 ExploreP: 0.0102\n",
      "Episode: 794 meanReward: 310.3438 meanLoss: 17.5185 ExploreP: 0.0102\n",
      "Episode: 795 meanReward: 299.7812 meanLoss: 36.8879 ExploreP: 0.0102\n",
      "Episode: 796 meanReward: 299.7812 meanLoss: 8.8045 ExploreP: 0.0102\n",
      "Episode: 797 meanReward: 300.0625 meanLoss: 16.0835 ExploreP: 0.0102\n",
      "Episode: 798 meanReward: 308.3125 meanLoss: 17.2704 ExploreP: 0.0102\n",
      "Episode: 799 meanReward: 308.3125 meanLoss: 8.2745 ExploreP: 0.0102\n",
      "Episode: 800 meanReward: 296.0938 meanLoss: 82.1290 ExploreP: 0.0102\n",
      "Episode: 801 meanReward: 291.5625 meanLoss: 10.6246 ExploreP: 0.0102\n",
      "Episode: 802 meanReward: 291.5625 meanLoss: 8.3659 ExploreP: 0.0102\n",
      "Episode: 803 meanReward: 291.5625 meanLoss: 14.2181 ExploreP: 0.0102\n",
      "Episode: 804 meanReward: 291.5625 meanLoss: 18.2841 ExploreP: 0.0102\n",
      "Episode: 805 meanReward: 303.4688 meanLoss: 17.2069 ExploreP: 0.0101\n",
      "Episode: 806 meanReward: 303.4688 meanLoss: 17.0966 ExploreP: 0.0101\n",
      "Episode: 807 meanReward: 305.3438 meanLoss: 16.9013 ExploreP: 0.0101\n",
      "Episode: 808 meanReward: 301.3750 meanLoss: 160.9569 ExploreP: 0.0101\n",
      "Episode: 809 meanReward: 313.4375 meanLoss: 27.8127 ExploreP: 0.0101\n",
      "Episode: 810 meanReward: 326.4062 meanLoss: 10.6740 ExploreP: 0.0101\n",
      "Episode: 811 meanReward: 326.4062 meanLoss: 16.1809 ExploreP: 0.0101\n",
      "Episode: 812 meanReward: 338.1562 meanLoss: 15.7994 ExploreP: 0.0101\n",
      "Episode: 813 meanReward: 338.1562 meanLoss: 16.9221 ExploreP: 0.0101\n",
      "Episode: 814 meanReward: 338.1562 meanLoss: 15.4679 ExploreP: 0.0101\n",
      "Episode: 815 meanReward: 353.4062 meanLoss: 17.2362 ExploreP: 0.0101\n",
      "Episode: 816 meanReward: 368.6562 meanLoss: 15.7184 ExploreP: 0.0101\n",
      "Episode: 817 meanReward: 382.6250 meanLoss: 16.8305 ExploreP: 0.0101\n",
      "Episode: 818 meanReward: 388.6250 meanLoss: 30.2162 ExploreP: 0.0101\n",
      "Episode: 819 meanReward: 403.5625 meanLoss: 13.8485 ExploreP: 0.0101\n",
      "Episode: 820 meanReward: 390.5000 meanLoss: 70.1102 ExploreP: 0.0101\n",
      "Episode: 821 meanReward: 379.3438 meanLoss: 62.1497 ExploreP: 0.0101\n",
      "Episode: 822 meanReward: 378.9375 meanLoss: 36.0526 ExploreP: 0.0101\n",
      "Episode: 823 meanReward: 368.3125 meanLoss: 22.6790 ExploreP: 0.0101\n",
      "Episode: 824 meanReward: 370.9062 meanLoss: 9.0489 ExploreP: 0.0101\n",
      "Episode: 825 meanReward: 359.4688 meanLoss: 11.7737 ExploreP: 0.0101\n",
      "Episode: 826 meanReward: 358.5312 meanLoss: 37.3133 ExploreP: 0.0101\n",
      "Episode: 827 meanReward: 362.5000 meanLoss: 6.0934 ExploreP: 0.0101\n",
      "Episode: 828 meanReward: 350.4375 meanLoss: 21.0531 ExploreP: 0.0101\n",
      "Episode: 829 meanReward: 340.4375 meanLoss: 244.5693 ExploreP: 0.0101\n",
      "Episode: 830 meanReward: 328.6562 meanLoss: 152.2306 ExploreP: 0.0101\n",
      "Episode: 831 meanReward: 317.0000 meanLoss: 9.7184 ExploreP: 0.0101\n",
      "Episode: 832 meanReward: 317.0312 meanLoss: 40.5327 ExploreP: 0.0101\n",
      "Episode: 833 meanReward: 308.9375 meanLoss: 23.0618 ExploreP: 0.0101\n",
      "Episode: 834 meanReward: 297.0000 meanLoss: 3.8902 ExploreP: 0.0101\n",
      "Episode: 835 meanReward: 286.5938 meanLoss: 14.2565 ExploreP: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 836 meanReward: 273.6562 meanLoss: 14.0269 ExploreP: 0.0101\n",
      "Episode: 837 meanReward: 260.6250 meanLoss: 4.6388 ExploreP: 0.0101\n",
      "Episode: 838 meanReward: 248.4375 meanLoss: 3.5984 ExploreP: 0.0101\n",
      "Episode: 839 meanReward: 245.6875 meanLoss: 2.4730 ExploreP: 0.0101\n",
      "Episode: 840 meanReward: 257.7500 meanLoss: 3.7414 ExploreP: 0.0101\n",
      "Episode: 841 meanReward: 249.4062 meanLoss: 12.3179 ExploreP: 0.0101\n",
      "Episode: 842 meanReward: 237.7812 meanLoss: 7.4269 ExploreP: 0.0101\n",
      "Episode: 843 meanReward: 230.0625 meanLoss: 6.2460 ExploreP: 0.0101\n",
      "Episode: 844 meanReward: 217.6562 meanLoss: 13.4853 ExploreP: 0.0101\n",
      "Episode: 845 meanReward: 204.4375 meanLoss: 15.1754 ExploreP: 0.0101\n",
      "Episode: 846 meanReward: 191.3125 meanLoss: 52.5178 ExploreP: 0.0101\n",
      "Episode: 847 meanReward: 177.9375 meanLoss: 24.5066 ExploreP: 0.0101\n",
      "Episode: 848 meanReward: 163.7500 meanLoss: 17.0487 ExploreP: 0.0101\n",
      "Episode: 849 meanReward: 151.6250 meanLoss: 14.4591 ExploreP: 0.0101\n",
      "Episode: 850 meanReward: 146.4062 meanLoss: 6.9175 ExploreP: 0.0101\n",
      "Episode: 851 meanReward: 134.0938 meanLoss: 7.4278 ExploreP: 0.0101\n",
      "Episode: 852 meanReward: 134.7812 meanLoss: 9.7101 ExploreP: 0.0101\n",
      "Episode: 853 meanReward: 135.6562 meanLoss: 12.7995 ExploreP: 0.0100\n",
      "Episode: 854 meanReward: 135.6250 meanLoss: 11.4987 ExploreP: 0.0100\n",
      "Episode: 855 meanReward: 141.6250 meanLoss: 5.0740 ExploreP: 0.0100\n",
      "Episode: 856 meanReward: 154.0938 meanLoss: 4.5245 ExploreP: 0.0100\n",
      "Episode: 857 meanReward: 162.7500 meanLoss: 25.1065 ExploreP: 0.0100\n",
      "Episode: 858 meanReward: 162.3125 meanLoss: 15.2796 ExploreP: 0.0100\n",
      "Episode: 859 meanReward: 157.2188 meanLoss: 7.1910 ExploreP: 0.0100\n",
      "Episode: 860 meanReward: 160.3438 meanLoss: 7.0954 ExploreP: 0.0100\n",
      "Episode: 861 meanReward: 170.3438 meanLoss: 4.0625 ExploreP: 0.0100\n",
      "Episode: 862 meanReward: 182.1250 meanLoss: 16.7550 ExploreP: 0.0100\n",
      "Episode: 863 meanReward: 193.7812 meanLoss: 18.0716 ExploreP: 0.0100\n",
      "Episode: 864 meanReward: 205.9688 meanLoss: 15.7844 ExploreP: 0.0100\n",
      "Episode: 865 meanReward: 218.5938 meanLoss: 17.7587 ExploreP: 0.0100\n",
      "Episode: 866 meanReward: 230.5312 meanLoss: 16.1616 ExploreP: 0.0100\n",
      "Episode: 867 meanReward: 240.9375 meanLoss: 16.0706 ExploreP: 0.0100\n",
      "Episode: 868 meanReward: 245.9688 meanLoss: 35.4489 ExploreP: 0.0100\n",
      "Episode: 869 meanReward: 259.0000 meanLoss: 2.2628 ExploreP: 0.0100\n",
      "Episode: 870 meanReward: 256.4062 meanLoss: 313.2878 ExploreP: 0.0100\n",
      "Episode: 871 meanReward: 259.1562 meanLoss: 9.0282 ExploreP: 0.0100\n",
      "Episode: 872 meanReward: 249.6250 meanLoss: 69.5433 ExploreP: 0.0100\n",
      "Episode: 873 meanReward: 245.6250 meanLoss: 72.0922 ExploreP: 0.0100\n",
      "Episode: 874 meanReward: 244.4375 meanLoss: 93.4831 ExploreP: 0.0100\n",
      "Episode: 875 meanReward: 242.2188 meanLoss: 7.4037 ExploreP: 0.0100\n",
      "Episode: 876 meanReward: 241.8125 meanLoss: 12.7843 ExploreP: 0.0100\n",
      "Episode: 877 meanReward: 255.0312 meanLoss: 1.1954 ExploreP: 0.0100\n",
      "Episode: 878 meanReward: 255.9375 meanLoss: 65.4128 ExploreP: 0.0100\n",
      "Episode: 879 meanReward: 256.0312 meanLoss: 5.4119 ExploreP: 0.0100\n",
      "Episode: 880 meanReward: 257.0938 meanLoss: 6.1687 ExploreP: 0.0100\n",
      "Episode: 881 meanReward: 256.6562 meanLoss: 6.9364 ExploreP: 0.0100\n",
      "Episode: 882 meanReward: 257.7500 meanLoss: 4.3446 ExploreP: 0.0100\n",
      "Episode: 883 meanReward: 256.1562 meanLoss: 5.9676 ExploreP: 0.0100\n",
      "Episode: 884 meanReward: 255.6562 meanLoss: 5.9870 ExploreP: 0.0100\n",
      "Episode: 885 meanReward: 254.6562 meanLoss: 3.6811 ExploreP: 0.0100\n",
      "Episode: 886 meanReward: 255.9375 meanLoss: 6.6468 ExploreP: 0.0100\n",
      "Episode: 887 meanReward: 252.1250 meanLoss: 5.1067 ExploreP: 0.0100\n",
      "Episode: 888 meanReward: 239.7500 meanLoss: 14.9694 ExploreP: 0.0100\n",
      "Episode: 889 meanReward: 232.2812 meanLoss: 16.4633 ExploreP: 0.0100\n",
      "Episode: 890 meanReward: 232.5312 meanLoss: 5.2181 ExploreP: 0.0100\n",
      "Episode: 891 meanReward: 229.3438 meanLoss: 36.0421 ExploreP: 0.0100\n",
      "Episode: 892 meanReward: 228.2188 meanLoss: 16.2408 ExploreP: 0.0100\n",
      "Episode: 893 meanReward: 228.2188 meanLoss: 2.5667 ExploreP: 0.0100\n",
      "Episode: 894 meanReward: 228.2188 meanLoss: 18.3528 ExploreP: 0.0100\n",
      "Episode: 895 meanReward: 228.2188 meanLoss: 20.6343 ExploreP: 0.0100\n",
      "Episode: 896 meanReward: 218.3125 meanLoss: 49.0326 ExploreP: 0.0100\n",
      "Episode: 897 meanReward: 218.3125 meanLoss: 2.2366 ExploreP: 0.0100\n",
      "Episode: 898 meanReward: 218.3125 meanLoss: 16.6092 ExploreP: 0.0100\n",
      "Episode: 899 meanReward: 215.3438 meanLoss: 17.6859 ExploreP: 0.0100\n",
      "Episode: 900 meanReward: 223.2500 meanLoss: 4.6767 ExploreP: 0.0100\n",
      "Episode: 901 meanReward: 220.3750 meanLoss: 19.5968 ExploreP: 0.0100\n",
      "Episode: 902 meanReward: 235.1562 meanLoss: 9.3640 ExploreP: 0.0100\n",
      "Episode: 903 meanReward: 235.1562 meanLoss: 17.1415 ExploreP: 0.0100\n",
      "Episode: 904 meanReward: 238.0312 meanLoss: 38.2971 ExploreP: 0.0100\n",
      "Episode: 905 meanReward: 238.5000 meanLoss: 88.7264 ExploreP: 0.0100\n",
      "Episode: 906 meanReward: 246.1250 meanLoss: 11.3952 ExploreP: 0.0100\n",
      "Episode: 907 meanReward: 256.0625 meanLoss: 4.1023 ExploreP: 0.0100\n",
      "Episode: 908 meanReward: 254.3125 meanLoss: 157.3024 ExploreP: 0.0100\n",
      "Episode: 909 meanReward: 238.9688 meanLoss: 234.7130 ExploreP: 0.0100\n",
      "Episode: 910 meanReward: 251.1875 meanLoss: 11.7500 ExploreP: 0.0100\n",
      "Episode: 911 meanReward: 264.4688 meanLoss: 16.1042 ExploreP: 0.0100\n",
      "Episode: 912 meanReward: 265.1875 meanLoss: 65.1251 ExploreP: 0.0100\n",
      "Episode: 913 meanReward: 262.5938 meanLoss: 300.1203 ExploreP: 0.0100\n",
      "Episode: 914 meanReward: 273.8438 meanLoss: 18.6296 ExploreP: 0.0100\n",
      "Episode: 915 meanReward: 278.0312 meanLoss: 27.7740 ExploreP: 0.0100\n",
      "Episode: 916 meanReward: 290.9062 meanLoss: 7.6199 ExploreP: 0.0100\n",
      "Episode: 917 meanReward: 292.4375 meanLoss: 38.0069 ExploreP: 0.0100\n",
      "Episode: 918 meanReward: 303.4688 meanLoss: 7.4911 ExploreP: 0.0100\n",
      "Episode: 919 meanReward: 313.9375 meanLoss: 14.9256 ExploreP: 0.0100\n",
      "Episode: 920 meanReward: 314.9375 meanLoss: 48.0953 ExploreP: 0.0100\n",
      "Episode: 921 meanReward: 313.5938 meanLoss: 232.4184 ExploreP: 0.0100\n",
      "Episode: 922 meanReward: 311.1250 meanLoss: 95.9113 ExploreP: 0.0100\n",
      "Episode: 923 meanReward: 326.0000 meanLoss: 10.6863 ExploreP: 0.0100\n",
      "Episode: 924 meanReward: 336.0625 meanLoss: 15.0674 ExploreP: 0.0100\n",
      "Episode: 925 meanReward: 321.6875 meanLoss: 147.3690 ExploreP: 0.0100\n",
      "Episode: 926 meanReward: 321.6875 meanLoss: 4.5764 ExploreP: 0.0100\n",
      "Episode: 927 meanReward: 319.8125 meanLoss: 20.5744 ExploreP: 0.0100\n",
      "Episode: 928 meanReward: 324.9375 meanLoss: 10.5927 ExploreP: 0.0100\n",
      "Episode: 929 meanReward: 324.9375 meanLoss: 18.5162 ExploreP: 0.0100\n",
      "Episode: 930 meanReward: 324.9375 meanLoss: 16.0938 ExploreP: 0.0100\n",
      "Episode: 931 meanReward: 327.9062 meanLoss: 16.9247 ExploreP: 0.0100\n",
      "Episode: 932 meanReward: 313.9688 meanLoss: 162.4744 ExploreP: 0.0100\n",
      "Episode: 933 meanReward: 301.7500 meanLoss: 200.9729 ExploreP: 0.0100\n",
      "Episode: 934 meanReward: 288.6875 meanLoss: 87.8016 ExploreP: 0.0100\n",
      "Episode: 935 meanReward: 274.2500 meanLoss: 129.5087 ExploreP: 0.0100\n",
      "Episode: 936 meanReward: 269.4688 meanLoss: 76.8497 ExploreP: 0.0100\n",
      "Episode: 937 meanReward: 270.3750 meanLoss: 52.8654 ExploreP: 0.0100\n",
      "Episode: 938 meanReward: 261.7500 meanLoss: 38.5268 ExploreP: 0.0100\n",
      "Episode: 939 meanReward: 260.4062 meanLoss: 6.0977 ExploreP: 0.0100\n",
      "Episode: 940 meanReward: 259.7812 meanLoss: 173.7729 ExploreP: 0.0100\n",
      "Episode: 941 meanReward: 263.8750 meanLoss: 38.5135 ExploreP: 0.0100\n",
      "Episode: 942 meanReward: 253.3750 meanLoss: 24.9129 ExploreP: 0.0100\n",
      "Episode: 943 meanReward: 239.5938 meanLoss: 42.4813 ExploreP: 0.0100\n",
      "Episode: 944 meanReward: 252.0000 meanLoss: 10.8333 ExploreP: 0.0100\n",
      "Episode: 945 meanReward: 267.1562 meanLoss: 12.6512 ExploreP: 0.0100\n",
      "Episode: 946 meanReward: 251.9062 meanLoss: 213.0469 ExploreP: 0.0100\n",
      "Episode: 947 meanReward: 246.3750 meanLoss: 374.3924 ExploreP: 0.0100\n",
      "Episode: 948 meanReward: 231.0312 meanLoss: 482.0865 ExploreP: 0.0100\n",
      "Episode: 949 meanReward: 227.3750 meanLoss: 426.6421 ExploreP: 0.0100\n",
      "Episode: 950 meanReward: 212.0625 meanLoss: 203.9822 ExploreP: 0.0100\n",
      "Episode: 951 meanReward: 196.7188 meanLoss: 186.9871 ExploreP: 0.0100\n",
      "Episode: 952 meanReward: 194.9375 meanLoss: 222.0652 ExploreP: 0.0100\n",
      "Episode: 953 meanReward: 198.8125 meanLoss: 65.9395 ExploreP: 0.0100\n",
      "Episode: 954 meanReward: 197.4062 meanLoss: 109.3489 ExploreP: 0.0100\n",
      "Episode: 955 meanReward: 194.6875 meanLoss: 12.9628 ExploreP: 0.0100\n",
      "Episode: 956 meanReward: 179.4062 meanLoss: 179.9002 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 957 meanReward: 180.1250 meanLoss: 119.2902 ExploreP: 0.0100\n",
      "Episode: 958 meanReward: 180.1250 meanLoss: 14.9621 ExploreP: 0.0100\n",
      "Episode: 959 meanReward: 182.0000 meanLoss: 13.3037 ExploreP: 0.0100\n",
      "Episode: 960 meanReward: 186.7812 meanLoss: 16.7106 ExploreP: 0.0100\n",
      "Episode: 961 meanReward: 186.7812 meanLoss: 17.9320 ExploreP: 0.0100\n",
      "Episode: 962 meanReward: 171.5312 meanLoss: 268.2022 ExploreP: 0.0100\n",
      "Episode: 963 meanReward: 157.3750 meanLoss: 144.1789 ExploreP: 0.0100\n",
      "Episode: 964 meanReward: 171.3125 meanLoss: 9.7695 ExploreP: 0.0100\n",
      "Episode: 965 meanReward: 186.4062 meanLoss: 14.5152 ExploreP: 0.0100\n",
      "Episode: 966 meanReward: 199.4688 meanLoss: 20.4714 ExploreP: 0.0100\n",
      "Episode: 967 meanReward: 213.9062 meanLoss: 19.4470 ExploreP: 0.0100\n",
      "Episode: 968 meanReward: 227.9062 meanLoss: 18.3419 ExploreP: 0.0100\n",
      "Episode: 969 meanReward: 228.0312 meanLoss: 146.9309 ExploreP: 0.0100\n",
      "Episode: 970 meanReward: 233.5312 meanLoss: 25.6430 ExploreP: 0.0100\n",
      "Episode: 971 meanReward: 221.4688 meanLoss: 108.4728 ExploreP: 0.0100\n",
      "Episode: 972 meanReward: 236.6562 meanLoss: 10.6966 ExploreP: 0.0100\n",
      "Episode: 973 meanReward: 232.6562 meanLoss: 211.9349 ExploreP: 0.0100\n",
      "Episode: 974 meanReward: 230.5938 meanLoss: 71.6613 ExploreP: 0.0100\n",
      "Episode: 975 meanReward: 229.4062 meanLoss: 155.5744 ExploreP: 0.0100\n",
      "Episode: 976 meanReward: 229.4062 meanLoss: 14.3297 ExploreP: 0.0100\n",
      "Episode: 977 meanReward: 221.3125 meanLoss: 26.3364 ExploreP: 0.0100\n",
      "Episode: 978 meanReward: 236.5625 meanLoss: 18.0187 ExploreP: 0.0100\n",
      "Episode: 979 meanReward: 251.8125 meanLoss: 15.7513 ExploreP: 0.0100\n",
      "Episode: 980 meanReward: 251.8438 meanLoss: 312.6602 ExploreP: 0.0100\n",
      "Episode: 981 meanReward: 253.0938 meanLoss: 167.4706 ExploreP: 0.0100\n",
      "Episode: 982 meanReward: 255.8438 meanLoss: 57.0927 ExploreP: 0.0100\n",
      "Episode: 983 meanReward: 257.8125 meanLoss: 74.9585 ExploreP: 0.0100\n",
      "Episode: 984 meanReward: 258.2500 meanLoss: 45.9202 ExploreP: 0.0100\n",
      "Episode: 985 meanReward: 256.9062 meanLoss: 16.8051 ExploreP: 0.0100\n",
      "Episode: 986 meanReward: 259.1875 meanLoss: 14.6152 ExploreP: 0.0100\n",
      "Episode: 987 meanReward: 249.2188 meanLoss: 12.8276 ExploreP: 0.0100\n",
      "Episode: 988 meanReward: 251.8125 meanLoss: 14.6425 ExploreP: 0.0100\n",
      "Episode: 989 meanReward: 253.6875 meanLoss: 8.2917 ExploreP: 0.0100\n",
      "Episode: 990 meanReward: 240.0000 meanLoss: 9.9140 ExploreP: 0.0100\n",
      "Episode: 991 meanReward: 224.9062 meanLoss: 23.2290 ExploreP: 0.0100\n",
      "Episode: 992 meanReward: 210.1250 meanLoss: 88.4212 ExploreP: 0.0100\n",
      "Episode: 993 meanReward: 195.0625 meanLoss: 30.2513 ExploreP: 0.0100\n",
      "Episode: 994 meanReward: 195.2188 meanLoss: 23.4516 ExploreP: 0.0100\n",
      "Episode: 995 meanReward: 194.1875 meanLoss: 89.7060 ExploreP: 0.0100\n",
      "Episode: 996 meanReward: 178.9062 meanLoss: 82.5010 ExploreP: 0.0100\n",
      "Episode: 997 meanReward: 163.6875 meanLoss: 115.4809 ExploreP: 0.0100\n",
      "Episode: 998 meanReward: 154.0000 meanLoss: 128.2546 ExploreP: 0.0100\n",
      "Episode: 999 meanReward: 139.7812 meanLoss: 228.3959 ExploreP: 0.0100\n",
      "Episode: 1000 meanReward: 124.7812 meanLoss: 192.3432 ExploreP: 0.0100\n",
      "Episode: 1001 meanReward: 123.3438 meanLoss: 160.6331 ExploreP: 0.0100\n",
      "Episode: 1002 meanReward: 116.5000 meanLoss: 122.6272 ExploreP: 0.0100\n",
      "Episode: 1003 meanReward: 120.9375 meanLoss: 24.1666 ExploreP: 0.0100\n",
      "Episode: 1004 meanReward: 106.4688 meanLoss: 37.4205 ExploreP: 0.0100\n",
      "Episode: 1005 meanReward: 106.7500 meanLoss: 178.0817 ExploreP: 0.0100\n",
      "Episode: 1006 meanReward: 104.1562 meanLoss: 233.2671 ExploreP: 0.0100\n",
      "Episode: 1007 meanReward: 104.0938 meanLoss: 154.6291 ExploreP: 0.0100\n",
      "Episode: 1008 meanReward: 91.9062 meanLoss: 37.3604 ExploreP: 0.0100\n",
      "Episode: 1009 meanReward: 88.3125 meanLoss: 39.9762 ExploreP: 0.0100\n",
      "Episode: 1010 meanReward: 78.7188 meanLoss: 21.7472 ExploreP: 0.0100\n",
      "Episode: 1011 meanReward: 63.9062 meanLoss: 222.2145 ExploreP: 0.0100\n",
      "Episode: 1012 meanReward: 69.0938 meanLoss: 38.2844 ExploreP: 0.0100\n",
      "Episode: 1013 meanReward: 75.5000 meanLoss: 24.6445 ExploreP: 0.0100\n",
      "Episode: 1014 meanReward: 78.3125 meanLoss: 12.1103 ExploreP: 0.0100\n",
      "Episode: 1015 meanReward: 91.6875 meanLoss: 1.5927 ExploreP: 0.0100\n",
      "Episode: 1016 meanReward: 104.4062 meanLoss: 14.3909 ExploreP: 0.0100\n",
      "Episode: 1017 meanReward: 116.9375 meanLoss: 14.2529 ExploreP: 0.0100\n",
      "Episode: 1018 meanReward: 115.0938 meanLoss: 259.6109 ExploreP: 0.0100\n",
      "Episode: 1019 meanReward: 115.0938 meanLoss: 53.3798 ExploreP: 0.0100\n",
      "Episode: 1020 meanReward: 127.7812 meanLoss: 8.0787 ExploreP: 0.0100\n",
      "Episode: 1021 meanReward: 139.5625 meanLoss: 14.0357 ExploreP: 0.0100\n",
      "Episode: 1022 meanReward: 153.2500 meanLoss: 13.3006 ExploreP: 0.0100\n",
      "Episode: 1023 meanReward: 168.3438 meanLoss: 15.3525 ExploreP: 0.0100\n",
      "Episode: 1024 meanReward: 183.1250 meanLoss: 18.0560 ExploreP: 0.0100\n",
      "Episode: 1025 meanReward: 198.1875 meanLoss: 18.1398 ExploreP: 0.0100\n",
      "Episode: 1026 meanReward: 213.2812 meanLoss: 16.1586 ExploreP: 0.0100\n",
      "Episode: 1027 meanReward: 213.1562 meanLoss: 268.5710 ExploreP: 0.0100\n",
      "Episode: 1028 meanReward: 214.0938 meanLoss: 285.0004 ExploreP: 0.0100\n",
      "Episode: 1029 meanReward: 216.3438 meanLoss: 57.8843 ExploreP: 0.0100\n",
      "Episode: 1030 meanReward: 211.6875 meanLoss: 75.0005 ExploreP: 0.0100\n",
      "Episode: 1031 meanReward: 213.3125 meanLoss: 29.0952 ExploreP: 0.0100\n",
      "Episode: 1032 meanReward: 216.1250 meanLoss: 27.2707 ExploreP: 0.0100\n",
      "Episode: 1033 meanReward: 220.0625 meanLoss: 15.1951 ExploreP: 0.0100\n",
      "Episode: 1034 meanReward: 220.6250 meanLoss: 60.0230 ExploreP: 0.0100\n",
      "Episode: 1035 meanReward: 214.8750 meanLoss: 86.8948 ExploreP: 0.0100\n",
      "Episode: 1036 meanReward: 216.8438 meanLoss: 25.8909 ExploreP: 0.0100\n",
      "Episode: 1037 meanReward: 221.9062 meanLoss: 10.7613 ExploreP: 0.0100\n",
      "Episode: 1038 meanReward: 224.0000 meanLoss: 33.4011 ExploreP: 0.0100\n",
      "Episode: 1039 meanReward: 226.5938 meanLoss: 26.9160 ExploreP: 0.0100\n",
      "Episode: 1040 meanReward: 226.8125 meanLoss: 18.3098 ExploreP: 0.0100\n",
      "Episode: 1041 meanReward: 226.2500 meanLoss: 19.0393 ExploreP: 0.0100\n",
      "Episode: 1042 meanReward: 223.9688 meanLoss: 15.4290 ExploreP: 0.0100\n",
      "Episode: 1043 meanReward: 227.4062 meanLoss: 9.8575 ExploreP: 0.0100\n",
      "Episode: 1044 meanReward: 227.6875 meanLoss: 11.7559 ExploreP: 0.0100\n",
      "Episode: 1045 meanReward: 220.1250 meanLoss: 197.5394 ExploreP: 0.0100\n",
      "Episode: 1046 meanReward: 214.8125 meanLoss: 296.1894 ExploreP: 0.0100\n",
      "Episode: 1047 meanReward: 199.7500 meanLoss: 194.9905 ExploreP: 0.0100\n",
      "Episode: 1048 meanReward: 187.5938 meanLoss: 36.1782 ExploreP: 0.0100\n",
      "Episode: 1049 meanReward: 178.2188 meanLoss: 10.3309 ExploreP: 0.0100\n",
      "Episode: 1050 meanReward: 183.6562 meanLoss: 15.1861 ExploreP: 0.0100\n",
      "Episode: 1051 meanReward: 186.6875 meanLoss: 3.9283 ExploreP: 0.0100\n",
      "Episode: 1052 meanReward: 184.8750 meanLoss: 2.0097 ExploreP: 0.0100\n",
      "Episode: 1053 meanReward: 175.1875 meanLoss: 19.5050 ExploreP: 0.0100\n",
      "Episode: 1054 meanReward: 163.7812 meanLoss: 41.7489 ExploreP: 0.0100\n",
      "Episode: 1055 meanReward: 149.0938 meanLoss: 213.8010 ExploreP: 0.0100\n",
      "Episode: 1056 meanReward: 136.0938 meanLoss: 38.2511 ExploreP: 0.0100\n",
      "Episode: 1057 meanReward: 124.0000 meanLoss: 9.3738 ExploreP: 0.0100\n",
      "Episode: 1058 meanReward: 115.0938 meanLoss: 8.1094 ExploreP: 0.0100\n",
      "Episode: 1059 meanReward: 115.8125 meanLoss: 152.3399 ExploreP: 0.0100\n",
      "Episode: 1060 meanReward: 117.6562 meanLoss: 32.9313 ExploreP: 0.0100\n",
      "Episode: 1061 meanReward: 120.9375 meanLoss: 11.4407 ExploreP: 0.0100\n",
      "Episode: 1062 meanReward: 135.2812 meanLoss: 7.9135 ExploreP: 0.0100\n",
      "Episode: 1063 meanReward: 136.0312 meanLoss: 60.5092 ExploreP: 0.0100\n",
      "Episode: 1064 meanReward: 148.2188 meanLoss: 2.0939 ExploreP: 0.0100\n",
      "Episode: 1065 meanReward: 145.2812 meanLoss: 140.6249 ExploreP: 0.0100\n",
      "Episode: 1066 meanReward: 148.4062 meanLoss: 32.1838 ExploreP: 0.0100\n",
      "Episode: 1067 meanReward: 163.1250 meanLoss: 3.0581 ExploreP: 0.0100\n",
      "Episode: 1068 meanReward: 175.6250 meanLoss: 14.4012 ExploreP: 0.0100\n",
      "Episode: 1069 meanReward: 185.5312 meanLoss: 15.9972 ExploreP: 0.0100\n",
      "Episode: 1070 meanReward: 198.5938 meanLoss: 16.5426 ExploreP: 0.0100\n",
      "Episode: 1071 meanReward: 197.0938 meanLoss: 114.2712 ExploreP: 0.0100\n",
      "Episode: 1072 meanReward: 198.1250 meanLoss: 21.0445 ExploreP: 0.0100\n",
      "Episode: 1073 meanReward: 210.3750 meanLoss: 11.0246 ExploreP: 0.0100\n",
      "Episode: 1074 meanReward: 207.4062 meanLoss: 314.5819 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1075 meanReward: 205.1562 meanLoss: 100.4093 ExploreP: 0.0100\n",
      "Episode: 1076 meanReward: 214.9688 meanLoss: 6.5108 ExploreP: 0.0100\n",
      "Episode: 1077 meanReward: 230.1562 meanLoss: 2.7333 ExploreP: 0.0100\n",
      "Episode: 1078 meanReward: 231.9375 meanLoss: 8.9237 ExploreP: 0.0100\n",
      "Episode: 1079 meanReward: 235.6250 meanLoss: 13.2548 ExploreP: 0.0100\n",
      "Episode: 1080 meanReward: 247.7812 meanLoss: 4.2318 ExploreP: 0.0100\n",
      "Episode: 1081 meanReward: 257.1562 meanLoss: 19.1651 ExploreP: 0.0100\n",
      "Episode: 1082 meanReward: 254.2812 meanLoss: 79.2887 ExploreP: 0.0100\n",
      "Episode: 1083 meanReward: 263.9375 meanLoss: 9.7117 ExploreP: 0.0100\n",
      "Episode: 1084 meanReward: 253.8750 meanLoss: 66.0561 ExploreP: 0.0100\n",
      "Episode: 1085 meanReward: 254.3438 meanLoss: 22.4412 ExploreP: 0.0100\n",
      "Episode: 1086 meanReward: 265.7500 meanLoss: 5.7132 ExploreP: 0.0100\n",
      "Episode: 1087 meanReward: 268.4688 meanLoss: 84.1380 ExploreP: 0.0100\n",
      "Episode: 1088 meanReward: 281.4688 meanLoss: 7.1483 ExploreP: 0.0100\n",
      "Episode: 1089 meanReward: 293.5625 meanLoss: 15.4749 ExploreP: 0.0100\n",
      "Episode: 1090 meanReward: 290.2188 meanLoss: 81.6797 ExploreP: 0.0100\n",
      "Episode: 1091 meanReward: 289.9375 meanLoss: 59.6744 ExploreP: 0.0100\n",
      "Episode: 1092 meanReward: 295.6875 meanLoss: 22.2828 ExploreP: 0.0100\n",
      "Episode: 1093 meanReward: 298.6562 meanLoss: 25.0278 ExploreP: 0.0100\n",
      "Episode: 1094 meanReward: 287.7500 meanLoss: 8.9298 ExploreP: 0.0100\n",
      "Episode: 1095 meanReward: 286.4688 meanLoss: 63.6274 ExploreP: 0.0100\n",
      "Episode: 1096 meanReward: 271.1875 meanLoss: 39.9877 ExploreP: 0.0100\n",
      "Episode: 1097 meanReward: 270.0625 meanLoss: 132.3477 ExploreP: 0.0100\n",
      "Episode: 1098 meanReward: 266.6562 meanLoss: 172.3866 ExploreP: 0.0100\n",
      "Episode: 1099 meanReward: 256.6562 meanLoss: 30.3056 ExploreP: 0.0100\n",
      "Episode: 1100 meanReward: 243.8125 meanLoss: 16.1618 ExploreP: 0.0100\n",
      "Episode: 1101 meanReward: 236.9062 meanLoss: 10.0159 ExploreP: 0.0100\n",
      "Episode: 1102 meanReward: 226.5938 meanLoss: 11.2274 ExploreP: 0.0100\n",
      "Episode: 1103 meanReward: 229.3438 meanLoss: 7.5646 ExploreP: 0.0100\n",
      "Episode: 1104 meanReward: 227.1250 meanLoss: 4.9566 ExploreP: 0.0100\n",
      "Episode: 1105 meanReward: 214.8438 meanLoss: 13.4511 ExploreP: 0.0100\n",
      "Episode: 1106 meanReward: 216.3438 meanLoss: 32.7937 ExploreP: 0.0100\n",
      "Episode: 1107 meanReward: 216.2812 meanLoss: 8.9443 ExploreP: 0.0100\n",
      "Episode: 1108 meanReward: 207.5000 meanLoss: 6.4562 ExploreP: 0.0100\n",
      "Episode: 1109 meanReward: 198.0000 meanLoss: 8.0994 ExploreP: 0.0100\n",
      "Episode: 1110 meanReward: 198.0000 meanLoss: 45.3663 ExploreP: 0.0100\n",
      "Episode: 1111 meanReward: 197.0312 meanLoss: 4.8575 ExploreP: 0.0100\n",
      "Episode: 1112 meanReward: 184.9062 meanLoss: 16.1129 ExploreP: 0.0100\n",
      "Episode: 1113 meanReward: 170.9062 meanLoss: 13.8012 ExploreP: 0.0100\n",
      "Episode: 1114 meanReward: 169.2188 meanLoss: 36.5872 ExploreP: 0.0100\n",
      "Episode: 1115 meanReward: 154.7812 meanLoss: 38.5432 ExploreP: 0.0100\n",
      "Episode: 1116 meanReward: 153.7188 meanLoss: 12.7135 ExploreP: 0.0100\n",
      "Episode: 1117 meanReward: 149.7500 meanLoss: 9.5048 ExploreP: 0.0100\n",
      "Episode: 1118 meanReward: 139.1250 meanLoss: 13.4332 ExploreP: 0.0100\n",
      "Episode: 1119 meanReward: 139.6875 meanLoss: 12.3840 ExploreP: 0.0100\n",
      "Episode: 1120 meanReward: 139.6875 meanLoss: 3.4705 ExploreP: 0.0100\n",
      "Episode: 1121 meanReward: 139.6875 meanLoss: 10.2761 ExploreP: 0.0100\n",
      "Episode: 1122 meanReward: 140.3438 meanLoss: 54.4188 ExploreP: 0.0100\n",
      "Episode: 1123 meanReward: 146.1875 meanLoss: 9.4690 ExploreP: 0.0100\n",
      "Episode: 1124 meanReward: 138.9062 meanLoss: 28.1991 ExploreP: 0.0100\n",
      "Episode: 1125 meanReward: 145.6250 meanLoss: 1.9630 ExploreP: 0.0100\n",
      "Episode: 1126 meanReward: 156.5312 meanLoss: 17.2476 ExploreP: 0.0100\n",
      "Episode: 1127 meanReward: 169.6562 meanLoss: 15.7137 ExploreP: 0.0100\n",
      "Episode: 1128 meanReward: 184.9375 meanLoss: 18.3745 ExploreP: 0.0100\n",
      "Episode: 1129 meanReward: 184.9688 meanLoss: 340.4023 ExploreP: 0.0100\n",
      "Episode: 1130 meanReward: 184.5625 meanLoss: 452.5977 ExploreP: 0.0100\n",
      "Episode: 1131 meanReward: 182.0312 meanLoss: 66.9174 ExploreP: 0.0100\n",
      "Episode: 1132 meanReward: 187.3438 meanLoss: 17.3814 ExploreP: 0.0100\n",
      "Episode: 1133 meanReward: 180.8750 meanLoss: 22.6820 ExploreP: 0.0100\n",
      "Episode: 1134 meanReward: 177.4688 meanLoss: 23.1160 ExploreP: 0.0100\n",
      "Episode: 1135 meanReward: 174.6250 meanLoss: 21.3425 ExploreP: 0.0100\n",
      "Episode: 1136 meanReward: 174.9688 meanLoss: 13.4711 ExploreP: 0.0100\n",
      "Episode: 1137 meanReward: 178.5625 meanLoss: 6.5038 ExploreP: 0.0100\n",
      "Episode: 1138 meanReward: 191.9062 meanLoss: 5.2901 ExploreP: 0.0100\n",
      "Episode: 1139 meanReward: 203.4062 meanLoss: 18.8791 ExploreP: 0.0100\n",
      "Episode: 1140 meanReward: 212.2188 meanLoss: 4.5551 ExploreP: 0.0100\n",
      "Episode: 1141 meanReward: 219.6562 meanLoss: 21.0833 ExploreP: 0.0100\n",
      "Episode: 1142 meanReward: 232.9375 meanLoss: 16.5401 ExploreP: 0.0100\n",
      "Episode: 1143 meanReward: 245.2812 meanLoss: 18.6069 ExploreP: 0.0100\n",
      "Episode: 1144 meanReward: 244.2500 meanLoss: 103.4050 ExploreP: 0.0100\n",
      "Episode: 1145 meanReward: 258.2500 meanLoss: 3.9615 ExploreP: 0.0100\n",
      "Episode: 1146 meanReward: 272.0625 meanLoss: 18.1465 ExploreP: 0.0100\n",
      "Episode: 1147 meanReward: 286.5000 meanLoss: 15.8971 ExploreP: 0.0100\n",
      "Episode: 1148 meanReward: 299.4375 meanLoss: 16.9173 ExploreP: 0.0100\n",
      "Episode: 1149 meanReward: 311.3125 meanLoss: 12.9906 ExploreP: 0.0100\n",
      "Episode: 1150 meanReward: 307.6562 meanLoss: 65.8438 ExploreP: 0.0100\n",
      "Episode: 1151 meanReward: 313.4688 meanLoss: 19.9476 ExploreP: 0.0100\n",
      "Episode: 1152 meanReward: 309.2500 meanLoss: 3.4523 ExploreP: 0.0100\n",
      "Episode: 1153 meanReward: 309.2500 meanLoss: 14.9510 ExploreP: 0.0100\n",
      "Episode: 1154 meanReward: 320.8438 meanLoss: 16.0436 ExploreP: 0.0100\n",
      "Episode: 1155 meanReward: 329.8750 meanLoss: 16.3352 ExploreP: 0.0100\n",
      "Episode: 1156 meanReward: 329.3125 meanLoss: 225.3451 ExploreP: 0.0100\n",
      "Episode: 1157 meanReward: 320.6562 meanLoss: 13.7804 ExploreP: 0.0100\n",
      "Episode: 1158 meanReward: 320.6562 meanLoss: 3.2478 ExploreP: 0.0100\n",
      "Episode: 1159 meanReward: 307.3438 meanLoss: 135.9640 ExploreP: 0.0100\n",
      "Episode: 1160 meanReward: 307.3438 meanLoss: 6.3878 ExploreP: 0.0100\n",
      "Episode: 1161 meanReward: 322.6250 meanLoss: 17.5497 ExploreP: 0.0100\n",
      "Episode: 1162 meanReward: 337.9062 meanLoss: 15.5046 ExploreP: 0.0100\n",
      "Episode: 1163 meanReward: 335.1250 meanLoss: 151.9059 ExploreP: 0.0100\n",
      "Episode: 1164 meanReward: 327.4062 meanLoss: 235.9936 ExploreP: 0.0100\n",
      "Episode: 1165 meanReward: 325.5000 meanLoss: 330.2182 ExploreP: 0.0100\n",
      "Episode: 1166 meanReward: 323.8750 meanLoss: 400.6043 ExploreP: 0.0100\n",
      "Episode: 1167 meanReward: 322.5625 meanLoss: 311.9701 ExploreP: 0.0100\n",
      "Episode: 1168 meanReward: 320.0312 meanLoss: 223.0662 ExploreP: 0.0100\n",
      "Episode: 1169 meanReward: 313.3750 meanLoss: 194.5280 ExploreP: 0.0100\n",
      "Episode: 1170 meanReward: 300.7188 meanLoss: 44.1911 ExploreP: 0.0100\n",
      "Episode: 1171 meanReward: 288.7188 meanLoss: 25.7905 ExploreP: 0.0100\n",
      "Episode: 1172 meanReward: 274.3750 meanLoss: 23.5799 ExploreP: 0.0100\n",
      "Episode: 1173 meanReward: 263.6562 meanLoss: 14.5747 ExploreP: 0.0100\n",
      "Episode: 1174 meanReward: 251.3125 meanLoss: 13.3823 ExploreP: 0.0100\n",
      "Episode: 1175 meanReward: 239.0312 meanLoss: 13.4543 ExploreP: 0.0100\n",
      "Episode: 1176 meanReward: 240.2188 meanLoss: 16.3551 ExploreP: 0.0100\n",
      "Episode: 1177 meanReward: 229.2500 meanLoss: 12.4400 ExploreP: 0.0100\n",
      "Episode: 1178 meanReward: 224.1250 meanLoss: 14.0775 ExploreP: 0.0100\n",
      "Episode: 1179 meanReward: 224.1250 meanLoss: 4.1451 ExploreP: 0.0100\n",
      "Episode: 1180 meanReward: 224.1250 meanLoss: 19.3153 ExploreP: 0.0100\n",
      "Episode: 1181 meanReward: 225.4375 meanLoss: 17.5430 ExploreP: 0.0100\n",
      "Episode: 1182 meanReward: 239.7188 meanLoss: 12.6479 ExploreP: 0.0100\n",
      "Episode: 1183 meanReward: 237.4688 meanLoss: 32.4809 ExploreP: 0.0100\n",
      "Episode: 1184 meanReward: 227.6562 meanLoss: 80.1704 ExploreP: 0.0100\n",
      "Episode: 1185 meanReward: 219.0312 meanLoss: 21.4842 ExploreP: 0.0100\n",
      "Episode: 1186 meanReward: 208.4688 meanLoss: 14.8111 ExploreP: 0.0100\n",
      "Episode: 1187 meanReward: 195.6875 meanLoss: 16.9948 ExploreP: 0.0100\n",
      "Episode: 1188 meanReward: 199.0312 meanLoss: 17.1539 ExploreP: 0.0100\n",
      "Episode: 1189 meanReward: 197.1562 meanLoss: 10.1751 ExploreP: 0.0100\n",
      "Episode: 1190 meanReward: 183.5312 meanLoss: 19.4685 ExploreP: 0.0100\n",
      "Episode: 1191 meanReward: 181.5625 meanLoss: 209.2061 ExploreP: 0.0100\n",
      "Episode: 1192 meanReward: 166.2812 meanLoss: 365.6680 ExploreP: 0.0100\n",
      "Episode: 1193 meanReward: 150.9375 meanLoss: 519.3547 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1194 meanReward: 135.5938 meanLoss: 417.9171 ExploreP: 0.0100\n",
      "Episode: 1195 meanReward: 135.5625 meanLoss: 255.5517 ExploreP: 0.0100\n",
      "Episode: 1196 meanReward: 135.4688 meanLoss: 146.4176 ExploreP: 0.0100\n",
      "Episode: 1197 meanReward: 135.4062 meanLoss: 135.9315 ExploreP: 0.0100\n",
      "Episode: 1198 meanReward: 137.2812 meanLoss: 44.6241 ExploreP: 0.0100\n",
      "Episode: 1199 meanReward: 137.5000 meanLoss: 46.1587 ExploreP: 0.0100\n",
      "Episode: 1200 meanReward: 138.1562 meanLoss: 60.4475 ExploreP: 0.0100\n",
      "Episode: 1201 meanReward: 140.9688 meanLoss: 16.4328 ExploreP: 0.0100\n",
      "Episode: 1202 meanReward: 146.7812 meanLoss: 6.8385 ExploreP: 0.0100\n",
      "Episode: 1203 meanReward: 160.9688 meanLoss: 5.1258 ExploreP: 0.0100\n",
      "Episode: 1204 meanReward: 166.7188 meanLoss: 27.7751 ExploreP: 0.0100\n",
      "Episode: 1205 meanReward: 170.5312 meanLoss: 22.4223 ExploreP: 0.0100\n",
      "Episode: 1206 meanReward: 174.7500 meanLoss: 21.9064 ExploreP: 0.0100\n",
      "Episode: 1207 meanReward: 181.3750 meanLoss: 15.3560 ExploreP: 0.0100\n",
      "Episode: 1208 meanReward: 185.8438 meanLoss: 18.8818 ExploreP: 0.0100\n",
      "Episode: 1209 meanReward: 187.1875 meanLoss: 24.5458 ExploreP: 0.0100\n",
      "Episode: 1210 meanReward: 183.4375 meanLoss: 23.8384 ExploreP: 0.0100\n",
      "Episode: 1211 meanReward: 170.5625 meanLoss: 27.0130 ExploreP: 0.0100\n",
      "Episode: 1212 meanReward: 159.7188 meanLoss: 6.1741 ExploreP: 0.0100\n",
      "Episode: 1213 meanReward: 150.2812 meanLoss: 11.9259 ExploreP: 0.0100\n",
      "Episode: 1214 meanReward: 137.4375 meanLoss: 44.2158 ExploreP: 0.0100\n",
      "Episode: 1215 meanReward: 133.3438 meanLoss: 30.1195 ExploreP: 0.0100\n",
      "Episode: 1216 meanReward: 136.7500 meanLoss: 9.8702 ExploreP: 0.0100\n",
      "Episode: 1217 meanReward: 130.2812 meanLoss: 21.4001 ExploreP: 0.0100\n",
      "Episode: 1218 meanReward: 126.0625 meanLoss: 164.6294 ExploreP: 0.0100\n",
      "Episode: 1219 meanReward: 138.8438 meanLoss: 5.1553 ExploreP: 0.0100\n",
      "Episode: 1220 meanReward: 147.0000 meanLoss: 19.4554 ExploreP: 0.0100\n",
      "Episode: 1221 meanReward: 145.3750 meanLoss: 11.3971 ExploreP: 0.0100\n",
      "Episode: 1222 meanReward: 159.0000 meanLoss: 7.9275 ExploreP: 0.0100\n",
      "Episode: 1223 meanReward: 163.5312 meanLoss: 35.4710 ExploreP: 0.0100\n",
      "Episode: 1224 meanReward: 170.2500 meanLoss: 15.3541 ExploreP: 0.0100\n",
      "Episode: 1225 meanReward: 173.5938 meanLoss: 39.9995 ExploreP: 0.0100\n",
      "Episode: 1226 meanReward: 178.5000 meanLoss: 8.0039 ExploreP: 0.0100\n",
      "Episode: 1227 meanReward: 185.0625 meanLoss: 9.9395 ExploreP: 0.0100\n",
      "Episode: 1228 meanReward: 189.4375 meanLoss: 15.2925 ExploreP: 0.0100\n",
      "Episode: 1229 meanReward: 204.7812 meanLoss: 5.0298 ExploreP: 0.0100\n",
      "Episode: 1230 meanReward: 218.2500 meanLoss: 17.0109 ExploreP: 0.0100\n",
      "Episode: 1231 meanReward: 224.4062 meanLoss: 20.4954 ExploreP: 0.0100\n",
      "Episode: 1232 meanReward: 228.1562 meanLoss: 7.7868 ExploreP: 0.0100\n",
      "Episode: 1233 meanReward: 230.0000 meanLoss: 5.1368 ExploreP: 0.0100\n",
      "Episode: 1234 meanReward: 225.7812 meanLoss: 7.5018 ExploreP: 0.0100\n",
      "Episode: 1235 meanReward: 216.4062 meanLoss: 13.4443 ExploreP: 0.0100\n",
      "Episode: 1236 meanReward: 220.0312 meanLoss: 8.5299 ExploreP: 0.0100\n",
      "Episode: 1237 meanReward: 220.4062 meanLoss: 8.3731 ExploreP: 0.0100\n",
      "Episode: 1238 meanReward: 218.1250 meanLoss: 11.5248 ExploreP: 0.0100\n",
      "Episode: 1239 meanReward: 223.7812 meanLoss: 2.4903 ExploreP: 0.0100\n",
      "Episode: 1240 meanReward: 231.2812 meanLoss: 16.8166 ExploreP: 0.0100\n",
      "Episode: 1241 meanReward: 226.4688 meanLoss: 287.0840 ExploreP: 0.0100\n",
      "Episode: 1242 meanReward: 235.3438 meanLoss: 6.8456 ExploreP: 0.0100\n",
      "Episode: 1243 meanReward: 248.2188 meanLoss: 3.5272 ExploreP: 0.0100\n",
      "Episode: 1244 meanReward: 244.4688 meanLoss: 278.4745 ExploreP: 0.0100\n",
      "Episode: 1245 meanReward: 253.9062 meanLoss: 6.3947 ExploreP: 0.0100\n",
      "Episode: 1246 meanReward: 266.7500 meanLoss: 18.9793 ExploreP: 0.0100\n",
      "Episode: 1247 meanReward: 278.6875 meanLoss: 15.7336 ExploreP: 0.0100\n",
      "Episode: 1248 meanReward: 289.3125 meanLoss: 15.7057 ExploreP: 0.0100\n",
      "Episode: 1249 meanReward: 304.4062 meanLoss: 15.2921 ExploreP: 0.0100\n",
      "Episode: 1250 meanReward: 319.1875 meanLoss: 16.2224 ExploreP: 0.0100\n",
      "Episode: 1251 meanReward: 319.1875 meanLoss: 15.2311 ExploreP: 0.0100\n",
      "Episode: 1252 meanReward: 308.3438 meanLoss: 130.9644 ExploreP: 0.0100\n",
      "Episode: 1253 meanReward: 320.5000 meanLoss: 3.1908 ExploreP: 0.0100\n",
      "Episode: 1254 meanReward: 319.2500 meanLoss: 19.3027 ExploreP: 0.0100\n",
      "Episode: 1255 meanReward: 315.5000 meanLoss: 34.9335 ExploreP: 0.0100\n",
      "Episode: 1256 meanReward: 308.8125 meanLoss: 42.2062 ExploreP: 0.0100\n",
      "Episode: 1257 meanReward: 305.5312 meanLoss: 89.3136 ExploreP: 0.0100\n",
      "Episode: 1258 meanReward: 315.9688 meanLoss: 13.0195 ExploreP: 0.0100\n",
      "Episode: 1259 meanReward: 313.0938 meanLoss: 69.5891 ExploreP: 0.0100\n",
      "Episode: 1260 meanReward: 324.0625 meanLoss: 1.8398 ExploreP: 0.0100\n",
      "Episode: 1261 meanReward: 324.0625 meanLoss: 14.9202 ExploreP: 0.0100\n",
      "Episode: 1262 meanReward: 310.9688 meanLoss: 97.8117 ExploreP: 0.0100\n",
      "Episode: 1263 meanReward: 307.8125 meanLoss: 23.7496 ExploreP: 0.0100\n",
      "Episode: 1264 meanReward: 318.7500 meanLoss: 4.3808 ExploreP: 0.0100\n",
      "Episode: 1265 meanReward: 329.4375 meanLoss: 17.6455 ExploreP: 0.0100\n",
      "Episode: 1266 meanReward: 340.5000 meanLoss: 18.5157 ExploreP: 0.0100\n",
      "Episode: 1267 meanReward: 349.8750 meanLoss: 19.3668 ExploreP: 0.0100\n",
      "Episode: 1268 meanReward: 354.8438 meanLoss: 16.3433 ExploreP: 0.0100\n",
      "Episode: 1269 meanReward: 363.4688 meanLoss: 18.1477 ExploreP: 0.0100\n",
      "Episode: 1270 meanReward: 373.8750 meanLoss: 15.7591 ExploreP: 0.0100\n",
      "Episode: 1271 meanReward: 373.8750 meanLoss: 15.6248 ExploreP: 0.0100\n",
      "Episode: 1272 meanReward: 373.8750 meanLoss: 15.0781 ExploreP: 0.0100\n",
      "Episode: 1273 meanReward: 388.3125 meanLoss: 14.3213 ExploreP: 0.0100\n",
      "Episode: 1274 meanReward: 388.3125 meanLoss: 13.1381 ExploreP: 0.0100\n",
      "Episode: 1275 meanReward: 388.3125 meanLoss: 12.7206 ExploreP: 0.0100\n",
      "Episode: 1276 meanReward: 402.9062 meanLoss: 18.7877 ExploreP: 0.0100\n",
      "Episode: 1277 meanReward: 402.9062 meanLoss: 18.4917 ExploreP: 0.0100\n",
      "Episode: 1278 meanReward: 387.5625 meanLoss: 272.9053 ExploreP: 0.0100\n",
      "Episode: 1279 meanReward: 373.4062 meanLoss: 96.3998 ExploreP: 0.0100\n",
      "Episode: 1280 meanReward: 361.6875 meanLoss: 25.6919 ExploreP: 0.0100\n",
      "Episode: 1281 meanReward: 349.0625 meanLoss: 41.2610 ExploreP: 0.0100\n",
      "Episode: 1282 meanReward: 334.0625 meanLoss: 171.2025 ExploreP: 0.0100\n",
      "Episode: 1283 meanReward: 322.2812 meanLoss: 59.6226 ExploreP: 0.0100\n",
      "Episode: 1284 meanReward: 324.2500 meanLoss: 36.0744 ExploreP: 0.0100\n",
      "Episode: 1285 meanReward: 312.0312 meanLoss: 40.6997 ExploreP: 0.0100\n",
      "Episode: 1286 meanReward: 301.1250 meanLoss: 22.4348 ExploreP: 0.0100\n",
      "Episode: 1287 meanReward: 304.2812 meanLoss: 13.3340 ExploreP: 0.0100\n",
      "Episode: 1288 meanReward: 308.2812 meanLoss: 11.3775 ExploreP: 0.0100\n",
      "Episode: 1289 meanReward: 314.2500 meanLoss: 9.2207 ExploreP: 0.0100\n",
      "Episode: 1290 meanReward: 304.5312 meanLoss: 29.5802 ExploreP: 0.0100\n",
      "Episode: 1291 meanReward: 305.7188 meanLoss: 31.7560 ExploreP: 0.0100\n",
      "Episode: 1292 meanReward: 299.1250 meanLoss: 14.2897 ExploreP: 0.0100\n",
      "Episode: 1293 meanReward: 286.4688 meanLoss: 16.4378 ExploreP: 0.0100\n",
      "Episode: 1294 meanReward: 299.5625 meanLoss: 14.4911 ExploreP: 0.0100\n",
      "Episode: 1295 meanReward: 300.8438 meanLoss: 39.4340 ExploreP: 0.0100\n",
      "Episode: 1296 meanReward: 290.4688 meanLoss: 50.8943 ExploreP: 0.0100\n",
      "Episode: 1297 meanReward: 284.3438 meanLoss: 23.7153 ExploreP: 0.0100\n",
      "Episode: 1298 meanReward: 279.3125 meanLoss: 17.1623 ExploreP: 0.0100\n",
      "Episode: 1299 meanReward: 279.3125 meanLoss: 6.4196 ExploreP: 0.0100\n",
      "Episode: 1300 meanReward: 279.3125 meanLoss: 18.6887 ExploreP: 0.0100\n",
      "Episode: 1301 meanReward: 279.3125 meanLoss: 13.4949 ExploreP: 0.0100\n",
      "Episode: 1302 meanReward: 279.3125 meanLoss: 16.8778 ExploreP: 0.0100\n",
      "Episode: 1303 meanReward: 264.4062 meanLoss: 236.8034 ExploreP: 0.0100\n",
      "Episode: 1304 meanReward: 249.2812 meanLoss: 298.3164 ExploreP: 0.0100\n",
      "Episode: 1305 meanReward: 234.3438 meanLoss: 240.9005 ExploreP: 0.0100\n",
      "Episode: 1306 meanReward: 221.0312 meanLoss: 40.5139 ExploreP: 0.0100\n",
      "Episode: 1307 meanReward: 209.3438 meanLoss: 12.4256 ExploreP: 0.0100\n",
      "Episode: 1308 meanReward: 196.5312 meanLoss: 7.8982 ExploreP: 0.0100\n",
      "Episode: 1309 meanReward: 183.1250 meanLoss: 17.5832 ExploreP: 0.0100\n",
      "Episode: 1310 meanReward: 183.1875 meanLoss: 217.5976 ExploreP: 0.0100\n",
      "Episode: 1311 meanReward: 185.6562 meanLoss: 53.1442 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1312 meanReward: 185.0312 meanLoss: 11.0932 ExploreP: 0.0100\n",
      "Episode: 1313 meanReward: 184.6250 meanLoss: 8.0671 ExploreP: 0.0100\n",
      "Episode: 1314 meanReward: 196.6875 meanLoss: 4.3436 ExploreP: 0.0100\n",
      "Episode: 1315 meanReward: 194.0938 meanLoss: 77.9000 ExploreP: 0.0100\n",
      "Episode: 1316 meanReward: 194.0938 meanLoss: 46.9747 ExploreP: 0.0100\n",
      "Episode: 1317 meanReward: 195.3125 meanLoss: 33.9729 ExploreP: 0.0100\n",
      "Episode: 1318 meanReward: 200.1250 meanLoss: 22.4729 ExploreP: 0.0100\n",
      "Episode: 1319 meanReward: 200.1562 meanLoss: 39.6115 ExploreP: 0.0100\n",
      "Episode: 1320 meanReward: 199.6250 meanLoss: 39.2698 ExploreP: 0.0100\n",
      "Episode: 1321 meanReward: 194.6250 meanLoss: 21.6056 ExploreP: 0.0100\n",
      "Episode: 1322 meanReward: 198.7812 meanLoss: 21.6025 ExploreP: 0.0100\n",
      "Episode: 1323 meanReward: 199.2500 meanLoss: 25.4117 ExploreP: 0.0100\n",
      "Episode: 1324 meanReward: 203.7500 meanLoss: 6.7156 ExploreP: 0.0100\n",
      "Episode: 1325 meanReward: 201.1250 meanLoss: 258.9597 ExploreP: 0.0100\n",
      "Episode: 1326 meanReward: 201.1250 meanLoss: 11.5260 ExploreP: 0.0100\n",
      "Episode: 1327 meanReward: 205.4375 meanLoss: 19.1393 ExploreP: 0.0100\n",
      "Episode: 1328 meanReward: 209.3125 meanLoss: 28.3408 ExploreP: 0.0100\n",
      "Episode: 1329 meanReward: 204.1250 meanLoss: 56.0755 ExploreP: 0.0100\n",
      "Episode: 1330 meanReward: 194.5000 meanLoss: 224.5316 ExploreP: 0.0100\n",
      "Episode: 1331 meanReward: 179.3438 meanLoss: 209.8828 ExploreP: 0.0100\n",
      "Episode: 1332 meanReward: 167.0625 meanLoss: 49.1838 ExploreP: 0.0100\n",
      "Episode: 1333 meanReward: 167.0625 meanLoss: 10.6569 ExploreP: 0.0100\n",
      "Episode: 1334 meanReward: 151.8125 meanLoss: 216.1674 ExploreP: 0.0100\n",
      "Episode: 1335 meanReward: 153.3750 meanLoss: 91.0124 ExploreP: 0.0100\n",
      "Episode: 1336 meanReward: 153.6562 meanLoss: 216.3273 ExploreP: 0.0100\n",
      "Episode: 1337 meanReward: 156.2188 meanLoss: 66.7369 ExploreP: 0.0100\n",
      "Episode: 1338 meanReward: 156.7188 meanLoss: 17.6930 ExploreP: 0.0100\n",
      "Episode: 1339 meanReward: 154.9062 meanLoss: 35.8371 ExploreP: 0.0100\n",
      "Episode: 1340 meanReward: 154.5312 meanLoss: 34.9868 ExploreP: 0.0100\n",
      "Episode: 1341 meanReward: 154.7500 meanLoss: 21.4708 ExploreP: 0.0100\n",
      "Episode: 1342 meanReward: 158.8438 meanLoss: 9.0634 ExploreP: 0.0100\n",
      "Episode: 1343 meanReward: 157.6562 meanLoss: 3.9511 ExploreP: 0.0100\n",
      "Episode: 1344 meanReward: 157.3750 meanLoss: 20.2794 ExploreP: 0.0100\n",
      "Episode: 1345 meanReward: 159.7812 meanLoss: 10.9342 ExploreP: 0.0100\n",
      "Episode: 1346 meanReward: 150.4688 meanLoss: 8.5392 ExploreP: 0.0100\n",
      "Episode: 1347 meanReward: 154.1562 meanLoss: 9.1409 ExploreP: 0.0100\n",
      "Episode: 1348 meanReward: 166.1250 meanLoss: 2.2946 ExploreP: 0.0100\n",
      "Episode: 1349 meanReward: 171.8438 meanLoss: 21.1679 ExploreP: 0.0100\n",
      "Episode: 1350 meanReward: 166.9062 meanLoss: 22.4228 ExploreP: 0.0100\n",
      "Episode: 1351 meanReward: 166.6875 meanLoss: 7.6579 ExploreP: 0.0100\n",
      "Episode: 1352 meanReward: 163.4688 meanLoss: 27.5343 ExploreP: 0.0100\n",
      "Episode: 1353 meanReward: 165.2500 meanLoss: 39.0786 ExploreP: 0.0100\n",
      "Episode: 1354 meanReward: 159.6250 meanLoss: 5.3641 ExploreP: 0.0100\n",
      "Episode: 1355 meanReward: 157.8750 meanLoss: 10.9975 ExploreP: 0.0100\n",
      "Episode: 1356 meanReward: 150.8438 meanLoss: 4.6734 ExploreP: 0.0100\n",
      "Episode: 1357 meanReward: 158.5000 meanLoss: 4.9284 ExploreP: 0.0100\n",
      "Episode: 1358 meanReward: 146.2188 meanLoss: 9.9046 ExploreP: 0.0100\n",
      "Episode: 1359 meanReward: 142.0000 meanLoss: 5.1507 ExploreP: 0.0100\n",
      "Episode: 1360 meanReward: 137.0625 meanLoss: 11.8406 ExploreP: 0.0100\n",
      "Episode: 1361 meanReward: 137.0312 meanLoss: 17.3711 ExploreP: 0.0100\n",
      "Episode: 1362 meanReward: 139.9375 meanLoss: 5.1053 ExploreP: 0.0100\n",
      "Episode: 1363 meanReward: 143.3750 meanLoss: 5.3684 ExploreP: 0.0100\n",
      "Episode: 1364 meanReward: 155.6562 meanLoss: 3.1856 ExploreP: 0.0100\n",
      "Episode: 1365 meanReward: 149.9375 meanLoss: 19.8258 ExploreP: 0.0100\n",
      "Episode: 1366 meanReward: 150.5000 meanLoss: 108.2591 ExploreP: 0.0100\n",
      "Episode: 1367 meanReward: 151.4062 meanLoss: 77.5096 ExploreP: 0.0100\n",
      "Episode: 1368 meanReward: 154.9688 meanLoss: 25.2523 ExploreP: 0.0100\n",
      "Episode: 1369 meanReward: 167.3438 meanLoss: 11.0623 ExploreP: 0.0100\n",
      "Episode: 1370 meanReward: 170.5000 meanLoss: 44.7153 ExploreP: 0.0100\n",
      "Episode: 1371 meanReward: 170.2188 meanLoss: 76.7136 ExploreP: 0.0100\n",
      "Episode: 1372 meanReward: 183.4062 meanLoss: 6.5957 ExploreP: 0.0100\n",
      "Episode: 1373 meanReward: 181.4062 meanLoss: 283.4530 ExploreP: 0.0100\n",
      "Episode: 1374 meanReward: 179.6875 meanLoss: 105.4523 ExploreP: 0.0100\n",
      "Episode: 1375 meanReward: 192.5625 meanLoss: 7.3846 ExploreP: 0.0100\n",
      "Episode: 1376 meanReward: 192.2188 meanLoss: 102.8273 ExploreP: 0.0100\n",
      "Episode: 1377 meanReward: 202.8438 meanLoss: 2.7402 ExploreP: 0.0100\n",
      "Episode: 1378 meanReward: 215.0938 meanLoss: 16.1090 ExploreP: 0.0100\n",
      "Episode: 1379 meanReward: 219.4688 meanLoss: 26.8256 ExploreP: 0.0100\n",
      "Episode: 1380 meanReward: 204.7812 meanLoss: 75.4269 ExploreP: 0.0100\n",
      "Episode: 1381 meanReward: 197.3125 meanLoss: 60.6193 ExploreP: 0.0100\n",
      "Episode: 1382 meanReward: 209.5938 meanLoss: 2.0381 ExploreP: 0.0100\n",
      "Episode: 1383 meanReward: 210.1875 meanLoss: 50.2352 ExploreP: 0.0100\n",
      "Episode: 1384 meanReward: 214.5000 meanLoss: 10.6798 ExploreP: 0.0100\n",
      "Episode: 1385 meanReward: 213.7500 meanLoss: 16.9149 ExploreP: 0.0100\n",
      "Episode: 1386 meanReward: 213.5312 meanLoss: 16.9388 ExploreP: 0.0100\n",
      "Episode: 1387 meanReward: 210.0938 meanLoss: 98.2303 ExploreP: 0.0100\n",
      "Episode: 1388 meanReward: 204.0312 meanLoss: 276.4096 ExploreP: 0.0100\n",
      "Episode: 1389 meanReward: 211.6562 meanLoss: 16.8684 ExploreP: 0.0100\n",
      "Episode: 1390 meanReward: 212.5000 meanLoss: 57.8763 ExploreP: 0.0100\n",
      "Episode: 1391 meanReward: 223.2500 meanLoss: 8.8091 ExploreP: 0.0100\n",
      "Episode: 1392 meanReward: 220.5625 meanLoss: 166.2874 ExploreP: 0.0100\n",
      "Episode: 1393 meanReward: 216.5625 meanLoss: 159.6482 ExploreP: 0.0100\n",
      "Episode: 1394 meanReward: 213.0625 meanLoss: 183.0308 ExploreP: 0.0100\n",
      "Episode: 1395 meanReward: 210.5938 meanLoss: 66.8428 ExploreP: 0.0100\n",
      "Episode: 1396 meanReward: 204.3438 meanLoss: 18.6081 ExploreP: 0.0100\n",
      "Episode: 1397 meanReward: 201.6562 meanLoss: 23.2328 ExploreP: 0.0100\n",
      "Episode: 1398 meanReward: 216.3438 meanLoss: 14.9597 ExploreP: 0.0100\n",
      "Episode: 1399 meanReward: 223.5625 meanLoss: 27.6903 ExploreP: 0.0100\n",
      "Episode: 1400 meanReward: 234.8438 meanLoss: 9.8450 ExploreP: 0.0100\n",
      "Episode: 1401 meanReward: 234.8438 meanLoss: 16.2887 ExploreP: 0.0100\n",
      "Episode: 1402 meanReward: 244.5000 meanLoss: 16.0357 ExploreP: 0.0100\n",
      "Episode: 1403 meanReward: 258.2812 meanLoss: 17.1560 ExploreP: 0.0100\n",
      "Episode: 1404 meanReward: 243.0000 meanLoss: 276.2008 ExploreP: 0.0100\n",
      "Episode: 1405 meanReward: 242.8750 meanLoss: 455.2501 ExploreP: 0.0100\n",
      "Episode: 1406 meanReward: 240.5625 meanLoss: 420.1925 ExploreP: 0.0100\n",
      "Episode: 1407 meanReward: 227.7500 meanLoss: 53.3606 ExploreP: 0.0100\n",
      "Episode: 1408 meanReward: 228.4062 meanLoss: 60.8023 ExploreP: 0.0100\n",
      "Episode: 1409 meanReward: 228.4062 meanLoss: 5.8006 ExploreP: 0.0100\n",
      "Episode: 1410 meanReward: 213.6562 meanLoss: 159.2271 ExploreP: 0.0100\n",
      "Episode: 1411 meanReward: 204.7188 meanLoss: 127.4889 ExploreP: 0.0100\n",
      "Episode: 1412 meanReward: 214.8750 meanLoss: 11.4227 ExploreP: 0.0100\n",
      "Episode: 1413 meanReward: 227.6250 meanLoss: 5.0974 ExploreP: 0.0100\n",
      "Episode: 1414 meanReward: 227.6250 meanLoss: 16.3295 ExploreP: 0.0100\n",
      "Episode: 1415 meanReward: 238.5625 meanLoss: 15.7975 ExploreP: 0.0100\n",
      "Episode: 1416 meanReward: 249.2500 meanLoss: 15.8409 ExploreP: 0.0100\n",
      "Episode: 1417 meanReward: 262.5312 meanLoss: 18.0171 ExploreP: 0.0100\n",
      "Episode: 1418 meanReward: 264.0000 meanLoss: 41.7809 ExploreP: 0.0100\n",
      "Episode: 1419 meanReward: 279.1875 meanLoss: 7.9923 ExploreP: 0.0100\n",
      "Episode: 1420 meanReward: 294.3750 meanLoss: 16.0472 ExploreP: 0.0100\n",
      "Episode: 1421 meanReward: 279.5312 meanLoss: 246.7629 ExploreP: 0.0100\n",
      "Episode: 1422 meanReward: 281.6250 meanLoss: 27.3602 ExploreP: 0.0100\n",
      "Episode: 1423 meanReward: 267.7188 meanLoss: 59.5628 ExploreP: 0.0100\n",
      "Episode: 1424 meanReward: 281.8438 meanLoss: 14.9417 ExploreP: 0.0100\n",
      "Episode: 1425 meanReward: 297.1562 meanLoss: 15.2780 ExploreP: 0.0100\n",
      "Episode: 1426 meanReward: 302.3438 meanLoss: 41.3978 ExploreP: 0.0100\n",
      "Episode: 1427 meanReward: 305.6562 meanLoss: 26.0601 ExploreP: 0.0100\n",
      "Episode: 1428 meanReward: 302.7812 meanLoss: 15.2314 ExploreP: 0.0100\n",
      "Episode: 1429 meanReward: 311.1875 meanLoss: 8.0894 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1430 meanReward: 298.8125 meanLoss: 71.3971 ExploreP: 0.0100\n",
      "Episode: 1431 meanReward: 304.0312 meanLoss: 7.9139 ExploreP: 0.0100\n",
      "Episode: 1432 meanReward: 294.1875 meanLoss: 41.1666 ExploreP: 0.0100\n",
      "Episode: 1433 meanReward: 284.8438 meanLoss: 12.6046 ExploreP: 0.0100\n",
      "Episode: 1434 meanReward: 271.3438 meanLoss: 32.5535 ExploreP: 0.0100\n",
      "Episode: 1435 meanReward: 256.6875 meanLoss: 178.3789 ExploreP: 0.0100\n",
      "Episode: 1436 meanReward: 259.0000 meanLoss: 29.0864 ExploreP: 0.0100\n",
      "Episode: 1437 meanReward: 259.6250 meanLoss: 196.5441 ExploreP: 0.0100\n",
      "Episode: 1438 meanReward: 274.8438 meanLoss: 7.2468 ExploreP: 0.0100\n",
      "Episode: 1439 meanReward: 273.5312 meanLoss: 94.7554 ExploreP: 0.0100\n",
      "Episode: 1440 meanReward: 285.8438 meanLoss: 9.0025 ExploreP: 0.0100\n",
      "Episode: 1441 meanReward: 285.8438 meanLoss: 16.7131 ExploreP: 0.0100\n",
      "Episode: 1442 meanReward: 291.3125 meanLoss: 42.7787 ExploreP: 0.0100\n",
      "Episode: 1443 meanReward: 306.5625 meanLoss: 12.6062 ExploreP: 0.0100\n",
      "Episode: 1444 meanReward: 299.9375 meanLoss: 53.8521 ExploreP: 0.0100\n",
      "Episode: 1445 meanReward: 299.9375 meanLoss: 7.0881 ExploreP: 0.0100\n",
      "Episode: 1446 meanReward: 287.8750 meanLoss: 68.3105 ExploreP: 0.0100\n",
      "Episode: 1447 meanReward: 287.8750 meanLoss: 13.2914 ExploreP: 0.0100\n",
      "Episode: 1448 meanReward: 287.8750 meanLoss: 15.6570 ExploreP: 0.0100\n",
      "Episode: 1449 meanReward: 287.8750 meanLoss: 15.9182 ExploreP: 0.0100\n",
      "Episode: 1450 meanReward: 297.8125 meanLoss: 15.7511 ExploreP: 0.0100\n",
      "Episode: 1451 meanReward: 283.1250 meanLoss: 256.3841 ExploreP: 0.0100\n",
      "Episode: 1452 meanReward: 268.5938 meanLoss: 164.6283 ExploreP: 0.0100\n",
      "Episode: 1453 meanReward: 271.3438 meanLoss: 21.2557 ExploreP: 0.0100\n",
      "Episode: 1454 meanReward: 280.6875 meanLoss: 10.2837 ExploreP: 0.0100\n",
      "Episode: 1455 meanReward: 289.8125 meanLoss: 22.1382 ExploreP: 0.0100\n",
      "Episode: 1456 meanReward: 289.8125 meanLoss: 5.9900 ExploreP: 0.0100\n",
      "Episode: 1457 meanReward: 289.8438 meanLoss: 16.2993 ExploreP: 0.0100\n",
      "Episode: 1458 meanReward: 299.9062 meanLoss: 15.6819 ExploreP: 0.0100\n",
      "Episode: 1459 meanReward: 304.0000 meanLoss: 28.6916 ExploreP: 0.0100\n",
      "Episode: 1460 meanReward: 313.1250 meanLoss: 5.7621 ExploreP: 0.0100\n",
      "Episode: 1461 meanReward: 300.7500 meanLoss: 64.0372 ExploreP: 0.0100\n",
      "Episode: 1462 meanReward: 302.0938 meanLoss: 27.9762 ExploreP: 0.0100\n",
      "Episode: 1463 meanReward: 302.0938 meanLoss: 4.9349 ExploreP: 0.0100\n",
      "Episode: 1464 meanReward: 297.3438 meanLoss: 249.4906 ExploreP: 0.0100\n",
      "Episode: 1465 meanReward: 306.6875 meanLoss: 5.0737 ExploreP: 0.0100\n",
      "Episode: 1466 meanReward: 316.0000 meanLoss: 24.0998 ExploreP: 0.0100\n",
      "Episode: 1467 meanReward: 330.6562 meanLoss: 13.5061 ExploreP: 0.0100\n",
      "Episode: 1468 meanReward: 343.6250 meanLoss: 15.9389 ExploreP: 0.0100\n",
      "Episode: 1469 meanReward: 358.3125 meanLoss: 16.0614 ExploreP: 0.0100\n",
      "Episode: 1470 meanReward: 346.9688 meanLoss: 61.4385 ExploreP: 0.0100\n",
      "Episode: 1471 meanReward: 361.0938 meanLoss: 3.4445 ExploreP: 0.0100\n",
      "Episode: 1472 meanReward: 361.0938 meanLoss: 16.2150 ExploreP: 0.0100\n",
      "Episode: 1473 meanReward: 361.0938 meanLoss: 16.5715 ExploreP: 0.0100\n",
      "Episode: 1474 meanReward: 366.4062 meanLoss: 20.4254 ExploreP: 0.0100\n",
      "Episode: 1475 meanReward: 356.0938 meanLoss: 33.0592 ExploreP: 0.0100\n",
      "Episode: 1476 meanReward: 367.2500 meanLoss: 15.6881 ExploreP: 0.0100\n",
      "Episode: 1477 meanReward: 352.2812 meanLoss: 241.9592 ExploreP: 0.0100\n",
      "Episode: 1478 meanReward: 364.3438 meanLoss: 13.4294 ExploreP: 0.0100\n",
      "Episode: 1479 meanReward: 364.3438 meanLoss: 14.4239 ExploreP: 0.0100\n",
      "Episode: 1480 meanReward: 352.5000 meanLoss: 57.9193 ExploreP: 0.0100\n",
      "Episode: 1481 meanReward: 338.0000 meanLoss: 152.6162 ExploreP: 0.0100\n",
      "Episode: 1482 meanReward: 338.0000 meanLoss: 6.4362 ExploreP: 0.0100\n",
      "Episode: 1483 meanReward: 352.6875 meanLoss: 15.4404 ExploreP: 0.0100\n",
      "Episode: 1484 meanReward: 367.2188 meanLoss: 14.9538 ExploreP: 0.0100\n",
      "Episode: 1485 meanReward: 373.8750 meanLoss: 23.1680 ExploreP: 0.0100\n",
      "Episode: 1486 meanReward: 366.3438 meanLoss: 22.8985 ExploreP: 0.0100\n",
      "Episode: 1487 meanReward: 356.0938 meanLoss: 81.9038 ExploreP: 0.0100\n",
      "Episode: 1488 meanReward: 340.9062 meanLoss: 279.1302 ExploreP: 0.0100\n",
      "Episode: 1489 meanReward: 325.5625 meanLoss: 384.3237 ExploreP: 0.0100\n",
      "Episode: 1490 meanReward: 312.8125 meanLoss: 46.6495 ExploreP: 0.0100\n",
      "Episode: 1491 meanReward: 305.7188 meanLoss: 18.9765 ExploreP: 0.0100\n",
      "Episode: 1492 meanReward: 291.8125 meanLoss: 125.6052 ExploreP: 0.0100\n",
      "Episode: 1493 meanReward: 292.1562 meanLoss: 46.7109 ExploreP: 0.0100\n",
      "Episode: 1494 meanReward: 300.5000 meanLoss: 3.1985 ExploreP: 0.0100\n",
      "Episode: 1495 meanReward: 288.0312 meanLoss: 39.5611 ExploreP: 0.0100\n",
      "Episode: 1496 meanReward: 290.7500 meanLoss: 6.6092 ExploreP: 0.0100\n",
      "Episode: 1497 meanReward: 279.6562 meanLoss: 4.6600 ExploreP: 0.0100\n",
      "Episode: 1498 meanReward: 272.8750 meanLoss: 11.1382 ExploreP: 0.0100\n",
      "Episode: 1499 meanReward: 262.2500 meanLoss: 10.0411 ExploreP: 0.0100\n",
      "Episode: 1500 meanReward: 250.1875 meanLoss: 17.5393 ExploreP: 0.0100\n",
      "Episode: 1501 meanReward: 237.9062 meanLoss: 20.4713 ExploreP: 0.0100\n",
      "Episode: 1502 meanReward: 235.6250 meanLoss: 39.2943 ExploreP: 0.0100\n",
      "Episode: 1503 meanReward: 222.9062 meanLoss: 28.3259 ExploreP: 0.0100\n",
      "Episode: 1504 meanReward: 209.8125 meanLoss: 25.3597 ExploreP: 0.0100\n",
      "Episode: 1505 meanReward: 198.0938 meanLoss: 9.6094 ExploreP: 0.0100\n",
      "Episode: 1506 meanReward: 187.0312 meanLoss: 46.3527 ExploreP: 0.0100\n",
      "Episode: 1507 meanReward: 185.5000 meanLoss: 18.1604 ExploreP: 0.0100\n",
      "Episode: 1508 meanReward: 176.8750 meanLoss: 5.3326 ExploreP: 0.0100\n",
      "Episode: 1509 meanReward: 178.5938 meanLoss: 29.8409 ExploreP: 0.0100\n",
      "Episode: 1510 meanReward: 170.0312 meanLoss: 4.1697 ExploreP: 0.0100\n",
      "Episode: 1511 meanReward: 159.5000 meanLoss: 10.7735 ExploreP: 0.0100\n",
      "Episode: 1512 meanReward: 158.3750 meanLoss: 23.0375 ExploreP: 0.0100\n",
      "Episode: 1513 meanReward: 160.5625 meanLoss: 7.5659 ExploreP: 0.0100\n",
      "Episode: 1514 meanReward: 149.5938 meanLoss: 10.6855 ExploreP: 0.0100\n",
      "Episode: 1515 meanReward: 136.5625 meanLoss: 14.7269 ExploreP: 0.0100\n",
      "Episode: 1516 meanReward: 122.1562 meanLoss: 65.9723 ExploreP: 0.0100\n",
      "Episode: 1517 meanReward: 114.6875 meanLoss: 29.8205 ExploreP: 0.0100\n",
      "Episode: 1518 meanReward: 109.5000 meanLoss: 24.6770 ExploreP: 0.0100\n",
      "Episode: 1519 meanReward: 114.9375 meanLoss: 6.6129 ExploreP: 0.0100\n",
      "Episode: 1520 meanReward: 122.1562 meanLoss: 5.1759 ExploreP: 0.0100\n",
      "Episode: 1521 meanReward: 128.9062 meanLoss: 9.3485 ExploreP: 0.0100\n",
      "Episode: 1522 meanReward: 132.5000 meanLoss: 8.3805 ExploreP: 0.0100\n",
      "Episode: 1523 meanReward: 134.3750 meanLoss: 16.7678 ExploreP: 0.0100\n",
      "Episode: 1524 meanReward: 148.2812 meanLoss: 3.1053 ExploreP: 0.0100\n",
      "Episode: 1525 meanReward: 160.3125 meanLoss: 2.9514 ExploreP: 0.0100\n",
      "Episode: 1526 meanReward: 150.7188 meanLoss: 85.2219 ExploreP: 0.0100\n",
      "Episode: 1527 meanReward: 152.2812 meanLoss: 13.7916 ExploreP: 0.0100\n",
      "Episode: 1528 meanReward: 164.1562 meanLoss: 10.6538 ExploreP: 0.0100\n",
      "Episode: 1529 meanReward: 163.6562 meanLoss: 60.8521 ExploreP: 0.0100\n",
      "Episode: 1530 meanReward: 160.8438 meanLoss: 44.8048 ExploreP: 0.0100\n",
      "Episode: 1531 meanReward: 159.9688 meanLoss: 17.1409 ExploreP: 0.0100\n",
      "Episode: 1532 meanReward: 172.0312 meanLoss: 2.7521 ExploreP: 0.0100\n",
      "Episode: 1533 meanReward: 184.3125 meanLoss: 17.2942 ExploreP: 0.0100\n",
      "Episode: 1534 meanReward: 197.9375 meanLoss: 16.3113 ExploreP: 0.0100\n",
      "Episode: 1535 meanReward: 210.6562 meanLoss: 5.2794 ExploreP: 0.0100\n",
      "Episode: 1536 meanReward: 223.7500 meanLoss: 16.6638 ExploreP: 0.0100\n",
      "Episode: 1537 meanReward: 235.4688 meanLoss: 15.8088 ExploreP: 0.0100\n",
      "Episode: 1538 meanReward: 250.5000 meanLoss: 18.6299 ExploreP: 0.0100\n",
      "Episode: 1539 meanReward: 247.6875 meanLoss: 208.8282 ExploreP: 0.0100\n",
      "Episode: 1540 meanReward: 252.3750 meanLoss: 20.1551 ExploreP: 0.0100\n",
      "Episode: 1541 meanReward: 258.2812 meanLoss: 23.0102 ExploreP: 0.0100\n",
      "Episode: 1542 meanReward: 265.0625 meanLoss: 8.9534 ExploreP: 0.0100\n",
      "Episode: 1543 meanReward: 275.5938 meanLoss: 9.3732 ExploreP: 0.0100\n",
      "Episode: 1544 meanReward: 276.8125 meanLoss: 74.8874 ExploreP: 0.0100\n",
      "Episode: 1545 meanReward: 280.3125 meanLoss: 7.7396 ExploreP: 0.0100\n",
      "Episode: 1546 meanReward: 281.4688 meanLoss: 6.3107 ExploreP: 0.0100\n",
      "Episode: 1547 meanReward: 282.2500 meanLoss: 20.4431 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1548 meanReward: 281.7812 meanLoss: 33.8270 ExploreP: 0.0100\n",
      "Episode: 1549 meanReward: 289.0000 meanLoss: 9.9575 ExploreP: 0.0100\n",
      "Episode: 1550 meanReward: 301.7188 meanLoss: 9.1671 ExploreP: 0.0100\n",
      "Episode: 1551 meanReward: 311.3125 meanLoss: 15.6439 ExploreP: 0.0100\n",
      "Episode: 1552 meanReward: 319.2812 meanLoss: 13.3422 ExploreP: 0.0100\n",
      "Episode: 1553 meanReward: 321.3125 meanLoss: 31.0437 ExploreP: 0.0100\n",
      "Episode: 1554 meanReward: 319.0938 meanLoss: 23.7841 ExploreP: 0.0100\n",
      "Episode: 1555 meanReward: 319.2188 meanLoss: 17.9856 ExploreP: 0.0100\n",
      "Episode: 1556 meanReward: 307.0625 meanLoss: 19.4357 ExploreP: 0.0100\n",
      "Episode: 1557 meanReward: 307.0625 meanLoss: 5.3387 ExploreP: 0.0100\n",
      "Episode: 1558 meanReward: 319.3438 meanLoss: 20.8012 ExploreP: 0.0100\n",
      "Episode: 1559 meanReward: 329.9062 meanLoss: 10.3260 ExploreP: 0.0100\n",
      "Episode: 1560 meanReward: 322.9062 meanLoss: 18.8689 ExploreP: 0.0100\n",
      "Episode: 1561 meanReward: 319.2500 meanLoss: 327.0603 ExploreP: 0.0100\n",
      "Episode: 1562 meanReward: 318.7188 meanLoss: 236.5054 ExploreP: 0.0100\n",
      "Episode: 1563 meanReward: 330.2188 meanLoss: 8.6501 ExploreP: 0.0100\n",
      "Episode: 1564 meanReward: 318.5625 meanLoss: 62.2573 ExploreP: 0.0100\n",
      "Episode: 1565 meanReward: 318.5625 meanLoss: 8.0059 ExploreP: 0.0100\n",
      "Episode: 1566 meanReward: 318.5625 meanLoss: 15.6934 ExploreP: 0.0100\n",
      "Episode: 1567 meanReward: 318.5625 meanLoss: 16.7266 ExploreP: 0.0100\n",
      "Episode: 1568 meanReward: 310.3125 meanLoss: 37.9356 ExploreP: 0.0100\n",
      "Episode: 1569 meanReward: 309.4688 meanLoss: 12.6191 ExploreP: 0.0100\n",
      "Episode: 1570 meanReward: 298.4375 meanLoss: 39.2243 ExploreP: 0.0100\n",
      "Episode: 1571 meanReward: 297.8438 meanLoss: 85.7188 ExploreP: 0.0100\n",
      "Episode: 1572 meanReward: 291.6250 meanLoss: 235.5161 ExploreP: 0.0100\n",
      "Episode: 1573 meanReward: 295.6875 meanLoss: 11.7900 ExploreP: 0.0100\n",
      "Episode: 1574 meanReward: 283.1562 meanLoss: 98.0342 ExploreP: 0.0100\n",
      "Episode: 1575 meanReward: 270.2500 meanLoss: 76.7663 ExploreP: 0.0100\n",
      "Episode: 1576 meanReward: 275.5312 meanLoss: 17.2713 ExploreP: 0.0100\n",
      "Episode: 1577 meanReward: 272.2500 meanLoss: 30.5353 ExploreP: 0.0100\n",
      "Episode: 1578 meanReward: 273.9688 meanLoss: 13.7389 ExploreP: 0.0100\n",
      "Episode: 1579 meanReward: 271.7812 meanLoss: 68.0011 ExploreP: 0.0100\n",
      "Episode: 1580 meanReward: 275.6250 meanLoss: 30.6981 ExploreP: 0.0100\n",
      "Episode: 1581 meanReward: 281.3125 meanLoss: 6.3765 ExploreP: 0.0100\n",
      "Episode: 1582 meanReward: 281.3125 meanLoss: 12.8892 ExploreP: 0.0100\n",
      "Episode: 1583 meanReward: 277.0625 meanLoss: 23.8130 ExploreP: 0.0100\n",
      "Episode: 1584 meanReward: 277.0625 meanLoss: 4.9974 ExploreP: 0.0100\n",
      "Episode: 1585 meanReward: 271.8125 meanLoss: 77.4790 ExploreP: 0.0100\n",
      "Episode: 1586 meanReward: 283.1875 meanLoss: 4.5648 ExploreP: 0.0100\n",
      "Episode: 1587 meanReward: 288.8438 meanLoss: 35.0561 ExploreP: 0.0100\n",
      "Episode: 1588 meanReward: 301.0000 meanLoss: 4.6956 ExploreP: 0.0100\n",
      "Episode: 1589 meanReward: 286.4062 meanLoss: 293.5217 ExploreP: 0.0100\n",
      "Episode: 1590 meanReward: 274.7500 meanLoss: 21.0506 ExploreP: 0.0100\n",
      "Episode: 1591 meanReward: 263.1562 meanLoss: 13.0769 ExploreP: 0.0100\n",
      "Episode: 1592 meanReward: 258.3125 meanLoss: 52.5820 ExploreP: 0.0100\n",
      "Episode: 1593 meanReward: 262.1875 meanLoss: 38.4805 ExploreP: 0.0100\n",
      "Episode: 1594 meanReward: 276.5000 meanLoss: 9.3721 ExploreP: 0.0100\n",
      "Episode: 1595 meanReward: 273.0312 meanLoss: 24.1481 ExploreP: 0.0100\n",
      "Episode: 1596 meanReward: 274.5938 meanLoss: 37.2746 ExploreP: 0.0100\n",
      "Episode: 1597 meanReward: 274.5938 meanLoss: 10.4460 ExploreP: 0.0100\n",
      "Episode: 1598 meanReward: 262.7188 meanLoss: 73.6671 ExploreP: 0.0100\n",
      "Episode: 1599 meanReward: 251.8125 meanLoss: 32.9793 ExploreP: 0.0100\n",
      "Episode: 1600 meanReward: 260.0625 meanLoss: 11.7226 ExploreP: 0.0100\n",
      "Episode: 1601 meanReward: 260.9062 meanLoss: 13.8044 ExploreP: 0.0100\n",
      "Episode: 1602 meanReward: 271.9375 meanLoss: 17.2601 ExploreP: 0.0100\n",
      "Episode: 1603 meanReward: 275.1562 meanLoss: 70.9403 ExploreP: 0.0100\n",
      "Episode: 1604 meanReward: 271.5938 meanLoss: 67.5365 ExploreP: 0.0100\n",
      "Episode: 1605 meanReward: 274.8750 meanLoss: 8.8117 ExploreP: 0.0100\n",
      "Episode: 1606 meanReward: 277.5625 meanLoss: 60.4492 ExploreP: 0.0100\n",
      "Episode: 1607 meanReward: 290.4688 meanLoss: 11.1157 ExploreP: 0.0100\n",
      "Episode: 1608 meanReward: 296.9375 meanLoss: 15.9300 ExploreP: 0.0100\n",
      "Episode: 1609 meanReward: 296.6562 meanLoss: 71.1290 ExploreP: 0.0100\n",
      "Episode: 1610 meanReward: 293.6562 meanLoss: 19.4226 ExploreP: 0.0100\n",
      "Episode: 1611 meanReward: 308.0938 meanLoss: 6.7310 ExploreP: 0.0100\n",
      "Episode: 1612 meanReward: 304.2812 meanLoss: 250.5493 ExploreP: 0.0100\n",
      "Episode: 1613 meanReward: 288.9688 meanLoss: 224.8971 ExploreP: 0.0100\n",
      "Episode: 1614 meanReward: 288.9688 meanLoss: 6.5719 ExploreP: 0.0100\n",
      "Episode: 1615 meanReward: 293.2188 meanLoss: 16.5394 ExploreP: 0.0100\n",
      "Episode: 1616 meanReward: 281.6875 meanLoss: 62.2076 ExploreP: 0.0100\n",
      "Episode: 1617 meanReward: 289.4375 meanLoss: 17.5025 ExploreP: 0.0100\n",
      "Episode: 1618 meanReward: 275.3750 meanLoss: 131.0431 ExploreP: 0.0100\n",
      "Episode: 1619 meanReward: 266.5312 meanLoss: 220.7839 ExploreP: 0.0100\n",
      "Episode: 1620 meanReward: 254.8438 meanLoss: 43.5261 ExploreP: 0.0100\n",
      "Episode: 1621 meanReward: 269.4375 meanLoss: 7.5112 ExploreP: 0.0100\n",
      "Episode: 1622 meanReward: 274.6562 meanLoss: 26.9055 ExploreP: 0.0100\n",
      "Episode: 1623 meanReward: 276.1562 meanLoss: 41.7155 ExploreP: 0.0100\n",
      "Episode: 1624 meanReward: 275.0625 meanLoss: 62.1200 ExploreP: 0.0100\n",
      "Episode: 1625 meanReward: 273.5312 meanLoss: 51.8238 ExploreP: 0.0100\n",
      "Episode: 1626 meanReward: 259.0312 meanLoss: 102.8794 ExploreP: 0.0100\n",
      "Episode: 1627 meanReward: 249.7812 meanLoss: 64.0681 ExploreP: 0.0100\n",
      "Episode: 1628 meanReward: 247.1250 meanLoss: 20.3355 ExploreP: 0.0100\n",
      "Episode: 1629 meanReward: 232.7812 meanLoss: 44.9270 ExploreP: 0.0100\n",
      "Episode: 1630 meanReward: 230.1875 meanLoss: 129.0689 ExploreP: 0.0100\n",
      "Episode: 1631 meanReward: 226.4062 meanLoss: 133.1776 ExploreP: 0.0100\n",
      "Episode: 1632 meanReward: 211.8125 meanLoss: 107.2701 ExploreP: 0.0100\n",
      "Episode: 1633 meanReward: 199.8125 meanLoss: 14.6360 ExploreP: 0.0100\n",
      "Episode: 1634 meanReward: 187.8750 meanLoss: 9.1132 ExploreP: 0.0100\n",
      "Episode: 1635 meanReward: 188.0000 meanLoss: 8.7312 ExploreP: 0.0100\n",
      "Episode: 1636 meanReward: 189.5000 meanLoss: 12.7803 ExploreP: 0.0100\n",
      "Episode: 1637 meanReward: 177.1875 meanLoss: 9.2917 ExploreP: 0.0100\n",
      "Episode: 1638 meanReward: 176.0938 meanLoss: 14.2475 ExploreP: 0.0100\n",
      "Episode: 1639 meanReward: 163.6562 meanLoss: 12.1681 ExploreP: 0.0100\n",
      "Episode: 1640 meanReward: 150.1875 meanLoss: 12.7743 ExploreP: 0.0100\n",
      "Episode: 1641 meanReward: 148.5000 meanLoss: 43.6222 ExploreP: 0.0100\n",
      "Episode: 1642 meanReward: 147.0938 meanLoss: 14.7729 ExploreP: 0.0100\n",
      "Episode: 1643 meanReward: 134.9062 meanLoss: 9.7541 ExploreP: 0.0100\n",
      "Episode: 1644 meanReward: 140.0938 meanLoss: 10.0912 ExploreP: 0.0100\n",
      "Episode: 1645 meanReward: 145.4688 meanLoss: 8.4734 ExploreP: 0.0100\n",
      "Episode: 1646 meanReward: 132.2188 meanLoss: 14.4942 ExploreP: 0.0100\n",
      "Episode: 1647 meanReward: 120.0938 meanLoss: 6.6241 ExploreP: 0.0100\n",
      "Episode: 1648 meanReward: 119.7188 meanLoss: 5.2306 ExploreP: 0.0100\n",
      "Episode: 1649 meanReward: 111.5625 meanLoss: 5.5316 ExploreP: 0.0100\n",
      "Episode: 1650 meanReward: 113.3438 meanLoss: 5.7602 ExploreP: 0.0100\n",
      "Episode: 1651 meanReward: 114.8438 meanLoss: 7.4110 ExploreP: 0.0100\n",
      "Episode: 1652 meanReward: 113.4375 meanLoss: 16.8482 ExploreP: 0.0100\n",
      "Episode: 1653 meanReward: 100.5312 meanLoss: 6.0329 ExploreP: 0.0100\n",
      "Episode: 1654 meanReward: 94.2500 meanLoss: 4.6265 ExploreP: 0.0100\n",
      "Episode: 1655 meanReward: 91.9688 meanLoss: 3.8922 ExploreP: 0.0100\n",
      "Episode: 1656 meanReward: 92.3750 meanLoss: 4.6066 ExploreP: 0.0100\n",
      "Episode: 1657 meanReward: 92.3438 meanLoss: 13.1468 ExploreP: 0.0100\n",
      "Episode: 1658 meanReward: 92.3438 meanLoss: 10.8994 ExploreP: 0.0100\n",
      "Episode: 1659 meanReward: 90.2188 meanLoss: 54.1964 ExploreP: 0.0100\n",
      "Episode: 1660 meanReward: 88.0625 meanLoss: 92.2913 ExploreP: 0.0100\n",
      "Episode: 1661 meanReward: 87.7188 meanLoss: 77.6582 ExploreP: 0.0100\n",
      "Episode: 1662 meanReward: 87.3438 meanLoss: 34.7676 ExploreP: 0.0100\n",
      "Episode: 1663 meanReward: 87.0000 meanLoss: 35.3594 ExploreP: 0.0100\n",
      "Episode: 1664 meanReward: 86.5000 meanLoss: 37.7957 ExploreP: 0.0100\n",
      "Episode: 1665 meanReward: 83.2188 meanLoss: 38.0055 ExploreP: 0.0100\n",
      "Episode: 1666 meanReward: 79.8438 meanLoss: 35.1661 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1667 meanReward: 76.7188 meanLoss: 26.9764 ExploreP: 0.0100\n",
      "Episode: 1668 meanReward: 76.0000 meanLoss: 7.4513 ExploreP: 0.0100\n",
      "Episode: 1669 meanReward: 83.7500 meanLoss: 3.0486 ExploreP: 0.0100\n",
      "Episode: 1670 meanReward: 85.9375 meanLoss: 5.6215 ExploreP: 0.0100\n",
      "Episode: 1671 meanReward: 88.0625 meanLoss: 5.4998 ExploreP: 0.0100\n",
      "Episode: 1672 meanReward: 89.4375 meanLoss: 20.9121 ExploreP: 0.0100\n",
      "Episode: 1673 meanReward: 91.0312 meanLoss: 20.0563 ExploreP: 0.0100\n",
      "Episode: 1674 meanReward: 92.2188 meanLoss: 7.7170 ExploreP: 0.0100\n",
      "Episode: 1675 meanReward: 92.0625 meanLoss: 12.7075 ExploreP: 0.0100\n",
      "Episode: 1676 meanReward: 89.2812 meanLoss: 9.8692 ExploreP: 0.0100\n",
      "Episode: 1677 meanReward: 86.0938 meanLoss: 10.8200 ExploreP: 0.0100\n",
      "Episode: 1678 meanReward: 86.1562 meanLoss: 12.0778 ExploreP: 0.0100\n",
      "Episode: 1679 meanReward: 84.5625 meanLoss: 12.8137 ExploreP: 0.0100\n",
      "Episode: 1680 meanReward: 82.9062 meanLoss: 11.3681 ExploreP: 0.0100\n",
      "Episode: 1681 meanReward: 81.2500 meanLoss: 12.0760 ExploreP: 0.0100\n",
      "Episode: 1682 meanReward: 78.3438 meanLoss: 43.6232 ExploreP: 0.0100\n",
      "Episode: 1683 meanReward: 77.0000 meanLoss: 77.1564 ExploreP: 0.0100\n",
      "Episode: 1684 meanReward: 75.0938 meanLoss: 46.0254 ExploreP: 0.0100\n",
      "Episode: 1685 meanReward: 72.9688 meanLoss: 20.1986 ExploreP: 0.0100\n",
      "Episode: 1686 meanReward: 70.6875 meanLoss: 12.3770 ExploreP: 0.0100\n",
      "Episode: 1687 meanReward: 68.1250 meanLoss: 9.0012 ExploreP: 0.0100\n",
      "Episode: 1688 meanReward: 65.3438 meanLoss: 12.0563 ExploreP: 0.0100\n",
      "Episode: 1689 meanReward: 64.6250 meanLoss: 21.9641 ExploreP: 0.0100\n",
      "Episode: 1690 meanReward: 67.3125 meanLoss: 10.9182 ExploreP: 0.0100\n",
      "Episode: 1691 meanReward: 68.7500 meanLoss: 36.5462 ExploreP: 0.0100\n",
      "Episode: 1692 meanReward: 69.2812 meanLoss: 67.9419 ExploreP: 0.0100\n",
      "Episode: 1693 meanReward: 83.9688 meanLoss: 7.4982 ExploreP: 0.0100\n",
      "Episode: 1694 meanReward: 83.8125 meanLoss: 202.4563 ExploreP: 0.0100\n",
      "Episode: 1695 meanReward: 85.0625 meanLoss: 91.6518 ExploreP: 0.0100\n",
      "Episode: 1696 meanReward: 100.1562 meanLoss: 12.5126 ExploreP: 0.0100\n",
      "Episode: 1697 meanReward: 115.4375 meanLoss: 8.6834 ExploreP: 0.0100\n",
      "Episode: 1698 meanReward: 129.8750 meanLoss: 21.9244 ExploreP: 0.0100\n",
      "Episode: 1699 meanReward: 144.9062 meanLoss: 15.3037 ExploreP: 0.0100\n",
      "Episode: 1700 meanReward: 142.9688 meanLoss: 296.0898 ExploreP: 0.0100\n",
      "Episode: 1701 meanReward: 133.5625 meanLoss: 165.9395 ExploreP: 0.0100\n",
      "Episode: 1702 meanReward: 144.0938 meanLoss: 6.2253 ExploreP: 0.0100\n",
      "Episode: 1703 meanReward: 147.1562 meanLoss: 36.0255 ExploreP: 0.0100\n",
      "Episode: 1704 meanReward: 159.2500 meanLoss: 15.9061 ExploreP: 0.0100\n",
      "Episode: 1705 meanReward: 156.4375 meanLoss: 288.0279 ExploreP: 0.0100\n",
      "Episode: 1706 meanReward: 167.7500 meanLoss: 24.0210 ExploreP: 0.0100\n",
      "Episode: 1707 meanReward: 172.8438 meanLoss: 29.0473 ExploreP: 0.0100\n",
      "Episode: 1708 meanReward: 170.0000 meanLoss: 253.9062 ExploreP: 0.0100\n",
      "Episode: 1709 meanReward: 172.6250 meanLoss: 54.9544 ExploreP: 0.0100\n",
      "Episode: 1710 meanReward: 185.8125 meanLoss: 2.6094 ExploreP: 0.0100\n",
      "Episode: 1711 meanReward: 199.5312 meanLoss: 16.0983 ExploreP: 0.0100\n",
      "Episode: 1712 meanReward: 203.1250 meanLoss: 46.3274 ExploreP: 0.0100\n",
      "Episode: 1713 meanReward: 217.0000 meanLoss: 13.4824 ExploreP: 0.0100\n",
      "Episode: 1714 meanReward: 222.8125 meanLoss: 46.2210 ExploreP: 0.0100\n",
      "Episode: 1715 meanReward: 228.0625 meanLoss: 9.9494 ExploreP: 0.0100\n",
      "Episode: 1716 meanReward: 230.4062 meanLoss: 14.1384 ExploreP: 0.0100\n",
      "Episode: 1717 meanReward: 230.6562 meanLoss: 227.0185 ExploreP: 0.0100\n",
      "Episode: 1718 meanReward: 230.7812 meanLoss: 238.3160 ExploreP: 0.0100\n",
      "Episode: 1719 meanReward: 231.9688 meanLoss: 80.8257 ExploreP: 0.0100\n",
      "Episode: 1720 meanReward: 234.5000 meanLoss: 43.8626 ExploreP: 0.0100\n",
      "Episode: 1721 meanReward: 243.5000 meanLoss: 6.9486 ExploreP: 0.0100\n",
      "Episode: 1722 meanReward: 255.3125 meanLoss: 10.7895 ExploreP: 0.0100\n",
      "Episode: 1723 meanReward: 257.3750 meanLoss: 53.2502 ExploreP: 0.0100\n",
      "Episode: 1724 meanReward: 258.5938 meanLoss: 91.1105 ExploreP: 0.0100\n",
      "Episode: 1725 meanReward: 245.0938 meanLoss: 81.2586 ExploreP: 0.0100\n",
      "Episode: 1726 meanReward: 246.0000 meanLoss: 99.9337 ExploreP: 0.0100\n",
      "Episode: 1727 meanReward: 249.5312 meanLoss: 20.6641 ExploreP: 0.0100\n",
      "Episode: 1728 meanReward: 234.3125 meanLoss: 208.1236 ExploreP: 0.0100\n",
      "Episode: 1729 meanReward: 220.4375 meanLoss: 133.8311 ExploreP: 0.0100\n",
      "Episode: 1730 meanReward: 207.5625 meanLoss: 42.9196 ExploreP: 0.0100\n",
      "Episode: 1731 meanReward: 193.5000 meanLoss: 41.6311 ExploreP: 0.0100\n",
      "Episode: 1732 meanReward: 194.2188 meanLoss: 33.9765 ExploreP: 0.0100\n",
      "Episode: 1733 meanReward: 193.2188 meanLoss: 45.5152 ExploreP: 0.0100\n",
      "Episode: 1734 meanReward: 178.0938 meanLoss: 152.9020 ExploreP: 0.0100\n",
      "Episode: 1735 meanReward: 170.3125 meanLoss: 201.9690 ExploreP: 0.0100\n",
      "Episode: 1736 meanReward: 156.4688 meanLoss: 81.5987 ExploreP: 0.0100\n",
      "Episode: 1737 meanReward: 158.9062 meanLoss: 13.0860 ExploreP: 0.0100\n",
      "Episode: 1738 meanReward: 146.2812 meanLoss: 9.0387 ExploreP: 0.0100\n",
      "Episode: 1739 meanReward: 142.0625 meanLoss: 8.4234 ExploreP: 0.0100\n",
      "Episode: 1740 meanReward: 146.5312 meanLoss: 12.8146 ExploreP: 0.0100\n",
      "Episode: 1741 meanReward: 146.4688 meanLoss: 13.9600 ExploreP: 0.0100\n",
      "Episode: 1742 meanReward: 142.6250 meanLoss: 8.9601 ExploreP: 0.0100\n",
      "Episode: 1743 meanReward: 142.6250 meanLoss: 3.0007 ExploreP: 0.0100\n",
      "Episode: 1744 meanReward: 152.5938 meanLoss: 15.4781 ExploreP: 0.0100\n",
      "Episode: 1745 meanReward: 137.7188 meanLoss: 268.3722 ExploreP: 0.0100\n",
      "Episode: 1746 meanReward: 131.9688 meanLoss: 263.3934 ExploreP: 0.0100\n",
      "Episode: 1747 meanReward: 126.8438 meanLoss: 115.9836 ExploreP: 0.0100\n",
      "Episode: 1748 meanReward: 126.4375 meanLoss: 69.2279 ExploreP: 0.0100\n",
      "Episode: 1749 meanReward: 141.2188 meanLoss: 4.1371 ExploreP: 0.0100\n",
      "Episode: 1750 meanReward: 145.6875 meanLoss: 45.0034 ExploreP: 0.0100\n",
      "Episode: 1751 meanReward: 159.7812 meanLoss: 3.7263 ExploreP: 0.0100\n",
      "Episode: 1752 meanReward: 157.2500 meanLoss: 210.3172 ExploreP: 0.0100\n",
      "Episode: 1753 meanReward: 146.6250 meanLoss: 366.0074 ExploreP: 0.0100\n",
      "Episode: 1754 meanReward: 131.3750 meanLoss: 506.4164 ExploreP: 0.0100\n",
      "Episode: 1755 meanReward: 127.3438 meanLoss: 547.0228 ExploreP: 0.0100\n",
      "Episode: 1756 meanReward: 125.1562 meanLoss: 429.6487 ExploreP: 0.0100\n",
      "Episode: 1757 meanReward: 127.8125 meanLoss: 40.8842 ExploreP: 0.0100\n",
      "Episode: 1758 meanReward: 129.6250 meanLoss: 19.5705 ExploreP: 0.0100\n",
      "Episode: 1759 meanReward: 127.7188 meanLoss: 21.0362 ExploreP: 0.0100\n",
      "Episode: 1760 meanReward: 129.4688 meanLoss: 26.7191 ExploreP: 0.0100\n",
      "Episode: 1761 meanReward: 130.9375 meanLoss: 31.6141 ExploreP: 0.0100\n",
      "Episode: 1762 meanReward: 133.0000 meanLoss: 9.6585 ExploreP: 0.0100\n",
      "Episode: 1763 meanReward: 134.5625 meanLoss: 13.5826 ExploreP: 0.0100\n",
      "Episode: 1764 meanReward: 135.7188 meanLoss: 17.6492 ExploreP: 0.0100\n",
      "Episode: 1765 meanReward: 139.1875 meanLoss: 14.4241 ExploreP: 0.0100\n",
      "Episode: 1766 meanReward: 142.2500 meanLoss: 12.8991 ExploreP: 0.0100\n",
      "Episode: 1767 meanReward: 143.6875 meanLoss: 16.7639 ExploreP: 0.0100\n",
      "Episode: 1768 meanReward: 157.5312 meanLoss: 5.4860 ExploreP: 0.0100\n",
      "Episode: 1769 meanReward: 163.9375 meanLoss: 24.2328 ExploreP: 0.0100\n",
      "Episode: 1770 meanReward: 165.2812 meanLoss: 41.3275 ExploreP: 0.0100\n",
      "Episode: 1771 meanReward: 167.8750 meanLoss: 20.3856 ExploreP: 0.0100\n",
      "Episode: 1772 meanReward: 173.8125 meanLoss: 15.8355 ExploreP: 0.0100\n",
      "Episode: 1773 meanReward: 169.3125 meanLoss: 54.5917 ExploreP: 0.0100\n",
      "Episode: 1774 meanReward: 163.9688 meanLoss: 20.7211 ExploreP: 0.0100\n",
      "Episode: 1775 meanReward: 149.2812 meanLoss: 133.1867 ExploreP: 0.0100\n",
      "Episode: 1776 meanReward: 137.3438 meanLoss: 41.9372 ExploreP: 0.0100\n",
      "Episode: 1777 meanReward: 140.9375 meanLoss: 8.2086 ExploreP: 0.0100\n",
      "Episode: 1778 meanReward: 145.7812 meanLoss: 34.7663 ExploreP: 0.0100\n",
      "Episode: 1779 meanReward: 148.5312 meanLoss: 40.3982 ExploreP: 0.0100\n",
      "Episode: 1780 meanReward: 152.3125 meanLoss: 6.4716 ExploreP: 0.0100\n",
      "Episode: 1781 meanReward: 139.0312 meanLoss: 74.2362 ExploreP: 0.0100\n",
      "Episode: 1782 meanReward: 141.2812 meanLoss: 22.2809 ExploreP: 0.0100\n",
      "Episode: 1783 meanReward: 126.6250 meanLoss: 172.7370 ExploreP: 0.0100\n",
      "Episode: 1784 meanReward: 141.9375 meanLoss: 11.3236 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1785 meanReward: 151.6250 meanLoss: 24.0722 ExploreP: 0.0100\n",
      "Episode: 1786 meanReward: 158.7500 meanLoss: 20.6270 ExploreP: 0.0100\n",
      "Episode: 1787 meanReward: 174.1250 meanLoss: 3.5996 ExploreP: 0.0100\n",
      "Episode: 1788 meanReward: 180.3125 meanLoss: 40.3369 ExploreP: 0.0100\n",
      "Episode: 1789 meanReward: 183.0312 meanLoss: 21.0067 ExploreP: 0.0100\n",
      "Episode: 1790 meanReward: 189.4375 meanLoss: 5.4585 ExploreP: 0.0100\n",
      "Episode: 1791 meanReward: 190.1562 meanLoss: 16.7165 ExploreP: 0.0100\n",
      "Episode: 1792 meanReward: 192.1250 meanLoss: 40.4421 ExploreP: 0.0100\n",
      "Episode: 1793 meanReward: 189.5000 meanLoss: 162.8061 ExploreP: 0.0100\n",
      "Episode: 1794 meanReward: 186.0938 meanLoss: 240.6846 ExploreP: 0.0100\n",
      "Episode: 1795 meanReward: 185.3438 meanLoss: 73.4368 ExploreP: 0.0100\n",
      "Episode: 1796 meanReward: 187.4375 meanLoss: 7.4846 ExploreP: 0.0100\n",
      "Episode: 1797 meanReward: 187.5000 meanLoss: 20.9661 ExploreP: 0.0100\n",
      "Episode: 1798 meanReward: 188.3438 meanLoss: 54.7417 ExploreP: 0.0100\n",
      "Episode: 1799 meanReward: 195.1250 meanLoss: 13.4751 ExploreP: 0.0100\n",
      "Episode: 1800 meanReward: 186.2188 meanLoss: 12.7310 ExploreP: 0.0100\n",
      "Episode: 1801 meanReward: 186.8438 meanLoss: 19.4088 ExploreP: 0.0100\n",
      "Episode: 1802 meanReward: 185.5625 meanLoss: 17.2523 ExploreP: 0.0100\n",
      "Episode: 1803 meanReward: 194.4375 meanLoss: 6.4565 ExploreP: 0.0100\n",
      "Episode: 1804 meanReward: 187.8125 meanLoss: 55.4279 ExploreP: 0.0100\n",
      "Episode: 1805 meanReward: 202.8750 meanLoss: 2.2417 ExploreP: 0.0100\n",
      "Episode: 1806 meanReward: 202.5312 meanLoss: 42.5883 ExploreP: 0.0100\n",
      "Episode: 1807 meanReward: 211.0938 meanLoss: 3.2163 ExploreP: 0.0100\n",
      "Episode: 1808 meanReward: 217.9688 meanLoss: 3.4449 ExploreP: 0.0100\n",
      "Episode: 1809 meanReward: 221.8125 meanLoss: 16.3371 ExploreP: 0.0100\n",
      "Episode: 1810 meanReward: 217.7812 meanLoss: 99.2605 ExploreP: 0.0100\n",
      "Episode: 1811 meanReward: 229.8125 meanLoss: 9.8666 ExploreP: 0.0100\n",
      "Episode: 1812 meanReward: 228.4688 meanLoss: 60.4749 ExploreP: 0.0100\n",
      "Episode: 1813 meanReward: 241.7500 meanLoss: 2.5719 ExploreP: 0.0100\n",
      "Episode: 1814 meanReward: 238.3750 meanLoss: 63.8522 ExploreP: 0.0100\n",
      "Episode: 1815 meanReward: 243.1250 meanLoss: 5.9776 ExploreP: 0.0100\n",
      "Episode: 1816 meanReward: 243.1250 meanLoss: 2.8670 ExploreP: 0.0100\n",
      "Episode: 1817 meanReward: 233.9688 meanLoss: 271.3639 ExploreP: 0.0100\n",
      "Episode: 1818 meanReward: 226.8125 meanLoss: 205.8765 ExploreP: 0.0100\n",
      "Episode: 1819 meanReward: 226.8125 meanLoss: 10.9226 ExploreP: 0.0100\n",
      "Episode: 1820 meanReward: 235.9688 meanLoss: 15.8950 ExploreP: 0.0100\n",
      "Episode: 1821 meanReward: 236.3438 meanLoss: 22.7174 ExploreP: 0.0100\n",
      "Episode: 1822 meanReward: 231.4688 meanLoss: 25.1307 ExploreP: 0.0100\n",
      "Episode: 1823 meanReward: 227.5938 meanLoss: 128.6123 ExploreP: 0.0100\n",
      "Episode: 1824 meanReward: 226.4688 meanLoss: 44.3369 ExploreP: 0.0100\n",
      "Episode: 1825 meanReward: 233.9062 meanLoss: 21.4769 ExploreP: 0.0100\n",
      "Episode: 1826 meanReward: 238.0625 meanLoss: 20.7439 ExploreP: 0.0100\n",
      "Episode: 1827 meanReward: 251.3125 meanLoss: 11.1229 ExploreP: 0.0100\n",
      "Episode: 1828 meanReward: 251.4688 meanLoss: 19.5363 ExploreP: 0.0100\n",
      "Episode: 1829 meanReward: 257.3125 meanLoss: 7.8290 ExploreP: 0.0100\n",
      "Episode: 1830 meanReward: 258.3750 meanLoss: 10.6751 ExploreP: 0.0100\n",
      "Episode: 1831 meanReward: 252.9375 meanLoss: 62.7930 ExploreP: 0.0100\n",
      "Episode: 1832 meanReward: 259.1562 meanLoss: 4.2699 ExploreP: 0.0100\n",
      "Episode: 1833 meanReward: 251.9688 meanLoss: 110.7699 ExploreP: 0.0100\n",
      "Episode: 1834 meanReward: 250.3438 meanLoss: 20.7595 ExploreP: 0.0100\n",
      "Episode: 1835 meanReward: 242.7812 meanLoss: 5.2975 ExploreP: 0.0100\n",
      "Episode: 1836 meanReward: 240.0312 meanLoss: 174.4045 ExploreP: 0.0100\n",
      "Episode: 1837 meanReward: 227.7812 meanLoss: 41.4737 ExploreP: 0.0100\n",
      "Episode: 1838 meanReward: 222.2500 meanLoss: 57.9108 ExploreP: 0.0100\n",
      "Episode: 1839 meanReward: 218.0938 meanLoss: 28.7964 ExploreP: 0.0100\n",
      "Episode: 1840 meanReward: 212.2188 meanLoss: 22.4163 ExploreP: 0.0100\n",
      "Episode: 1841 meanReward: 208.7812 meanLoss: 32.9398 ExploreP: 0.0100\n",
      "Episode: 1842 meanReward: 211.2188 meanLoss: 57.2849 ExploreP: 0.0100\n",
      "Episode: 1843 meanReward: 200.6562 meanLoss: 36.5058 ExploreP: 0.0100\n",
      "Episode: 1844 meanReward: 201.6562 meanLoss: 22.3451 ExploreP: 0.0100\n",
      "Episode: 1845 meanReward: 190.1562 meanLoss: 22.6333 ExploreP: 0.0100\n",
      "Episode: 1846 meanReward: 189.8438 meanLoss: 30.1677 ExploreP: 0.0100\n",
      "Episode: 1847 meanReward: 188.4062 meanLoss: 14.1741 ExploreP: 0.0100\n",
      "Episode: 1848 meanReward: 188.4062 meanLoss: 6.6465 ExploreP: 0.0100\n",
      "Episode: 1849 meanReward: 200.4375 meanLoss: 22.3440 ExploreP: 0.0100\n",
      "Episode: 1850 meanReward: 202.2500 meanLoss: 44.6066 ExploreP: 0.0100\n",
      "Episode: 1851 meanReward: 194.6250 meanLoss: 9.7595 ExploreP: 0.0100\n",
      "Episode: 1852 meanReward: 194.6250 meanLoss: 7.4343 ExploreP: 0.0100\n",
      "Episode: 1853 meanReward: 191.5625 meanLoss: 62.2936 ExploreP: 0.0100\n",
      "Episode: 1854 meanReward: 202.3125 meanLoss: 6.1054 ExploreP: 0.0100\n",
      "Episode: 1855 meanReward: 217.4062 meanLoss: 19.5682 ExploreP: 0.0100\n",
      "Episode: 1856 meanReward: 230.0312 meanLoss: 15.9167 ExploreP: 0.0100\n",
      "Episode: 1857 meanReward: 234.0000 meanLoss: 23.5054 ExploreP: 0.0100\n",
      "Episode: 1858 meanReward: 244.9375 meanLoss: 4.8218 ExploreP: 0.0100\n",
      "Episode: 1859 meanReward: 229.9062 meanLoss: 289.6443 ExploreP: 0.0100\n",
      "Episode: 1860 meanReward: 226.3125 meanLoss: 227.4860 ExploreP: 0.0100\n",
      "Episode: 1861 meanReward: 231.9062 meanLoss: 6.1775 ExploreP: 0.0100\n",
      "Episode: 1862 meanReward: 231.6562 meanLoss: 41.4703 ExploreP: 0.0100\n",
      "Episode: 1863 meanReward: 243.9062 meanLoss: 2.2411 ExploreP: 0.0100\n",
      "Episode: 1864 meanReward: 246.5938 meanLoss: 17.8552 ExploreP: 0.0100\n",
      "Episode: 1865 meanReward: 259.5938 meanLoss: 17.6333 ExploreP: 0.0100\n",
      "Episode: 1866 meanReward: 273.7812 meanLoss: 15.9597 ExploreP: 0.0100\n",
      "Episode: 1867 meanReward: 268.2188 meanLoss: 86.9912 ExploreP: 0.0100\n",
      "Episode: 1868 meanReward: 282.4688 meanLoss: 2.9788 ExploreP: 0.0100\n",
      "Episode: 1869 meanReward: 294.7188 meanLoss: 16.7948 ExploreP: 0.0100\n",
      "Episode: 1870 meanReward: 296.0938 meanLoss: 172.0319 ExploreP: 0.0100\n",
      "Episode: 1871 meanReward: 306.3750 meanLoss: 16.2356 ExploreP: 0.0100\n",
      "Episode: 1872 meanReward: 310.0625 meanLoss: 27.0504 ExploreP: 0.0100\n",
      "Episode: 1873 meanReward: 308.8125 meanLoss: 58.8170 ExploreP: 0.0100\n",
      "Episode: 1874 meanReward: 320.6875 meanLoss: 12.5319 ExploreP: 0.0100\n",
      "Episode: 1875 meanReward: 331.2500 meanLoss: 16.4159 ExploreP: 0.0100\n",
      "Episode: 1876 meanReward: 340.8750 meanLoss: 16.5074 ExploreP: 0.0100\n",
      "Episode: 1877 meanReward: 342.4375 meanLoss: 42.3878 ExploreP: 0.0100\n",
      "Episode: 1878 meanReward: 339.4375 meanLoss: 216.4142 ExploreP: 0.0100\n",
      "Episode: 1879 meanReward: 339.3750 meanLoss: 32.5996 ExploreP: 0.0100\n",
      "Episode: 1880 meanReward: 324.1875 meanLoss: 228.1793 ExploreP: 0.0100\n",
      "Episode: 1881 meanReward: 312.0625 meanLoss: 322.0023 ExploreP: 0.0100\n",
      "Episode: 1882 meanReward: 314.7500 meanLoss: 47.7297 ExploreP: 0.0100\n",
      "Episode: 1883 meanReward: 307.5312 meanLoss: 172.6373 ExploreP: 0.0100\n",
      "Episode: 1884 meanReward: 292.4688 meanLoss: 205.3445 ExploreP: 0.0100\n",
      "Episode: 1885 meanReward: 288.0312 meanLoss: 285.8217 ExploreP: 0.0100\n",
      "Episode: 1886 meanReward: 272.7188 meanLoss: 256.2763 ExploreP: 0.0100\n",
      "Episode: 1887 meanReward: 257.7188 meanLoss: 161.0600 ExploreP: 0.0100\n",
      "Episode: 1888 meanReward: 247.0312 meanLoss: 15.8427 ExploreP: 0.0100\n",
      "Episode: 1889 meanReward: 237.2500 meanLoss: 18.3412 ExploreP: 0.0100\n",
      "Episode: 1890 meanReward: 223.2812 meanLoss: 16.8019 ExploreP: 0.0100\n",
      "Episode: 1891 meanReward: 224.3125 meanLoss: 23.0016 ExploreP: 0.0100\n",
      "Episode: 1892 meanReward: 223.9062 meanLoss: 16.0874 ExploreP: 0.0100\n",
      "Episode: 1893 meanReward: 209.5312 meanLoss: 15.5815 ExploreP: 0.0100\n",
      "Episode: 1894 meanReward: 219.9375 meanLoss: 2.7573 ExploreP: 0.0100\n",
      "Episode: 1895 meanReward: 219.9375 meanLoss: 10.8306 ExploreP: 0.0100\n",
      "Episode: 1896 meanReward: 212.5938 meanLoss: 27.8798 ExploreP: 0.0100\n",
      "Episode: 1897 meanReward: 205.0938 meanLoss: 26.3483 ExploreP: 0.0100\n",
      "Episode: 1898 meanReward: 199.1250 meanLoss: 20.7519 ExploreP: 0.0100\n",
      "Episode: 1899 meanReward: 212.2500 meanLoss: 9.9696 ExploreP: 0.0100\n",
      "Episode: 1900 meanReward: 212.2500 meanLoss: 16.6259 ExploreP: 0.0100\n",
      "Episode: 1901 meanReward: 200.4062 meanLoss: 69.3479 ExploreP: 0.0100\n",
      "Episode: 1902 meanReward: 214.0938 meanLoss: 11.3107 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1903 meanReward: 214.0938 meanLoss: 16.3771 ExploreP: 0.0100\n",
      "Episode: 1904 meanReward: 221.3438 meanLoss: 16.7312 ExploreP: 0.0100\n",
      "Episode: 1905 meanReward: 233.4688 meanLoss: 16.2331 ExploreP: 0.0100\n",
      "Episode: 1906 meanReward: 220.8750 meanLoss: 83.3821 ExploreP: 0.0100\n",
      "Episode: 1907 meanReward: 220.8750 meanLoss: 12.4600 ExploreP: 0.0100\n",
      "Episode: 1908 meanReward: 220.8750 meanLoss: 15.1154 ExploreP: 0.0100\n",
      "Episode: 1909 meanReward: 227.9062 meanLoss: 18.3432 ExploreP: 0.0100\n",
      "Episode: 1910 meanReward: 229.1875 meanLoss: 49.9288 ExploreP: 0.0100\n",
      "Episode: 1911 meanReward: 225.5312 meanLoss: 108.6778 ExploreP: 0.0100\n",
      "Episode: 1912 meanReward: 230.4375 meanLoss: 41.3956 ExploreP: 0.0100\n",
      "Episode: 1913 meanReward: 230.0625 meanLoss: 113.9900 ExploreP: 0.0100\n",
      "Episode: 1914 meanReward: 235.0312 meanLoss: 17.6588 ExploreP: 0.0100\n",
      "Episode: 1915 meanReward: 244.9688 meanLoss: 7.7541 ExploreP: 0.0100\n",
      "Episode: 1916 meanReward: 245.4062 meanLoss: 185.0363 ExploreP: 0.0100\n",
      "Episode: 1917 meanReward: 249.7500 meanLoss: 17.7653 ExploreP: 0.0100\n",
      "Episode: 1918 meanReward: 265.0625 meanLoss: 8.9298 ExploreP: 0.0100\n",
      "Episode: 1919 meanReward: 280.2812 meanLoss: 16.6761 ExploreP: 0.0100\n",
      "Episode: 1920 meanReward: 277.0938 meanLoss: 129.0172 ExploreP: 0.0100\n",
      "Episode: 1921 meanReward: 290.5000 meanLoss: 12.8380 ExploreP: 0.0100\n",
      "Episode: 1922 meanReward: 296.5000 meanLoss: 35.3790 ExploreP: 0.0100\n",
      "Episode: 1923 meanReward: 302.2500 meanLoss: 25.2907 ExploreP: 0.0100\n",
      "Episode: 1924 meanReward: 310.5312 meanLoss: 26.2760 ExploreP: 0.0100\n",
      "Episode: 1925 meanReward: 313.3438 meanLoss: 31.4269 ExploreP: 0.0100\n",
      "Episode: 1926 meanReward: 304.4375 meanLoss: 19.2301 ExploreP: 0.0100\n",
      "Episode: 1927 meanReward: 304.0625 meanLoss: 10.6159 ExploreP: 0.0100\n",
      "Episode: 1928 meanReward: 296.5000 meanLoss: 126.3314 ExploreP: 0.0100\n",
      "Episode: 1929 meanReward: 289.0625 meanLoss: 279.9650 ExploreP: 0.0100\n",
      "Episode: 1930 meanReward: 279.8125 meanLoss: 387.6086 ExploreP: 0.0100\n",
      "Episode: 1931 meanReward: 264.5312 meanLoss: 366.2390 ExploreP: 0.0100\n",
      "Episode: 1932 meanReward: 249.4375 meanLoss: 344.0432 ExploreP: 0.0100\n",
      "Episode: 1933 meanReward: 246.0625 meanLoss: 268.5157 ExploreP: 0.0100\n",
      "Episode: 1934 meanReward: 230.7500 meanLoss: 229.2632 ExploreP: 0.0100\n",
      "Episode: 1935 meanReward: 215.4375 meanLoss: 263.6481 ExploreP: 0.0100\n",
      "Episode: 1936 meanReward: 207.2812 meanLoss: 24.3980 ExploreP: 0.0100\n",
      "Episode: 1937 meanReward: 196.3438 meanLoss: 21.5032 ExploreP: 0.0100\n",
      "Episode: 1938 meanReward: 196.9062 meanLoss: 14.0442 ExploreP: 0.0100\n",
      "Episode: 1939 meanReward: 185.0938 meanLoss: 6.1811 ExploreP: 0.0100\n",
      "Episode: 1940 meanReward: 173.8750 meanLoss: 7.0363 ExploreP: 0.0100\n",
      "Episode: 1941 meanReward: 165.3750 meanLoss: 10.4340 ExploreP: 0.0100\n",
      "Episode: 1942 meanReward: 169.1250 meanLoss: 10.7761 ExploreP: 0.0100\n",
      "Episode: 1943 meanReward: 173.8750 meanLoss: 17.4878 ExploreP: 0.0100\n",
      "Episode: 1944 meanReward: 178.2500 meanLoss: 11.1889 ExploreP: 0.0100\n",
      "Episode: 1945 meanReward: 193.4688 meanLoss: 8.4727 ExploreP: 0.0100\n",
      "Episode: 1946 meanReward: 199.2812 meanLoss: 13.3571 ExploreP: 0.0100\n",
      "Episode: 1947 meanReward: 199.3750 meanLoss: 23.9904 ExploreP: 0.0100\n",
      "Episode: 1948 meanReward: 214.0000 meanLoss: 11.8514 ExploreP: 0.0100\n",
      "Episode: 1949 meanReward: 224.5625 meanLoss: 10.4291 ExploreP: 0.0100\n",
      "Episode: 1950 meanReward: 224.5625 meanLoss: 10.6698 ExploreP: 0.0100\n",
      "Episode: 1951 meanReward: 224.5625 meanLoss: 18.2260 ExploreP: 0.0100\n",
      "Episode: 1952 meanReward: 228.0000 meanLoss: 54.9118 ExploreP: 0.0100\n",
      "Episode: 1953 meanReward: 215.4688 meanLoss: 45.0576 ExploreP: 0.0100\n",
      "Episode: 1954 meanReward: 212.5312 meanLoss: 42.0458 ExploreP: 0.0100\n",
      "Episode: 1955 meanReward: 207.0000 meanLoss: 134.8040 ExploreP: 0.0100\n",
      "Episode: 1956 meanReward: 198.7500 meanLoss: 54.1329 ExploreP: 0.0100\n",
      "Episode: 1957 meanReward: 210.3125 meanLoss: 3.3231 ExploreP: 0.0100\n",
      "Episode: 1958 meanReward: 204.8438 meanLoss: 203.7525 ExploreP: 0.0100\n",
      "Episode: 1959 meanReward: 205.2188 meanLoss: 14.5988 ExploreP: 0.0100\n",
      "Episode: 1960 meanReward: 214.7500 meanLoss: 22.2341 ExploreP: 0.0100\n",
      "Episode: 1961 meanReward: 217.9062 meanLoss: 14.3861 ExploreP: 0.0100\n",
      "Episode: 1962 meanReward: 233.1250 meanLoss: 10.2541 ExploreP: 0.0100\n",
      "Episode: 1963 meanReward: 233.3438 meanLoss: 251.4534 ExploreP: 0.0100\n",
      "Episode: 1964 meanReward: 234.4688 meanLoss: 114.3695 ExploreP: 0.0100\n",
      "Episode: 1965 meanReward: 235.8750 meanLoss: 106.3212 ExploreP: 0.0100\n",
      "Episode: 1966 meanReward: 239.5625 meanLoss: 15.9121 ExploreP: 0.0100\n",
      "Episode: 1967 meanReward: 245.6562 meanLoss: 26.1043 ExploreP: 0.0100\n",
      "Episode: 1968 meanReward: 241.3750 meanLoss: 13.1827 ExploreP: 0.0100\n",
      "Episode: 1969 meanReward: 241.6875 meanLoss: 17.7860 ExploreP: 0.0100\n",
      "Episode: 1970 meanReward: 242.8438 meanLoss: 20.1576 ExploreP: 0.0100\n",
      "Episode: 1971 meanReward: 245.8750 meanLoss: 13.0201 ExploreP: 0.0100\n",
      "Episode: 1972 meanReward: 257.0938 meanLoss: 3.3925 ExploreP: 0.0100\n",
      "Episode: 1973 meanReward: 268.5000 meanLoss: 13.5450 ExploreP: 0.0100\n",
      "Episode: 1974 meanReward: 266.3125 meanLoss: 51.8891 ExploreP: 0.0100\n",
      "Episode: 1975 meanReward: 267.8438 meanLoss: 8.2885 ExploreP: 0.0100\n",
      "Episode: 1976 meanReward: 273.5000 meanLoss: 23.0603 ExploreP: 0.0100\n",
      "Episode: 1977 meanReward: 262.1562 meanLoss: 274.5118 ExploreP: 0.0100\n",
      "Episode: 1978 meanReward: 252.2812 meanLoss: 1047.4106 ExploreP: 0.0100\n",
      "Episode: 1979 meanReward: 247.5625 meanLoss: 1024.5563 ExploreP: 0.0100\n",
      "Episode: 1980 meanReward: 235.8438 meanLoss: 468.5005 ExploreP: 0.0100\n",
      "Episode: 1981 meanReward: 223.2188 meanLoss: 272.0362 ExploreP: 0.0100\n",
      "Episode: 1982 meanReward: 209.2812 meanLoss: 319.6505 ExploreP: 0.0100\n",
      "Episode: 1983 meanReward: 194.6875 meanLoss: 268.8179 ExploreP: 0.0100\n",
      "Episode: 1984 meanReward: 190.6562 meanLoss: 115.1290 ExploreP: 0.0100\n",
      "Episode: 1985 meanReward: 188.1250 meanLoss: 120.2243 ExploreP: 0.0100\n",
      "Episode: 1986 meanReward: 184.3750 meanLoss: 84.9184 ExploreP: 0.0100\n",
      "Episode: 1987 meanReward: 183.3438 meanLoss: 91.9488 ExploreP: 0.0100\n",
      "Episode: 1988 meanReward: 183.6250 meanLoss: 109.5620 ExploreP: 0.0100\n",
      "Episode: 1989 meanReward: 169.0625 meanLoss: 80.9156 ExploreP: 0.0100\n",
      "Episode: 1990 meanReward: 168.6875 meanLoss: 39.2433 ExploreP: 0.0100\n",
      "Episode: 1991 meanReward: 153.5625 meanLoss: 56.2918 ExploreP: 0.0100\n",
      "Episode: 1992 meanReward: 144.0312 meanLoss: 88.0198 ExploreP: 0.0100\n",
      "Episode: 1993 meanReward: 141.0625 meanLoss: 44.9655 ExploreP: 0.0100\n",
      "Episode: 1994 meanReward: 126.0938 meanLoss: 28.4750 ExploreP: 0.0100\n",
      "Episode: 1995 meanReward: 126.3125 meanLoss: 38.1535 ExploreP: 0.0100\n",
      "Episode: 1996 meanReward: 125.2500 meanLoss: 32.2879 ExploreP: 0.0100\n",
      "Episode: 1997 meanReward: 123.9688 meanLoss: 79.6947 ExploreP: 0.0100\n",
      "Episode: 1998 meanReward: 120.4062 meanLoss: 111.6076 ExploreP: 0.0100\n",
      "Episode: 1999 meanReward: 114.8750 meanLoss: 118.3771 ExploreP: 0.0100\n",
      "Episode: 2000 meanReward: 112.0000 meanLoss: 124.8966 ExploreP: 0.0100\n",
      "Episode: 2001 meanReward: 107.4375 meanLoss: 171.0063 ExploreP: 0.0100\n",
      "Episode: 2002 meanReward: 103.6250 meanLoss: 184.8998 ExploreP: 0.0100\n",
      "Episode: 2003 meanReward: 97.4375 meanLoss: 167.0656 ExploreP: 0.0100\n",
      "Episode: 2004 meanReward: 82.6562 meanLoss: 147.9053 ExploreP: 0.0100\n",
      "Episode: 2005 meanReward: 68.0938 meanLoss: 123.2558 ExploreP: 0.0100\n",
      "Episode: 2006 meanReward: 70.6875 meanLoss: 236.6853 ExploreP: 0.0100\n",
      "Episode: 2007 meanReward: 79.4688 meanLoss: 178.1067 ExploreP: 0.0100\n",
      "Episode: 2008 meanReward: 79.7188 meanLoss: 26.6113 ExploreP: 0.0100\n",
      "Episode: 2009 meanReward: 91.0625 meanLoss: 22.1616 ExploreP: 0.0100\n",
      "Episode: 2010 meanReward: 100.9375 meanLoss: 16.3717 ExploreP: 0.0100\n",
      "Episode: 2011 meanReward: 110.4688 meanLoss: 19.7431 ExploreP: 0.0100\n",
      "Episode: 2012 meanReward: 122.1875 meanLoss: 14.1278 ExploreP: 0.0100\n",
      "Episode: 2013 meanReward: 124.9688 meanLoss: 200.6075 ExploreP: 0.0100\n",
      "Episode: 2014 meanReward: 138.9062 meanLoss: 38.3203 ExploreP: 0.0100\n",
      "Episode: 2015 meanReward: 153.5000 meanLoss: 9.2447 ExploreP: 0.0100\n",
      "Episode: 2016 meanReward: 167.9688 meanLoss: 21.7194 ExploreP: 0.0100\n",
      "Episode: 2017 meanReward: 183.0312 meanLoss: 22.0842 ExploreP: 0.0100\n",
      "Episode: 2018 meanReward: 197.6875 meanLoss: 13.7894 ExploreP: 0.0100\n",
      "Episode: 2019 meanReward: 212.5000 meanLoss: 19.4422 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2020 meanReward: 216.6250 meanLoss: 53.0521 ExploreP: 0.0100\n",
      "Episode: 2021 meanReward: 217.6875 meanLoss: 103.0564 ExploreP: 0.0100\n",
      "Episode: 2022 meanReward: 232.4375 meanLoss: 10.8498 ExploreP: 0.0100\n",
      "Episode: 2023 meanReward: 247.5625 meanLoss: 10.5092 ExploreP: 0.0100\n",
      "Episode: 2024 meanReward: 262.4688 meanLoss: 15.8831 ExploreP: 0.0100\n",
      "Episode: 2025 meanReward: 271.0000 meanLoss: 28.0775 ExploreP: 0.0100\n",
      "Episode: 2026 meanReward: 277.3438 meanLoss: 26.3669 ExploreP: 0.0100\n",
      "Episode: 2027 meanReward: 286.1562 meanLoss: 27.1442 ExploreP: 0.0100\n",
      "Episode: 2028 meanReward: 301.1875 meanLoss: 33.7296 ExploreP: 0.0100\n",
      "Episode: 2029 meanReward: 301.1875 meanLoss: 285.3807 ExploreP: 0.0100\n",
      "Episode: 2030 meanReward: 301.0938 meanLoss: 534.8342 ExploreP: 0.0100\n",
      "Episode: 2031 meanReward: 307.0000 meanLoss: 36.4242 ExploreP: 0.0100\n",
      "Episode: 2032 meanReward: 322.3125 meanLoss: 17.3153 ExploreP: 0.0100\n",
      "Episode: 2033 meanReward: 337.5000 meanLoss: 22.5429 ExploreP: 0.0100\n",
      "Episode: 2034 meanReward: 351.7188 meanLoss: 17.2218 ExploreP: 0.0100\n",
      "Episode: 2035 meanReward: 366.6875 meanLoss: 17.8074 ExploreP: 0.0100\n",
      "Episode: 2036 meanReward: 374.3438 meanLoss: 19.0029 ExploreP: 0.0100\n",
      "Episode: 2037 meanReward: 388.9062 meanLoss: 16.3698 ExploreP: 0.0100\n",
      "Episode: 2038 meanReward: 398.3125 meanLoss: 14.8384 ExploreP: 0.0100\n",
      "Episode: 2039 meanReward: 385.7812 meanLoss: 69.4011 ExploreP: 0.0100\n",
      "Episode: 2040 meanReward: 384.3438 meanLoss: 2.9103 ExploreP: 0.0100\n",
      "Episode: 2041 meanReward: 369.4375 meanLoss: 285.6847 ExploreP: 0.0100\n",
      "Episode: 2042 meanReward: 369.4375 meanLoss: 9.9933 ExploreP: 0.0100\n",
      "Episode: 2043 meanReward: 369.4375 meanLoss: 17.8281 ExploreP: 0.0100\n",
      "Episode: 2044 meanReward: 369.4375 meanLoss: 15.0824 ExploreP: 0.0100\n",
      "Episode: 2045 meanReward: 379.6250 meanLoss: 17.7067 ExploreP: 0.0100\n",
      "Episode: 2046 meanReward: 365.3125 meanLoss: 217.2629 ExploreP: 0.0100\n",
      "Episode: 2047 meanReward: 365.3125 meanLoss: 12.1999 ExploreP: 0.0100\n",
      "Episode: 2048 meanReward: 365.3125 meanLoss: 16.4307 ExploreP: 0.0100\n",
      "Episode: 2049 meanReward: 365.3125 meanLoss: 16.1873 ExploreP: 0.0100\n",
      "Episode: 2050 meanReward: 365.3125 meanLoss: 17.6336 ExploreP: 0.0100\n",
      "Episode: 2051 meanReward: 350.2188 meanLoss: 287.2704 ExploreP: 0.0100\n",
      "Episode: 2052 meanReward: 360.5312 meanLoss: 20.5551 ExploreP: 0.0100\n",
      "Episode: 2053 meanReward: 359.2188 meanLoss: 251.9639 ExploreP: 0.0100\n",
      "Episode: 2054 meanReward: 343.9688 meanLoss: 273.1553 ExploreP: 0.0100\n",
      "Episode: 2055 meanReward: 328.8125 meanLoss: 163.5891 ExploreP: 0.0100\n",
      "Episode: 2056 meanReward: 317.6250 meanLoss: 26.1485 ExploreP: 0.0100\n",
      "Episode: 2057 meanReward: 315.5312 meanLoss: 22.4062 ExploreP: 0.0100\n",
      "Episode: 2058 meanReward: 324.1562 meanLoss: 8.7786 ExploreP: 0.0100\n",
      "Episode: 2059 meanReward: 330.1875 meanLoss: 17.8673 ExploreP: 0.0100\n",
      "Episode: 2060 meanReward: 314.9688 meanLoss: 273.1438 ExploreP: 0.0100\n",
      "Episode: 2061 meanReward: 330.0625 meanLoss: 19.8027 ExploreP: 0.0100\n",
      "Episode: 2062 meanReward: 345.3438 meanLoss: 15.6334 ExploreP: 0.0100\n",
      "Episode: 2063 meanReward: 338.9062 meanLoss: 254.2607 ExploreP: 0.0100\n",
      "Episode: 2064 meanReward: 338.9062 meanLoss: 20.4035 ExploreP: 0.0100\n",
      "Episode: 2065 meanReward: 335.9375 meanLoss: 26.8263 ExploreP: 0.0100\n",
      "Episode: 2066 meanReward: 321.7812 meanLoss: 220.7003 ExploreP: 0.0100\n",
      "Episode: 2067 meanReward: 321.7812 meanLoss: 12.6773 ExploreP: 0.0100\n",
      "Episode: 2068 meanReward: 315.8438 meanLoss: 90.9127 ExploreP: 0.0100\n",
      "Episode: 2069 meanReward: 301.2812 meanLoss: 188.1665 ExploreP: 0.0100\n",
      "Episode: 2070 meanReward: 286.4062 meanLoss: 171.7679 ExploreP: 0.0100\n",
      "Episode: 2071 meanReward: 298.9375 meanLoss: 14.4378 ExploreP: 0.0100\n",
      "Episode: 2072 meanReward: 285.1562 meanLoss: 258.5535 ExploreP: 0.0100\n",
      "Episode: 2073 meanReward: 284.7812 meanLoss: 294.1437 ExploreP: 0.0100\n",
      "Episode: 2074 meanReward: 269.5000 meanLoss: 249.2936 ExploreP: 0.0100\n",
      "Episode: 2075 meanReward: 269.5000 meanLoss: 10.5990 ExploreP: 0.0100\n",
      "Episode: 2076 meanReward: 269.5000 meanLoss: 14.7887 ExploreP: 0.0100\n",
      "Episode: 2077 meanReward: 259.3125 meanLoss: 48.4128 ExploreP: 0.0100\n",
      "Episode: 2078 meanReward: 269.8750 meanLoss: 17.2018 ExploreP: 0.0100\n",
      "Episode: 2079 meanReward: 269.8750 meanLoss: 11.4875 ExploreP: 0.0100\n",
      "Episode: 2080 meanReward: 262.6875 meanLoss: 28.6354 ExploreP: 0.0100\n",
      "Episode: 2081 meanReward: 255.2188 meanLoss: 25.9031 ExploreP: 0.0100\n",
      "Episode: 2082 meanReward: 246.5000 meanLoss: 18.6273 ExploreP: 0.0100\n",
      "Episode: 2083 meanReward: 246.5000 meanLoss: 145.5733 ExploreP: 0.0100\n",
      "Episode: 2084 meanReward: 231.5938 meanLoss: 242.1646 ExploreP: 0.0100\n",
      "Episode: 2085 meanReward: 236.8125 meanLoss: 27.0799 ExploreP: 0.0100\n",
      "Episode: 2086 meanReward: 236.7500 meanLoss: 165.0602 ExploreP: 0.0100\n",
      "Episode: 2087 meanReward: 236.6250 meanLoss: 200.9352 ExploreP: 0.0100\n",
      "Episode: 2088 meanReward: 232.6562 meanLoss: 232.4339 ExploreP: 0.0100\n",
      "Episode: 2089 meanReward: 240.9688 meanLoss: 11.0955 ExploreP: 0.0100\n",
      "Episode: 2090 meanReward: 229.8750 meanLoss: 49.3902 ExploreP: 0.0100\n",
      "Episode: 2091 meanReward: 229.8750 meanLoss: 8.5184 ExploreP: 0.0100\n",
      "Episode: 2092 meanReward: 236.5938 meanLoss: 29.5296 ExploreP: 0.0100\n",
      "Episode: 2093 meanReward: 227.7188 meanLoss: 22.1779 ExploreP: 0.0100\n",
      "Episode: 2094 meanReward: 221.9375 meanLoss: 12.3181 ExploreP: 0.0100\n",
      "Episode: 2095 meanReward: 224.9375 meanLoss: 39.2886 ExploreP: 0.0100\n",
      "Episode: 2096 meanReward: 209.7812 meanLoss: 210.6707 ExploreP: 0.0100\n",
      "Episode: 2097 meanReward: 197.5312 meanLoss: 350.0693 ExploreP: 0.0100\n",
      "Episode: 2098 meanReward: 196.9375 meanLoss: 284.2186 ExploreP: 0.0100\n",
      "Episode: 2099 meanReward: 181.8125 meanLoss: 237.5589 ExploreP: 0.0100\n",
      "Episode: 2100 meanReward: 192.2812 meanLoss: 16.9166 ExploreP: 0.0100\n",
      "Episode: 2101 meanReward: 202.2188 meanLoss: 8.8058 ExploreP: 0.0100\n",
      "Episode: 2102 meanReward: 207.5000 meanLoss: 40.3446 ExploreP: 0.0100\n",
      "Episode: 2103 meanReward: 198.2188 meanLoss: 20.2969 ExploreP: 0.0100\n",
      "Episode: 2104 meanReward: 201.2500 meanLoss: 21.4934 ExploreP: 0.0100\n",
      "Episode: 2105 meanReward: 204.5625 meanLoss: 12.2798 ExploreP: 0.0100\n",
      "Episode: 2106 meanReward: 206.7500 meanLoss: 20.8617 ExploreP: 0.0100\n",
      "Episode: 2107 meanReward: 193.7500 meanLoss: 34.6696 ExploreP: 0.0100\n",
      "Episode: 2108 meanReward: 180.2188 meanLoss: 23.9349 ExploreP: 0.0100\n",
      "Episode: 2109 meanReward: 176.4688 meanLoss: 30.0956 ExploreP: 0.0100\n",
      "Episode: 2110 meanReward: 168.0312 meanLoss: 21.3590 ExploreP: 0.0100\n",
      "Episode: 2111 meanReward: 155.8125 meanLoss: 19.0143 ExploreP: 0.0100\n",
      "Episode: 2112 meanReward: 150.6250 meanLoss: 12.5571 ExploreP: 0.0100\n",
      "Episode: 2113 meanReward: 146.5938 meanLoss: 8.6028 ExploreP: 0.0100\n",
      "Episode: 2114 meanReward: 143.6250 meanLoss: 10.5437 ExploreP: 0.0100\n",
      "Episode: 2115 meanReward: 147.0000 meanLoss: 8.4184 ExploreP: 0.0100\n",
      "Episode: 2116 meanReward: 150.4375 meanLoss: 6.9824 ExploreP: 0.0100\n",
      "Episode: 2117 meanReward: 160.0312 meanLoss: 7.2920 ExploreP: 0.0100\n",
      "Episode: 2118 meanReward: 170.5938 meanLoss: 24.1919 ExploreP: 0.0100\n",
      "Episode: 2119 meanReward: 185.8750 meanLoss: 24.8090 ExploreP: 0.0100\n",
      "Episode: 2120 meanReward: 201.0312 meanLoss: 21.8566 ExploreP: 0.0100\n",
      "Episode: 2121 meanReward: 186.8125 meanLoss: 250.0299 ExploreP: 0.0100\n",
      "Episode: 2122 meanReward: 183.0625 meanLoss: 279.1425 ExploreP: 0.0100\n",
      "Episode: 2123 meanReward: 167.9688 meanLoss: 348.7779 ExploreP: 0.0100\n",
      "Episode: 2124 meanReward: 165.7188 meanLoss: 44.1480 ExploreP: 0.0100\n",
      "Episode: 2125 meanReward: 165.6562 meanLoss: 25.5880 ExploreP: 0.0100\n",
      "Episode: 2126 meanReward: 160.5938 meanLoss: 34.4568 ExploreP: 0.0100\n",
      "Episode: 2127 meanReward: 159.7500 meanLoss: 91.9255 ExploreP: 0.0100\n",
      "Episode: 2128 meanReward: 161.8125 meanLoss: 28.7656 ExploreP: 0.0100\n",
      "Episode: 2129 meanReward: 165.9375 meanLoss: 22.7448 ExploreP: 0.0100\n",
      "Episode: 2130 meanReward: 169.0625 meanLoss: 34.9156 ExploreP: 0.0100\n",
      "Episode: 2131 meanReward: 171.9375 meanLoss: 20.8614 ExploreP: 0.0100\n",
      "Episode: 2132 meanReward: 162.0938 meanLoss: 11.8325 ExploreP: 0.0100\n",
      "Episode: 2133 meanReward: 154.1562 meanLoss: 10.8114 ExploreP: 0.0100\n",
      "Episode: 2134 meanReward: 151.2188 meanLoss: 11.6852 ExploreP: 0.0100\n",
      "Episode: 2135 meanReward: 148.0312 meanLoss: 10.8983 ExploreP: 0.0100\n",
      "Episode: 2136 meanReward: 147.7812 meanLoss: 5.6239 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2137 meanReward: 147.2188 meanLoss: 5.8508 ExploreP: 0.0100\n",
      "Episode: 2138 meanReward: 152.3125 meanLoss: 16.7153 ExploreP: 0.0100\n",
      "Episode: 2139 meanReward: 165.3125 meanLoss: 2.1974 ExploreP: 0.0100\n",
      "Episode: 2140 meanReward: 163.5938 meanLoss: 323.3689 ExploreP: 0.0100\n",
      "Episode: 2141 meanReward: 162.2500 meanLoss: 499.2136 ExploreP: 0.0100\n",
      "Episode: 2142 meanReward: 159.1250 meanLoss: 441.8227 ExploreP: 0.0100\n",
      "Episode: 2143 meanReward: 156.0312 meanLoss: 306.1075 ExploreP: 0.0100\n",
      "Episode: 2144 meanReward: 153.1875 meanLoss: 154.1525 ExploreP: 0.0100\n",
      "Episode: 2145 meanReward: 149.7188 meanLoss: 103.4021 ExploreP: 0.0100\n",
      "Episode: 2146 meanReward: 161.4062 meanLoss: 11.5397 ExploreP: 0.0100\n",
      "Episode: 2147 meanReward: 165.5000 meanLoss: 27.2860 ExploreP: 0.0100\n",
      "Episode: 2148 meanReward: 176.9688 meanLoss: 7.5511 ExploreP: 0.0100\n",
      "Episode: 2149 meanReward: 176.9688 meanLoss: 11.4643 ExploreP: 0.0100\n",
      "Episode: 2150 meanReward: 167.0625 meanLoss: 200.8751 ExploreP: 0.0100\n",
      "Episode: 2151 meanReward: 162.9375 meanLoss: 12.6195 ExploreP: 0.0100\n",
      "Episode: 2152 meanReward: 162.9375 meanLoss: 7.5470 ExploreP: 0.0100\n",
      "Episode: 2153 meanReward: 177.1562 meanLoss: 18.1341 ExploreP: 0.0100\n",
      "Episode: 2154 meanReward: 192.0000 meanLoss: 13.7312 ExploreP: 0.0100\n",
      "Episode: 2155 meanReward: 207.0938 meanLoss: 16.9384 ExploreP: 0.0100\n",
      "Episode: 2156 meanReward: 217.8438 meanLoss: 17.3978 ExploreP: 0.0100\n",
      "Episode: 2157 meanReward: 212.4688 meanLoss: 198.1194 ExploreP: 0.0100\n",
      "Episode: 2158 meanReward: 223.3125 meanLoss: 7.2007 ExploreP: 0.0100\n",
      "Episode: 2159 meanReward: 236.4375 meanLoss: 15.2148 ExploreP: 0.0100\n",
      "Episode: 2160 meanReward: 249.5312 meanLoss: 16.2878 ExploreP: 0.0100\n",
      "Episode: 2161 meanReward: 260.6250 meanLoss: 16.4802 ExploreP: 0.0100\n",
      "Episode: 2162 meanReward: 272.7188 meanLoss: 18.1179 ExploreP: 0.0100\n",
      "Episode: 2163 meanReward: 270.3750 meanLoss: 256.7483 ExploreP: 0.0100\n",
      "Episode: 2164 meanReward: 282.8125 meanLoss: 9.3211 ExploreP: 0.0100\n",
      "Episode: 2165 meanReward: 280.3750 meanLoss: 265.7467 ExploreP: 0.0100\n",
      "Episode: 2166 meanReward: 292.9062 meanLoss: 20.6068 ExploreP: 0.0100\n",
      "Episode: 2167 meanReward: 291.0000 meanLoss: 197.5211 ExploreP: 0.0100\n",
      "Episode: 2168 meanReward: 288.6562 meanLoss: 81.1158 ExploreP: 0.0100\n",
      "Episode: 2169 meanReward: 286.2188 meanLoss: 72.9011 ExploreP: 0.0100\n",
      "Episode: 2170 meanReward: 279.1562 meanLoss: 210.3393 ExploreP: 0.0100\n",
      "Episode: 2171 meanReward: 263.8438 meanLoss: 300.6551 ExploreP: 0.0100\n",
      "Episode: 2172 meanReward: 264.0938 meanLoss: 253.8531 ExploreP: 0.0100\n",
      "Episode: 2173 meanReward: 279.3750 meanLoss: 10.3418 ExploreP: 0.0100\n",
      "Episode: 2174 meanReward: 290.7500 meanLoss: 18.5204 ExploreP: 0.0100\n",
      "Episode: 2175 meanReward: 298.7500 meanLoss: 31.7425 ExploreP: 0.0100\n",
      "Episode: 2176 meanReward: 299.6562 meanLoss: 49.1251 ExploreP: 0.0100\n",
      "Episode: 2177 meanReward: 307.4375 meanLoss: 8.1574 ExploreP: 0.0100\n",
      "Episode: 2178 meanReward: 295.3125 meanLoss: 21.7237 ExploreP: 0.0100\n",
      "Episode: 2179 meanReward: 302.9375 meanLoss: 5.6052 ExploreP: 0.0100\n",
      "Episode: 2180 meanReward: 291.3438 meanLoss: 60.4285 ExploreP: 0.0100\n",
      "Episode: 2181 meanReward: 279.0000 meanLoss: 21.2307 ExploreP: 0.0100\n",
      "Episode: 2182 meanReward: 293.6562 meanLoss: 3.7979 ExploreP: 0.0100\n",
      "Episode: 2183 meanReward: 286.5000 meanLoss: 63.8720 ExploreP: 0.0100\n",
      "Episode: 2184 meanReward: 286.5000 meanLoss: 8.6048 ExploreP: 0.0100\n",
      "Episode: 2185 meanReward: 275.4062 meanLoss: 49.9287 ExploreP: 0.0100\n",
      "Episode: 2186 meanReward: 262.9688 meanLoss: 25.8250 ExploreP: 0.0100\n",
      "Episode: 2187 meanReward: 262.9688 meanLoss: 2.8790 ExploreP: 0.0100\n",
      "Episode: 2188 meanReward: 262.9688 meanLoss: 17.0574 ExploreP: 0.0100\n",
      "Episode: 2189 meanReward: 264.9688 meanLoss: 77.5057 ExploreP: 0.0100\n",
      "Episode: 2190 meanReward: 260.0625 meanLoss: 8.1616 ExploreP: 0.0100\n",
      "Episode: 2191 meanReward: 245.7812 meanLoss: 197.9382 ExploreP: 0.0100\n",
      "Episode: 2192 meanReward: 243.5312 meanLoss: 8.8857 ExploreP: 0.0100\n",
      "Episode: 2193 meanReward: 229.2188 meanLoss: 62.5225 ExploreP: 0.0100\n",
      "Episode: 2194 meanReward: 217.0312 meanLoss: 52.4898 ExploreP: 0.0100\n",
      "Episode: 2195 meanReward: 224.5625 meanLoss: 23.2703 ExploreP: 0.0100\n",
      "Episode: 2196 meanReward: 224.5625 meanLoss: 8.8905 ExploreP: 0.0100\n",
      "Episode: 2197 meanReward: 239.5625 meanLoss: 16.2562 ExploreP: 0.0100\n",
      "Episode: 2198 meanReward: 224.7500 meanLoss: 269.0764 ExploreP: 0.0100\n",
      "Episode: 2199 meanReward: 227.5938 meanLoss: 46.8839 ExploreP: 0.0100\n",
      "Episode: 2200 meanReward: 231.7500 meanLoss: 21.6041 ExploreP: 0.0100\n",
      "Episode: 2201 meanReward: 231.5938 meanLoss: 174.6411 ExploreP: 0.0100\n",
      "Episode: 2202 meanReward: 237.0938 meanLoss: 40.8815 ExploreP: 0.0100\n",
      "Episode: 2203 meanReward: 239.5625 meanLoss: 27.4186 ExploreP: 0.0100\n",
      "Episode: 2204 meanReward: 243.0312 meanLoss: 27.4829 ExploreP: 0.0100\n",
      "Episode: 2205 meanReward: 234.7500 meanLoss: 8.5097 ExploreP: 0.0100\n",
      "Episode: 2206 meanReward: 228.9375 meanLoss: 16.6516 ExploreP: 0.0100\n",
      "Episode: 2207 meanReward: 226.1250 meanLoss: 9.4259 ExploreP: 0.0100\n",
      "Episode: 2208 meanReward: 240.4375 meanLoss: 2.6117 ExploreP: 0.0100\n",
      "Episode: 2209 meanReward: 247.6250 meanLoss: 12.9802 ExploreP: 0.0100\n",
      "Episode: 2210 meanReward: 259.7500 meanLoss: 15.7591 ExploreP: 0.0100\n",
      "Episode: 2211 meanReward: 250.2188 meanLoss: 42.1737 ExploreP: 0.0100\n",
      "Episode: 2212 meanReward: 261.8125 meanLoss: 5.1287 ExploreP: 0.0100\n",
      "Episode: 2213 meanReward: 274.1562 meanLoss: 18.1219 ExploreP: 0.0100\n",
      "Episode: 2214 meanReward: 258.8125 meanLoss: 258.3788 ExploreP: 0.0100\n",
      "Episode: 2215 meanReward: 270.0938 meanLoss: 16.1056 ExploreP: 0.0100\n",
      "Episode: 2216 meanReward: 270.0938 meanLoss: 15.1658 ExploreP: 0.0100\n",
      "Episode: 2217 meanReward: 270.9375 meanLoss: 51.6553 ExploreP: 0.0100\n",
      "Episode: 2218 meanReward: 269.2188 meanLoss: 132.7509 ExploreP: 0.0100\n",
      "Episode: 2219 meanReward: 269.2188 meanLoss: 13.9898 ExploreP: 0.0100\n",
      "Episode: 2220 meanReward: 254.0000 meanLoss: 262.1326 ExploreP: 0.0100\n",
      "Episode: 2221 meanReward: 251.0312 meanLoss: 444.3124 ExploreP: 0.0100\n",
      "Episode: 2222 meanReward: 243.2500 meanLoss: 110.8038 ExploreP: 0.0100\n",
      "Episode: 2223 meanReward: 245.7188 meanLoss: 15.2921 ExploreP: 0.0100\n",
      "Episode: 2224 meanReward: 232.9062 meanLoss: 102.5683 ExploreP: 0.0100\n",
      "Episode: 2225 meanReward: 232.1562 meanLoss: 184.5762 ExploreP: 0.0100\n",
      "Episode: 2226 meanReward: 229.1875 meanLoss: 273.5781 ExploreP: 0.0100\n",
      "Episode: 2227 meanReward: 221.1250 meanLoss: 249.8341 ExploreP: 0.0100\n",
      "Episode: 2228 meanReward: 209.0000 meanLoss: 51.2873 ExploreP: 0.0100\n",
      "Episode: 2229 meanReward: 209.0000 meanLoss: 6.3000 ExploreP: 0.0100\n",
      "Episode: 2230 meanReward: 208.5938 meanLoss: 260.6945 ExploreP: 0.0100\n",
      "Episode: 2231 meanReward: 209.1250 meanLoss: 50.4394 ExploreP: 0.0100\n",
      "Episode: 2232 meanReward: 205.2812 meanLoss: 174.7444 ExploreP: 0.0100\n",
      "Episode: 2233 meanReward: 208.7500 meanLoss: 21.2259 ExploreP: 0.0100\n",
      "Episode: 2234 meanReward: 218.3125 meanLoss: 13.9910 ExploreP: 0.0100\n",
      "Episode: 2235 meanReward: 222.5625 meanLoss: 31.7303 ExploreP: 0.0100\n",
      "Episode: 2236 meanReward: 221.9062 meanLoss: 58.2416 ExploreP: 0.0100\n",
      "Episode: 2237 meanReward: 218.2188 meanLoss: 38.8979 ExploreP: 0.0100\n",
      "Episode: 2238 meanReward: 217.1250 meanLoss: 23.2706 ExploreP: 0.0100\n",
      "Episode: 2239 meanReward: 216.4062 meanLoss: 31.4448 ExploreP: 0.0100\n",
      "Episode: 2240 meanReward: 208.4688 meanLoss: 21.3667 ExploreP: 0.0100\n",
      "Episode: 2241 meanReward: 208.4688 meanLoss: 12.1960 ExploreP: 0.0100\n",
      "Episode: 2242 meanReward: 197.2188 meanLoss: 49.1757 ExploreP: 0.0100\n",
      "Episode: 2243 meanReward: 206.7500 meanLoss: 11.1656 ExploreP: 0.0100\n",
      "Episode: 2244 meanReward: 194.6875 meanLoss: 48.3597 ExploreP: 0.0100\n",
      "Episode: 2245 meanReward: 194.6875 meanLoss: 11.9301 ExploreP: 0.0100\n",
      "Episode: 2246 meanReward: 198.6250 meanLoss: 42.6109 ExploreP: 0.0100\n",
      "Episode: 2247 meanReward: 198.6250 meanLoss: 6.1994 ExploreP: 0.0100\n",
      "Episode: 2248 meanReward: 185.6250 meanLoss: 95.1379 ExploreP: 0.0100\n",
      "Episode: 2249 meanReward: 180.9375 meanLoss: 92.6284 ExploreP: 0.0100\n",
      "Episode: 2250 meanReward: 195.0938 meanLoss: 5.8200 ExploreP: 0.0100\n",
      "Episode: 2251 meanReward: 183.1562 meanLoss: 79.1013 ExploreP: 0.0100\n",
      "Episode: 2252 meanReward: 183.3750 meanLoss: 121.0986 ExploreP: 0.0100\n",
      "Episode: 2253 meanReward: 183.3750 meanLoss: 388.2089 ExploreP: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2254 meanReward: 185.2188 meanLoss: 76.7458 ExploreP: 0.0100\n",
      "Episode: 2255 meanReward: 185.6250 meanLoss: 25.7414 ExploreP: 0.0100\n",
      "Episode: 2256 meanReward: 191.5938 meanLoss: 24.9989 ExploreP: 0.0100\n",
      "Episode: 2257 meanReward: 206.6562 meanLoss: 3.3437 ExploreP: 0.0100\n",
      "Episode: 2258 meanReward: 215.4688 meanLoss: 25.7515 ExploreP: 0.0100\n",
      "Episode: 2259 meanReward: 215.7500 meanLoss: 204.2622 ExploreP: 0.0100\n",
      "Episode: 2260 meanReward: 212.6875 meanLoss: 184.8425 ExploreP: 0.0100\n",
      "Episode: 2261 meanReward: 202.3750 meanLoss: 24.9492 ExploreP: 0.0100\n",
      "Episode: 2262 meanReward: 217.5938 meanLoss: 6.4897 ExploreP: 0.0100\n",
      "Episode: 2263 meanReward: 217.9375 meanLoss: 51.9544 ExploreP: 0.0100\n",
      "Episode: 2264 meanReward: 217.4062 meanLoss: 52.6901 ExploreP: 0.0100\n",
      "Episode: 2265 meanReward: 214.6562 meanLoss: 148.4705 ExploreP: 0.0100\n",
      "Episode: 2266 meanReward: 214.6562 meanLoss: 11.0851 ExploreP: 0.0100\n",
      "Episode: 2267 meanReward: 211.0938 meanLoss: 58.3545 ExploreP: 0.0100\n",
      "Episode: 2268 meanReward: 223.2812 meanLoss: 5.7666 ExploreP: 0.0100\n",
      "Episode: 2269 meanReward: 222.2812 meanLoss: 90.5686 ExploreP: 0.0100\n",
      "Episode: 2270 meanReward: 217.9375 meanLoss: 204.2201 ExploreP: 0.0100\n",
      "Episode: 2271 meanReward: 213.5625 meanLoss: 358.7394 ExploreP: 0.0100\n",
      "Episode: 2272 meanReward: 221.5000 meanLoss: 15.0888 ExploreP: 0.0100\n",
      "Episode: 2273 meanReward: 213.2188 meanLoss: 33.1626 ExploreP: 0.0100\n",
      "Episode: 2274 meanReward: 224.4688 meanLoss: 11.8750 ExploreP: 0.0100\n",
      "Episode: 2275 meanReward: 224.4688 meanLoss: 15.7411 ExploreP: 0.0100\n",
      "Episode: 2276 meanReward: 236.5312 meanLoss: 15.9753 ExploreP: 0.0100\n",
      "Episode: 2277 meanReward: 236.5312 meanLoss: 15.7204 ExploreP: 0.0100\n",
      "Episode: 2278 meanReward: 232.8125 meanLoss: 269.9871 ExploreP: 0.0100\n",
      "Episode: 2279 meanReward: 232.8125 meanLoss: 18.5884 ExploreP: 0.0100\n",
      "Episode: 2280 meanReward: 231.3125 meanLoss: 220.0639 ExploreP: 0.0100\n",
      "Episode: 2281 meanReward: 246.2500 meanLoss: 5.5122 ExploreP: 0.0100\n",
      "Episode: 2282 meanReward: 246.2500 meanLoss: 15.9664 ExploreP: 0.0100\n",
      "Episode: 2283 meanReward: 243.1562 meanLoss: 267.1774 ExploreP: 0.0100\n",
      "Episode: 2284 meanReward: 243.0000 meanLoss: 333.6640 ExploreP: 0.0100\n",
      "Episode: 2285 meanReward: 244.0000 meanLoss: 150.5430 ExploreP: 0.0100\n",
      "Episode: 2286 meanReward: 254.8438 meanLoss: 5.4712 ExploreP: 0.0100\n",
      "Episode: 2287 meanReward: 266.2500 meanLoss: 13.4201 ExploreP: 0.0100\n",
      "Episode: 2288 meanReward: 275.3438 meanLoss: 13.7041 ExploreP: 0.0100\n",
      "Episode: 2289 meanReward: 265.4062 meanLoss: 42.0125 ExploreP: 0.0100\n",
      "Episode: 2290 meanReward: 271.7500 meanLoss: 8.3812 ExploreP: 0.0100\n",
      "Episode: 2291 meanReward: 275.6250 meanLoss: 56.2564 ExploreP: 0.0100\n",
      "Episode: 2292 meanReward: 285.6250 meanLoss: 15.8713 ExploreP: 0.0100\n",
      "Episode: 2293 meanReward: 295.9375 meanLoss: 4.4685 ExploreP: 0.0100\n",
      "Episode: 2294 meanReward: 281.4688 meanLoss: 208.1000 ExploreP: 0.0100\n",
      "Episode: 2295 meanReward: 287.9375 meanLoss: 14.2541 ExploreP: 0.0100\n",
      "Episode: 2296 meanReward: 287.7500 meanLoss: 102.8680 ExploreP: 0.0100\n",
      "Episode: 2297 meanReward: 286.8750 meanLoss: 181.0284 ExploreP: 0.0100\n",
      "Episode: 2298 meanReward: 273.3750 meanLoss: 66.4426 ExploreP: 0.0100\n",
      "Episode: 2299 meanReward: 273.4375 meanLoss: 28.1013 ExploreP: 0.0100\n",
      "Episode: 2300 meanReward: 264.2500 meanLoss: 12.5588 ExploreP: 0.0100\n",
      "Episode: 2301 meanReward: 264.8750 meanLoss: 24.7913 ExploreP: 0.0100\n",
      "Episode: 2302 meanReward: 267.7188 meanLoss: 18.9960 ExploreP: 0.0100\n",
      "Episode: 2303 meanReward: 271.3125 meanLoss: 14.6533 ExploreP: 0.0100\n",
      "Episode: 2304 meanReward: 258.9062 meanLoss: 10.1669 ExploreP: 0.0100\n",
      "Episode: 2305 meanReward: 254.6250 meanLoss: 18.9103 ExploreP: 0.0100\n",
      "Episode: 2306 meanReward: 242.2500 meanLoss: 12.4155 ExploreP: 0.0100\n",
      "Episode: 2307 meanReward: 229.2812 meanLoss: 8.5870 ExploreP: 0.0100\n",
      "Episode: 2308 meanReward: 216.8438 meanLoss: 8.6404 ExploreP: 0.0100\n",
      "Episode: 2309 meanReward: 204.7188 meanLoss: 10.9201 ExploreP: 0.0100\n",
      "Episode: 2310 meanReward: 208.5312 meanLoss: 8.4330 ExploreP: 0.0100\n",
      "Episode: 2311 meanReward: 195.5312 meanLoss: 5.1255 ExploreP: 0.0100\n",
      "Episode: 2312 meanReward: 197.5625 meanLoss: 6.1751 ExploreP: 0.0100\n",
      "Episode: 2313 meanReward: 194.6250 meanLoss: 8.6137 ExploreP: 0.0100\n",
      "Episode: 2314 meanReward: 194.6250 meanLoss: 1.9252 ExploreP: 0.0100\n",
      "Episode: 2315 meanReward: 209.6562 meanLoss: 12.9078 ExploreP: 0.0100\n",
      "Episode: 2316 meanReward: 210.5000 meanLoss: 177.4685 ExploreP: 0.0100\n",
      "Episode: 2317 meanReward: 224.7812 meanLoss: 10.1348 ExploreP: 0.0100\n",
      "Episode: 2318 meanReward: 217.0000 meanLoss: 29.8046 ExploreP: 0.0100\n",
      "Episode: 2319 meanReward: 211.1562 meanLoss: 10.1069 ExploreP: 0.0100\n",
      "Episode: 2320 meanReward: 202.1250 meanLoss: 26.3826 ExploreP: 0.0100\n",
      "Episode: 2321 meanReward: 201.0000 meanLoss: 36.5545 ExploreP: 0.0100\n",
      "Episode: 2322 meanReward: 186.5625 meanLoss: 93.4354 ExploreP: 0.0100\n",
      "Episode: 2323 meanReward: 182.2812 meanLoss: 184.2358 ExploreP: 0.0100\n",
      "Episode: 2324 meanReward: 177.0625 meanLoss: 27.6610 ExploreP: 0.0100\n",
      "Episode: 2325 meanReward: 165.5312 meanLoss: 6.1690 ExploreP: 0.0100\n",
      "Episode: 2326 meanReward: 167.9688 meanLoss: 13.8851 ExploreP: 0.0100\n",
      "Episode: 2327 meanReward: 160.6875 meanLoss: 6.4104 ExploreP: 0.0100\n",
      "Episode: 2328 meanReward: 163.1875 meanLoss: 7.5852 ExploreP: 0.0100\n",
      "Episode: 2329 meanReward: 166.4688 meanLoss: 5.4171 ExploreP: 0.0100\n",
      "Episode: 2330 meanReward: 167.9062 meanLoss: 5.6667 ExploreP: 0.0100\n",
      "Episode: 2331 meanReward: 170.8750 meanLoss: 4.5541 ExploreP: 0.0100\n",
      "Episode: 2332 meanReward: 175.0312 meanLoss: 2.0079 ExploreP: 0.0100\n",
      "Episode: 2333 meanReward: 187.2812 meanLoss: 8.0503 ExploreP: 0.0100\n",
      "Episode: 2334 meanReward: 184.3125 meanLoss: 167.6452 ExploreP: 0.0100\n",
      "Episode: 2335 meanReward: 180.6250 meanLoss: 323.8822 ExploreP: 0.0100\n",
      "Episode: 2336 meanReward: 177.7812 meanLoss: 346.4621 ExploreP: 0.0100\n",
      "Episode: 2337 meanReward: 178.8125 meanLoss: 44.6430 ExploreP: 0.0100\n",
      "Episode: 2338 meanReward: 177.2500 meanLoss: 12.0033 ExploreP: 0.0100\n",
      "Episode: 2339 meanReward: 176.0625 meanLoss: 12.9702 ExploreP: 0.0100\n",
      "Episode: 2340 meanReward: 175.0938 meanLoss: 12.7434 ExploreP: 0.0100\n",
      "Episode: 2341 meanReward: 174.0938 meanLoss: 10.5503 ExploreP: 0.0100\n",
      "Episode: 2342 meanReward: 172.4062 meanLoss: 4.7262 ExploreP: 0.0100\n",
      "Episode: 2343 meanReward: 185.4062 meanLoss: 2.7281 ExploreP: 0.0100\n",
      "Episode: 2344 meanReward: 197.8750 meanLoss: 11.7362 ExploreP: 0.0100\n",
      "Episode: 2345 meanReward: 188.6875 meanLoss: 57.3638 ExploreP: 0.0100\n",
      "Episode: 2346 meanReward: 188.6875 meanLoss: 1.8975 ExploreP: 0.0100\n",
      "Episode: 2347 meanReward: 188.6875 meanLoss: 13.2599 ExploreP: 0.0100\n",
      "Episode: 2348 meanReward: 191.0000 meanLoss: 48.5879 ExploreP: 0.0100\n",
      "Episode: 2349 meanReward: 189.0938 meanLoss: 3.6589 ExploreP: 0.0100\n",
      "Episode: 2350 meanReward: 188.9688 meanLoss: 14.2703 ExploreP: 0.0100\n",
      "Episode: 2351 meanReward: 186.1562 meanLoss: 17.1235 ExploreP: 0.0100\n",
      "Episode: 2352 meanReward: 180.1562 meanLoss: 116.3042 ExploreP: 0.0100\n",
      "Episode: 2353 meanReward: 177.3125 meanLoss: 104.9821 ExploreP: 0.0100\n",
      "Episode: 2354 meanReward: 181.1250 meanLoss: 20.8009 ExploreP: 0.0100\n",
      "Episode: 2355 meanReward: 189.1562 meanLoss: 4.1526 ExploreP: 0.0100\n",
      "Episode: 2356 meanReward: 192.1562 meanLoss: 6.1357 ExploreP: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver() # save the trained model\n",
    "rewards_list, loss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_loss = deque(maxlen=batch_size)\n",
    "    episode_reward = deque(maxlen=batch_size)\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            \n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([initial_state, final_state])\n",
    "            total_reward += reward\n",
    "            initial_state = final_state\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            initial_states = np.array([each[0] for each in rnn_states])\n",
    "            final_states = np.array([each[1] for each in rnn_states])\n",
    "            actions_logits = sess.run(model.actions_logits, \n",
    "                                      feed_dict = {model.states: next_states, \n",
    "                                                   model.initial_state: final_states[0].reshape([1, -1])})\n",
    "            nextQs = np.max(actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (0.99 * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], \n",
    "                               feed_dict = {model.states: states, \n",
    "                                            model.actions: actions,\n",
    "                                            model.targetQs: targetQs,\n",
    "                                            model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode: {}'.format(ep),\n",
    "              'meanReward: {:.4f}'.format(np.mean(episode_reward)),\n",
    "              'meanLoss: {:.4f}'.format(np.mean(loss_batch)),\n",
    "              'ExploreP: {:.4f}'.format(explore_p))\n",
    "        rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        if(np.mean(episode_reward) >= 500):\n",
    "            break\n",
    "    \n",
    "    saver.save(sess, 'checkpoints/model3.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average losses')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsvXd85FW9//88U5NJ2WSTbHY3W7IdlrKUBUFsgCCIgiIqelUQruhPrNfu9Vruvdbr1St+RQUbNlCxIEgRkCYILgss7C7ba9qm18n08/tjciaf+cznM/OZJFOSnOfjkUeSKZ/Pmc/MnNd51yOklGg0Go1GY8ZV6gFoNBqNpjzRAqHRaDQaS7RAaDQajcYSLRAajUajsUQLhEaj0Wgs0QKh0Wg0Gku0QGg0Go3GEi0QGo1Go7FEC4RGo9FoLPGUegDTobGxUba2tpZ6GBqNRjOr2Lp1a6+UsinX42a1QLS2tvL000+XehgajUYzqxBCHHbyOO1i0mg0Go0lWiA0Go1GY4kWCI1Go9FYogVCo9FoNJZogdBoNBqNJVogNBqNRmOJFgiNRqPRWKIFQqPRzEtGR0cJhUKlHkZZM6sL5TQajWYqSClpb28HoLq6moaGBioqKko8qvJDWxAajWbeEY/HAQgEAoyPj3PkyBEikUiJR1V+aIHQaDTzjkQiAcCCBQtYtmwZUkotEBZogdBoNPMOJRAulwu32w1MWhWaSbRAaDSaeYcSA5fLhcuVnAaVaGgm0QKh0WjmHUoM3G53SiC0BZGJFgiNRjPvMLqYhBC43W5tQVigBUKj0cw7jAKhfmsLIpOCCYQQ4idCiG4hxHaL+z4uhJBCiMaJ/4UQ4gYhxD4hxPNCiNMKNS6NRqMxxiAAbUHYUEgL4mfAReYbhRDLgQuAI4abLwbWTfxcB3y/gOPSaDTznEQikXIvgbYg7CiYQEgpHwX6Le76NvBJQBpuuwz4uUzyJFAnhFhSqLFpNJr5TSKRSKW3QtKC0AKRSVFjEEKIS4F2KeU2010twFHD/20Tt1kd4zohxNNCiKd7enoKNFKNRjOXicfjKfcSJC0I7WLKpGgCIYQIAP8OfN7qbovbpMVtSClvklJullJubmpqmskhajSaeYJyMSm0BWFNMS2INcAqYJsQ4hCwDHhGCLGYpMWw3PDYZUBHEcem0WjmEWYXk8vlQkqJlJbr0nlL0QRCSvmClHKRlLJVStlKUhROk1J2AX8G3jWRzXQWMCSl7CzW2DQazfzC7GLS7TasKWSa663AP4ANQog2IcS1WR5+N3AA2AfcDLy/UOPSaDQas4tJt9uwpmD7QUgp35bj/lbD3xK4vlBj0Wg0pSccDuP1etMm5lJhFYMAbUGYKf07pdFo5jyxWIzDhw8zMDBQ6qGQSCSQUmbEINR9mkm0QGg0moIzMjKClLIsVujmNhugLQg7tEBoNJqCMzQ0BFAWWUJWAqE7ulqjBUKj0RSUUChEOBwGykMglAiYK6lBu5jMFCxIrdFoNJC0HsqppbaVBSGE0P2YLNAWhEajKRhSSkZGRqipqcHtdpeFBWElEOr/chCwckILhEajKRijo6PE43Fqa2tT1cqlxsrFpP7XFkQ6WiA0Gk3BGB4exuPxEAgEEEKUxQpdWxDO0QKh0WgKRjwex+/3I4RACFEWFkQikUjFHIxoCyITLRAajaZgSClTm/KUi0CY+zAptAWRiRYIjUZTMNRqHSibGIS5zYZCWxCZaIHQaDQFw2xBlMMK3U4glAVRDiJWLmiB0Gg0BaNcXUzmDCbQxXJWaIHQaDQFQ0qZWq2Xu4tJt9vIRAuERqMpGMYYRLlYENliEOp+TRItEBqNpmBYuZhKLRLm7UYV2oLIRAuERqMpCEoIjAJhvL1UY7JLc9UWRCZaIDQaTUEwVyyXw6Y8SpyyxSC0QExSyD2pfyKE6BZCbDfc9j9CiF1CiOeFEH8UQtQZ7vuMEGKfEGK3EOI1hRqXRqMpDuVoQdj1YTLepl1MkxTSgvgZcJHptvuBE6WUJwN7gM8ACCE2AlcCJ0w850YhROY7qNFoZg3lKBB2fZjUbeVSq1EuFEwgpJSPAv2m2/4qpYxN/PsksGzi78uA26SUYSnlQWAfcGahxqbRaAqP2Z2jfperQKjbtQUxSSljENcA90z83QIcNdzXNnFbBkKI64QQTwshnu7p6SnwEDUazVRRk7HZgijlCj2bi0ndrgVikpIIhBDi34EY8Ct1k8XDLJcZUsqbpJSbpZSbm5qaCjVEjUYzTWabi0ndrl1MkxR9y1EhxFXA64Dz5eQnpQ1YbnjYMqCj2GPTaDQzx2wUCG1BpFNUC0IIcRHwKeBSKWXQcNefgSuFEH4hxCpgHfDPYo5No9HMLOWY5qomf21BOKNgFoQQ4lbgVUCjEKIN+ALJrCU/cP/EauJJKeX7pJQ7hBC/BXaSdD1dL6XUMq7RzGLK1YKw2ixIoS2IdAomEFLKt1nc/OMsj/8y8OVCjUej0RSXchUIO3EAbUGY0ZXUGo2mIJSrQNhlMEHSgpBSapGYQAuERqMpCOUag8hmQZSDiJUTWiA0mnlGsSbocrUgtEA4RwuERjOPGBkZYf/+/UURCSuBKPWeEFog8kMLhEZTJPr7+2lvby/pGKLRKIlEomgCoURBUepeR1og8qPohXIazXxldHSUSCRS0jGoybkYE6BxNzlFuVsQ5RAnKSe0BaHRFAEpJeFwuOQTj5qcizFJG3eTU5S7QJSbBRGNRhkeHi7Z+bVAaDRFIBKJkEgkSr7lZjEtCCuBcLlcJXv96trPJoEYGhqis7OzZOfXAqHRFIFwOJz6ez4JhHkyLmUMIlcfJpi6QBRK+Iv5flmhBUKjKQKhUCj1dzlsuTkfYxBOBGKqe1b09vZy9OjR3A/MEy0QGs08wGhBlDqLB+aniykfCyLf9ygSiRCNRqc+OBuKKehWaIHQaAqMlJJQKITHk0wanE8CYeVimg0Cke8YVXxpptEWhEYzx1G1B5WVlUBpYxDlkMU0F2MQWiA0Gs2UUO6lQCAAzB8LYjbGILRApKMFQqMpMKFQCCEEFRUVwPwRiNkYg5hqkLpQWUylTrfVAqHRFJhwOIzf70+1mZ4vWUyzOc013zEWSni1BaHRzHFCoRB+v78sirBKbUGUu4sJpjZGdeyZFr85KxBCiJ8IIbqFENsNty0UQtwvhNg78bt+4nYhhLhBCLFPCPG8EOK0Qo1Loykm0WiUeDxORUVFyfv8GN0gpYpBlNrFZG4eaEW+YyzkdZ2zAgH8DLjIdNungQellOuAByf+B7gYWDfxcx3w/QKOS6MpGipAbbQgSu1igdJbEKWY8HL1YVLka0EU6roWW9CtyHm1hBDfEELUCiG8QogHhRC9Qoh35HqelPJRoN9082XALRN/3wK8wXD7z2WSJ4E6IcQS5y9DoylPYrEYAF6vFyFESfc8LqZA2PU9KqWbbbYJRLEF3QonFsSFUsph4HVAG7Ae+MQUz9cspewEmPi9aOL2FsBYp942cZtGM6ux2nazlM3qrP4u5LmsLIhinN+KfAQiHxEvpAVRiOPmgxOB8E78fi1wq5TSbBXMBFZOQcsrIoS4TgjxtBDi6Z6engIMRaOZOdTkoSbG+WRBQKZAlDIOM5stiFLhRCDuFELsAjYDDwohmoBQjufYcUy5jiZ+d0/c3gYsNzxuGdBhdQAp5U1Sys1Sys1NTU1THIZGUxyUm8W47eZ8FojZYEHka+XNaxeTlPLTwNnAZillFAiSjBlMhT8DV038fRVwh+H2d01kM50FDClXlEYzmzFn8pTSgiimy8IupXQ2CMRULIhgOE7/WGT+uZiEEAHgeiYzi5aStCZyPe9W4B/ABiFEmxDiWuBrwAVCiL3ABRP/A9wNHAD2ATcD78/zdWg0ZYl5Uip1mqdCWxD2TEUgbv3nEf7zzh0Mj8/clrLlYEE42ZP6p8BW4KUT/7cBvwPuyvYkKeXbbO463+KxkqQIaTRzCnMmz3x3Mc2WGES+Qep9PaOMhuPc8vhBPnXpqdMZZtpxFWVrQQBrpJTfAKIAUspxrIPKGo3GRDm6mFTLj2Kcq5wsCKu0WyvytSCGghF6RsL4PC5u23KErqGphmjTmS0CERFCVDKRVSSEWAOEsz9Fo9GAtYup1BaE2+0u+BjKLQahuq0WQiD2HBsC4C2bl5NIwP89sGfK4zQyK2IQwBeAe4HlQohfkayA/mRBR6XRzBHKMQbhZJKcLuXmYsrntef7Hu3rGgHg9JV1XH5aC799+ih7j41MbaAGZoUFIaW8H7gcuBq4lWQ208OFHZZGMzcwr1qVBVHKIG0xGuaVm4spH4HI9/rsPTZCfZWPmgov7zprBQGfhx89dnDKY1XMijoIIcQ5QEhK+RegDvisEGJlwUem0cwBzDGIcvDBa4HITr5B6v09I6xorAFgQaWHza31bGsbnNpADRRT0O1wYmt+HwgKITaRbLFxGPh5QUel0cwRrCwIKF0Wj+pmOt/qIAplQYyGY3QNBlnVlBQIKSUbl9Syr3uUcCw+9QFTXEG3w4lAxCbSUC8DbpBSfgeoKeywNJq5gVUMQt1eqrGU0oKYDTGIfERsZ8cwIFmzqDr1nI1La4klJHuPjU59wKRbn+UsECNCiM8A7wD+IoRwM9mfSaPR2KA6mprTXNV9pRhPqQViNlgQ2UQsHo9z8ODBVBv3F9qHcCFZ21ybuq4bl9QCsLNzeNpjng0WxFtJprVeK6XsItll9X8KOiqNZg5gNSmVck+IYrqY7AQCSpPJNVMWRCQSIRKJEAolax12tA9RX+mloboidV1XNlQR8LknrIupUw4uJieV1CPAd6SUcSHEeuA4ktlMGo0mC1aTUqldTGpfimLEIOx2byvFhGfuqpuNbAIRjyfjCmqfjxfah1jfGEibyN0uwXGLa+aNBfEo4BdCtJCsgXg3yd3iNBpNFqxW0aUUCGPAvBgWhN1kXIp2IzNlQajjxONxgpEY+3tGWbmwMmMi37i0lhc7hqd1nZ1ukVpInAiEkFIGSdZCfFdK+UbghMIOS6OZ/WSzIEpVB6F2tSuGQNhNxqWyIIxt17OR7T1SFkQ8HufFzmESUrKyIWlBGK/rxiULGAnHaBsYn5Exl7MFIYQQZwP/Avxl4rbCN3PRaGY55RiDKAcLolQxCKcV5NneI6OL6Z8HBxAkYw5WFgTAjmnEIcohBuHkin0E+AzwRynlDiHEauChwg5Lo5n9lKuLqRgTtLlA0EgpXExO+zCB8xjEH55p4/QVddQHvBkT+YbmGlxieplM5ZDmmjNILaV8BHhECFEjhKiWUh4APlT4oWk0s5tysiBUym2xWn3kikHMBgsiWwxi37Fh9naP8l+v3wDEMwSi0udmdVP1lDOZpJSzw8UkhDhJCPEssB3YKYTYKoTQMQiNJgd2AlGKjq7GLJ5irEqzrdhni4spmwXx9z3H8HkEF25cBJCayI3v68Yltbw4RQtCnbvsBQL4IfBvUsqVUsoVwMdI7vqm0WiyYJc5U+o6gGIIRLm5mPIRiFxB6lhc8s+D/VxwXBPVPnfqOeaJfOPSWtoHxxkM5r/LnPn9KmeBqJJSpmIOE51cqwo2Io1mjpCtmriUaZ7FsiBmu4vJLkj9Qvswo+E4b9i0JOtKfzoV1cbPTrkLxAEhxH8IIVonfj4HTKuXrRDio0KIHUKI7UKIW4UQFUKIVUKIp4QQe4UQvxFC+KZzDo2m1GSzIIyTT7FiAlBcF1O5CYTTeoJcMYjHDgxQW+nlzJULMlx3xucctyTZsm53V/57Q1gJeilwIhDXAE3AH4A/Tvz97qmecKLg7kMk95U4kWTK7JXA14FvSynXAQPAtVM9h0ZTDtitWo0upng8zv79+xkdnV5jNydjUefWMYjs2F0fKSVdg0G2HBnmrNULEcisrqCmaj81fg+HesemNF674xYTJ1lMA8x81pIHqBRCRIEA0AmcB7x94v5bgC+SbDWu0cxK7CZJowURiURIJBJEo9GCjqXcYhDFnPCMGUFOsLs+vSMhvvPAHrw+H+cdt4h4PJ7VxSSEoLWxigPTFAirsRQLW4EQQtzJxD7UVkgpL53KCaWU7UKIbwJHgHHgr8BWYFBKGZt4WBvJpoAazazFbpI0xiCUMBQ6JlFuLqZixmDy3WrV6vqMR+K87xdbGBiL8NUrz6TJGyIWi6Wup91Kv7WxiueODuQ95nKJQWSzIL5ZiBMKIepJ7i2xChgEfgdcbPFQyysihLgOuA5gxYoVhRiiRjMjZHMxmQWiGIVr6tzlIBBWrdALORbITyCMIjYYjPDh255jR9sAXzh3Nae3NtDV1UU8Hk8VHqrnma/pqoYAf3m+g3Asjt/jvAFF2buYJgrkCsGrgYNSyh4AIcQfgJcCdUIIz4QVsQzosBnXTcBNAJs3by7NVdNoHODUxQSFtyDKLQahHlMMgcjXgoDJyf6h3d186vbn6R+L8MXXHsdpi8DtduN2u1M1Eeo1WMVWVjVVkZBwtD/I2kXO91krF4FwfsVmjiPAWUKIgEhe2fOBnSTbd1wx8ZirgDtKMDaNZsZwEqQuloupmAKRyzoodvuIqQiEy+XiV08e4t0/3UJdwMufrj+HSzctSd3n8XiIxWJp77HRMlK0NiQrAg72Bqc85nklEFLKp4DbgWeAFybGcBPwKeDfhBD7gAbgx8Uem0Yzk+SKQUgpi+ZiUhN2MWIQdvUfitkgEF3DYX791BEuOWkJf/7AyzixZUHKYjBaEGaBgPTXtaoxKRD5ZjJZxYxKgZMNgwAQQlRJKfMPx1sgpfwC8AXTzQeAM2fi+BpNOZDNgoCJqtyJjWeKYUGoiabUAlHshoVTEYjfbjmKzy34wqUbqfAmYwdKIJQF4UQg6gI+6gNeDvblN3Ua94IodszGiJNeTC8VQuwEXpz4f5MQ4saCj0yjmeVki0EAqX2NoTgCkW0im+lzgf2EXO4WxNbDAzx5aIA3nrqURTUVqdvj8ThutxshBG63m0QikQpUg/3ram2s4mBP/gJhPm4pcHLFvg28BugDkFJuA15RyEFpNHMBOxeTWSA8Hk9RN/AptQVRzgIhpeQrd79IXcDLG05ZmnEctztpTajf0Wg053Vd1VDFoTwtCKvFRSniEI4kVUp51HRTvABj0WjmFLlcTEog/H7/vHIxlbNA3L/zGFsPD/DWM1bg96Q/XlkQkBR1cCa8rY1VdA6FGI84nzaLafFlw4lAHBVCvBSQQgifEOLjTLibNBqNNdkmJfWFD4fDuN1uPB7PnHIxlWMMQhWz5eIXTx6mpa6S849rzrg+RneSEgogtwUxEag+3O/ciiimoGfDiUC8D7ieZGVzG3DKxP8ajcaGbJOkmlAikQher7foe0SXOgZhDNIXA6eN+joGx/n7vl7edPoyPB53hoBZWRDgXCDyiUOUiwXhpBdTL8n9qDUajUOyTZLGQjGfz1eU1hNG/3mpLQiv1wtQ8P5TxvE4EYg/PtuOlHDFacsQ4cGM62MVg4DcAtGqBCKPOISUsmjvVzZyCoQQ4gaLm4eAp6WUuphNo7HAiYsJkpNlMdIYy83F5PF4ykogpJTcvrWNl6xayIqGAJ2dQ2nXR0qZkbGkaiHM19Us9tV+D001/rxqIcrFgnDiYqog6VbaO/FzMrAQuFYI8X8FHJtGM2txYkEAKReT8TmFIFvri5nGSVDY6/Wm2oxMFSkl4VicofFo1snTyWt/5sgAB3vHuOL0ZUBmXyX1moyWg3mFn63z6qqGKg7mKRDmGEQpcFIotxY4T3VaFUJ8n2QH1gtIVkJrNBoTTmIQkD5RFqv9dqE7hOayIAB8Ph9jY1Ovu73x4X3871/3EE8kz3X1S1v54qUn2I4n1yT7u6fbCPjcvPakyXYaxutjrKJWqL+drPRbGwP8bVePo9cG1hlw5WpBtJC+xWgVsFRKGQfC1k/RaOY3Tl1MPp+v4BaE1X4IpRYIr9eb6mVkRW9vr+0mSseGQ/zfA3vZvLKeT7xmA8ctruGpg/1Zx5NtLOOROHc938nFJy6hyu9JjT2XQKhAtTOBqKJ3NMxIyJlbrZhJBdlwYkF8A3hOCPEwIEgWyX1FCFEFPFDAsWk0s5ZcAqFWqG63uygCYR5LOQgEJAPVfr8/4/7nD7Tjcvs46+T1qVYXihsf2kciIfmfKzaxoiHA8HiUnz5+iGg8gdedeb1zZTE9ureH0XCMy0+b3ILGnDhg9X7mY0GsTvVkCnLSsgW2Y1HPN4paWQuElPLHQoi7SfZJEsBnpZSqFfcnCjk4jWa24iRQq9o2FCvt1DiWQgqE0xgEZArEc0cH+fZfd3Ng/z4k0HH7flY1VvPpi4/ngo3NdAyOc+s/j/LmzctY0RAAYEVFmIpEkMN9Y5YttXNZEE/s66XS6+aM1oWp24zviRBi2i6mVY3VQDKTKZdAmK9fWQvEBCGS24JWAGuFEGullI8WblgazezGSS2AmiTnowXh8/mA9FTXb/11Nzf8bR8NlS7ecVoLzbUVdMSqeGDPANf94mk+fuEGOgbHkUiuP3dt6nnNVQIfcXZ1jdgKRDax+vu+Xs5ctRCfoXLavGeFlUCoFGUn6agrGwIIkVkLEQqFCAaDxGIx4vE4dXV1ebmuCo2TNNd/BT5MchOf54CzgH+Q3ENao9FYkEsgmpubM1aghRIIq7EUWiByBYWVa00JRPvgON9/ZD+XnLSEL71uHX1dSSfFhQ0NfOCCjXzi9uf5n/t2A/COs1awrD6QOtfiGh8uIdnTNZLMscxjPF1DIfb3jPHWM5an3W5MWXW5XGmdXBU1NTVUVFQ4EogKr5ulCyo52JseVzl27BihUCh1jNHRURYtWpR2rnJPc/0wcAZwWEp5LnAq4Dwcr9HMQ4z7L1gRCARSrpVS1CUUWiCcpNQaM7i+99A+BIJ/v+R4KtyTaaPBYJAKr5sbrjyFj1+4ntWNVWnWQywWw+t2sbSugl1dI3mP54n9vQC8dE1j2u3m90QVyZmvobKErJ5jZlVjZqprIpGgpqaGtWvX0traisfjoaurK+145S4QISllCEAI4ZdS7gI2FHZYGs3sxq5RnxWzzYIYGBhgZMR6Mlbnc5K77/P5iEajtA0E+d3TR3nrGctZWleZWq1XV1cTCoVSx/vAeev428dfxZIFlaljqP00Vi6sZM8xe4GwG8/j+/qoD3jZuKQ27XbzpGxss2FHrvRhJRDmAjz1vng8HpYvX57heiwlTkbQJoSoA/4E3C+EuAOb/aI1Gk0Sp5MkFC8GMRMWRDwep6enh6Ghoaznc/LavV4v0WiU7/0taT28/9w1wOSkX1NTg5SS8fFx22Ooxy6vq+Rwf5BgJJbxGLv3QkrJ4/t6OXtNAy5X+v1WAuFkws4lEMOhGP1jkwWC5rEpkairq6OiosJyLMUk5yuWUr5RSjkopfwi8B8ktwJ9Q6EHptHMZvKxIOxaNCj6xyJ0DNpPkrmYSYEYHR1N1VVkO59TF1Pn0Dh/2HqEK89cnrIM1GQcCAQQQhAM2u/nnBKIhZVICfu6M2sn7ATrQO8YXcMhzlnbmHGfuSraiQUBOQSiSe1PPelmshqb1+ulubm5LGIQWYPUQggX8LyU8kQAKeUjM3HSCYvkR8CJgASuAXYDvwFagUPAW6SUAzNxPo2m2OTT2iKbayIci3P5jY9zqC/I8oWVnL26gTec2sLZqxscWyh2AjEVi0W5lrJ1YnViPR0bDnHjg/t59NndBDw1vP9Vk3EFNRm7XC4qKiocCUTLguRqe1fXCCcvq0t7jJ1APLEvGX84Z02mQJhFO5FIpMUb7Mh2XVc1JAXiQO8YmydSap18TsrWgpBSJoBtQogVM3ze7wD3SimPAzaR3F/i08CDUsp1wIMT/2s0s5J8XEyQXLFaTSw/e/wQh/qCXPeK1WxcUsu927t4+81P8YYbn+C+HV2Ox6LOYSTfCScej6cm61wWRLbXfrhvjHO/+TC3bu3g7DUN/PraM1i8IH1rT5XqGQgECIfDtoKkBKKpxoff40pmMjkcz+P7+mipq2TlRD2FkanEINTz7K7rsvpKPC6RsiCcNmgsWwtigiXADiHEP4GUbSSlvHQqJxRC1JKsxr564jgRICKEuAx41cTDbgEeBj41lXNoNKXG2BraCVYC0TMS5rt/28f5xy3is689HoBQNM7vn2njpkcP8N5fbOWH7zyd15ywOOuxZ8rFNDIygpSSQCBAKBTKer5sq+I7nusgGIlz30deiRjuYmFV+jQUi8VSgdpAIEBfXx+hUIiqqqqMYymBEMC65mp2mwLVdjUZiYTkHwf6uHBjs+UEbZyUVY2CGlM2sl1Xj9vFioZAqhbC6U535S4QX5rhc64mmSb7UyHEJmAryVTaZillJ4CUslMIsWiGz6vRFI18u6daTSzfun83oWicf7/k+NRtFV43//KSlbx183LO/9Yj3PjwfttJzjgWdY5s58vFyMgIPp+PQCBAMBi0Xf3mEsd7t3dx+sp6Niyu5eB4X0ZX13g8ngrQqklZCYEZdbuUkg2Lanhswm1kHAtkTsIH+8YYGo+mVU8bMU7KanxOXUzZrutqQ6qrk4JC81iKjZMg9SMkYwLeib+3AM9M45we4DTg+1LKU0laJY7dSUKI64QQTwshnu7p0eUYmvIkXxfTvp4xvn7vi5z4hfu47HuP85k/vMBtW45y1UtbWd1UnfF4j9vFv758NduODvLPLI3q1FhgemmusViMYDBIbW1tzqyrbG6TI31BdnYOc/GJSatHZTIZn2t0MeU6VywWS51rfXMV3SNhBgxZQnaT8Pb2ZBbWiS3WbS+MQWrj3uG5yHVdVzVWcahvjERCOhYIp48pBDkFQgjxHuB24IcTN7WQTHmdKm1Am5TyqYn/bycpGMeEEEsmzrkE6LZ6spTyJinlZinl5qampmkMQ6MpHE6zmMKxOO/40VP8+592sO3IABeduJgKj4s/PdtOY7WfD52/zva5bz59GQurfNz06IGs55gJC0IFp2tqahwJhN1rv3dHJ0DKLWYWiEQikWpiCNkFIpFIkEgkUmKyvjnZZsPoZrKbhF9oG8LncbGuOVN8jY9PJBJEIpHU3uG5yHVdWxurCMcSdA6HHLsDHTT7AAAgAElEQVSYnBy3UDhxMV1PslHfUwBSyr3Tcf9IKbuEEEeFEBuklLuB84GdEz9XAV+b+K13q9PMWpwKxGN7evn7vl6uP3M5rz9pMcetWw1ALJ4gGpdU+uxdNRVeN1ed3cq3H9jDnmMjqQnSjNWEne+EoyZJn8+XWlHbCUQ26+ne7V2c2FLL8oXJwLDP5yMej6eCwOaeR9ncK8q9pAru1k6kke45NsJZqxvSnpchEO1DHL+k1rL7q/m8kUjEkXtJPS+XBQHJnkwNy6stxzaV4xYKJ07S8EQgGQAhhIdkaup0+CDwKyHE8yR3q/sKSWG4QAixl+RmRF+b5jk0mpKgslOcCMTdL3SyoNLLW89cid9jKJhyu7KKg+JdZ6+k0uvOakVYuXzynXCMgqd+22UW2bmYuoZCPHNkkIsMQXUVY1B+fjXpG1frdhle6rHqGE3VXqr9HvYbaiGsBCKRkOzoGOaklvTqaSNGgQiHwzMmEKtVV9fe0bxdTOUqEI8IIT4LVAohLgB+B9w5nZNKKZ+bcBOdLKV8g5RyQErZJ6U8X0q5buJ3dseqRlMGRKPR1Ipa4fSLH47FuX/nMS7c2IzP455SXUJ9lY8rTl/GHc+1W1YRg/WKPt8Jxyh4anWfr4vprzuTabkXnTgpEGriVQJh1TXVvLubwmhBKNYsqmZ/T3ohGqS/F4f6xhgNxzjJJv5gfHw0GiUejzuKP6jnZbuuzbV+Kr1uDvSO5eVigjINUpMMIPeQ3F70vcDdwOcKOSiNZrbQ09NDR0d65xmnX/zH9vQyEo5xyclLprVCfOX6JqJxyfb2Ycv7Z8qCUMfIFhfIltt/zwtdrF1UndaS2+v1IoTIKhB2xWdmC0JKyZqmqrRqaqv3YntH8jrZBajVOYUQKfF3akHYiZnxuOaeTLPdgrgM+LmU8s1SyiuklDfLUoxUoylD4vE4kUgk5+5jVvxlwr10ztpGWzeKE05enpzonm8btLzfLgah7nOC8Ri5BMJ4fEUoGuefh/p59fHNGePw+XwZLiazBWEnEG63O82iWdNUTddwiNHwZPqreTzb25MBaruYjXFsqt5jpiwISMYhDvTMHYG4FNgjhPiFEOKSiRiERqNhcpI0upnUZJct6yUUjfPAhHvJ63alVp5TmQQW1VSwZEEF29qsG+jZuZjAuUAYj6EmZKsYhJ04vtg5TDwhOXVFXcZzjAKhgtXG8WZzMRkfm7Qgkj7+Az2jaa/PeLwX2oY4fnGNbYBaoSZlpxlMxudk47SV9RzpD7K7czj1+uzoGgrxxL7e8hUIKeW7gbUkYw9vB/YLIX5U6IFpNLMBK4EIhUIIIVLFXlY8tnfSvQTZV+UjIyNZ22sDbFpWl9WCmK5AGI+h3C/5WBDZ3DoqC8lcA2Ecq50F4fF40q7d2kXJLKH9NgIhpWR7x1BW95JCHdepe0mdJ9c1fdNpLfg9Lv7wzJG0sZnZ3zPKG773OG//0VN0DtlXrhcSR9ERKWUUuAe4jWTl82WFHJRGM1uwEwifz5d1ZXi3wb0E2Sfsvr4+Ojs7GR3N7FSqOHn5Ag73BRkMRjLumwkXkzlt187tYycQO9qHqA94WbogUzR9Ph9SSqLRaMoqMJLNxeTxeNJey4qFVbhdgv3d1tXKh/uCjISyB6gV6jlO3UvqOblchXUBH5edspS/7jhGMBK3FIhdXcO89Yf/IJZI4HUL/rrzWHlaEEKIi4QQPwP2AVeQ7MK6pMDj0mhmBXYCkc16ONof5C/Pd3LJyUtSbo5cBWFSSjo7O217IG2a6GD6vIWbaSZcTGYrxO22zrqyczGpVbvVZGjMZLJqimflYlI9kswWhM/jYuXCgK0F8UKOCmoj6jkzbUEAvOvsViKxOI/v6029vnu3d/L1e3dx/a+e4S0/+Adul+C2687mkpOW8NCuHoJh6yy1QuLEgriaZOX0einlVVLKu6WUxR+pRlNmSCnTBEKtgo29hKz4xn27cbngg+dNtrjOJRA1NTW43W7a29st+xKpCW/b0Uw300y5mMwWhFUMwsqCiMQS7O4a4YSl1pOymoBV11YnLqZ4PI6UMsOCAJXqmi4Qauzb24fwuXMHqI2vIV8LwnheO05sWcAJS2p4eHcP4ViCj//ued73y2e4+dED7OgY4sxVDfz2vWezdlE173ppK2PROI/ssWwuUVByRl6klFca/xdCnAO8XUp5fcFGpdHMAtSk5ff7CYfDaTURdgLxzJEB7tzWwYfOW5u2dabdxKL88j6fj4aGBg4fPszg4CCNjel7GCyo9LK6scoyUD0TAmG2QvJxMe05NkI0LjnRpjDN5XLh8XjysiCUOFkKRFM1D+/uJhZPpMaoHvPs0UGOW1KDz+OsvQXkb0GoseTKTrps01K+e9/zXPydxzjYO8aHz1/HB89bi8cUPD91eR1rmqq594VO/vUiZ7v1zRSOYhBCiFOEEN8QQhwC/hvYVdBRaTSzADX5VFYmJ/pwOJwKUFutOqWU/PddO2mq8fPeV65Ju8/OgjCugP1+Px6PJ613kZGTly2wDFRPNwZhVRluJxBWLqYdHRNuHRsLApKTsNprwiwQVhaEugZKIIyPWdNURTQuOTowniZYnUPjbDnUz6s2OOsU5HK58spgUucBZ9f1nHUN1FZ66Bgc54a3ncpHL1ifIQ7qmK89aQltg+P8Y3+f47HMBLYCIYRYL4T4vBDiReD/AUcBIaU8V0r53aKNUKMpU4wCoYqqQqEQfr/fulBsexfPHBnk4xeup8qfPunYCYS5cMzc3M7Iycvq6B4J02XKeJluDMLKKrCLQVjXHQxT4/ewYmHmxjwKn89n2WYDJi0I41iNFoTxMZB0MQHs705vZ/HHZ9uRMplF5ISKigqqq62b+dmRz3X1ugSfvngjf/nQy7l009Ksj33F+kXU+t388qnDeY1numSzIHaRbKT3einlyyZEwX6fQY1mnqEmSGMTu3A4bOte+v3WNpYvrOSK05dn3Gc3sZhX5NkEYtPyZKB6m8mKyNfFFIlE0m63sgryiUFs7xhi49JaXC5714jRjWPlYjKOAzJ7NqVZEBP9jvb3jKZeu5SSPzzTzuaV9axsyNx4yIrGxkYWL86+GZOZfAQikUiwoqGKtYtyi5Df6+as1QsnYhbFm4azCcSbgC7gISHEzUKI80lu3KTJk0QikXUPX83sxDhx+v1+xsbGbAPUUkqePTrIWasacFtMlLksCKNAxGIxy9X7CUtr8bhEmpvJyj0E9hNZLBbj0KFDaXUXVpO+cjHlErRYPMGLncM5s4ayCYTVWM1FcsbsoQUBL43V/pRAuFwunm8bYl/3KG86fVnWcUwXNR4nVfFO4hTG456yvI5gJM6WgwPTGmM+2AqElPKPUsq3AseR3P7zo0CzEOL7QogLizS+OUF3dzft7e2lHkZR6e/vZ3DQunBrrmAWCDVBWQnEkf4g/WMRTl1Rb3ksu4nFaKXA5ERqZUVUeN2sb65JS3W1q0uwEwiVHWRc0NhZEFbPN5/vQO8YoWjCNkCtyNeCMAezzTGRNU1V7J9oZyGE4PfPtOHzuFKFiYXC7rpYYSXcdgghOG5xMrj+0O7iZTM5qaQek1L+Skr5OmAZ8Bx57ACnSa527NwCc5XBwUGGh62bx80VzAKh/rbKenn2SFIsrVpNqOeBMxcTWAsEwEktC9jePpQ6Ti6BsHtNxsnWLgYBme02MuoO2nIHqIFUPYMQwlYgzG6vbDvkrV1Uzb7uUeLxOLGE5M/bOrhwYzO1Fbn3lZ4O+bqY8slI8ntcnLW6obwEwoiUsl9K+UMp5XmFGtBcRO18NV9QRUxzXRStBMIuQP3skQECPrdt/r1d+wqrIDXYC8QJLbUMBKOp1gzmOgDj+Yz3m19TruaDdi4x82O3dwxR4XVZbptqHo/P57Pcy9rKujLve21OhV3TVM3QeJSf/+MQP33iEIPBaMHdS8axFsKCkFJy7oYmDvSMcaQvOK1xOiUvgdBMDSUQpSiVLwWqr04sFpvTr9k4GXo8Hvx+P1VV1gHQZ48OsmlZnWX8QWGVOmqecN1uNy6Xy14gliZdOTsmeh+Z6wAU+QiEXQzC/Dj1WPW4LYf6+dOz7Zyc43UrqqurLa+fnYvJbEEY7z+jdSF+j4vbn27jod29rFtUzcvXpteOFIJ8BSKfGISUMpWi+3CRiuZ0Z9YioD64VlWicxHj5BWLxVKr3rmGcnOoL/nKlSstv/ChaJydHcO85xWrsx7PriDMeA7Insl03OJahEjWHlywsTnvGIT6rBpvt7JCsgmEy+XiN1uO8Lk/bWdZfYCvXn5S1tetaGhosLzdaqy5XEwnLVvA7v++mLa2NuLxOCtXrnQ0hulSKBeTen2rGqtobQjw0K5u3nV263SG6oi5P1uVAVarsrmMat0MSbGY6wKhsPuyb28fIpaQnLrcOv5gfL6VBWF2Q3i93rRrbKTK72FVY1XKgrATCEU+LiZzDEJKye+3HmFHd5T2wXE6h8bxhIYgHmF3MMDL1jbyvbefxoLA9N5/KzHKp3mgUzfOTFBIF5N6zqs2LOLWfx4hFI1T4c29Le10KJmLSQjhFkI8K4S4a+L/VUKIp4QQe4UQvxFCOK9vL3Pmm0CYLYhyQkrJwYMHs3ZGdYrV5G2FClCfYhOgVti5mMx+eWN7bCs2Lqllp8nFNJ0YhJ0Fcf+Lx/j6PS/y4K5jjIZjrG+uYdPyOs5oXcjnLjmen737jGmLg/G8RuvGfF3smuTl48aZCQrpYlLPOfe4RYRjCZ48UPiq6lJaEB8GXgRU/tvXgW9LKW8TQvwAuBb4fqkGN1MYK0DnSy2EshpU++ZyQu0AFwqF8q6SNeNYII4OsKy+kkU19g38ILuLyYjX602lolq5LE9YuoC7nu9kYCyCj6m5mHJZEFsPD3L71nZesbaFG695Req+jo4OIpEIra2tWV9rPpjHahc0t5qUrQS2kBTSxaSO+5JVC6nwunhoV7fjtiFTpSQWhBBiGXAJydbhiOSrPw+4feIhtwBvKMXYZhqrL9pcJxqN4vf7cbvdZZfJpN6DmRAuq8nbiueODNrWPxjJx8UEWTKZJgLVOzuHpxyDyBak7h4J8cHbnqOx2senLlqfdux8UzedYLYgrATC6tqpsZejBWFXwJjruJCsd/nFtS/h3y7cMPWBOqRULqb/Az4JqHe0ARiUk23E2wBnDVPKHHPmxXxAWRAej6csLQjj7+ngxILoGgrRMRTKGX8A5y4mxwLRMZzVxWTllrEKUpuP8Znfv8BwKMr1562n0tQVtRATsnms2SwIq8K9chUI4+Odop53RutCFlQWPrZXdIEQQrwO6JZSbjXebPFQyysshLhOCPG0EOLpnp6egoxxJnFiQYRCIQ4ePDgnBES1gfD5fFmzbUqFMaNsJo6VSyCeOZJsi2BXIGckHxcTYBuobqj2s7i2gh0dQ5ar/5sfPcDDu7sZCWWmIavrYrYg1BiO9gd5cFc3/98r19LaWG2bxTTTGMXTzoJQ5zePpxQCkctbkK9A5OO6mklKEYM4B7hUCPFaoIJkDOL/gDohhGfCilgGdFg9WUp5E3ATwObNm8s+yd6JQASDQSKRCJFIJNU6eraiBEFZEOPj446fK6Xk8OHD1NXVUVdnPaH29vYSCoVYtmxqRU/FFoh7t3dRH/A63sHMiQUhhMgpvicsrWVHR7qLSUrJx367jcf29gLQ4hqiubGe6y48hdecsDjt/ObPrZqgbt/ahhBwxeZlRAePORrvTGAcm7l4UN0P1gJRjllMdpbddI870xTdgpBSfkZKuUxK2QpcCfxNSvkvwEMktzQFuAq4o9hjKwROXEzKDVNuq+2poFa1Xq8Xr9dLPB53HHsZHR1Ntcy2IxQKpZriTYViupiCkRj37zzGxSdNbi2aDbOLSRVXWp3DiUDs7xllfGKbSiEEv9lylMf29vK5S47n1vecxVvPWE40Fud9v3yG13337/xmyxGODY2nnRsmJ9lEQnL71jbOWdNIS12lZcvvQq3YjdZVPpXdpbAg7DKqjEzXgihWPLOc6iA+BdwmhPhv4FngxyUez4zgxIJQX/Ry89dPhWg0mlrhqgybWCzmaFcu1dwv23VQ1zAYDFJTk3vbSLvnq6Z0U508nAQZH3ixm/FoPGevf4XRj25cMdsJxNjYmO2xNi5dQELCvu4RFvng2EiYL//lRc5avZBrzlmFyyVYxFLe9JI1PNmZ4Ia/7eVTv3+BJa5hltV6ee8r17DOMA4hBE8e6KN9cJxPXrQhNS6zSBVqxW5l3ZSji0mNxalATNWC2L9/P3V1dTQ1NU1jpLkpqUBIKR8m2SkWKeUB4MxSjqcQGLtxzgcLIhqNpnb5MgZTcwlEJBJJ7SiWbXWv7hsfH5+WQKhjTbWy3YmL4M5tHTTX+jmzdaGjYxr918bPi5XLxtj222oMKlB99wsdbFzo4r7HBoklJF9/08mpfRlcLhcuIXjT6cu4/LQW9naPcv+T27jzuXb+9Fw7rzrjpJRoCSH43dY2aio8vOaExannW7mYCmVBmF1MuSwIo9gWEycCYdcCJdsxYXIL2mKl75aTBTEnUR8Er9eb04KYKwKhhMFoQeRicHAQIQRVVVVZXUxqclBiki/G9yAWixVMIIbGozyyu4d3nr0y60Y5RsxdS3NZEGBvnS2rr6SlrpK7X+jkMRGmLVHHF1+/MWOzHKOrY31zDRy/iLFwnDu3tXGgZ4T1S+qRUjIeS3DP9k4uP21ZqnrXSiAK6WIyWhBCiJwWxFQzhaZLIV1MMPl9KkaHAi0QBUZ9qNWm7Fb3q0lvLriYIpFIamWvJt9cwpdIJBgeHqa6uhqfz8fY2JjtRKNWzOFw2HKD+1wYrZPpxCFyCcR927uIxBOO3UvGY2VzpShyWWdCCB782CvZfbCNoeEhVrSuobWxKuMx5glVSsmFJy3lnufb+dU/DvGly+tJJBL8fW8voWiCNxs6otrFIIrhYjKfw86CUM8tJnZtP4zkG6RWqCaYkLk1ayHQ3VwLjFrt2O3hq97sciwqc0IsFqOvr49EIpESOzV5CSEc1UKMjib79tfV1aV6/FhdKxU4DQSSextbWRHxeJy+vj7bFZxxcimkQPx5WwcrGwKcvCx39pLCPMllczHZ7cdgpMLrprnWT0t9VYY4QKZAqPM21QY4c9VC7niunaHxKHu7hvnZE0c4bUUdpxjqOZT7yVg7UawgtZPWIfn6+WcKJwIxnSC1Fog5hPow2wmEEoXKyso0a2K2cOzYMXp7e1MtFiDd9M2VbRMOh+np6cHn8xEIBLK6pdS1qaqqwuVyWQrEyMgIvb29hMNhy/MlEok098xUySYQ3cMhntjfy6WbluY1WZoL4LKdw4lAQPYVvZ1AeDweXr2xmVAkxjfv28037t3FgiovP3zn5qwtvwu5YjdbEE62Jc3Xzz9TZIs3KrRAaIBJgVCrCvPKVr3Zqv5hNrmZRkZGGB0dpaqqirGxMTo7O4F0gchmQQSDQY4cOQLA0qVJV0w0PhmIM2MM+FdWVloKhDqX3TmVhSOEKJgF8cunjiCBN52WX62GuQAumwWhWoDneg3ZgsbZBGLFwgCbVy7gF08eRsoE/3nZSTTV+DPGYHzeVN0mTjAHqeebi8koEMZEkEKjBaLAGAVC/W/ELBDl7Gbq6+ujp6eHeDxOPB6nu7ubiooKWlpaaGxsTE1sRp+4nQURDAZpa2vD6/WyYsUK/H4/vaNhLv7u43ztnl2092d2WzVOmIFAgEgkkiEEuQL+RotuJgTCPHmHonF+/dRhztuwyNKtkw218ZDRglB59WaU2zLXgiKby8csEOp6qJXpNee0snxhJR+9YD3LF2a+FrMVU8gJeTouprloQRRrXxktEAXGOCFBpktArQZy9dcpBwYHB+nv7+fAgQO0t7cTj8dZvDhZgdvQ0EB9fT0VFRVpX16Px2NpEah228uXL0+99q/evYuBUIy2gXGu/vGTPGzae9e46rKLQ+SyINT74fF4piUQVqmWkExt7R2NcM3LVk3puD6fLyW0uVIZnU5EU7EgAE5dXsdjnzyPtU1VlivdYruYVIyj3IPUdu5kI1ogNIAzC0IVlQkhSupiGhkZySpQ8XicmpoaAoEA4+Pj1NfXp/ZiBli0aFHGzl12mUzqdasJ8KkDffz+mTb+9eVr+fzrT2BRtZerf7qF3245mnZ+SH4B/X4/Lpcro5VHrpoSNemaV9/hcJiBgQHb1251HEj/gksp+enjh9jQXMNL11jvjpYLo8WVq1usU4GYSgzC+L+dm6rYLiZ1DqcxiFK6mOwSLRRTdTFBcXdp1AJRYJxaEJA7oAtJ//TQ0FBGLGO6jI+P09HRwcGDB+nq6spIyVWVx8qltHr1ahobc+/xaxcQNq6CovEE/3HHdlrqKvngeetY1lDNt998Mi9f18in//A89+88lhoDTPrf/X5/xjizVaUbW1eYJ9fBwUG6u7sdWxXqfTV+cf95sJ+dncNcfU7rlCcln8+XKoCbCQsiWwzCqrWHOq4Sj2wTWTEtCLNAOOlOW0oLArInEEw120u5d4tlQeg6iALjxIJQG7VnE4ixsTEGBgZS7RVisZjtHr5TQblqFixYwPDwMCMjI6xevTr1YTf73J2uYAbGY/zXXTupa+jmna/YyJmrFqYspZjw8PDubu7c1smeY6Pc/K7NVPqSq3u3S/KDd5zO229+kg/8+hl++M7TCQ4P8MKBdvpfCBPwuwlEhzl7VS3LlyfPpUQMrC0I42RnnlxV1lMoFEq9H9mwmqR+8vhB6gJe3nDK1DvVG12Nueo8putiUm42q9Ye5qQKq2MUMwahjqnGayVY5maHpUxzhez9kvKtF1GvX32utUDMEcwWhLnVgzHt0uPxWKZnxmIx2tvbcbvdNDY2EgqF6O/vp7a2dsZMzfHxcfx+P83NzQQCATo6OojFYhmTQD6FaeFYnA/c9jwDQyEOjfZx101PsrIhgBvwjB3jWNjDkKzEJeBtZy7ngo3NAKlAbZXfw0+uPoM3/+AfXP3TLdSLINWuGJGqBMFwHFd0lL+/2Mam49dTUzEprsqyME+Oxtfg8XjSVqPKEpmqQDz44jHu23GMD52/jkrf1FsgqAB/JBJJ+2xYYZ7grcg2ERnjQ+p6wKSFZhQIOwvCmElVDBeTsgztxlMuaa6Q3YLItyWJFog5iDGgZlWcZWyNrX7HYrGML3woFEJKydKlS6msrCQajXLo0CG6u7tpaZn+vkpSSsbHx1mwIFnUZaxFUDGGfAVCSskX7tjB1sMDfPWC9bxk7SK2dEvu23GMSg80JqI0LWrmtHUtbFpWR5V/8qPodrtT7TYaqv3cet1Z3PNCJ4u9IVYu8HL8hrUAPLbjCJ/99WN84y87+K83nZKWERYOhzN8tWYLQr0uY/1JtjYfRowC0T0c4hO3P8/GJbVcf+4aR8+3w2hBOHExQfaeUtkmIuP7rARCvSZlQeSaZI1pzMWwILIJhJ0FUYoYBGgLQpMD4+rLuCpTmAte7NonhEKhlM9dPa6hoYGenh5GR0eprq6mc2gcv8fNwqrcXVPNhEIhEolEKtXWagWUr0D88snD3LblKB84dy0v31BFLBbjrWe08tYzVhAKhTh8+DAtLS2W+0KbV8bNtRVcfc4q2tra0sa0eXUTrz6umVu3HOK1pyzn+Ibk2ITHS9tAkF3b2ljWtIDTVyab5dkJhDqm1+vNWyASCcnHfreNYCTGDW87Bb9neg3UVIZVJBJxFKRWr8FuwshmXajnq8+hlUDkctMYs8GKEYMwdh6wesxsiUFM14IoVpBaC0QBMZvcLpfL0oJQX25jxo9ZIHw+X9qXtL6+nsHBQR54Zi93HYzx4K5uVjVUcc9HXp73JKXiDyp1dLoC8ULbEP95107OO24R/3bBenp7e9KyjXKtglS7DfPEZ/bJe71eLj+thSc6DvKp3z/PBasq2XWkky29bprFCH2JAOPCx83v3MyrNzZnBLkhOeEo91JtbS19fX2MhyN4PR48WfZwUO6fmx87wGN7e/nyG09k7aL8u8ta4fV6CYfDOVeZ0w2GqmtrdBGpY5ozcbKJjHo/C+nzd+JiKjcLYqaD1CoIr5IIioHOYiogZoEw50fHYrFUvyKwz/gJhUJUVFSk3dY9EuaL9x3mf+/dyfNH+njz6cs40DvGDx85kPc4VfxBTQ7qA2gcRzwez+igacVIKMoHbn2Gxmo///vmTbhcItXJ1tyU0G4VZJ64FGaXi8fjocLn4RMXrKVtIMhd29rw+7xc96p1XPeK1dz8zlM5qWUBH7rt2dT+zPGEZMvhQUIxmTpHJBLB4/EQCATYeniAi//3QV71zYd5bE8PBw8e5MiRI4yMjGT4tx/Z28tX79nFa09azNvPXOHoWjvB5/OlYlFOXUxW5NqzwtzWJJsF4cTFVEifvzFIrcZn9ZhysCAK4WKCyddRLPcSaAuioDixIMxtKdTtxsfE4/E0gXhg5zE+cfs24tEI7z9rJW9+xUk01C1gLBLn/z20j0s3LXVcxaviD7W1tWm3mzNk1Oo925dNSsnn/rSdo/1BfvPes6mfcHcZXWeq/kBVAlthdH0Y6yzs9mc+vtnL458+j7H+Y/jcLlasWMG+ffuoqankR+/azGXfe5xrb9nClSfX89Bz+9k2UsnJy+r44qsWEo/HCYfD9AbjfP5X2zh88ABNjQ0MJVy89yd/57INlbzxtJWMj4/j9XpThX1bD/Xxvw8e5uzVy/jWW06Z0UnI6/U6Wo2bXURmck2Q5mrsbDGIXC4mJUbZzjcdnAapy8GCUNc1l4sp307E6nUUy70EWiAKipVAmC0I42rAqvup8olXVFQQisb5yt0v8vN/HGbjklq+c+VZyKEuZCwpKJ9/3UYe2d3D5/+8g29ecTJ/3tbBI3t6aKjysbKhijNXLeSctem1Cyr+oNxLCiuByDZZDYwNobkAABjMSURBVAYjfO+hfdzxXAcfu2A9Zxg2yTEKREVFRc5CH6cWhDp2JBJh1YJKDvQl8Hr9qWPEYjFaaiv48VVncMUPnuAnfz/AGUv8fOzsDXznwb186/4+vvSmOu559gi3bO0m5K7m+nPWcNGJS2le2sK3//QEdz3Xzq27Y2xqruDMZkHimR4G4n6e3b6XNYsauPmqzan9EWYKo3txuhYEZJ8gzRaAuvbmLKZccQzj1rKlikFYuZjsWpUUmlz9mKbqYgJtQcwZrFxMxsKuaDSakVJproVQAeqDA2E+fNtT7Dk2yrUvW8UnL9qA3+Pm0Hh/SkSaayv42IXr+dKdO3nJVx9ESljfXM2BnjHu2NaBlHD7+85ms2HyVrEBFaBWmFtR2OXkByMxvvu3ffz8iUOMReK86bRlvP/ctRmvSb1e9Tvbh9xqZWwscjNi3D/CKLjG67hxaS13XH8OA309LPQlWLt2Leuba/ivWx/m3T9+gkQ0zKbVy/nyW85Ejg8xMjKCSMS4/ORFvO601TzRFuLBXd3cuf0wXnc/icBCNi2u4eOXbaLaP/NfIaN4ZhPlXCtVJ2mnRoEwLgLysSCAtOy7YriY7Cq7zW7AUogD5K5R0S4mG4QQy4GfA4uBBHCTlPI7QoiFwG+AVuAQ8BYppfPeB2VINheTVRAWkpNDMBhMfdlCoRB7ekJ8/BdPUO33css1Z/LK9ZP70Pr9/rR+RO88ayV7u0epq/Ry+WnLWLsomSU0Eopy4bcf5Ut37uSO689B7XIWDAbx+XwZ4zCLmXGfB8VoOMY1P93ClsP9vO7kpXzg3LVsWJwZqFVZQ8YqZ7Mgmc9t7lRqFyRX7hgV1DUG/I2B8XXNNXQmRlO3XXjCYkYuOI5bn9zPxSe08rbzTiUQqGBIhhkcHKSnpwchBBtbF3PSGjfvfeUaurvXMjg4QGtrKwcPHmRhdXpcaKYwWhC5JpFsE5FTC0K9z8ZJy2kMwijmhdosSJ0/V5DWzoIoBbn6MU1FvOaFQAAx4GNSymeEEDXAViHE/cDVwINSyq8JIT4NfBr4VAnGN2NkczFFo1GklBmTblVVVaqSuaamhq37j/GVBw7T2tjEL659SUbL5YqKCoaHh1OrZ4/bxVfeeFLqHAcPHqS5uZmaQIBPXXQcH/nNc/zh2XaumNgZLBQKpVJNI7EE45E44XicUExmTNDGOMhoOMbVP/knzx4d5IYrT+X1OXZOUyt6p83GzK42u5WsmkyVSBprSpTbwxg0ND7/rLVNnLi4MnUdjb/Hxsaora1NE6SammoGBvoZGRmxHMtMoVJdjYWKdkxXIFQMQi1YjJ9VyB4UhnR3YKFX7GqB5bS3VCkFwuVyZW2bM52xzekYhJSyE+ic+HtECPEi0AJcBrxq4mG3AA8zxwRCrSpUYBjIyE6qqalhYGCAnp4ethwZ5oYH97B4YSM/e89ZljUO6vnGiV4xOjpKJBKhs7OT1tZWLt20lJ89cYhv3LuLi09cTKU3+YULJwRfvftFfvrEISKx5JgbPBE+f8Ey1qxJpL6YarLqHgnxvl9sZVvbEDdceSqXnLwk57VQqZsqoJnrQ24VA1G3m48LkwJhlTKsAt3mGIaxbYh6j1Q6cSKRoK5ucvc0SF5rt9tdcIFQY4rFYjnPYbeVLTjLKlLV1Obgr1kgnBTbFXpCVse2uyZWQepit9lQ5LIgtIvJAUKIVuBU4CmgeUI8kFJ2CiEWlXBoM4KVBaFuHxsbw+PxpGXpQPJDUN/QyA/ueoo/vnCM1roKvv3ul9oWwKnnh8PhDIEIBoOpibazs5OWlhY+//qNXH7jE3zg189wfHMl0cFu7tq7h66Qizee0sIJLQvweVzc9vdd3PjwfjauX8ea5tqUaf/Y3h4++pvnGA3H+N7bT+WiE3OLAyQnvNHRUce7YRn3RQB7gVBdcJXgGi0IyKwGNwqTOpbRpSOEoKKiIq1w0HifsvCgsALh8/kIhUKOXEy5sphyxSBgcpMi9VhjnUi2uIIxDlLoCdn8PbIai8qmUn+X0oKYyUI5mGcCIYSoBn4PfERKOez0YgkhrgOuA1ixYuZyzwuB2aVhzPgIBoOWPX8O943xodueo62tl1evredfzmqluc4+ZdXlcqUmEyNSSoLBILW1tfj9fo4dO8bAwACnrVjIda9YzS1PHOKpvREaGGXNyuXc/LpNnNgyuX/ymS0BPvKTB3n/L5/mZ9e+hBc7h/n5c4P8+rle1jZV8+v3nMX6ZueFYSpWoCbyXB9yY7sNsHcxCSFSmUzG1FmrlGHz+6EeYxZptbudFcUSiAULFjhyJRitUvN3yGkMAjIFwmhB5PpuKpEqhovJ+Nvu/nIQCOPe6ubxTjX9Vn2+i2kVlUQghBBekuLwKynlHyZuPiaEWDJhPSwBuq2eK6W8CbgJYPPmzTPb83qGMX841N/BYJB4PJ4hEFsP9/OvtzxNPCH57zefzXHV41RWVub8IFVUVGRsnBMOh1PpqzU1NQSDQXp7e6mrq+Ozrz2ez772eIaGhujs7GTNmjUZk9HKphquP28dn723nXO/8TeaXaMMiRreduYq/uOSjXk3pFPHdyoQ5nYb2Sq5lUCYa0rMxX52LiajBWF3DkVVVVVq8inkF7WysjJrIF9hnIjM454pgXDi5splacwE6th274+6X73uUlsQYN31d6pNDY1FtcWiFFlMAvgx8KKU8luGu/4MXAV8beL3HcUe20xjZ0Go3dSMtQf3vNDJR37zHEsWVPCzd59Ja2Nyn2cnxTR+vz8tUA2TPnk1ydTU1KQ2BFIr5mg0avuhc7vdrFtUzZffsJGtR4bYuCDGq8/YyMIFU2snYRSIbEVyCqtOo3aV3CrV1aqmJJsF4fP5EEI4mogVbrebiooKxsfHS+bfNo8HrNOQnUxE6jl2AuEkDuJ2uwmHwwVf3eZjQUDp01zBuk/WVC2I2traGd8HJhelsCDOAd4JvCCEeG7its+SFIbfCiGuBY4Aby7B2GaUbBaE3+9PfXAe2HmM9//6GU5ZXseP3rWZhurkBO6k7TRMBqrD4XCaQBjPYaxFUAKhBMXqg6o+4OesWcgrNyyis7OT6kp/xuOc4vV6Uyt69Xc2zF+wbCtZY7t0I+YiMPOqv6KignXr1uX9Ra2pqSEcDpeVQMRisQxLyMlEpFKQ7QTCWDxnh8fjYWxszJHwTwcnMQhI38CoVO9Rtn5MU7UgVLflYlKKLKa/A3af2POLOZZCYycQUsqU9TAeifOFP+9g/aIabn3PWVOqylUTvtrLwNy+GzKL1SCzktuIy5XsQKtcB5DfXhBmjCt6J2ayueV4ts1zzIFp4+3KpZUthpEvdXV11NTUlIVA2FWdg/OVqpVAGN01uZ5v3FujlFlM5eRistr/RVGqFiBTofSf8DmMnYsJJq2D7z20j/bBcf7zshOm3LLB7XanVRSPj49ntM9wu92Wldy5KppVO2w7904+2E3kVqjVsApUZ+tdox5rPq7P50v1sprKhkd2lMIXbEe2dhtOJyLja7FapTtxMUHy81QMF5Pde2i0eqB8LQgtEPOM/v7+tKpdhZUFoQJ5lZWVHOwd46ZHD/DGU1t4yerpbR9aV1eX2ldamftm37q5jUeunkhGgVBjnw52riC7c/v9/tR1zeZi8vl8tLS0UFOTHh9Rr18JJhR/+8lCk00gnL5m4/thbPetyEdgtAWRJJsFMZs+i+U/wjInGo3S09NDV1dXRgDJKoPB5XKlMpO+dOcOfB4Xn7n4uGmPo76+nubmZkZHR+nv709r360wCoSqfM02WSvff669kZ2Sj0BAMog/Pj5um6VjpLq6OuNaV1RUpGokZtOXMh+UZTcTFoQxCykfC6JYAuE0SG20IEqdxaQtiHmOykiKRCIMDKS3jrISiIaGBryVtVz3i608vLuHf7tgPYtqZ6anT11dHUuWLEkVdJkxt7tQt9mh8ttLJRCVlZUkEglCoZCjdEszLpcrlXGUq2XEbMbcWFHh1MWi3g+rxQw4i2GYn1MInAapyyGLSQXsZ3sMojwcqbOY0dFR/H4/Xq+Xvr4+amtrUymaVl/QQyPwwVu3cmw4xOdft5F3n9M6o+Opra0lEAhYTug+ny8lDk4qmo0uppno/1JZWUlFRYXjtFIVQwkGg1Pqn6/OOTAwMKMxiHLDrh+T0wnSyq2k/rda5Fg9vxiFabOpDgLsq6lnkzVb/iMsY+LxOOPj41RXV9PU1ISUkr6+PiDzQ7Dt6CDv+fnTvPHGJ5ASfvves7nmZasK8gG2S101ZjI52fxcCZ3a6Ge6eL1eVq5c6diCUHGI0dHRVKuPfKmsrExVlcPs+FLmi127DacT5HQtCGN6ayEnZPW5zidIXUqB0BbEPEdlDVVXV+Pz+airq2NgYIC6uro0c/hb9+/hhgf3sqDSy4fPX8c1L1vFgsridWRUGAXCvN2pFcZAW6lW3oFAIOW6m8rkrqwVFbifqwJhbrUCM+dicnIMJVKFvL7V1dVZFxiqUC8SiRR0f2ynTDc2VA7MvW9LERkdHU1ruNfQ0IDL5aKvry+1chgaj/HDR/bzmhOaefzT5/HRC9aXRBxgcgWmBCLXFqJWbSmKjTlVN1+UFVLKlMdCM10Xk51AqOfmc4xCu5jMfbPM9wcCAcbGxgq6u51Tsr0vMDus2fIfYZkipWRsbIzq6uo032h9fT0jIyOp9MzfP9tBOJbg4xduKMjuY/lgbGxn3g/bCqv0x2JjjFdM9QuljjEbvpBTQcWWwuFw2u1OXSyqKHKqLiYojkA4IRAIEIlEUvU+pY5BzHYX09z8xhQBtUoxt9iur69PWRHReILfPn2Uczc0sS6PzqeFRGUyOdm0pxwsCGUBTGcMc10gjMF8I/n44GtqajIy3/J1MTl9bCFRr0FlF5arBVHoxoYzxdz8xhSB0dFRXC5XmgsEJq2IWCzGk/v76B2L8Z6Xry7RKDOZbQIBkxPgdC2IuZjBBMn31OfzWQqE02u2ePHijF4/s9GC8Pl8+Hy+shAIl8uVymZURKPRVMPK2YAOUk+BWCzG8PAwtbW1lm90fX09fX393Lezi+OWNHL2mulVSc8kaitO9Xc2VMbITNVBTJW6urpptbfwer14vd45KxCQFNHh4eE0q2G6yQVTsSDKYeKrqqpKJTaU2oKAyS4Avb29DA4OAtDY2FiyceWDtiAMqOriXKhU1oYG64nf7XazdyhB51CYa162piy+NApjx0+nLS+Mv0uBz+ejqalpWtexpaWFpqamGRxVeVFVVUUikUhr+TLdNM98LIjKykr8fn9GR9lSYHSVlTqLCZLzSldXF4ODg9TW1rJq1SoWLlxYsnHlw//f3v3H1lXWcRx/f/prXUu7tht0dC1sxEVBghsuBIUYAhqYEDCKGQQCIRpCggGNxADRwP7wDxIjaDQEAihEMjCTzEUJYoCIJjIZjEzYNBIcrnODrbftOrestP36x3luPa2nvV3vXc89535fSXPvee7tPc/T5/Z8z/Oc5zyPtyCC48eP09/fz8TEBJ2dnXR2diYeFEdHRxkeHi654ldjyxJ6+87gqjUrTma2T9j0RXVKKY50SrtvuVyzjX7Jg+L0LUePHp3skit35FapuY/iGhsbWbly5bz3VUnFv0U13AcBMDg4yMjICMuWLZvxpLJaeYAgCg579+6dHCY3MDDA0NAQS5YsoaOjY8pBdWBgAEklK/ryc0/n8jmu17yQ4mWZy93RDQ0NFZmoz51cxYWM4tchyp1q4kRaENWkeG2weO9LWooBYnh4mNbW1sy0GuJqPkDEg0NfX9/k+s6FQoHBwUEKhQItLS00NTVRV1fH4cOH6erqqprpnk9UcYGYufZPt7W1VUW3gSutpaWFQqHA+Pg4o6Ojc5omYzYncg2i2rS2tqYeIIp/t4aGBpYvX565QAs1HiDGx8fZt2/flOAA0SygPT09jI2NMTw8zMjICCMjI5MXa7N4JhDX1NQ0ZSGg2bS1tf3fNNquOrW2tjIwMEChUGBoaIjGxkY6Ozvn/XnFawpZPBlqb29nYmIi1a7FxsZG2tra6OzszOTfEGo8QBw4cICxsbEpwSGuoaGBpUuXTnYnZekGl9m0t7cnjs922dbc3ExdXR2FQoGmpib6+vrKOjA1NzezatWqCuZw4dTX16fe3y+Jnp6eVPNQrqprO0q6QtLfJb0r6e6TtZ9CocCRI0c49dRT5zy7aFZubimlo6Mj9X8eV3mSaGtrY9GiRWUHB+egyloQkuqBnwJfAPqB1yVtNbNdldzPsWPHOHTo0GTzz7m86O7uzsVJjKsO1daCuAB418zeM7NR4BngmkrvpDhaqbu7u9If7VyqPDi4Sqq2ALEC2Bvb7g9pkyTdKmm7pO0HDx6c106am5vp7e3N9Z21zjlXrmoLEEmnP1MWejazR81snZmty/Odsc45l7ZqCxD9QF9suxf4d0p5cc65mlZtAeJ1YLWkVZKagOuArSnnyTnnalJVjWIyszFJ3wB+B9QDT5jZOylnyznnalJVBQgAM3seeD7tfDjnXK2rti4m55xzVcIDhHPOuUQeIJxzziVSfL3UrJF0EHh/nr++DDhUwexUmzyXz8uWXXkuX5bKdqaZlbyRLNMBohyStpvZurTzcbLkuXxetuzKc/nyWDbvYnLOOZfIA4RzzrlEtRwgHk07AydZnsvnZcuuPJcvd2Wr2WsQzjnnZlfLLQjnnHOzqMkAsVDLmi4ESX2SXpG0W9I7ku4M6V2Sfi/pH+Exs0vnSaqXtEPSb8L2KknbQtmeDRM7ZpKkDkmbJf0t1OFn8lJ3kr4VvpNvS9okqTnLdSfpCUkfSno7lpZYV4r8OBxjdko6P72cz1/NBYjYsqbrgXOA6yWdk26uyjIGfNvMzgYuBG4P5bkbeMnMVgMvhe2suhPYHdt+AHgwlG0Q+FoquaqMHwEvmNkngE8RlTPzdSdpBXAHsM7MziWafPM6sl13PweumJY2U12tB1aHn1uBhxcojxVVcwGCBVrWdKGY2X4zezM8HyE6wKwgKtOT4W1PAl9KJ4flkdQLXAk8FrYFXApsDm/Jctnagc8BjwOY2aiZDZGTuiOaDHSxpAagBdhPhuvOzF4FCtOSZ6qra4CnLPIa0CHp9IXJaeXUYoAouaxpVklaCawFtgHdZrYfoiACnJZezsryEPAdYCJsLwWGzGwsbGe5/s4CDgI/C11oj0lqJQd1Z2b7gB8A/yIKDMPAG+Sn7opmqqtcHGdqMUCUXNY0iySdAvwK+KaZHU47P5Ug6SrgQzN7I56c8Nas1l8DcD7wsJmtBf5DBruTkoS++GuAVUAP0ErU7TJdVuuulFx8T2sxQORuWVNJjUTB4Wkzey4kf1Bs0obHD9PKXxkuAq6WtIeoK/BSohZFR+i2gGzXXz/Qb2bbwvZmooCRh7r7PPBPMztoZh8BzwGfJT91VzRTXeXiOFOLASJXy5qGPvnHgd1m9sPYS1uBm8Pzm4FfL3TeymVm95hZr5mtJKqnl83sBuAV4NrwtkyWDcDMDgB7JX08JF0G7CIHdUfUtXShpJbwHS2WLRd1FzNTXW0FbgqjmS4EhotdUVlSkzfKSfoi0ZlocVnT76ecpXmTdDHwR+Cv/K+f/l6i6xC/BM4g+mf9qplNv8CWGZIuAe4ys6sknUXUougCdgA3mtnxNPM3X5LWEF2AbwLeA24hOnHLfN1J2ghsIBpptwP4OlE/fCbrTtIm4BKiWVs/AO4DtpBQVyEo/oRo1NNR4BYz255GvstRkwHCOedcabXYxeScc24OPEA455xL5AHCOedcIg8QzjnnEnmAcM45l8gDhHMxksYlvRX7mfXOZkm3SbqpAvvdI2lZuZ/jXCX5MFfnYiQdMbNTUtjvHqKZTw8t9L6dm4m3IJybg3CG/4Ckv4Sfj4X0+yXdFZ7fIWlXmP//mZDWJWlLSHtN0nkhfamkF8MkfY8Qm7tH0o1hH29JeiRMUe/cgvMA4dxUi6d1MW2IvXbYzC4gukP2oYTfvRtYa2bnAbeFtI3AjpB2L/BUSL8P+FOYpG8r0Z24SDqb6O7ji8xsDTAO3FDZIjo3Nw2l3+JcTTkWDsxJNsUeH0x4fSfwtKQtRFMwAFwMfAXAzF4OLYclROtAfDmk/1bSYHj/ZcCngdej2RpYTDYn63M54AHCubmzGZ4XXUl04L8a+J6kTzL7tM9JnyHgSTO7p5yMOlcJ3sXk3NxtiD3+Of6CpDqgz8xeIVrgqAM4BXiV0EUUJhw8FNbriKevB4rrTr8EXCvptPBal6QzT2KZnJuRtyCcm2qxpLdi2y+YWXGo6yJJ24hOrK6f9nv1wC9C95GI1l0eknQ/0YpxO4lm9SxODb0R2CTpTeAPRDOBYma7JH0XeDEEnY+A24H3K11Q50rxYa7OzYEPQ3W1yLuYnHPOJfIWhHPOuUTegnDOOZfIA4RzzrlEHiCcc84l8gDhnHMukQcI55xziTxAOOecS/Rf4iXxHJJQkKYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward:120.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-seq.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action_logits, initial_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                             model.initial_state: initial_state})\n",
    "        action = np.argmax(action_logits)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "print('total_reward:{}'.format(total_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

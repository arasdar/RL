{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info: [-0.01929692 -0.15405606 -0.00796877  0.26203255] 0 1.0 False {}\n",
      "state, action, reward, done, info: [-0.02237804  0.04117873 -0.00272812 -0.03315313] 1 1.0 False {}\n",
      "state, action, reward, done, info: [-0.02155446  0.2363397  -0.00339118 -0.32669556] 1 1.0 False {}\n",
      "state, action, reward, done, info: [-0.01682767  0.04126619 -0.00992509 -0.03508398] 0 1.0 False {}\n",
      "state, action, reward, done, info: [-0.01600235  0.23652906 -0.01062677 -0.33088178] 1 1.0 False {}\n",
      "state, action, reward, done, info: [-0.01127176  0.43180065 -0.01724441 -0.62689685] 1 1.0 False {}\n",
      "state, action, reward, done, info: [-0.00263575  0.627159   -0.02978234 -0.92496041] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.00990743  0.82267028 -0.04828155 -1.22685199] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.02636083  1.01837936 -0.07281859 -1.53426277] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.04672842  1.21429898 -0.10350385 -1.84875314] 1 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    labelQs = tf.placeholder(tf.float32, [None], name='labelQs')\n",
    "        \n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return actions, states, targetQs, labelQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs, labelQs):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    lossQtgt = tf.reduce_mean(tf.square(Qs - targetQs)) # next state, next action and nextQs\n",
    "    lossQlbl = tf.reduce_mean(tf.square(Qs - labelQs)) # current state, action, and currentQs\n",
    "    lossQtgt_sigm = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Qs, \n",
    "                                                                           labels=tf.nn.sigmoid(targetQs)))\n",
    "    lossQlbl_sigm = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Qs,\n",
    "                                                                           labels=tf.nn.sigmoid(labelQs)))\n",
    "    loss = lossQtgt + lossQlbl + lossQtgt_sigm + lossQlbl_sigm\n",
    "    return actions_logits, final_state, loss, lossQtgt, lossQlbl, lossQtgt_sigm, lossQlbl_sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.actions, self.states, self.targetQs, self.labelQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss, self.lossQtgt, self.lossQlbl, self.lossQtgt_sigm, self.lossQlbl_sigm = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, labelQs=self.labelQs, \n",
    "            cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_total_reward = deque(maxlen=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state:', np.array(states).shape[1], \n",
    "#       'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32                # number of samples in the memory/ experience as mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.0068957 ,  0.00404566, -0.02286297,  0.00812363]),\n",
       " 1,\n",
       " array([ 0.00697661,  0.19948791, -0.02270049, -0.29168426]),\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states, rewards, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 meanReward: 13.0000 meanLoss: 2.4191 meanLossQlbl: 0.0857 meanLossQlbl_sigm: 0.6443 meanLossQtgt: 1.1021 meanLossQtgt_sigm: 0.5870 ExploreP: 0.9987\n",
      "Episode: 1 meanReward: 16.0000 meanLoss: 2.4825 meanLossQlbl: 0.0473 meanLossQlbl_sigm: 0.2381 meanLossQtgt: 1.9933 meanLossQtgt_sigm: 0.2039 ExploreP: 0.9968\n",
      "Episode: 2 meanReward: 19.3333 meanLoss: 4.9990 meanLossQlbl: 1.2001 meanLossQlbl_sigm: 0.1493 meanLossQtgt: 3.4026 meanLossQtgt_sigm: 0.2469 ExploreP: 0.9943\n",
      "Episode: 3 meanReward: 18.2500 meanLoss: 8.7723 meanLossQlbl: 2.6923 meanLossQlbl_sigm: 0.2559 meanLossQtgt: 5.4928 meanLossQtgt_sigm: 0.3314 ExploreP: 0.9928\n",
      "Episode: 4 meanReward: 18.2000 meanLoss: 5.2933 meanLossQlbl: 0.1563 meanLossQlbl_sigm: 0.0116 meanLossQtgt: 4.9729 meanLossQtgt_sigm: 0.1524 ExploreP: 0.9910\n",
      "Episode: 5 meanReward: 16.8333 meanLoss: 6.4541 meanLossQlbl: 0.1934 meanLossQlbl_sigm: 0.0003 meanLossQtgt: 6.0901 meanLossQtgt_sigm: 0.1701 ExploreP: 0.9901\n",
      "Episode: 6 meanReward: 17.4286 meanLoss: 6.0084 meanLossQlbl: 0.2517 meanLossQlbl_sigm: 0.0005 meanLossQtgt: 5.5933 meanLossQtgt_sigm: 0.1629 ExploreP: 0.9880\n",
      "Episode: 7 meanReward: 19.3750 meanLoss: 6.2760 meanLossQlbl: 0.3459 meanLossQlbl_sigm: 0.0006 meanLossQtgt: 5.8081 meanLossQtgt_sigm: 0.1214 ExploreP: 0.9848\n",
      "Episode: 8 meanReward: 19.6667 meanLoss: 5.1856 meanLossQlbl: 0.0865 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 4.9912 meanLossQtgt_sigm: 0.1078 ExploreP: 0.9826\n",
      "Episode: 9 meanReward: 20.6000 meanLoss: 2.7749 meanLossQlbl: 0.3983 meanLossQlbl_sigm: 0.0163 meanLossQtgt: 2.2933 meanLossQtgt_sigm: 0.0669 ExploreP: 0.9798\n",
      "Episode: 10 meanReward: 21.0000 meanLoss: 10.3968 meanLossQlbl: 0.0662 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 10.1717 meanLossQtgt_sigm: 0.1589 ExploreP: 0.9774\n",
      "Episode: 11 meanReward: 20.5833 meanLoss: 15.4247 meanLossQlbl: 0.1654 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.0357 meanLossQtgt_sigm: 0.2235 ExploreP: 0.9758\n",
      "Episode: 12 meanReward: 21.3077 meanLoss: 24.6054 meanLossQlbl: 6.6320 meanLossQlbl_sigm: 0.1367 meanLossQtgt: 17.5424 meanLossQtgt_sigm: 0.2943 ExploreP: 0.9730\n",
      "Episode: 13 meanReward: 20.4286 meanLoss: 16.6886 meanLossQlbl: 0.0990 meanLossQlbl_sigm: 0.0004 meanLossQtgt: 16.3895 meanLossQtgt_sigm: 0.1996 ExploreP: 0.9721\n",
      "Episode: 14 meanReward: 20.6667 meanLoss: 25.9887 meanLossQlbl: 0.4456 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.2057 meanLossQtgt_sigm: 0.3374 ExploreP: 0.9698\n",
      "Episode: 15 meanReward: 20.7500 meanLoss: 18.2745 meanLossQlbl: 0.2154 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 17.8234 meanLossQtgt_sigm: 0.2356 ExploreP: 0.9677\n",
      "Episode: 16 meanReward: 20.3529 meanLoss: 13.5904 meanLossQlbl: 0.3176 meanLossQlbl_sigm: 0.0046 meanLossQtgt: 13.0874 meanLossQtgt_sigm: 0.1807 ExploreP: 0.9663\n",
      "Episode: 17 meanReward: 20.2222 meanLoss: 18.2679 meanLossQlbl: 0.7810 meanLossQlbl_sigm: 0.0193 meanLossQtgt: 17.2288 meanLossQtgt_sigm: 0.2388 ExploreP: 0.9646\n",
      "Episode: 18 meanReward: 20.3158 meanLoss: 26.9208 meanLossQlbl: 0.6810 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.9273 meanLossQtgt_sigm: 0.3125 ExploreP: 0.9625\n",
      "Episode: 19 meanReward: 19.8500 meanLoss: 30.0375 meanLossQlbl: 0.2141 meanLossQlbl_sigm: 0.0123 meanLossQtgt: 29.4373 meanLossQtgt_sigm: 0.3738 ExploreP: 0.9615\n",
      "Episode: 20 meanReward: 19.6667 meanLoss: 19.0970 meanLossQlbl: 1.1267 meanLossQlbl_sigm: 0.0717 meanLossQtgt: 17.6081 meanLossQtgt_sigm: 0.2906 ExploreP: 0.9599\n",
      "Episode: 21 meanReward: 19.5000 meanLoss: 23.3965 meanLossQlbl: 1.1851 meanLossQlbl_sigm: 0.0496 meanLossQtgt: 21.8580 meanLossQtgt_sigm: 0.3039 ExploreP: 0.9584\n",
      "Episode: 22 meanReward: 19.9130 meanLoss: 11.0685 meanLossQlbl: 0.4980 meanLossQlbl_sigm: 0.0146 meanLossQtgt: 10.4190 meanLossQtgt_sigm: 0.1370 ExploreP: 0.9557\n",
      "Episode: 23 meanReward: 20.2083 meanLoss: 18.0361 meanLossQlbl: 0.1700 meanLossQlbl_sigm: 0.0011 meanLossQtgt: 17.6601 meanLossQtgt_sigm: 0.2049 ExploreP: 0.9531\n",
      "Episode: 24 meanReward: 20.5200 meanLoss: 5.8276 meanLossQlbl: 0.7984 meanLossQlbl_sigm: 0.0012 meanLossQtgt: 4.9577 meanLossQtgt_sigm: 0.0703 ExploreP: 0.9505\n",
      "Episode: 25 meanReward: 20.2308 meanLoss: 19.8930 meanLossQlbl: 0.8280 meanLossQlbl_sigm: 0.0008 meanLossQtgt: 18.8506 meanLossQtgt_sigm: 0.2137 ExploreP: 0.9493\n",
      "Episode: 26 meanReward: 19.9259 meanLoss: 24.5217 meanLossQlbl: 2.3402 meanLossQlbl_sigm: 0.0143 meanLossQtgt: 21.9173 meanLossQtgt_sigm: 0.2499 ExploreP: 0.9481\n",
      "Episode: 27 meanReward: 19.7143 meanLoss: 34.8104 meanLossQlbl: 2.1116 meanLossQlbl_sigm: 0.0205 meanLossQtgt: 32.3162 meanLossQtgt_sigm: 0.3620 ExploreP: 0.9468\n",
      "Episode: 28 meanReward: 19.7241 meanLoss: 40.4359 meanLossQlbl: 0.3858 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 39.6178 meanLossQtgt_sigm: 0.4320 ExploreP: 0.9450\n",
      "Episode: 29 meanReward: 19.5333 meanLoss: 27.7902 meanLossQlbl: 1.3095 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.1498 meanLossQtgt_sigm: 0.3309 ExploreP: 0.9437\n",
      "Episode: 30 meanReward: 20.0000 meanLoss: 25.3922 meanLossQlbl: 1.4673 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.6542 meanLossQtgt_sigm: 0.2707 ExploreP: 0.9405\n",
      "Episode: 31 meanReward: 19.7188 meanLoss: 15.2064 meanLossQlbl: 0.6511 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.3752 meanLossQtgt_sigm: 0.1802 ExploreP: 0.9395\n",
      "Episode: 32 meanReward: 19.8125 meanLoss: 30.3966 meanLossQlbl: 1.4753 meanLossQlbl_sigm: 0.0209 meanLossQtgt: 28.5988 meanLossQtgt_sigm: 0.3017 ExploreP: 0.9380\n",
      "Episode: 33 meanReward: 19.7188 meanLoss: 51.0996 meanLossQlbl: 0.3966 meanLossQlbl_sigm: 0.0011 meanLossQtgt: 50.2027 meanLossQtgt_sigm: 0.4991 ExploreP: 0.9365\n",
      "Episode: 34 meanReward: 19.8438 meanLoss: 36.5133 meanLossQlbl: 0.0660 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.0849 meanLossQtgt_sigm: 0.3624 ExploreP: 0.9337\n",
      "Episode: 35 meanReward: 20.1875 meanLoss: 24.6823 meanLossQlbl: 0.1926 meanLossQlbl_sigm: 0.0004 meanLossQtgt: 24.2466 meanLossQtgt_sigm: 0.2426 ExploreP: 0.9313\n",
      "Episode: 36 meanReward: 20.0000 meanLoss: 34.9365 meanLossQlbl: 5.5274 meanLossQlbl_sigm: 0.1093 meanLossQtgt: 28.9564 meanLossQtgt_sigm: 0.3434 ExploreP: 0.9302\n",
      "Episode: 37 meanReward: 20.6562 meanLoss: 104.2789 meanLossQlbl: 50.8272 meanLossQlbl_sigm: 0.3847 meanLossQtgt: 52.6251 meanLossQtgt_sigm: 0.4420 ExploreP: 0.9274\n",
      "Episode: 38 meanReward: 20.8750 meanLoss: 38.1859 meanLossQlbl: 3.7303 meanLossQlbl_sigm: 0.0137 meanLossQtgt: 34.1381 meanLossQtgt_sigm: 0.3038 ExploreP: 0.9248\n",
      "Episode: 39 meanReward: 20.3438 meanLoss: 33.6079 meanLossQlbl: 3.7986 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.5304 meanLossQtgt_sigm: 0.2789 ExploreP: 0.9233\n",
      "Episode: 40 meanReward: 19.9688 meanLoss: 46.4469 meanLossQlbl: 2.3435 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.6495 meanLossQtgt_sigm: 0.4539 ExploreP: 0.9224\n",
      "Episode: 41 meanReward: 19.5625 meanLoss: 46.0067 meanLossQlbl: 0.8402 meanLossQlbl_sigm: 0.0010 meanLossQtgt: 44.7319 meanLossQtgt_sigm: 0.4336 ExploreP: 0.9210\n",
      "Episode: 42 meanReward: 19.4062 meanLoss: 54.7368 meanLossQlbl: 1.2684 meanLossQlbl_sigm: 0.0029 meanLossQtgt: 52.9986 meanLossQtgt_sigm: 0.4668 ExploreP: 0.9191\n",
      "Episode: 43 meanReward: 19.4062 meanLoss: 30.1304 meanLossQlbl: 1.3762 meanLossQlbl_sigm: 0.0060 meanLossQtgt: 28.5098 meanLossQtgt_sigm: 0.2384 ExploreP: 0.9177\n",
      "Episode: 44 meanReward: 19.6875 meanLoss: 27.2652 meanLossQlbl: 0.4325 meanLossQlbl_sigm: 0.0024 meanLossQtgt: 26.5996 meanLossQtgt_sigm: 0.2306 ExploreP: 0.9142\n",
      "Episode: 45 meanReward: 20.1562 meanLoss: 14.3696 meanLossQlbl: 1.5455 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 12.7008 meanLossQtgt_sigm: 0.1233 ExploreP: 0.9120\n",
      "Episode: 46 meanReward: 20.7500 meanLoss: 13.0920 meanLossQlbl: 2.1099 meanLossQlbl_sigm: 0.0062 meanLossQtgt: 10.8949 meanLossQtgt_sigm: 0.0809 ExploreP: 0.9081\n",
      "Episode: 47 meanReward: 21.1250 meanLoss: 21.5381 meanLossQlbl: 4.4335 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 16.9583 meanLossQtgt_sigm: 0.1464 ExploreP: 0.9051\n",
      "Episode: 48 meanReward: 21.7500 meanLoss: 17.9932 meanLossQlbl: 2.1873 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 15.6229 meanLossQtgt_sigm: 0.1830 ExploreP: 0.9020\n",
      "Episode: 49 meanReward: 21.6250 meanLoss: 49.7423 meanLossQlbl: 0.5613 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 48.8326 meanLossQtgt_sigm: 0.3484 ExploreP: 0.9008\n",
      "Episode: 50 meanReward: 21.3438 meanLoss: 70.0343 meanLossQlbl: 1.6644 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.8066 meanLossQtgt_sigm: 0.5633 ExploreP: 0.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 51 meanReward: 21.5312 meanLoss: 70.3398 meanLossQlbl: 2.3562 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.4151 meanLossQtgt_sigm: 0.5686 ExploreP: 0.8981\n",
      "Episode: 52 meanReward: 21.4375 meanLoss: 57.8995 meanLossQlbl: 3.8054 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 53.6789 meanLossQtgt_sigm: 0.4151 ExploreP: 0.8970\n",
      "Episode: 53 meanReward: 21.2188 meanLoss: 66.4481 meanLossQlbl: 5.4058 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 60.6123 meanLossQtgt_sigm: 0.4299 ExploreP: 0.8962\n",
      "Episode: 54 meanReward: 20.8750 meanLoss: 63.5829 meanLossQlbl: 4.1102 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 59.0032 meanLossQtgt_sigm: 0.4695 ExploreP: 0.8946\n",
      "Episode: 55 meanReward: 20.9062 meanLoss: 61.8647 meanLossQlbl: 2.2045 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 59.2359 meanLossQtgt_sigm: 0.4243 ExploreP: 0.8921\n",
      "Episode: 56 meanReward: 21.6562 meanLoss: 12.9759 meanLossQlbl: 1.6465 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 11.2207 meanLossQtgt_sigm: 0.1088 ExploreP: 0.8875\n",
      "Episode: 57 meanReward: 21.7812 meanLoss: 55.2949 meanLossQlbl: 0.2822 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 54.6450 meanLossQtgt_sigm: 0.3677 ExploreP: 0.8860\n",
      "Episode: 58 meanReward: 21.7500 meanLoss: 99.0234 meanLossQlbl: 1.1346 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 97.2050 meanLossQtgt_sigm: 0.6838 ExploreP: 0.8851\n",
      "Episode: 59 meanReward: 22.0938 meanLoss: 56.0435 meanLossQlbl: 2.1479 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 53.4288 meanLossQtgt_sigm: 0.4669 ExploreP: 0.8829\n",
      "Episode: 60 meanReward: 21.8125 meanLoss: 23.9354 meanLossQlbl: 1.7565 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 21.9233 meanLossQtgt_sigm: 0.2556 ExploreP: 0.8819\n",
      "Episode: 61 meanReward: 21.8750 meanLoss: 58.4195 meanLossQlbl: 0.8450 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 57.1215 meanLossQtgt_sigm: 0.4530 ExploreP: 0.8805\n",
      "Episode: 62 meanReward: 21.2812 meanLoss: 89.3151 meanLossQlbl: 0.3428 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 88.2945 meanLossQtgt_sigm: 0.6777 ExploreP: 0.8792\n",
      "Episode: 63 meanReward: 21.4375 meanLoss: 87.3867 meanLossQlbl: 0.6069 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 86.1647 meanLossQtgt_sigm: 0.6150 ExploreP: 0.8778\n",
      "Episode: 64 meanReward: 21.4688 meanLoss: 49.0207 meanLossQlbl: 2.7085 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 45.9614 meanLossQtgt_sigm: 0.3508 ExploreP: 0.8764\n",
      "Episode: 65 meanReward: 21.6562 meanLoss: 41.9801 meanLossQlbl: 1.7001 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.9210 meanLossQtgt_sigm: 0.3590 ExploreP: 0.8745\n",
      "Episode: 66 meanReward: 21.5312 meanLoss: 48.2025 meanLossQlbl: 1.1862 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 46.6320 meanLossQtgt_sigm: 0.3842 ExploreP: 0.8722\n",
      "Episode: 67 meanReward: 21.6875 meanLoss: 42.5191 meanLossQlbl: 0.4082 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 41.7699 meanLossQtgt_sigm: 0.3410 ExploreP: 0.8695\n",
      "Episode: 68 meanReward: 21.6562 meanLoss: 40.5217 meanLossQlbl: 0.5870 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 39.6186 meanLossQtgt_sigm: 0.3161 ExploreP: 0.8686\n",
      "Episode: 69 meanReward: 21.1875 meanLoss: 73.1590 meanLossQlbl: 0.7923 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 71.7861 meanLossQtgt_sigm: 0.5807 ExploreP: 0.8672\n",
      "Episode: 70 meanReward: 20.6562 meanLoss: 70.6443 meanLossQlbl: 2.3384 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 67.6993 meanLossQtgt_sigm: 0.6066 ExploreP: 0.8663\n",
      "Episode: 71 meanReward: 21.6250 meanLoss: 32.7586 meanLossQlbl: 0.9876 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.4829 meanLossQtgt_sigm: 0.2881 ExploreP: 0.8623\n",
      "Episode: 72 meanReward: 21.9062 meanLoss: 33.8529 meanLossQlbl: 0.1406 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.4254 meanLossQtgt_sigm: 0.2869 ExploreP: 0.8607\n",
      "Episode: 73 meanReward: 21.9375 meanLoss: 56.2691 meanLossQlbl: 0.9902 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 54.8070 meanLossQtgt_sigm: 0.4719 ExploreP: 0.8592\n",
      "Episode: 74 meanReward: 23.2812 meanLoss: 24.1683 meanLossQlbl: 0.3811 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.5895 meanLossQtgt_sigm: 0.1977 ExploreP: 0.8539\n",
      "Episode: 75 meanReward: 23.1875 meanLoss: 36.7136 meanLossQlbl: 0.0422 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.3687 meanLossQtgt_sigm: 0.3027 ExploreP: 0.8528\n",
      "Episode: 76 meanReward: 23.2188 meanLoss: 42.2365 meanLossQlbl: 0.7685 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 41.1261 meanLossQtgt_sigm: 0.3419 ExploreP: 0.8494\n",
      "Episode: 77 meanReward: 22.8438 meanLoss: 36.4039 meanLossQlbl: 0.0980 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.0034 meanLossQtgt_sigm: 0.3024 ExploreP: 0.8484\n",
      "Episode: 78 meanReward: 22.0625 meanLoss: 66.8024 meanLossQlbl: 0.1694 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 66.0658 meanLossQtgt_sigm: 0.5672 ExploreP: 0.8469\n",
      "Episode: 79 meanReward: 21.3750 meanLoss: 63.7591 meanLossQlbl: 0.1845 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 63.0057 meanLossQtgt_sigm: 0.5689 ExploreP: 0.8459\n",
      "Episode: 80 meanReward: 21.1875 meanLoss: 45.8710 meanLossQlbl: 0.5079 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.9335 meanLossQtgt_sigm: 0.4296 ExploreP: 0.8436\n",
      "Episode: 81 meanReward: 21.3750 meanLoss: 31.4483 meanLossQlbl: 1.4497 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 29.7174 meanLossQtgt_sigm: 0.2812 ExploreP: 0.8419\n",
      "Episode: 82 meanReward: 21.4062 meanLoss: 46.7099 meanLossQlbl: 0.6925 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 45.5720 meanLossQtgt_sigm: 0.4454 ExploreP: 0.8407\n",
      "Episode: 83 meanReward: 21.3438 meanLoss: 53.4733 meanLossQlbl: 0.4108 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 52.5562 meanLossQtgt_sigm: 0.5064 ExploreP: 0.8395\n",
      "Episode: 84 meanReward: 21.5625 meanLoss: 46.7394 meanLossQlbl: 0.2194 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 46.0587 meanLossQtgt_sigm: 0.4613 ExploreP: 0.8378\n",
      "Episode: 85 meanReward: 21.6562 meanLoss: 46.0148 meanLossQlbl: 2.4698 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 43.0975 meanLossQtgt_sigm: 0.4475 ExploreP: 0.8368\n",
      "Episode: 86 meanReward: 21.7188 meanLoss: 37.3285 meanLossQlbl: 4.7785 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.1707 meanLossQtgt_sigm: 0.3793 ExploreP: 0.8352\n",
      "Episode: 87 meanReward: 21.4375 meanLoss: 34.3817 meanLossQlbl: 1.3839 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.6547 meanLossQtgt_sigm: 0.3430 ExploreP: 0.8336\n",
      "Episode: 88 meanReward: 20.7188 meanLoss: 34.5086 meanLossQlbl: 0.5379 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 33.6351 meanLossQtgt_sigm: 0.3356 ExploreP: 0.8312\n",
      "Episode: 89 meanReward: 20.5000 meanLoss: 37.9743 meanLossQlbl: 1.5952 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.0533 meanLossQtgt_sigm: 0.3259 ExploreP: 0.8304\n",
      "Episode: 90 meanReward: 20.4688 meanLoss: 37.1344 meanLossQlbl: 6.7433 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 30.0211 meanLossQtgt_sigm: 0.3700 ExploreP: 0.8296\n",
      "Episode: 91 meanReward: 20.8125 meanLoss: 33.9501 meanLossQlbl: 2.0073 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.5889 meanLossQtgt_sigm: 0.3539 ExploreP: 0.8266\n",
      "Episode: 92 meanReward: 21.5312 meanLoss: 8.0619 meanLossQlbl: 1.1658 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 6.7815 meanLossQtgt_sigm: 0.1145 ExploreP: 0.8239\n",
      "Episode: 93 meanReward: 21.4688 meanLoss: 24.2416 meanLossQlbl: 0.4981 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.5045 meanLossQtgt_sigm: 0.2390 ExploreP: 0.8227\n",
      "Episode: 94 meanReward: 21.5312 meanLoss: 30.9556 meanLossQlbl: 1.9570 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 28.6512 meanLossQtgt_sigm: 0.3474 ExploreP: 0.8214\n",
      "Episode: 95 meanReward: 21.4062 meanLoss: 27.0077 meanLossQlbl: 2.9123 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.7815 meanLossQtgt_sigm: 0.3139 ExploreP: 0.8204\n",
      "Episode: 96 meanReward: 21.2812 meanLoss: 33.7561 meanLossQlbl: 0.8218 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.5314 meanLossQtgt_sigm: 0.4028 ExploreP: 0.8193\n",
      "Episode: 97 meanReward: 22.3438 meanLoss: 205.8398 meanLossQlbl: 97.5616 meanLossQlbl_sigm: 0.3284 meanLossQtgt: 107.3853 meanLossQtgt_sigm: 0.5644 ExploreP: 0.8148\n",
      "Episode: 98 meanReward: 21.9688 meanLoss: 261.2232 meanLossQlbl: 145.3258 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 114.5111 meanLossQtgt_sigm: 0.6931 ExploreP: 0.8137\n",
      "Episode: 99 meanReward: 21.4062 meanLoss: 196.4710 meanLossQlbl: 111.4387 meanLossQlbl_sigm: 0.6931 meanLossQtgt: 83.6460 meanLossQtgt_sigm: 0.6931 ExploreP: 0.8126\n",
      "Episode: 100 meanReward: 21.7812 meanLoss: 120.1887 meanLossQlbl: 68.7890 meanLossQlbl_sigm: 0.6621 meanLossQtgt: 50.0686 meanLossQtgt_sigm: 0.6690 ExploreP: 0.8108\n",
      "Episode: 101 meanReward: 23.1562 meanLoss: 31.9540 meanLossQlbl: 8.0825 meanLossQlbl_sigm: 0.0772 meanLossQtgt: 23.6010 meanLossQtgt_sigm: 0.1934 ExploreP: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 102 meanReward: 24.1875 meanLoss: 17.9597 meanLossQlbl: 0.8432 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.9601 meanLossQtgt_sigm: 0.1564 ExploreP: 0.8025\n",
      "Episode: 103 meanReward: 23.2812 meanLoss: 19.8980 meanLossQlbl: 2.2411 meanLossQlbl_sigm: 0.0083 meanLossQtgt: 17.4860 meanLossQtgt_sigm: 0.1626 ExploreP: 0.8011\n",
      "Episode: 104 meanReward: 23.1250 meanLoss: 534.6590 meanLossQlbl: 268.5401 meanLossQlbl_sigm: 0.5973 meanLossQtgt: 264.8720 meanLossQtgt_sigm: 0.6496 ExploreP: 0.8000\n",
      "Episode: 105 meanReward: 23.2188 meanLoss: 562.6449 meanLossQlbl: 311.9095 meanLossQlbl_sigm: 0.6474 meanLossQtgt: 249.4172 meanLossQtgt_sigm: 0.6709 ExploreP: 0.7984\n",
      "Episode: 106 meanReward: 22.3125 meanLoss: 274.7181 meanLossQlbl: 143.6965 meanLossQlbl_sigm: 0.6550 meanLossQtgt: 129.6999 meanLossQtgt_sigm: 0.6668 ExploreP: 0.7957\n",
      "Episode: 107 meanReward: 22.3125 meanLoss: 30.3212 meanLossQlbl: 1.4376 meanLossQlbl_sigm: 0.0318 meanLossQtgt: 28.5920 meanLossQtgt_sigm: 0.2598 ExploreP: 0.7947\n",
      "Episode: 108 meanReward: 22.9375 meanLoss: 90.3756 meanLossQlbl: 34.5035 meanLossQlbl_sigm: 0.1445 meanLossQtgt: 55.3628 meanLossQtgt_sigm: 0.3648 ExploreP: 0.7900\n",
      "Episode: 109 meanReward: 22.8438 meanLoss: 216.6444 meanLossQlbl: 97.8071 meanLossQlbl_sigm: 0.3107 meanLossQtgt: 117.9962 meanLossQtgt_sigm: 0.5304 ExploreP: 0.7893\n",
      "Episode: 110 meanReward: 23.0625 meanLoss: 100.6711 meanLossQlbl: 43.9410 meanLossQlbl_sigm: 0.2133 meanLossQtgt: 56.0800 meanLossQtgt_sigm: 0.4369 ExploreP: 0.7874\n",
      "Episode: 111 meanReward: 23.2188 meanLoss: 107.2700 meanLossQlbl: 29.9702 meanLossQlbl_sigm: 0.1567 meanLossQtgt: 76.5869 meanLossQtgt_sigm: 0.5560 ExploreP: 0.7860\n",
      "Episode: 112 meanReward: 23.5312 meanLoss: 138.5607 meanLossQlbl: 54.6362 meanLossQlbl_sigm: 0.2411 meanLossQtgt: 83.2387 meanLossQtgt_sigm: 0.4447 ExploreP: 0.7831\n",
      "Episode: 113 meanReward: 23.2500 meanLoss: 65.6820 meanLossQlbl: 9.0242 meanLossQlbl_sigm: 0.0650 meanLossQtgt: 56.2477 meanLossQtgt_sigm: 0.3450 ExploreP: 0.7822\n",
      "Episode: 114 meanReward: 24.8125 meanLoss: 47.6323 meanLossQlbl: 7.8424 meanLossQlbl_sigm: 0.0390 meanLossQtgt: 39.5004 meanLossQtgt_sigm: 0.2505 ExploreP: 0.7773\n",
      "Episode: 115 meanReward: 24.8125 meanLoss: 35.2673 meanLossQlbl: 0.8235 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 34.1647 meanLossQtgt_sigm: 0.2791 ExploreP: 0.7762\n",
      "Episode: 116 meanReward: 24.5625 meanLoss: 48.7954 meanLossQlbl: 1.3419 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 46.9908 meanLossQtgt_sigm: 0.4628 ExploreP: 0.7753\n",
      "Episode: 117 meanReward: 25.0312 meanLoss: 41.3985 meanLossQlbl: 0.8758 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 40.1109 meanLossQtgt_sigm: 0.4118 ExploreP: 0.7732\n",
      "Episode: 118 meanReward: 25.2188 meanLoss: 24.1177 meanLossQlbl: 0.8454 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 23.0204 meanLossQtgt_sigm: 0.2519 ExploreP: 0.7712\n",
      "Episode: 119 meanReward: 27.2500 meanLoss: 16.0899 meanLossQlbl: 1.9174 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 14.0654 meanLossQtgt_sigm: 0.1071 ExploreP: 0.7648\n",
      "Episode: 120 meanReward: 26.6875 meanLoss: 31.3640 meanLossQlbl: 5.0874 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.0278 meanLossQtgt_sigm: 0.2488 ExploreP: 0.7640\n",
      "Episode: 121 meanReward: 27.3125 meanLoss: 32.6744 meanLossQlbl: 5.5967 meanLossQlbl_sigm: 0.0015 meanLossQtgt: 26.7810 meanLossQtgt_sigm: 0.2953 ExploreP: 0.7618\n",
      "Episode: 122 meanReward: 27.9375 meanLoss: 15.7855 meanLossQlbl: 2.6459 meanLossQlbl_sigm: 0.0360 meanLossQtgt: 12.9618 meanLossQtgt_sigm: 0.1417 ExploreP: 0.7595\n",
      "Episode: 123 meanReward: 29.8750 meanLoss: 17.3418 meanLossQlbl: 1.2583 meanLossQlbl_sigm: 0.0081 meanLossQtgt: 15.9730 meanLossQtgt_sigm: 0.1024 ExploreP: 0.7522\n",
      "Episode: 124 meanReward: 29.8438 meanLoss: 57.0304 meanLossQlbl: 13.6930 meanLossQlbl_sigm: 0.0092 meanLossQtgt: 43.1211 meanLossQtgt_sigm: 0.2071 ExploreP: 0.7497\n",
      "Episode: 125 meanReward: 30.5312 meanLoss: 31.5046 meanLossQlbl: 2.6141 meanLossQlbl_sigm: 0.0025 meanLossQtgt: 28.6730 meanLossQtgt_sigm: 0.2150 ExploreP: 0.7471\n",
      "Episode: 126 meanReward: 32.0938 meanLoss: 15.7131 meanLossQlbl: 1.9874 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.6401 meanLossQtgt_sigm: 0.0856 ExploreP: 0.7422\n",
      "Episode: 127 meanReward: 32.0625 meanLoss: 110.0233 meanLossQlbl: 0.6702 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 108.8289 meanLossQtgt_sigm: 0.5243 ExploreP: 0.7414\n",
      "Episode: 128 meanReward: 33.0625 meanLoss: 113.9130 meanLossQlbl: 0.7916 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 112.5734 meanLossQtgt_sigm: 0.5480 ExploreP: 0.7381\n",
      "Episode: 129 meanReward: 32.1250 meanLoss: 62.9925 meanLossQlbl: 0.5357 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 62.0703 meanLossQtgt_sigm: 0.3865 ExploreP: 0.7362\n",
      "Episode: 130 meanReward: 32.2812 meanLoss: 74.7494 meanLossQlbl: 0.2317 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 74.0479 meanLossQtgt_sigm: 0.4697 ExploreP: 0.7348\n",
      "Episode: 131 meanReward: 36.5312 meanLoss: 13.6796 meanLossQlbl: 0.2979 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.2902 meanLossQtgt_sigm: 0.0915 ExploreP: 0.7241\n",
      "Episode: 132 meanReward: 37.2812 meanLoss: 91.7135 meanLossQlbl: 43.5986 meanLossQlbl_sigm: 0.0889 meanLossQtgt: 47.8563 meanLossQtgt_sigm: 0.1697 ExploreP: 0.7207\n",
      "Episode: 133 meanReward: 36.4375 meanLoss: 45.2067 meanLossQlbl: 0.7213 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.1852 meanLossQtgt_sigm: 0.3002 ExploreP: 0.7184\n",
      "Episode: 134 meanReward: 36.9688 meanLoss: 10.1973 meanLossQlbl: 1.8709 meanLossQlbl_sigm: 0.0006 meanLossQtgt: 8.2726 meanLossQtgt_sigm: 0.0532 ExploreP: 0.7141\n",
      "Episode: 135 meanReward: 37.5625 meanLoss: 36.5379 meanLossQlbl: 1.4130 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 34.8659 meanLossQtgt_sigm: 0.2589 ExploreP: 0.7115\n",
      "Episode: 136 meanReward: 37.7500 meanLoss: 56.1069 meanLossQlbl: 1.4863 meanLossQlbl_sigm: 0.0022 meanLossQtgt: 54.2432 meanLossQtgt_sigm: 0.3752 ExploreP: 0.7101\n",
      "Episode: 137 meanReward: 37.9375 meanLoss: 70.5731 meanLossQlbl: 3.9092 meanLossQlbl_sigm: 0.0476 meanLossQtgt: 66.0780 meanLossQtgt_sigm: 0.5383 ExploreP: 0.7083\n",
      "Episode: 138 meanReward: 37.3750 meanLoss: 48.9577 meanLossQlbl: 0.9173 meanLossQlbl_sigm: 0.0081 meanLossQtgt: 47.6866 meanLossQtgt_sigm: 0.3457 ExploreP: 0.7072\n",
      "Episode: 139 meanReward: 37.5625 meanLoss: 91.4332 meanLossQlbl: 2.9202 meanLossQlbl_sigm: 0.0037 meanLossQtgt: 87.9830 meanLossQtgt_sigm: 0.5263 ExploreP: 0.7058\n",
      "Episode: 140 meanReward: 36.0938 meanLoss: 61.2015 meanLossQlbl: 12.4284 meanLossQlbl_sigm: 0.0014 meanLossQtgt: 48.4062 meanLossQtgt_sigm: 0.3655 ExploreP: 0.7049\n",
      "Episode: 141 meanReward: 36.6562 meanLoss: 35.9056 meanLossQlbl: 10.2908 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.3423 meanLossQtgt_sigm: 0.2726 ExploreP: 0.7031\n",
      "Episode: 142 meanReward: 36.3125 meanLoss: 28.5360 meanLossQlbl: 3.5965 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 24.6836 meanLossQtgt_sigm: 0.2559 ExploreP: 0.7021\n",
      "Episode: 143 meanReward: 36.4688 meanLoss: 26.2048 meanLossQlbl: 2.5147 meanLossQlbl_sigm: 0.0002 meanLossQtgt: 23.5171 meanLossQtgt_sigm: 0.1728 ExploreP: 0.7006\n",
      "Episode: 144 meanReward: 35.7812 meanLoss: 50.5250 meanLossQlbl: 1.2509 meanLossQlbl_sigm: 0.0007 meanLossQtgt: 48.9409 meanLossQtgt_sigm: 0.3324 ExploreP: 0.6995\n",
      "Episode: 145 meanReward: 36.6562 meanLoss: 51.8074 meanLossQlbl: 1.9003 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 49.5748 meanLossQtgt_sigm: 0.3323 ExploreP: 0.6968\n",
      "Episode: 146 meanReward: 35.1875 meanLoss: 50.6096 meanLossQlbl: 3.0579 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 47.2620 meanLossQtgt_sigm: 0.2897 ExploreP: 0.6956\n",
      "Episode: 147 meanReward: 36.3438 meanLoss: 34.7775 meanLossQlbl: 2.9639 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.6656 meanLossQtgt_sigm: 0.1480 ExploreP: 0.6921\n",
      "Episode: 148 meanReward: 39.5938 meanLoss: 20.3192 meanLossQlbl: 2.0240 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.2174 meanLossQtgt_sigm: 0.0777 ExploreP: 0.6842\n",
      "Episode: 149 meanReward: 39.5312 meanLoss: 76.1209 meanLossQlbl: 7.3414 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 68.4002 meanLossQtgt_sigm: 0.3793 ExploreP: 0.6825\n",
      "Episode: 150 meanReward: 40.0312 meanLoss: 100.0825 meanLossQlbl: 12.0410 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 87.8224 meanLossQtgt_sigm: 0.2191 ExploreP: 0.6797\n",
      "Episode: 151 meanReward: 38.8438 meanLoss: 43.1271 meanLossQlbl: 11.1106 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 31.8415 meanLossQtgt_sigm: 0.1750 ExploreP: 0.6766\n",
      "Episode: 152 meanReward: 39.0000 meanLoss: 127.0405 meanLossQlbl: 2.0902 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 124.4008 meanLossQtgt_sigm: 0.5495 ExploreP: 0.6755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 153 meanReward: 38.6562 meanLoss: 210.1166 meanLossQlbl: 5.2735 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 203.9228 meanLossQtgt_sigm: 0.9203 ExploreP: 0.6743\n",
      "Episode: 154 meanReward: 38.8438 meanLoss: 64.8374 meanLossQlbl: 7.9590 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 56.5380 meanLossQtgt_sigm: 0.3404 ExploreP: 0.6719\n",
      "Episode: 155 meanReward: 36.7500 meanLoss: 79.9700 meanLossQlbl: 3.1841 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 76.3698 meanLossQtgt_sigm: 0.4162 ExploreP: 0.6698\n",
      "Episode: 156 meanReward: 36.5625 meanLoss: 31.5129 meanLossQlbl: 4.9022 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.4069 meanLossQtgt_sigm: 0.2038 ExploreP: 0.6681\n",
      "Episode: 157 meanReward: 35.8438 meanLoss: 39.1934 meanLossQlbl: 6.8230 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.1444 meanLossQtgt_sigm: 0.2260 ExploreP: 0.6672\n",
      "Episode: 158 meanReward: 34.5625 meanLoss: 80.4160 meanLossQlbl: 7.8032 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 72.1481 meanLossQtgt_sigm: 0.4647 ExploreP: 0.6655\n",
      "Episode: 159 meanReward: 34.7500 meanLoss: 80.5256 meanLossQlbl: 2.0271 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 78.0246 meanLossQtgt_sigm: 0.4739 ExploreP: 0.6644\n",
      "Episode: 160 meanReward: 34.0000 meanLoss: 86.5786 meanLossQlbl: 2.9520 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 83.0809 meanLossQtgt_sigm: 0.5458 ExploreP: 0.6630\n",
      "Episode: 161 meanReward: 38.6250 meanLoss: 14.8891 meanLossQlbl: 1.3784 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.4317 meanLossQtgt_sigm: 0.0790 ExploreP: 0.6518\n",
      "Episode: 162 meanReward: 38.6250 meanLoss: 64.4636 meanLossQlbl: 5.1189 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 59.0013 meanLossQtgt_sigm: 0.3434 ExploreP: 0.6505\n",
      "Episode: 163 meanReward: 35.0625 meanLoss: 24.6318 meanLossQlbl: 5.8919 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.6245 meanLossQtgt_sigm: 0.1152 ExploreP: 0.6483\n",
      "Episode: 164 meanReward: 34.5000 meanLoss: 19.6906 meanLossQlbl: 6.1514 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 13.4522 meanLossQtgt_sigm: 0.0870 ExploreP: 0.6464\n",
      "Episode: 165 meanReward: 33.8438 meanLoss: 83.8983 meanLossQlbl: 0.4628 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 83.0096 meanLossQtgt_sigm: 0.4258 ExploreP: 0.6457\n",
      "Episode: 166 meanReward: 32.8438 meanLoss: 109.8832 meanLossQlbl: 2.0120 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 107.3074 meanLossQtgt_sigm: 0.5639 ExploreP: 0.6438\n",
      "Episode: 167 meanReward: 33.6875 meanLoss: 19.9227 meanLossQlbl: 3.2132 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 16.6181 meanLossQtgt_sigm: 0.0914 ExploreP: 0.6398\n",
      "Episode: 168 meanReward: 36.9062 meanLoss: 20.7498 meanLossQlbl: 2.1716 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 18.4911 meanLossQtgt_sigm: 0.0870 ExploreP: 0.6321\n",
      "Episode: 169 meanReward: 36.5938 meanLoss: 185.4498 meanLossQlbl: 2.0141 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 182.7671 meanLossQtgt_sigm: 0.6687 ExploreP: 0.6311\n",
      "Episode: 170 meanReward: 37.6250 meanLoss: 93.3669 meanLossQlbl: 2.9657 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 90.0217 meanLossQtgt_sigm: 0.3795 ExploreP: 0.6281\n",
      "Episode: 171 meanReward: 38.0938 meanLoss: 47.8065 meanLossQlbl: 3.0016 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 44.5069 meanLossQtgt_sigm: 0.2980 ExploreP: 0.6260\n",
      "Episode: 172 meanReward: 38.2188 meanLoss: 42.2756 meanLossQlbl: 6.0706 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 36.0429 meanLossQtgt_sigm: 0.1621 ExploreP: 0.6249\n",
      "Episode: 173 meanReward: 39.5938 meanLoss: 45.0070 meanLossQlbl: 8.5636 meanLossQlbl_sigm: 0.0065 meanLossQtgt: 36.4074 meanLossQtgt_sigm: 0.0296 ExploreP: 0.6206\n",
      "Episode: 174 meanReward: 39.6562 meanLoss: 71.6069 meanLossQlbl: 4.3366 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 66.8837 meanLossQtgt_sigm: 0.3866 ExploreP: 0.6196\n",
      "Episode: 175 meanReward: 39.8125 meanLoss: 122.2603 meanLossQlbl: 8.5226 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 113.1230 meanLossQtgt_sigm: 0.6146 ExploreP: 0.6180\n",
      "Episode: 176 meanReward: 43.9375 meanLoss: 11.6256 meanLossQlbl: 1.3028 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 10.2691 meanLossQtgt_sigm: 0.0538 ExploreP: 0.6090\n",
      "Episode: 177 meanReward: 43.2500 meanLoss: 217.8052 meanLossQlbl: 0.3213 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 216.7670 meanLossQtgt_sigm: 0.7169 ExploreP: 0.6080\n",
      "Episode: 178 meanReward: 43.6875 meanLoss: 152.6188 meanLossQlbl: 6.9141 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 145.1260 meanLossQtgt_sigm: 0.5788 ExploreP: 0.6062\n",
      "Episode: 179 meanReward: 42.4688 meanLoss: 94.1865 meanLossQlbl: 13.4747 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 80.3298 meanLossQtgt_sigm: 0.3820 ExploreP: 0.6054\n",
      "Episode: 180 meanReward: 39.9375 meanLoss: 64.5577 meanLossQlbl: 10.3537 meanLossQlbl_sigm: 0.0001 meanLossQtgt: 53.9772 meanLossQtgt_sigm: 0.2268 ExploreP: 0.6033\n",
      "Episode: 181 meanReward: 39.9688 meanLoss: 37.7199 meanLossQlbl: 12.5136 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.1158 meanLossQtgt_sigm: 0.0905 ExploreP: 0.6018\n",
      "Episode: 182 meanReward: 39.7500 meanLoss: 34.0441 meanLossQlbl: 5.9369 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 27.9557 meanLossQtgt_sigm: 0.1515 ExploreP: 0.5997\n",
      "Episode: 183 meanReward: 40.9062 meanLoss: 28.6892 meanLossQlbl: 1.5887 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 26.9630 meanLossQtgt_sigm: 0.1375 ExploreP: 0.5948\n",
      "Episode: 184 meanReward: 41.3438 meanLoss: 87.5013 meanLossQlbl: 12.5930 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 74.6920 meanLossQtgt_sigm: 0.2163 ExploreP: 0.5931\n",
      "Episode: 185 meanReward: 43.8750 meanLoss: 37.1875 meanLossQlbl: 4.4368 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 32.6325 meanLossQtgt_sigm: 0.1183 ExploreP: 0.5873\n",
      "Episode: 186 meanReward: 46.0938 meanLoss: 27.7976 meanLossQlbl: 2.1016 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 25.5786 meanLossQtgt_sigm: 0.1174 ExploreP: 0.5811\n",
      "Episode: 187 meanReward: 45.8125 meanLoss: 122.5772 meanLossQlbl: 56.1690 meanLossQlbl_sigm: 0.2961 meanLossQtgt: 65.7348 meanLossQtgt_sigm: 0.3773 ExploreP: 0.5799\n",
      "Episode: 188 meanReward: 46.1875 meanLoss: 85.3220 meanLossQlbl: 3.7158 meanLossQlbl_sigm: 0.0074 meanLossQtgt: 81.2961 meanLossQtgt_sigm: 0.3027 ExploreP: 0.5776\n",
      "Episode: 189 meanReward: 48.0312 meanLoss: 32.9544 meanLossQlbl: 4.4119 meanLossQlbl_sigm: 0.0039 meanLossQtgt: 28.5152 meanLossQtgt_sigm: 0.0235 ExploreP: 0.5736\n",
      "Episode: 190 meanReward: 47.5312 meanLoss: 105.1535 meanLossQlbl: 6.1447 meanLossQlbl_sigm: 0.0028 meanLossQtgt: 98.5903 meanLossQtgt_sigm: 0.4156 ExploreP: 0.5730\n",
      "Episode: 191 meanReward: 48.0625 meanLoss: 97.2834 meanLossQlbl: 10.5087 meanLossQlbl_sigm: 0.0400 meanLossQtgt: 86.4206 meanLossQtgt_sigm: 0.3141 ExploreP: 0.5711\n",
      "Episode: 192 meanReward: 52.1562 meanLoss: 22.3968 meanLossQlbl: 1.8697 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 20.4440 meanLossQtgt_sigm: 0.0830 ExploreP: 0.5626\n",
      "Episode: 193 meanReward: 47.2188 meanLoss: 264.7977 meanLossQlbl: 0.3636 meanLossQlbl_sigm: 0.0000 meanLossQtgt: 263.6325 meanLossQtgt_sigm: 0.8016 ExploreP: 0.5618\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver() # save the trained model\n",
    "rewards_list, loss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_loss = deque(maxlen=batch_size)\n",
    "    episode_reward = deque(maxlen=batch_size)\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        lossQlbl_batch, lossQlbl_sigm_batch, lossQtgt_batch, lossQtgt_sigm_batch = [], [], [], []\n",
    "        state = env.reset()\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            \n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([initial_state, final_state])\n",
    "            total_reward += reward\n",
    "            initial_state = final_state\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            initial_states = np.array([each[0] for each in rnn_states])\n",
    "            final_states = np.array([each[1] for each in rnn_states])\n",
    "            actions_logits = sess.run(model.actions_logits, \n",
    "                                      feed_dict = {model.states: states, \n",
    "                                                   model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            labelQs = np.max(actions_logits, axis=1)\n",
    "            next_actions_logits = sess.run(model.actions_logits, \n",
    "                                           feed_dict = {model.states: next_states, \n",
    "                                                        model.initial_state: final_states[0].reshape([1, -1])})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (0.99 * nextQs)\n",
    "            loss, _, lossQlbl, lossQlbl_sigm, lossQtgt, lossQtgt_sigm = sess.run([model.loss, model.opt, \n",
    "                                                                                  model.lossQlbl, \n",
    "                                                                                  model.lossQlbl_sigm, \n",
    "                                                                                  model.lossQtgt, \n",
    "                                                                                  model.lossQtgt_sigm], \n",
    "                                            feed_dict = {model.states: states, \n",
    "                                                         model.actions: actions,\n",
    "                                                         model.targetQs: targetQs,\n",
    "                                                         model.labelQs: labelQs,\n",
    "                                                         model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            loss_batch.append(loss)\n",
    "            lossQlbl_batch.append(lossQlbl)\n",
    "            lossQlbl_sigm_batch.append(lossQlbl_sigm)\n",
    "            lossQtgt_batch.append(lossQtgt)\n",
    "            lossQtgt_sigm_batch.append(lossQtgt_sigm)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode: {}'.format(ep),\n",
    "              'meanReward: {:.4f}'.format(np.mean(episode_reward)),\n",
    "              'meanLoss: {:.4f}'.format(np.mean(loss_batch)),\n",
    "              'meanLossQlbl: {:.4f}'.format(np.mean(lossQlbl_batch)),\n",
    "              'meanLossQlbl_sigm: {:.4f}'.format(np.mean(lossQlbl_sigm_batch)),\n",
    "              'meanLossQtgt: {:.4f}'.format(np.mean(lossQtgt_batch)),\n",
    "              'meanLossQtgt_sigm: {:.4f}'.format(np.mean(lossQtgt_sigm_batch)),\n",
    "              'ExploreP: {:.4f}'.format(explore_p))\n",
    "        rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        if(np.mean(episode_reward) >= 500):\n",
    "            break\n",
    "    \n",
    "    saver.save(sess, 'checkpoints/model4.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average losses')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward:120.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-seq.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action_logits, initial_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                             model.initial_state: initial_state})\n",
    "        action = np.argmax(action_logits)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "print('total_reward:{}'.format(total_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

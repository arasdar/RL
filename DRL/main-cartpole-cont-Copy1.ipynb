{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    #states = tf.placeholder(tf.float32, [None, *state_size], name='states')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    rates = tf.placeholder(tf.float32, [None], name='rates')\n",
    "    return states, actions, targetQs, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator/Controller: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(states, actions, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=action_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        nl1_fused = tf.concat(axis=1, values=[nl1, actions])\n",
    "        h2 = tf.layers.dense(inputs=nl1_fused, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "                \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return rewards logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, actions, targetQs, rates):\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                              labels=actions_labels)\n",
    "    targetQs = tf.reshape(targetQs, shape=[-1, 1])\n",
    "    gloss = tf.reduce_mean(neg_log_prob * targetQs) # DPG: r+(gamma*nextQ)\n",
    "    gQs = discriminator(actions=actions_logits, hidden_size=hidden_size, states=states)\n",
    "    dQs = discriminator(actions=actions_labels, hidden_size=hidden_size, states=states, reuse=True) # Qs\n",
    "    rates = tf.reshape(rates, shape=[-1, 1])\n",
    "    dlossA = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                    labels=rates)) # 0-1\n",
    "    dlossA += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs, # GAN\n",
    "                                                                     labels=rates)) # 0-1\n",
    "    dlossA /= 2\n",
    "    dlossQ = tf.reduce_mean(tf.square(gQs - targetQs)) # DQN\n",
    "    dlossQ += tf.reduce_mean(tf.square(dQs - targetQs)) # DQN\n",
    "    dlossQ /= 2\n",
    "    return actions_logits, gQs, gloss, dlossA, dlossQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizating/training/learning G & D\n",
    "def model_opt(g_loss, d_lossA, d_lossQ, g_learning_rate, d_learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        g_opt = tf.train.AdamOptimizer(g_learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_optA = tf.train.AdamOptimizer(d_learning_rate).minimize(d_lossA, var_list=d_vars)\n",
    "        d_optQ = tf.train.AdamOptimizer(d_learning_rate).minimize(d_lossQ, var_list=d_vars)\n",
    "\n",
    "    return g_opt, d_optA, d_optQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, g_learning_rate, d_learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, self.rates = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.Qs_logits, self.g_loss, self.d_lossA, self.d_lossQ = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, rates=self.rates) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_opt, self.d_optA, self.d_optQ = model_opt(g_loss=self.g_loss, \n",
    "                                                         d_lossA=self.d_lossA, \n",
    "                                                         d_lossQ=self.d_lossQ, \n",
    "                                                         g_learning_rate=g_learning_rate, \n",
    "                                                         d_learning_rate=d_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size) # data batch\n",
    "        self.rates = deque(maxlen=max_size) # rates\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), # ==  self.rates\n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx], [self.rates[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 4*2             # number of units in each Q-network hidden layer\n",
    "g_learning_rate = 1e-4         # Q-network learning rate\n",
    "d_learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e3)             # experience mini-batch size: 200/500 a successfull episode size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size,\n",
    "              g_learning_rate=g_learning_rate, d_learning_rate=d_learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "total_reward = 0\n",
    "num_step = 0\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    memory.rates.append(-1) # empty\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()\n",
    "        rate = total_reward/500\n",
    "        total_reward = 0 # reset\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.rates[-1-idx] == -1:\n",
    "                memory.rates[-1-idx] = rate\n",
    "        num_step = 0 # reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:19.0000 R:19.0000 rate:0.0380 gloss:0.7675 dlossA:0.7475 dlossQ:0.9213 exploreP:0.9981\n",
      "Episode:1 meanR:20.0000 R:21.0000 rate:0.0420 gloss:0.7488 dlossA:0.7385 dlossQ:0.9226 exploreP:0.9960\n",
      "Episode:2 meanR:39.6667 R:79.0000 rate:0.1580 gloss:0.7440 dlossA:0.7310 dlossQ:0.9353 exploreP:0.9883\n",
      "Episode:3 meanR:39.5000 R:39.0000 rate:0.0780 gloss:0.7102 dlossA:0.7148 dlossQ:0.9416 exploreP:0.9845\n",
      "Episode:4 meanR:34.6000 R:15.0000 rate:0.0300 gloss:0.7035 dlossA:0.7095 dlossQ:0.9450 exploreP:0.9830\n",
      "Episode:5 meanR:37.5000 R:52.0000 rate:0.1040 gloss:0.6812 dlossA:0.6967 dlossQ:0.9486 exploreP:0.9780\n",
      "Episode:6 meanR:39.7143 R:53.0000 rate:0.1060 gloss:0.6610 dlossA:0.6854 dlossQ:0.9543 exploreP:0.9729\n",
      "Episode:7 meanR:37.6250 R:23.0000 rate:0.0460 gloss:0.6264 dlossA:0.6665 dlossQ:0.9546 exploreP:0.9706\n",
      "Episode:8 meanR:36.0000 R:23.0000 rate:0.0460 gloss:0.6413 dlossA:0.6766 dlossQ:0.9544 exploreP:0.9684\n",
      "Episode:9 meanR:33.9000 R:15.0000 rate:0.0300 gloss:0.6488 dlossA:0.6784 dlossQ:0.9667 exploreP:0.9670\n",
      "Episode:10 meanR:32.7273 R:21.0000 rate:0.0420 gloss:0.6113 dlossA:0.6626 dlossQ:0.9579 exploreP:0.9650\n",
      "Episode:11 meanR:34.7500 R:57.0000 rate:0.1140 gloss:0.5996 dlossA:0.6551 dlossQ:0.9606 exploreP:0.9596\n",
      "Episode:12 meanR:33.0000 R:12.0000 rate:0.0240 gloss:0.5616 dlossA:0.6356 dlossQ:0.9566 exploreP:0.9584\n",
      "Episode:13 meanR:31.9286 R:18.0000 rate:0.0360 gloss:0.5581 dlossA:0.6368 dlossQ:0.9604 exploreP:0.9567\n",
      "Episode:14 meanR:31.2000 R:21.0000 rate:0.0420 gloss:0.5597 dlossA:0.6345 dlossQ:0.9576 exploreP:0.9547\n",
      "Episode:15 meanR:30.0000 R:12.0000 rate:0.0240 gloss:0.5576 dlossA:0.6357 dlossQ:0.9541 exploreP:0.9536\n",
      "Episode:16 meanR:28.9412 R:12.0000 rate:0.0240 gloss:0.5439 dlossA:0.6299 dlossQ:0.9620 exploreP:0.9525\n",
      "Episode:17 meanR:28.0556 R:13.0000 rate:0.0260 gloss:0.5309 dlossA:0.6198 dlossQ:0.9611 exploreP:0.9512\n",
      "Episode:18 meanR:27.7895 R:23.0000 rate:0.0460 gloss:0.5385 dlossA:0.6261 dlossQ:0.9641 exploreP:0.9491\n",
      "Episode:19 meanR:27.5000 R:22.0000 rate:0.0440 gloss:0.5284 dlossA:0.6217 dlossQ:0.9565 exploreP:0.9470\n",
      "Episode:20 meanR:27.7143 R:32.0000 rate:0.0640 gloss:0.5089 dlossA:0.6131 dlossQ:0.9667 exploreP:0.9440\n",
      "Episode:21 meanR:26.9545 R:11.0000 rate:0.0220 gloss:0.4818 dlossA:0.6093 dlossQ:0.9427 exploreP:0.9430\n",
      "Episode:22 meanR:26.7391 R:22.0000 rate:0.0440 gloss:0.4840 dlossA:0.6039 dlossQ:0.9575 exploreP:0.9409\n",
      "Episode:23 meanR:26.3333 R:17.0000 rate:0.0340 gloss:0.4682 dlossA:0.5994 dlossQ:0.9602 exploreP:0.9394\n",
      "Episode:24 meanR:26.3600 R:27.0000 rate:0.0540 gloss:0.4516 dlossA:0.5877 dlossQ:0.9678 exploreP:0.9369\n",
      "Episode:25 meanR:25.8462 R:13.0000 rate:0.0260 gloss:0.4397 dlossA:0.5775 dlossQ:0.9825 exploreP:0.9357\n",
      "Episode:26 meanR:26.1481 R:34.0000 rate:0.0680 gloss:0.4475 dlossA:0.5865 dlossQ:0.9860 exploreP:0.9325\n",
      "Episode:27 meanR:26.2143 R:28.0000 rate:0.0560 gloss:0.4424 dlossA:0.5816 dlossQ:0.9826 exploreP:0.9299\n",
      "Episode:28 meanR:26.3793 R:31.0000 rate:0.0620 gloss:0.4033 dlossA:0.5686 dlossQ:0.9855 exploreP:0.9271\n",
      "Episode:29 meanR:26.1333 R:19.0000 rate:0.0380 gloss:0.4063 dlossA:0.5714 dlossQ:0.9966 exploreP:0.9253\n",
      "Episode:30 meanR:25.9032 R:19.0000 rate:0.0380 gloss:0.3839 dlossA:0.5601 dlossQ:0.9950 exploreP:0.9236\n",
      "Episode:31 meanR:26.3438 R:40.0000 rate:0.0800 gloss:0.3614 dlossA:0.5497 dlossQ:1.0018 exploreP:0.9200\n",
      "Episode:32 meanR:26.2121 R:22.0000 rate:0.0440 gloss:0.3803 dlossA:0.5590 dlossQ:1.0201 exploreP:0.9180\n",
      "Episode:33 meanR:26.2353 R:27.0000 rate:0.0540 gloss:0.3474 dlossA:0.5405 dlossQ:1.0176 exploreP:0.9155\n",
      "Episode:34 meanR:25.9714 R:17.0000 rate:0.0340 gloss:0.3311 dlossA:0.5414 dlossQ:1.0120 exploreP:0.9140\n",
      "Episode:35 meanR:25.8889 R:23.0000 rate:0.0460 gloss:0.3190 dlossA:0.5319 dlossQ:1.0264 exploreP:0.9119\n",
      "Episode:36 meanR:25.4595 R:10.0000 rate:0.0200 gloss:0.3196 dlossA:0.5299 dlossQ:1.0354 exploreP:0.9110\n",
      "Episode:37 meanR:25.5263 R:28.0000 rate:0.0560 gloss:0.3059 dlossA:0.5284 dlossQ:1.0358 exploreP:0.9085\n",
      "Episode:38 meanR:25.7436 R:34.0000 rate:0.0680 gloss:0.2931 dlossA:0.5252 dlossQ:1.0512 exploreP:0.9054\n",
      "Episode:39 meanR:25.5250 R:17.0000 rate:0.0340 gloss:0.2575 dlossA:0.5198 dlossQ:1.0290 exploreP:0.9039\n",
      "Episode:40 meanR:25.1707 R:11.0000 rate:0.0220 gloss:0.2309 dlossA:0.5140 dlossQ:1.0413 exploreP:0.9029\n",
      "Episode:41 meanR:25.0714 R:21.0000 rate:0.0420 gloss:0.2787 dlossA:0.5201 dlossQ:1.0643 exploreP:0.9011\n",
      "Episode:42 meanR:25.0000 R:22.0000 rate:0.0440 gloss:0.2547 dlossA:0.5104 dlossQ:1.0592 exploreP:0.8991\n",
      "Episode:43 meanR:25.2500 R:36.0000 rate:0.0720 gloss:0.2263 dlossA:0.5051 dlossQ:1.0667 exploreP:0.8959\n",
      "Episode:44 meanR:25.6000 R:41.0000 rate:0.0820 gloss:0.2170 dlossA:0.4974 dlossQ:1.0874 exploreP:0.8923\n",
      "Episode:45 meanR:26.4565 R:65.0000 rate:0.1300 gloss:0.1844 dlossA:0.4920 dlossQ:1.0800 exploreP:0.8866\n",
      "Episode:46 meanR:26.1489 R:12.0000 rate:0.0240 gloss:0.1614 dlossA:0.4934 dlossQ:1.0733 exploreP:0.8855\n",
      "Episode:47 meanR:25.9583 R:17.0000 rate:0.0340 gloss:0.1373 dlossA:0.4758 dlossQ:1.0756 exploreP:0.8840\n",
      "Episode:48 meanR:26.1633 R:36.0000 rate:0.0720 gloss:0.1356 dlossA:0.4752 dlossQ:1.0879 exploreP:0.8809\n",
      "Episode:49 meanR:26.2400 R:30.0000 rate:0.0600 gloss:0.1186 dlossA:0.4742 dlossQ:1.1004 exploreP:0.8783\n",
      "Episode:50 meanR:25.9412 R:11.0000 rate:0.0220 gloss:0.1439 dlossA:0.4783 dlossQ:1.1092 exploreP:0.8773\n",
      "Episode:51 meanR:26.0385 R:31.0000 rate:0.0620 gloss:0.0626 dlossA:0.4543 dlossQ:1.1267 exploreP:0.8746\n",
      "Episode:52 meanR:25.9623 R:22.0000 rate:0.0440 gloss:0.0686 dlossA:0.4523 dlossQ:1.1172 exploreP:0.8727\n",
      "Episode:53 meanR:26.1667 R:37.0000 rate:0.0740 gloss:0.0536 dlossA:0.4431 dlossQ:1.1190 exploreP:0.8695\n",
      "Episode:54 meanR:25.8545 R:9.0000 rate:0.0180 gloss:0.0454 dlossA:0.4520 dlossQ:1.1322 exploreP:0.8688\n",
      "Episode:55 meanR:25.6786 R:16.0000 rate:0.0320 gloss:0.0418 dlossA:0.4489 dlossQ:1.1482 exploreP:0.8674\n",
      "Episode:56 meanR:25.4912 R:15.0000 rate:0.0300 gloss:0.0492 dlossA:0.4543 dlossQ:1.1567 exploreP:0.8661\n",
      "Episode:57 meanR:26.1207 R:62.0000 rate:0.1240 gloss:0.0322 dlossA:0.4471 dlossQ:1.1944 exploreP:0.8608\n",
      "Episode:58 meanR:26.3220 R:38.0000 rate:0.0760 gloss:0.0167 dlossA:0.4300 dlossQ:1.1636 exploreP:0.8576\n",
      "Episode:59 meanR:26.1000 R:13.0000 rate:0.0260 gloss:0.0103 dlossA:0.4305 dlossQ:1.1675 exploreP:0.8565\n",
      "Episode:60 meanR:25.9016 R:14.0000 rate:0.0280 gloss:-0.0257 dlossA:0.4401 dlossQ:1.1939 exploreP:0.8553\n",
      "Episode:61 meanR:26.1613 R:42.0000 rate:0.0840 gloss:-0.0541 dlossA:0.4230 dlossQ:1.1826 exploreP:0.8518\n",
      "Episode:62 meanR:25.9841 R:15.0000 rate:0.0300 gloss:-0.0763 dlossA:0.4073 dlossQ:1.1823 exploreP:0.8505\n",
      "Episode:63 meanR:26.0781 R:32.0000 rate:0.0640 gloss:-0.0534 dlossA:0.4387 dlossQ:1.1909 exploreP:0.8478\n",
      "Episode:64 meanR:26.0154 R:22.0000 rate:0.0440 gloss:-0.1086 dlossA:0.4304 dlossQ:1.2019 exploreP:0.8460\n",
      "Episode:65 meanR:25.9091 R:19.0000 rate:0.0380 gloss:-0.1005 dlossA:0.4157 dlossQ:1.1877 exploreP:0.8444\n",
      "Episode:66 meanR:25.9254 R:27.0000 rate:0.0540 gloss:-0.0971 dlossA:0.4277 dlossQ:1.1840 exploreP:0.8421\n",
      "Episode:67 meanR:26.2941 R:51.0000 rate:0.1020 gloss:-0.1158 dlossA:0.4311 dlossQ:1.2531 exploreP:0.8379\n",
      "Episode:68 meanR:26.1449 R:16.0000 rate:0.0320 gloss:-0.1536 dlossA:0.4013 dlossQ:1.2485 exploreP:0.8366\n",
      "Episode:69 meanR:27.1857 R:99.0000 rate:0.1980 gloss:-0.1571 dlossA:0.4270 dlossQ:1.2396 exploreP:0.8284\n",
      "Episode:70 meanR:27.0563 R:18.0000 rate:0.0360 gloss:-0.1541 dlossA:0.4199 dlossQ:1.2441 exploreP:0.8270\n",
      "Episode:71 meanR:26.9444 R:19.0000 rate:0.0380 gloss:-0.1398 dlossA:0.4221 dlossQ:1.2497 exploreP:0.8254\n",
      "Episode:72 meanR:26.9178 R:25.0000 rate:0.0500 gloss:-0.1561 dlossA:0.4117 dlossQ:1.2587 exploreP:0.8234\n",
      "Episode:73 meanR:26.7568 R:15.0000 rate:0.0300 gloss:-0.2030 dlossA:0.4016 dlossQ:1.2506 exploreP:0.8222\n",
      "Episode:74 meanR:26.5600 R:12.0000 rate:0.0240 gloss:-0.1507 dlossA:0.4159 dlossQ:1.2718 exploreP:0.8212\n",
      "Episode:75 meanR:26.8947 R:52.0000 rate:0.1040 gloss:-0.2211 dlossA:0.4102 dlossQ:1.2805 exploreP:0.8170\n",
      "Episode:76 meanR:26.8831 R:26.0000 rate:0.0520 gloss:-0.2302 dlossA:0.3942 dlossQ:1.2981 exploreP:0.8149\n",
      "Episode:77 meanR:26.8077 R:21.0000 rate:0.0420 gloss:-0.2158 dlossA:0.4176 dlossQ:1.2817 exploreP:0.8132\n",
      "Episode:78 meanR:26.6456 R:14.0000 rate:0.0280 gloss:-0.2628 dlossA:0.4114 dlossQ:1.2713 exploreP:0.8121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:79 meanR:26.4875 R:14.0000 rate:0.0280 gloss:-0.2549 dlossA:0.3790 dlossQ:1.3373 exploreP:0.8110\n",
      "Episode:80 meanR:26.4198 R:21.0000 rate:0.0420 gloss:-0.3144 dlossA:0.4091 dlossQ:1.3147 exploreP:0.8093\n",
      "Episode:81 meanR:26.3659 R:22.0000 rate:0.0440 gloss:-0.2363 dlossA:0.4120 dlossQ:1.3166 exploreP:0.8075\n",
      "Episode:82 meanR:26.2651 R:18.0000 rate:0.0360 gloss:-0.2827 dlossA:0.4042 dlossQ:1.3296 exploreP:0.8061\n",
      "Episode:83 meanR:26.1548 R:17.0000 rate:0.0340 gloss:-0.2991 dlossA:0.3903 dlossQ:1.3757 exploreP:0.8047\n",
      "Episode:84 meanR:26.2000 R:30.0000 rate:0.0600 gloss:-0.2486 dlossA:0.4060 dlossQ:1.3328 exploreP:0.8024\n",
      "Episode:85 meanR:26.1628 R:23.0000 rate:0.0460 gloss:-0.3016 dlossA:0.4116 dlossQ:1.3563 exploreP:0.8005\n",
      "Episode:86 meanR:26.0000 R:12.0000 rate:0.0240 gloss:-0.3021 dlossA:0.4049 dlossQ:1.3542 exploreP:0.7996\n",
      "Episode:87 meanR:25.7955 R:8.0000 rate:0.0160 gloss:-0.2598 dlossA:0.3852 dlossQ:1.3991 exploreP:0.7990\n",
      "Episode:88 meanR:25.6404 R:12.0000 rate:0.0240 gloss:-0.2906 dlossA:0.4026 dlossQ:1.3721 exploreP:0.7980\n",
      "Episode:89 meanR:25.4444 R:8.0000 rate:0.0160 gloss:-0.2412 dlossA:0.4344 dlossQ:1.3210 exploreP:0.7974\n",
      "Episode:90 meanR:25.3736 R:19.0000 rate:0.0380 gloss:-0.2895 dlossA:0.4051 dlossQ:1.3783 exploreP:0.7959\n",
      "Episode:91 meanR:25.4457 R:32.0000 rate:0.0640 gloss:-0.3888 dlossA:0.4075 dlossQ:1.4181 exploreP:0.7934\n",
      "Episode:92 meanR:25.3226 R:14.0000 rate:0.0280 gloss:-0.3327 dlossA:0.3813 dlossQ:1.4336 exploreP:0.7923\n",
      "Episode:93 meanR:25.2340 R:17.0000 rate:0.0340 gloss:-0.3490 dlossA:0.4264 dlossQ:1.4366 exploreP:0.7909\n",
      "Episode:94 meanR:25.1368 R:16.0000 rate:0.0320 gloss:-0.3010 dlossA:0.3842 dlossQ:1.4240 exploreP:0.7897\n",
      "Episode:95 meanR:25.0000 R:12.0000 rate:0.0240 gloss:-0.3902 dlossA:0.3977 dlossQ:1.4367 exploreP:0.7888\n",
      "Episode:96 meanR:24.8454 R:10.0000 rate:0.0200 gloss:-0.3052 dlossA:0.4154 dlossQ:1.4469 exploreP:0.7880\n",
      "Episode:97 meanR:24.8367 R:24.0000 rate:0.0480 gloss:-0.3406 dlossA:0.3995 dlossQ:1.4364 exploreP:0.7861\n",
      "Episode:98 meanR:24.7273 R:14.0000 rate:0.0280 gloss:-0.3236 dlossA:0.3876 dlossQ:1.4667 exploreP:0.7850\n",
      "Episode:99 meanR:24.5900 R:11.0000 rate:0.0220 gloss:-0.3181 dlossA:0.3882 dlossQ:1.4545 exploreP:0.7842\n",
      "Episode:100 meanR:24.7400 R:34.0000 rate:0.0680 gloss:-0.4331 dlossA:0.4048 dlossQ:1.4589 exploreP:0.7816\n",
      "Episode:101 meanR:24.7700 R:24.0000 rate:0.0480 gloss:-0.3844 dlossA:0.3804 dlossQ:1.4958 exploreP:0.7797\n",
      "Episode:102 meanR:24.1200 R:14.0000 rate:0.0280 gloss:-0.4956 dlossA:0.3810 dlossQ:1.5219 exploreP:0.7786\n",
      "Episode:103 meanR:23.9900 R:26.0000 rate:0.0520 gloss:-0.5195 dlossA:0.4131 dlossQ:1.4967 exploreP:0.7766\n",
      "Episode:104 meanR:24.2400 R:40.0000 rate:0.0800 gloss:-0.4721 dlossA:0.4083 dlossQ:1.5075 exploreP:0.7736\n",
      "Episode:105 meanR:23.8400 R:12.0000 rate:0.0240 gloss:-0.4695 dlossA:0.3935 dlossQ:1.5149 exploreP:0.7727\n",
      "Episode:106 meanR:23.6900 R:38.0000 rate:0.0760 gloss:-0.5512 dlossA:0.3888 dlossQ:1.5239 exploreP:0.7698\n",
      "Episode:107 meanR:23.6400 R:18.0000 rate:0.0360 gloss:-0.6410 dlossA:0.3916 dlossQ:1.5355 exploreP:0.7684\n",
      "Episode:108 meanR:23.5000 R:9.0000 rate:0.0180 gloss:-0.8513 dlossA:0.4024 dlossQ:1.5647 exploreP:0.7677\n",
      "Episode:109 meanR:23.5800 R:23.0000 rate:0.0460 gloss:-0.7238 dlossA:0.3904 dlossQ:1.5194 exploreP:0.7660\n",
      "Episode:110 meanR:23.5900 R:22.0000 rate:0.0440 gloss:-0.7323 dlossA:0.4023 dlossQ:1.5280 exploreP:0.7643\n",
      "Episode:111 meanR:23.3300 R:31.0000 rate:0.0620 gloss:-0.8455 dlossA:0.3933 dlossQ:1.5093 exploreP:0.7620\n",
      "Episode:112 meanR:23.3800 R:17.0000 rate:0.0340 gloss:-1.1553 dlossA:0.4019 dlossQ:1.4684 exploreP:0.7607\n",
      "Episode:113 meanR:23.4000 R:20.0000 rate:0.0400 gloss:-1.1219 dlossA:0.3657 dlossQ:1.4778 exploreP:0.7592\n",
      "Episode:114 meanR:23.4400 R:25.0000 rate:0.0500 gloss:-1.2282 dlossA:0.3840 dlossQ:1.3325 exploreP:0.7573\n",
      "Episode:115 meanR:23.5000 R:18.0000 rate:0.0360 gloss:-1.4794 dlossA:0.3834 dlossQ:1.3594 exploreP:0.7560\n",
      "Episode:116 meanR:23.5300 R:15.0000 rate:0.0300 gloss:-1.7586 dlossA:0.3951 dlossQ:1.3639 exploreP:0.7549\n",
      "Episode:117 meanR:23.5800 R:18.0000 rate:0.0360 gloss:-1.9860 dlossA:0.4207 dlossQ:1.3291 exploreP:0.7535\n",
      "Episode:118 meanR:23.5100 R:16.0000 rate:0.0320 gloss:-2.1003 dlossA:0.3623 dlossQ:1.2453 exploreP:0.7523\n",
      "Episode:119 meanR:23.5500 R:26.0000 rate:0.0520 gloss:-2.3889 dlossA:0.3780 dlossQ:1.1656 exploreP:0.7504\n",
      "Episode:120 meanR:23.4200 R:19.0000 rate:0.0380 gloss:-2.8814 dlossA:0.3902 dlossQ:1.0993 exploreP:0.7490\n",
      "Episode:121 meanR:23.6000 R:29.0000 rate:0.0580 gloss:-3.3974 dlossA:0.3947 dlossQ:1.1038 exploreP:0.7469\n",
      "Episode:122 meanR:23.5200 R:14.0000 rate:0.0280 gloss:-3.5936 dlossA:0.3734 dlossQ:1.0080 exploreP:0.7458\n",
      "Episode:123 meanR:23.5200 R:17.0000 rate:0.0340 gloss:-4.0867 dlossA:0.3670 dlossQ:0.9971 exploreP:0.7446\n",
      "Episode:124 meanR:23.3400 R:9.0000 rate:0.0180 gloss:-4.8033 dlossA:0.4130 dlossQ:1.0488 exploreP:0.7439\n",
      "Episode:125 meanR:23.3500 R:14.0000 rate:0.0280 gloss:-4.5024 dlossA:0.3944 dlossQ:0.9738 exploreP:0.7429\n",
      "Episode:126 meanR:23.1500 R:14.0000 rate:0.0280 gloss:-4.7096 dlossA:0.4072 dlossQ:1.0776 exploreP:0.7419\n",
      "Episode:127 meanR:23.0100 R:14.0000 rate:0.0280 gloss:-4.9308 dlossA:0.4026 dlossQ:0.9354 exploreP:0.7408\n",
      "Episode:128 meanR:22.8000 R:10.0000 rate:0.0200 gloss:-5.1724 dlossA:0.4047 dlossQ:0.8634 exploreP:0.7401\n",
      "Episode:129 meanR:22.9200 R:31.0000 rate:0.0620 gloss:-5.2460 dlossA:0.3847 dlossQ:0.9398 exploreP:0.7379\n",
      "Episode:130 meanR:22.8500 R:12.0000 rate:0.0240 gloss:-5.6263 dlossA:0.3956 dlossQ:0.9507 exploreP:0.7370\n",
      "Episode:131 meanR:22.6700 R:22.0000 rate:0.0440 gloss:-6.0237 dlossA:0.3958 dlossQ:0.9539 exploreP:0.7354\n",
      "Episode:132 meanR:22.6000 R:15.0000 rate:0.0300 gloss:-6.2329 dlossA:0.3816 dlossQ:1.0539 exploreP:0.7343\n",
      "Episode:133 meanR:22.5700 R:24.0000 rate:0.0480 gloss:-6.1744 dlossA:0.3833 dlossQ:0.9857 exploreP:0.7326\n",
      "Episode:134 meanR:22.5300 R:13.0000 rate:0.0260 gloss:-6.4991 dlossA:0.4006 dlossQ:1.0100 exploreP:0.7316\n",
      "Episode:135 meanR:22.4600 R:16.0000 rate:0.0320 gloss:-5.8820 dlossA:0.3933 dlossQ:0.9720 exploreP:0.7305\n",
      "Episode:136 meanR:22.4600 R:10.0000 rate:0.0200 gloss:-6.2276 dlossA:0.4180 dlossQ:1.0122 exploreP:0.7298\n",
      "Episode:137 meanR:22.3000 R:12.0000 rate:0.0240 gloss:-6.0102 dlossA:0.3531 dlossQ:1.0286 exploreP:0.7289\n",
      "Episode:138 meanR:22.0500 R:9.0000 rate:0.0180 gloss:-6.5609 dlossA:0.4127 dlossQ:1.0546 exploreP:0.7282\n",
      "Episode:139 meanR:21.9700 R:9.0000 rate:0.0180 gloss:-6.6887 dlossA:0.3582 dlossQ:1.0706 exploreP:0.7276\n",
      "Episode:140 meanR:22.0100 R:15.0000 rate:0.0300 gloss:-6.7745 dlossA:0.3728 dlossQ:1.0424 exploreP:0.7265\n",
      "Episode:141 meanR:22.0700 R:27.0000 rate:0.0540 gloss:-6.7410 dlossA:0.4128 dlossQ:1.0157 exploreP:0.7246\n",
      "Episode:142 meanR:21.9500 R:10.0000 rate:0.0200 gloss:-7.1603 dlossA:0.4029 dlossQ:1.0982 exploreP:0.7239\n",
      "Episode:143 meanR:21.8200 R:23.0000 rate:0.0460 gloss:-6.6270 dlossA:0.3703 dlossQ:1.1193 exploreP:0.7222\n",
      "Episode:144 meanR:21.5100 R:10.0000 rate:0.0200 gloss:-7.2032 dlossA:0.3565 dlossQ:1.1051 exploreP:0.7215\n",
      "Episode:145 meanR:20.9800 R:12.0000 rate:0.0240 gloss:-8.0147 dlossA:0.3522 dlossQ:1.0725 exploreP:0.7207\n",
      "Episode:146 meanR:20.9900 R:13.0000 rate:0.0260 gloss:-8.3029 dlossA:0.3668 dlossQ:1.0445 exploreP:0.7197\n",
      "Episode:147 meanR:20.9400 R:12.0000 rate:0.0240 gloss:-9.4859 dlossA:0.3978 dlossQ:1.0830 exploreP:0.7189\n",
      "Episode:148 meanR:20.7100 R:13.0000 rate:0.0260 gloss:-8.9977 dlossA:0.3739 dlossQ:1.0781 exploreP:0.7180\n",
      "Episode:149 meanR:20.5900 R:18.0000 rate:0.0360 gloss:-8.5240 dlossA:0.3824 dlossQ:1.0596 exploreP:0.7167\n",
      "Episode:150 meanR:20.5800 R:10.0000 rate:0.0200 gloss:-8.6657 dlossA:0.3439 dlossQ:1.0730 exploreP:0.7160\n",
      "Episode:151 meanR:20.3800 R:11.0000 rate:0.0220 gloss:-8.8137 dlossA:0.3452 dlossQ:1.0601 exploreP:0.7152\n",
      "Episode:152 meanR:20.4300 R:27.0000 rate:0.0540 gloss:-9.5169 dlossA:0.3958 dlossQ:1.0228 exploreP:0.7133\n",
      "Episode:153 meanR:20.2000 R:14.0000 rate:0.0280 gloss:-9.2392 dlossA:0.3801 dlossQ:1.0771 exploreP:0.7123\n",
      "Episode:154 meanR:20.2400 R:13.0000 rate:0.0260 gloss:-8.9506 dlossA:0.3736 dlossQ:1.0744 exploreP:0.7114\n",
      "Episode:155 meanR:20.3000 R:22.0000 rate:0.0440 gloss:-9.5609 dlossA:0.3940 dlossQ:1.0810 exploreP:0.7099\n",
      "Episode:156 meanR:20.5100 R:36.0000 rate:0.0720 gloss:-9.2870 dlossA:0.3793 dlossQ:1.0817 exploreP:0.7074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:157 meanR:20.0300 R:14.0000 rate:0.0280 gloss:-10.1152 dlossA:0.3459 dlossQ:1.0745 exploreP:0.7064\n",
      "Episode:158 meanR:19.7500 R:10.0000 rate:0.0200 gloss:-11.1960 dlossA:0.3675 dlossQ:1.0652 exploreP:0.7057\n",
      "Episode:159 meanR:19.7300 R:11.0000 rate:0.0220 gloss:-11.3027 dlossA:0.4026 dlossQ:1.0143 exploreP:0.7049\n",
      "Episode:160 meanR:19.7000 R:11.0000 rate:0.0220 gloss:-11.5884 dlossA:0.3883 dlossQ:1.0785 exploreP:0.7042\n",
      "Episode:161 meanR:19.3800 R:10.0000 rate:0.0200 gloss:-11.5759 dlossA:0.4343 dlossQ:1.0870 exploreP:0.7035\n",
      "Episode:162 meanR:19.3900 R:16.0000 rate:0.0320 gloss:-10.2323 dlossA:0.3688 dlossQ:1.1840 exploreP:0.7024\n",
      "Episode:163 meanR:19.2100 R:14.0000 rate:0.0280 gloss:-10.6517 dlossA:0.3851 dlossQ:1.1381 exploreP:0.7014\n",
      "Episode:164 meanR:19.1300 R:14.0000 rate:0.0280 gloss:-11.0346 dlossA:0.3905 dlossQ:1.1036 exploreP:0.7004\n",
      "Episode:165 meanR:19.3300 R:39.0000 rate:0.0780 gloss:-12.1765 dlossA:0.3969 dlossQ:1.1504 exploreP:0.6977\n",
      "Episode:166 meanR:19.1600 R:10.0000 rate:0.0200 gloss:-11.5548 dlossA:0.3931 dlossQ:1.1955 exploreP:0.6970\n",
      "Episode:167 meanR:18.9800 R:33.0000 rate:0.0660 gloss:-11.5606 dlossA:0.3831 dlossQ:1.1395 exploreP:0.6948\n",
      "Episode:168 meanR:18.9500 R:13.0000 rate:0.0260 gloss:-12.5394 dlossA:0.3853 dlossQ:1.1155 exploreP:0.6939\n",
      "Episode:169 meanR:18.0500 R:9.0000 rate:0.0180 gloss:-8.5727 dlossA:0.3585 dlossQ:2.1097 exploreP:0.6933\n",
      "Episode:170 meanR:18.0700 R:20.0000 rate:0.0400 gloss:-13.6460 dlossA:0.3694 dlossQ:1.0666 exploreP:0.6919\n",
      "Episode:171 meanR:18.0500 R:17.0000 rate:0.0340 gloss:-14.0381 dlossA:0.3753 dlossQ:1.1470 exploreP:0.6908\n",
      "Episode:172 meanR:18.0600 R:26.0000 rate:0.0520 gloss:-15.0644 dlossA:0.3642 dlossQ:1.0751 exploreP:0.6890\n",
      "Episode:173 meanR:18.1000 R:19.0000 rate:0.0380 gloss:-16.1035 dlossA:0.4001 dlossQ:1.0724 exploreP:0.6877\n",
      "Episode:174 meanR:18.1000 R:12.0000 rate:0.0240 gloss:-14.4810 dlossA:0.4211 dlossQ:1.1107 exploreP:0.6869\n",
      "Episode:175 meanR:17.7100 R:13.0000 rate:0.0260 gloss:-12.7303 dlossA:0.3676 dlossQ:1.1939 exploreP:0.6860\n",
      "Episode:176 meanR:17.6300 R:18.0000 rate:0.0360 gloss:-13.7656 dlossA:0.3798 dlossQ:1.1091 exploreP:0.6848\n",
      "Episode:177 meanR:17.5300 R:11.0000 rate:0.0220 gloss:-16.2131 dlossA:0.3911 dlossQ:1.1546 exploreP:0.6841\n",
      "Episode:178 meanR:17.4900 R:10.0000 rate:0.0200 gloss:-14.5125 dlossA:0.3805 dlossQ:1.0578 exploreP:0.6834\n",
      "Episode:179 meanR:17.5200 R:17.0000 rate:0.0340 gloss:-16.6248 dlossA:0.3836 dlossQ:1.0860 exploreP:0.6822\n",
      "Episode:180 meanR:17.4500 R:14.0000 rate:0.0280 gloss:-15.3172 dlossA:0.3789 dlossQ:1.1219 exploreP:0.6813\n",
      "Episode:181 meanR:17.3900 R:16.0000 rate:0.0320 gloss:-16.2547 dlossA:0.3736 dlossQ:1.0697 exploreP:0.6802\n",
      "Episode:182 meanR:17.3600 R:15.0000 rate:0.0300 gloss:-18.0651 dlossA:0.3844 dlossQ:1.0838 exploreP:0.6792\n",
      "Episode:183 meanR:17.3700 R:18.0000 rate:0.0360 gloss:-16.7523 dlossA:0.3873 dlossQ:1.1305 exploreP:0.6780\n",
      "Episode:184 meanR:17.1800 R:11.0000 rate:0.0220 gloss:-16.3854 dlossA:0.4008 dlossQ:1.1113 exploreP:0.6773\n",
      "Episode:185 meanR:17.0600 R:11.0000 rate:0.0220 gloss:-15.4790 dlossA:0.3706 dlossQ:1.1087 exploreP:0.6765\n",
      "Episode:186 meanR:17.1200 R:18.0000 rate:0.0360 gloss:-18.8016 dlossA:0.3799 dlossQ:1.0952 exploreP:0.6753\n",
      "Episode:187 meanR:17.3000 R:26.0000 rate:0.0520 gloss:-17.8992 dlossA:0.4056 dlossQ:1.1043 exploreP:0.6736\n",
      "Episode:188 meanR:17.4300 R:25.0000 rate:0.0500 gloss:-16.6124 dlossA:0.3965 dlossQ:1.2206 exploreP:0.6720\n",
      "Episode:189 meanR:17.4900 R:14.0000 rate:0.0280 gloss:-16.3296 dlossA:0.3820 dlossQ:1.1601 exploreP:0.6710\n",
      "Episode:190 meanR:17.5100 R:21.0000 rate:0.0420 gloss:-18.1269 dlossA:0.3614 dlossQ:1.0648 exploreP:0.6696\n",
      "Episode:191 meanR:17.3000 R:11.0000 rate:0.0220 gloss:-21.6164 dlossA:0.3970 dlossQ:1.0033 exploreP:0.6689\n",
      "Episode:192 meanR:17.4100 R:25.0000 rate:0.0500 gloss:-20.1257 dlossA:0.3818 dlossQ:1.0526 exploreP:0.6673\n",
      "Episode:193 meanR:17.5300 R:29.0000 rate:0.0580 gloss:-21.2839 dlossA:0.3974 dlossQ:1.1582 exploreP:0.6654\n",
      "Episode:194 meanR:17.4800 R:11.0000 rate:0.0220 gloss:-17.9634 dlossA:0.3728 dlossQ:1.1382 exploreP:0.6647\n",
      "Episode:195 meanR:17.4600 R:10.0000 rate:0.0200 gloss:-19.0454 dlossA:0.3930 dlossQ:1.1252 exploreP:0.6640\n",
      "Episode:196 meanR:17.5600 R:20.0000 rate:0.0400 gloss:-21.2785 dlossA:0.3840 dlossQ:1.1237 exploreP:0.6627\n",
      "Episode:197 meanR:17.5300 R:21.0000 rate:0.0420 gloss:-22.6524 dlossA:0.3791 dlossQ:1.1110 exploreP:0.6613\n",
      "Episode:198 meanR:17.5700 R:18.0000 rate:0.0360 gloss:-22.3335 dlossA:0.3830 dlossQ:1.0863 exploreP:0.6602\n",
      "Episode:199 meanR:17.7200 R:26.0000 rate:0.0520 gloss:-23.3650 dlossA:0.3967 dlossQ:1.0946 exploreP:0.6585\n",
      "Episode:200 meanR:17.5900 R:21.0000 rate:0.0420 gloss:-21.8179 dlossA:0.3985 dlossQ:1.1612 exploreP:0.6571\n",
      "Episode:201 meanR:17.5300 R:18.0000 rate:0.0360 gloss:-22.2256 dlossA:0.3921 dlossQ:1.0626 exploreP:0.6559\n",
      "Episode:202 meanR:17.6400 R:25.0000 rate:0.0500 gloss:-22.5213 dlossA:0.3876 dlossQ:1.0583 exploreP:0.6543\n",
      "Episode:203 meanR:17.7500 R:37.0000 rate:0.0740 gloss:-26.9788 dlossA:0.3632 dlossQ:1.0458 exploreP:0.6519\n",
      "Episode:204 meanR:17.5400 R:19.0000 rate:0.0380 gloss:-26.2967 dlossA:0.3734 dlossQ:1.0392 exploreP:0.6507\n",
      "Episode:205 meanR:17.8000 R:38.0000 rate:0.0760 gloss:-23.6727 dlossA:0.3795 dlossQ:1.3602 exploreP:0.6483\n",
      "Episode:206 meanR:17.5600 R:14.0000 rate:0.0280 gloss:-28.0965 dlossA:0.3685 dlossQ:1.0742 exploreP:0.6474\n",
      "Episode:207 meanR:17.4600 R:8.0000 rate:0.0160 gloss:-29.5731 dlossA:0.3664 dlossQ:1.0227 exploreP:0.6469\n",
      "Episode:208 meanR:17.5600 R:19.0000 rate:0.0380 gloss:-28.4893 dlossA:0.3990 dlossQ:1.4292 exploreP:0.6457\n",
      "Episode:209 meanR:17.4700 R:14.0000 rate:0.0280 gloss:-25.2442 dlossA:0.4093 dlossQ:1.1956 exploreP:0.6448\n",
      "Episode:210 meanR:17.4400 R:19.0000 rate:0.0380 gloss:-26.1035 dlossA:0.3646 dlossQ:1.2054 exploreP:0.6436\n",
      "Episode:211 meanR:17.6100 R:48.0000 rate:0.0960 gloss:-32.9323 dlossA:0.3658 dlossQ:1.0114 exploreP:0.6406\n",
      "Episode:212 meanR:17.5800 R:14.0000 rate:0.0280 gloss:-30.2758 dlossA:0.3922 dlossQ:1.1519 exploreP:0.6397\n",
      "Episode:213 meanR:17.5800 R:20.0000 rate:0.0400 gloss:-30.1176 dlossA:0.3952 dlossQ:1.2316 exploreP:0.6384\n",
      "Episode:214 meanR:17.5200 R:19.0000 rate:0.0380 gloss:-29.1241 dlossA:0.3937 dlossQ:1.1452 exploreP:0.6372\n",
      "Episode:215 meanR:17.4600 R:12.0000 rate:0.0240 gloss:-30.9825 dlossA:0.3906 dlossQ:1.1069 exploreP:0.6365\n",
      "Episode:216 meanR:17.4500 R:14.0000 rate:0.0280 gloss:-31.9518 dlossA:0.3823 dlossQ:1.1303 exploreP:0.6356\n",
      "Episode:217 meanR:17.4500 R:18.0000 rate:0.0360 gloss:-31.2032 dlossA:0.3868 dlossQ:1.1521 exploreP:0.6345\n",
      "Episode:218 meanR:17.4600 R:17.0000 rate:0.0340 gloss:-32.0215 dlossA:0.3856 dlossQ:1.1777 exploreP:0.6334\n",
      "Episode:219 meanR:17.3900 R:19.0000 rate:0.0380 gloss:-36.2032 dlossA:0.3684 dlossQ:1.0939 exploreP:0.6322\n",
      "Episode:220 meanR:17.3600 R:16.0000 rate:0.0320 gloss:-33.0005 dlossA:0.3748 dlossQ:1.1066 exploreP:0.6312\n",
      "Episode:221 meanR:17.1700 R:10.0000 rate:0.0200 gloss:-35.5506 dlossA:0.3803 dlossQ:1.1374 exploreP:0.6306\n",
      "Episode:222 meanR:17.1300 R:10.0000 rate:0.0200 gloss:-36.2108 dlossA:0.3741 dlossQ:1.1067 exploreP:0.6300\n",
      "Episode:223 meanR:17.0800 R:12.0000 rate:0.0240 gloss:-37.0985 dlossA:0.3801 dlossQ:1.0857 exploreP:0.6292\n",
      "Episode:224 meanR:17.1000 R:11.0000 rate:0.0220 gloss:-37.3502 dlossA:0.3938 dlossQ:1.3806 exploreP:0.6286\n",
      "Episode:225 meanR:17.1000 R:14.0000 rate:0.0280 gloss:-35.2012 dlossA:0.3857 dlossQ:1.1815 exploreP:0.6277\n",
      "Episode:226 meanR:17.0600 R:10.0000 rate:0.0200 gloss:-35.5077 dlossA:0.3773 dlossQ:1.2009 exploreP:0.6271\n",
      "Episode:227 meanR:17.0800 R:16.0000 rate:0.0320 gloss:-35.7565 dlossA:0.3961 dlossQ:1.2128 exploreP:0.6261\n",
      "Episode:228 meanR:17.1700 R:19.0000 rate:0.0380 gloss:-36.1868 dlossA:0.3711 dlossQ:1.1955 exploreP:0.6249\n",
      "Episode:229 meanR:17.0000 R:14.0000 rate:0.0280 gloss:-42.2253 dlossA:0.4052 dlossQ:1.0413 exploreP:0.6241\n",
      "Episode:230 meanR:17.0300 R:15.0000 rate:0.0300 gloss:-39.0285 dlossA:0.3866 dlossQ:1.1736 exploreP:0.6231\n",
      "Episode:231 meanR:16.9400 R:13.0000 rate:0.0260 gloss:-38.4176 dlossA:0.4223 dlossQ:1.2153 exploreP:0.6224\n",
      "Episode:232 meanR:16.8900 R:10.0000 rate:0.0200 gloss:-30.7191 dlossA:0.4018 dlossQ:1.3010 exploreP:0.6217\n",
      "Episode:233 meanR:16.8500 R:20.0000 rate:0.0400 gloss:-39.0276 dlossA:0.3941 dlossQ:1.1363 exploreP:0.6205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:234 meanR:16.8400 R:12.0000 rate:0.0240 gloss:-43.8661 dlossA:0.4130 dlossQ:1.1345 exploreP:0.6198\n",
      "Episode:235 meanR:17.3500 R:67.0000 rate:0.1340 gloss:-40.7539 dlossA:0.3823 dlossQ:1.1371 exploreP:0.6157\n",
      "Episode:236 meanR:17.4000 R:15.0000 rate:0.0300 gloss:-44.3330 dlossA:0.3774 dlossQ:1.0579 exploreP:0.6148\n",
      "Episode:237 meanR:17.3900 R:11.0000 rate:0.0220 gloss:-47.9061 dlossA:0.3624 dlossQ:1.0089 exploreP:0.6141\n",
      "Episode:238 meanR:17.4400 R:14.0000 rate:0.0280 gloss:-49.4585 dlossA:0.3971 dlossQ:1.0219 exploreP:0.6133\n",
      "Episode:239 meanR:17.4900 R:14.0000 rate:0.0280 gloss:-39.6029 dlossA:0.3757 dlossQ:1.1510 exploreP:0.6125\n",
      "Episode:240 meanR:17.4400 R:10.0000 rate:0.0200 gloss:-47.6132 dlossA:0.3638 dlossQ:1.0428 exploreP:0.6118\n",
      "Episode:241 meanR:17.3400 R:17.0000 rate:0.0340 gloss:-51.6325 dlossA:0.3951 dlossQ:1.0234 exploreP:0.6108\n",
      "Episode:242 meanR:17.3800 R:14.0000 rate:0.0280 gloss:-39.8800 dlossA:0.3789 dlossQ:1.1709 exploreP:0.6100\n",
      "Episode:243 meanR:17.2400 R:9.0000 rate:0.0180 gloss:-48.3538 dlossA:0.3633 dlossQ:1.1017 exploreP:0.6094\n",
      "Episode:244 meanR:17.2600 R:12.0000 rate:0.0240 gloss:-53.3497 dlossA:0.3686 dlossQ:1.0233 exploreP:0.6087\n",
      "Episode:245 meanR:17.2900 R:15.0000 rate:0.0300 gloss:-50.3961 dlossA:0.3661 dlossQ:1.0092 exploreP:0.6078\n",
      "Episode:246 meanR:17.3000 R:14.0000 rate:0.0280 gloss:-53.5142 dlossA:0.3757 dlossQ:1.0056 exploreP:0.6070\n",
      "Episode:247 meanR:17.2900 R:11.0000 rate:0.0220 gloss:-49.0888 dlossA:0.3864 dlossQ:1.0956 exploreP:0.6063\n",
      "Episode:248 meanR:17.2800 R:12.0000 rate:0.0240 gloss:-45.3439 dlossA:0.3769 dlossQ:1.1140 exploreP:0.6056\n",
      "Episode:249 meanR:17.2900 R:19.0000 rate:0.0380 gloss:-55.6016 dlossA:0.3512 dlossQ:1.0237 exploreP:0.6045\n",
      "Episode:250 meanR:17.4100 R:22.0000 rate:0.0440 gloss:-52.9574 dlossA:0.3853 dlossQ:1.0528 exploreP:0.6032\n",
      "Episode:251 meanR:17.4200 R:12.0000 rate:0.0240 gloss:-46.2135 dlossA:0.4232 dlossQ:1.5015 exploreP:0.6025\n",
      "Episode:252 meanR:17.2400 R:9.0000 rate:0.0180 gloss:-43.7497 dlossA:0.3876 dlossQ:1.2630 exploreP:0.6019\n",
      "Episode:253 meanR:17.2000 R:10.0000 rate:0.0200 gloss:-50.2009 dlossA:0.3799 dlossQ:1.1574 exploreP:0.6013\n",
      "Episode:254 meanR:17.1700 R:10.0000 rate:0.0200 gloss:-53.8908 dlossA:0.4069 dlossQ:1.0575 exploreP:0.6008\n",
      "Episode:255 meanR:17.0500 R:10.0000 rate:0.0200 gloss:-49.4817 dlossA:0.3845 dlossQ:1.1702 exploreP:0.6002\n",
      "Episode:256 meanR:16.8100 R:12.0000 rate:0.0240 gloss:-42.7453 dlossA:0.4374 dlossQ:1.1955 exploreP:0.5995\n",
      "Episode:257 meanR:16.7900 R:12.0000 rate:0.0240 gloss:-41.0926 dlossA:0.3753 dlossQ:1.3110 exploreP:0.5988\n",
      "Episode:258 meanR:16.7900 R:10.0000 rate:0.0200 gloss:-45.7559 dlossA:0.4053 dlossQ:1.1203 exploreP:0.5982\n",
      "Episode:259 meanR:17.2000 R:52.0000 rate:0.1040 gloss:-56.4390 dlossA:0.3742 dlossQ:1.1038 exploreP:0.5951\n",
      "Episode:260 meanR:17.2300 R:14.0000 rate:0.0280 gloss:-53.1371 dlossA:0.4345 dlossQ:1.1456 exploreP:0.5943\n",
      "Episode:261 meanR:17.2500 R:12.0000 rate:0.0240 gloss:-41.5064 dlossA:0.4010 dlossQ:1.3187 exploreP:0.5936\n",
      "Episode:262 meanR:17.1900 R:10.0000 rate:0.0200 gloss:-57.3746 dlossA:0.3759 dlossQ:1.1470 exploreP:0.5930\n",
      "Episode:263 meanR:17.2200 R:17.0000 rate:0.0340 gloss:-60.5969 dlossA:0.4041 dlossQ:1.0641 exploreP:0.5920\n",
      "Episode:264 meanR:17.2000 R:12.0000 rate:0.0240 gloss:-55.4859 dlossA:0.4057 dlossQ:1.2842 exploreP:0.5913\n",
      "Episode:265 meanR:16.9400 R:13.0000 rate:0.0260 gloss:-55.0748 dlossA:0.4011 dlossQ:1.2122 exploreP:0.5906\n",
      "Episode:266 meanR:16.9300 R:9.0000 rate:0.0180 gloss:-51.5912 dlossA:0.3731 dlossQ:1.1334 exploreP:0.5900\n",
      "Episode:267 meanR:16.8500 R:25.0000 rate:0.0500 gloss:-62.8234 dlossA:0.3902 dlossQ:1.1396 exploreP:0.5886\n",
      "Episode:268 meanR:16.8100 R:9.0000 rate:0.0180 gloss:-57.1364 dlossA:0.3369 dlossQ:1.1294 exploreP:0.5881\n",
      "Episode:269 meanR:17.2300 R:51.0000 rate:0.1020 gloss:-68.0837 dlossA:0.3740 dlossQ:1.0698 exploreP:0.5851\n",
      "Episode:270 meanR:17.2000 R:17.0000 rate:0.0340 gloss:-69.1497 dlossA:0.3952 dlossQ:1.0664 exploreP:0.5842\n",
      "Episode:271 meanR:17.1200 R:9.0000 rate:0.0180 gloss:-57.4706 dlossA:0.3563 dlossQ:1.1469 exploreP:0.5836\n",
      "Episode:272 meanR:16.9800 R:12.0000 rate:0.0240 gloss:-70.2137 dlossA:0.3719 dlossQ:1.0278 exploreP:0.5830\n",
      "Episode:273 meanR:16.9600 R:17.0000 rate:0.0340 gloss:-74.7131 dlossA:0.3783 dlossQ:1.0139 exploreP:0.5820\n",
      "Episode:274 meanR:16.9600 R:12.0000 rate:0.0240 gloss:-72.0261 dlossA:0.3783 dlossQ:1.2405 exploreP:0.5813\n",
      "Episode:275 meanR:16.9600 R:13.0000 rate:0.0260 gloss:-63.3025 dlossA:0.4222 dlossQ:1.1959 exploreP:0.5806\n",
      "Episode:276 meanR:16.8900 R:11.0000 rate:0.0220 gloss:-51.5734 dlossA:0.4073 dlossQ:1.3255 exploreP:0.5799\n",
      "Episode:277 meanR:17.1100 R:33.0000 rate:0.0660 gloss:-61.3933 dlossA:0.4075 dlossQ:1.1565 exploreP:0.5780\n",
      "Episode:278 meanR:17.1400 R:13.0000 rate:0.0260 gloss:-64.3747 dlossA:0.3811 dlossQ:1.2307 exploreP:0.5773\n",
      "Episode:279 meanR:17.1000 R:13.0000 rate:0.0260 gloss:-75.1143 dlossA:0.3860 dlossQ:1.0163 exploreP:0.5766\n",
      "Episode:280 meanR:17.1200 R:16.0000 rate:0.0320 gloss:-62.6152 dlossA:0.3991 dlossQ:1.2433 exploreP:0.5757\n",
      "Episode:281 meanR:17.1200 R:16.0000 rate:0.0320 gloss:-77.8794 dlossA:0.3884 dlossQ:1.0901 exploreP:0.5748\n",
      "Episode:282 meanR:17.1000 R:13.0000 rate:0.0260 gloss:-73.6541 dlossA:0.3794 dlossQ:1.0938 exploreP:0.5740\n",
      "Episode:283 meanR:17.1500 R:23.0000 rate:0.0460 gloss:-76.3762 dlossA:0.3659 dlossQ:1.1209 exploreP:0.5727\n",
      "Episode:284 meanR:17.1400 R:10.0000 rate:0.0200 gloss:-86.0924 dlossA:0.3507 dlossQ:1.0480 exploreP:0.5722\n",
      "Episode:285 meanR:17.1700 R:14.0000 rate:0.0280 gloss:-86.0663 dlossA:0.3734 dlossQ:1.0486 exploreP:0.5714\n",
      "Episode:286 meanR:17.3500 R:36.0000 rate:0.0720 gloss:-82.8324 dlossA:0.3718 dlossQ:1.0725 exploreP:0.5694\n",
      "Episode:287 meanR:17.2800 R:19.0000 rate:0.0380 gloss:-72.1325 dlossA:0.3889 dlossQ:1.2341 exploreP:0.5683\n",
      "Episode:288 meanR:17.1600 R:13.0000 rate:0.0260 gloss:-94.4052 dlossA:0.3946 dlossQ:1.0100 exploreP:0.5676\n",
      "Episode:289 meanR:17.1600 R:14.0000 rate:0.0280 gloss:-81.0717 dlossA:0.3596 dlossQ:1.1470 exploreP:0.5668\n",
      "Episode:290 meanR:17.0900 R:14.0000 rate:0.0280 gloss:-92.9294 dlossA:0.3728 dlossQ:1.0544 exploreP:0.5660\n",
      "Episode:291 meanR:17.1100 R:13.0000 rate:0.0260 gloss:-79.9119 dlossA:0.3805 dlossQ:1.1884 exploreP:0.5653\n",
      "Episode:292 meanR:16.9800 R:12.0000 rate:0.0240 gloss:-90.7811 dlossA:0.4005 dlossQ:1.1353 exploreP:0.5646\n",
      "Episode:293 meanR:16.8100 R:12.0000 rate:0.0240 gloss:-79.6935 dlossA:0.3865 dlossQ:1.2104 exploreP:0.5640\n",
      "Episode:294 meanR:16.8200 R:12.0000 rate:0.0240 gloss:-74.7859 dlossA:0.3911 dlossQ:1.1147 exploreP:0.5633\n",
      "Episode:295 meanR:16.9400 R:22.0000 rate:0.0440 gloss:-89.0178 dlossA:0.3839 dlossQ:1.1282 exploreP:0.5621\n",
      "Episode:296 meanR:16.8500 R:11.0000 rate:0.0220 gloss:-77.8712 dlossA:0.3760 dlossQ:1.1728 exploreP:0.5615\n",
      "Episode:297 meanR:16.7800 R:14.0000 rate:0.0280 gloss:-82.0033 dlossA:0.3786 dlossQ:1.3048 exploreP:0.5607\n",
      "Episode:298 meanR:16.7000 R:10.0000 rate:0.0200 gloss:-87.5257 dlossA:0.3697 dlossQ:1.1619 exploreP:0.5602\n",
      "Episode:299 meanR:16.5900 R:15.0000 rate:0.0300 gloss:-80.2190 dlossA:0.4044 dlossQ:1.1604 exploreP:0.5593\n",
      "Episode:300 meanR:16.5000 R:12.0000 rate:0.0240 gloss:-96.7942 dlossA:0.3633 dlossQ:1.0906 exploreP:0.5587\n",
      "Episode:301 meanR:16.4200 R:10.0000 rate:0.0200 gloss:-107.1151 dlossA:0.4012 dlossQ:1.0779 exploreP:0.5581\n",
      "Episode:302 meanR:16.2800 R:11.0000 rate:0.0220 gloss:-87.7237 dlossA:0.3957 dlossQ:1.1555 exploreP:0.5575\n",
      "Episode:303 meanR:16.0100 R:10.0000 rate:0.0200 gloss:-81.0037 dlossA:0.3888 dlossQ:1.2338 exploreP:0.5570\n",
      "Episode:304 meanR:15.9300 R:11.0000 rate:0.0220 gloss:-83.6597 dlossA:0.4190 dlossQ:1.2996 exploreP:0.5564\n",
      "Episode:305 meanR:15.6500 R:10.0000 rate:0.0200 gloss:-85.2886 dlossA:0.3570 dlossQ:1.1788 exploreP:0.5558\n",
      "Episode:306 meanR:15.6400 R:13.0000 rate:0.0260 gloss:-105.5181 dlossA:0.3865 dlossQ:0.9782 exploreP:0.5551\n",
      "Episode:307 meanR:15.6500 R:9.0000 rate:0.0180 gloss:-90.9234 dlossA:0.3562 dlossQ:1.1519 exploreP:0.5546\n",
      "Episode:308 meanR:15.5800 R:12.0000 rate:0.0240 gloss:-89.3243 dlossA:0.4024 dlossQ:1.1929 exploreP:0.5540\n",
      "Episode:309 meanR:15.8700 R:43.0000 rate:0.0860 gloss:-100.6650 dlossA:0.3672 dlossQ:1.0844 exploreP:0.5516\n",
      "Episode:310 meanR:15.7800 R:10.0000 rate:0.0200 gloss:-110.2145 dlossA:0.4124 dlossQ:1.0534 exploreP:0.5511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:311 meanR:15.4500 R:15.0000 rate:0.0300 gloss:-84.7628 dlossA:0.3843 dlossQ:1.2521 exploreP:0.5503\n",
      "Episode:312 meanR:15.4000 R:9.0000 rate:0.0180 gloss:-108.0698 dlossA:0.3845 dlossQ:1.0447 exploreP:0.5498\n",
      "Episode:313 meanR:15.4100 R:21.0000 rate:0.0420 gloss:-98.4084 dlossA:0.3802 dlossQ:1.0837 exploreP:0.5487\n",
      "Episode:314 meanR:15.3200 R:10.0000 rate:0.0200 gloss:-103.8420 dlossA:0.3905 dlossQ:1.1084 exploreP:0.5481\n",
      "Episode:315 meanR:15.3100 R:11.0000 rate:0.0220 gloss:-92.6905 dlossA:0.3755 dlossQ:1.1951 exploreP:0.5475\n",
      "Episode:316 meanR:15.2900 R:12.0000 rate:0.0240 gloss:-116.3836 dlossA:0.3583 dlossQ:0.9997 exploreP:0.5469\n",
      "Episode:317 meanR:15.2800 R:17.0000 rate:0.0340 gloss:-107.8786 dlossA:0.3906 dlossQ:1.0831 exploreP:0.5460\n",
      "Episode:318 meanR:15.2700 R:16.0000 rate:0.0320 gloss:-110.5470 dlossA:0.3664 dlossQ:1.1351 exploreP:0.5451\n",
      "Episode:319 meanR:15.1700 R:9.0000 rate:0.0180 gloss:-108.2002 dlossA:0.3693 dlossQ:1.0966 exploreP:0.5446\n",
      "Episode:320 meanR:15.1600 R:15.0000 rate:0.0300 gloss:-129.0048 dlossA:0.3588 dlossQ:1.1749 exploreP:0.5438\n",
      "Episode:321 meanR:15.2200 R:16.0000 rate:0.0320 gloss:-114.0873 dlossA:0.3610 dlossQ:1.1343 exploreP:0.5430\n",
      "Episode:322 meanR:15.2400 R:12.0000 rate:0.0240 gloss:-117.5488 dlossA:0.3578 dlossQ:1.0725 exploreP:0.5424\n",
      "Episode:323 meanR:15.3200 R:20.0000 rate:0.0400 gloss:-113.6204 dlossA:0.3823 dlossQ:1.0976 exploreP:0.5413\n",
      "Episode:324 meanR:15.3100 R:10.0000 rate:0.0200 gloss:-111.1955 dlossA:0.3587 dlossQ:1.1075 exploreP:0.5408\n",
      "Episode:325 meanR:15.2800 R:11.0000 rate:0.0220 gloss:-116.6547 dlossA:0.3909 dlossQ:1.1120 exploreP:0.5402\n",
      "Episode:326 meanR:15.2900 R:11.0000 rate:0.0220 gloss:-106.1272 dlossA:0.4094 dlossQ:1.1607 exploreP:0.5396\n",
      "Episode:327 meanR:15.3400 R:21.0000 rate:0.0420 gloss:-96.8406 dlossA:0.3986 dlossQ:1.2767 exploreP:0.5385\n",
      "Episode:328 meanR:15.2800 R:13.0000 rate:0.0260 gloss:-111.0240 dlossA:0.4034 dlossQ:1.2263 exploreP:0.5378\n",
      "Episode:329 meanR:15.2300 R:9.0000 rate:0.0180 gloss:-97.1441 dlossA:0.3669 dlossQ:1.2305 exploreP:0.5373\n",
      "Episode:330 meanR:15.2500 R:17.0000 rate:0.0340 gloss:-129.2835 dlossA:0.3866 dlossQ:1.0357 exploreP:0.5364\n",
      "Episode:331 meanR:15.2500 R:13.0000 rate:0.0260 gloss:-126.4991 dlossA:0.3637 dlossQ:1.1185 exploreP:0.5357\n",
      "Episode:332 meanR:15.3000 R:15.0000 rate:0.0300 gloss:-113.2840 dlossA:0.3830 dlossQ:1.3476 exploreP:0.5350\n",
      "Episode:333 meanR:15.1900 R:9.0000 rate:0.0180 gloss:-124.2586 dlossA:0.3858 dlossQ:1.2350 exploreP:0.5345\n",
      "Episode:334 meanR:15.2500 R:18.0000 rate:0.0360 gloss:-130.6258 dlossA:0.3661 dlossQ:1.0414 exploreP:0.5335\n",
      "Episode:335 meanR:14.6800 R:10.0000 rate:0.0200 gloss:-130.2708 dlossA:0.3863 dlossQ:1.0857 exploreP:0.5330\n",
      "Episode:336 meanR:14.6100 R:8.0000 rate:0.0160 gloss:-129.0290 dlossA:0.3902 dlossQ:1.2131 exploreP:0.5326\n",
      "Episode:337 meanR:14.6300 R:13.0000 rate:0.0260 gloss:-108.2496 dlossA:0.3786 dlossQ:1.2288 exploreP:0.5319\n",
      "Episode:338 meanR:14.6500 R:16.0000 rate:0.0320 gloss:-133.6197 dlossA:0.3853 dlossQ:1.0617 exploreP:0.5311\n",
      "Episode:339 meanR:14.6100 R:10.0000 rate:0.0200 gloss:-115.4233 dlossA:0.3784 dlossQ:1.1026 exploreP:0.5306\n",
      "Episode:340 meanR:14.6500 R:14.0000 rate:0.0280 gloss:-119.5340 dlossA:0.4030 dlossQ:1.6580 exploreP:0.5298\n",
      "Episode:341 meanR:14.6000 R:12.0000 rate:0.0240 gloss:-88.5306 dlossA:0.4054 dlossQ:1.4513 exploreP:0.5292\n",
      "Episode:342 meanR:14.5900 R:13.0000 rate:0.0260 gloss:-143.7020 dlossA:0.3828 dlossQ:1.1096 exploreP:0.5285\n",
      "Episode:343 meanR:14.6400 R:14.0000 rate:0.0280 gloss:-136.7051 dlossA:0.3875 dlossQ:1.0632 exploreP:0.5278\n",
      "Episode:344 meanR:14.7100 R:19.0000 rate:0.0380 gloss:-129.7516 dlossA:0.3927 dlossQ:1.1676 exploreP:0.5268\n",
      "Episode:345 meanR:14.6600 R:10.0000 rate:0.0200 gloss:-122.9653 dlossA:0.3798 dlossQ:1.1190 exploreP:0.5263\n",
      "Episode:346 meanR:14.7000 R:18.0000 rate:0.0360 gloss:-144.7628 dlossA:0.3752 dlossQ:1.0519 exploreP:0.5254\n",
      "Episode:347 meanR:14.6800 R:9.0000 rate:0.0180 gloss:-127.0806 dlossA:0.3813 dlossQ:1.1650 exploreP:0.5249\n",
      "Episode:348 meanR:14.7800 R:22.0000 rate:0.0440 gloss:-138.3255 dlossA:0.3994 dlossQ:1.1613 exploreP:0.5238\n",
      "Episode:349 meanR:14.6800 R:9.0000 rate:0.0180 gloss:-87.0764 dlossA:0.3721 dlossQ:1.4489 exploreP:0.5233\n",
      "Episode:350 meanR:14.5600 R:10.0000 rate:0.0200 gloss:-171.5290 dlossA:0.3883 dlossQ:1.0162 exploreP:0.5228\n",
      "Episode:351 meanR:14.5700 R:13.0000 rate:0.0260 gloss:-130.6844 dlossA:0.3847 dlossQ:1.1893 exploreP:0.5221\n",
      "Episode:352 meanR:14.6000 R:12.0000 rate:0.0240 gloss:-131.2409 dlossA:0.3992 dlossQ:1.1710 exploreP:0.5215\n",
      "Episode:353 meanR:14.6400 R:14.0000 rate:0.0280 gloss:-143.6388 dlossA:0.3736 dlossQ:1.0640 exploreP:0.5208\n",
      "Episode:354 meanR:14.6400 R:10.0000 rate:0.0200 gloss:-144.0145 dlossA:0.3855 dlossQ:1.1493 exploreP:0.5203\n",
      "Episode:355 meanR:14.6400 R:10.0000 rate:0.0200 gloss:-149.3567 dlossA:0.3537 dlossQ:1.1090 exploreP:0.5198\n",
      "Episode:356 meanR:14.6200 R:10.0000 rate:0.0200 gloss:-150.9966 dlossA:0.4003 dlossQ:1.0278 exploreP:0.5193\n",
      "Episode:357 meanR:14.6500 R:15.0000 rate:0.0300 gloss:-129.6825 dlossA:0.3821 dlossQ:1.2060 exploreP:0.5185\n",
      "Episode:358 meanR:14.6700 R:12.0000 rate:0.0240 gloss:-150.4948 dlossA:0.3910 dlossQ:1.1227 exploreP:0.5179\n",
      "Episode:359 meanR:14.3600 R:21.0000 rate:0.0420 gloss:-143.6465 dlossA:0.3832 dlossQ:1.1693 exploreP:0.5168\n",
      "Episode:360 meanR:14.3400 R:12.0000 rate:0.0240 gloss:-160.4170 dlossA:0.3875 dlossQ:1.0632 exploreP:0.5162\n",
      "Episode:361 meanR:14.3900 R:17.0000 rate:0.0340 gloss:-151.7493 dlossA:0.3913 dlossQ:1.1201 exploreP:0.5154\n",
      "Episode:362 meanR:14.4000 R:11.0000 rate:0.0220 gloss:-127.3889 dlossA:0.3760 dlossQ:1.2469 exploreP:0.5148\n",
      "Episode:363 meanR:14.3400 R:11.0000 rate:0.0220 gloss:-168.8164 dlossA:0.3721 dlossQ:1.1015 exploreP:0.5143\n",
      "Episode:364 meanR:14.3300 R:11.0000 rate:0.0220 gloss:-152.3013 dlossA:0.3986 dlossQ:1.1042 exploreP:0.5137\n",
      "Episode:365 meanR:14.3300 R:13.0000 rate:0.0260 gloss:-137.4192 dlossA:0.3884 dlossQ:1.2257 exploreP:0.5131\n",
      "Episode:366 meanR:14.4100 R:17.0000 rate:0.0340 gloss:-172.2295 dlossA:0.3881 dlossQ:1.0361 exploreP:0.5122\n",
      "Episode:367 meanR:14.3400 R:18.0000 rate:0.0360 gloss:-128.2715 dlossA:0.4083 dlossQ:1.3089 exploreP:0.5113\n",
      "Episode:368 meanR:14.4100 R:16.0000 rate:0.0320 gloss:-170.3532 dlossA:0.3671 dlossQ:1.0521 exploreP:0.5105\n",
      "Episode:369 meanR:13.9800 R:8.0000 rate:0.0160 gloss:-140.1763 dlossA:0.3883 dlossQ:1.1641 exploreP:0.5101\n",
      "Episode:370 meanR:13.9900 R:18.0000 rate:0.0360 gloss:-153.2524 dlossA:0.3951 dlossQ:1.1301 exploreP:0.5092\n",
      "Episode:371 meanR:14.0000 R:10.0000 rate:0.0200 gloss:-174.3291 dlossA:0.3491 dlossQ:1.1098 exploreP:0.5087\n",
      "Episode:372 meanR:13.9800 R:10.0000 rate:0.0200 gloss:-194.1136 dlossA:0.3717 dlossQ:0.9924 exploreP:0.5082\n",
      "Episode:373 meanR:13.9000 R:9.0000 rate:0.0180 gloss:-150.5481 dlossA:0.3971 dlossQ:1.1395 exploreP:0.5078\n",
      "Episode:374 meanR:13.9000 R:12.0000 rate:0.0240 gloss:-137.5647 dlossA:0.3947 dlossQ:1.2547 exploreP:0.5072\n",
      "Episode:375 meanR:13.9100 R:14.0000 rate:0.0280 gloss:-151.1550 dlossA:0.3909 dlossQ:1.1633 exploreP:0.5065\n",
      "Episode:376 meanR:13.9300 R:13.0000 rate:0.0260 gloss:-174.2241 dlossA:0.3699 dlossQ:1.1111 exploreP:0.5058\n",
      "Episode:377 meanR:13.8700 R:27.0000 rate:0.0540 gloss:-161.1998 dlossA:0.3869 dlossQ:1.2063 exploreP:0.5045\n",
      "Episode:378 meanR:13.8300 R:9.0000 rate:0.0180 gloss:-192.4097 dlossA:0.4078 dlossQ:1.0147 exploreP:0.5040\n",
      "Episode:379 meanR:13.8500 R:15.0000 rate:0.0300 gloss:-150.0907 dlossA:0.3744 dlossQ:1.2200 exploreP:0.5033\n",
      "Episode:380 meanR:13.8700 R:18.0000 rate:0.0360 gloss:-185.7187 dlossA:0.3923 dlossQ:1.1542 exploreP:0.5024\n",
      "Episode:381 meanR:13.8300 R:12.0000 rate:0.0240 gloss:-181.3481 dlossA:0.3903 dlossQ:1.1736 exploreP:0.5018\n",
      "Episode:382 meanR:13.7900 R:9.0000 rate:0.0180 gloss:-200.3491 dlossA:0.3982 dlossQ:1.0112 exploreP:0.5014\n",
      "Episode:383 meanR:13.8000 R:24.0000 rate:0.0480 gloss:-163.0807 dlossA:0.3857 dlossQ:1.1439 exploreP:0.5002\n",
      "Episode:384 meanR:13.8300 R:13.0000 rate:0.0260 gloss:-173.8563 dlossA:0.3785 dlossQ:1.1566 exploreP:0.4996\n",
      "Episode:385 meanR:13.8500 R:16.0000 rate:0.0320 gloss:-197.2272 dlossA:0.3867 dlossQ:1.1802 exploreP:0.4988\n",
      "Episode:386 meanR:13.7200 R:23.0000 rate:0.0460 gloss:-156.2050 dlossA:0.4123 dlossQ:1.2286 exploreP:0.4977\n",
      "Episode:387 meanR:13.6900 R:16.0000 rate:0.0320 gloss:-180.6217 dlossA:0.4007 dlossQ:1.2121 exploreP:0.4969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:388 meanR:13.6800 R:12.0000 rate:0.0240 gloss:-156.0411 dlossA:0.3720 dlossQ:1.2696 exploreP:0.4963\n",
      "Episode:389 meanR:13.8000 R:26.0000 rate:0.0520 gloss:-216.8078 dlossA:0.3736 dlossQ:1.0648 exploreP:0.4950\n",
      "Episode:390 meanR:13.7700 R:11.0000 rate:0.0220 gloss:-179.1007 dlossA:0.3934 dlossQ:1.1467 exploreP:0.4945\n",
      "Episode:391 meanR:13.7500 R:11.0000 rate:0.0220 gloss:-170.4941 dlossA:0.4054 dlossQ:1.2980 exploreP:0.4940\n",
      "Episode:392 meanR:13.7300 R:10.0000 rate:0.0200 gloss:-168.9406 dlossA:0.4052 dlossQ:1.2060 exploreP:0.4935\n",
      "Episode:393 meanR:13.7400 R:13.0000 rate:0.0260 gloss:-170.6272 dlossA:0.3757 dlossQ:1.2887 exploreP:0.4928\n",
      "Episode:394 meanR:13.7200 R:10.0000 rate:0.0200 gloss:-209.1181 dlossA:0.3919 dlossQ:0.9866 exploreP:0.4924\n",
      "Episode:395 meanR:13.6100 R:11.0000 rate:0.0220 gloss:-182.5229 dlossA:0.3793 dlossQ:1.1203 exploreP:0.4918\n",
      "Episode:396 meanR:13.6400 R:14.0000 rate:0.0280 gloss:-191.5340 dlossA:0.3779 dlossQ:1.1921 exploreP:0.4912\n",
      "Episode:397 meanR:13.6500 R:15.0000 rate:0.0300 gloss:-172.7062 dlossA:0.3906 dlossQ:1.1992 exploreP:0.4904\n",
      "Episode:398 meanR:13.6500 R:10.0000 rate:0.0200 gloss:-225.7668 dlossA:0.3515 dlossQ:0.9797 exploreP:0.4900\n",
      "Episode:399 meanR:13.6100 R:11.0000 rate:0.0220 gloss:-238.1340 dlossA:0.3340 dlossQ:0.9832 exploreP:0.4894\n",
      "Episode:400 meanR:13.6300 R:14.0000 rate:0.0280 gloss:-202.4371 dlossA:0.3801 dlossQ:1.1066 exploreP:0.4888\n",
      "Episode:401 meanR:13.6600 R:13.0000 rate:0.0260 gloss:-206.4220 dlossA:0.3840 dlossQ:1.1286 exploreP:0.4881\n",
      "Episode:402 meanR:13.7200 R:17.0000 rate:0.0340 gloss:-208.8907 dlossA:0.3565 dlossQ:1.1104 exploreP:0.4873\n",
      "Episode:403 meanR:13.7700 R:15.0000 rate:0.0300 gloss:-217.2607 dlossA:0.3738 dlossQ:1.0669 exploreP:0.4866\n",
      "Episode:404 meanR:13.7800 R:12.0000 rate:0.0240 gloss:-216.4031 dlossA:0.3895 dlossQ:1.1136 exploreP:0.4860\n",
      "Episode:405 meanR:13.8000 R:12.0000 rate:0.0240 gloss:-214.3854 dlossA:0.3833 dlossQ:1.2056 exploreP:0.4855\n",
      "Episode:406 meanR:13.7800 R:11.0000 rate:0.0220 gloss:-173.2948 dlossA:0.3665 dlossQ:1.2401 exploreP:0.4849\n",
      "Episode:407 meanR:13.8000 R:11.0000 rate:0.0220 gloss:-235.5784 dlossA:0.4151 dlossQ:1.0317 exploreP:0.4844\n",
      "Episode:408 meanR:13.8000 R:12.0000 rate:0.0240 gloss:-183.4181 dlossA:0.3715 dlossQ:1.2355 exploreP:0.4839\n",
      "Episode:409 meanR:13.5200 R:15.0000 rate:0.0300 gloss:-214.1056 dlossA:0.3997 dlossQ:1.1456 exploreP:0.4831\n",
      "Episode:410 meanR:13.6700 R:25.0000 rate:0.0500 gloss:-190.7157 dlossA:0.3986 dlossQ:1.2015 exploreP:0.4820\n",
      "Episode:411 meanR:13.6300 R:11.0000 rate:0.0220 gloss:-240.9515 dlossA:0.3466 dlossQ:1.0793 exploreP:0.4814\n",
      "Episode:412 meanR:13.6900 R:15.0000 rate:0.0300 gloss:-240.0441 dlossA:0.3919 dlossQ:1.1130 exploreP:0.4807\n",
      "Episode:413 meanR:13.5700 R:9.0000 rate:0.0180 gloss:-223.5868 dlossA:0.3866 dlossQ:1.1446 exploreP:0.4803\n",
      "Episode:414 meanR:13.6200 R:15.0000 rate:0.0300 gloss:-210.9100 dlossA:0.3756 dlossQ:1.1746 exploreP:0.4796\n",
      "Episode:415 meanR:13.6600 R:15.0000 rate:0.0300 gloss:-219.9628 dlossA:0.3820 dlossQ:1.0777 exploreP:0.4789\n",
      "Episode:416 meanR:13.6500 R:11.0000 rate:0.0220 gloss:-244.4783 dlossA:0.3484 dlossQ:1.0761 exploreP:0.4784\n",
      "Episode:417 meanR:13.6100 R:13.0000 rate:0.0260 gloss:-257.8095 dlossA:0.3800 dlossQ:1.0061 exploreP:0.4778\n",
      "Episode:418 meanR:13.5600 R:11.0000 rate:0.0220 gloss:-208.0953 dlossA:0.4030 dlossQ:1.3029 exploreP:0.4773\n",
      "Episode:419 meanR:13.5700 R:10.0000 rate:0.0200 gloss:-213.2951 dlossA:0.4009 dlossQ:1.2063 exploreP:0.4768\n",
      "Episode:420 meanR:13.5200 R:10.0000 rate:0.0200 gloss:-246.2924 dlossA:0.3596 dlossQ:1.1553 exploreP:0.4763\n",
      "Episode:421 meanR:13.4500 R:9.0000 rate:0.0180 gloss:-272.7740 dlossA:0.3919 dlossQ:1.0588 exploreP:0.4759\n",
      "Episode:422 meanR:13.4600 R:13.0000 rate:0.0260 gloss:-223.7032 dlossA:0.3695 dlossQ:1.1909 exploreP:0.4753\n",
      "Episode:423 meanR:13.4100 R:15.0000 rate:0.0300 gloss:-240.8494 dlossA:0.4012 dlossQ:1.1388 exploreP:0.4746\n",
      "Episode:424 meanR:13.4600 R:15.0000 rate:0.0300 gloss:-208.1036 dlossA:0.4061 dlossQ:1.2453 exploreP:0.4739\n",
      "Episode:425 meanR:13.4700 R:12.0000 rate:0.0240 gloss:-236.2666 dlossA:0.3983 dlossQ:1.1112 exploreP:0.4734\n",
      "Episode:426 meanR:13.4700 R:11.0000 rate:0.0220 gloss:-223.3343 dlossA:0.3811 dlossQ:1.2037 exploreP:0.4729\n",
      "Episode:427 meanR:13.3800 R:12.0000 rate:0.0240 gloss:-271.0266 dlossA:0.3670 dlossQ:1.0395 exploreP:0.4723\n",
      "Episode:428 meanR:13.4100 R:16.0000 rate:0.0320 gloss:-235.0197 dlossA:0.3901 dlossQ:1.2021 exploreP:0.4716\n",
      "Episode:429 meanR:13.5100 R:19.0000 rate:0.0380 gloss:-264.9611 dlossA:0.3865 dlossQ:1.1138 exploreP:0.4707\n",
      "Episode:430 meanR:13.5000 R:16.0000 rate:0.0320 gloss:-209.8607 dlossA:0.4132 dlossQ:1.2780 exploreP:0.4699\n",
      "Episode:431 meanR:13.4600 R:9.0000 rate:0.0180 gloss:-223.8345 dlossA:0.3876 dlossQ:1.2306 exploreP:0.4695\n",
      "Episode:432 meanR:13.4300 R:12.0000 rate:0.0240 gloss:-276.5085 dlossA:0.3598 dlossQ:1.0801 exploreP:0.4690\n",
      "Episode:433 meanR:13.4500 R:11.0000 rate:0.0220 gloss:-258.9992 dlossA:0.3790 dlossQ:1.1285 exploreP:0.4685\n",
      "Episode:434 meanR:13.3600 R:9.0000 rate:0.0180 gloss:-202.3896 dlossA:0.4043 dlossQ:1.2707 exploreP:0.4681\n",
      "Episode:435 meanR:13.3900 R:13.0000 rate:0.0260 gloss:-315.9872 dlossA:0.3460 dlossQ:0.9625 exploreP:0.4675\n",
      "Episode:436 meanR:13.4800 R:17.0000 rate:0.0340 gloss:-268.5522 dlossA:0.3828 dlossQ:1.0993 exploreP:0.4667\n",
      "Episode:437 meanR:13.5000 R:15.0000 rate:0.0300 gloss:-254.7786 dlossA:0.3888 dlossQ:1.1718 exploreP:0.4660\n",
      "Episode:438 meanR:13.4500 R:11.0000 rate:0.0220 gloss:-271.1323 dlossA:0.3803 dlossQ:1.0969 exploreP:0.4655\n",
      "Episode:439 meanR:13.4400 R:9.0000 rate:0.0180 gloss:-240.9046 dlossA:0.3891 dlossQ:1.2083 exploreP:0.4651\n",
      "Episode:440 meanR:13.4500 R:15.0000 rate:0.0300 gloss:-242.3527 dlossA:0.4087 dlossQ:1.1954 exploreP:0.4644\n",
      "Episode:441 meanR:13.4400 R:11.0000 rate:0.0220 gloss:-244.3539 dlossA:0.3767 dlossQ:1.2341 exploreP:0.4639\n",
      "Episode:442 meanR:13.4300 R:12.0000 rate:0.0240 gloss:-315.9936 dlossA:0.4043 dlossQ:1.0558 exploreP:0.4634\n",
      "Episode:443 meanR:13.5600 R:27.0000 rate:0.0540 gloss:-274.1695 dlossA:0.3776 dlossQ:1.1588 exploreP:0.4621\n",
      "Episode:444 meanR:13.4900 R:12.0000 rate:0.0240 gloss:-283.6631 dlossA:0.3618 dlossQ:1.1232 exploreP:0.4616\n",
      "Episode:445 meanR:13.5000 R:11.0000 rate:0.0220 gloss:-319.8039 dlossA:0.4038 dlossQ:1.0627 exploreP:0.4611\n",
      "Episode:446 meanR:13.4100 R:9.0000 rate:0.0180 gloss:-169.3670 dlossA:0.3804 dlossQ:1.5882 exploreP:0.4607\n",
      "Episode:447 meanR:13.4500 R:13.0000 rate:0.0260 gloss:-310.8713 dlossA:0.4192 dlossQ:1.0335 exploreP:0.4601\n",
      "Episode:448 meanR:13.3600 R:13.0000 rate:0.0260 gloss:-255.5196 dlossA:0.3974 dlossQ:1.2261 exploreP:0.4595\n",
      "Episode:449 meanR:13.4500 R:18.0000 rate:0.0360 gloss:-255.4160 dlossA:0.3988 dlossQ:1.1999 exploreP:0.4587\n",
      "Episode:450 meanR:13.4800 R:13.0000 rate:0.0260 gloss:-303.2423 dlossA:0.3634 dlossQ:1.0284 exploreP:0.4581\n",
      "Episode:451 meanR:13.5000 R:15.0000 rate:0.0300 gloss:-291.5894 dlossA:0.3655 dlossQ:1.1381 exploreP:0.4575\n",
      "Episode:452 meanR:13.4600 R:8.0000 rate:0.0160 gloss:-312.0456 dlossA:0.3581 dlossQ:1.0557 exploreP:0.4571\n",
      "Episode:453 meanR:13.4400 R:12.0000 rate:0.0240 gloss:-296.1934 dlossA:0.3772 dlossQ:1.0927 exploreP:0.4566\n",
      "Episode:454 meanR:13.4600 R:12.0000 rate:0.0240 gloss:-271.0883 dlossA:0.4100 dlossQ:1.1823 exploreP:0.4560\n",
      "Episode:455 meanR:13.6300 R:27.0000 rate:0.0540 gloss:-274.0664 dlossA:0.3926 dlossQ:1.1640 exploreP:0.4548\n",
      "Episode:456 meanR:13.6300 R:10.0000 rate:0.0200 gloss:-233.1339 dlossA:0.4253 dlossQ:1.2552 exploreP:0.4544\n",
      "Episode:457 meanR:13.5800 R:10.0000 rate:0.0200 gloss:-240.1877 dlossA:0.3654 dlossQ:1.2937 exploreP:0.4539\n",
      "Episode:458 meanR:13.6300 R:17.0000 rate:0.0340 gloss:-338.6753 dlossA:0.3942 dlossQ:1.1081 exploreP:0.4532\n",
      "Episode:459 meanR:13.6000 R:18.0000 rate:0.0360 gloss:-277.9756 dlossA:0.3882 dlossQ:1.1726 exploreP:0.4524\n",
      "Episode:460 meanR:13.5900 R:11.0000 rate:0.0220 gloss:-362.0244 dlossA:0.3881 dlossQ:0.9556 exploreP:0.4519\n",
      "Episode:461 meanR:13.5200 R:10.0000 rate:0.0200 gloss:-245.4390 dlossA:0.3592 dlossQ:1.2542 exploreP:0.4515\n",
      "Episode:462 meanR:13.5200 R:11.0000 rate:0.0220 gloss:-407.3064 dlossA:0.3938 dlossQ:0.9598 exploreP:0.4510\n",
      "Episode:463 meanR:13.5300 R:12.0000 rate:0.0240 gloss:-246.8860 dlossA:0.3927 dlossQ:1.3200 exploreP:0.4505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:464 meanR:13.5500 R:13.0000 rate:0.0260 gloss:-252.3365 dlossA:0.3948 dlossQ:1.2115 exploreP:0.4499\n",
      "Episode:465 meanR:13.5600 R:14.0000 rate:0.0280 gloss:-333.5944 dlossA:0.3815 dlossQ:1.1246 exploreP:0.4493\n",
      "Episode:466 meanR:13.4900 R:10.0000 rate:0.0200 gloss:-248.8007 dlossA:0.4326 dlossQ:1.2985 exploreP:0.4488\n",
      "Episode:467 meanR:13.5000 R:19.0000 rate:0.0380 gloss:-289.3574 dlossA:0.4109 dlossQ:1.2089 exploreP:0.4480\n",
      "Episode:468 meanR:13.4500 R:11.0000 rate:0.0220 gloss:-310.4630 dlossA:0.3489 dlossQ:1.1285 exploreP:0.4475\n",
      "Episode:469 meanR:13.4600 R:9.0000 rate:0.0180 gloss:-376.6898 dlossA:0.3726 dlossQ:0.9862 exploreP:0.4471\n",
      "Episode:470 meanR:13.3800 R:10.0000 rate:0.0200 gloss:-291.8041 dlossA:0.3746 dlossQ:1.0923 exploreP:0.4467\n",
      "Episode:471 meanR:13.3800 R:10.0000 rate:0.0200 gloss:-331.9218 dlossA:0.4228 dlossQ:1.1515 exploreP:0.4462\n",
      "Episode:472 meanR:13.3700 R:9.0000 rate:0.0180 gloss:-271.7763 dlossA:0.3613 dlossQ:1.2978 exploreP:0.4459\n",
      "Episode:473 meanR:13.3700 R:9.0000 rate:0.0180 gloss:-427.8993 dlossA:0.3633 dlossQ:0.8790 exploreP:0.4455\n",
      "Episode:474 meanR:13.3400 R:9.0000 rate:0.0180 gloss:-310.4564 dlossA:0.3801 dlossQ:1.1462 exploreP:0.4451\n",
      "Episode:475 meanR:13.3000 R:10.0000 rate:0.0200 gloss:-319.1371 dlossA:0.3584 dlossQ:1.1543 exploreP:0.4446\n",
      "Episode:476 meanR:13.2800 R:11.0000 rate:0.0220 gloss:-392.6763 dlossA:0.3763 dlossQ:0.9875 exploreP:0.4442\n",
      "Episode:477 meanR:13.1000 R:9.0000 rate:0.0180 gloss:-266.8907 dlossA:0.3707 dlossQ:1.4454 exploreP:0.4438\n",
      "Episode:478 meanR:13.1100 R:10.0000 rate:0.0200 gloss:-367.9293 dlossA:0.3747 dlossQ:1.1041 exploreP:0.4433\n",
      "Episode:479 meanR:13.2100 R:25.0000 rate:0.0500 gloss:-379.5216 dlossA:0.3516 dlossQ:1.0769 exploreP:0.4423\n",
      "Episode:480 meanR:13.1200 R:9.0000 rate:0.0180 gloss:-395.1317 dlossA:0.3681 dlossQ:1.0107 exploreP:0.4419\n",
      "Episode:481 meanR:13.0900 R:9.0000 rate:0.0180 gloss:-340.7095 dlossA:0.3714 dlossQ:1.1607 exploreP:0.4415\n",
      "Episode:482 meanR:13.1300 R:13.0000 rate:0.0260 gloss:-310.6439 dlossA:0.4088 dlossQ:1.2172 exploreP:0.4409\n",
      "Episode:483 meanR:13.0000 R:11.0000 rate:0.0220 gloss:-308.3627 dlossA:0.4091 dlossQ:1.2149 exploreP:0.4404\n",
      "Episode:484 meanR:13.0000 R:13.0000 rate:0.0260 gloss:-321.5794 dlossA:0.3900 dlossQ:1.2691 exploreP:0.4399\n",
      "Episode:485 meanR:12.9700 R:13.0000 rate:0.0260 gloss:-403.5946 dlossA:0.3383 dlossQ:0.9821 exploreP:0.4393\n",
      "Episode:486 meanR:12.8900 R:15.0000 rate:0.0300 gloss:-333.9095 dlossA:0.3943 dlossQ:1.1830 exploreP:0.4387\n",
      "Episode:487 meanR:12.8300 R:10.0000 rate:0.0200 gloss:-404.8069 dlossA:0.3426 dlossQ:1.0425 exploreP:0.4382\n",
      "Episode:488 meanR:12.8100 R:10.0000 rate:0.0200 gloss:-291.8671 dlossA:0.4410 dlossQ:1.3390 exploreP:0.4378\n",
      "Episode:489 meanR:12.6800 R:13.0000 rate:0.0260 gloss:-407.0645 dlossA:0.3721 dlossQ:1.0452 exploreP:0.4373\n",
      "Episode:490 meanR:12.7800 R:21.0000 rate:0.0420 gloss:-354.2790 dlossA:0.3898 dlossQ:1.1732 exploreP:0.4364\n",
      "Episode:491 meanR:12.8100 R:14.0000 rate:0.0280 gloss:-380.2603 dlossA:0.3598 dlossQ:1.0793 exploreP:0.4358\n",
      "Episode:492 meanR:12.8700 R:16.0000 rate:0.0320 gloss:-409.7528 dlossA:0.3739 dlossQ:1.0270 exploreP:0.4351\n",
      "Episode:493 meanR:12.8800 R:14.0000 rate:0.0280 gloss:-355.4579 dlossA:0.3548 dlossQ:1.1560 exploreP:0.4345\n",
      "Episode:494 meanR:12.9000 R:12.0000 rate:0.0240 gloss:-450.5090 dlossA:0.3598 dlossQ:1.0447 exploreP:0.4340\n",
      "Episode:495 meanR:12.9300 R:14.0000 rate:0.0280 gloss:-366.6446 dlossA:0.3839 dlossQ:1.1548 exploreP:0.4334\n",
      "Episode:496 meanR:12.9200 R:13.0000 rate:0.0260 gloss:-397.8470 dlossA:0.3837 dlossQ:1.1005 exploreP:0.4328\n",
      "Episode:497 meanR:12.9000 R:13.0000 rate:0.0260 gloss:-377.4917 dlossA:0.3874 dlossQ:1.1332 exploreP:0.4323\n",
      "Episode:498 meanR:12.9400 R:14.0000 rate:0.0280 gloss:-349.5888 dlossA:0.4102 dlossQ:1.2342 exploreP:0.4317\n",
      "Episode:499 meanR:12.9500 R:12.0000 rate:0.0240 gloss:-370.0619 dlossA:0.3504 dlossQ:1.1846 exploreP:0.4312\n",
      "Episode:500 meanR:12.9100 R:10.0000 rate:0.0200 gloss:-427.7470 dlossA:0.4146 dlossQ:1.1037 exploreP:0.4308\n",
      "Episode:501 meanR:12.9100 R:13.0000 rate:0.0260 gloss:-340.5153 dlossA:0.3689 dlossQ:1.2730 exploreP:0.4302\n",
      "Episode:502 meanR:12.9100 R:17.0000 rate:0.0340 gloss:-353.2292 dlossA:0.4175 dlossQ:1.2094 exploreP:0.4295\n",
      "Episode:503 meanR:12.9000 R:14.0000 rate:0.0280 gloss:-309.5655 dlossA:0.3937 dlossQ:1.8130 exploreP:0.4289\n",
      "Episode:504 meanR:12.8700 R:9.0000 rate:0.0180 gloss:-317.1080 dlossA:0.4075 dlossQ:1.3166 exploreP:0.4286\n",
      "Episode:505 meanR:12.8900 R:14.0000 rate:0.0280 gloss:-355.4510 dlossA:0.4071 dlossQ:1.2604 exploreP:0.4280\n",
      "Episode:506 meanR:12.9100 R:13.0000 rate:0.0260 gloss:-390.8905 dlossA:0.3858 dlossQ:1.1320 exploreP:0.4274\n",
      "Episode:507 meanR:12.9100 R:11.0000 rate:0.0220 gloss:-335.3769 dlossA:0.4041 dlossQ:1.1967 exploreP:0.4270\n",
      "Episode:508 meanR:12.8900 R:10.0000 rate:0.0200 gloss:-357.0962 dlossA:0.4035 dlossQ:1.1745 exploreP:0.4265\n",
      "Episode:509 meanR:12.9100 R:17.0000 rate:0.0340 gloss:-419.2369 dlossA:0.3722 dlossQ:1.1046 exploreP:0.4258\n",
      "Episode:510 meanR:12.7700 R:11.0000 rate:0.0220 gloss:-402.9780 dlossA:0.3503 dlossQ:1.2213 exploreP:0.4254\n",
      "Episode:511 meanR:12.7900 R:13.0000 rate:0.0260 gloss:-426.2148 dlossA:0.3900 dlossQ:1.0654 exploreP:0.4248\n",
      "Episode:512 meanR:12.7300 R:9.0000 rate:0.0180 gloss:-412.1337 dlossA:0.3485 dlossQ:1.1472 exploreP:0.4245\n",
      "Episode:513 meanR:12.7500 R:11.0000 rate:0.0220 gloss:-452.1400 dlossA:0.3719 dlossQ:1.0793 exploreP:0.4240\n",
      "Episode:514 meanR:12.7200 R:12.0000 rate:0.0240 gloss:-454.2954 dlossA:0.3642 dlossQ:1.0403 exploreP:0.4235\n",
      "Episode:515 meanR:12.6900 R:12.0000 rate:0.0240 gloss:-444.9453 dlossA:0.3520 dlossQ:1.0862 exploreP:0.4230\n",
      "Episode:516 meanR:12.6700 R:9.0000 rate:0.0180 gloss:-427.9202 dlossA:0.3917 dlossQ:1.0776 exploreP:0.4227\n",
      "Episode:517 meanR:12.7100 R:17.0000 rate:0.0340 gloss:-357.2364 dlossA:0.4052 dlossQ:1.3059 exploreP:0.4220\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list = [] # goal\n",
    "rewards_list, gloss_list, dloss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    for ep in range(1111*2):\n",
    "        total_reward = 0 # each episode\n",
    "        gloss_batch, dlossA_batch, dlossQ_batch= [], [], []\n",
    "        state = env.reset() # each episode\n",
    "        num_step = 0 # each episode\n",
    "        idx_arr = np.arange(memory_size// batch_size)\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "                #print(action)\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits) # adding epsilon*noise\n",
    "                #print(action)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.rates.append(-1) # empty\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            # Rating the memory\n",
    "            if done is True:\n",
    "                rate = total_reward/500 # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.rates[-1-idx] == -1: # double-check the landmark/marked indexes\n",
    "                        memory.rates[-1-idx] = rate # rate the trajectory/data\n",
    "                        \n",
    "            # Training with the maxrated minibatch\n",
    "            batch = memory.buffer\n",
    "            percentage = 0.9\n",
    "            #for idx in range(memory_size// batch_size):\n",
    "            idx = np.random.choice(idx_arr)\n",
    "            states = np.array([each[0] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            actions = np.array([each[1] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            next_states = np.array([each[2] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rewards = np.array([each[3] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            dones = np.array([each[4] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rates = np.array(memory.rates)[idx*batch_size:(idx+1)*batch_size]\n",
    "            #print(states.shape, actions.shape, next_states.shape, rewards.shape, dones.shape, rates.shape)\n",
    "            states = states[rates >= (np.max(rates)*percentage)]\n",
    "            actions = actions[rates >= (np.max(rates)*percentage)]\n",
    "            next_states = next_states[rates >= (np.max(rates)*percentage)]\n",
    "            rewards = rewards[rates >= (np.max(rates)*percentage)]\n",
    "            dones = dones[rates >= (np.max(rates)*percentage)]\n",
    "            rates = rates[rates >= (np.max(rates)*percentage)]\n",
    "            #print(states.shape, actions.shape, next_states.shape, rewards.shape, dones.shape, rates.shape)\n",
    "            nextQs_logits = sess.run(model.Qs_logits, feed_dict = {model.states: next_states})\n",
    "            #nextQs = np.max(nextQs_logits, axis=1) * (1-dones) # DQN\n",
    "            nextQs = nextQs_logits.reshape([-1]) * (1-dones) # DPG\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            gloss, dlossA, dlossQ, _, _ = sess.run([model.g_loss, model.d_lossA, model.d_lossQ, \n",
    "                                                    model.g_opt, model.d_optA], #, model.d_optQ\n",
    "                                                   feed_dict = {model.states: states, \n",
    "                                                                model.actions: actions,\n",
    "                                                                model.targetQs: targetQs, \n",
    "                                                                model.rates: rates})\n",
    "            gloss_batch.append(gloss)\n",
    "            dlossA_batch.append(dlossA)\n",
    "            dlossQ_batch.append(dlossQ)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'gloss:{:.4f}'.format(np.mean(gloss_batch)),\n",
    "              'dlossA:{:.4f}'.format(np.mean(dlossA_batch)),\n",
    "              'dlossQ:{:.4f}'.format(np.mean(dlossQ_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        #gloss_list.append([ep, np.mean(gloss_batch)])\n",
    "        #dloss_list.append([ep, np.mean(dloss_batch)])\n",
    "        \n",
    "        # Break episode/epoch loop\n",
    "        ## Option 1: Solve the First Version\n",
    "        #The task is episodic, and in order to solve the environment, \n",
    "        #your agent must get an average score of +30 over 100 consecutive episodes.\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eps, arr = np.array(episode_rewards_list).T\n",
    "# smoothed_arr = running_mean(arr, 10)\n",
    "# plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "# plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(gloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(dloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print('total_reward: {}'.format(total_reward))\n",
    "                break\n",
    "                \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

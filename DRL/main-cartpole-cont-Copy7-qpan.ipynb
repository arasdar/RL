{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    #states = tf.placeholder(tf.float32, [None, *state_size], name='states')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    rates = tf.placeholder(tf.float32, [None], name='rates')\n",
    "    return states, actions, targetQs, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator/Controller: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(states, actions, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=action_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        nl1_fused = tf.concat(axis=1, values=[nl1, actions])\n",
    "        h2 = tf.layers.dense(inputs=nl1_fused, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "                \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return rewards logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, actions, targetQs, rates):\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                              labels=actions_labels)\n",
    "    targetQs = tf.reshape(targetQs, shape=[-1, 1])\n",
    "    glossP = tf.reduce_mean(neg_log_prob * targetQs) # DPG\n",
    "    gQs = discriminator(actions=actions_logits, hidden_size=hidden_size, states=states)\n",
    "    rates = tf.reshape(rates, shape=[-1, 1])\n",
    "    glossA = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                    labels=rates)) # 0-1\n",
    "    glossA += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                     labels=tf.nn.sigmoid(targetQs))) # 0-1\n",
    "    dQs = discriminator(actions=actions_labels, hidden_size=hidden_size, states=states, reuse=True)\n",
    "    dlossA = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs, # GAN\n",
    "                                                                    labels=rates)) # 0-1\n",
    "    dlossA += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs, # GAN\n",
    "                                                                     labels=tf.nn.sigmoid(targetQs))) # 0-1\n",
    "    dlossA += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gQs, # GAN\n",
    "                                                                     labels=tf.zeros_like(targetQs))) # 0-1\n",
    "    glossQ = tf.reduce_mean(tf.square(gQs - targetQs)) # DQN\n",
    "    dlossQ = tf.reduce_mean(tf.square(dQs - targetQs)) # DQN\n",
    "    return actions_logits, gQs, glossP, glossA, dlossA, glossQ, dlossQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(g_lossP, g_lossA, d_lossA, g_learning_rate, d_learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        g_optP = tf.train.AdamOptimizer(g_learning_rate).minimize(g_lossP, var_list=g_vars)\n",
    "        g_optA = tf.train.AdamOptimizer(g_learning_rate).minimize(g_lossA, var_list=g_vars)\n",
    "        d_optA = tf.train.AdamOptimizer(d_learning_rate).minimize(d_lossA, var_list=d_vars)\n",
    "    return g_optP, g_optA, d_optA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, g_learning_rate, d_learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, self.rates = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.Qs_logits, self.g_lossP, self.g_lossA, self.d_lossA, self.g_lossQ, self.d_lossQ = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs, rates=self.rates) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_optP, self.g_optA, self.d_optA = model_opt(g_lossP=self.g_lossP, \n",
    "                                                          g_lossA=self.g_lossA, \n",
    "                                                          d_lossA=self.d_lossA, \n",
    "                                                          g_learning_rate=g_learning_rate, \n",
    "                                                          d_learning_rate=d_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size) # data batch\n",
    "        self.rates = deque(maxlen=max_size) # rates\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), # ==  self.rates\n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx], [self.rates[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 4*2             # number of units in each Q-network hidden layer\n",
    "g_learning_rate = 1e-4         # Q-network learning rate\n",
    "d_learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e3)             # experience mini-batch size: 200/500 a successfull episode size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size,\n",
    "              g_learning_rate=g_learning_rate, d_learning_rate=d_learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "total_reward = 0\n",
    "num_step = 0\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    memory.rates.append(-1) # empty\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()\n",
    "        rate = total_reward/500\n",
    "        total_reward = 0 # reset\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.rates[-1-idx] == -1:\n",
    "                memory.rates[-1-idx] = rate\n",
    "        num_step = 0 # reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:15.0000 R:15.0000 rate:0.0300 glossP:0.7149 dlossA:2.1780 glossA:1.3908 glossQ:1.0005 dlossQ:0.6405 exploreP:0.9985\n",
      "Episode:1 meanR:18.0000 R:21.0000 rate:0.0420 glossP:0.7084 dlossA:2.1718 glossA:1.3898 glossQ:1.0005 dlossQ:0.6566 exploreP:0.9964\n",
      "Episode:2 meanR:17.3333 R:16.0000 rate:0.0320 glossP:0.6999 dlossA:2.1604 glossA:1.3889 glossQ:1.0007 dlossQ:0.6765 exploreP:0.9949\n",
      "Episode:3 meanR:17.7500 R:19.0000 rate:0.0380 glossP:0.7004 dlossA:2.1477 glossA:1.3871 glossQ:1.0000 dlossQ:0.6809 exploreP:0.9930\n",
      "Episode:4 meanR:17.2000 R:15.0000 rate:0.0300 glossP:0.6900 dlossA:2.1454 glossA:1.3861 glossQ:1.0009 dlossQ:0.6772 exploreP:0.9915\n",
      "Episode:5 meanR:20.1667 R:35.0000 rate:0.0700 glossP:0.6861 dlossA:2.1352 glossA:1.3853 glossQ:1.0011 dlossQ:0.7023 exploreP:0.9881\n",
      "Episode:6 meanR:20.7143 R:24.0000 rate:0.0480 glossP:0.6782 dlossA:2.1242 glossA:1.3835 glossQ:1.0014 dlossQ:0.7188 exploreP:0.9857\n",
      "Episode:7 meanR:19.3750 R:10.0000 rate:0.0200 glossP:0.6709 dlossA:2.1211 glossA:1.3825 glossQ:1.0016 dlossQ:0.7240 exploreP:0.9848\n",
      "Episode:8 meanR:20.3333 R:28.0000 rate:0.0560 glossP:0.6718 dlossA:2.1128 glossA:1.3822 glossQ:1.0018 dlossQ:0.7222 exploreP:0.9820\n",
      "Episode:9 meanR:22.6000 R:43.0000 rate:0.0860 glossP:0.6639 dlossA:2.1032 glossA:1.3810 glossQ:1.0022 dlossQ:0.7590 exploreP:0.9779\n",
      "Episode:10 meanR:25.5455 R:55.0000 rate:0.1100 glossP:0.6551 dlossA:2.0866 glossA:1.3793 glossQ:1.0028 dlossQ:0.7835 exploreP:0.9726\n",
      "Episode:11 meanR:26.2500 R:34.0000 rate:0.0680 glossP:0.6494 dlossA:2.0745 glossA:1.3782 glossQ:1.0036 dlossQ:0.8204 exploreP:0.9693\n",
      "Episode:12 meanR:25.4615 R:16.0000 rate:0.0320 glossP:0.6419 dlossA:2.0686 glossA:1.3766 glossQ:1.0037 dlossQ:0.8286 exploreP:0.9678\n",
      "Episode:13 meanR:24.7143 R:15.0000 rate:0.0300 glossP:0.6425 dlossA:2.0614 glossA:1.3754 glossQ:1.0041 dlossQ:0.8369 exploreP:0.9663\n",
      "Episode:14 meanR:25.2000 R:32.0000 rate:0.0640 glossP:0.6326 dlossA:2.0582 glossA:1.3760 glossQ:1.0045 dlossQ:0.8526 exploreP:0.9633\n",
      "Episode:15 meanR:24.9375 R:21.0000 rate:0.0420 glossP:0.6299 dlossA:2.0499 glossA:1.3744 glossQ:1.0050 dlossQ:0.8575 exploreP:0.9613\n",
      "Episode:16 meanR:25.4118 R:33.0000 rate:0.0660 glossP:0.6322 dlossA:2.0427 glossA:1.3718 glossQ:1.0092 dlossQ:0.8648 exploreP:0.9581\n",
      "Episode:17 meanR:24.9444 R:17.0000 rate:0.0340 glossP:0.6199 dlossA:2.0362 glossA:1.3720 glossQ:1.0057 dlossQ:0.8811 exploreP:0.9565\n",
      "Episode:18 meanR:24.4737 R:16.0000 rate:0.0320 glossP:0.6121 dlossA:2.0316 glossA:1.3725 glossQ:1.0059 dlossQ:0.8897 exploreP:0.9550\n",
      "Episode:19 meanR:23.8500 R:12.0000 rate:0.0240 glossP:0.6057 dlossA:2.0281 glossA:1.3689 glossQ:1.0070 dlossQ:0.8876 exploreP:0.9539\n",
      "Episode:20 meanR:24.3810 R:35.0000 rate:0.0700 glossP:0.6016 dlossA:2.0193 glossA:1.3685 glossQ:1.0094 dlossQ:0.8953 exploreP:0.9506\n",
      "Episode:21 meanR:24.3182 R:23.0000 rate:0.0460 glossP:0.5908 dlossA:2.0125 glossA:1.3685 glossQ:1.0079 dlossQ:0.8971 exploreP:0.9484\n",
      "Episode:22 meanR:24.1304 R:20.0000 rate:0.0400 glossP:0.5821 dlossA:2.0017 glossA:1.3625 glossQ:1.0099 dlossQ:0.8713 exploreP:0.9466\n",
      "Episode:23 meanR:24.8333 R:41.0000 rate:0.0820 glossP:0.5685 dlossA:1.9907 glossA:1.3626 glossQ:1.0108 dlossQ:0.8838 exploreP:0.9427\n",
      "Episode:24 meanR:24.4000 R:14.0000 rate:0.0280 glossP:0.5615 dlossA:1.9798 glossA:1.3583 glossQ:1.0120 dlossQ:0.8768 exploreP:0.9414\n",
      "Episode:25 meanR:24.1154 R:17.0000 rate:0.0340 glossP:0.5449 dlossA:1.9669 glossA:1.3542 glossQ:1.0130 dlossQ:0.8493 exploreP:0.9398\n",
      "Episode:26 meanR:23.8519 R:17.0000 rate:0.0340 glossP:0.5394 dlossA:1.9671 glossA:1.3598 glossQ:1.0144 dlossQ:0.8497 exploreP:0.9383\n",
      "Episode:27 meanR:23.6786 R:19.0000 rate:0.0380 glossP:0.5341 dlossA:1.9599 glossA:1.3575 glossQ:1.0132 dlossQ:0.8576 exploreP:0.9365\n",
      "Episode:28 meanR:23.2759 R:12.0000 rate:0.0240 glossP:0.5200 dlossA:1.9488 glossA:1.3533 glossQ:1.0150 dlossQ:0.8415 exploreP:0.9354\n",
      "Episode:29 meanR:23.7000 R:36.0000 rate:0.0720 glossP:0.4999 dlossA:1.9323 glossA:1.3484 glossQ:1.0175 dlossQ:0.8004 exploreP:0.9321\n",
      "Episode:30 meanR:23.7097 R:24.0000 rate:0.0480 glossP:0.4879 dlossA:1.9221 glossA:1.3484 glossQ:1.0185 dlossQ:0.7916 exploreP:0.9298\n",
      "Episode:31 meanR:23.4688 R:16.0000 rate:0.0320 glossP:0.4750 dlossA:1.9125 glossA:1.3466 glossQ:1.0198 dlossQ:0.7748 exploreP:0.9284\n",
      "Episode:32 meanR:23.3939 R:21.0000 rate:0.0420 glossP:0.4496 dlossA:1.8924 glossA:1.3420 glossQ:1.0305 dlossQ:0.7245 exploreP:0.9264\n",
      "Episode:33 meanR:23.1765 R:16.0000 rate:0.0320 glossP:0.4295 dlossA:1.8802 glossA:1.3359 glossQ:1.0248 dlossQ:0.6947 exploreP:0.9250\n",
      "Episode:34 meanR:23.4857 R:34.0000 rate:0.0680 glossP:0.4221 dlossA:1.8721 glossA:1.3345 glossQ:1.0234 dlossQ:0.6894 exploreP:0.9219\n",
      "Episode:35 meanR:23.4167 R:21.0000 rate:0.0420 glossP:0.3954 dlossA:1.8554 glossA:1.3332 glossQ:1.0243 dlossQ:0.6533 exploreP:0.9200\n",
      "Episode:36 meanR:23.3784 R:22.0000 rate:0.0440 glossP:0.3746 dlossA:1.8351 glossA:1.3233 glossQ:1.0384 dlossQ:0.6136 exploreP:0.9180\n",
      "Episode:37 meanR:23.7632 R:38.0000 rate:0.0760 glossP:0.3553 dlossA:1.8227 glossA:1.3229 glossQ:1.0326 dlossQ:0.5960 exploreP:0.9145\n",
      "Episode:38 meanR:23.6667 R:20.0000 rate:0.0400 glossP:0.3396 dlossA:1.8096 glossA:1.3190 glossQ:1.0352 dlossQ:0.5883 exploreP:0.9127\n",
      "Episode:39 meanR:23.5000 R:17.0000 rate:0.0340 glossP:0.3194 dlossA:1.7950 glossA:1.3159 glossQ:1.0376 dlossQ:0.5453 exploreP:0.9112\n",
      "Episode:40 meanR:24.2927 R:56.0000 rate:0.1120 glossP:0.3089 dlossA:1.7885 glossA:1.3167 glossQ:1.0367 dlossQ:0.5597 exploreP:0.9061\n",
      "Episode:41 meanR:24.5714 R:36.0000 rate:0.0720 glossP:0.2942 dlossA:1.7727 glossA:1.3090 glossQ:1.0424 dlossQ:0.5622 exploreP:0.9029\n",
      "Episode:42 meanR:24.6279 R:27.0000 rate:0.0540 glossP:0.2816 dlossA:1.7652 glossA:1.3120 glossQ:1.0407 dlossQ:0.5623 exploreP:0.9005\n",
      "Episode:43 meanR:24.4773 R:18.0000 rate:0.0360 glossP:0.2751 dlossA:1.7616 glossA:1.3123 glossQ:1.0439 dlossQ:0.5598 exploreP:0.8989\n",
      "Episode:44 meanR:24.8889 R:43.0000 rate:0.0860 glossP:0.2784 dlossA:1.7553 glossA:1.3076 glossQ:1.0613 dlossQ:0.5936 exploreP:0.8951\n",
      "Episode:45 meanR:24.5870 R:11.0000 rate:0.0220 glossP:0.2568 dlossA:1.7457 glossA:1.3049 glossQ:1.0334 dlossQ:0.5522 exploreP:0.8941\n",
      "Episode:46 meanR:24.3191 R:12.0000 rate:0.0240 glossP:0.2679 dlossA:1.7494 glossA:1.3059 glossQ:1.0390 dlossQ:0.5883 exploreP:0.8931\n",
      "Episode:47 meanR:24.3333 R:25.0000 rate:0.0500 glossP:0.2610 dlossA:1.7425 glossA:1.3031 glossQ:1.0453 dlossQ:0.5893 exploreP:0.8909\n",
      "Episode:48 meanR:24.1020 R:13.0000 rate:0.0260 glossP:0.2871 dlossA:1.7594 glossA:1.3095 glossQ:1.0405 dlossQ:0.6687 exploreP:0.8897\n",
      "Episode:49 meanR:24.3000 R:34.0000 rate:0.0680 glossP:0.2532 dlossA:1.7362 glossA:1.3025 glossQ:1.0427 dlossQ:0.6034 exploreP:0.8867\n",
      "Episode:50 meanR:24.2941 R:24.0000 rate:0.0480 glossP:0.2568 dlossA:1.7406 glossA:1.3094 glossQ:1.0410 dlossQ:0.6329 exploreP:0.8846\n",
      "Episode:51 meanR:24.5962 R:40.0000 rate:0.0800 glossP:0.2524 dlossA:1.7365 glossA:1.3070 glossQ:1.0420 dlossQ:0.6415 exploreP:0.8811\n",
      "Episode:52 meanR:24.4717 R:18.0000 rate:0.0360 glossP:0.2626 dlossA:1.7362 glossA:1.3095 glossQ:1.0809 dlossQ:0.6866 exploreP:0.8796\n",
      "Episode:53 meanR:24.4815 R:25.0000 rate:0.0500 glossP:0.2646 dlossA:1.7393 glossA:1.3054 glossQ:1.0455 dlossQ:0.7029 exploreP:0.8774\n",
      "Episode:54 meanR:24.2545 R:12.0000 rate:0.0240 glossP:0.2471 dlossA:1.7284 glossA:1.3020 glossQ:1.0446 dlossQ:0.6763 exploreP:0.8764\n",
      "Episode:55 meanR:24.3571 R:30.0000 rate:0.0600 glossP:0.2652 dlossA:1.7381 glossA:1.3069 glossQ:1.0443 dlossQ:0.7310 exploreP:0.8738\n",
      "Episode:56 meanR:24.5263 R:34.0000 rate:0.0680 glossP:0.2596 dlossA:1.7382 glossA:1.3095 glossQ:1.0423 dlossQ:0.7383 exploreP:0.8708\n",
      "Episode:57 meanR:24.3793 R:16.0000 rate:0.0320 glossP:0.2504 dlossA:1.7325 glossA:1.3081 glossQ:1.0451 dlossQ:0.7320 exploreP:0.8695\n",
      "Episode:58 meanR:24.4915 R:31.0000 rate:0.0620 glossP:0.2725 dlossA:1.7447 glossA:1.3122 glossQ:1.0416 dlossQ:0.8068 exploreP:0.8668\n",
      "Episode:59 meanR:24.3167 R:14.0000 rate:0.0280 glossP:0.2644 dlossA:1.7383 glossA:1.3080 glossQ:1.0419 dlossQ:0.7946 exploreP:0.8656\n",
      "Episode:60 meanR:24.4098 R:30.0000 rate:0.0600 glossP:0.2641 dlossA:1.7386 glossA:1.3090 glossQ:1.0429 dlossQ:0.8126 exploreP:0.8630\n",
      "Episode:61 meanR:24.3548 R:21.0000 rate:0.0420 glossP:0.2689 dlossA:1.7440 glossA:1.3131 glossQ:1.0502 dlossQ:0.8521 exploreP:0.8612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:62 meanR:25.0159 R:66.0000 rate:0.1320 glossP:0.2624 dlossA:1.7325 glossA:1.3050 glossQ:1.0455 dlossQ:0.8549 exploreP:0.8556\n",
      "Episode:63 meanR:24.9375 R:20.0000 rate:0.0400 glossP:0.2502 dlossA:1.7307 glossA:1.3096 glossQ:1.0411 dlossQ:0.8587 exploreP:0.8540\n",
      "Episode:64 meanR:25.5077 R:62.0000 rate:0.1240 glossP:0.2348 dlossA:1.7187 glossA:1.3058 glossQ:1.0428 dlossQ:0.8387 exploreP:0.8487\n",
      "Episode:65 meanR:25.2879 R:11.0000 rate:0.0220 glossP:0.2302 dlossA:1.7068 glossA:1.2972 glossQ:1.0508 dlossQ:0.8569 exploreP:0.8478\n",
      "Episode:66 meanR:25.1194 R:14.0000 rate:0.0280 glossP:0.2176 dlossA:1.6990 glossA:1.2944 glossQ:1.0446 dlossQ:0.8423 exploreP:0.8466\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list = [], []\n",
    "# gloss_list, dloss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    for ep in range(1111*3):\n",
    "        total_reward = 0 # each episode\n",
    "        glossP_batch, glossA_batch, dlossA_batch= [], [], []\n",
    "        glossQ_batch, dlossQ_batch= [], []\n",
    "        state = env.reset() # each episode\n",
    "        num_step = 0 # each episode\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.rates.append(-1) # empty\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            # Rating the memory\n",
    "            if done is True:\n",
    "                rate = total_reward/500 # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.rates[-1-idx] == -1: # double-check the landmark/marked indexes\n",
    "                        memory.rates[-1-idx] = rate # rate the trajectory/data\n",
    "                        \n",
    "            # Training with the maxrated minibatch\n",
    "            batch = memory.buffer\n",
    "            percentage = 0.9\n",
    "            #for idx in range(memory_size// batch_size):\n",
    "            idx_arr = np.arange(memory_size// batch_size)\n",
    "            idx = np.random.choice(idx_arr)\n",
    "            states = np.array([each[0] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            actions = np.array([each[1] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            next_states = np.array([each[2] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rewards = np.array([each[3] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            dones = np.array([each[4] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rates = np.array(memory.rates)[idx*batch_size:(idx+1)*batch_size]\n",
    "            #print(states.shape, actions.shape, next_states.shape, rewards.shape, dones.shape, rates.shape)\n",
    "            states = states[rates >= (np.max(rates)*percentage)]\n",
    "            actions = actions[rates >= (np.max(rates)*percentage)]\n",
    "            next_states = next_states[rates >= (np.max(rates)*percentage)]\n",
    "            rewards = rewards[rates >= (np.max(rates)*percentage)]\n",
    "            dones = dones[rates >= (np.max(rates)*percentage)]\n",
    "            rates = rates[rates >= (np.max(rates)*percentage)]\n",
    "            #print(states.shape, actions.shape, next_states.shape, rewards.shape, dones.shape, rates.shape)\n",
    "            nextQs_logits = sess.run(model.Qs_logits, feed_dict = {model.states: next_states})\n",
    "            #nextQs = np.max(nextQs_logits, axis=1) * (1-dones) # DQN\n",
    "            nextQs = nextQs_logits.reshape([-1]) * (1-dones) # DPG\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            dlossA, _, glossQ, dlossQ = sess.run([model.d_lossA, model.d_optA,\n",
    "                                                  model.g_lossQ, model.d_lossQ],\n",
    "                                                 feed_dict = {model.states: states, \n",
    "                                                              model.actions: actions,\n",
    "                                                              model.targetQs: targetQs, \n",
    "                                                              model.rates: rates})\n",
    "            glossA, _ = sess.run([model.g_lossA, model.g_optA], feed_dict = {model.states: states, \n",
    "                                                                             model.actions: actions,\n",
    "                                                                             model.targetQs: targetQs, \n",
    "                                                                             model.rates: rates})\n",
    "            glossP, _ = sess.run([model.g_lossP, model.g_optP], feed_dict = {model.states: states, \n",
    "                                                                             model.actions: actions,\n",
    "                                                                             model.targetQs: targetQs, \n",
    "                                                                             model.rates: rates})\n",
    "            glossP_batch.append(glossP)\n",
    "            dlossA_batch.append(dlossA)\n",
    "            glossA_batch.append(glossA)\n",
    "            glossQ_batch.append(glossQ)\n",
    "            dlossQ_batch.append(dlossQ)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'glossP:{:.4f}'.format(np.mean(glossP_batch)),\n",
    "              'dlossA:{:.4f}'.format(np.mean(dlossA_batch)),\n",
    "              'glossA:{:.4f}'.format(np.mean(glossA_batch)),\n",
    "              'glossQ:{:.4f}'.format(np.mean(glossQ_batch)),\n",
    "              'dlossQ:{:.4f}'.format(np.mean(dlossQ_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        #gloss_list.append([ep, np.mean(gloss_batch)])\n",
    "        #dloss_list.append([ep, np.mean(dloss_batch)])\n",
    "        \n",
    "        # Break episode/epoch loop\n",
    "        ## Option 1: Solve the First Version\n",
    "        #The task is episodic, and in order to solve the environment, \n",
    "        #your agent must get an average score of +30 over 100 consecutive episodes.\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(gloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(dloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print('total_reward: {}'.format(total_reward))\n",
    "                break\n",
    "                \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

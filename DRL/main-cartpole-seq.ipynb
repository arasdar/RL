{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential DQN\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.10.0\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, next_state, reward, done, info: [ 0.00848692 -0.01232851 -0.03539592  0.04655268] 0 [ 0.00824035 -0.2069255  -0.03446486  0.3278611 ] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.00824035 -0.2069255  -0.03446486  0.3278611 ] 1 [ 0.00410184 -0.01133027 -0.02790764  0.02451182] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.00410184 -0.01133027 -0.02790764  0.02451182] 1 [ 0.00387524  0.18418056 -0.02741741 -0.276844  ] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.00387524  0.18418056 -0.02741741 -0.276844  ] 0 [ 0.00755885 -0.01053973 -0.03295429  0.00706695] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.00755885 -0.01053973 -0.03295429  0.00706695] 1 [ 0.00734806  0.18503896 -0.03281295 -0.2958286 ] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.00734806  0.18503896 -0.03281295 -0.2958286 ] 1 [ 0.01104883  0.38061295 -0.03872952 -0.59867696] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.01104883  0.38061295 -0.03872952 -0.59867696] 1 [ 0.01866109  0.57625479 -0.05070306 -0.90330327] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.01866109  0.57625479 -0.05070306 -0.90330327] 1 [ 0.03018619  0.77202551 -0.06876912 -1.21148229] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.03018619  0.77202551 -0.06876912 -1.21148229] 1 [ 0.0456267   0.96796451 -0.09299877 -1.52489828] 1.0 False {}\n",
      "state, action, next_state, reward, done, info: [ 0.0456267   0.96796451 -0.09299877 -1.52489828] 1 [ 0.06498599  1.1640781  -0.12349673 -1.84509972] 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action) # take a random action\n",
    "    print('state, action, next_state, reward, done, info:', state, action, next_state, reward, done, info)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    # RNN\n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    return states, actions, targetQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, final_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)\n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx], [self.states[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state:', np.array(states).shape[1], \n",
    "#       'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "action_size = 2\n",
    "state_size = 4\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity - 1000 DQN\n",
    "batch_size = 128               # experience mini-batch size - 20 DQN\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:12.0000 R:12.0000 loss:0.8702 exploreP:0.9988\n",
      "Episode:1 meanR:32.0000 R:52.0000 loss:0.9405 exploreP:0.9937\n",
      "Episode:2 meanR:45.6667 R:73.0000 loss:1.3626 exploreP:0.9865\n",
      "Episode:3 meanR:42.7500 R:34.0000 loss:1.7622 exploreP:0.9832\n",
      "Episode:4 meanR:40.2000 R:30.0000 loss:1.7501 exploreP:0.9803\n",
      "Episode:5 meanR:40.0000 R:39.0000 loss:1.7121 exploreP:0.9765\n",
      "Episode:6 meanR:38.1429 R:27.0000 loss:1.8985 exploreP:0.9739\n",
      "Episode:7 meanR:37.3750 R:32.0000 loss:2.1310 exploreP:0.9708\n",
      "Episode:8 meanR:36.5556 R:30.0000 loss:2.4070 exploreP:0.9680\n",
      "Episode:9 meanR:35.2000 R:23.0000 loss:2.6545 exploreP:0.9658\n",
      "Episode:10 meanR:34.3636 R:26.0000 loss:2.9866 exploreP:0.9633\n",
      "Episode:11 meanR:33.0000 R:18.0000 loss:3.2750 exploreP:0.9616\n",
      "Episode:12 meanR:31.8462 R:18.0000 loss:3.5348 exploreP:0.9599\n",
      "Episode:13 meanR:30.9286 R:19.0000 loss:3.9222 exploreP:0.9580\n",
      "Episode:14 meanR:30.1333 R:19.0000 loss:4.1273 exploreP:0.9562\n",
      "Episode:15 meanR:29.3750 R:18.0000 loss:4.3936 exploreP:0.9545\n",
      "Episode:16 meanR:28.5294 R:15.0000 loss:4.8395 exploreP:0.9531\n",
      "Episode:17 meanR:27.8333 R:16.0000 loss:5.2882 exploreP:0.9516\n",
      "Episode:18 meanR:27.1579 R:15.0000 loss:5.5950 exploreP:0.9502\n",
      "Episode:19 meanR:26.5000 R:14.0000 loss:5.8755 exploreP:0.9489\n",
      "Episode:20 meanR:25.9524 R:15.0000 loss:6.0196 exploreP:0.9475\n",
      "Episode:21 meanR:25.4091 R:14.0000 loss:6.2211 exploreP:0.9462\n",
      "Episode:22 meanR:24.9130 R:14.0000 loss:6.4526 exploreP:0.9449\n",
      "Episode:23 meanR:24.4583 R:14.0000 loss:6.6291 exploreP:0.9436\n",
      "Episode:24 meanR:24.0000 R:13.0000 loss:6.5832 exploreP:0.9423\n",
      "Episode:25 meanR:23.6154 R:14.0000 loss:6.3271 exploreP:0.9410\n",
      "Episode:26 meanR:23.2963 R:15.0000 loss:6.1062 exploreP:0.9396\n",
      "Episode:27 meanR:23.0357 R:16.0000 loss:5.5260 exploreP:0.9382\n",
      "Episode:28 meanR:22.8966 R:19.0000 loss:16.0552 exploreP:0.9364\n",
      "Episode:29 meanR:23.2000 R:32.0000 loss:34.8518 exploreP:0.9334\n",
      "Episode:30 meanR:23.7419 R:40.0000 loss:15.8681 exploreP:0.9298\n",
      "Episode:31 meanR:23.9375 R:30.0000 loss:14.6386 exploreP:0.9270\n",
      "Episode:32 meanR:24.1515 R:31.0000 loss:8.4746 exploreP:0.9242\n",
      "Episode:33 meanR:24.5294 R:37.0000 loss:2.9875 exploreP:0.9208\n",
      "Episode:34 meanR:24.6000 R:27.0000 loss:3.2211 exploreP:0.9183\n",
      "Episode:35 meanR:24.9167 R:36.0000 loss:3.3322 exploreP:0.9151\n",
      "Episode:36 meanR:25.1622 R:34.0000 loss:3.3413 exploreP:0.9120\n",
      "Episode:37 meanR:25.2895 R:30.0000 loss:3.5353 exploreP:0.9093\n",
      "Episode:38 meanR:25.3846 R:29.0000 loss:3.6319 exploreP:0.9067\n",
      "Episode:39 meanR:25.3750 R:25.0000 loss:3.7262 exploreP:0.9044\n",
      "Episode:40 meanR:25.2927 R:22.0000 loss:4.0646 exploreP:0.9025\n",
      "Episode:41 meanR:25.2857 R:25.0000 loss:4.3827 exploreP:0.9003\n",
      "Episode:42 meanR:25.4419 R:32.0000 loss:4.4432 exploreP:0.8974\n",
      "Episode:43 meanR:25.5455 R:30.0000 loss:4.5112 exploreP:0.8947\n",
      "Episode:44 meanR:26.0000 R:46.0000 loss:4.2995 exploreP:0.8907\n",
      "Episode:45 meanR:26.2609 R:38.0000 loss:3.7943 exploreP:0.8873\n",
      "Episode:46 meanR:26.7234 R:48.0000 loss:3.6372 exploreP:0.8831\n",
      "Episode:47 meanR:27.0625 R:43.0000 loss:3.5189 exploreP:0.8794\n",
      "Episode:48 meanR:27.3265 R:40.0000 loss:3.6017 exploreP:0.8759\n",
      "Episode:49 meanR:27.9000 R:56.0000 loss:3.6380 exploreP:0.8711\n",
      "Episode:50 meanR:27.7843 R:22.0000 loss:4.0608 exploreP:0.8692\n",
      "Episode:51 meanR:27.5769 R:17.0000 loss:4.8568 exploreP:0.8677\n",
      "Episode:52 meanR:27.3208 R:14.0000 loss:5.3723 exploreP:0.8665\n",
      "Episode:53 meanR:27.0926 R:15.0000 loss:6.5176 exploreP:0.8653\n",
      "Episode:54 meanR:26.8909 R:16.0000 loss:6.9513 exploreP:0.8639\n",
      "Episode:55 meanR:26.6786 R:15.0000 loss:7.7800 exploreP:0.8626\n",
      "Episode:56 meanR:26.4561 R:14.0000 loss:8.9273 exploreP:0.8614\n",
      "Episode:57 meanR:26.2414 R:14.0000 loss:10.0552 exploreP:0.8602\n",
      "Episode:58 meanR:26.0508 R:15.0000 loss:10.1507 exploreP:0.8590\n",
      "Episode:59 meanR:25.9667 R:21.0000 loss:10.4013 exploreP:0.8572\n",
      "Episode:60 meanR:26.1639 R:38.0000 loss:9.1845 exploreP:0.8540\n",
      "Episode:61 meanR:26.4032 R:41.0000 loss:7.3532 exploreP:0.8505\n",
      "Episode:62 meanR:26.4603 R:30.0000 loss:5.9563 exploreP:0.8480\n",
      "Episode:63 meanR:26.3906 R:22.0000 loss:5.5741 exploreP:0.8461\n",
      "Episode:64 meanR:26.2462 R:17.0000 loss:5.8438 exploreP:0.8447\n",
      "Episode:65 meanR:26.0455 R:13.0000 loss:7.1337 exploreP:0.8436\n",
      "Episode:66 meanR:25.8955 R:16.0000 loss:7.6084 exploreP:0.8423\n",
      "Episode:67 meanR:25.7353 R:15.0000 loss:8.4210 exploreP:0.8411\n",
      "Episode:68 meanR:25.5652 R:14.0000 loss:9.6470 exploreP:0.8399\n",
      "Episode:69 meanR:25.4714 R:19.0000 loss:9.6283 exploreP:0.8383\n",
      "Episode:70 meanR:25.4507 R:24.0000 loss:9.9960 exploreP:0.8363\n",
      "Episode:71 meanR:25.6250 R:38.0000 loss:9.2862 exploreP:0.8332\n",
      "Episode:72 meanR:25.8904 R:45.0000 loss:7.2926 exploreP:0.8295\n",
      "Episode:73 meanR:25.9865 R:33.0000 loss:5.7013 exploreP:0.8268\n",
      "Episode:74 meanR:25.8667 R:17.0000 loss:5.9426 exploreP:0.8254\n",
      "Episode:75 meanR:25.7105 R:14.0000 loss:6.4497 exploreP:0.8243\n",
      "Episode:76 meanR:25.5584 R:14.0000 loss:7.8841 exploreP:0.8231\n",
      "Episode:77 meanR:25.3974 R:13.0000 loss:8.4605 exploreP:0.8221\n",
      "Episode:78 meanR:25.2405 R:13.0000 loss:9.2246 exploreP:0.8210\n",
      "Episode:79 meanR:25.1250 R:16.0000 loss:10.4628 exploreP:0.8197\n",
      "Episode:80 meanR:25.0247 R:17.0000 loss:10.9619 exploreP:0.8184\n",
      "Episode:81 meanR:24.9268 R:17.0000 loss:11.5132 exploreP:0.8170\n",
      "Episode:82 meanR:24.8434 R:18.0000 loss:11.9384 exploreP:0.8155\n",
      "Episode:83 meanR:24.7381 R:16.0000 loss:11.8390 exploreP:0.8142\n",
      "Episode:84 meanR:24.6000 R:13.0000 loss:11.7318 exploreP:0.8132\n",
      "Episode:85 meanR:24.4651 R:13.0000 loss:11.8426 exploreP:0.8122\n",
      "Episode:86 meanR:24.3448 R:14.0000 loss:11.8017 exploreP:0.8110\n",
      "Episode:87 meanR:24.2386 R:15.0000 loss:11.6965 exploreP:0.8098\n",
      "Episode:88 meanR:24.1124 R:13.0000 loss:11.8850 exploreP:0.8088\n",
      "Episode:89 meanR:23.9778 R:12.0000 loss:12.3040 exploreP:0.8078\n",
      "Episode:90 meanR:23.8462 R:12.0000 loss:12.5316 exploreP:0.8069\n",
      "Episode:91 meanR:23.7391 R:14.0000 loss:12.6343 exploreP:0.8058\n",
      "Episode:92 meanR:23.6452 R:15.0000 loss:12.7894 exploreP:0.8046\n",
      "Episode:93 meanR:23.5532 R:15.0000 loss:12.7658 exploreP:0.8034\n",
      "Episode:94 meanR:23.4737 R:16.0000 loss:12.4107 exploreP:0.8021\n",
      "Episode:95 meanR:23.3958 R:16.0000 loss:11.9242 exploreP:0.8008\n",
      "Episode:96 meanR:23.2990 R:14.0000 loss:11.8689 exploreP:0.7997\n",
      "Episode:97 meanR:23.2041 R:14.0000 loss:11.9233 exploreP:0.7986\n",
      "Episode:98 meanR:23.1313 R:16.0000 loss:11.6401 exploreP:0.7974\n",
      "Episode:99 meanR:23.0500 R:15.0000 loss:11.2995 exploreP:0.7962\n",
      "Episode:100 meanR:23.0700 R:14.0000 loss:11.2434 exploreP:0.7951\n",
      "Episode:101 meanR:22.7000 R:15.0000 loss:11.2297 exploreP:0.7939\n",
      "Episode:102 meanR:22.0900 R:12.0000 loss:11.4130 exploreP:0.7930\n",
      "Episode:103 meanR:21.8700 R:12.0000 loss:11.6825 exploreP:0.7920\n",
      "Episode:104 meanR:21.6700 R:10.0000 loss:11.8701 exploreP:0.7913\n",
      "Episode:105 meanR:21.4100 R:13.0000 loss:12.3080 exploreP:0.7902\n",
      "Episode:106 meanR:21.2400 R:10.0000 loss:12.5147 exploreP:0.7895\n",
      "Episode:107 meanR:21.0200 R:10.0000 loss:12.7240 exploreP:0.7887\n",
      "Episode:108 meanR:20.8400 R:12.0000 loss:12.7141 exploreP:0.7877\n",
      "Episode:109 meanR:20.7300 R:12.0000 loss:12.9768 exploreP:0.7868\n",
      "Episode:110 meanR:20.5700 R:10.0000 loss:13.2518 exploreP:0.7860\n",
      "Episode:111 meanR:20.5200 R:13.0000 loss:13.2018 exploreP:0.7850\n",
      "Episode:112 meanR:20.4500 R:11.0000 loss:13.2130 exploreP:0.7842\n",
      "Episode:113 meanR:20.3900 R:13.0000 loss:13.2020 exploreP:0.7832\n",
      "Episode:114 meanR:20.3200 R:12.0000 loss:12.9260 exploreP:0.7822\n",
      "Episode:115 meanR:20.2400 R:10.0000 loss:12.6930 exploreP:0.7815\n",
      "Episode:116 meanR:20.2000 R:11.0000 loss:12.2276 exploreP:0.7806\n",
      "Episode:117 meanR:20.1700 R:13.0000 loss:11.7995 exploreP:0.7796\n",
      "Episode:118 meanR:20.1500 R:13.0000 loss:10.8860 exploreP:0.7786\n",
      "Episode:119 meanR:20.1300 R:12.0000 loss:10.2831 exploreP:0.7777\n",
      "Episode:120 meanR:20.0800 R:10.0000 loss:10.1074 exploreP:0.7769\n",
      "Episode:121 meanR:20.0400 R:10.0000 loss:10.0798 exploreP:0.7762\n",
      "Episode:122 meanR:20.0200 R:12.0000 loss:9.9605 exploreP:0.7753\n",
      "Episode:123 meanR:19.9900 R:11.0000 loss:9.7807 exploreP:0.7744\n",
      "Episode:124 meanR:19.9800 R:12.0000 loss:9.4673 exploreP:0.7735\n",
      "Episode:125 meanR:19.9600 R:12.0000 loss:8.9243 exploreP:0.7726\n",
      "Episode:126 meanR:19.9100 R:10.0000 loss:8.2909 exploreP:0.7718\n",
      "Episode:127 meanR:19.8700 R:12.0000 loss:7.7241 exploreP:0.7709\n",
      "Episode:128 meanR:19.8100 R:13.0000 loss:7.4252 exploreP:0.7699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:129 meanR:19.6600 R:17.0000 loss:7.0923 exploreP:0.7686\n",
      "Episode:130 meanR:19.4000 R:14.0000 loss:6.9766 exploreP:0.7676\n",
      "Episode:131 meanR:19.2600 R:16.0000 loss:7.1571 exploreP:0.7664\n",
      "Episode:132 meanR:19.1300 R:18.0000 loss:7.1388 exploreP:0.7650\n",
      "Episode:133 meanR:18.9800 R:22.0000 loss:6.8797 exploreP:0.7633\n",
      "Episode:134 meanR:18.9000 R:19.0000 loss:6.4964 exploreP:0.7619\n",
      "Episode:135 meanR:18.7900 R:25.0000 loss:6.1994 exploreP:0.7600\n",
      "Episode:136 meanR:18.6800 R:23.0000 loss:6.5970 exploreP:0.7583\n",
      "Episode:137 meanR:18.6000 R:22.0000 loss:6.8233 exploreP:0.7567\n",
      "Episode:138 meanR:18.5200 R:21.0000 loss:7.2645 exploreP:0.7551\n",
      "Episode:139 meanR:18.5100 R:24.0000 loss:7.6009 exploreP:0.7533\n",
      "Episode:140 meanR:18.4800 R:19.0000 loss:7.9517 exploreP:0.7519\n",
      "Episode:141 meanR:18.4300 R:20.0000 loss:8.3710 exploreP:0.7504\n",
      "Episode:142 meanR:18.3900 R:28.0000 loss:7.8867 exploreP:0.7483\n",
      "Episode:143 meanR:18.3900 R:30.0000 loss:7.1859 exploreP:0.7461\n",
      "Episode:144 meanR:18.3400 R:41.0000 loss:7.0020 exploreP:0.7431\n",
      "Episode:145 meanR:18.3100 R:35.0000 loss:6.6469 exploreP:0.7406\n",
      "Episode:146 meanR:18.0500 R:22.0000 loss:6.9576 exploreP:0.7389\n",
      "Episode:147 meanR:17.8600 R:24.0000 loss:7.2708 exploreP:0.7372\n",
      "Episode:148 meanR:17.6600 R:20.0000 loss:7.9522 exploreP:0.7357\n",
      "Episode:149 meanR:17.2500 R:15.0000 loss:9.0983 exploreP:0.7347\n",
      "Episode:150 meanR:17.1900 R:16.0000 loss:10.1028 exploreP:0.7335\n",
      "Episode:151 meanR:17.2600 R:24.0000 loss:9.0820 exploreP:0.7318\n",
      "Episode:152 meanR:17.3000 R:18.0000 loss:8.8466 exploreP:0.7305\n",
      "Episode:153 meanR:17.4000 R:25.0000 loss:8.2692 exploreP:0.7287\n",
      "Episode:154 meanR:17.4300 R:19.0000 loss:8.1762 exploreP:0.7273\n",
      "Episode:155 meanR:17.5400 R:26.0000 loss:7.7294 exploreP:0.7254\n",
      "Episode:156 meanR:17.6100 R:21.0000 loss:7.6885 exploreP:0.7239\n",
      "Episode:157 meanR:17.7000 R:23.0000 loss:7.1824 exploreP:0.7223\n",
      "Episode:158 meanR:17.8500 R:30.0000 loss:7.2138 exploreP:0.7202\n",
      "Episode:159 meanR:17.9600 R:32.0000 loss:6.5356 exploreP:0.7179\n",
      "Episode:160 meanR:17.8900 R:31.0000 loss:6.3534 exploreP:0.7157\n",
      "Episode:161 meanR:17.7600 R:28.0000 loss:6.6665 exploreP:0.7137\n",
      "Episode:162 meanR:17.8000 R:34.0000 loss:6.9095 exploreP:0.7113\n",
      "Episode:163 meanR:17.9700 R:39.0000 loss:5.7043 exploreP:0.7086\n",
      "Episode:164 meanR:18.1700 R:37.0000 loss:5.9787 exploreP:0.7060\n",
      "Episode:165 meanR:18.3500 R:31.0000 loss:6.2673 exploreP:0.7039\n",
      "Episode:166 meanR:18.6400 R:45.0000 loss:7.1600 exploreP:0.7008\n",
      "Episode:167 meanR:19.0600 R:57.0000 loss:7.1622 exploreP:0.6968\n",
      "Episode:168 meanR:19.1300 R:21.0000 loss:7.5321 exploreP:0.6954\n",
      "Episode:169 meanR:19.1600 R:22.0000 loss:8.3338 exploreP:0.6939\n",
      "Episode:170 meanR:19.0700 R:15.0000 loss:10.3514 exploreP:0.6929\n",
      "Episode:171 meanR:18.8800 R:19.0000 loss:12.0470 exploreP:0.6916\n",
      "Episode:172 meanR:18.5900 R:16.0000 loss:12.9185 exploreP:0.6905\n",
      "Episode:173 meanR:18.4100 R:15.0000 loss:15.3201 exploreP:0.6895\n",
      "Episode:174 meanR:18.4000 R:16.0000 loss:17.6508 exploreP:0.6884\n",
      "Episode:175 meanR:18.4100 R:15.0000 loss:18.2623 exploreP:0.6874\n",
      "Episode:176 meanR:18.4200 R:15.0000 loss:18.7758 exploreP:0.6863\n",
      "Episode:177 meanR:18.4400 R:15.0000 loss:18.5295 exploreP:0.6853\n",
      "Episode:178 meanR:18.5500 R:24.0000 loss:32.0831 exploreP:0.6837\n",
      "Episode:179 meanR:18.6700 R:28.0000 loss:33.3211 exploreP:0.6818\n",
      "Episode:180 meanR:18.8800 R:38.0000 loss:34.7715 exploreP:0.6793\n",
      "Episode:181 meanR:19.0600 R:35.0000 loss:35.8935 exploreP:0.6769\n",
      "Episode:182 meanR:19.1900 R:31.0000 loss:29.9067 exploreP:0.6749\n",
      "Episode:183 meanR:19.4300 R:40.0000 loss:8.6062 exploreP:0.6722\n",
      "Episode:184 meanR:19.6000 R:30.0000 loss:8.9420 exploreP:0.6702\n",
      "Episode:185 meanR:19.8800 R:41.0000 loss:8.8595 exploreP:0.6675\n",
      "Episode:186 meanR:20.1500 R:41.0000 loss:8.5352 exploreP:0.6648\n",
      "Episode:187 meanR:20.4000 R:40.0000 loss:8.8139 exploreP:0.6622\n",
      "Episode:188 meanR:20.7100 R:44.0000 loss:8.5234 exploreP:0.6594\n",
      "Episode:189 meanR:21.2100 R:62.0000 loss:8.1166 exploreP:0.6554\n",
      "Episode:190 meanR:21.4800 R:39.0000 loss:7.9356 exploreP:0.6528\n",
      "Episode:191 meanR:21.6500 R:31.0000 loss:8.9454 exploreP:0.6509\n",
      "Episode:192 meanR:21.8500 R:35.0000 loss:9.2898 exploreP:0.6486\n",
      "Episode:193 meanR:22.0800 R:38.0000 loss:10.9268 exploreP:0.6462\n",
      "Episode:194 meanR:22.2800 R:36.0000 loss:8.3375 exploreP:0.6439\n",
      "Episode:195 meanR:22.5900 R:47.0000 loss:8.2680 exploreP:0.6409\n",
      "Episode:196 meanR:22.7700 R:32.0000 loss:8.4828 exploreP:0.6389\n",
      "Episode:197 meanR:23.1300 R:50.0000 loss:6.7485 exploreP:0.6358\n",
      "Episode:198 meanR:23.4000 R:43.0000 loss:6.8465 exploreP:0.6331\n",
      "Episode:199 meanR:23.7400 R:49.0000 loss:7.0004 exploreP:0.6301\n",
      "Episode:200 meanR:24.2600 R:66.0000 loss:7.0803 exploreP:0.6260\n",
      "Episode:201 meanR:24.3300 R:22.0000 loss:8.6691 exploreP:0.6246\n",
      "Episode:202 meanR:24.4800 R:27.0000 loss:10.4303 exploreP:0.6230\n",
      "Episode:203 meanR:24.5000 R:14.0000 loss:13.2483 exploreP:0.6221\n",
      "Episode:204 meanR:24.8500 R:45.0000 loss:9.4410 exploreP:0.6194\n",
      "Episode:205 meanR:25.3400 R:62.0000 loss:9.2355 exploreP:0.6156\n",
      "Episode:206 meanR:25.4500 R:21.0000 loss:9.6937 exploreP:0.6143\n",
      "Episode:207 meanR:25.6500 R:30.0000 loss:9.2649 exploreP:0.6125\n",
      "Episode:208 meanR:25.9700 R:44.0000 loss:7.9322 exploreP:0.6099\n",
      "Episode:209 meanR:26.0500 R:20.0000 loss:8.9457 exploreP:0.6087\n",
      "Episode:210 meanR:26.2900 R:34.0000 loss:9.4534 exploreP:0.6066\n",
      "Episode:211 meanR:26.9400 R:78.0000 loss:7.3824 exploreP:0.6020\n",
      "Episode:212 meanR:27.2300 R:40.0000 loss:7.2090 exploreP:0.5996\n",
      "Episode:213 meanR:27.5200 R:42.0000 loss:7.5572 exploreP:0.5972\n",
      "Episode:214 meanR:27.6200 R:22.0000 loss:10.5940 exploreP:0.5959\n",
      "Episode:215 meanR:28.3800 R:86.0000 loss:7.9792 exploreP:0.5909\n",
      "Episode:216 meanR:28.9500 R:68.0000 loss:6.3166 exploreP:0.5869\n",
      "Episode:217 meanR:29.2300 R:41.0000 loss:7.7896 exploreP:0.5846\n",
      "Episode:218 meanR:29.4400 R:34.0000 loss:10.3630 exploreP:0.5826\n",
      "Episode:219 meanR:29.6600 R:34.0000 loss:12.5320 exploreP:0.5807\n",
      "Episode:220 meanR:29.8000 R:24.0000 loss:15.9094 exploreP:0.5793\n",
      "Episode:221 meanR:29.9600 R:26.0000 loss:17.2058 exploreP:0.5778\n",
      "Episode:222 meanR:30.1000 R:26.0000 loss:18.6289 exploreP:0.5763\n",
      "Episode:223 meanR:30.2600 R:27.0000 loss:19.4776 exploreP:0.5748\n",
      "Episode:224 meanR:30.4000 R:26.0000 loss:20.2985 exploreP:0.5734\n",
      "Episode:225 meanR:30.5200 R:24.0000 loss:19.8842 exploreP:0.5720\n",
      "Episode:226 meanR:30.6500 R:23.0000 loss:19.2821 exploreP:0.5707\n",
      "Episode:227 meanR:30.7700 R:24.0000 loss:18.6110 exploreP:0.5694\n",
      "Episode:228 meanR:31.0400 R:40.0000 loss:17.2108 exploreP:0.5671\n",
      "Episode:229 meanR:31.2100 R:34.0000 loss:16.0784 exploreP:0.5652\n",
      "Episode:230 meanR:31.4000 R:33.0000 loss:15.8269 exploreP:0.5634\n",
      "Episode:231 meanR:31.5800 R:34.0000 loss:14.2798 exploreP:0.5615\n",
      "Episode:232 meanR:31.6800 R:28.0000 loss:15.9023 exploreP:0.5600\n",
      "Episode:233 meanR:31.8300 R:37.0000 loss:15.5630 exploreP:0.5580\n",
      "Episode:234 meanR:31.9200 R:28.0000 loss:15.6777 exploreP:0.5564\n",
      "Episode:235 meanR:32.0300 R:36.0000 loss:15.5635 exploreP:0.5545\n",
      "Episode:236 meanR:32.1700 R:37.0000 loss:14.2646 exploreP:0.5525\n",
      "Episode:237 meanR:32.2400 R:29.0000 loss:15.1569 exploreP:0.5509\n",
      "Episode:238 meanR:32.3400 R:31.0000 loss:14.7433 exploreP:0.5492\n",
      "Episode:239 meanR:32.4700 R:37.0000 loss:14.5773 exploreP:0.5472\n",
      "Episode:240 meanR:32.6000 R:32.0000 loss:15.0848 exploreP:0.5455\n",
      "Episode:241 meanR:32.7000 R:30.0000 loss:14.8550 exploreP:0.5439\n",
      "Episode:242 meanR:32.7000 R:28.0000 loss:14.9619 exploreP:0.5424\n",
      "Episode:243 meanR:32.7800 R:38.0000 loss:15.0062 exploreP:0.5404\n",
      "Episode:244 meanR:32.7400 R:37.0000 loss:14.5249 exploreP:0.5384\n",
      "Episode:245 meanR:33.0500 R:66.0000 loss:12.7853 exploreP:0.5350\n",
      "Episode:246 meanR:33.5300 R:70.0000 loss:10.4631 exploreP:0.5313\n",
      "Episode:247 meanR:33.7900 R:50.0000 loss:10.0747 exploreP:0.5287\n",
      "Episode:248 meanR:34.0600 R:47.0000 loss:10.9963 exploreP:0.5263\n",
      "Episode:249 meanR:34.2700 R:36.0000 loss:14.5546 exploreP:0.5244\n",
      "Episode:250 meanR:35.0100 R:90.0000 loss:12.8156 exploreP:0.5198\n",
      "Episode:251 meanR:34.9800 R:21.0000 loss:10.3542 exploreP:0.5187\n",
      "Episode:252 meanR:34.9400 R:14.0000 loss:13.9614 exploreP:0.5180\n",
      "Episode:253 meanR:35.6500 R:96.0000 loss:10.0424 exploreP:0.5132\n",
      "Episode:254 meanR:36.2400 R:78.0000 loss:8.0418 exploreP:0.5092\n",
      "Episode:255 meanR:36.2600 R:28.0000 loss:11.8367 exploreP:0.5079\n",
      "Episode:256 meanR:36.2700 R:22.0000 loss:17.2900 exploreP:0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:257 meanR:36.2400 R:20.0000 loss:18.1862 exploreP:0.5058\n",
      "Episode:258 meanR:36.3700 R:43.0000 loss:21.7344 exploreP:0.5036\n",
      "Episode:259 meanR:37.1200 R:107.0000 loss:39.5012 exploreP:0.4984\n",
      "Episode:260 meanR:38.0200 R:121.0000 loss:7.4086 exploreP:0.4925\n",
      "Episode:261 meanR:39.3800 R:164.0000 loss:5.2127 exploreP:0.4847\n",
      "Episode:262 meanR:41.1000 R:206.0000 loss:4.4917 exploreP:0.4750\n",
      "Episode:263 meanR:41.7500 R:104.0000 loss:6.6695 exploreP:0.4702\n",
      "Episode:264 meanR:42.2900 R:91.0000 loss:5.8990 exploreP:0.4660\n",
      "Episode:265 meanR:42.5000 R:52.0000 loss:4.2510 exploreP:0.4636\n",
      "Episode:266 meanR:42.3300 R:28.0000 loss:9.8185 exploreP:0.4624\n",
      "Episode:267 meanR:41.9400 R:18.0000 loss:16.9045 exploreP:0.4616\n",
      "Episode:268 meanR:41.8500 R:12.0000 loss:23.1944 exploreP:0.4610\n",
      "Episode:269 meanR:42.7200 R:109.0000 loss:14.8802 exploreP:0.4561\n",
      "Episode:270 meanR:43.4400 R:87.0000 loss:4.4321 exploreP:0.4523\n",
      "Episode:271 meanR:44.5500 R:130.0000 loss:3.4473 exploreP:0.4466\n",
      "Episode:272 meanR:45.1900 R:80.0000 loss:2.9617 exploreP:0.4431\n",
      "Episode:273 meanR:45.7600 R:72.0000 loss:4.7917 exploreP:0.4400\n",
      "Episode:274 meanR:46.2000 R:60.0000 loss:5.6948 exploreP:0.4374\n",
      "Episode:275 meanR:46.6600 R:61.0000 loss:5.8684 exploreP:0.4348\n",
      "Episode:276 meanR:47.9200 R:141.0000 loss:4.3886 exploreP:0.4288\n",
      "Episode:277 meanR:48.5000 R:73.0000 loss:9.2374 exploreP:0.4258\n",
      "Episode:278 meanR:49.7200 R:146.0000 loss:6.0487 exploreP:0.4198\n",
      "Episode:279 meanR:50.1300 R:69.0000 loss:3.0944 exploreP:0.4170\n",
      "Episode:280 meanR:50.9100 R:116.0000 loss:4.4002 exploreP:0.4123\n",
      "Episode:281 meanR:51.3100 R:75.0000 loss:10.8573 exploreP:0.4093\n",
      "Episode:282 meanR:51.5800 R:58.0000 loss:12.2366 exploreP:0.4069\n",
      "Episode:283 meanR:52.3600 R:118.0000 loss:10.9548 exploreP:0.4023\n",
      "Episode:284 meanR:52.5800 R:52.0000 loss:12.6066 exploreP:0.4003\n",
      "Episode:285 meanR:52.2600 R:9.0000 loss:14.5069 exploreP:0.3999\n",
      "Episode:286 meanR:51.9500 R:10.0000 loss:18.2550 exploreP:0.3995\n",
      "Episode:287 meanR:53.3700 R:182.0000 loss:9.6669 exploreP:0.3925\n",
      "Episode:288 meanR:55.0100 R:208.0000 loss:6.0180 exploreP:0.3846\n",
      "Episode:289 meanR:55.6600 R:127.0000 loss:9.0733 exploreP:0.3799\n",
      "Episode:290 meanR:55.5500 R:28.0000 loss:12.7910 exploreP:0.3789\n",
      "Episode:291 meanR:55.5000 R:26.0000 loss:23.9057 exploreP:0.3779\n",
      "Episode:292 meanR:55.3800 R:23.0000 loss:33.7206 exploreP:0.3771\n",
      "Episode:293 meanR:57.9400 R:294.0000 loss:6.0786 exploreP:0.3664\n",
      "Episode:294 meanR:59.4300 R:185.0000 loss:1.3758 exploreP:0.3599\n",
      "Episode:295 meanR:60.8700 R:191.0000 loss:1.0059 exploreP:0.3533\n",
      "Episode:296 meanR:60.8200 R:27.0000 loss:15.2665 exploreP:0.3523\n",
      "Episode:297 meanR:62.5300 R:221.0000 loss:10.7281 exploreP:0.3449\n",
      "Episode:298 meanR:63.6700 R:157.0000 loss:8.4483 exploreP:0.3396\n",
      "Episode:299 meanR:64.3000 R:112.0000 loss:3.6220 exploreP:0.3360\n",
      "Episode:300 meanR:64.0000 R:36.0000 loss:13.1410 exploreP:0.3348\n",
      "Episode:301 meanR:65.4200 R:164.0000 loss:14.3327 exploreP:0.3295\n",
      "Episode:302 meanR:65.4600 R:31.0000 loss:12.1719 exploreP:0.3285\n",
      "Episode:303 meanR:65.6000 R:28.0000 loss:18.5799 exploreP:0.3276\n",
      "Episode:304 meanR:66.2800 R:113.0000 loss:20.2385 exploreP:0.3241\n",
      "Episode:305 meanR:66.4800 R:82.0000 loss:11.4171 exploreP:0.3215\n",
      "Episode:306 meanR:67.3700 R:110.0000 loss:14.4182 exploreP:0.3181\n",
      "Episode:307 meanR:68.0200 R:95.0000 loss:15.2874 exploreP:0.3152\n",
      "Episode:308 meanR:69.3600 R:178.0000 loss:3.3077 exploreP:0.3098\n",
      "Episode:309 meanR:70.5700 R:141.0000 loss:17.2819 exploreP:0.3056\n",
      "Episode:310 meanR:72.8700 R:264.0000 loss:63.0926 exploreP:0.2979\n",
      "Episode:311 meanR:74.7300 R:264.0000 loss:112.2196 exploreP:0.2904\n",
      "Episode:312 meanR:76.1200 R:179.0000 loss:190.5271 exploreP:0.2854\n",
      "Episode:313 meanR:77.6200 R:192.0000 loss:234.4814 exploreP:0.2802\n",
      "Episode:314 meanR:82.4000 R:500.0000 loss:172.3251 exploreP:0.2670\n",
      "Episode:315 meanR:83.1900 R:165.0000 loss:4.7612 exploreP:0.2628\n",
      "Episode:316 meanR:83.4100 R:90.0000 loss:1.6349 exploreP:0.2605\n",
      "Episode:317 meanR:83.5600 R:56.0000 loss:1.2201 exploreP:0.2591\n",
      "Episode:318 meanR:83.6200 R:40.0000 loss:21.2062 exploreP:0.2581\n",
      "Episode:319 meanR:84.4000 R:112.0000 loss:24.2588 exploreP:0.2554\n",
      "Episode:320 meanR:85.1700 R:101.0000 loss:3.6203 exploreP:0.2529\n",
      "Episode:321 meanR:86.9700 R:206.0000 loss:0.7076 exploreP:0.2480\n",
      "Episode:322 meanR:88.5800 R:187.0000 loss:0.8403 exploreP:0.2436\n",
      "Episode:323 meanR:92.8400 R:453.0000 loss:0.7972 exploreP:0.2332\n",
      "Episode:324 meanR:93.9000 R:132.0000 loss:0.6286 exploreP:0.2303\n",
      "Episode:325 meanR:94.3600 R:70.0000 loss:12.0055 exploreP:0.2287\n",
      "Episode:326 meanR:97.5700 R:344.0000 loss:2.1335 exploreP:0.2213\n",
      "Episode:327 meanR:97.5600 R:23.0000 loss:12.8131 exploreP:0.2209\n",
      "Episode:328 meanR:97.4300 R:27.0000 loss:25.0914 exploreP:0.2203\n",
      "Episode:329 meanR:99.9300 R:284.0000 loss:49.5288 exploreP:0.2144\n",
      "Episode:330 meanR:100.8700 R:127.0000 loss:100.4337 exploreP:0.2118\n",
      "Episode:331 meanR:105.2200 R:469.0000 loss:1.6819 exploreP:0.2026\n",
      "Episode:332 meanR:106.0600 R:112.0000 loss:18.8759 exploreP:0.2004\n",
      "Episode:333 meanR:108.2700 R:258.0000 loss:1.9106 exploreP:0.1956\n",
      "Episode:334 meanR:109.3200 R:133.0000 loss:2.4421 exploreP:0.1931\n",
      "Episode:335 meanR:110.4900 R:153.0000 loss:24.8997 exploreP:0.1904\n",
      "Episode:336 meanR:111.1400 R:102.0000 loss:3.3471 exploreP:0.1885\n",
      "Episode:337 meanR:112.8900 R:204.0000 loss:1.9026 exploreP:0.1849\n",
      "Episode:338 meanR:115.1000 R:252.0000 loss:3.5941 exploreP:0.1806\n",
      "Episode:339 meanR:116.7600 R:203.0000 loss:4.5350 exploreP:0.1771\n",
      "Episode:340 meanR:121.4400 R:500.0000 loss:1.3837 exploreP:0.1690\n",
      "Episode:341 meanR:126.1400 R:500.0000 loss:0.6351 exploreP:0.1612\n",
      "Episode:342 meanR:127.0600 R:120.0000 loss:41.3794 exploreP:0.1594\n",
      "Episode:343 meanR:129.1000 R:242.0000 loss:2.5271 exploreP:0.1559\n",
      "Episode:344 meanR:133.7300 R:500.0000 loss:0.6431 exploreP:0.1487\n",
      "Episode:345 meanR:135.3500 R:228.0000 loss:25.8203 exploreP:0.1456\n",
      "Episode:346 meanR:138.0200 R:337.0000 loss:2.3428 exploreP:0.1411\n",
      "Episode:347 meanR:137.7600 R:24.0000 loss:44.6773 exploreP:0.1408\n",
      "Episode:348 meanR:138.5300 R:124.0000 loss:42.0601 exploreP:0.1392\n",
      "Episode:349 meanR:138.3900 R:22.0000 loss:53.6056 exploreP:0.1389\n",
      "Episode:350 meanR:139.4900 R:200.0000 loss:21.7678 exploreP:0.1364\n",
      "Episode:351 meanR:141.6800 R:240.0000 loss:1.0298 exploreP:0.1334\n",
      "Episode:352 meanR:144.9200 R:338.0000 loss:0.6766 exploreP:0.1293\n",
      "Episode:353 meanR:148.9600 R:500.0000 loss:0.7909 exploreP:0.1234\n",
      "Episode:354 meanR:149.6900 R:151.0000 loss:42.9005 exploreP:0.1217\n",
      "Episode:355 meanR:150.3500 R:94.0000 loss:5.8615 exploreP:0.1207\n",
      "Episode:356 meanR:155.1300 R:500.0000 loss:1.5907 exploreP:0.1153\n",
      "Episode:357 meanR:159.7000 R:477.0000 loss:3.1982 exploreP:0.1104\n",
      "Episode:358 meanR:164.2700 R:500.0000 loss:0.8810 exploreP:0.1055\n",
      "Episode:359 meanR:164.3800 R:118.0000 loss:54.0463 exploreP:0.1044\n",
      "Episode:360 meanR:168.1700 R:500.0000 loss:2.0291 exploreP:0.0998\n",
      "Episode:361 meanR:171.5300 R:500.0000 loss:13.5517 exploreP:0.0954\n",
      "Episode:362 meanR:174.4700 R:500.0000 loss:14.2171 exploreP:0.0912\n",
      "Episode:363 meanR:174.3600 R:93.0000 loss:55.5742 exploreP:0.0905\n",
      "Episode:364 meanR:176.5400 R:309.0000 loss:10.2529 exploreP:0.0880\n",
      "Episode:365 meanR:181.0200 R:500.0000 loss:2.8419 exploreP:0.0842\n",
      "Episode:366 meanR:185.7400 R:500.0000 loss:14.5984 exploreP:0.0806\n",
      "Episode:367 meanR:187.1900 R:163.0000 loss:45.2832 exploreP:0.0795\n",
      "Episode:368 meanR:192.0700 R:500.0000 loss:1.7826 exploreP:0.0761\n",
      "Episode:369 meanR:195.9800 R:500.0000 loss:2.5465 exploreP:0.0729\n",
      "Episode:370 meanR:200.1100 R:500.0000 loss:15.4317 exploreP:0.0698\n",
      "Episode:371 meanR:203.8100 R:500.0000 loss:15.3791 exploreP:0.0669\n",
      "Episode:372 meanR:208.0100 R:500.0000 loss:14.8099 exploreP:0.0641\n",
      "Episode:373 meanR:208.8500 R:156.0000 loss:49.3629 exploreP:0.0633\n",
      "Episode:374 meanR:213.2500 R:500.0000 loss:3.0943 exploreP:0.0607\n",
      "Episode:375 meanR:212.9400 R:30.0000 loss:63.8958 exploreP:0.0605\n",
      "Episode:376 meanR:211.7400 R:21.0000 loss:123.8176 exploreP:0.0604\n",
      "Episode:377 meanR:213.7400 R:273.0000 loss:44.8560 exploreP:0.0590\n",
      "Episode:378 meanR:217.2800 R:500.0000 loss:0.8383 exploreP:0.0567\n",
      "Episode:379 meanR:221.5900 R:500.0000 loss:5.3125 exploreP:0.0544\n",
      "Episode:380 meanR:225.4300 R:500.0000 loss:15.8165 exploreP:0.0522\n",
      "Episode:381 meanR:227.4800 R:280.0000 loss:28.0765 exploreP:0.0511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:382 meanR:231.9000 R:500.0000 loss:5.1639 exploreP:0.0490\n",
      "Episode:383 meanR:234.6800 R:396.0000 loss:19.9895 exploreP:0.0475\n",
      "Episode:384 meanR:239.1600 R:500.0000 loss:6.4433 exploreP:0.0457\n",
      "Episode:385 meanR:244.0700 R:500.0000 loss:16.0802 exploreP:0.0440\n",
      "Episode:386 meanR:246.6000 R:263.0000 loss:30.0700 exploreP:0.0431\n",
      "Episode:387 meanR:245.0700 R:29.0000 loss:63.2757 exploreP:0.0430\n",
      "Episode:388 meanR:244.1200 R:113.0000 loss:72.0559 exploreP:0.0426\n",
      "Episode:389 meanR:247.8500 R:500.0000 loss:8.8695 exploreP:0.0410\n",
      "Episode:390 meanR:252.5700 R:500.0000 loss:15.3101 exploreP:0.0395\n",
      "Episode:391 meanR:255.9900 R:368.0000 loss:23.0226 exploreP:0.0384\n",
      "Episode:392 meanR:260.7600 R:500.0000 loss:7.4707 exploreP:0.0371\n",
      "Episode:393 meanR:262.8200 R:500.0000 loss:15.5268 exploreP:0.0357\n",
      "Episode:394 meanR:262.5500 R:158.0000 loss:47.0453 exploreP:0.0353\n",
      "Episode:395 meanR:265.6400 R:500.0000 loss:4.0197 exploreP:0.0341\n",
      "Episode:396 meanR:266.4600 R:109.0000 loss:61.5701 exploreP:0.0338\n",
      "Episode:397 meanR:264.5400 R:29.0000 loss:52.1844 exploreP:0.0338\n",
      "Episode:398 meanR:267.9700 R:500.0000 loss:13.7701 exploreP:0.0326\n",
      "Episode:399 meanR:271.4100 R:456.0000 loss:15.5682 exploreP:0.0316\n",
      "Episode:400 meanR:272.2900 R:124.0000 loss:9.9203 exploreP:0.0313\n",
      "Episode:401 meanR:272.5500 R:190.0000 loss:4.9188 exploreP:0.0309\n",
      "Episode:402 meanR:273.6200 R:138.0000 loss:11.8843 exploreP:0.0306\n",
      "Episode:403 meanR:276.5400 R:320.0000 loss:3.3424 exploreP:0.0300\n",
      "Episode:404 meanR:280.4100 R:500.0000 loss:5.3073 exploreP:0.0290\n",
      "Episode:405 meanR:284.5900 R:500.0000 loss:15.5935 exploreP:0.0281\n",
      "Episode:406 meanR:288.4900 R:500.0000 loss:15.5390 exploreP:0.0272\n",
      "Episode:407 meanR:292.5400 R:500.0000 loss:16.2365 exploreP:0.0264\n",
      "Episode:408 meanR:295.7600 R:500.0000 loss:15.1935 exploreP:0.0256\n",
      "Episode:409 meanR:299.3500 R:500.0000 loss:14.9264 exploreP:0.0248\n",
      "Episode:410 meanR:298.0000 R:129.0000 loss:59.4281 exploreP:0.0246\n",
      "Episode:411 meanR:300.3600 R:500.0000 loss:0.8769 exploreP:0.0239\n",
      "Episode:412 meanR:303.5700 R:500.0000 loss:15.5753 exploreP:0.0232\n",
      "Episode:413 meanR:306.6500 R:500.0000 loss:15.4167 exploreP:0.0226\n",
      "Episode:414 meanR:306.6500 R:500.0000 loss:15.0768 exploreP:0.0220\n",
      "Episode:415 meanR:307.7800 R:278.0000 loss:29.7155 exploreP:0.0216\n",
      "Episode:416 meanR:311.8800 R:500.0000 loss:5.0465 exploreP:0.0211\n",
      "Episode:417 meanR:312.7600 R:144.0000 loss:56.6707 exploreP:0.0209\n",
      "Episode:418 meanR:317.3600 R:500.0000 loss:0.6765 exploreP:0.0204\n",
      "Episode:419 meanR:321.2400 R:500.0000 loss:16.1368 exploreP:0.0199\n",
      "Episode:420 meanR:325.2300 R:500.0000 loss:9.4396 exploreP:0.0194\n",
      "Episode:421 meanR:324.8100 R:164.0000 loss:4.9022 exploreP:0.0192\n",
      "Episode:422 meanR:327.9400 R:500.0000 loss:0.9653 exploreP:0.0188\n",
      "Episode:423 meanR:328.4100 R:500.0000 loss:14.5593 exploreP:0.0184\n",
      "Episode:424 meanR:332.0900 R:500.0000 loss:16.5796 exploreP:0.0180\n",
      "Episode:425 meanR:333.2500 R:186.0000 loss:43.5610 exploreP:0.0178\n",
      "Episode:426 meanR:334.8100 R:500.0000 loss:1.1933 exploreP:0.0174\n",
      "Episode:427 meanR:339.5800 R:500.0000 loss:16.3915 exploreP:0.0171\n",
      "Episode:428 meanR:344.3100 R:500.0000 loss:8.0710 exploreP:0.0167\n",
      "Episode:429 meanR:346.4700 R:500.0000 loss:12.4438 exploreP:0.0164\n",
      "Episode:430 meanR:350.2000 R:500.0000 loss:16.6366 exploreP:0.0161\n",
      "Episode:431 meanR:350.5100 R:500.0000 loss:15.7423 exploreP:0.0158\n",
      "Episode:432 meanR:354.3900 R:500.0000 loss:9.2867 exploreP:0.0155\n",
      "Episode:433 meanR:356.7800 R:497.0000 loss:9.5478 exploreP:0.0152\n",
      "Episode:434 meanR:360.4500 R:500.0000 loss:0.8499 exploreP:0.0150\n",
      "Episode:435 meanR:363.9200 R:500.0000 loss:9.3082 exploreP:0.0147\n",
      "Episode:436 meanR:367.9000 R:500.0000 loss:10.0006 exploreP:0.0145\n",
      "Episode:437 meanR:370.8600 R:500.0000 loss:1.0487 exploreP:0.0143\n",
      "Episode:438 meanR:373.3400 R:500.0000 loss:18.5015 exploreP:0.0141\n",
      "Episode:439 meanR:376.3100 R:500.0000 loss:17.9978 exploreP:0.0139\n",
      "Episode:440 meanR:373.7100 R:240.0000 loss:27.8784 exploreP:0.0138\n",
      "Episode:441 meanR:373.7100 R:500.0000 loss:0.9084 exploreP:0.0136\n",
      "Episode:442 meanR:377.5100 R:500.0000 loss:7.2711 exploreP:0.0134\n",
      "Episode:443 meanR:380.0900 R:500.0000 loss:14.6007 exploreP:0.0133\n",
      "Episode:444 meanR:380.0900 R:500.0000 loss:10.6582 exploreP:0.0131\n",
      "Episode:445 meanR:382.8100 R:500.0000 loss:16.0611 exploreP:0.0129\n",
      "Episode:446 meanR:384.4400 R:500.0000 loss:14.2520 exploreP:0.0128\n",
      "Episode:447 meanR:388.0500 R:385.0000 loss:21.4933 exploreP:0.0127\n",
      "Episode:448 meanR:391.1500 R:434.0000 loss:1.7410 exploreP:0.0126\n",
      "Episode:449 meanR:395.9300 R:500.0000 loss:0.6033 exploreP:0.0125\n",
      "Episode:450 meanR:398.9300 R:500.0000 loss:14.7502 exploreP:0.0123\n",
      "Episode:451 meanR:401.5300 R:500.0000 loss:19.2549 exploreP:0.0122\n",
      "Episode:452 meanR:400.1400 R:199.0000 loss:47.0313 exploreP:0.0122\n",
      "Episode:453 meanR:400.1400 R:500.0000 loss:1.3323 exploreP:0.0121\n",
      "Episode:454 meanR:403.6300 R:500.0000 loss:16.9271 exploreP:0.0120\n",
      "Episode:455 meanR:407.6900 R:500.0000 loss:17.8833 exploreP:0.0119\n",
      "Episode:456 meanR:407.6900 R:500.0000 loss:16.9995 exploreP:0.0118\n",
      "Episode:457 meanR:407.9200 R:500.0000 loss:13.2719 exploreP:0.0117\n",
      "Episode:458 meanR:407.9200 R:500.0000 loss:17.5656 exploreP:0.0116\n",
      "Episode:459 meanR:411.7400 R:500.0000 loss:15.4292 exploreP:0.0115\n",
      "Episode:460 meanR:411.7400 R:500.0000 loss:15.5350 exploreP:0.0115\n",
      "Episode:461 meanR:411.7400 R:500.0000 loss:17.0413 exploreP:0.0114\n",
      "Episode:462 meanR:411.7400 R:500.0000 loss:16.6924 exploreP:0.0113\n",
      "Episode:463 meanR:415.8100 R:500.0000 loss:16.1976 exploreP:0.0113\n",
      "Episode:464 meanR:414.7100 R:199.0000 loss:37.5259 exploreP:0.0112\n",
      "Episode:465 meanR:410.7700 R:106.0000 loss:7.6089 exploreP:0.0112\n",
      "Episode:466 meanR:408.8400 R:307.0000 loss:11.4253 exploreP:0.0112\n",
      "Episode:467 meanR:412.2100 R:500.0000 loss:7.9398 exploreP:0.0111\n",
      "Episode:468 meanR:412.2100 R:500.0000 loss:18.6940 exploreP:0.0111\n",
      "Episode:469 meanR:412.2100 R:500.0000 loss:17.1730 exploreP:0.0110\n",
      "Episode:470 meanR:412.2100 R:500.0000 loss:17.5461 exploreP:0.0110\n",
      "Episode:471 meanR:412.2100 R:500.0000 loss:17.0247 exploreP:0.0109\n",
      "Episode:472 meanR:411.2900 R:408.0000 loss:19.2373 exploreP:0.0109\n",
      "Episode:473 meanR:414.7300 R:500.0000 loss:4.7527 exploreP:0.0108\n",
      "Episode:474 meanR:414.7300 R:500.0000 loss:8.7105 exploreP:0.0108\n",
      "Episode:475 meanR:419.4300 R:500.0000 loss:17.6150 exploreP:0.0108\n",
      "Episode:476 meanR:424.0200 R:480.0000 loss:16.8347 exploreP:0.0107\n",
      "Episode:477 meanR:426.2900 R:500.0000 loss:6.8485 exploreP:0.0107\n",
      "Episode:478 meanR:426.2900 R:500.0000 loss:10.0981 exploreP:0.0107\n",
      "Episode:479 meanR:426.2900 R:500.0000 loss:11.9191 exploreP:0.0106\n",
      "Episode:480 meanR:421.4200 R:13.0000 loss:51.8871 exploreP:0.0106\n",
      "Episode:481 meanR:423.6200 R:500.0000 loss:23.4536 exploreP:0.0106\n",
      "Episode:482 meanR:423.6200 R:500.0000 loss:13.4097 exploreP:0.0106\n",
      "Episode:483 meanR:424.6600 R:500.0000 loss:2.0536 exploreP:0.0105\n",
      "Episode:484 meanR:424.6600 R:500.0000 loss:5.9438 exploreP:0.0105\n",
      "Episode:485 meanR:424.0800 R:442.0000 loss:7.9451 exploreP:0.0105\n",
      "Episode:486 meanR:426.4500 R:500.0000 loss:1.2350 exploreP:0.0105\n",
      "Episode:487 meanR:431.1600 R:500.0000 loss:14.0001 exploreP:0.0104\n",
      "Episode:488 meanR:435.0300 R:500.0000 loss:19.3909 exploreP:0.0104\n",
      "Episode:489 meanR:435.0300 R:500.0000 loss:19.2416 exploreP:0.0104\n",
      "Episode:490 meanR:435.0300 R:500.0000 loss:18.4548 exploreP:0.0104\n",
      "Episode:491 meanR:436.3500 R:500.0000 loss:12.5793 exploreP:0.0104\n",
      "Episode:492 meanR:436.3500 R:500.0000 loss:11.8192 exploreP:0.0103\n",
      "Episode:493 meanR:436.3500 R:500.0000 loss:18.6552 exploreP:0.0103\n",
      "Episode:494 meanR:439.7700 R:500.0000 loss:17.2780 exploreP:0.0103\n",
      "Episode:495 meanR:439.7700 R:500.0000 loss:17.2208 exploreP:0.0103\n",
      "Episode:496 meanR:443.6800 R:500.0000 loss:12.8417 exploreP:0.0103\n",
      "Episode:497 meanR:448.3900 R:500.0000 loss:7.8294 exploreP:0.0103\n",
      "Episode:498 meanR:448.3900 R:500.0000 loss:8.1898 exploreP:0.0103\n",
      "Episode:499 meanR:446.5500 R:272.0000 loss:21.7900 exploreP:0.0102\n",
      "Episode:500 meanR:450.3100 R:500.0000 loss:1.2584 exploreP:0.0102\n",
      "Episode:501 meanR:453.4100 R:500.0000 loss:19.2654 exploreP:0.0102\n",
      "Episode:502 meanR:457.0300 R:500.0000 loss:7.2175 exploreP:0.0102\n",
      "Episode:503 meanR:455.6800 R:185.0000 loss:51.3261 exploreP:0.0102\n",
      "Episode:504 meanR:455.6800 R:500.0000 loss:1.3220 exploreP:0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:505 meanR:455.4100 R:473.0000 loss:19.6434 exploreP:0.0102\n",
      "Episode:506 meanR:455.4100 R:500.0000 loss:3.4267 exploreP:0.0102\n",
      "Episode:507 meanR:455.4100 R:500.0000 loss:17.6960 exploreP:0.0102\n",
      "Episode:508 meanR:455.4100 R:500.0000 loss:18.9431 exploreP:0.0102\n",
      "Episode:509 meanR:455.4100 R:500.0000 loss:17.6513 exploreP:0.0102\n",
      "Episode:510 meanR:454.3900 R:27.0000 loss:72.0261 exploreP:0.0102\n",
      "Episode:511 meanR:449.5600 R:17.0000 loss:140.2437 exploreP:0.0102\n",
      "Episode:512 meanR:444.6900 R:13.0000 loss:206.4319 exploreP:0.0102\n",
      "Episode:513 meanR:441.6700 R:198.0000 loss:64.6669 exploreP:0.0102\n",
      "Episode:514 meanR:441.6700 R:500.0000 loss:2.3294 exploreP:0.0101\n",
      "Episode:515 meanR:443.8900 R:500.0000 loss:6.1226 exploreP:0.0101\n",
      "Episode:516 meanR:443.8900 R:500.0000 loss:15.1049 exploreP:0.0101\n",
      "Episode:517 meanR:447.4500 R:500.0000 loss:16.4297 exploreP:0.0101\n",
      "Episode:518 meanR:447.4500 R:500.0000 loss:16.5606 exploreP:0.0101\n",
      "Episode:519 meanR:447.4500 R:500.0000 loss:16.6599 exploreP:0.0101\n",
      "Episode:520 meanR:444.4000 R:195.0000 loss:37.8564 exploreP:0.0101\n",
      "Episode:521 meanR:445.6200 R:286.0000 loss:23.3151 exploreP:0.0101\n",
      "Episode:522 meanR:442.9700 R:235.0000 loss:17.1112 exploreP:0.0101\n",
      "Episode:523 meanR:440.4000 R:243.0000 loss:17.0001 exploreP:0.0101\n",
      "Episode:524 meanR:440.3400 R:494.0000 loss:4.5346 exploreP:0.0101\n",
      "Episode:525 meanR:443.4800 R:500.0000 loss:0.9655 exploreP:0.0101\n",
      "Episode:526 meanR:443.4800 R:500.0000 loss:16.9652 exploreP:0.0101\n",
      "Episode:527 meanR:440.3600 R:188.0000 loss:41.7490 exploreP:0.0101\n",
      "Episode:528 meanR:437.3100 R:195.0000 loss:4.6130 exploreP:0.0101\n",
      "Episode:529 meanR:434.3700 R:206.0000 loss:10.1053 exploreP:0.0101\n",
      "Episode:530 meanR:432.3600 R:299.0000 loss:5.4703 exploreP:0.0101\n",
      "Episode:531 meanR:430.0200 R:266.0000 loss:1.3664 exploreP:0.0101\n",
      "Episode:532 meanR:427.6800 R:266.0000 loss:3.2615 exploreP:0.0101\n",
      "Episode:533 meanR:427.3500 R:464.0000 loss:2.1336 exploreP:0.0101\n",
      "Episode:534 meanR:424.7400 R:239.0000 loss:2.2008 exploreP:0.0101\n",
      "Episode:535 meanR:424.7400 R:500.0000 loss:5.2923 exploreP:0.0101\n",
      "Episode:536 meanR:422.2700 R:253.0000 loss:24.3677 exploreP:0.0101\n",
      "Episode:537 meanR:420.5300 R:326.0000 loss:1.0581 exploreP:0.0101\n",
      "Episode:538 meanR:418.6400 R:311.0000 loss:17.7971 exploreP:0.0101\n",
      "Episode:539 meanR:415.3900 R:175.0000 loss:33.9928 exploreP:0.0101\n",
      "Episode:540 meanR:415.8000 R:281.0000 loss:3.5480 exploreP:0.0101\n",
      "Episode:541 meanR:415.1900 R:439.0000 loss:5.4021 exploreP:0.0101\n",
      "Episode:542 meanR:411.2800 R:109.0000 loss:5.4632 exploreP:0.0101\n",
      "Episode:543 meanR:407.7800 R:150.0000 loss:6.3180 exploreP:0.0101\n",
      "Episode:544 meanR:407.2000 R:442.0000 loss:2.2884 exploreP:0.0101\n",
      "Episode:545 meanR:406.4400 R:424.0000 loss:9.1954 exploreP:0.0101\n",
      "Episode:546 meanR:406.4400 R:500.0000 loss:2.9241 exploreP:0.0100\n",
      "Episode:547 meanR:406.3000 R:371.0000 loss:24.7000 exploreP:0.0100\n",
      "Episode:548 meanR:406.9600 R:500.0000 loss:3.5014 exploreP:0.0100\n",
      "Episode:549 meanR:403.4600 R:150.0000 loss:44.6688 exploreP:0.0100\n",
      "Episode:550 meanR:403.4600 R:500.0000 loss:1.8654 exploreP:0.0100\n",
      "Episode:551 meanR:400.0800 R:162.0000 loss:44.7900 exploreP:0.0100\n",
      "Episode:552 meanR:399.6400 R:155.0000 loss:14.6891 exploreP:0.0100\n",
      "Episode:553 meanR:396.2400 R:160.0000 loss:1.3909 exploreP:0.0100\n",
      "Episode:554 meanR:392.6100 R:137.0000 loss:2.6505 exploreP:0.0100\n",
      "Episode:555 meanR:389.3400 R:173.0000 loss:0.9708 exploreP:0.0100\n",
      "Episode:556 meanR:385.8800 R:154.0000 loss:0.3920 exploreP:0.0100\n",
      "Episode:557 meanR:382.5400 R:166.0000 loss:0.2952 exploreP:0.0100\n",
      "Episode:558 meanR:379.4500 R:191.0000 loss:0.5181 exploreP:0.0100\n",
      "Episode:559 meanR:376.5800 R:213.0000 loss:0.3960 exploreP:0.0100\n",
      "Episode:560 meanR:376.5800 R:500.0000 loss:0.3904 exploreP:0.0100\n",
      "Episode:561 meanR:373.9600 R:238.0000 loss:29.0513 exploreP:0.0100\n",
      "Episode:562 meanR:373.9600 R:500.0000 loss:4.8153 exploreP:0.0100\n",
      "Episode:563 meanR:373.9600 R:500.0000 loss:8.1352 exploreP:0.0100\n",
      "Episode:564 meanR:376.9700 R:500.0000 loss:8.6064 exploreP:0.0100\n",
      "Episode:565 meanR:378.0700 R:216.0000 loss:24.6794 exploreP:0.0100\n",
      "Episode:566 meanR:380.0000 R:500.0000 loss:4.8534 exploreP:0.0100\n",
      "Episode:567 meanR:380.0000 R:500.0000 loss:19.2287 exploreP:0.0100\n",
      "Episode:568 meanR:380.0000 R:500.0000 loss:14.8585 exploreP:0.0100\n",
      "Episode:569 meanR:380.0000 R:500.0000 loss:17.0581 exploreP:0.0100\n",
      "Episode:570 meanR:380.0000 R:500.0000 loss:15.7310 exploreP:0.0100\n",
      "Episode:571 meanR:380.0000 R:500.0000 loss:15.9306 exploreP:0.0100\n",
      "Episode:572 meanR:380.9200 R:500.0000 loss:15.6703 exploreP:0.0100\n",
      "Episode:573 meanR:380.9200 R:500.0000 loss:17.6158 exploreP:0.0100\n",
      "Episode:574 meanR:380.9200 R:500.0000 loss:16.9848 exploreP:0.0100\n",
      "Episode:575 meanR:380.9200 R:500.0000 loss:15.7147 exploreP:0.0100\n",
      "Episode:576 meanR:381.1200 R:500.0000 loss:15.2310 exploreP:0.0100\n",
      "Episode:577 meanR:381.1200 R:500.0000 loss:12.7969 exploreP:0.0100\n",
      "Episode:578 meanR:377.1400 R:102.0000 loss:32.2029 exploreP:0.0100\n",
      "Episode:579 meanR:374.1100 R:197.0000 loss:18.5932 exploreP:0.0100\n",
      "Episode:580 meanR:376.1900 R:221.0000 loss:31.4930 exploreP:0.0100\n",
      "Episode:581 meanR:373.7600 R:257.0000 loss:10.6637 exploreP:0.0100\n",
      "Episode:582 meanR:370.8900 R:213.0000 loss:13.1536 exploreP:0.0100\n",
      "Episode:583 meanR:368.1400 R:225.0000 loss:4.2121 exploreP:0.0100\n",
      "Episode:584 meanR:365.1600 R:202.0000 loss:8.3551 exploreP:0.0100\n",
      "Episode:585 meanR:362.6000 R:186.0000 loss:3.2802 exploreP:0.0100\n",
      "Episode:586 meanR:359.5500 R:195.0000 loss:1.1067 exploreP:0.0100\n",
      "Episode:587 meanR:357.3500 R:280.0000 loss:1.4367 exploreP:0.0100\n",
      "Episode:588 meanR:357.3100 R:496.0000 loss:1.8574 exploreP:0.0100\n",
      "Episode:589 meanR:354.6300 R:232.0000 loss:11.2665 exploreP:0.0100\n",
      "Episode:590 meanR:354.2100 R:458.0000 loss:1.8585 exploreP:0.0100\n",
      "Episode:591 meanR:350.6300 R:142.0000 loss:1.6999 exploreP:0.0100\n",
      "Episode:592 meanR:350.6300 R:500.0000 loss:3.0383 exploreP:0.0100\n",
      "Episode:593 meanR:350.6300 R:500.0000 loss:13.8385 exploreP:0.0100\n",
      "Episode:594 meanR:347.6900 R:206.0000 loss:32.8169 exploreP:0.0100\n",
      "Episode:595 meanR:343.6200 R:93.0000 loss:2.6249 exploreP:0.0100\n",
      "Episode:596 meanR:339.8700 R:125.0000 loss:2.6548 exploreP:0.0100\n",
      "Episode:597 meanR:336.8200 R:195.0000 loss:8.9268 exploreP:0.0100\n",
      "Episode:598 meanR:333.4100 R:159.0000 loss:1.7718 exploreP:0.0100\n",
      "Episode:599 meanR:335.1100 R:442.0000 loss:2.6452 exploreP:0.0100\n",
      "Episode:600 meanR:331.9600 R:185.0000 loss:5.1882 exploreP:0.0100\n",
      "Episode:601 meanR:331.9600 R:500.0000 loss:0.8001 exploreP:0.0100\n",
      "Episode:602 meanR:331.9600 R:500.0000 loss:1.6527 exploreP:0.0100\n",
      "Episode:603 meanR:332.4600 R:235.0000 loss:25.2700 exploreP:0.0100\n",
      "Episode:604 meanR:332.0600 R:460.0000 loss:0.8007 exploreP:0.0100\n",
      "Episode:605 meanR:332.3300 R:500.0000 loss:0.6745 exploreP:0.0100\n",
      "Episode:606 meanR:329.2900 R:196.0000 loss:2.3504 exploreP:0.0100\n",
      "Episode:607 meanR:329.2900 R:500.0000 loss:1.6947 exploreP:0.0100\n",
      "Episode:608 meanR:329.2900 R:500.0000 loss:51.9382 exploreP:0.0100\n",
      "Episode:609 meanR:329.2900 R:500.0000 loss:3.5864 exploreP:0.0100\n",
      "Episode:610 meanR:334.0100 R:499.0000 loss:6.9150 exploreP:0.0100\n",
      "Episode:611 meanR:338.8400 R:500.0000 loss:4.7442 exploreP:0.0100\n",
      "Episode:612 meanR:341.9600 R:325.0000 loss:30.7011 exploreP:0.0100\n",
      "Episode:613 meanR:342.6400 R:266.0000 loss:14.3911 exploreP:0.0100\n",
      "Episode:614 meanR:342.6400 R:500.0000 loss:3.0362 exploreP:0.0100\n",
      "Episode:615 meanR:342.6400 R:500.0000 loss:16.7601 exploreP:0.0100\n",
      "Episode:616 meanR:342.6400 R:500.0000 loss:15.9198 exploreP:0.0100\n",
      "Episode:617 meanR:342.6400 R:500.0000 loss:14.6194 exploreP:0.0100\n",
      "Episode:618 meanR:342.6400 R:500.0000 loss:14.6646 exploreP:0.0100\n",
      "Episode:619 meanR:342.6400 R:500.0000 loss:15.0243 exploreP:0.0100\n",
      "Episode:620 meanR:345.6900 R:500.0000 loss:16.2456 exploreP:0.0100\n",
      "Episode:621 meanR:347.8300 R:500.0000 loss:16.4193 exploreP:0.0100\n",
      "Episode:622 meanR:346.9600 R:148.0000 loss:54.9096 exploreP:0.0100\n",
      "Episode:623 meanR:345.7900 R:126.0000 loss:32.6370 exploreP:0.0100\n",
      "Episode:624 meanR:342.3400 R:149.0000 loss:2.2416 exploreP:0.0100\n",
      "Episode:625 meanR:338.7600 R:142.0000 loss:1.5903 exploreP:0.0100\n",
      "Episode:626 meanR:335.3200 R:156.0000 loss:0.7213 exploreP:0.0100\n",
      "Episode:627 meanR:338.4400 R:500.0000 loss:0.5680 exploreP:0.0100\n",
      "Episode:628 meanR:341.4900 R:500.0000 loss:9.0717 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:629 meanR:344.4300 R:500.0000 loss:17.2327 exploreP:0.0100\n",
      "Episode:630 meanR:346.4400 R:500.0000 loss:16.0470 exploreP:0.0100\n",
      "Episode:631 meanR:348.7800 R:500.0000 loss:16.0464 exploreP:0.0100\n",
      "Episode:632 meanR:351.1200 R:500.0000 loss:20.2337 exploreP:0.0100\n",
      "Episode:633 meanR:351.4800 R:500.0000 loss:15.5130 exploreP:0.0100\n",
      "Episode:634 meanR:354.0900 R:500.0000 loss:1.1226 exploreP:0.0100\n",
      "Episode:635 meanR:354.0900 R:500.0000 loss:17.3331 exploreP:0.0100\n",
      "Episode:636 meanR:356.5600 R:500.0000 loss:13.6065 exploreP:0.0100\n",
      "Episode:637 meanR:358.3000 R:500.0000 loss:14.3423 exploreP:0.0100\n",
      "Episode:638 meanR:360.1900 R:500.0000 loss:14.9160 exploreP:0.0100\n",
      "Episode:639 meanR:358.5700 R:13.0000 loss:68.6695 exploreP:0.0100\n",
      "Episode:640 meanR:358.3100 R:255.0000 loss:40.7770 exploreP:0.0100\n",
      "Episode:641 meanR:354.9800 R:106.0000 loss:0.8269 exploreP:0.0100\n",
      "Episode:642 meanR:354.9600 R:107.0000 loss:26.4539 exploreP:0.0100\n",
      "Episode:643 meanR:354.9200 R:146.0000 loss:24.1882 exploreP:0.0100\n",
      "Episode:644 meanR:351.8100 R:131.0000 loss:4.0695 exploreP:0.0100\n",
      "Episode:645 meanR:352.5700 R:500.0000 loss:1.7503 exploreP:0.0100\n",
      "Episode:646 meanR:350.3400 R:277.0000 loss:5.7248 exploreP:0.0100\n",
      "Episode:647 meanR:351.6300 R:500.0000 loss:3.2292 exploreP:0.0100\n",
      "Episode:648 meanR:351.6300 R:500.0000 loss:16.0354 exploreP:0.0100\n",
      "Episode:649 meanR:355.1300 R:500.0000 loss:5.8136 exploreP:0.0100\n",
      "Episode:650 meanR:355.1300 R:500.0000 loss:15.1173 exploreP:0.0100\n",
      "Episode:651 meanR:358.5100 R:500.0000 loss:14.6731 exploreP:0.0100\n",
      "Episode:652 meanR:361.9600 R:500.0000 loss:14.3863 exploreP:0.0100\n",
      "Episode:653 meanR:365.3600 R:500.0000 loss:7.3103 exploreP:0.0100\n",
      "Episode:654 meanR:368.9900 R:500.0000 loss:16.8601 exploreP:0.0100\n",
      "Episode:655 meanR:372.2600 R:500.0000 loss:15.3947 exploreP:0.0100\n",
      "Episode:656 meanR:373.3400 R:262.0000 loss:29.2338 exploreP:0.0100\n",
      "Episode:657 meanR:373.2300 R:155.0000 loss:15.0658 exploreP:0.0100\n",
      "Episode:658 meanR:372.7200 R:140.0000 loss:10.6364 exploreP:0.0100\n",
      "Episode:659 meanR:371.6500 R:106.0000 loss:3.7855 exploreP:0.0100\n",
      "Episode:660 meanR:367.6700 R:102.0000 loss:10.1774 exploreP:0.0100\n",
      "Episode:661 meanR:366.3400 R:105.0000 loss:2.9382 exploreP:0.0100\n",
      "Episode:662 meanR:362.3700 R:103.0000 loss:3.1212 exploreP:0.0100\n",
      "Episode:663 meanR:358.3500 R:98.0000 loss:5.4659 exploreP:0.0100\n",
      "Episode:664 meanR:354.3500 R:100.0000 loss:12.6293 exploreP:0.0100\n",
      "Episode:665 meanR:353.2400 R:105.0000 loss:14.8360 exploreP:0.0100\n",
      "Episode:666 meanR:349.2300 R:99.0000 loss:18.3992 exploreP:0.0100\n",
      "Episode:667 meanR:345.2400 R:101.0000 loss:17.6846 exploreP:0.0100\n",
      "Episode:668 meanR:341.2500 R:101.0000 loss:21.6007 exploreP:0.0100\n",
      "Episode:669 meanR:337.2300 R:98.0000 loss:24.1698 exploreP:0.0100\n",
      "Episode:670 meanR:333.2700 R:104.0000 loss:19.7683 exploreP:0.0100\n",
      "Episode:671 meanR:329.3700 R:110.0000 loss:9.6894 exploreP:0.0100\n",
      "Episode:672 meanR:325.4700 R:110.0000 loss:6.1090 exploreP:0.0100\n",
      "Episode:673 meanR:321.5800 R:111.0000 loss:4.3030 exploreP:0.0100\n",
      "Episode:674 meanR:318.1200 R:154.0000 loss:1.9207 exploreP:0.0100\n",
      "Episode:675 meanR:314.6300 R:151.0000 loss:0.6405 exploreP:0.0100\n",
      "Episode:676 meanR:311.0600 R:143.0000 loss:0.4193 exploreP:0.0100\n",
      "Episode:677 meanR:307.3700 R:131.0000 loss:0.2882 exploreP:0.0100\n",
      "Episode:678 meanR:307.5000 R:115.0000 loss:0.2361 exploreP:0.0100\n",
      "Episode:679 meanR:306.6200 R:109.0000 loss:0.3138 exploreP:0.0100\n",
      "Episode:680 meanR:305.4900 R:108.0000 loss:0.1723 exploreP:0.0100\n",
      "Episode:681 meanR:303.9600 R:104.0000 loss:0.1368 exploreP:0.0100\n",
      "Episode:682 meanR:302.9500 R:112.0000 loss:0.1369 exploreP:0.0100\n",
      "Episode:683 meanR:301.8300 R:113.0000 loss:0.0914 exploreP:0.0100\n",
      "Episode:684 meanR:300.9700 R:116.0000 loss:0.1536 exploreP:0.0100\n",
      "Episode:685 meanR:300.2600 R:115.0000 loss:0.1178 exploreP:0.0100\n",
      "Episode:686 meanR:299.4400 R:113.0000 loss:0.0891 exploreP:0.0100\n",
      "Episode:687 meanR:297.9700 R:133.0000 loss:0.1443 exploreP:0.0100\n",
      "Episode:688 meanR:294.2300 R:122.0000 loss:1.4964 exploreP:0.0100\n",
      "Episode:689 meanR:293.3900 R:148.0000 loss:0.9908 exploreP:0.0100\n",
      "Episode:690 meanR:290.1800 R:137.0000 loss:0.1988 exploreP:0.0100\n",
      "Episode:691 meanR:290.1100 R:135.0000 loss:0.2992 exploreP:0.0100\n",
      "Episode:692 meanR:286.7100 R:160.0000 loss:0.3198 exploreP:0.0100\n",
      "Episode:693 meanR:285.5800 R:387.0000 loss:1.0247 exploreP:0.0100\n",
      "Episode:694 meanR:285.6700 R:215.0000 loss:11.4278 exploreP:0.0100\n",
      "Episode:695 meanR:289.7400 R:500.0000 loss:7.3232 exploreP:0.0100\n",
      "Episode:696 meanR:293.4900 R:500.0000 loss:17.1232 exploreP:0.0100\n",
      "Episode:697 meanR:296.5400 R:500.0000 loss:18.4409 exploreP:0.0100\n",
      "Episode:698 meanR:299.9500 R:500.0000 loss:15.0499 exploreP:0.0100\n",
      "Episode:699 meanR:300.5300 R:500.0000 loss:15.9025 exploreP:0.0100\n",
      "Episode:700 meanR:303.6800 R:500.0000 loss:15.3646 exploreP:0.0100\n",
      "Episode:701 meanR:303.6800 R:500.0000 loss:13.9093 exploreP:0.0100\n",
      "Episode:702 meanR:298.8000 R:12.0000 loss:72.8795 exploreP:0.0100\n",
      "Episode:703 meanR:301.4500 R:500.0000 loss:18.5741 exploreP:0.0100\n",
      "Episode:704 meanR:301.8500 R:500.0000 loss:16.2324 exploreP:0.0100\n",
      "Episode:705 meanR:301.8500 R:500.0000 loss:17.0759 exploreP:0.0100\n",
      "Episode:706 meanR:304.8900 R:500.0000 loss:17.5519 exploreP:0.0100\n",
      "Episode:707 meanR:304.8900 R:500.0000 loss:17.0603 exploreP:0.0100\n",
      "Episode:708 meanR:304.8900 R:500.0000 loss:15.5079 exploreP:0.0100\n",
      "Episode:709 meanR:304.8900 R:500.0000 loss:14.7767 exploreP:0.0100\n",
      "Episode:710 meanR:304.9000 R:500.0000 loss:16.5548 exploreP:0.0100\n",
      "Episode:711 meanR:304.9000 R:500.0000 loss:15.3765 exploreP:0.0100\n",
      "Episode:712 meanR:306.6500 R:500.0000 loss:13.9495 exploreP:0.0100\n",
      "Episode:713 meanR:308.9900 R:500.0000 loss:13.9668 exploreP:0.0100\n",
      "Episode:714 meanR:308.9900 R:500.0000 loss:17.5321 exploreP:0.0100\n",
      "Episode:715 meanR:308.9900 R:500.0000 loss:16.5356 exploreP:0.0100\n",
      "Episode:716 meanR:308.9900 R:500.0000 loss:17.2875 exploreP:0.0100\n",
      "Episode:717 meanR:308.9900 R:500.0000 loss:15.6997 exploreP:0.0100\n",
      "Episode:718 meanR:308.9900 R:500.0000 loss:15.0602 exploreP:0.0100\n",
      "Episode:719 meanR:308.9900 R:500.0000 loss:12.9107 exploreP:0.0100\n",
      "Episode:720 meanR:308.9900 R:500.0000 loss:18.2027 exploreP:0.0100\n",
      "Episode:721 meanR:308.9900 R:500.0000 loss:13.7394 exploreP:0.0100\n",
      "Episode:722 meanR:312.5100 R:500.0000 loss:18.1441 exploreP:0.0100\n",
      "Episode:723 meanR:316.2500 R:500.0000 loss:17.0465 exploreP:0.0100\n",
      "Episode:724 meanR:319.7600 R:500.0000 loss:16.2276 exploreP:0.0100\n",
      "Episode:725 meanR:323.3400 R:500.0000 loss:18.7687 exploreP:0.0100\n",
      "Episode:726 meanR:326.7800 R:500.0000 loss:17.8431 exploreP:0.0100\n",
      "Episode:727 meanR:321.9100 R:13.0000 loss:78.4211 exploreP:0.0100\n",
      "Episode:728 meanR:317.0200 R:11.0000 loss:134.5806 exploreP:0.0100\n",
      "Episode:729 meanR:317.0200 R:500.0000 loss:23.9017 exploreP:0.0100\n",
      "Episode:730 meanR:312.1500 R:13.0000 loss:96.4910 exploreP:0.0100\n",
      "Episode:731 meanR:312.1500 R:500.0000 loss:33.2380 exploreP:0.0100\n",
      "Episode:732 meanR:312.1500 R:500.0000 loss:19.0938 exploreP:0.0100\n",
      "Episode:733 meanR:312.1500 R:500.0000 loss:18.8343 exploreP:0.0100\n",
      "Episode:734 meanR:312.1500 R:500.0000 loss:14.8732 exploreP:0.0100\n",
      "Episode:735 meanR:312.1500 R:500.0000 loss:17.1025 exploreP:0.0100\n",
      "Episode:736 meanR:312.1500 R:500.0000 loss:16.3689 exploreP:0.0100\n",
      "Episode:737 meanR:312.1500 R:500.0000 loss:17.0312 exploreP:0.0100\n",
      "Episode:738 meanR:312.1500 R:500.0000 loss:13.8957 exploreP:0.0100\n",
      "Episode:739 meanR:317.0200 R:500.0000 loss:14.2078 exploreP:0.0100\n",
      "Episode:740 meanR:319.4700 R:500.0000 loss:19.2284 exploreP:0.0100\n",
      "Episode:741 meanR:323.4100 R:500.0000 loss:16.7259 exploreP:0.0100\n",
      "Episode:742 meanR:327.3400 R:500.0000 loss:15.7800 exploreP:0.0100\n",
      "Episode:743 meanR:330.8800 R:500.0000 loss:13.6305 exploreP:0.0100\n",
      "Episode:744 meanR:334.5700 R:500.0000 loss:19.0207 exploreP:0.0100\n",
      "Episode:745 meanR:334.5700 R:500.0000 loss:18.1826 exploreP:0.0100\n",
      "Episode:746 meanR:334.5900 R:279.0000 loss:32.2006 exploreP:0.0100\n",
      "Episode:747 meanR:334.5900 R:500.0000 loss:5.2034 exploreP:0.0100\n",
      "Episode:748 meanR:334.5900 R:500.0000 loss:15.6778 exploreP:0.0100\n",
      "Episode:749 meanR:331.7600 R:217.0000 loss:31.1819 exploreP:0.0100\n",
      "Episode:750 meanR:328.1800 R:142.0000 loss:45.4882 exploreP:0.0100\n",
      "Episode:751 meanR:323.3000 R:12.0000 loss:35.6548 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:752 meanR:318.4200 R:12.0000 loss:77.9524 exploreP:0.0100\n",
      "Episode:753 meanR:318.4200 R:500.0000 loss:10.9067 exploreP:0.0100\n",
      "Episode:754 meanR:318.4200 R:500.0000 loss:7.2594 exploreP:0.0100\n",
      "Episode:755 meanR:316.3600 R:294.0000 loss:29.2192 exploreP:0.0100\n",
      "Episode:756 meanR:315.8300 R:209.0000 loss:1.7057 exploreP:0.0100\n",
      "Episode:757 meanR:315.4700 R:119.0000 loss:1.0198 exploreP:0.0100\n",
      "Episode:758 meanR:315.0400 R:97.0000 loss:1.7643 exploreP:0.0100\n",
      "Episode:759 meanR:314.7000 R:72.0000 loss:2.7305 exploreP:0.0100\n",
      "Episode:760 meanR:314.4200 R:74.0000 loss:6.4882 exploreP:0.0100\n",
      "Episode:761 meanR:313.5500 R:18.0000 loss:8.8507 exploreP:0.0100\n",
      "Episode:762 meanR:312.6600 R:14.0000 loss:22.0991 exploreP:0.0100\n",
      "Episode:763 meanR:311.8300 R:15.0000 loss:23.2943 exploreP:0.0100\n",
      "Episode:764 meanR:311.5200 R:69.0000 loss:9.3641 exploreP:0.0100\n",
      "Episode:765 meanR:315.4700 R:500.0000 loss:4.1231 exploreP:0.0100\n",
      "Episode:766 meanR:319.4800 R:500.0000 loss:14.1218 exploreP:0.0100\n",
      "Episode:767 meanR:323.4700 R:500.0000 loss:14.8541 exploreP:0.0100\n",
      "Episode:768 meanR:327.4600 R:500.0000 loss:16.1403 exploreP:0.0100\n",
      "Episode:769 meanR:331.4800 R:500.0000 loss:17.5110 exploreP:0.0100\n",
      "Episode:770 meanR:335.4400 R:500.0000 loss:16.3593 exploreP:0.0100\n",
      "Episode:771 meanR:339.3400 R:500.0000 loss:15.4568 exploreP:0.0100\n",
      "Episode:772 meanR:343.2400 R:500.0000 loss:15.2431 exploreP:0.0100\n",
      "Episode:773 meanR:347.1300 R:500.0000 loss:14.4487 exploreP:0.0100\n",
      "Episode:774 meanR:350.5900 R:500.0000 loss:13.8274 exploreP:0.0100\n",
      "Episode:775 meanR:354.0800 R:500.0000 loss:15.4042 exploreP:0.0100\n",
      "Episode:776 meanR:357.6500 R:500.0000 loss:13.5912 exploreP:0.0100\n",
      "Episode:777 meanR:361.3400 R:500.0000 loss:16.7599 exploreP:0.0100\n",
      "Episode:778 meanR:365.1900 R:500.0000 loss:16.2009 exploreP:0.0100\n",
      "Episode:779 meanR:369.1000 R:500.0000 loss:15.9478 exploreP:0.0100\n",
      "Episode:780 meanR:373.0200 R:500.0000 loss:13.5222 exploreP:0.0100\n",
      "Episode:781 meanR:376.9800 R:500.0000 loss:19.3287 exploreP:0.0100\n",
      "Episode:782 meanR:380.8600 R:500.0000 loss:15.7124 exploreP:0.0100\n",
      "Episode:783 meanR:384.7300 R:500.0000 loss:18.7090 exploreP:0.0100\n",
      "Episode:784 meanR:388.5700 R:500.0000 loss:8.2194 exploreP:0.0100\n",
      "Episode:785 meanR:392.4200 R:500.0000 loss:17.7742 exploreP:0.0100\n",
      "Episode:786 meanR:392.6900 R:140.0000 loss:66.7606 exploreP:0.0100\n",
      "Episode:787 meanR:392.9400 R:158.0000 loss:17.1912 exploreP:0.0100\n",
      "Episode:788 meanR:396.7200 R:500.0000 loss:14.7617 exploreP:0.0100\n",
      "Episode:789 meanR:399.4200 R:418.0000 loss:14.1358 exploreP:0.0100\n",
      "Episode:790 meanR:401.0700 R:302.0000 loss:6.3781 exploreP:0.0100\n",
      "Episode:791 meanR:404.7200 R:500.0000 loss:1.3649 exploreP:0.0100\n",
      "Episode:792 meanR:408.1200 R:500.0000 loss:1.3688 exploreP:0.0100\n",
      "Episode:793 meanR:409.2500 R:500.0000 loss:10.7863 exploreP:0.0100\n",
      "Episode:794 meanR:408.7700 R:167.0000 loss:47.1218 exploreP:0.0100\n",
      "Episode:795 meanR:408.7700 R:500.0000 loss:1.6834 exploreP:0.0100\n",
      "Episode:796 meanR:408.7700 R:500.0000 loss:13.3856 exploreP:0.0100\n",
      "Episode:797 meanR:408.7700 R:500.0000 loss:15.4609 exploreP:0.0100\n",
      "Episode:798 meanR:408.7700 R:500.0000 loss:9.3968 exploreP:0.0100\n",
      "Episode:799 meanR:408.7700 R:500.0000 loss:14.2829 exploreP:0.0100\n",
      "Episode:800 meanR:408.7700 R:500.0000 loss:16.4927 exploreP:0.0100\n",
      "Episode:801 meanR:408.7700 R:500.0000 loss:15.5519 exploreP:0.0100\n",
      "Episode:802 meanR:413.6500 R:500.0000 loss:15.9575 exploreP:0.0100\n",
      "Episode:803 meanR:413.6500 R:500.0000 loss:15.5896 exploreP:0.0100\n",
      "Episode:804 meanR:413.6500 R:500.0000 loss:15.4783 exploreP:0.0100\n",
      "Episode:805 meanR:413.6500 R:500.0000 loss:15.6159 exploreP:0.0100\n",
      "Episode:806 meanR:413.6500 R:500.0000 loss:9.7866 exploreP:0.0100\n",
      "Episode:807 meanR:413.6500 R:500.0000 loss:16.7264 exploreP:0.0100\n",
      "Episode:808 meanR:413.6500 R:500.0000 loss:15.6737 exploreP:0.0100\n",
      "Episode:809 meanR:413.6500 R:500.0000 loss:15.1529 exploreP:0.0100\n",
      "Episode:810 meanR:413.6500 R:500.0000 loss:14.6425 exploreP:0.0100\n",
      "Episode:811 meanR:413.6500 R:500.0000 loss:14.6518 exploreP:0.0100\n",
      "Episode:812 meanR:413.6500 R:500.0000 loss:14.7877 exploreP:0.0100\n",
      "Episode:813 meanR:413.6500 R:500.0000 loss:14.8081 exploreP:0.0100\n",
      "Episode:814 meanR:413.6500 R:500.0000 loss:15.7742 exploreP:0.0100\n",
      "Episode:815 meanR:413.6500 R:500.0000 loss:14.7729 exploreP:0.0100\n",
      "Episode:816 meanR:413.6500 R:500.0000 loss:15.7532 exploreP:0.0100\n",
      "Episode:817 meanR:413.6500 R:500.0000 loss:14.9431 exploreP:0.0100\n",
      "Episode:818 meanR:413.6500 R:500.0000 loss:16.0659 exploreP:0.0100\n",
      "Episode:819 meanR:413.6500 R:500.0000 loss:14.9115 exploreP:0.0100\n",
      "Episode:820 meanR:412.0800 R:343.0000 loss:12.8480 exploreP:0.0100\n",
      "Episode:821 meanR:409.8700 R:279.0000 loss:6.8232 exploreP:0.0100\n",
      "Episode:822 meanR:406.6200 R:175.0000 loss:14.6363 exploreP:0.0100\n",
      "Episode:823 meanR:402.7000 R:108.0000 loss:22.4215 exploreP:0.0100\n",
      "Episode:824 meanR:399.8100 R:211.0000 loss:7.1798 exploreP:0.0100\n",
      "Episode:825 meanR:397.8600 R:305.0000 loss:6.2214 exploreP:0.0100\n",
      "Episode:826 meanR:397.7100 R:485.0000 loss:2.4394 exploreP:0.0100\n",
      "Episode:827 meanR:398.6000 R:102.0000 loss:54.5231 exploreP:0.0100\n",
      "Episode:828 meanR:399.6100 R:112.0000 loss:9.2737 exploreP:0.0100\n",
      "Episode:829 meanR:395.5900 R:98.0000 loss:6.2398 exploreP:0.0100\n",
      "Episode:830 meanR:396.4600 R:100.0000 loss:5.8254 exploreP:0.0100\n",
      "Episode:831 meanR:392.5600 R:110.0000 loss:3.4538 exploreP:0.0100\n",
      "Episode:832 meanR:388.7300 R:117.0000 loss:2.3458 exploreP:0.0100\n",
      "Episode:833 meanR:384.8900 R:116.0000 loss:1.1295 exploreP:0.0100\n",
      "Episode:834 meanR:381.2100 R:132.0000 loss:1.2014 exploreP:0.0100\n",
      "Episode:835 meanR:377.5200 R:131.0000 loss:0.8288 exploreP:0.0100\n",
      "Episode:836 meanR:373.7800 R:126.0000 loss:4.1339 exploreP:0.0100\n",
      "Episode:837 meanR:370.0600 R:128.0000 loss:1.3860 exploreP:0.0100\n",
      "Episode:838 meanR:366.3100 R:125.0000 loss:1.0593 exploreP:0.0100\n",
      "Episode:839 meanR:362.4500 R:114.0000 loss:0.8132 exploreP:0.0100\n",
      "Episode:840 meanR:358.5200 R:107.0000 loss:0.7979 exploreP:0.0100\n",
      "Episode:841 meanR:354.2000 R:68.0000 loss:2.0799 exploreP:0.0100\n",
      "Episode:842 meanR:349.6800 R:48.0000 loss:11.6188 exploreP:0.0100\n",
      "Episode:843 meanR:345.2400 R:56.0000 loss:9.7872 exploreP:0.0100\n",
      "Episode:844 meanR:340.7700 R:53.0000 loss:5.6702 exploreP:0.0100\n",
      "Episode:845 meanR:336.2400 R:47.0000 loss:4.3944 exploreP:0.0100\n",
      "Episode:846 meanR:333.9100 R:46.0000 loss:4.5902 exploreP:0.0100\n",
      "Episode:847 meanR:329.2700 R:36.0000 loss:5.0942 exploreP:0.0100\n",
      "Episode:848 meanR:324.9000 R:63.0000 loss:3.3842 exploreP:0.0100\n",
      "Episode:849 meanR:323.1700 R:44.0000 loss:1.7191 exploreP:0.0100\n",
      "Episode:850 meanR:322.1900 R:44.0000 loss:1.3539 exploreP:0.0100\n",
      "Episode:851 meanR:322.6100 R:54.0000 loss:1.0737 exploreP:0.0100\n",
      "Episode:852 meanR:325.9400 R:345.0000 loss:2.7998 exploreP:0.0100\n",
      "Episode:853 meanR:322.0400 R:110.0000 loss:2.9530 exploreP:0.0100\n",
      "Episode:854 meanR:322.0400 R:500.0000 loss:1.7028 exploreP:0.0100\n",
      "Episode:855 meanR:322.5900 R:349.0000 loss:1.8478 exploreP:0.0100\n",
      "Episode:856 meanR:325.5000 R:500.0000 loss:2.0823 exploreP:0.0100\n",
      "Episode:857 meanR:327.7800 R:347.0000 loss:10.1050 exploreP:0.0100\n",
      "Episode:858 meanR:331.8100 R:500.0000 loss:2.0192 exploreP:0.0100\n",
      "Episode:859 meanR:336.0900 R:500.0000 loss:18.1437 exploreP:0.0100\n",
      "Episode:860 meanR:340.3500 R:500.0000 loss:17.5578 exploreP:0.0100\n",
      "Episode:861 meanR:345.1700 R:500.0000 loss:9.0199 exploreP:0.0100\n",
      "Episode:862 meanR:350.0300 R:500.0000 loss:13.6450 exploreP:0.0100\n",
      "Episode:863 meanR:354.8800 R:500.0000 loss:15.7990 exploreP:0.0100\n",
      "Episode:864 meanR:359.1900 R:500.0000 loss:10.7873 exploreP:0.0100\n",
      "Episode:865 meanR:359.1900 R:500.0000 loss:16.3119 exploreP:0.0100\n",
      "Episode:866 meanR:359.1900 R:500.0000 loss:18.5396 exploreP:0.0100\n",
      "Episode:867 meanR:359.1900 R:500.0000 loss:16.3602 exploreP:0.0100\n",
      "Episode:868 meanR:355.5600 R:137.0000 loss:40.6730 exploreP:0.0100\n",
      "Episode:869 meanR:351.8500 R:129.0000 loss:10.8452 exploreP:0.0100\n",
      "Episode:870 meanR:348.8000 R:195.0000 loss:5.1751 exploreP:0.0100\n",
      "Episode:871 meanR:348.8000 R:500.0000 loss:15.6281 exploreP:0.0100\n",
      "Episode:872 meanR:348.8000 R:500.0000 loss:13.8418 exploreP:0.0100\n",
      "Episode:873 meanR:348.8000 R:500.0000 loss:16.0798 exploreP:0.0100\n",
      "Episode:874 meanR:348.8000 R:500.0000 loss:12.3104 exploreP:0.0100\n",
      "Episode:875 meanR:348.8000 R:500.0000 loss:12.7606 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:876 meanR:348.8000 R:500.0000 loss:16.8002 exploreP:0.0100\n",
      "Episode:877 meanR:348.8000 R:500.0000 loss:11.5839 exploreP:0.0100\n",
      "Episode:878 meanR:348.8000 R:500.0000 loss:14.0821 exploreP:0.0100\n",
      "Episode:879 meanR:348.8000 R:500.0000 loss:18.4423 exploreP:0.0100\n",
      "Episode:880 meanR:348.8000 R:500.0000 loss:16.4679 exploreP:0.0100\n",
      "Episode:881 meanR:348.8000 R:500.0000 loss:15.1849 exploreP:0.0100\n",
      "Episode:882 meanR:348.8000 R:500.0000 loss:14.9894 exploreP:0.0100\n",
      "Episode:883 meanR:348.8000 R:500.0000 loss:13.4257 exploreP:0.0100\n",
      "Episode:884 meanR:348.8000 R:500.0000 loss:14.1580 exploreP:0.0100\n",
      "Episode:885 meanR:348.8000 R:500.0000 loss:20.3774 exploreP:0.0100\n",
      "Episode:886 meanR:352.4000 R:500.0000 loss:18.0469 exploreP:0.0100\n",
      "Episode:887 meanR:355.8200 R:500.0000 loss:13.2041 exploreP:0.0100\n",
      "Episode:888 meanR:355.8200 R:500.0000 loss:20.7753 exploreP:0.0100\n",
      "Episode:889 meanR:356.6400 R:500.0000 loss:17.1621 exploreP:0.0100\n",
      "Episode:890 meanR:358.6200 R:500.0000 loss:16.5067 exploreP:0.0100\n",
      "Episode:891 meanR:358.6200 R:500.0000 loss:15.4099 exploreP:0.0100\n",
      "Episode:892 meanR:358.6200 R:500.0000 loss:9.4194 exploreP:0.0100\n",
      "Episode:893 meanR:356.9900 R:337.0000 loss:13.5867 exploreP:0.0100\n",
      "Episode:894 meanR:356.3100 R:99.0000 loss:13.6595 exploreP:0.0100\n",
      "Episode:895 meanR:353.5300 R:222.0000 loss:4.2832 exploreP:0.0100\n",
      "Episode:896 meanR:350.4500 R:192.0000 loss:6.9628 exploreP:0.0100\n",
      "Episode:897 meanR:347.7000 R:225.0000 loss:5.6052 exploreP:0.0100\n",
      "Episode:898 meanR:347.7000 R:500.0000 loss:1.3549 exploreP:0.0100\n",
      "Episode:899 meanR:347.7000 R:500.0000 loss:15.4071 exploreP:0.0100\n",
      "Episode:900 meanR:345.1000 R:240.0000 loss:41.4959 exploreP:0.0100\n",
      "Episode:901 meanR:345.1000 R:500.0000 loss:1.8562 exploreP:0.0100\n",
      "Episode:902 meanR:345.1000 R:500.0000 loss:17.7895 exploreP:0.0100\n",
      "Episode:903 meanR:345.1000 R:500.0000 loss:17.4345 exploreP:0.0100\n",
      "Episode:904 meanR:345.1000 R:500.0000 loss:18.8172 exploreP:0.0100\n",
      "Episode:905 meanR:345.1000 R:500.0000 loss:12.9740 exploreP:0.0100\n",
      "Episode:906 meanR:345.1000 R:500.0000 loss:13.1157 exploreP:0.0100\n",
      "Episode:907 meanR:345.1000 R:500.0000 loss:14.1136 exploreP:0.0100\n",
      "Episode:908 meanR:345.1000 R:500.0000 loss:14.8775 exploreP:0.0100\n",
      "Episode:909 meanR:345.1000 R:500.0000 loss:20.0261 exploreP:0.0100\n",
      "Episode:910 meanR:345.1000 R:500.0000 loss:5.9766 exploreP:0.0100\n",
      "Episode:911 meanR:345.1000 R:500.0000 loss:17.6843 exploreP:0.0100\n",
      "Episode:912 meanR:345.1000 R:500.0000 loss:17.4630 exploreP:0.0100\n",
      "Episode:913 meanR:344.4400 R:434.0000 loss:16.4672 exploreP:0.0100\n",
      "Episode:914 meanR:344.4400 R:500.0000 loss:12.4949 exploreP:0.0100\n",
      "Episode:915 meanR:342.0300 R:259.0000 loss:36.3899 exploreP:0.0100\n",
      "Episode:916 meanR:342.0300 R:500.0000 loss:9.0799 exploreP:0.0100\n",
      "Episode:917 meanR:342.0300 R:500.0000 loss:7.4197 exploreP:0.0100\n",
      "Episode:918 meanR:342.0300 R:500.0000 loss:17.5637 exploreP:0.0100\n",
      "Episode:919 meanR:342.0300 R:500.0000 loss:16.8406 exploreP:0.0100\n",
      "Episode:920 meanR:343.6000 R:500.0000 loss:19.0046 exploreP:0.0100\n",
      "Episode:921 meanR:345.8100 R:500.0000 loss:16.6830 exploreP:0.0100\n",
      "Episode:922 meanR:349.0600 R:500.0000 loss:18.8306 exploreP:0.0100\n",
      "Episode:923 meanR:352.9800 R:500.0000 loss:15.4755 exploreP:0.0100\n",
      "Episode:924 meanR:355.8700 R:500.0000 loss:18.3681 exploreP:0.0100\n",
      "Episode:925 meanR:357.8200 R:500.0000 loss:15.7524 exploreP:0.0100\n",
      "Episode:926 meanR:357.9700 R:500.0000 loss:16.0976 exploreP:0.0100\n",
      "Episode:927 meanR:361.9500 R:500.0000 loss:17.3344 exploreP:0.0100\n",
      "Episode:928 meanR:365.8300 R:500.0000 loss:16.6455 exploreP:0.0100\n",
      "Episode:929 meanR:369.8500 R:500.0000 loss:18.1862 exploreP:0.0100\n",
      "Episode:930 meanR:370.1000 R:125.0000 loss:68.3398 exploreP:0.0100\n",
      "Episode:931 meanR:369.9900 R:99.0000 loss:39.2808 exploreP:0.0100\n",
      "Episode:932 meanR:369.7100 R:89.0000 loss:24.3378 exploreP:0.0100\n",
      "Episode:933 meanR:369.4100 R:86.0000 loss:17.2214 exploreP:0.0100\n",
      "Episode:934 meanR:368.8500 R:76.0000 loss:10.1300 exploreP:0.0100\n",
      "Episode:935 meanR:368.2200 R:68.0000 loss:7.3221 exploreP:0.0100\n",
      "Episode:936 meanR:367.7100 R:75.0000 loss:4.4028 exploreP:0.0100\n",
      "Episode:937 meanR:367.1900 R:76.0000 loss:4.3164 exploreP:0.0100\n",
      "Episode:938 meanR:366.7400 R:80.0000 loss:3.9575 exploreP:0.0100\n",
      "Episode:939 meanR:366.4300 R:83.0000 loss:1.6368 exploreP:0.0100\n",
      "Episode:940 meanR:366.1500 R:79.0000 loss:1.6572 exploreP:0.0100\n",
      "Episode:941 meanR:366.3600 R:89.0000 loss:1.2956 exploreP:0.0100\n",
      "Episode:942 meanR:366.7900 R:91.0000 loss:1.0177 exploreP:0.0100\n",
      "Episode:943 meanR:367.2500 R:102.0000 loss:1.0256 exploreP:0.0100\n",
      "Episode:944 meanR:367.9800 R:126.0000 loss:1.2569 exploreP:0.0100\n",
      "Episode:945 meanR:369.0900 R:158.0000 loss:1.5901 exploreP:0.0100\n",
      "Episode:946 meanR:370.2400 R:161.0000 loss:2.3607 exploreP:0.0100\n",
      "Episode:947 meanR:372.1400 R:226.0000 loss:2.1676 exploreP:0.0100\n",
      "Episode:948 meanR:376.5100 R:500.0000 loss:1.0700 exploreP:0.0100\n",
      "Episode:949 meanR:381.0700 R:500.0000 loss:13.5453 exploreP:0.0100\n",
      "Episode:950 meanR:385.6300 R:500.0000 loss:15.0794 exploreP:0.0100\n",
      "Episode:951 meanR:390.0900 R:500.0000 loss:17.4612 exploreP:0.0100\n",
      "Episode:952 meanR:391.6400 R:500.0000 loss:17.2782 exploreP:0.0100\n",
      "Episode:953 meanR:395.5400 R:500.0000 loss:11.2510 exploreP:0.0100\n",
      "Episode:954 meanR:395.5400 R:500.0000 loss:15.0501 exploreP:0.0100\n",
      "Episode:955 meanR:397.0500 R:500.0000 loss:11.9602 exploreP:0.0100\n",
      "Episode:956 meanR:397.0500 R:500.0000 loss:15.2285 exploreP:0.0100\n",
      "Episode:957 meanR:398.5800 R:500.0000 loss:15.8549 exploreP:0.0100\n",
      "Episode:958 meanR:397.2700 R:369.0000 loss:19.2987 exploreP:0.0100\n",
      "Episode:959 meanR:397.2700 R:500.0000 loss:1.4783 exploreP:0.0100\n",
      "Episode:960 meanR:397.2700 R:500.0000 loss:14.7763 exploreP:0.0100\n",
      "Episode:961 meanR:395.0400 R:277.0000 loss:9.0323 exploreP:0.0100\n",
      "Episode:962 meanR:395.0400 R:500.0000 loss:1.1576 exploreP:0.0100\n",
      "Episode:963 meanR:395.0400 R:500.0000 loss:15.1055 exploreP:0.0100\n",
      "Episode:964 meanR:395.0400 R:500.0000 loss:10.8376 exploreP:0.0100\n",
      "Episode:965 meanR:392.4100 R:237.0000 loss:32.1823 exploreP:0.0100\n",
      "Episode:966 meanR:392.4100 R:500.0000 loss:1.1062 exploreP:0.0100\n",
      "Episode:967 meanR:389.6000 R:219.0000 loss:29.5107 exploreP:0.0100\n",
      "Episode:968 meanR:393.2300 R:500.0000 loss:0.3669 exploreP:0.0100\n",
      "Episode:969 meanR:396.9400 R:500.0000 loss:15.6297 exploreP:0.0100\n",
      "Episode:970 meanR:397.4200 R:243.0000 loss:17.4957 exploreP:0.0100\n",
      "Episode:971 meanR:395.1300 R:271.0000 loss:7.4103 exploreP:0.0100\n",
      "Episode:972 meanR:391.3200 R:119.0000 loss:44.7521 exploreP:0.0100\n",
      "Episode:973 meanR:387.1900 R:87.0000 loss:2.9082 exploreP:0.0100\n",
      "Episode:974 meanR:387.1900 R:500.0000 loss:0.6660 exploreP:0.0100\n",
      "Episode:975 meanR:387.1900 R:500.0000 loss:16.0448 exploreP:0.0100\n",
      "Episode:976 meanR:384.9600 R:277.0000 loss:31.0077 exploreP:0.0100\n",
      "Episode:977 meanR:384.9600 R:500.0000 loss:2.3399 exploreP:0.0100\n",
      "Episode:978 meanR:384.9600 R:500.0000 loss:18.0387 exploreP:0.0100\n",
      "Episode:979 meanR:384.9600 R:500.0000 loss:16.4282 exploreP:0.0100\n",
      "Episode:980 meanR:384.9600 R:500.0000 loss:16.4856 exploreP:0.0100\n",
      "Episode:981 meanR:384.9600 R:500.0000 loss:15.7622 exploreP:0.0100\n",
      "Episode:982 meanR:384.9600 R:500.0000 loss:16.4347 exploreP:0.0100\n",
      "Episode:983 meanR:384.9600 R:500.0000 loss:11.3330 exploreP:0.0100\n",
      "Episode:984 meanR:384.9600 R:500.0000 loss:15.9927 exploreP:0.0100\n",
      "Episode:985 meanR:384.8300 R:487.0000 loss:11.7481 exploreP:0.0100\n",
      "Episode:986 meanR:384.8300 R:500.0000 loss:0.3643 exploreP:0.0100\n",
      "Episode:987 meanR:384.8300 R:500.0000 loss:13.7924 exploreP:0.0100\n",
      "Episode:988 meanR:384.8300 R:500.0000 loss:11.2078 exploreP:0.0100\n",
      "Episode:989 meanR:384.8300 R:500.0000 loss:13.8835 exploreP:0.0100\n",
      "Episode:990 meanR:384.8300 R:500.0000 loss:14.4044 exploreP:0.0100\n",
      "Episode:991 meanR:383.7400 R:391.0000 loss:20.1409 exploreP:0.0100\n",
      "Episode:992 meanR:383.7400 R:500.0000 loss:0.3931 exploreP:0.0100\n",
      "Episode:993 meanR:383.7800 R:341.0000 loss:28.0223 exploreP:0.0100\n",
      "Episode:994 meanR:387.7900 R:500.0000 loss:0.4170 exploreP:0.0100\n",
      "Episode:995 meanR:390.5700 R:500.0000 loss:18.0936 exploreP:0.0100\n",
      "Episode:996 meanR:391.0000 R:235.0000 loss:31.6162 exploreP:0.0100\n",
      "Episode:997 meanR:393.7500 R:500.0000 loss:0.4991 exploreP:0.0100\n",
      "Episode:998 meanR:391.1800 R:243.0000 loss:25.2920 exploreP:0.0100\n",
      "Episode:999 meanR:388.6800 R:250.0000 loss:0.9478 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1000 meanR:388.2000 R:192.0000 loss:3.4871 exploreP:0.0100\n",
      "Episode:1001 meanR:384.9000 R:170.0000 loss:2.0874 exploreP:0.0100\n",
      "Episode:1002 meanR:381.7900 R:189.0000 loss:0.9853 exploreP:0.0100\n",
      "Episode:1003 meanR:379.2100 R:242.0000 loss:0.5880 exploreP:0.0100\n",
      "Episode:1004 meanR:376.6900 R:248.0000 loss:4.2010 exploreP:0.0100\n",
      "Episode:1005 meanR:374.3100 R:262.0000 loss:6.2375 exploreP:0.0100\n",
      "Episode:1006 meanR:372.1200 R:281.0000 loss:5.3078 exploreP:0.0100\n",
      "Episode:1007 meanR:370.0200 R:290.0000 loss:0.7103 exploreP:0.0100\n",
      "Episode:1008 meanR:369.1700 R:415.0000 loss:0.8168 exploreP:0.0100\n",
      "Episode:1009 meanR:365.2800 R:111.0000 loss:7.5425 exploreP:0.0100\n",
      "Episode:1010 meanR:365.2800 R:500.0000 loss:8.0406 exploreP:0.0100\n",
      "Episode:1011 meanR:365.2800 R:500.0000 loss:16.6541 exploreP:0.0100\n",
      "Episode:1012 meanR:365.2800 R:500.0000 loss:11.9853 exploreP:0.0100\n",
      "Episode:1013 meanR:361.9100 R:97.0000 loss:50.9032 exploreP:0.0100\n",
      "Episode:1014 meanR:361.9100 R:500.0000 loss:5.4606 exploreP:0.0100\n",
      "Episode:1015 meanR:364.3200 R:500.0000 loss:16.3678 exploreP:0.0100\n",
      "Episode:1016 meanR:364.3200 R:500.0000 loss:15.3313 exploreP:0.0100\n",
      "Episode:1017 meanR:364.3200 R:500.0000 loss:15.0176 exploreP:0.0100\n",
      "Episode:1018 meanR:364.3200 R:500.0000 loss:16.9749 exploreP:0.0100\n",
      "Episode:1019 meanR:364.3200 R:500.0000 loss:15.6060 exploreP:0.0100\n",
      "Episode:1020 meanR:364.3200 R:500.0000 loss:14.3701 exploreP:0.0100\n",
      "Episode:1021 meanR:364.3200 R:500.0000 loss:12.4464 exploreP:0.0100\n",
      "Episode:1022 meanR:364.3200 R:500.0000 loss:15.4421 exploreP:0.0100\n",
      "Episode:1023 meanR:362.2100 R:289.0000 loss:15.8360 exploreP:0.0100\n",
      "Episode:1024 meanR:360.9200 R:371.0000 loss:1.0235 exploreP:0.0100\n",
      "Episode:1025 meanR:358.2500 R:233.0000 loss:0.7617 exploreP:0.0100\n",
      "Episode:1026 meanR:358.2500 R:500.0000 loss:0.4376 exploreP:0.0100\n",
      "Episode:1027 meanR:358.2500 R:500.0000 loss:10.7421 exploreP:0.0100\n",
      "Episode:1028 meanR:358.2500 R:500.0000 loss:15.5102 exploreP:0.0100\n",
      "Episode:1029 meanR:358.2500 R:500.0000 loss:13.6179 exploreP:0.0100\n",
      "Episode:1030 meanR:359.8300 R:283.0000 loss:21.2462 exploreP:0.0100\n",
      "Episode:1031 meanR:361.9200 R:308.0000 loss:6.8839 exploreP:0.0100\n",
      "Episode:1032 meanR:363.1400 R:211.0000 loss:2.2987 exploreP:0.0100\n",
      "Episode:1033 meanR:363.5800 R:130.0000 loss:4.6001 exploreP:0.0100\n",
      "Episode:1034 meanR:364.0500 R:123.0000 loss:1.5834 exploreP:0.0100\n",
      "Episode:1035 meanR:368.3700 R:500.0000 loss:0.9247 exploreP:0.0100\n",
      "Episode:1036 meanR:372.6200 R:500.0000 loss:19.4835 exploreP:0.0100\n",
      "Episode:1037 meanR:376.8600 R:500.0000 loss:15.9620 exploreP:0.0100\n",
      "Episode:1038 meanR:381.0600 R:500.0000 loss:19.8786 exploreP:0.0100\n",
      "Episode:1039 meanR:385.2300 R:500.0000 loss:20.4757 exploreP:0.0100\n",
      "Episode:1040 meanR:389.4400 R:500.0000 loss:21.4371 exploreP:0.0100\n",
      "Episode:1041 meanR:393.5500 R:500.0000 loss:18.7579 exploreP:0.0100\n",
      "Episode:1042 meanR:397.6400 R:500.0000 loss:16.2122 exploreP:0.0100\n",
      "Episode:1043 meanR:401.6200 R:500.0000 loss:15.9206 exploreP:0.0100\n",
      "Episode:1044 meanR:400.6100 R:25.0000 loss:76.3122 exploreP:0.0100\n",
      "Episode:1045 meanR:399.2700 R:24.0000 loss:135.7243 exploreP:0.0100\n",
      "Episode:1046 meanR:401.4400 R:378.0000 loss:20.6691 exploreP:0.0100\n",
      "Episode:1047 meanR:401.9100 R:273.0000 loss:2.2691 exploreP:0.0100\n",
      "Episode:1048 meanR:401.9100 R:500.0000 loss:8.6574 exploreP:0.0100\n",
      "Episode:1049 meanR:398.7800 R:187.0000 loss:33.2409 exploreP:0.0100\n",
      "Episode:1050 meanR:398.7800 R:500.0000 loss:1.0345 exploreP:0.0100\n",
      "Episode:1051 meanR:395.4500 R:167.0000 loss:37.7576 exploreP:0.0100\n",
      "Episode:1052 meanR:391.5200 R:107.0000 loss:43.3794 exploreP:0.0100\n",
      "Episode:1053 meanR:387.6800 R:116.0000 loss:4.7321 exploreP:0.0100\n",
      "Episode:1054 meanR:384.0600 R:138.0000 loss:3.9456 exploreP:0.0100\n",
      "Episode:1055 meanR:380.7000 R:164.0000 loss:1.3045 exploreP:0.0100\n",
      "Episode:1056 meanR:377.4400 R:174.0000 loss:4.6992 exploreP:0.0100\n",
      "Episode:1057 meanR:374.3100 R:187.0000 loss:2.8142 exploreP:0.0100\n",
      "Episode:1058 meanR:372.8800 R:226.0000 loss:1.7303 exploreP:0.0100\n",
      "Episode:1059 meanR:372.8800 R:500.0000 loss:0.3518 exploreP:0.0100\n",
      "Episode:1060 meanR:369.8200 R:194.0000 loss:2.0125 exploreP:0.0100\n",
      "Episode:1061 meanR:369.7200 R:267.0000 loss:8.9455 exploreP:0.0100\n",
      "Episode:1062 meanR:369.7200 R:500.0000 loss:0.4975 exploreP:0.0100\n",
      "Episode:1063 meanR:366.6500 R:193.0000 loss:50.0516 exploreP:0.0100\n",
      "Episode:1064 meanR:362.6800 R:103.0000 loss:6.8371 exploreP:0.0100\n",
      "Episode:1065 meanR:361.9200 R:161.0000 loss:2.9413 exploreP:0.0100\n",
      "Episode:1066 meanR:358.8000 R:188.0000 loss:1.5999 exploreP:0.0100\n",
      "Episode:1067 meanR:359.0000 R:239.0000 loss:1.5065 exploreP:0.0100\n",
      "Episode:1068 meanR:356.0800 R:208.0000 loss:5.6498 exploreP:0.0100\n",
      "Episode:1069 meanR:352.8400 R:176.0000 loss:0.6978 exploreP:0.0100\n",
      "Episode:1070 meanR:353.4900 R:308.0000 loss:0.3692 exploreP:0.0100\n",
      "Episode:1071 meanR:355.7800 R:500.0000 loss:0.3678 exploreP:0.0100\n",
      "Episode:1072 meanR:359.5900 R:500.0000 loss:11.8690 exploreP:0.0100\n",
      "Episode:1073 meanR:363.7200 R:500.0000 loss:11.8793 exploreP:0.0100\n",
      "Episode:1074 meanR:360.0600 R:134.0000 loss:48.1112 exploreP:0.0100\n",
      "Episode:1075 meanR:360.0600 R:500.0000 loss:7.4286 exploreP:0.0100\n",
      "Episode:1076 meanR:362.2900 R:500.0000 loss:17.0246 exploreP:0.0100\n",
      "Episode:1077 meanR:362.2900 R:500.0000 loss:14.2106 exploreP:0.0100\n",
      "Episode:1078 meanR:362.2900 R:500.0000 loss:12.1094 exploreP:0.0100\n",
      "Episode:1079 meanR:362.2900 R:500.0000 loss:16.3073 exploreP:0.0100\n",
      "Episode:1080 meanR:362.2300 R:494.0000 loss:14.4396 exploreP:0.0100\n",
      "Episode:1081 meanR:362.2300 R:500.0000 loss:3.6378 exploreP:0.0100\n",
      "Episode:1082 meanR:362.2300 R:500.0000 loss:13.3177 exploreP:0.0100\n",
      "Episode:1083 meanR:362.2300 R:500.0000 loss:8.5422 exploreP:0.0100\n",
      "Episode:1084 meanR:362.2300 R:500.0000 loss:11.5119 exploreP:0.0100\n",
      "Episode:1085 meanR:362.3600 R:500.0000 loss:17.3981 exploreP:0.0100\n",
      "Episode:1086 meanR:359.0100 R:165.0000 loss:41.8523 exploreP:0.0100\n",
      "Episode:1087 meanR:355.9100 R:190.0000 loss:1.0423 exploreP:0.0100\n",
      "Episode:1088 meanR:353.4400 R:253.0000 loss:0.8547 exploreP:0.0100\n",
      "Episode:1089 meanR:350.7100 R:227.0000 loss:1.7726 exploreP:0.0100\n",
      "Episode:1090 meanR:348.7100 R:300.0000 loss:1.3486 exploreP:0.0100\n",
      "Episode:1091 meanR:349.8000 R:500.0000 loss:8.0757 exploreP:0.0100\n",
      "Episode:1092 meanR:349.8000 R:500.0000 loss:12.5839 exploreP:0.0100\n",
      "Episode:1093 meanR:351.3900 R:500.0000 loss:17.6699 exploreP:0.0100\n",
      "Episode:1094 meanR:351.3900 R:500.0000 loss:16.5706 exploreP:0.0100\n",
      "Episode:1095 meanR:351.3900 R:500.0000 loss:11.1457 exploreP:0.0100\n",
      "Episode:1096 meanR:354.0400 R:500.0000 loss:19.1423 exploreP:0.0100\n",
      "Episode:1097 meanR:349.3400 R:30.0000 loss:58.3687 exploreP:0.0100\n",
      "Episode:1098 meanR:351.9100 R:500.0000 loss:13.2838 exploreP:0.0100\n",
      "Episode:1099 meanR:349.5300 R:12.0000 loss:80.8416 exploreP:0.0100\n",
      "Episode:1100 meanR:351.5600 R:395.0000 loss:28.7874 exploreP:0.0100\n",
      "Episode:1101 meanR:353.2200 R:336.0000 loss:7.3225 exploreP:0.0100\n",
      "Episode:1102 meanR:356.3300 R:500.0000 loss:0.5412 exploreP:0.0100\n",
      "Episode:1103 meanR:358.9100 R:500.0000 loss:2.9781 exploreP:0.0100\n",
      "Episode:1104 meanR:361.4300 R:500.0000 loss:17.9837 exploreP:0.0100\n",
      "Episode:1105 meanR:363.8100 R:500.0000 loss:13.1011 exploreP:0.0100\n",
      "Episode:1106 meanR:366.0000 R:500.0000 loss:20.4457 exploreP:0.0100\n",
      "Episode:1107 meanR:368.1000 R:500.0000 loss:18.8978 exploreP:0.0100\n",
      "Episode:1108 meanR:368.9500 R:500.0000 loss:15.0116 exploreP:0.0100\n",
      "Episode:1109 meanR:372.8400 R:500.0000 loss:16.1940 exploreP:0.0100\n",
      "Episode:1110 meanR:372.8400 R:500.0000 loss:17.6897 exploreP:0.0100\n",
      "Episode:1111 meanR:372.8400 R:500.0000 loss:17.7507 exploreP:0.0100\n",
      "Episode:1112 meanR:372.8400 R:500.0000 loss:16.8528 exploreP:0.0100\n",
      "Episode:1113 meanR:376.8700 R:500.0000 loss:14.7575 exploreP:0.0100\n",
      "Episode:1114 meanR:376.8700 R:500.0000 loss:16.1595 exploreP:0.0100\n",
      "Episode:1115 meanR:376.8700 R:500.0000 loss:18.2113 exploreP:0.0100\n",
      "Episode:1116 meanR:376.8700 R:500.0000 loss:14.4090 exploreP:0.0100\n",
      "Episode:1117 meanR:376.8700 R:500.0000 loss:16.0333 exploreP:0.0100\n",
      "Episode:1118 meanR:375.4500 R:358.0000 loss:24.2248 exploreP:0.0100\n",
      "Episode:1119 meanR:375.4500 R:500.0000 loss:1.8314 exploreP:0.0100\n",
      "Episode:1120 meanR:375.4500 R:500.0000 loss:15.4126 exploreP:0.0100\n",
      "Episode:1121 meanR:375.4500 R:500.0000 loss:8.1128 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1122 meanR:375.4500 R:500.0000 loss:19.1108 exploreP:0.0100\n",
      "Episode:1123 meanR:377.5600 R:500.0000 loss:21.6712 exploreP:0.0100\n",
      "Episode:1124 meanR:378.8500 R:500.0000 loss:21.1641 exploreP:0.0100\n",
      "Episode:1125 meanR:381.5200 R:500.0000 loss:14.2696 exploreP:0.0100\n",
      "Episode:1126 meanR:381.5200 R:500.0000 loss:19.9728 exploreP:0.0100\n",
      "Episode:1127 meanR:381.5200 R:500.0000 loss:13.1542 exploreP:0.0100\n",
      "Episode:1128 meanR:381.5200 R:500.0000 loss:16.9659 exploreP:0.0100\n",
      "Episode:1129 meanR:381.5200 R:500.0000 loss:21.1708 exploreP:0.0100\n",
      "Episode:1130 meanR:383.6900 R:500.0000 loss:19.1455 exploreP:0.0100\n",
      "Episode:1131 meanR:385.6100 R:500.0000 loss:17.0294 exploreP:0.0100\n",
      "Episode:1132 meanR:388.5000 R:500.0000 loss:15.7526 exploreP:0.0100\n",
      "Episode:1133 meanR:392.2000 R:500.0000 loss:14.2289 exploreP:0.0100\n",
      "Episode:1134 meanR:395.9700 R:500.0000 loss:17.7862 exploreP:0.0100\n",
      "Episode:1135 meanR:395.9700 R:500.0000 loss:16.2161 exploreP:0.0100\n",
      "Episode:1136 meanR:395.9700 R:500.0000 loss:16.2067 exploreP:0.0100\n",
      "Episode:1137 meanR:395.9700 R:500.0000 loss:15.8834 exploreP:0.0100\n",
      "Episode:1138 meanR:395.9700 R:500.0000 loss:16.6115 exploreP:0.0100\n",
      "Episode:1139 meanR:395.9700 R:500.0000 loss:16.2433 exploreP:0.0100\n",
      "Episode:1140 meanR:395.9700 R:500.0000 loss:15.9012 exploreP:0.0100\n",
      "Episode:1141 meanR:392.3100 R:134.0000 loss:59.9837 exploreP:0.0100\n",
      "Episode:1142 meanR:392.3100 R:500.0000 loss:7.1110 exploreP:0.0100\n",
      "Episode:1143 meanR:392.3100 R:500.0000 loss:8.0951 exploreP:0.0100\n",
      "Episode:1144 meanR:397.0600 R:500.0000 loss:15.9867 exploreP:0.0100\n",
      "Episode:1145 meanR:401.8200 R:500.0000 loss:15.9501 exploreP:0.0100\n",
      "Episode:1146 meanR:403.0400 R:500.0000 loss:16.5398 exploreP:0.0100\n",
      "Episode:1147 meanR:405.3100 R:500.0000 loss:18.4601 exploreP:0.0100\n",
      "Episode:1148 meanR:405.3100 R:500.0000 loss:15.1523 exploreP:0.0100\n",
      "Episode:1149 meanR:408.4400 R:500.0000 loss:12.7816 exploreP:0.0100\n",
      "Episode:1150 meanR:408.4400 R:500.0000 loss:18.1141 exploreP:0.0100\n",
      "Episode:1151 meanR:411.7700 R:500.0000 loss:11.5633 exploreP:0.0100\n",
      "Episode:1152 meanR:415.7000 R:500.0000 loss:11.3856 exploreP:0.0100\n",
      "Episode:1153 meanR:419.5400 R:500.0000 loss:19.4500 exploreP:0.0100\n",
      "Episode:1154 meanR:423.1600 R:500.0000 loss:16.4565 exploreP:0.0100\n",
      "Episode:1155 meanR:426.5200 R:500.0000 loss:16.5498 exploreP:0.0100\n",
      "Episode:1156 meanR:429.7800 R:500.0000 loss:7.5169 exploreP:0.0100\n",
      "Episode:1157 meanR:432.9100 R:500.0000 loss:17.7735 exploreP:0.0100\n",
      "Episode:1158 meanR:435.6500 R:500.0000 loss:14.5757 exploreP:0.0100\n",
      "Episode:1159 meanR:435.6500 R:500.0000 loss:15.3841 exploreP:0.0100\n",
      "Episode:1160 meanR:435.3200 R:161.0000 loss:35.8142 exploreP:0.0100\n",
      "Episode:1161 meanR:437.6500 R:500.0000 loss:3.3327 exploreP:0.0100\n",
      "Episode:1162 meanR:437.6500 R:500.0000 loss:20.5253 exploreP:0.0100\n",
      "Episode:1163 meanR:440.7200 R:500.0000 loss:16.9784 exploreP:0.0100\n",
      "Episode:1164 meanR:444.6900 R:500.0000 loss:14.0169 exploreP:0.0100\n",
      "Episode:1165 meanR:447.2000 R:412.0000 loss:20.8520 exploreP:0.0100\n",
      "Episode:1166 meanR:450.3200 R:500.0000 loss:10.0791 exploreP:0.0100\n",
      "Episode:1167 meanR:452.6800 R:475.0000 loss:14.5652 exploreP:0.0100\n",
      "Episode:1168 meanR:455.6000 R:500.0000 loss:2.8575 exploreP:0.0100\n",
      "Episode:1169 meanR:456.0800 R:224.0000 loss:17.7223 exploreP:0.0100\n",
      "Episode:1170 meanR:457.7100 R:471.0000 loss:1.5599 exploreP:0.0100\n",
      "Episode:1171 meanR:457.7100 R:500.0000 loss:4.0489 exploreP:0.0100\n",
      "Episode:1172 meanR:457.7100 R:500.0000 loss:16.7605 exploreP:0.0100\n",
      "Episode:1173 meanR:454.6900 R:198.0000 loss:47.4627 exploreP:0.0100\n",
      "Episode:1174 meanR:455.0900 R:174.0000 loss:3.6493 exploreP:0.0100\n",
      "Episode:1175 meanR:454.7800 R:469.0000 loss:1.4308 exploreP:0.0100\n",
      "Episode:1176 meanR:454.7800 R:500.0000 loss:1.4851 exploreP:0.0100\n",
      "Episode:1177 meanR:454.7800 R:500.0000 loss:16.2817 exploreP:0.0100\n",
      "Episode:1178 meanR:454.7800 R:500.0000 loss:6.2024 exploreP:0.0100\n",
      "Episode:1179 meanR:454.7800 R:500.0000 loss:19.0299 exploreP:0.0100\n",
      "Episode:1180 meanR:454.8400 R:500.0000 loss:20.3797 exploreP:0.0100\n",
      "Episode:1181 meanR:454.8400 R:500.0000 loss:17.6500 exploreP:0.0100\n",
      "Episode:1182 meanR:454.8400 R:500.0000 loss:17.1626 exploreP:0.0100\n",
      "Episode:1183 meanR:454.8400 R:500.0000 loss:18.0672 exploreP:0.0100\n",
      "Episode:1184 meanR:454.8400 R:500.0000 loss:17.1284 exploreP:0.0100\n",
      "Episode:1185 meanR:454.8400 R:500.0000 loss:10.4342 exploreP:0.0100\n",
      "Episode:1186 meanR:458.1900 R:500.0000 loss:10.5294 exploreP:0.0100\n",
      "Episode:1187 meanR:458.2600 R:197.0000 loss:46.7253 exploreP:0.0100\n",
      "Episode:1188 meanR:457.3700 R:164.0000 loss:1.3716 exploreP:0.0100\n",
      "Episode:1189 meanR:456.7400 R:164.0000 loss:3.4083 exploreP:0.0100\n",
      "Episode:1190 meanR:455.3600 R:162.0000 loss:2.1775 exploreP:0.0100\n",
      "Episode:1191 meanR:452.2200 R:186.0000 loss:1.5194 exploreP:0.0100\n",
      "Episode:1192 meanR:449.1800 R:196.0000 loss:1.4808 exploreP:0.0100\n",
      "Episode:1193 meanR:446.1700 R:199.0000 loss:0.6106 exploreP:0.0100\n",
      "Episode:1194 meanR:444.2100 R:304.0000 loss:0.5351 exploreP:0.0100\n",
      "Episode:1195 meanR:442.6300 R:342.0000 loss:6.5545 exploreP:0.0100\n",
      "Episode:1196 meanR:440.7200 R:309.0000 loss:18.7085 exploreP:0.0100\n",
      "Episode:1197 meanR:445.4200 R:500.0000 loss:0.8971 exploreP:0.0100\n",
      "Episode:1198 meanR:445.4200 R:500.0000 loss:16.1057 exploreP:0.0100\n",
      "Episode:1199 meanR:448.2000 R:290.0000 loss:35.7424 exploreP:0.0100\n",
      "Episode:1200 meanR:449.2500 R:500.0000 loss:3.5323 exploreP:0.0100\n",
      "Episode:1201 meanR:450.8900 R:500.0000 loss:16.6513 exploreP:0.0100\n",
      "Episode:1202 meanR:447.9600 R:207.0000 loss:36.4410 exploreP:0.0100\n",
      "Episode:1203 meanR:444.7500 R:179.0000 loss:3.1070 exploreP:0.0100\n",
      "Episode:1204 meanR:441.6700 R:192.0000 loss:5.6625 exploreP:0.0100\n",
      "Episode:1205 meanR:438.6600 R:199.0000 loss:2.6736 exploreP:0.0100\n",
      "Episode:1206 meanR:435.7700 R:211.0000 loss:1.8806 exploreP:0.0100\n",
      "Episode:1207 meanR:432.9200 R:215.0000 loss:1.6491 exploreP:0.0100\n",
      "Episode:1208 meanR:429.9400 R:202.0000 loss:1.6424 exploreP:0.0100\n",
      "Episode:1209 meanR:426.9800 R:204.0000 loss:1.2590 exploreP:0.0100\n",
      "Episode:1210 meanR:426.0300 R:405.0000 loss:2.6146 exploreP:0.0100\n",
      "Episode:1211 meanR:426.0300 R:500.0000 loss:1.9461 exploreP:0.0100\n",
      "Episode:1212 meanR:426.0300 R:500.0000 loss:15.2356 exploreP:0.0100\n",
      "Episode:1213 meanR:423.5000 R:247.0000 loss:28.4827 exploreP:0.0100\n",
      "Episode:1214 meanR:423.5000 R:500.0000 loss:2.4445 exploreP:0.0100\n",
      "Episode:1215 meanR:423.5000 R:500.0000 loss:16.1968 exploreP:0.0100\n",
      "Episode:1216 meanR:423.5000 R:500.0000 loss:16.4022 exploreP:0.0100\n",
      "Episode:1217 meanR:423.5000 R:500.0000 loss:15.7603 exploreP:0.0100\n",
      "Episode:1218 meanR:424.9200 R:500.0000 loss:15.4425 exploreP:0.0100\n",
      "Episode:1219 meanR:424.9200 R:500.0000 loss:15.5278 exploreP:0.0100\n",
      "Episode:1220 meanR:424.9200 R:500.0000 loss:15.2662 exploreP:0.0100\n",
      "Episode:1221 meanR:424.9200 R:500.0000 loss:15.2443 exploreP:0.0100\n",
      "Episode:1222 meanR:424.9200 R:500.0000 loss:16.1577 exploreP:0.0100\n",
      "Episode:1223 meanR:424.9200 R:500.0000 loss:15.8968 exploreP:0.0100\n",
      "Episode:1224 meanR:424.9200 R:500.0000 loss:15.7854 exploreP:0.0100\n",
      "Episode:1225 meanR:424.9200 R:500.0000 loss:17.4362 exploreP:0.0100\n",
      "Episode:1226 meanR:424.9200 R:500.0000 loss:16.8995 exploreP:0.0100\n",
      "Episode:1227 meanR:424.9200 R:500.0000 loss:16.6041 exploreP:0.0100\n",
      "Episode:1228 meanR:424.9200 R:500.0000 loss:16.5536 exploreP:0.0100\n",
      "Episode:1229 meanR:424.9200 R:500.0000 loss:16.2073 exploreP:0.0100\n",
      "Episode:1230 meanR:424.9200 R:500.0000 loss:15.9557 exploreP:0.0100\n",
      "Episode:1231 meanR:424.9200 R:500.0000 loss:16.0357 exploreP:0.0100\n",
      "Episode:1232 meanR:424.9200 R:500.0000 loss:15.5502 exploreP:0.0100\n",
      "Episode:1233 meanR:424.9200 R:500.0000 loss:15.5680 exploreP:0.0100\n",
      "Episode:1234 meanR:424.9200 R:500.0000 loss:15.3068 exploreP:0.0100\n",
      "Episode:1235 meanR:424.9200 R:500.0000 loss:14.4156 exploreP:0.0100\n",
      "Episode:1236 meanR:424.9200 R:500.0000 loss:15.4577 exploreP:0.0100\n",
      "Episode:1237 meanR:424.9200 R:500.0000 loss:15.3156 exploreP:0.0100\n",
      "Episode:1238 meanR:424.9200 R:500.0000 loss:15.0530 exploreP:0.0100\n",
      "Episode:1239 meanR:424.9200 R:500.0000 loss:14.8823 exploreP:0.0100\n",
      "Episode:1240 meanR:424.9200 R:500.0000 loss:15.1003 exploreP:0.0100\n",
      "Episode:1241 meanR:424.9500 R:137.0000 loss:54.4102 exploreP:0.0100\n",
      "Episode:1242 meanR:423.9900 R:404.0000 loss:48.2216 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1243 meanR:420.2900 R:130.0000 loss:7.9710 exploreP:0.0100\n",
      "Episode:1244 meanR:416.4900 R:120.0000 loss:11.9472 exploreP:0.0100\n",
      "Episode:1245 meanR:412.5600 R:107.0000 loss:10.1851 exploreP:0.0100\n",
      "Episode:1246 meanR:408.3700 R:81.0000 loss:9.9882 exploreP:0.0100\n",
      "Episode:1247 meanR:408.3700 R:500.0000 loss:15.7607 exploreP:0.0100\n",
      "Episode:1248 meanR:408.3700 R:500.0000 loss:25.6031 exploreP:0.0100\n",
      "Episode:1249 meanR:408.3700 R:500.0000 loss:16.3267 exploreP:0.0100\n",
      "Episode:1250 meanR:408.3700 R:500.0000 loss:14.5843 exploreP:0.0100\n",
      "Episode:1251 meanR:408.3700 R:500.0000 loss:14.9271 exploreP:0.0100\n",
      "Episode:1252 meanR:408.3700 R:500.0000 loss:15.5738 exploreP:0.0100\n",
      "Episode:1253 meanR:408.3700 R:500.0000 loss:15.4466 exploreP:0.0100\n",
      "Episode:1254 meanR:408.3700 R:500.0000 loss:15.0850 exploreP:0.0100\n",
      "Episode:1255 meanR:408.3700 R:500.0000 loss:14.6999 exploreP:0.0100\n",
      "Episode:1256 meanR:408.3700 R:500.0000 loss:14.7835 exploreP:0.0100\n",
      "Episode:1257 meanR:408.3700 R:500.0000 loss:14.2647 exploreP:0.0100\n",
      "Episode:1258 meanR:408.3700 R:500.0000 loss:13.6228 exploreP:0.0100\n",
      "Episode:1259 meanR:408.3700 R:500.0000 loss:13.8950 exploreP:0.0100\n",
      "Episode:1260 meanR:411.7600 R:500.0000 loss:14.1759 exploreP:0.0100\n",
      "Episode:1261 meanR:411.7600 R:500.0000 loss:13.3481 exploreP:0.0100\n",
      "Episode:1262 meanR:408.9800 R:222.0000 loss:27.1394 exploreP:0.0100\n",
      "Episode:1263 meanR:405.4500 R:147.0000 loss:5.7253 exploreP:0.0100\n",
      "Episode:1264 meanR:405.4500 R:500.0000 loss:2.4864 exploreP:0.0100\n",
      "Episode:1265 meanR:406.3300 R:500.0000 loss:3.8330 exploreP:0.0100\n",
      "Episode:1266 meanR:406.3300 R:500.0000 loss:16.7294 exploreP:0.0100\n",
      "Episode:1267 meanR:406.5800 R:500.0000 loss:20.1908 exploreP:0.0100\n",
      "Episode:1268 meanR:406.5800 R:500.0000 loss:18.4465 exploreP:0.0100\n",
      "Episode:1269 meanR:409.3400 R:500.0000 loss:14.3808 exploreP:0.0100\n",
      "Episode:1270 meanR:409.6300 R:500.0000 loss:15.9069 exploreP:0.0100\n",
      "Episode:1271 meanR:409.6300 R:500.0000 loss:16.4670 exploreP:0.0100\n",
      "Episode:1272 meanR:409.6300 R:500.0000 loss:15.0560 exploreP:0.0100\n",
      "Episode:1273 meanR:412.6500 R:500.0000 loss:16.9287 exploreP:0.0100\n",
      "Episode:1274 meanR:415.9100 R:500.0000 loss:14.4861 exploreP:0.0100\n",
      "Episode:1275 meanR:416.2200 R:500.0000 loss:16.0372 exploreP:0.0100\n",
      "Episode:1276 meanR:416.2200 R:500.0000 loss:17.3441 exploreP:0.0100\n",
      "Episode:1277 meanR:416.2200 R:500.0000 loss:19.0282 exploreP:0.0100\n",
      "Episode:1278 meanR:416.2200 R:500.0000 loss:18.3815 exploreP:0.0100\n",
      "Episode:1279 meanR:416.2200 R:500.0000 loss:18.0547 exploreP:0.0100\n",
      "Episode:1280 meanR:416.2200 R:500.0000 loss:16.8455 exploreP:0.0100\n",
      "Episode:1281 meanR:416.2200 R:500.0000 loss:14.8886 exploreP:0.0100\n",
      "Episode:1282 meanR:416.2200 R:500.0000 loss:17.1178 exploreP:0.0100\n",
      "Episode:1283 meanR:416.2200 R:500.0000 loss:15.5911 exploreP:0.0100\n",
      "Episode:1284 meanR:416.2200 R:500.0000 loss:27.8211 exploreP:0.0100\n",
      "Episode:1285 meanR:416.2200 R:500.0000 loss:15.3545 exploreP:0.0100\n",
      "Episode:1286 meanR:416.2200 R:500.0000 loss:17.3843 exploreP:0.0100\n",
      "Episode:1287 meanR:419.2500 R:500.0000 loss:17.3620 exploreP:0.0100\n",
      "Episode:1288 meanR:422.6100 R:500.0000 loss:16.9578 exploreP:0.0100\n",
      "Episode:1289 meanR:425.9700 R:500.0000 loss:16.5420 exploreP:0.0100\n",
      "Episode:1290 meanR:429.3500 R:500.0000 loss:16.4088 exploreP:0.0100\n",
      "Episode:1291 meanR:432.4900 R:500.0000 loss:15.1012 exploreP:0.0100\n",
      "Episode:1292 meanR:435.5300 R:500.0000 loss:14.0687 exploreP:0.0100\n",
      "Episode:1293 meanR:438.5400 R:500.0000 loss:13.1550 exploreP:0.0100\n",
      "Episode:1294 meanR:440.5000 R:500.0000 loss:14.1314 exploreP:0.0100\n",
      "Episode:1295 meanR:442.0800 R:500.0000 loss:18.0414 exploreP:0.0100\n",
      "Episode:1296 meanR:443.9900 R:500.0000 loss:17.5156 exploreP:0.0100\n",
      "Episode:1297 meanR:443.9900 R:500.0000 loss:16.1351 exploreP:0.0100\n",
      "Episode:1298 meanR:443.9900 R:500.0000 loss:12.6561 exploreP:0.0100\n",
      "Episode:1299 meanR:446.0900 R:500.0000 loss:15.1243 exploreP:0.0100\n",
      "Episode:1300 meanR:446.0900 R:500.0000 loss:12.8600 exploreP:0.0100\n",
      "Episode:1301 meanR:446.0900 R:500.0000 loss:13.3839 exploreP:0.0100\n",
      "Episode:1302 meanR:449.0200 R:500.0000 loss:14.3435 exploreP:0.0100\n",
      "Episode:1303 meanR:452.2300 R:500.0000 loss:15.6072 exploreP:0.0100\n",
      "Episode:1304 meanR:455.3100 R:500.0000 loss:15.8778 exploreP:0.0100\n",
      "Episode:1305 meanR:458.3200 R:500.0000 loss:15.8724 exploreP:0.0100\n",
      "Episode:1306 meanR:461.2100 R:500.0000 loss:12.3834 exploreP:0.0100\n",
      "Episode:1307 meanR:464.0600 R:500.0000 loss:17.4656 exploreP:0.0100\n",
      "Episode:1308 meanR:467.0400 R:500.0000 loss:16.4973 exploreP:0.0100\n",
      "Episode:1309 meanR:467.8200 R:282.0000 loss:27.6364 exploreP:0.0100\n",
      "Episode:1310 meanR:468.7700 R:500.0000 loss:15.0803 exploreP:0.0100\n",
      "Episode:1311 meanR:468.7700 R:500.0000 loss:16.2735 exploreP:0.0100\n",
      "Episode:1312 meanR:468.7700 R:500.0000 loss:11.8308 exploreP:0.0100\n",
      "Episode:1313 meanR:471.3000 R:500.0000 loss:5.8165 exploreP:0.0100\n",
      "Episode:1314 meanR:471.3000 R:500.0000 loss:6.1548 exploreP:0.0100\n",
      "Episode:1315 meanR:471.3000 R:500.0000 loss:7.8281 exploreP:0.0100\n",
      "Episode:1316 meanR:471.3000 R:500.0000 loss:10.5370 exploreP:0.0100\n",
      "Episode:1317 meanR:471.3000 R:500.0000 loss:18.1669 exploreP:0.0100\n",
      "Episode:1318 meanR:471.3000 R:500.0000 loss:16.8669 exploreP:0.0100\n",
      "Episode:1319 meanR:471.3000 R:500.0000 loss:17.8162 exploreP:0.0100\n",
      "Episode:1320 meanR:471.3000 R:500.0000 loss:18.7176 exploreP:0.0100\n",
      "Episode:1321 meanR:471.3000 R:500.0000 loss:20.0448 exploreP:0.0100\n",
      "Episode:1322 meanR:471.3000 R:500.0000 loss:18.9147 exploreP:0.0100\n",
      "Episode:1323 meanR:471.3000 R:500.0000 loss:17.1105 exploreP:0.0100\n",
      "Episode:1324 meanR:471.3000 R:500.0000 loss:17.4804 exploreP:0.0100\n",
      "Episode:1325 meanR:471.3000 R:500.0000 loss:15.5660 exploreP:0.0100\n",
      "Episode:1326 meanR:471.3000 R:500.0000 loss:16.8227 exploreP:0.0100\n",
      "Episode:1327 meanR:471.3000 R:500.0000 loss:17.3085 exploreP:0.0100\n",
      "Episode:1328 meanR:471.3000 R:500.0000 loss:16.1981 exploreP:0.0100\n",
      "Episode:1329 meanR:471.3000 R:500.0000 loss:40.7651 exploreP:0.0100\n",
      "Episode:1330 meanR:471.3000 R:500.0000 loss:18.1589 exploreP:0.0100\n",
      "Episode:1331 meanR:471.3000 R:500.0000 loss:17.6905 exploreP:0.0100\n",
      "Episode:1332 meanR:471.3000 R:500.0000 loss:16.5781 exploreP:0.0100\n",
      "Episode:1333 meanR:471.3000 R:500.0000 loss:16.2404 exploreP:0.0100\n",
      "Episode:1334 meanR:471.3000 R:500.0000 loss:16.4105 exploreP:0.0100\n",
      "Episode:1335 meanR:471.3000 R:500.0000 loss:15.7010 exploreP:0.0100\n",
      "Episode:1336 meanR:471.3000 R:500.0000 loss:15.5747 exploreP:0.0100\n",
      "Episode:1337 meanR:471.3000 R:500.0000 loss:15.8406 exploreP:0.0100\n",
      "Episode:1338 meanR:471.3000 R:500.0000 loss:15.1814 exploreP:0.0100\n",
      "Episode:1339 meanR:471.3000 R:500.0000 loss:15.5406 exploreP:0.0100\n",
      "Episode:1340 meanR:471.3000 R:500.0000 loss:15.7844 exploreP:0.0100\n",
      "Episode:1341 meanR:474.9300 R:500.0000 loss:16.3289 exploreP:0.0100\n",
      "Episode:1342 meanR:475.8900 R:500.0000 loss:16.5446 exploreP:0.0100\n",
      "Episode:1343 meanR:479.5900 R:500.0000 loss:15.7734 exploreP:0.0100\n",
      "Episode:1344 meanR:483.3900 R:500.0000 loss:15.5022 exploreP:0.0100\n",
      "Episode:1345 meanR:487.3200 R:500.0000 loss:15.4726 exploreP:0.0100\n",
      "Episode:1346 meanR:491.5100 R:500.0000 loss:15.4545 exploreP:0.0100\n",
      "Episode:1347 meanR:491.5100 R:500.0000 loss:15.7860 exploreP:0.0100\n",
      "Episode:1348 meanR:491.5100 R:500.0000 loss:17.0034 exploreP:0.0100\n",
      "Episode:1349 meanR:491.5100 R:500.0000 loss:24.4165 exploreP:0.0100\n",
      "Episode:1350 meanR:491.5100 R:500.0000 loss:20.5715 exploreP:0.0100\n",
      "Episode:1351 meanR:491.5100 R:500.0000 loss:20.0716 exploreP:0.0100\n",
      "Episode:1352 meanR:491.5100 R:500.0000 loss:21.5191 exploreP:0.0100\n",
      "Episode:1353 meanR:491.5100 R:500.0000 loss:21.4883 exploreP:0.0100\n",
      "Episode:1354 meanR:491.5100 R:500.0000 loss:22.5422 exploreP:0.0100\n",
      "Episode:1355 meanR:491.5100 R:500.0000 loss:20.2107 exploreP:0.0100\n",
      "Episode:1356 meanR:491.5100 R:500.0000 loss:18.6402 exploreP:0.0100\n",
      "Episode:1357 meanR:491.5100 R:500.0000 loss:16.7492 exploreP:0.0100\n",
      "Episode:1358 meanR:491.5100 R:500.0000 loss:15.6274 exploreP:0.0100\n",
      "Episode:1359 meanR:491.5100 R:500.0000 loss:15.1845 exploreP:0.0100\n",
      "Episode:1360 meanR:491.5100 R:500.0000 loss:15.0667 exploreP:0.0100\n",
      "Episode:1361 meanR:491.5100 R:500.0000 loss:14.8717 exploreP:0.0100\n",
      "Episode:1362 meanR:494.2900 R:500.0000 loss:15.5258 exploreP:0.0100\n",
      "Episode:1363 meanR:497.8200 R:500.0000 loss:16.9312 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1364 meanR:497.8200 R:500.0000 loss:15.9479 exploreP:0.0100\n",
      "Episode:1365 meanR:497.8200 R:500.0000 loss:16.1805 exploreP:0.0100\n",
      "Episode:1366 meanR:497.8200 R:500.0000 loss:17.3289 exploreP:0.0100\n",
      "Episode:1367 meanR:497.8200 R:500.0000 loss:17.3300 exploreP:0.0100\n",
      "Episode:1368 meanR:497.8200 R:500.0000 loss:18.2305 exploreP:0.0100\n",
      "Episode:1369 meanR:497.8200 R:500.0000 loss:16.0975 exploreP:0.0100\n",
      "Episode:1370 meanR:497.8200 R:500.0000 loss:19.5856 exploreP:0.0100\n",
      "Episode:1371 meanR:497.8200 R:500.0000 loss:17.9754 exploreP:0.0100\n",
      "Episode:1372 meanR:497.8200 R:500.0000 loss:16.2737 exploreP:0.0100\n",
      "Episode:1373 meanR:497.8200 R:500.0000 loss:13.8482 exploreP:0.0100\n",
      "Episode:1374 meanR:497.8200 R:500.0000 loss:18.1417 exploreP:0.0100\n",
      "Episode:1375 meanR:497.8200 R:500.0000 loss:16.2270 exploreP:0.0100\n",
      "Episode:1376 meanR:497.8200 R:500.0000 loss:13.8687 exploreP:0.0100\n",
      "Episode:1377 meanR:492.9400 R:12.0000 loss:72.0214 exploreP:0.0100\n",
      "Episode:1378 meanR:488.0600 R:12.0000 loss:139.0896 exploreP:0.0100\n",
      "Episode:1379 meanR:488.0600 R:500.0000 loss:32.6057 exploreP:0.0100\n",
      "Episode:1380 meanR:488.0600 R:500.0000 loss:16.8035 exploreP:0.0100\n",
      "Episode:1381 meanR:488.0600 R:500.0000 loss:12.8656 exploreP:0.0100\n",
      "Episode:1382 meanR:488.0600 R:500.0000 loss:16.2223 exploreP:0.0100\n",
      "Episode:1383 meanR:488.0600 R:500.0000 loss:15.9629 exploreP:0.0100\n",
      "Episode:1384 meanR:488.0600 R:500.0000 loss:16.3586 exploreP:0.0100\n",
      "Episode:1385 meanR:488.0600 R:500.0000 loss:16.3726 exploreP:0.0100\n",
      "Episode:1386 meanR:488.0600 R:500.0000 loss:15.8979 exploreP:0.0100\n",
      "Episode:1387 meanR:488.0600 R:500.0000 loss:15.4786 exploreP:0.0100\n",
      "Episode:1388 meanR:488.0600 R:500.0000 loss:14.8081 exploreP:0.0100\n",
      "Episode:1389 meanR:488.0600 R:500.0000 loss:15.3946 exploreP:0.0100\n",
      "Episode:1390 meanR:488.0600 R:500.0000 loss:14.5270 exploreP:0.0100\n",
      "Episode:1391 meanR:488.0600 R:500.0000 loss:12.9921 exploreP:0.0100\n",
      "Episode:1392 meanR:488.0600 R:500.0000 loss:15.9308 exploreP:0.0100\n",
      "Episode:1393 meanR:488.0600 R:500.0000 loss:13.3332 exploreP:0.0100\n",
      "Episode:1394 meanR:488.0600 R:500.0000 loss:14.3649 exploreP:0.0100\n",
      "Episode:1395 meanR:488.0600 R:500.0000 loss:14.4795 exploreP:0.0100\n",
      "Episode:1396 meanR:488.0600 R:500.0000 loss:17.3711 exploreP:0.0100\n",
      "Episode:1397 meanR:488.0600 R:500.0000 loss:18.6196 exploreP:0.0100\n",
      "Episode:1398 meanR:488.0600 R:500.0000 loss:18.1486 exploreP:0.0100\n",
      "Episode:1399 meanR:488.0600 R:500.0000 loss:17.8452 exploreP:0.0100\n",
      "Episode:1400 meanR:488.0600 R:500.0000 loss:17.4758 exploreP:0.0100\n",
      "Episode:1401 meanR:488.0600 R:500.0000 loss:16.3812 exploreP:0.0100\n",
      "Episode:1402 meanR:488.0600 R:500.0000 loss:16.3715 exploreP:0.0100\n",
      "Episode:1403 meanR:488.0600 R:500.0000 loss:16.3054 exploreP:0.0100\n",
      "Episode:1404 meanR:488.0600 R:500.0000 loss:18.8813 exploreP:0.0100\n",
      "Episode:1405 meanR:488.0600 R:500.0000 loss:17.4353 exploreP:0.0100\n",
      "Episode:1406 meanR:488.0600 R:500.0000 loss:11.7188 exploreP:0.0100\n",
      "Episode:1407 meanR:488.0600 R:500.0000 loss:17.9777 exploreP:0.0100\n",
      "Episode:1408 meanR:485.7400 R:268.0000 loss:30.9072 exploreP:0.0100\n",
      "Episode:1409 meanR:487.9200 R:500.0000 loss:5.1808 exploreP:0.0100\n",
      "Episode:1410 meanR:487.9200 R:500.0000 loss:19.0246 exploreP:0.0100\n",
      "Episode:1411 meanR:487.9200 R:500.0000 loss:21.3550 exploreP:0.0100\n",
      "Episode:1412 meanR:487.9200 R:500.0000 loss:15.8005 exploreP:0.0100\n",
      "Episode:1413 meanR:485.8000 R:288.0000 loss:34.7748 exploreP:0.0100\n",
      "Episode:1414 meanR:485.8000 R:500.0000 loss:15.4062 exploreP:0.0100\n",
      "Episode:1415 meanR:485.8000 R:500.0000 loss:18.7849 exploreP:0.0100\n",
      "Episode:1416 meanR:485.8000 R:500.0000 loss:18.0438 exploreP:0.0100\n",
      "Episode:1417 meanR:485.8000 R:500.0000 loss:12.3165 exploreP:0.0100\n",
      "Episode:1418 meanR:485.8000 R:500.0000 loss:6.3428 exploreP:0.0100\n",
      "Episode:1419 meanR:485.8000 R:500.0000 loss:10.1528 exploreP:0.0100\n",
      "Episode:1420 meanR:485.8000 R:500.0000 loss:17.4259 exploreP:0.0100\n",
      "Episode:1421 meanR:485.8000 R:500.0000 loss:13.2227 exploreP:0.0100\n",
      "Episode:1422 meanR:485.8000 R:500.0000 loss:14.9914 exploreP:0.0100\n",
      "Episode:1423 meanR:485.7000 R:490.0000 loss:12.8588 exploreP:0.0100\n",
      "Episode:1424 meanR:483.4200 R:272.0000 loss:17.1508 exploreP:0.0100\n",
      "Episode:1425 meanR:480.8100 R:239.0000 loss:11.1396 exploreP:0.0100\n",
      "Episode:1426 meanR:478.4400 R:263.0000 loss:2.7214 exploreP:0.0100\n",
      "Episode:1427 meanR:475.6700 R:223.0000 loss:1.8446 exploreP:0.0100\n",
      "Episode:1428 meanR:472.3100 R:164.0000 loss:6.5755 exploreP:0.0100\n",
      "Episode:1429 meanR:468.4700 R:116.0000 loss:3.3011 exploreP:0.0100\n",
      "Episode:1430 meanR:464.5300 R:106.0000 loss:4.8494 exploreP:0.0100\n",
      "Episode:1431 meanR:460.6800 R:115.0000 loss:2.9248 exploreP:0.0100\n",
      "Episode:1432 meanR:458.5000 R:282.0000 loss:3.3243 exploreP:0.0100\n",
      "Episode:1433 meanR:454.8100 R:131.0000 loss:19.8645 exploreP:0.0100\n",
      "Episode:1434 meanR:451.1100 R:130.0000 loss:3.8088 exploreP:0.0100\n",
      "Episode:1435 meanR:447.5000 R:139.0000 loss:2.8787 exploreP:0.0100\n",
      "Episode:1436 meanR:445.4800 R:298.0000 loss:2.4791 exploreP:0.0100\n",
      "Episode:1437 meanR:442.0600 R:158.0000 loss:13.4547 exploreP:0.0100\n",
      "Episode:1438 meanR:439.1900 R:213.0000 loss:12.1903 exploreP:0.0100\n",
      "Episode:1439 meanR:439.1900 R:500.0000 loss:5.9871 exploreP:0.0100\n",
      "Episode:1440 meanR:439.1900 R:500.0000 loss:15.3045 exploreP:0.0100\n",
      "Episode:1441 meanR:436.5200 R:233.0000 loss:38.7741 exploreP:0.0100\n",
      "Episode:1442 meanR:432.8800 R:136.0000 loss:7.7046 exploreP:0.0100\n",
      "Episode:1443 meanR:429.6100 R:173.0000 loss:2.2607 exploreP:0.0100\n",
      "Episode:1444 meanR:429.6100 R:500.0000 loss:0.8260 exploreP:0.0100\n",
      "Episode:1445 meanR:426.9900 R:238.0000 loss:33.5868 exploreP:0.0100\n",
      "Episode:1446 meanR:423.8300 R:184.0000 loss:3.0008 exploreP:0.0100\n",
      "Episode:1447 meanR:423.8300 R:500.0000 loss:0.5218 exploreP:0.0100\n",
      "Episode:1448 meanR:423.8300 R:500.0000 loss:3.2230 exploreP:0.0100\n",
      "Episode:1449 meanR:423.8300 R:500.0000 loss:13.2952 exploreP:0.0100\n",
      "Episode:1450 meanR:422.4300 R:360.0000 loss:0.7255 exploreP:0.0100\n",
      "Episode:1451 meanR:420.3700 R:294.0000 loss:1.4763 exploreP:0.0100\n",
      "Episode:1452 meanR:420.3700 R:500.0000 loss:0.2859 exploreP:0.0100\n",
      "Episode:1453 meanR:420.3700 R:500.0000 loss:15.7634 exploreP:0.0100\n",
      "Episode:1454 meanR:416.8000 R:143.0000 loss:56.6846 exploreP:0.0100\n",
      "Episode:1455 meanR:416.8000 R:500.0000 loss:8.8039 exploreP:0.0100\n",
      "Episode:1456 meanR:414.6800 R:288.0000 loss:8.2152 exploreP:0.0100\n",
      "Episode:1457 meanR:413.1700 R:349.0000 loss:1.5909 exploreP:0.0100\n",
      "Episode:1458 meanR:410.9000 R:273.0000 loss:4.3091 exploreP:0.0100\n",
      "Episode:1459 meanR:410.9000 R:500.0000 loss:0.9222 exploreP:0.0100\n",
      "Episode:1460 meanR:407.4000 R:150.0000 loss:31.7668 exploreP:0.0100\n",
      "Episode:1461 meanR:406.1900 R:379.0000 loss:8.0220 exploreP:0.0100\n",
      "Episode:1462 meanR:402.8200 R:163.0000 loss:21.0667 exploreP:0.0100\n",
      "Episode:1463 meanR:399.3600 R:154.0000 loss:9.7915 exploreP:0.0100\n",
      "Episode:1464 meanR:395.7000 R:134.0000 loss:5.5808 exploreP:0.0100\n",
      "Episode:1465 meanR:391.9500 R:125.0000 loss:4.9273 exploreP:0.0100\n",
      "Episode:1466 meanR:388.2300 R:128.0000 loss:5.9047 exploreP:0.0100\n",
      "Episode:1467 meanR:383.4800 R:25.0000 loss:6.5320 exploreP:0.0100\n",
      "Episode:1468 meanR:378.8200 R:34.0000 loss:15.1646 exploreP:0.0100\n",
      "Episode:1469 meanR:375.6100 R:179.0000 loss:7.3686 exploreP:0.0100\n",
      "Episode:1470 meanR:372.7500 R:214.0000 loss:3.4617 exploreP:0.0100\n",
      "Episode:1471 meanR:372.7500 R:500.0000 loss:1.0319 exploreP:0.0100\n",
      "Episode:1472 meanR:371.3300 R:358.0000 loss:20.0433 exploreP:0.0100\n",
      "Episode:1473 meanR:368.6800 R:235.0000 loss:1.5523 exploreP:0.0100\n",
      "Episode:1474 meanR:365.9400 R:226.0000 loss:1.5246 exploreP:0.0100\n",
      "Episode:1475 meanR:362.9900 R:205.0000 loss:1.3936 exploreP:0.0100\n",
      "Episode:1476 meanR:360.2300 R:224.0000 loss:0.9997 exploreP:0.0100\n",
      "Episode:1477 meanR:365.1100 R:500.0000 loss:1.3983 exploreP:0.0100\n",
      "Episode:1478 meanR:369.9900 R:500.0000 loss:18.7910 exploreP:0.0100\n",
      "Episode:1479 meanR:369.9900 R:500.0000 loss:17.5921 exploreP:0.0100\n",
      "Episode:1480 meanR:366.5700 R:158.0000 loss:69.1459 exploreP:0.0100\n",
      "Episode:1481 meanR:363.5900 R:202.0000 loss:5.0868 exploreP:0.0100\n",
      "Episode:1482 meanR:361.5600 R:297.0000 loss:1.2369 exploreP:0.0100\n",
      "Episode:1483 meanR:361.5600 R:500.0000 loss:1.1272 exploreP:0.0100\n",
      "Episode:1484 meanR:361.5600 R:500.0000 loss:13.0927 exploreP:0.0100\n",
      "Episode:1485 meanR:361.5600 R:500.0000 loss:18.7818 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1486 meanR:361.5600 R:500.0000 loss:15.9374 exploreP:0.0100\n",
      "Episode:1487 meanR:361.5600 R:500.0000 loss:16.3641 exploreP:0.0100\n",
      "Episode:1488 meanR:361.5600 R:500.0000 loss:15.0065 exploreP:0.0100\n",
      "Episode:1489 meanR:361.5600 R:500.0000 loss:8.4297 exploreP:0.0100\n",
      "Episode:1490 meanR:361.5600 R:500.0000 loss:11.6695 exploreP:0.0100\n",
      "Episode:1491 meanR:361.5600 R:500.0000 loss:17.0128 exploreP:0.0100\n",
      "Episode:1492 meanR:361.5600 R:500.0000 loss:16.6813 exploreP:0.0100\n",
      "Episode:1493 meanR:361.5600 R:500.0000 loss:8.4034 exploreP:0.0100\n",
      "Episode:1494 meanR:361.5600 R:500.0000 loss:14.9061 exploreP:0.0100\n",
      "Episode:1495 meanR:361.5600 R:500.0000 loss:21.5848 exploreP:0.0100\n",
      "Episode:1496 meanR:361.5600 R:500.0000 loss:17.8625 exploreP:0.0100\n",
      "Episode:1497 meanR:361.5600 R:500.0000 loss:17.0074 exploreP:0.0100\n",
      "Episode:1498 meanR:361.5600 R:500.0000 loss:18.2579 exploreP:0.0100\n",
      "Episode:1499 meanR:361.5600 R:500.0000 loss:9.0868 exploreP:0.0100\n",
      "Episode:1500 meanR:361.5600 R:500.0000 loss:20.1733 exploreP:0.0100\n",
      "Episode:1501 meanR:358.1500 R:159.0000 loss:55.2275 exploreP:0.0100\n",
      "Episode:1502 meanR:358.1500 R:500.0000 loss:1.4917 exploreP:0.0100\n",
      "Episode:1503 meanR:358.1500 R:500.0000 loss:20.0161 exploreP:0.0100\n",
      "Episode:1504 meanR:358.1500 R:500.0000 loss:17.9268 exploreP:0.0100\n",
      "Episode:1505 meanR:358.1500 R:500.0000 loss:18.7803 exploreP:0.0100\n",
      "Episode:1506 meanR:358.1500 R:500.0000 loss:15.0008 exploreP:0.0100\n",
      "Episode:1507 meanR:358.1500 R:500.0000 loss:17.2403 exploreP:0.0100\n",
      "Episode:1508 meanR:360.4700 R:500.0000 loss:15.9066 exploreP:0.0100\n",
      "Episode:1509 meanR:360.4700 R:500.0000 loss:9.2939 exploreP:0.0100\n",
      "Episode:1510 meanR:357.2300 R:176.0000 loss:46.8424 exploreP:0.0100\n",
      "Episode:1511 meanR:353.4000 R:117.0000 loss:5.2937 exploreP:0.0100\n",
      "Episode:1512 meanR:348.5000 R:10.0000 loss:6.5856 exploreP:0.0100\n",
      "Episode:1513 meanR:350.6200 R:500.0000 loss:5.5066 exploreP:0.0100\n",
      "Episode:1514 meanR:350.6200 R:500.0000 loss:19.1340 exploreP:0.0100\n",
      "Episode:1515 meanR:350.6200 R:500.0000 loss:11.9508 exploreP:0.0100\n",
      "Episode:1516 meanR:350.6200 R:500.0000 loss:13.5975 exploreP:0.0100\n",
      "Episode:1517 meanR:350.6200 R:500.0000 loss:16.6975 exploreP:0.0100\n",
      "Episode:1518 meanR:350.6200 R:500.0000 loss:17.7960 exploreP:0.0100\n",
      "Episode:1519 meanR:350.6200 R:500.0000 loss:10.9533 exploreP:0.0100\n",
      "Episode:1520 meanR:350.6200 R:500.0000 loss:22.6169 exploreP:0.0100\n",
      "Episode:1521 meanR:350.6200 R:500.0000 loss:18.5815 exploreP:0.0100\n",
      "Episode:1522 meanR:350.6200 R:500.0000 loss:14.7418 exploreP:0.0100\n",
      "Episode:1523 meanR:350.7200 R:500.0000 loss:14.3397 exploreP:0.0100\n",
      "Episode:1524 meanR:353.0000 R:500.0000 loss:18.5747 exploreP:0.0100\n",
      "Episode:1525 meanR:355.6100 R:500.0000 loss:13.7197 exploreP:0.0100\n",
      "Episode:1526 meanR:357.9800 R:500.0000 loss:16.4778 exploreP:0.0100\n",
      "Episode:1527 meanR:360.7500 R:500.0000 loss:18.5951 exploreP:0.0100\n",
      "Episode:1528 meanR:364.1100 R:500.0000 loss:14.8518 exploreP:0.0100\n",
      "Episode:1529 meanR:367.9500 R:500.0000 loss:17.6675 exploreP:0.0100\n",
      "Episode:1530 meanR:371.8900 R:500.0000 loss:17.9213 exploreP:0.0100\n",
      "Episode:1531 meanR:375.7400 R:500.0000 loss:14.6443 exploreP:0.0100\n",
      "Episode:1532 meanR:377.9200 R:500.0000 loss:15.2234 exploreP:0.0100\n",
      "Episode:1533 meanR:381.6100 R:500.0000 loss:18.8087 exploreP:0.0100\n",
      "Episode:1534 meanR:385.3100 R:500.0000 loss:20.3380 exploreP:0.0100\n",
      "Episode:1535 meanR:388.9200 R:500.0000 loss:20.6414 exploreP:0.0100\n",
      "Episode:1536 meanR:390.9400 R:500.0000 loss:16.7348 exploreP:0.0100\n",
      "Episode:1537 meanR:394.3600 R:500.0000 loss:16.8788 exploreP:0.0100\n",
      "Episode:1538 meanR:397.2300 R:500.0000 loss:19.4820 exploreP:0.0100\n",
      "Episode:1539 meanR:397.2300 R:500.0000 loss:20.5927 exploreP:0.0100\n",
      "Episode:1540 meanR:397.2300 R:500.0000 loss:22.9799 exploreP:0.0100\n",
      "Episode:1541 meanR:399.9000 R:500.0000 loss:22.0658 exploreP:0.0100\n",
      "Episode:1542 meanR:403.5400 R:500.0000 loss:22.0562 exploreP:0.0100\n",
      "Episode:1543 meanR:406.8100 R:500.0000 loss:22.0369 exploreP:0.0100\n",
      "Episode:1544 meanR:406.8100 R:500.0000 loss:21.6390 exploreP:0.0100\n",
      "Episode:1545 meanR:409.4300 R:500.0000 loss:21.5954 exploreP:0.0100\n",
      "Episode:1546 meanR:412.5900 R:500.0000 loss:22.1821 exploreP:0.0100\n",
      "Episode:1547 meanR:412.5900 R:500.0000 loss:20.8404 exploreP:0.0100\n",
      "Episode:1548 meanR:412.5900 R:500.0000 loss:19.1157 exploreP:0.0100\n",
      "Episode:1549 meanR:412.5900 R:500.0000 loss:19.9038 exploreP:0.0100\n",
      "Episode:1550 meanR:413.9900 R:500.0000 loss:18.6775 exploreP:0.0100\n",
      "Episode:1551 meanR:416.0500 R:500.0000 loss:16.9951 exploreP:0.0100\n",
      "Episode:1552 meanR:416.0500 R:500.0000 loss:16.3478 exploreP:0.0100\n",
      "Episode:1553 meanR:416.0500 R:500.0000 loss:15.8362 exploreP:0.0100\n",
      "Episode:1554 meanR:419.6200 R:500.0000 loss:15.7573 exploreP:0.0100\n",
      "Episode:1555 meanR:419.6200 R:500.0000 loss:15.4586 exploreP:0.0100\n",
      "Episode:1556 meanR:421.7400 R:500.0000 loss:15.6632 exploreP:0.0100\n",
      "Episode:1557 meanR:423.2500 R:500.0000 loss:16.1151 exploreP:0.0100\n",
      "Episode:1558 meanR:425.5200 R:500.0000 loss:15.6482 exploreP:0.0100\n",
      "Episode:1559 meanR:424.9400 R:442.0000 loss:17.7048 exploreP:0.0100\n",
      "Episode:1560 meanR:428.4400 R:500.0000 loss:5.4929 exploreP:0.0100\n",
      "Episode:1561 meanR:429.6500 R:500.0000 loss:15.5387 exploreP:0.0100\n",
      "Episode:1562 meanR:433.0200 R:500.0000 loss:15.8409 exploreP:0.0100\n",
      "Episode:1563 meanR:436.4800 R:500.0000 loss:15.5063 exploreP:0.0100\n",
      "Episode:1564 meanR:440.1400 R:500.0000 loss:16.3596 exploreP:0.0100\n",
      "Episode:1565 meanR:443.8900 R:500.0000 loss:13.9113 exploreP:0.0100\n",
      "Episode:1566 meanR:446.8200 R:421.0000 loss:19.7038 exploreP:0.0100\n",
      "Episode:1567 meanR:451.5700 R:500.0000 loss:7.5414 exploreP:0.0100\n",
      "Episode:1568 meanR:456.2300 R:500.0000 loss:8.0352 exploreP:0.0100\n",
      "Episode:1569 meanR:458.9200 R:448.0000 loss:7.8476 exploreP:0.0100\n",
      "Episode:1570 meanR:461.7800 R:500.0000 loss:3.4980 exploreP:0.0100\n",
      "Episode:1571 meanR:459.9800 R:320.0000 loss:10.8165 exploreP:0.0100\n",
      "Episode:1572 meanR:459.7100 R:331.0000 loss:1.6005 exploreP:0.0100\n",
      "Episode:1573 meanR:460.8600 R:350.0000 loss:3.7144 exploreP:0.0100\n",
      "Episode:1574 meanR:461.6400 R:304.0000 loss:20.2617 exploreP:0.0100\n",
      "Episode:1575 meanR:462.1000 R:251.0000 loss:2.7209 exploreP:0.0100\n",
      "Episode:1576 meanR:462.5600 R:270.0000 loss:3.5381 exploreP:0.0100\n",
      "Episode:1577 meanR:460.6400 R:308.0000 loss:4.4388 exploreP:0.0100\n",
      "Episode:1578 meanR:460.6400 R:500.0000 loss:1.4411 exploreP:0.0100\n",
      "Episode:1579 meanR:460.6400 R:500.0000 loss:21.6139 exploreP:0.0100\n",
      "Episode:1580 meanR:461.6300 R:257.0000 loss:31.4988 exploreP:0.0100\n",
      "Episode:1581 meanR:461.7500 R:214.0000 loss:0.9840 exploreP:0.0100\n",
      "Episode:1582 meanR:461.1500 R:237.0000 loss:0.7170 exploreP:0.0100\n",
      "Episode:1583 meanR:458.4100 R:226.0000 loss:0.6551 exploreP:0.0100\n",
      "Episode:1584 meanR:455.6900 R:228.0000 loss:0.5275 exploreP:0.0100\n",
      "Episode:1585 meanR:455.6900 R:500.0000 loss:0.9250 exploreP:0.0100\n",
      "Episode:1586 meanR:455.6900 R:500.0000 loss:16.4455 exploreP:0.0100\n",
      "Episode:1587 meanR:455.6900 R:500.0000 loss:11.9600 exploreP:0.0100\n",
      "Episode:1588 meanR:454.3000 R:361.0000 loss:22.9391 exploreP:0.0100\n",
      "Episode:1589 meanR:450.3700 R:107.0000 loss:57.7168 exploreP:0.0100\n",
      "Episode:1590 meanR:446.2300 R:86.0000 loss:54.1669 exploreP:0.0100\n",
      "Episode:1591 meanR:442.4600 R:123.0000 loss:47.5379 exploreP:0.0100\n",
      "Episode:1592 meanR:437.9100 R:45.0000 loss:11.8995 exploreP:0.0100\n",
      "Episode:1593 meanR:433.1000 R:19.0000 loss:29.0342 exploreP:0.0100\n",
      "Episode:1594 meanR:428.2500 R:15.0000 loss:42.1807 exploreP:0.0100\n",
      "Episode:1595 meanR:423.4000 R:15.0000 loss:43.9587 exploreP:0.0100\n",
      "Episode:1596 meanR:419.1600 R:76.0000 loss:24.8968 exploreP:0.0100\n",
      "Episode:1597 meanR:416.8100 R:265.0000 loss:20.3202 exploreP:0.0100\n",
      "Episode:1598 meanR:415.5500 R:374.0000 loss:4.7375 exploreP:0.0100\n",
      "Episode:1599 meanR:415.5500 R:500.0000 loss:2.2284 exploreP:0.0100\n",
      "Episode:1600 meanR:412.9700 R:242.0000 loss:42.6097 exploreP:0.0100\n",
      "Episode:1601 meanR:412.9800 R:160.0000 loss:8.6873 exploreP:0.0100\n",
      "Episode:1602 meanR:409.3400 R:136.0000 loss:4.7538 exploreP:0.0100\n",
      "Episode:1603 meanR:409.3400 R:500.0000 loss:2.1773 exploreP:0.0100\n",
      "Episode:1604 meanR:409.3400 R:500.0000 loss:9.5665 exploreP:0.0100\n",
      "Episode:1605 meanR:409.3400 R:500.0000 loss:18.8111 exploreP:0.0100\n",
      "Episode:1606 meanR:409.3400 R:500.0000 loss:22.1581 exploreP:0.0100\n",
      "Episode:1607 meanR:409.3400 R:500.0000 loss:22.1021 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1608 meanR:409.3400 R:500.0000 loss:22.9602 exploreP:0.0100\n",
      "Episode:1609 meanR:409.3400 R:500.0000 loss:20.9245 exploreP:0.0100\n",
      "Episode:1610 meanR:411.4400 R:386.0000 loss:24.7458 exploreP:0.0100\n",
      "Episode:1611 meanR:415.2700 R:500.0000 loss:8.6189 exploreP:0.0100\n",
      "Episode:1612 meanR:420.1700 R:500.0000 loss:16.7138 exploreP:0.0100\n",
      "Episode:1613 meanR:417.7600 R:259.0000 loss:28.3371 exploreP:0.0100\n",
      "Episode:1614 meanR:417.7600 R:500.0000 loss:4.3560 exploreP:0.0100\n",
      "Episode:1615 meanR:414.9800 R:222.0000 loss:31.0271 exploreP:0.0100\n",
      "Episode:1616 meanR:411.7500 R:177.0000 loss:16.5595 exploreP:0.0100\n",
      "Episode:1617 meanR:408.2200 R:147.0000 loss:7.8434 exploreP:0.0100\n",
      "Episode:1618 meanR:404.9000 R:168.0000 loss:3.2042 exploreP:0.0100\n",
      "Episode:1619 meanR:401.6700 R:177.0000 loss:1.8849 exploreP:0.0100\n",
      "Episode:1620 meanR:397.8300 R:116.0000 loss:0.6435 exploreP:0.0100\n",
      "Episode:1621 meanR:393.8700 R:104.0000 loss:0.5292 exploreP:0.0100\n",
      "Episode:1622 meanR:389.8000 R:93.0000 loss:0.5225 exploreP:0.0100\n",
      "Episode:1623 meanR:386.0000 R:120.0000 loss:2.0616 exploreP:0.0100\n",
      "Episode:1624 meanR:382.0200 R:102.0000 loss:3.1286 exploreP:0.0100\n",
      "Episode:1625 meanR:377.9900 R:97.0000 loss:2.6198 exploreP:0.0100\n",
      "Episode:1626 meanR:373.9400 R:95.0000 loss:1.0045 exploreP:0.0100\n",
      "Episode:1627 meanR:369.9400 R:100.0000 loss:0.9734 exploreP:0.0100\n",
      "Episode:1628 meanR:365.8500 R:91.0000 loss:0.7922 exploreP:0.0100\n",
      "Episode:1629 meanR:361.3600 R:51.0000 loss:1.3123 exploreP:0.0100\n",
      "Episode:1630 meanR:356.7800 R:42.0000 loss:16.9804 exploreP:0.0100\n",
      "Episode:1631 meanR:352.2100 R:43.0000 loss:11.8988 exploreP:0.0100\n",
      "Episode:1632 meanR:347.3300 R:12.0000 loss:7.8327 exploreP:0.0100\n",
      "Episode:1633 meanR:342.4500 R:12.0000 loss:23.1528 exploreP:0.0100\n",
      "Episode:1634 meanR:337.5500 R:10.0000 loss:31.3364 exploreP:0.0100\n",
      "Episode:1635 meanR:333.6300 R:108.0000 loss:39.4396 exploreP:0.0100\n",
      "Episode:1636 meanR:333.6300 R:500.0000 loss:2.6003 exploreP:0.0100\n",
      "Episode:1637 meanR:332.8400 R:421.0000 loss:12.3742 exploreP:0.0100\n",
      "Episode:1638 meanR:329.9000 R:206.0000 loss:3.0488 exploreP:0.0100\n",
      "Episode:1639 meanR:327.3200 R:242.0000 loss:8.2313 exploreP:0.0100\n",
      "Episode:1640 meanR:325.6700 R:335.0000 loss:3.5802 exploreP:0.0100\n",
      "Episode:1641 meanR:323.0600 R:239.0000 loss:4.2201 exploreP:0.0100\n",
      "Episode:1642 meanR:319.9000 R:184.0000 loss:20.8236 exploreP:0.0100\n",
      "Episode:1643 meanR:319.9000 R:500.0000 loss:2.6054 exploreP:0.0100\n",
      "Episode:1644 meanR:319.5500 R:465.0000 loss:19.9318 exploreP:0.0100\n",
      "Episode:1645 meanR:319.5500 R:500.0000 loss:5.8996 exploreP:0.0100\n",
      "Episode:1646 meanR:316.7900 R:224.0000 loss:32.5647 exploreP:0.0100\n",
      "Episode:1647 meanR:316.7900 R:500.0000 loss:2.8854 exploreP:0.0100\n",
      "Episode:1648 meanR:316.7900 R:500.0000 loss:22.7404 exploreP:0.0100\n",
      "Episode:1649 meanR:316.7900 R:500.0000 loss:13.1494 exploreP:0.0100\n",
      "Episode:1650 meanR:316.7900 R:500.0000 loss:16.8192 exploreP:0.0100\n",
      "Episode:1651 meanR:316.7900 R:500.0000 loss:15.4983 exploreP:0.0100\n",
      "Episode:1652 meanR:316.7900 R:500.0000 loss:21.4914 exploreP:0.0100\n",
      "Episode:1653 meanR:316.7900 R:500.0000 loss:14.8111 exploreP:0.0100\n",
      "Episode:1654 meanR:316.7900 R:500.0000 loss:8.5784 exploreP:0.0100\n",
      "Episode:1655 meanR:312.7500 R:96.0000 loss:74.5100 exploreP:0.0100\n",
      "Episode:1656 meanR:308.3600 R:61.0000 loss:108.5169 exploreP:0.0100\n",
      "Episode:1657 meanR:303.8800 R:52.0000 loss:56.1287 exploreP:0.0100\n",
      "Episode:1658 meanR:303.8800 R:500.0000 loss:19.8218 exploreP:0.0100\n",
      "Episode:1659 meanR:304.4600 R:500.0000 loss:11.7255 exploreP:0.0100\n",
      "Episode:1660 meanR:304.4600 R:500.0000 loss:12.4481 exploreP:0.0100\n",
      "Episode:1661 meanR:302.4900 R:303.0000 loss:29.7072 exploreP:0.0100\n",
      "Episode:1662 meanR:302.4900 R:500.0000 loss:3.4534 exploreP:0.0100\n",
      "Episode:1663 meanR:302.4900 R:500.0000 loss:17.2901 exploreP:0.0100\n",
      "Episode:1664 meanR:302.4900 R:500.0000 loss:18.3732 exploreP:0.0100\n",
      "Episode:1665 meanR:302.4900 R:500.0000 loss:16.6588 exploreP:0.0100\n",
      "Episode:1666 meanR:300.3300 R:205.0000 loss:40.9319 exploreP:0.0100\n",
      "Episode:1667 meanR:295.6700 R:34.0000 loss:11.6497 exploreP:0.0100\n",
      "Episode:1668 meanR:290.7900 R:12.0000 loss:19.8936 exploreP:0.0100\n",
      "Episode:1669 meanR:286.6000 R:29.0000 loss:25.3653 exploreP:0.0100\n",
      "Episode:1670 meanR:283.1900 R:159.0000 loss:24.5047 exploreP:0.0100\n",
      "Episode:1671 meanR:284.9900 R:500.0000 loss:18.0499 exploreP:0.0100\n",
      "Episode:1672 meanR:286.6800 R:500.0000 loss:6.6567 exploreP:0.0100\n",
      "Episode:1673 meanR:288.1800 R:500.0000 loss:11.0442 exploreP:0.0100\n",
      "Episode:1674 meanR:290.1400 R:500.0000 loss:15.8772 exploreP:0.0100\n",
      "Episode:1675 meanR:292.6300 R:500.0000 loss:14.5284 exploreP:0.0100\n",
      "Episode:1676 meanR:294.9300 R:500.0000 loss:16.0851 exploreP:0.0100\n",
      "Episode:1677 meanR:296.8500 R:500.0000 loss:16.1383 exploreP:0.0100\n",
      "Episode:1678 meanR:296.8500 R:500.0000 loss:15.9092 exploreP:0.0100\n",
      "Episode:1679 meanR:296.8500 R:500.0000 loss:18.3946 exploreP:0.0100\n",
      "Episode:1680 meanR:299.2800 R:500.0000 loss:17.4022 exploreP:0.0100\n",
      "Episode:1681 meanR:302.1400 R:500.0000 loss:17.2865 exploreP:0.0100\n",
      "Episode:1682 meanR:304.7700 R:500.0000 loss:17.7832 exploreP:0.0100\n",
      "Episode:1683 meanR:307.5100 R:500.0000 loss:17.1366 exploreP:0.0100\n",
      "Episode:1684 meanR:307.4200 R:219.0000 loss:43.8804 exploreP:0.0100\n",
      "Episode:1685 meanR:307.4200 R:500.0000 loss:3.4865 exploreP:0.0100\n",
      "Episode:1686 meanR:307.4200 R:500.0000 loss:23.8360 exploreP:0.0100\n",
      "Episode:1687 meanR:307.4200 R:500.0000 loss:18.0544 exploreP:0.0100\n",
      "Episode:1688 meanR:308.8100 R:500.0000 loss:12.1244 exploreP:0.0100\n",
      "Episode:1689 meanR:312.7400 R:500.0000 loss:18.6788 exploreP:0.0100\n",
      "Episode:1690 meanR:316.8800 R:500.0000 loss:11.5818 exploreP:0.0100\n",
      "Episode:1691 meanR:317.1800 R:153.0000 loss:51.9594 exploreP:0.0100\n",
      "Episode:1692 meanR:316.8200 R:9.0000 loss:32.7790 exploreP:0.0100\n",
      "Episode:1693 meanR:316.7200 R:9.0000 loss:73.1316 exploreP:0.0100\n",
      "Episode:1694 meanR:316.6700 R:10.0000 loss:87.7983 exploreP:0.0100\n",
      "Episode:1695 meanR:316.6400 R:12.0000 loss:70.3893 exploreP:0.0100\n",
      "Episode:1696 meanR:320.8800 R:500.0000 loss:11.0209 exploreP:0.0100\n",
      "Episode:1697 meanR:323.2300 R:500.0000 loss:11.4015 exploreP:0.0100\n",
      "Episode:1698 meanR:324.4900 R:500.0000 loss:13.9396 exploreP:0.0100\n",
      "Episode:1699 meanR:324.4900 R:500.0000 loss:17.2179 exploreP:0.0100\n",
      "Episode:1700 meanR:327.0700 R:500.0000 loss:22.7656 exploreP:0.0100\n",
      "Episode:1701 meanR:330.4700 R:500.0000 loss:18.5001 exploreP:0.0100\n",
      "Episode:1702 meanR:334.1100 R:500.0000 loss:15.7097 exploreP:0.0100\n",
      "Episode:1703 meanR:334.1100 R:500.0000 loss:14.5021 exploreP:0.0100\n",
      "Episode:1704 meanR:334.1100 R:500.0000 loss:13.8931 exploreP:0.0100\n",
      "Episode:1705 meanR:334.1100 R:500.0000 loss:16.0448 exploreP:0.0100\n",
      "Episode:1706 meanR:334.1100 R:500.0000 loss:15.9979 exploreP:0.0100\n",
      "Episode:1707 meanR:334.1100 R:500.0000 loss:18.0400 exploreP:0.0100\n",
      "Episode:1708 meanR:334.1100 R:500.0000 loss:20.2451 exploreP:0.0100\n",
      "Episode:1709 meanR:334.1100 R:500.0000 loss:22.0646 exploreP:0.0100\n",
      "Episode:1710 meanR:335.2500 R:500.0000 loss:18.6595 exploreP:0.0100\n",
      "Episode:1711 meanR:335.2500 R:500.0000 loss:19.4345 exploreP:0.0100\n",
      "Episode:1712 meanR:335.2500 R:500.0000 loss:15.5650 exploreP:0.0100\n",
      "Episode:1713 meanR:337.6600 R:500.0000 loss:16.7771 exploreP:0.0100\n",
      "Episode:1714 meanR:337.6600 R:500.0000 loss:16.5136 exploreP:0.0100\n",
      "Episode:1715 meanR:340.4400 R:500.0000 loss:17.0271 exploreP:0.0100\n",
      "Episode:1716 meanR:343.6700 R:500.0000 loss:17.6320 exploreP:0.0100\n",
      "Episode:1717 meanR:347.2000 R:500.0000 loss:18.0577 exploreP:0.0100\n",
      "Episode:1718 meanR:350.5200 R:500.0000 loss:17.8826 exploreP:0.0100\n",
      "Episode:1719 meanR:353.7500 R:500.0000 loss:16.4960 exploreP:0.0100\n",
      "Episode:1720 meanR:357.5900 R:500.0000 loss:12.6500 exploreP:0.0100\n",
      "Episode:1721 meanR:361.5500 R:500.0000 loss:18.0161 exploreP:0.0100\n",
      "Episode:1722 meanR:365.6200 R:500.0000 loss:15.8784 exploreP:0.0100\n",
      "Episode:1723 meanR:367.8900 R:347.0000 loss:27.4494 exploreP:0.0100\n",
      "Episode:1724 meanR:371.8100 R:494.0000 loss:3.5972 exploreP:0.0100\n",
      "Episode:1725 meanR:374.8700 R:403.0000 loss:2.8788 exploreP:0.0100\n",
      "Episode:1726 meanR:375.9200 R:200.0000 loss:2.3481 exploreP:0.0100\n",
      "Episode:1727 meanR:376.9700 R:205.0000 loss:1.5892 exploreP:0.0100\n",
      "Episode:1728 meanR:378.2700 R:221.0000 loss:0.8113 exploreP:0.0100\n",
      "Episode:1729 meanR:380.0900 R:233.0000 loss:0.6801 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1730 meanR:382.5500 R:288.0000 loss:11.4155 exploreP:0.0100\n",
      "Episode:1731 meanR:386.0500 R:393.0000 loss:1.4831 exploreP:0.0100\n",
      "Episode:1732 meanR:389.0800 R:315.0000 loss:11.8819 exploreP:0.0100\n",
      "Episode:1733 meanR:393.9600 R:500.0000 loss:0.8449 exploreP:0.0100\n",
      "Episode:1734 meanR:396.3100 R:245.0000 loss:28.5856 exploreP:0.0100\n",
      "Episode:1735 meanR:396.4900 R:126.0000 loss:24.9552 exploreP:0.0100\n",
      "Episode:1736 meanR:394.6900 R:320.0000 loss:15.0690 exploreP:0.0100\n",
      "Episode:1737 meanR:395.4800 R:500.0000 loss:0.9205 exploreP:0.0100\n",
      "Episode:1738 meanR:398.4200 R:500.0000 loss:15.2213 exploreP:0.0100\n",
      "Episode:1739 meanR:401.0000 R:500.0000 loss:14.5436 exploreP:0.0100\n",
      "Episode:1740 meanR:400.0900 R:244.0000 loss:32.9338 exploreP:0.0100\n",
      "Episode:1741 meanR:402.7000 R:500.0000 loss:0.8919 exploreP:0.0100\n",
      "Episode:1742 meanR:405.8600 R:500.0000 loss:7.5784 exploreP:0.0100\n",
      "Episode:1743 meanR:405.8600 R:500.0000 loss:12.7133 exploreP:0.0100\n",
      "Episode:1744 meanR:405.9000 R:469.0000 loss:15.9536 exploreP:0.0100\n",
      "Episode:1745 meanR:405.9000 R:500.0000 loss:2.3452 exploreP:0.0100\n",
      "Episode:1746 meanR:408.6600 R:500.0000 loss:14.4324 exploreP:0.0100\n",
      "Episode:1747 meanR:405.9600 R:230.0000 loss:28.9344 exploreP:0.0100\n",
      "Episode:1748 meanR:405.9600 R:500.0000 loss:1.0162 exploreP:0.0100\n",
      "Episode:1749 meanR:405.9600 R:500.0000 loss:19.2995 exploreP:0.0100\n",
      "Episode:1750 meanR:405.9600 R:500.0000 loss:17.5336 exploreP:0.0100\n",
      "Episode:1751 meanR:405.9600 R:500.0000 loss:18.3700 exploreP:0.0100\n",
      "Episode:1752 meanR:403.2900 R:233.0000 loss:41.0357 exploreP:0.0100\n",
      "Episode:1753 meanR:399.8100 R:152.0000 loss:12.0807 exploreP:0.0100\n",
      "Episode:1754 meanR:397.8600 R:305.0000 loss:4.6662 exploreP:0.0100\n",
      "Episode:1755 meanR:401.0300 R:413.0000 loss:3.7687 exploreP:0.0100\n",
      "Episode:1756 meanR:404.2700 R:385.0000 loss:2.5603 exploreP:0.0100\n",
      "Episode:1757 meanR:407.0300 R:328.0000 loss:2.4534 exploreP:0.0100\n",
      "Episode:1758 meanR:407.0300 R:500.0000 loss:2.1496 exploreP:0.0100\n",
      "Episode:1759 meanR:402.7100 R:68.0000 loss:50.2200 exploreP:0.0100\n",
      "Episode:1760 meanR:402.7100 R:500.0000 loss:13.7890 exploreP:0.0100\n",
      "Episode:1761 meanR:404.6800 R:500.0000 loss:16.2543 exploreP:0.0100\n",
      "Episode:1762 meanR:404.6800 R:500.0000 loss:15.6595 exploreP:0.0100\n",
      "Episode:1763 meanR:402.3200 R:264.0000 loss:22.8723 exploreP:0.0100\n",
      "Episode:1764 meanR:399.9300 R:261.0000 loss:2.5444 exploreP:0.0100\n",
      "Episode:1765 meanR:398.3700 R:344.0000 loss:1.9657 exploreP:0.0100\n",
      "Episode:1766 meanR:401.3200 R:500.0000 loss:1.3816 exploreP:0.0100\n",
      "Episode:1767 meanR:405.9800 R:500.0000 loss:0.9504 exploreP:0.0100\n",
      "Episode:1768 meanR:409.1400 R:328.0000 loss:7.9083 exploreP:0.0100\n",
      "Episode:1769 meanR:411.5000 R:265.0000 loss:2.7124 exploreP:0.0100\n",
      "Episode:1770 meanR:412.8300 R:292.0000 loss:7.2756 exploreP:0.0100\n",
      "Episode:1771 meanR:410.2200 R:239.0000 loss:1.7979 exploreP:0.0100\n",
      "Episode:1772 meanR:407.6000 R:238.0000 loss:1.7238 exploreP:0.0100\n",
      "Episode:1773 meanR:404.8600 R:226.0000 loss:2.3302 exploreP:0.0100\n",
      "Episode:1774 meanR:403.6300 R:377.0000 loss:3.3675 exploreP:0.0100\n",
      "Episode:1775 meanR:400.9200 R:229.0000 loss:1.3061 exploreP:0.0100\n",
      "Episode:1776 meanR:398.2200 R:230.0000 loss:0.4670 exploreP:0.0100\n",
      "Episode:1777 meanR:395.3500 R:213.0000 loss:0.7020 exploreP:0.0100\n",
      "Episode:1778 meanR:392.4300 R:208.0000 loss:0.5660 exploreP:0.0100\n",
      "Episode:1779 meanR:389.4400 R:201.0000 loss:0.5490 exploreP:0.0100\n",
      "Episode:1780 meanR:387.5500 R:311.0000 loss:0.7866 exploreP:0.0100\n",
      "Episode:1781 meanR:384.3900 R:184.0000 loss:0.6573 exploreP:0.0100\n",
      "Episode:1782 meanR:381.3300 R:194.0000 loss:0.7649 exploreP:0.0100\n",
      "Episode:1783 meanR:378.5600 R:223.0000 loss:0.6714 exploreP:0.0100\n",
      "Episode:1784 meanR:380.1400 R:377.0000 loss:0.6513 exploreP:0.0100\n",
      "Episode:1785 meanR:380.1400 R:500.0000 loss:0.3937 exploreP:0.0100\n",
      "Episode:1786 meanR:378.1900 R:305.0000 loss:14.0105 exploreP:0.0100\n",
      "Episode:1787 meanR:376.2500 R:306.0000 loss:1.3198 exploreP:0.0100\n",
      "Episode:1788 meanR:376.2500 R:500.0000 loss:1.5209 exploreP:0.0100\n",
      "Episode:1789 meanR:376.2500 R:500.0000 loss:18.5831 exploreP:0.0100\n",
      "Episode:1790 meanR:376.2500 R:500.0000 loss:3.1903 exploreP:0.0100\n",
      "Episode:1791 meanR:379.7200 R:500.0000 loss:16.7300 exploreP:0.0100\n",
      "Episode:1792 meanR:384.6300 R:500.0000 loss:14.4696 exploreP:0.0100\n",
      "Episode:1793 meanR:389.5400 R:500.0000 loss:10.1037 exploreP:0.0100\n",
      "Episode:1794 meanR:394.4400 R:500.0000 loss:10.1177 exploreP:0.0100\n",
      "Episode:1795 meanR:396.0300 R:171.0000 loss:79.9454 exploreP:0.0100\n",
      "Episode:1796 meanR:393.9700 R:294.0000 loss:16.7361 exploreP:0.0100\n",
      "Episode:1797 meanR:393.9700 R:500.0000 loss:6.9536 exploreP:0.0100\n",
      "Episode:1798 meanR:393.9700 R:500.0000 loss:16.9404 exploreP:0.0100\n",
      "Episode:1799 meanR:393.9700 R:500.0000 loss:15.3552 exploreP:0.0100\n",
      "Episode:1800 meanR:393.9700 R:500.0000 loss:16.4481 exploreP:0.0100\n",
      "Episode:1801 meanR:393.9700 R:500.0000 loss:12.6691 exploreP:0.0100\n",
      "Episode:1802 meanR:393.9700 R:500.0000 loss:14.4837 exploreP:0.0100\n",
      "Episode:1803 meanR:393.9700 R:500.0000 loss:19.2088 exploreP:0.0100\n",
      "Episode:1804 meanR:389.0900 R:12.0000 loss:80.9396 exploreP:0.0100\n",
      "Episode:1805 meanR:389.0900 R:500.0000 loss:28.3291 exploreP:0.0100\n",
      "Episode:1806 meanR:389.0900 R:500.0000 loss:14.4298 exploreP:0.0100\n",
      "Episode:1807 meanR:389.0900 R:500.0000 loss:9.0212 exploreP:0.0100\n",
      "Episode:1808 meanR:389.0900 R:500.0000 loss:20.1253 exploreP:0.0100\n",
      "Episode:1809 meanR:389.0900 R:500.0000 loss:13.2327 exploreP:0.0100\n",
      "Episode:1810 meanR:389.0900 R:500.0000 loss:19.2409 exploreP:0.0100\n",
      "Episode:1811 meanR:389.0900 R:500.0000 loss:17.5117 exploreP:0.0100\n",
      "Episode:1812 meanR:389.0900 R:500.0000 loss:16.5846 exploreP:0.0100\n",
      "Episode:1813 meanR:389.0900 R:500.0000 loss:15.5923 exploreP:0.0100\n",
      "Episode:1814 meanR:389.0900 R:500.0000 loss:14.1450 exploreP:0.0100\n",
      "Episode:1815 meanR:389.0900 R:500.0000 loss:15.4155 exploreP:0.0100\n",
      "Episode:1816 meanR:389.0900 R:500.0000 loss:14.5645 exploreP:0.0100\n",
      "Episode:1817 meanR:389.0900 R:500.0000 loss:15.3128 exploreP:0.0100\n",
      "Episode:1818 meanR:389.0900 R:500.0000 loss:16.2324 exploreP:0.0100\n",
      "Episode:1819 meanR:389.0900 R:500.0000 loss:17.8064 exploreP:0.0100\n",
      "Episode:1820 meanR:389.0900 R:500.0000 loss:15.1270 exploreP:0.0100\n",
      "Episode:1821 meanR:389.0900 R:500.0000 loss:13.4113 exploreP:0.0100\n",
      "Episode:1822 meanR:389.0900 R:500.0000 loss:15.3920 exploreP:0.0100\n",
      "Episode:1823 meanR:390.6200 R:500.0000 loss:16.2857 exploreP:0.0100\n",
      "Episode:1824 meanR:390.6800 R:500.0000 loss:15.6753 exploreP:0.0100\n",
      "Episode:1825 meanR:391.6500 R:500.0000 loss:14.6388 exploreP:0.0100\n",
      "Episode:1826 meanR:394.6500 R:500.0000 loss:15.0316 exploreP:0.0100\n",
      "Episode:1827 meanR:397.6000 R:500.0000 loss:13.5933 exploreP:0.0100\n",
      "Episode:1828 meanR:396.6700 R:128.0000 loss:61.1666 exploreP:0.0100\n",
      "Episode:1829 meanR:396.0700 R:173.0000 loss:22.5851 exploreP:0.0100\n",
      "Episode:1830 meanR:398.1900 R:500.0000 loss:10.2132 exploreP:0.0100\n",
      "Episode:1831 meanR:399.2600 R:500.0000 loss:10.3866 exploreP:0.0100\n",
      "Episode:1832 meanR:401.1100 R:500.0000 loss:17.4069 exploreP:0.0100\n",
      "Episode:1833 meanR:401.1100 R:500.0000 loss:16.2264 exploreP:0.0100\n",
      "Episode:1834 meanR:403.6600 R:500.0000 loss:15.3948 exploreP:0.0100\n",
      "Episode:1835 meanR:407.4000 R:500.0000 loss:19.3023 exploreP:0.0100\n",
      "Episode:1836 meanR:405.4400 R:124.0000 loss:66.2963 exploreP:0.0100\n",
      "Episode:1837 meanR:401.0200 R:58.0000 loss:40.8180 exploreP:0.0100\n",
      "Episode:1838 meanR:401.0200 R:500.0000 loss:120.6376 exploreP:0.0100\n",
      "Episode:1839 meanR:401.0200 R:500.0000 loss:18.1487 exploreP:0.0100\n",
      "Episode:1840 meanR:403.5800 R:500.0000 loss:17.0969 exploreP:0.0100\n",
      "Episode:1841 meanR:403.5800 R:500.0000 loss:16.3904 exploreP:0.0100\n",
      "Episode:1842 meanR:403.5800 R:500.0000 loss:15.9871 exploreP:0.0100\n",
      "Episode:1843 meanR:403.5800 R:500.0000 loss:15.9952 exploreP:0.0100\n",
      "Episode:1844 meanR:403.8900 R:500.0000 loss:16.3461 exploreP:0.0100\n",
      "Episode:1845 meanR:403.8900 R:500.0000 loss:16.2117 exploreP:0.0100\n",
      "Episode:1846 meanR:403.8900 R:500.0000 loss:16.2593 exploreP:0.0100\n",
      "Episode:1847 meanR:406.5900 R:500.0000 loss:15.0264 exploreP:0.0100\n",
      "Episode:1848 meanR:406.5900 R:500.0000 loss:15.1158 exploreP:0.0100\n",
      "Episode:1849 meanR:406.5900 R:500.0000 loss:14.9135 exploreP:0.0100\n",
      "Episode:1850 meanR:406.5900 R:500.0000 loss:14.4642 exploreP:0.0100\n",
      "Episode:1851 meanR:406.5900 R:500.0000 loss:14.3311 exploreP:0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1852 meanR:409.2600 R:500.0000 loss:14.5520 exploreP:0.0100\n",
      "Episode:1853 meanR:412.7400 R:500.0000 loss:15.5814 exploreP:0.0100\n",
      "Episode:1854 meanR:414.6900 R:500.0000 loss:14.6429 exploreP:0.0100\n",
      "Episode:1855 meanR:415.5600 R:500.0000 loss:15.6408 exploreP:0.0100\n",
      "Episode:1856 meanR:416.7100 R:500.0000 loss:15.6198 exploreP:0.0100\n",
      "Episode:1857 meanR:415.0000 R:157.0000 loss:48.6374 exploreP:0.0100\n",
      "Episode:1858 meanR:415.0000 R:500.0000 loss:6.1222 exploreP:0.0100\n",
      "Episode:1859 meanR:419.3200 R:500.0000 loss:18.2836 exploreP:0.0100\n",
      "Episode:1860 meanR:419.3200 R:500.0000 loss:16.9061 exploreP:0.0100\n",
      "Episode:1861 meanR:419.3200 R:500.0000 loss:15.8860 exploreP:0.0100\n",
      "Episode:1862 meanR:419.3200 R:500.0000 loss:15.3622 exploreP:0.0100\n",
      "Episode:1863 meanR:421.6800 R:500.0000 loss:17.4563 exploreP:0.0100\n",
      "Episode:1864 meanR:424.0700 R:500.0000 loss:17.6931 exploreP:0.0100\n",
      "Episode:1865 meanR:423.4400 R:281.0000 loss:28.6911 exploreP:0.0100\n",
      "Episode:1866 meanR:420.0900 R:165.0000 loss:15.3426 exploreP:0.0100\n",
      "Episode:1867 meanR:417.4600 R:237.0000 loss:4.3531 exploreP:0.0100\n",
      "Episode:1868 meanR:415.5800 R:140.0000 loss:33.1132 exploreP:0.0100\n",
      "Episode:1869 meanR:415.0500 R:212.0000 loss:2.7029 exploreP:0.0100\n",
      "Episode:1870 meanR:415.6200 R:349.0000 loss:4.6586 exploreP:0.0100\n",
      "Episode:1871 meanR:417.0100 R:378.0000 loss:5.0193 exploreP:0.0100\n",
      "Episode:1872 meanR:419.6300 R:500.0000 loss:1.5481 exploreP:0.0100\n",
      "Episode:1873 meanR:421.9800 R:461.0000 loss:11.7974 exploreP:0.0100\n",
      "Episode:1874 meanR:420.7600 R:255.0000 loss:8.8712 exploreP:0.0100\n",
      "Episode:1875 meanR:423.4700 R:500.0000 loss:3.4950 exploreP:0.0100\n",
      "Episode:1876 meanR:423.3100 R:214.0000 loss:46.5265 exploreP:0.0100\n",
      "Episode:1877 meanR:426.1800 R:500.0000 loss:1.6227 exploreP:0.0100\n",
      "Episode:1878 meanR:429.1000 R:500.0000 loss:12.0620 exploreP:0.0100\n",
      "Episode:1879 meanR:432.0900 R:500.0000 loss:10.2980 exploreP:0.0100\n",
      "Episode:1880 meanR:433.9800 R:500.0000 loss:16.9970 exploreP:0.0100\n",
      "Episode:1881 meanR:433.7000 R:156.0000 loss:63.1891 exploreP:0.0100\n",
      "Episode:1882 meanR:436.7600 R:500.0000 loss:4.1546 exploreP:0.0100\n",
      "Episode:1883 meanR:439.5300 R:500.0000 loss:18.3300 exploreP:0.0100\n",
      "Episode:1884 meanR:440.7600 R:500.0000 loss:19.2952 exploreP:0.0100\n",
      "Episode:1885 meanR:440.7600 R:500.0000 loss:16.5409 exploreP:0.0100\n",
      "Episode:1886 meanR:442.7100 R:500.0000 loss:16.2397 exploreP:0.0100\n",
      "Episode:1887 meanR:444.6500 R:500.0000 loss:17.3187 exploreP:0.0100\n",
      "Episode:1888 meanR:444.6500 R:500.0000 loss:18.1310 exploreP:0.0100\n",
      "Episode:1889 meanR:441.0300 R:138.0000 loss:68.8115 exploreP:0.0100\n",
      "Episode:1890 meanR:438.6200 R:259.0000 loss:10.0965 exploreP:0.0100\n",
      "Episode:1891 meanR:434.7300 R:111.0000 loss:37.4865 exploreP:0.0100\n",
      "Episode:1892 meanR:432.2600 R:253.0000 loss:6.0249 exploreP:0.0100\n",
      "Episode:1893 meanR:428.2000 R:94.0000 loss:10.8860 exploreP:0.0100\n",
      "Episode:1894 meanR:424.3900 R:119.0000 loss:10.3656 exploreP:0.0100\n",
      "Episode:1895 meanR:427.6800 R:500.0000 loss:1.1745 exploreP:0.0100\n",
      "Episode:1896 meanR:429.7400 R:500.0000 loss:18.4406 exploreP:0.0100\n",
      "Episode:1897 meanR:429.7400 R:500.0000 loss:16.6364 exploreP:0.0100\n",
      "Episode:1898 meanR:429.7400 R:500.0000 loss:18.3085 exploreP:0.0100\n",
      "Episode:1899 meanR:429.7400 R:500.0000 loss:16.4688 exploreP:0.0100\n",
      "Episode:1900 meanR:429.7400 R:500.0000 loss:14.7265 exploreP:0.0100\n",
      "Episode:1901 meanR:427.5600 R:282.0000 loss:31.7101 exploreP:0.0100\n",
      "Episode:1902 meanR:427.5600 R:500.0000 loss:3.7715 exploreP:0.0100\n",
      "Episode:1903 meanR:424.1300 R:157.0000 loss:55.4449 exploreP:0.0100\n",
      "Episode:1904 meanR:429.0100 R:500.0000 loss:0.8140 exploreP:0.0100\n",
      "Episode:1905 meanR:429.0100 R:500.0000 loss:13.0790 exploreP:0.0100\n",
      "Episode:1906 meanR:429.0100 R:500.0000 loss:19.4014 exploreP:0.0100\n",
      "Episode:1907 meanR:429.0100 R:500.0000 loss:17.1352 exploreP:0.0100\n",
      "Episode:1908 meanR:429.0100 R:500.0000 loss:15.2936 exploreP:0.0100\n",
      "Episode:1909 meanR:429.0100 R:500.0000 loss:19.2063 exploreP:0.0100\n",
      "Episode:1910 meanR:429.0100 R:500.0000 loss:16.0748 exploreP:0.0100\n",
      "Episode:1911 meanR:429.0100 R:500.0000 loss:15.8974 exploreP:0.0100\n",
      "Episode:1912 meanR:429.0100 R:500.0000 loss:15.6841 exploreP:0.0100\n",
      "Episode:1913 meanR:429.0100 R:500.0000 loss:15.5152 exploreP:0.0100\n",
      "Episode:1914 meanR:429.0100 R:500.0000 loss:16.1115 exploreP:0.0100\n",
      "Episode:1915 meanR:429.0100 R:500.0000 loss:17.9188 exploreP:0.0100\n",
      "Episode:1916 meanR:429.0100 R:500.0000 loss:17.1013 exploreP:0.0100\n",
      "Episode:1917 meanR:429.0100 R:500.0000 loss:16.5080 exploreP:0.0100\n",
      "Episode:1918 meanR:429.0100 R:500.0000 loss:16.7836 exploreP:0.0100\n",
      "Episode:1919 meanR:429.0100 R:500.0000 loss:17.7826 exploreP:0.0100\n",
      "Episode:1920 meanR:429.0100 R:500.0000 loss:17.2330 exploreP:0.0100\n",
      "Episode:1921 meanR:429.0100 R:500.0000 loss:16.9588 exploreP:0.0100\n",
      "Episode:1922 meanR:429.0100 R:500.0000 loss:17.8616 exploreP:0.0100\n",
      "Episode:1923 meanR:429.0100 R:500.0000 loss:17.7703 exploreP:0.0100\n",
      "Episode:1924 meanR:429.0100 R:500.0000 loss:15.1581 exploreP:0.0100\n",
      "Episode:1925 meanR:429.0100 R:500.0000 loss:17.8999 exploreP:0.0100\n",
      "Episode:1926 meanR:425.7400 R:173.0000 loss:46.8544 exploreP:0.0100\n",
      "Episode:1927 meanR:425.7400 R:500.0000 loss:3.1140 exploreP:0.0100\n",
      "Episode:1928 meanR:429.4600 R:500.0000 loss:16.7703 exploreP:0.0100\n",
      "Episode:1929 meanR:432.7300 R:500.0000 loss:20.5508 exploreP:0.0100\n",
      "Episode:1930 meanR:429.9300 R:220.0000 loss:31.7162 exploreP:0.0100\n",
      "Episode:1931 meanR:427.5000 R:257.0000 loss:4.2747 exploreP:0.0100\n",
      "Episode:1932 meanR:425.5800 R:308.0000 loss:8.7055 exploreP:0.0100\n",
      "Episode:1933 meanR:425.5800 R:500.0000 loss:5.3526 exploreP:0.0100\n",
      "Episode:1934 meanR:425.5800 R:500.0000 loss:13.8984 exploreP:0.0100\n",
      "Episode:1935 meanR:425.5800 R:500.0000 loss:14.5700 exploreP:0.0100\n",
      "Episode:1936 meanR:424.4500 R:11.0000 loss:78.9311 exploreP:0.0100\n",
      "Episode:1937 meanR:423.9800 R:11.0000 loss:148.7051 exploreP:0.0100\n",
      "Episode:1938 meanR:419.0800 R:10.0000 loss:199.8281 exploreP:0.0100\n",
      "Episode:1939 meanR:419.0800 R:500.0000 loss:17.3829 exploreP:0.0100\n",
      "Episode:1940 meanR:419.0800 R:500.0000 loss:18.4377 exploreP:0.0100\n",
      "Episode:1941 meanR:419.0800 R:500.0000 loss:9.0740 exploreP:0.0100\n",
      "Episode:1942 meanR:419.0800 R:500.0000 loss:5.4920 exploreP:0.0100\n",
      "Episode:1943 meanR:419.0800 R:500.0000 loss:3.1454 exploreP:0.0100\n",
      "Episode:1944 meanR:415.3600 R:128.0000 loss:7.1605 exploreP:0.0100\n",
      "Episode:1945 meanR:415.3600 R:500.0000 loss:2.9579 exploreP:0.0100\n",
      "Episode:1946 meanR:415.3600 R:500.0000 loss:12.9602 exploreP:0.0100\n",
      "Episode:1947 meanR:413.3600 R:300.0000 loss:28.5818 exploreP:0.0100\n",
      "Episode:1948 meanR:413.3600 R:500.0000 loss:5.9103 exploreP:0.0100\n",
      "Episode:1949 meanR:410.7000 R:234.0000 loss:30.2522 exploreP:0.0100\n",
      "Episode:1950 meanR:410.7000 R:500.0000 loss:2.5669 exploreP:0.0100\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "        initial_state = sess.run(model.initial_state)\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            # Explore (Env) or Exploit (Model): NO\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            # if explore_p > np.random.rand():\n",
    "            #     action = env.action_space.sample()\n",
    "            # else:\n",
    "            action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([initial_state, final_state])\n",
    "            total_reward += reward\n",
    "            initial_state = final_state\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            #batch, rnn_states = memory.sample(batch_size)\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            initial_states = np.array([each[0] for each in rnn_states])\n",
    "            final_states = np.array([each[1] for each in rnn_states])\n",
    "            next_actions_logits = sess.run(model.actions_logits, \n",
    "                                           feed_dict = {model.states: next_states, \n",
    "                                                        model.initial_state: final_states[0].reshape([1, -1])})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs,\n",
    "                                                        model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward:120.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-seq.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    \n",
    "    # Episode/epoch\n",
    "    for _ in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        \n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits, initial_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                    feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                                 model.initial_state: initial_state})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # At the end of each episode\n",
    "        print('total_reward:{}'.format(total_reward))\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

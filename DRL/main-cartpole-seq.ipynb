{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential DQN\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aras/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "state = env.reset()\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action) # take a random action\n",
    "    #print('state, action, next_state, reward, done, info:', state, action, next_state, reward, done, info)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    # RNN\n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    return states, actions, targetQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, num_classes, initial_state, cell, lstm_size, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, final_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)\n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx], [self.states[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state:', np.array(states).shape[1], \n",
    "#       'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "action_size = 2\n",
    "state_size = 4\n",
    "hidden_size = 4*2               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 128            # memory capacity - 1000 DQN\n",
    "batch_size = 128             # experience mini-batch size - 20 DQN\n",
    "gamma = 0.99                 # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 8)\n",
      "(1, ?, 8) (1, 8)\n",
      "(1, ?, 8) (1, 8)\n",
      "(?, 8)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    memory.states.append(np.zeros([1, hidden_size]))\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        # Reseting the env/first state\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training\n",
    "# batch = memory.buffer\n",
    "# states = np.array([each[0] for each in batch])\n",
    "# actions = np.array([each[1] for each in batch])\n",
    "# next_states = np.array([each[2] for each in batch])\n",
    "# rewards = np.array([each[3] for each in batch])\n",
    "# dones = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_states = np.array(memory.states)\n",
    "# initial_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:9.0000 R:9.0000 loss:1.2233\n",
      "Episode:1 meanR:9.0000 R:9.0000 loss:1.2138\n",
      "Episode:2 meanR:9.0000 R:9.0000 loss:1.2093\n",
      "Episode:3 meanR:9.0000 R:9.0000 loss:1.2098\n",
      "Episode:4 meanR:9.0000 R:9.0000 loss:1.2867\n",
      "Episode:5 meanR:9.1667 R:10.0000 loss:1.2996\n",
      "Episode:6 meanR:9.1429 R:9.0000 loss:1.3731\n",
      "Episode:7 meanR:9.0000 R:8.0000 loss:1.4004\n",
      "Episode:8 meanR:9.0000 R:9.0000 loss:1.4432\n",
      "Episode:9 meanR:9.0000 R:9.0000 loss:1.5317\n",
      "Episode:10 meanR:9.0909 R:10.0000 loss:1.6059\n",
      "Episode:11 meanR:9.1667 R:10.0000 loss:1.6575\n",
      "Episode:12 meanR:9.2308 R:10.0000 loss:1.6962\n",
      "Episode:13 meanR:9.2143 R:9.0000 loss:1.7094\n",
      "Episode:14 meanR:9.1333 R:8.0000 loss:1.7141\n",
      "Episode:15 meanR:9.1875 R:10.0000 loss:1.6172\n",
      "Episode:16 meanR:9.1765 R:9.0000 loss:1.6447\n",
      "Episode:17 meanR:9.1667 R:9.0000 loss:1.5614\n",
      "Episode:18 meanR:9.1053 R:8.0000 loss:1.4644\n",
      "Episode:19 meanR:9.2000 R:11.0000 loss:1.3644\n",
      "Episode:20 meanR:9.2381 R:10.0000 loss:1.2323\n",
      "Episode:21 meanR:9.1818 R:8.0000 loss:1.1936\n",
      "Episode:22 meanR:9.1304 R:8.0000 loss:1.1267\n",
      "Episode:23 meanR:9.1667 R:10.0000 loss:1.0209\n",
      "Episode:24 meanR:9.1600 R:9.0000 loss:0.9947\n",
      "Episode:25 meanR:9.1154 R:8.0000 loss:0.9983\n",
      "Episode:26 meanR:9.1111 R:9.0000 loss:1.0068\n",
      "Episode:27 meanR:9.1071 R:9.0000 loss:1.0209\n",
      "Episode:28 meanR:9.1034 R:9.0000 loss:1.0322\n",
      "Episode:29 meanR:9.0667 R:8.0000 loss:1.0377\n",
      "Episode:30 meanR:9.0645 R:9.0000 loss:1.0512\n",
      "Episode:31 meanR:9.0625 R:9.0000 loss:1.0610\n",
      "Episode:32 meanR:9.0909 R:10.0000 loss:1.0734\n",
      "Episode:33 meanR:9.0882 R:9.0000 loss:1.0856\n",
      "Episode:34 meanR:9.1143 R:10.0000 loss:1.0990\n",
      "Episode:35 meanR:9.1389 R:10.0000 loss:1.1113\n",
      "Episode:36 meanR:9.1351 R:9.0000 loss:1.1301\n",
      "Episode:37 meanR:9.1316 R:9.0000 loss:1.1347\n",
      "Episode:38 meanR:9.1538 R:10.0000 loss:1.1525\n",
      "Episode:39 meanR:9.1750 R:10.0000 loss:1.1663\n",
      "Episode:40 meanR:9.1707 R:9.0000 loss:1.1737\n",
      "Episode:41 meanR:9.1905 R:10.0000 loss:1.1849\n",
      "Episode:42 meanR:9.2093 R:10.0000 loss:1.1945\n",
      "Episode:43 meanR:9.2273 R:10.0000 loss:1.2052\n",
      "Episode:44 meanR:9.2667 R:11.0000 loss:1.2101\n",
      "Episode:45 meanR:9.2826 R:10.0000 loss:1.2235\n",
      "Episode:46 meanR:9.2766 R:9.0000 loss:1.2338\n",
      "Episode:47 meanR:9.2917 R:10.0000 loss:1.2421\n",
      "Episode:48 meanR:9.3061 R:10.0000 loss:1.2510\n",
      "Episode:49 meanR:9.3000 R:9.0000 loss:1.2619\n",
      "Episode:50 meanR:9.2941 R:9.0000 loss:1.2693\n",
      "Episode:51 meanR:9.2692 R:8.0000 loss:1.2858\n",
      "Episode:52 meanR:9.2453 R:8.0000 loss:1.2890\n",
      "Episode:53 meanR:9.2407 R:9.0000 loss:1.2988\n",
      "Episode:54 meanR:9.2545 R:10.0000 loss:1.3079\n",
      "Episode:55 meanR:9.2679 R:10.0000 loss:1.3154\n",
      "Episode:56 meanR:9.2982 R:11.0000 loss:1.3221\n",
      "Episode:57 meanR:9.3103 R:10.0000 loss:1.3298\n",
      "Episode:58 meanR:9.3220 R:10.0000 loss:1.3377\n",
      "Episode:59 meanR:9.3333 R:10.0000 loss:1.3451\n",
      "Episode:60 meanR:9.3279 R:9.0000 loss:1.3524\n",
      "Episode:61 meanR:9.3387 R:10.0000 loss:1.3607\n",
      "Episode:62 meanR:9.3333 R:9.0000 loss:1.3668\n",
      "Episode:63 meanR:9.3438 R:10.0000 loss:1.3730\n",
      "Episode:64 meanR:9.3538 R:10.0000 loss:1.3761\n",
      "Episode:65 meanR:9.3485 R:9.0000 loss:1.3707\n",
      "Episode:66 meanR:9.3284 R:8.0000 loss:1.3946\n",
      "Episode:67 meanR:9.3382 R:10.0000 loss:1.3926\n",
      "Episode:68 meanR:9.3333 R:9.0000 loss:1.4006\n",
      "Episode:69 meanR:9.3429 R:10.0000 loss:1.4085\n",
      "Episode:70 meanR:9.3380 R:9.0000 loss:1.4178\n",
      "Episode:71 meanR:9.3333 R:9.0000 loss:1.4266\n",
      "Episode:72 meanR:9.3425 R:10.0000 loss:1.4344\n",
      "Episode:73 meanR:9.3514 R:10.0000 loss:1.4401\n",
      "Episode:74 meanR:9.3333 R:8.0000 loss:1.4460\n",
      "Episode:75 meanR:9.3158 R:8.0000 loss:1.4544\n",
      "Episode:76 meanR:9.3247 R:10.0000 loss:1.4655\n",
      "Episode:77 meanR:9.3077 R:8.0000 loss:1.4683\n",
      "Episode:78 meanR:9.3038 R:9.0000 loss:1.4793\n",
      "Episode:79 meanR:9.3125 R:10.0000 loss:1.4882\n",
      "Episode:80 meanR:9.3210 R:10.0000 loss:1.4905\n",
      "Episode:81 meanR:9.3171 R:9.0000 loss:1.4918\n",
      "Episode:82 meanR:9.3373 R:11.0000 loss:1.4989\n",
      "Episode:83 meanR:9.3452 R:10.0000 loss:1.5001\n",
      "Episode:84 meanR:9.3529 R:10.0000 loss:1.5036\n",
      "Episode:85 meanR:9.3605 R:10.0000 loss:1.5066\n",
      "Episode:86 meanR:9.3448 R:8.0000 loss:1.5145\n",
      "Episode:87 meanR:9.3409 R:9.0000 loss:1.5225\n",
      "Episode:88 meanR:9.3483 R:10.0000 loss:1.5253\n",
      "Episode:89 meanR:9.3333 R:8.0000 loss:1.5269\n",
      "Episode:90 meanR:9.3407 R:10.0000 loss:1.5337\n",
      "Episode:91 meanR:9.3478 R:10.0000 loss:1.5348\n",
      "Episode:92 meanR:9.3441 R:9.0000 loss:1.5397\n",
      "Episode:93 meanR:9.3404 R:9.0000 loss:1.5481\n",
      "Episode:94 meanR:9.3368 R:9.0000 loss:1.5566\n",
      "Episode:95 meanR:9.3333 R:9.0000 loss:1.5649\n",
      "Episode:96 meanR:9.3299 R:9.0000 loss:1.5755\n",
      "Episode:97 meanR:9.3163 R:8.0000 loss:1.5855\n",
      "Episode:98 meanR:9.3232 R:10.0000 loss:1.5977\n",
      "Episode:99 meanR:9.3300 R:10.0000 loss:1.6034\n",
      "Episode:100 meanR:9.3400 R:10.0000 loss:1.6054\n",
      "Episode:101 meanR:9.3400 R:9.0000 loss:1.6059\n",
      "Episode:102 meanR:9.3500 R:10.0000 loss:1.6118\n",
      "Episode:103 meanR:9.3600 R:10.0000 loss:1.6126\n",
      "Episode:104 meanR:9.3700 R:10.0000 loss:1.6162\n",
      "Episode:105 meanR:9.3500 R:8.0000 loss:1.6245\n",
      "Episode:106 meanR:9.3600 R:10.0000 loss:1.6311\n",
      "Episode:107 meanR:9.3600 R:8.0000 loss:1.6356\n",
      "Episode:108 meanR:9.3600 R:9.0000 loss:1.6432\n",
      "Episode:109 meanR:9.3700 R:10.0000 loss:1.6465\n",
      "Episode:110 meanR:9.3500 R:8.0000 loss:1.6515\n",
      "Episode:111 meanR:9.3300 R:8.0000 loss:1.6605\n",
      "Episode:112 meanR:9.3300 R:10.0000 loss:1.6688\n",
      "Episode:113 meanR:9.3400 R:10.0000 loss:1.6744\n",
      "Episode:114 meanR:9.3600 R:10.0000 loss:1.6794\n",
      "Episode:115 meanR:9.3600 R:10.0000 loss:1.6830\n",
      "Episode:116 meanR:9.3600 R:9.0000 loss:1.6895\n",
      "Episode:117 meanR:9.3600 R:9.0000 loss:1.6991\n",
      "Episode:118 meanR:9.3700 R:9.0000 loss:1.7079\n",
      "Episode:119 meanR:9.3500 R:9.0000 loss:1.7140\n",
      "Episode:120 meanR:9.3500 R:10.0000 loss:1.7170\n",
      "Episode:121 meanR:9.3600 R:9.0000 loss:1.7188\n",
      "Episode:122 meanR:9.3800 R:10.0000 loss:1.7200\n",
      "Episode:123 meanR:9.3700 R:9.0000 loss:1.7250\n",
      "Episode:124 meanR:9.3800 R:10.0000 loss:1.7242\n",
      "Episode:125 meanR:9.3900 R:9.0000 loss:1.7241\n",
      "Episode:126 meanR:9.4000 R:10.0000 loss:1.7334\n",
      "Episode:127 meanR:9.3900 R:8.0000 loss:1.7451\n",
      "Episode:128 meanR:9.3900 R:9.0000 loss:1.7570\n",
      "Episode:129 meanR:9.4100 R:10.0000 loss:1.7650\n",
      "Episode:130 meanR:9.4200 R:10.0000 loss:1.7660\n",
      "Episode:131 meanR:9.4300 R:10.0000 loss:1.7653\n",
      "Episode:132 meanR:9.4400 R:11.0000 loss:1.7630\n",
      "Episode:133 meanR:9.4400 R:9.0000 loss:1.7659\n",
      "Episode:134 meanR:9.4500 R:11.0000 loss:1.7684\n",
      "Episode:135 meanR:9.4400 R:9.0000 loss:1.7702\n",
      "Episode:136 meanR:9.4300 R:8.0000 loss:1.7846\n",
      "Episode:137 meanR:9.4400 R:10.0000 loss:1.7911\n",
      "Episode:138 meanR:9.4400 R:10.0000 loss:1.7950\n",
      "Episode:139 meanR:9.4300 R:9.0000 loss:1.7989\n",
      "Episode:140 meanR:9.4400 R:10.0000 loss:1.8030\n",
      "Episode:141 meanR:9.4400 R:10.0000 loss:1.7919\n",
      "Episode:142 meanR:9.4300 R:9.0000 loss:1.8132\n",
      "Episode:143 meanR:9.4300 R:10.0000 loss:1.8142\n",
      "Episode:144 meanR:9.4100 R:9.0000 loss:1.8239\n",
      "Episode:145 meanR:9.4000 R:9.0000 loss:1.8370\n",
      "Episode:146 meanR:9.4100 R:10.0000 loss:1.8485\n",
      "Episode:147 meanR:9.4100 R:10.0000 loss:1.8508\n",
      "Episode:148 meanR:9.4000 R:9.0000 loss:1.8636\n",
      "Episode:149 meanR:9.4100 R:10.0000 loss:1.8634\n",
      "Episode:150 meanR:9.4100 R:9.0000 loss:1.8638\n",
      "Episode:151 meanR:9.4200 R:9.0000 loss:1.8756\n",
      "Episode:152 meanR:9.4300 R:9.0000 loss:1.8861\n",
      "Episode:153 meanR:9.4200 R:8.0000 loss:1.8980\n",
      "Episode:154 meanR:9.4000 R:8.0000 loss:1.9138\n",
      "Episode:155 meanR:9.4000 R:10.0000 loss:1.9257\n",
      "Episode:156 meanR:9.3900 R:10.0000 loss:1.9279\n",
      "Episode:157 meanR:9.3700 R:8.0000 loss:1.9364\n",
      "Episode:158 meanR:9.3700 R:10.0000 loss:1.9456\n",
      "Episode:159 meanR:9.3600 R:9.0000 loss:1.9485\n",
      "Episode:160 meanR:9.3700 R:10.0000 loss:1.9558\n",
      "Episode:161 meanR:9.3500 R:8.0000 loss:1.9667\n",
      "Episode:162 meanR:9.3600 R:10.0000 loss:1.9779\n",
      "Episode:163 meanR:9.3600 R:10.0000 loss:1.9805\n",
      "Episode:164 meanR:9.3600 R:10.0000 loss:1.9813\n",
      "Episode:165 meanR:9.3600 R:9.0000 loss:1.9824\n",
      "Episode:166 meanR:9.3700 R:9.0000 loss:1.9861\n",
      "Episode:167 meanR:9.3700 R:10.0000 loss:1.9807\n",
      "Episode:168 meanR:9.3600 R:8.0000 loss:1.9829\n",
      "Episode:169 meanR:9.3500 R:9.0000 loss:1.9970\n",
      "Episode:170 meanR:9.3400 R:8.0000 loss:2.0105\n",
      "Episode:171 meanR:9.3600 R:11.0000 loss:2.0121\n",
      "Episode:172 meanR:9.3600 R:10.0000 loss:2.0102\n",
      "Episode:173 meanR:9.3500 R:9.0000 loss:2.0140\n",
      "Episode:174 meanR:9.3600 R:9.0000 loss:2.0239\n",
      "Episode:175 meanR:9.3700 R:9.0000 loss:2.0271\n",
      "Episode:176 meanR:9.3600 R:9.0000 loss:2.0387\n",
      "Episode:177 meanR:9.3800 R:10.0000 loss:2.0476\n",
      "Episode:178 meanR:9.3700 R:8.0000 loss:2.0599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:179 meanR:9.3600 R:9.0000 loss:2.0725\n",
      "Episode:180 meanR:9.3600 R:10.0000 loss:2.0754\n",
      "Episode:181 meanR:9.3700 R:10.0000 loss:2.0766\n",
      "Episode:182 meanR:9.3600 R:10.0000 loss:2.0698\n",
      "Episode:183 meanR:9.3600 R:10.0000 loss:2.0637\n",
      "Episode:184 meanR:9.3600 R:10.0000 loss:2.0601\n",
      "Episode:185 meanR:9.3500 R:9.0000 loss:2.0785\n",
      "Episode:186 meanR:9.3700 R:10.0000 loss:2.0838\n",
      "Episode:187 meanR:9.3800 R:10.0000 loss:2.0807\n",
      "Episode:188 meanR:9.3700 R:9.0000 loss:2.0841\n",
      "Episode:189 meanR:9.3800 R:9.0000 loss:2.0897\n",
      "Episode:190 meanR:9.3700 R:9.0000 loss:2.0979\n",
      "Episode:191 meanR:9.3700 R:10.0000 loss:2.1023\n",
      "Episode:192 meanR:9.3800 R:10.0000 loss:2.0935\n",
      "Episode:193 meanR:9.3900 R:10.0000 loss:2.0962\n",
      "Episode:194 meanR:9.3900 R:9.0000 loss:2.1064\n",
      "Episode:195 meanR:9.3900 R:9.0000 loss:2.1211\n",
      "Episode:196 meanR:9.4000 R:10.0000 loss:2.1305\n",
      "Episode:197 meanR:9.4200 R:10.0000 loss:2.1368\n",
      "Episode:198 meanR:9.4200 R:10.0000 loss:2.1412\n",
      "Episode:199 meanR:9.4100 R:9.0000 loss:2.1442\n",
      "Episode:200 meanR:9.4000 R:9.0000 loss:2.1598\n",
      "Episode:201 meanR:9.4000 R:9.0000 loss:2.1738\n",
      "Episode:202 meanR:9.3900 R:9.0000 loss:2.1787\n",
      "Episode:203 meanR:9.3800 R:9.0000 loss:2.1847\n",
      "Episode:204 meanR:9.3800 R:10.0000 loss:2.1878\n",
      "Episode:205 meanR:9.3900 R:9.0000 loss:2.2004\n",
      "Episode:206 meanR:9.3800 R:9.0000 loss:2.2145\n",
      "Episode:207 meanR:9.3900 R:9.0000 loss:2.2280\n",
      "Episode:208 meanR:9.3900 R:9.0000 loss:2.2348\n",
      "Episode:209 meanR:9.3800 R:9.0000 loss:2.2421\n",
      "Episode:210 meanR:9.4000 R:10.0000 loss:2.2513\n",
      "Episode:211 meanR:9.4200 R:10.0000 loss:2.2583\n",
      "Episode:212 meanR:9.4200 R:10.0000 loss:2.2638\n",
      "Episode:213 meanR:9.4200 R:10.0000 loss:2.2602\n",
      "Episode:214 meanR:9.4000 R:8.0000 loss:2.2684\n",
      "Episode:215 meanR:9.4000 R:10.0000 loss:2.2715\n",
      "Episode:216 meanR:9.4100 R:10.0000 loss:2.2678\n",
      "Episode:217 meanR:9.4200 R:10.0000 loss:2.2656\n",
      "Episode:218 meanR:9.4200 R:9.0000 loss:2.2769\n",
      "Episode:219 meanR:9.4100 R:8.0000 loss:2.2891\n",
      "Episode:220 meanR:9.4100 R:10.0000 loss:2.2918\n",
      "Episode:221 meanR:9.4100 R:9.0000 loss:2.2938\n",
      "Episode:222 meanR:9.4000 R:9.0000 loss:2.3002\n",
      "Episode:223 meanR:9.4100 R:10.0000 loss:2.3022\n",
      "Episode:224 meanR:9.4100 R:10.0000 loss:2.3083\n",
      "Episode:225 meanR:9.4100 R:9.0000 loss:2.3222\n",
      "Episode:226 meanR:9.4100 R:10.0000 loss:2.3306\n",
      "Episode:227 meanR:9.4200 R:9.0000 loss:2.3405\n",
      "Episode:228 meanR:9.4300 R:10.0000 loss:2.3326\n",
      "Episode:229 meanR:9.4300 R:10.0000 loss:2.3405\n",
      "Episode:230 meanR:9.4100 R:8.0000 loss:2.3610\n",
      "Episode:231 meanR:9.4000 R:9.0000 loss:2.3777\n",
      "Episode:232 meanR:9.3900 R:10.0000 loss:2.3751\n",
      "Episode:233 meanR:9.4000 R:10.0000 loss:2.3637\n",
      "Episode:234 meanR:9.3800 R:9.0000 loss:2.3756\n",
      "Episode:235 meanR:9.3700 R:8.0000 loss:2.3882\n",
      "Episode:236 meanR:9.3800 R:9.0000 loss:2.3989\n",
      "Episode:237 meanR:9.3700 R:9.0000 loss:2.4155\n",
      "Episode:238 meanR:9.3700 R:10.0000 loss:2.4248\n",
      "Episode:239 meanR:9.3800 R:10.0000 loss:2.4225\n",
      "Episode:240 meanR:9.3800 R:10.0000 loss:2.4271\n",
      "Episode:241 meanR:9.3700 R:9.0000 loss:2.4312\n",
      "Episode:242 meanR:9.3700 R:9.0000 loss:2.4477\n",
      "Episode:243 meanR:9.3800 R:11.0000 loss:2.4477\n",
      "Episode:244 meanR:9.3900 R:10.0000 loss:2.4296\n",
      "Episode:245 meanR:9.3900 R:9.0000 loss:2.4345\n",
      "Episode:246 meanR:9.3800 R:9.0000 loss:2.4523\n",
      "Episode:247 meanR:9.3600 R:8.0000 loss:2.4755\n",
      "Episode:248 meanR:9.3800 R:11.0000 loss:2.4667\n",
      "Episode:249 meanR:9.3800 R:10.0000 loss:2.4480\n",
      "Episode:250 meanR:9.3900 R:10.0000 loss:2.4452\n",
      "Episode:251 meanR:9.3900 R:9.0000 loss:2.4482\n",
      "Episode:252 meanR:9.4000 R:10.0000 loss:2.4604\n",
      "Episode:253 meanR:9.4200 R:10.0000 loss:2.4677\n",
      "Episode:254 meanR:9.4400 R:10.0000 loss:2.4713\n",
      "Episode:255 meanR:9.4300 R:9.0000 loss:2.4712\n",
      "Episode:256 meanR:9.4200 R:9.0000 loss:2.4836\n",
      "Episode:257 meanR:9.4400 R:10.0000 loss:2.5046\n",
      "Episode:258 meanR:9.4400 R:10.0000 loss:2.5086\n",
      "Episode:259 meanR:9.4500 R:10.0000 loss:2.5021\n",
      "Episode:260 meanR:9.4400 R:9.0000 loss:2.4929\n",
      "Episode:261 meanR:9.4500 R:9.0000 loss:2.5082\n",
      "Episode:262 meanR:9.4500 R:10.0000 loss:2.5269\n",
      "Episode:263 meanR:9.4300 R:8.0000 loss:2.5469\n",
      "Episode:264 meanR:9.4200 R:9.0000 loss:2.5674\n",
      "Episode:265 meanR:9.4200 R:9.0000 loss:2.5749\n",
      "Episode:266 meanR:9.4300 R:10.0000 loss:2.5867\n",
      "Episode:267 meanR:9.4300 R:10.0000 loss:2.5926\n",
      "Episode:268 meanR:9.4300 R:8.0000 loss:2.6154\n",
      "Episode:269 meanR:9.4400 R:10.0000 loss:2.6166\n",
      "Episode:270 meanR:9.4600 R:10.0000 loss:2.6128\n",
      "Episode:271 meanR:9.4400 R:9.0000 loss:2.6283\n",
      "Episode:272 meanR:9.4400 R:10.0000 loss:2.6378\n",
      "Episode:273 meanR:9.4500 R:10.0000 loss:2.6424\n",
      "Episode:274 meanR:9.4500 R:9.0000 loss:2.6454\n",
      "Episode:275 meanR:9.4500 R:9.0000 loss:2.6519\n",
      "Episode:276 meanR:9.4500 R:9.0000 loss:2.6684\n",
      "Episode:277 meanR:9.4400 R:9.0000 loss:2.6632\n",
      "Episode:278 meanR:9.4500 R:9.0000 loss:2.6695\n",
      "Episode:279 meanR:9.4500 R:9.0000 loss:2.6768\n",
      "Episode:280 meanR:9.4400 R:9.0000 loss:2.6965\n",
      "Episode:281 meanR:9.4300 R:9.0000 loss:2.7127\n",
      "Episode:282 meanR:9.4200 R:9.0000 loss:2.7120\n",
      "Episode:283 meanR:9.4200 R:10.0000 loss:2.7202\n",
      "Episode:284 meanR:9.4100 R:9.0000 loss:2.7340\n",
      "Episode:285 meanR:9.4000 R:8.0000 loss:2.7506\n",
      "Episode:286 meanR:9.3900 R:9.0000 loss:2.7697\n",
      "Episode:287 meanR:9.3800 R:9.0000 loss:2.7912\n",
      "Episode:288 meanR:9.3800 R:9.0000 loss:2.8035\n",
      "Episode:289 meanR:9.3900 R:10.0000 loss:2.8004\n",
      "Episode:290 meanR:9.3900 R:9.0000 loss:2.8014\n",
      "Episode:291 meanR:9.3900 R:10.0000 loss:2.8006\n",
      "Episode:292 meanR:9.3800 R:9.0000 loss:2.7998\n",
      "Episode:293 meanR:9.3800 R:10.0000 loss:2.7985\n",
      "Episode:294 meanR:9.3800 R:9.0000 loss:2.7982\n",
      "Episode:295 meanR:9.3700 R:8.0000 loss:2.8133\n",
      "Episode:296 meanR:9.3700 R:10.0000 loss:2.8177\n",
      "Episode:297 meanR:9.3700 R:10.0000 loss:2.8191\n",
      "Episode:298 meanR:9.3700 R:10.0000 loss:2.8118\n",
      "Episode:299 meanR:9.3700 R:9.0000 loss:2.8006\n",
      "Episode:300 meanR:9.3800 R:10.0000 loss:2.7969\n",
      "Episode:301 meanR:9.3800 R:9.0000 loss:2.7985\n",
      "Episode:302 meanR:9.3800 R:9.0000 loss:2.8069\n",
      "Episode:303 meanR:9.3800 R:9.0000 loss:2.8267\n",
      "Episode:304 meanR:9.3700 R:9.0000 loss:2.8347\n",
      "Episode:305 meanR:9.3700 R:9.0000 loss:2.8546\n",
      "Episode:306 meanR:9.3800 R:10.0000 loss:2.8527\n",
      "Episode:307 meanR:9.3800 R:9.0000 loss:2.8675\n",
      "Episode:308 meanR:9.3700 R:8.0000 loss:2.8837\n",
      "Episode:309 meanR:9.3800 R:10.0000 loss:2.8732\n",
      "Episode:310 meanR:9.3700 R:9.0000 loss:2.8887\n",
      "Episode:311 meanR:9.3600 R:9.0000 loss:2.9085\n",
      "Episode:312 meanR:9.3600 R:10.0000 loss:2.9191\n",
      "Episode:313 meanR:9.3500 R:9.0000 loss:2.9239\n",
      "Episode:314 meanR:9.3700 R:10.0000 loss:2.9320\n",
      "Episode:315 meanR:9.3600 R:9.0000 loss:2.9373\n",
      "Episode:316 meanR:9.3600 R:10.0000 loss:2.9333\n",
      "Episode:317 meanR:9.3500 R:9.0000 loss:2.9348\n",
      "Episode:318 meanR:9.3400 R:8.0000 loss:2.9516\n",
      "Episode:319 meanR:9.3600 R:10.0000 loss:2.9538\n",
      "Episode:320 meanR:9.3500 R:9.0000 loss:2.9669\n",
      "Episode:321 meanR:9.3600 R:10.0000 loss:2.9638\n",
      "Episode:322 meanR:9.3700 R:10.0000 loss:2.9422\n",
      "Episode:323 meanR:9.3700 R:10.0000 loss:2.9475\n",
      "Episode:324 meanR:9.3600 R:9.0000 loss:2.9478\n",
      "Episode:325 meanR:9.3600 R:9.0000 loss:2.9570\n",
      "Episode:326 meanR:9.3400 R:8.0000 loss:2.9904\n",
      "Episode:327 meanR:9.3400 R:9.0000 loss:3.0015\n",
      "Episode:328 meanR:9.3400 R:10.0000 loss:3.0102\n",
      "Episode:329 meanR:9.3200 R:8.0000 loss:3.0258\n",
      "Episode:330 meanR:9.3400 R:10.0000 loss:3.0383\n",
      "Episode:331 meanR:9.3400 R:9.0000 loss:3.0422\n",
      "Episode:332 meanR:9.3200 R:8.0000 loss:3.0471\n",
      "Episode:333 meanR:9.3100 R:9.0000 loss:3.0668\n",
      "Episode:334 meanR:9.3100 R:9.0000 loss:3.0789\n",
      "Episode:335 meanR:9.3300 R:10.0000 loss:3.0879\n",
      "Episode:336 meanR:9.3400 R:10.0000 loss:3.0941\n",
      "Episode:337 meanR:9.3500 R:10.0000 loss:3.1015\n",
      "Episode:338 meanR:9.3400 R:9.0000 loss:3.1072\n",
      "Episode:339 meanR:9.3300 R:9.0000 loss:3.1132\n",
      "Episode:340 meanR:9.3300 R:10.0000 loss:3.0962\n",
      "Episode:341 meanR:9.3400 R:10.0000 loss:3.0826\n",
      "Episode:342 meanR:9.3400 R:9.0000 loss:3.0984\n",
      "Episode:343 meanR:9.3100 R:8.0000 loss:3.1039\n",
      "Episode:344 meanR:9.3100 R:10.0000 loss:3.1164\n",
      "Episode:345 meanR:9.3200 R:10.0000 loss:3.1059\n",
      "Episode:346 meanR:9.3300 R:10.0000 loss:3.0805\n",
      "Episode:347 meanR:9.3400 R:9.0000 loss:3.0814\n",
      "Episode:348 meanR:9.3300 R:10.0000 loss:3.0821\n",
      "Episode:349 meanR:9.3300 R:10.0000 loss:3.0886\n",
      "Episode:350 meanR:9.3100 R:8.0000 loss:3.1167\n",
      "Episode:351 meanR:9.3100 R:9.0000 loss:3.1442\n",
      "Episode:352 meanR:9.3000 R:9.0000 loss:3.1504\n",
      "Episode:353 meanR:9.3000 R:10.0000 loss:3.1483\n",
      "Episode:354 meanR:9.3000 R:10.0000 loss:3.1543\n",
      "Episode:355 meanR:9.3100 R:10.0000 loss:3.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:356 meanR:9.3100 R:9.0000 loss:3.1579\n",
      "Episode:357 meanR:9.3100 R:10.0000 loss:3.1415\n",
      "Episode:358 meanR:9.3100 R:10.0000 loss:3.1512\n",
      "Episode:359 meanR:9.3000 R:9.0000 loss:3.1679\n",
      "Episode:360 meanR:9.3100 R:10.0000 loss:3.1799\n",
      "Episode:361 meanR:9.3100 R:9.0000 loss:3.1813\n",
      "Episode:362 meanR:9.3000 R:9.0000 loss:3.2070\n",
      "Episode:363 meanR:9.3200 R:10.0000 loss:3.2154\n",
      "Episode:364 meanR:9.3200 R:9.0000 loss:3.1990\n",
      "Episode:365 meanR:9.3300 R:10.0000 loss:3.1959\n",
      "Episode:366 meanR:9.3300 R:10.0000 loss:3.1897\n",
      "Episode:367 meanR:9.3300 R:10.0000 loss:3.1985\n",
      "Episode:368 meanR:9.3500 R:10.0000 loss:3.2054\n",
      "Episode:369 meanR:9.3400 R:9.0000 loss:3.2184\n",
      "Episode:370 meanR:9.3300 R:9.0000 loss:3.2264\n",
      "Episode:371 meanR:9.3300 R:9.0000 loss:3.2545\n",
      "Episode:372 meanR:9.3200 R:9.0000 loss:3.2771\n",
      "Episode:373 meanR:9.3100 R:9.0000 loss:3.2844\n",
      "Episode:374 meanR:9.3200 R:10.0000 loss:3.2958\n",
      "Episode:375 meanR:9.3300 R:10.0000 loss:3.2860\n",
      "Episode:376 meanR:9.3300 R:9.0000 loss:3.2892\n",
      "Episode:377 meanR:9.3400 R:10.0000 loss:3.3012\n",
      "Episode:378 meanR:9.3400 R:9.0000 loss:3.3023\n",
      "Episode:379 meanR:9.3500 R:10.0000 loss:3.3177\n",
      "Episode:380 meanR:9.3600 R:10.0000 loss:3.3249\n",
      "Episode:381 meanR:9.3700 R:10.0000 loss:3.3326\n",
      "Episode:382 meanR:9.3700 R:9.0000 loss:3.3502\n",
      "Episode:383 meanR:9.3700 R:10.0000 loss:3.3429\n",
      "Episode:384 meanR:9.3800 R:10.0000 loss:3.3318\n",
      "Episode:385 meanR:9.3900 R:9.0000 loss:3.3303\n",
      "Episode:386 meanR:9.3800 R:8.0000 loss:3.3480\n",
      "Episode:387 meanR:9.3800 R:9.0000 loss:3.3672\n",
      "Episode:388 meanR:9.3700 R:8.0000 loss:3.4077\n",
      "Episode:389 meanR:9.3600 R:9.0000 loss:3.4373\n",
      "Episode:390 meanR:9.3700 R:10.0000 loss:3.4314\n",
      "Episode:391 meanR:9.3600 R:9.0000 loss:3.4496\n",
      "Episode:392 meanR:9.3600 R:9.0000 loss:3.4589\n",
      "Episode:393 meanR:9.3600 R:10.0000 loss:3.4702\n",
      "Episode:394 meanR:9.3800 R:11.0000 loss:3.4636\n",
      "Episode:395 meanR:9.3900 R:9.0000 loss:3.4791\n",
      "Episode:396 meanR:9.3900 R:10.0000 loss:3.4733\n",
      "Episode:397 meanR:9.3900 R:10.0000 loss:3.4803\n",
      "Episode:398 meanR:9.3800 R:9.0000 loss:3.5014\n",
      "Episode:399 meanR:9.3900 R:10.0000 loss:3.4918\n",
      "Episode:400 meanR:9.3900 R:10.0000 loss:3.4600\n",
      "Episode:401 meanR:9.3900 R:9.0000 loss:3.4585\n",
      "Episode:402 meanR:9.3900 R:9.0000 loss:3.4462\n",
      "Episode:403 meanR:9.3900 R:9.0000 loss:3.4557\n",
      "Episode:404 meanR:9.3900 R:9.0000 loss:3.4819\n",
      "Episode:405 meanR:9.3900 R:9.0000 loss:3.4885\n",
      "Episode:406 meanR:9.3800 R:9.0000 loss:3.4980\n",
      "Episode:407 meanR:9.3800 R:9.0000 loss:3.5268\n",
      "Episode:408 meanR:9.3900 R:9.0000 loss:3.5723\n",
      "Episode:409 meanR:9.3900 R:10.0000 loss:3.5657\n",
      "Episode:410 meanR:9.3900 R:9.0000 loss:3.5876\n",
      "Episode:411 meanR:9.3900 R:9.0000 loss:3.6136\n",
      "Episode:412 meanR:9.3900 R:10.0000 loss:3.6097\n",
      "Episode:413 meanR:9.3900 R:9.0000 loss:3.6286\n",
      "Episode:414 meanR:9.3900 R:10.0000 loss:3.6400\n",
      "Episode:415 meanR:9.4100 R:11.0000 loss:3.6143\n",
      "Episode:416 meanR:9.4000 R:9.0000 loss:3.6095\n",
      "Episode:417 meanR:9.4100 R:10.0000 loss:3.6018\n",
      "Episode:418 meanR:9.4300 R:10.0000 loss:3.5880\n",
      "Episode:419 meanR:9.4200 R:9.0000 loss:3.5861\n",
      "Episode:420 meanR:9.4300 R:10.0000 loss:3.5841\n",
      "Episode:421 meanR:9.4200 R:9.0000 loss:3.5804\n",
      "Episode:422 meanR:9.4100 R:9.0000 loss:3.5894\n",
      "Episode:423 meanR:9.4000 R:9.0000 loss:3.6174\n",
      "Episode:424 meanR:9.4100 R:10.0000 loss:3.6117\n",
      "Episode:425 meanR:9.4000 R:8.0000 loss:3.6221\n",
      "Episode:426 meanR:9.4100 R:9.0000 loss:3.6594\n",
      "Episode:427 meanR:9.4000 R:8.0000 loss:3.6849\n",
      "Episode:428 meanR:9.4000 R:10.0000 loss:3.7035\n",
      "Episode:429 meanR:9.4200 R:10.0000 loss:3.7288\n",
      "Episode:430 meanR:9.4200 R:10.0000 loss:3.7183\n",
      "Episode:431 meanR:9.4300 R:10.0000 loss:3.7262\n",
      "Episode:432 meanR:9.4600 R:11.0000 loss:3.7169\n",
      "Episode:433 meanR:9.4500 R:8.0000 loss:3.7298\n",
      "Episode:434 meanR:9.4400 R:8.0000 loss:3.7802\n",
      "Episode:435 meanR:9.4400 R:10.0000 loss:3.7761\n",
      "Episode:436 meanR:9.4300 R:9.0000 loss:3.7765\n",
      "Episode:437 meanR:9.4300 R:10.0000 loss:3.7682\n",
      "Episode:438 meanR:9.4300 R:9.0000 loss:3.7888\n",
      "Episode:439 meanR:9.4400 R:10.0000 loss:3.7591\n",
      "Episode:440 meanR:9.4400 R:10.0000 loss:3.7428\n",
      "Episode:441 meanR:9.4300 R:9.0000 loss:3.7209\n",
      "Episode:442 meanR:9.4300 R:9.0000 loss:3.7518\n",
      "Episode:443 meanR:9.4400 R:9.0000 loss:3.7829\n",
      "Episode:444 meanR:9.4300 R:9.0000 loss:3.8132\n",
      "Episode:445 meanR:9.4300 R:10.0000 loss:3.8270\n",
      "Episode:446 meanR:9.4300 R:10.0000 loss:3.8515\n",
      "Episode:447 meanR:9.4400 R:10.0000 loss:3.8159\n",
      "Episode:448 meanR:9.4400 R:10.0000 loss:3.7825\n",
      "Episode:449 meanR:9.4200 R:8.0000 loss:3.8188\n",
      "Episode:450 meanR:9.4200 R:8.0000 loss:3.8488\n",
      "Episode:451 meanR:9.4300 R:10.0000 loss:3.8685\n",
      "Episode:452 meanR:9.4400 R:10.0000 loss:3.8561\n",
      "Episode:453 meanR:9.4300 R:9.0000 loss:3.8793\n",
      "Episode:454 meanR:9.4300 R:10.0000 loss:3.8908\n",
      "Episode:455 meanR:9.4200 R:9.0000 loss:3.8928\n",
      "Episode:456 meanR:9.4300 R:10.0000 loss:3.8825\n",
      "Episode:457 meanR:9.4200 R:9.0000 loss:3.8832\n",
      "Episode:458 meanR:9.4200 R:10.0000 loss:3.8770\n",
      "Episode:459 meanR:9.4200 R:9.0000 loss:3.9004\n",
      "Episode:460 meanR:9.4200 R:10.0000 loss:3.9142\n",
      "Episode:461 meanR:9.4200 R:9.0000 loss:3.9388\n",
      "Episode:462 meanR:9.4200 R:9.0000 loss:3.9657\n",
      "Episode:463 meanR:9.4000 R:8.0000 loss:3.9681\n",
      "Episode:464 meanR:9.4000 R:9.0000 loss:3.9585\n",
      "Episode:465 meanR:9.3900 R:9.0000 loss:3.9892\n",
      "Episode:466 meanR:9.3800 R:9.0000 loss:4.0181\n",
      "Episode:467 meanR:9.3700 R:9.0000 loss:4.0279\n",
      "Episode:468 meanR:9.3500 R:8.0000 loss:4.0668\n",
      "Episode:469 meanR:9.3400 R:8.0000 loss:4.0995\n",
      "Episode:470 meanR:9.3500 R:10.0000 loss:4.1145\n",
      "Episode:471 meanR:9.3400 R:8.0000 loss:4.1387\n",
      "Episode:472 meanR:9.3400 R:9.0000 loss:4.1608\n",
      "Episode:473 meanR:9.3500 R:10.0000 loss:4.1792\n",
      "Episode:474 meanR:9.3500 R:10.0000 loss:4.1634\n",
      "Episode:475 meanR:9.3300 R:8.0000 loss:4.1918\n",
      "Episode:476 meanR:9.3400 R:10.0000 loss:4.1989\n",
      "Episode:477 meanR:9.3300 R:9.0000 loss:4.1904\n",
      "Episode:478 meanR:9.3300 R:9.0000 loss:4.1732\n",
      "Episode:479 meanR:9.3300 R:10.0000 loss:4.1690\n",
      "Episode:480 meanR:9.3200 R:9.0000 loss:4.1611\n",
      "Episode:481 meanR:9.3100 R:9.0000 loss:4.1692\n",
      "Episode:482 meanR:9.3000 R:8.0000 loss:4.1793\n",
      "Episode:483 meanR:9.3000 R:10.0000 loss:4.1491\n",
      "Episode:484 meanR:9.3000 R:10.0000 loss:4.1382\n",
      "Episode:485 meanR:9.3000 R:9.0000 loss:4.1196\n",
      "Episode:486 meanR:9.3200 R:10.0000 loss:4.1072\n",
      "Episode:487 meanR:9.3300 R:10.0000 loss:4.1155\n",
      "Episode:488 meanR:9.3500 R:10.0000 loss:4.1191\n",
      "Episode:489 meanR:9.3600 R:10.0000 loss:4.0818\n",
      "Episode:490 meanR:9.3500 R:9.0000 loss:4.1058\n",
      "Episode:491 meanR:9.3500 R:9.0000 loss:4.1109\n",
      "Episode:492 meanR:9.3400 R:8.0000 loss:4.1383\n",
      "Episode:493 meanR:9.3300 R:9.0000 loss:4.1773\n",
      "Episode:494 meanR:9.3100 R:9.0000 loss:4.1862\n",
      "Episode:495 meanR:9.3000 R:8.0000 loss:4.2135\n",
      "Episode:496 meanR:9.2900 R:9.0000 loss:4.2012\n",
      "Episode:497 meanR:9.2800 R:9.0000 loss:4.2298\n",
      "Episode:498 meanR:9.2800 R:9.0000 loss:4.2580\n",
      "Episode:499 meanR:9.2800 R:10.0000 loss:4.2541\n",
      "Episode:500 meanR:9.2800 R:10.0000 loss:4.2555\n",
      "Episode:501 meanR:9.2900 R:10.0000 loss:4.2632\n",
      "Episode:502 meanR:9.2900 R:9.0000 loss:4.2881\n",
      "Episode:503 meanR:9.3000 R:10.0000 loss:4.3015\n",
      "Episode:504 meanR:9.3000 R:9.0000 loss:4.3102\n",
      "Episode:505 meanR:9.3100 R:10.0000 loss:4.2972\n",
      "Episode:506 meanR:9.3200 R:10.0000 loss:4.2514\n",
      "Episode:507 meanR:9.3200 R:9.0000 loss:4.2495\n",
      "Episode:508 meanR:9.3300 R:10.0000 loss:4.2378\n",
      "Episode:509 meanR:9.3200 R:9.0000 loss:4.2086\n",
      "Episode:510 meanR:9.3300 R:10.0000 loss:4.2055\n",
      "Episode:511 meanR:9.3200 R:8.0000 loss:4.2113\n",
      "Episode:512 meanR:9.3200 R:10.0000 loss:4.2225\n",
      "Episode:513 meanR:9.3200 R:9.0000 loss:4.2437\n",
      "Episode:514 meanR:9.3200 R:10.0000 loss:4.2609\n",
      "Episode:515 meanR:9.3100 R:10.0000 loss:4.2683\n",
      "Episode:516 meanR:9.3100 R:9.0000 loss:4.2677\n",
      "Episode:517 meanR:9.3000 R:9.0000 loss:4.3002\n",
      "Episode:518 meanR:9.2900 R:9.0000 loss:4.3088\n",
      "Episode:519 meanR:9.2900 R:9.0000 loss:4.3435\n",
      "Episode:520 meanR:9.2800 R:9.0000 loss:4.3776\n",
      "Episode:521 meanR:9.2800 R:9.0000 loss:4.3852\n",
      "Episode:522 meanR:9.2700 R:8.0000 loss:4.4387\n",
      "Episode:523 meanR:9.2800 R:10.0000 loss:4.4359\n",
      "Episode:524 meanR:9.2800 R:10.0000 loss:4.4350\n",
      "Episode:525 meanR:9.3000 R:10.0000 loss:4.3950\n",
      "Episode:526 meanR:9.3100 R:10.0000 loss:4.4000\n",
      "Episode:527 meanR:9.3300 R:10.0000 loss:4.3834\n",
      "Episode:528 meanR:9.3200 R:9.0000 loss:4.4103\n",
      "Episode:529 meanR:9.3200 R:10.0000 loss:4.4230\n",
      "Episode:530 meanR:9.3100 R:9.0000 loss:4.4236\n",
      "Episode:531 meanR:9.3000 R:9.0000 loss:4.4309\n",
      "Episode:532 meanR:9.2800 R:9.0000 loss:4.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:533 meanR:9.3000 R:10.0000 loss:4.4262\n",
      "Episode:534 meanR:9.3100 R:9.0000 loss:4.4238\n",
      "Episode:535 meanR:9.3000 R:9.0000 loss:4.4294\n",
      "Episode:536 meanR:9.3100 R:10.0000 loss:4.3963\n",
      "Episode:537 meanR:9.3100 R:10.0000 loss:4.4053\n",
      "Episode:538 meanR:9.3100 R:9.0000 loss:4.4266\n",
      "Episode:539 meanR:9.2900 R:8.0000 loss:4.4844\n",
      "Episode:540 meanR:9.2800 R:9.0000 loss:4.5282\n",
      "Episode:541 meanR:9.2800 R:9.0000 loss:4.5626\n",
      "Episode:542 meanR:9.2700 R:8.0000 loss:4.5945\n",
      "Episode:543 meanR:9.2600 R:8.0000 loss:4.6315\n",
      "Episode:544 meanR:9.2700 R:10.0000 loss:4.6606\n",
      "Episode:545 meanR:9.2600 R:9.0000 loss:4.6482\n",
      "Episode:546 meanR:9.2600 R:10.0000 loss:4.6388\n",
      "Episode:547 meanR:9.2600 R:10.0000 loss:4.6333\n",
      "Episode:548 meanR:9.2500 R:9.0000 loss:4.6418\n",
      "Episode:549 meanR:9.2700 R:10.0000 loss:4.6266\n",
      "Episode:550 meanR:9.2800 R:9.0000 loss:4.6478\n",
      "Episode:551 meanR:9.2800 R:10.0000 loss:4.6612\n",
      "Episode:552 meanR:9.2700 R:9.0000 loss:4.6690\n",
      "Episode:553 meanR:9.2600 R:8.0000 loss:4.6770\n",
      "Episode:554 meanR:9.2500 R:9.0000 loss:4.6825\n",
      "Episode:555 meanR:9.2500 R:9.0000 loss:4.6896\n",
      "Episode:556 meanR:9.2500 R:10.0000 loss:4.6470\n",
      "Episode:557 meanR:9.2600 R:10.0000 loss:4.5930\n",
      "Episode:558 meanR:9.2500 R:9.0000 loss:4.6212\n",
      "Episode:559 meanR:9.2500 R:9.0000 loss:4.6293\n",
      "Episode:560 meanR:9.2500 R:10.0000 loss:4.6427\n",
      "Episode:561 meanR:9.2400 R:8.0000 loss:4.6985\n",
      "Episode:562 meanR:9.2300 R:8.0000 loss:4.7341\n",
      "Episode:563 meanR:9.2500 R:10.0000 loss:4.7472\n",
      "Episode:564 meanR:9.2400 R:8.0000 loss:4.7754\n",
      "Episode:565 meanR:9.2500 R:10.0000 loss:4.7880\n",
      "Episode:566 meanR:9.2600 R:10.0000 loss:4.7789\n",
      "Episode:567 meanR:9.2700 R:10.0000 loss:4.7261\n",
      "Episode:568 meanR:9.2900 R:10.0000 loss:4.6971\n",
      "Episode:569 meanR:9.3000 R:9.0000 loss:4.6982\n",
      "Episode:570 meanR:9.3000 R:10.0000 loss:4.7131\n",
      "Episode:571 meanR:9.3200 R:10.0000 loss:4.7212\n",
      "Episode:572 meanR:9.3200 R:9.0000 loss:4.7206\n",
      "Episode:573 meanR:9.3000 R:8.0000 loss:4.7535\n",
      "Episode:574 meanR:9.3000 R:10.0000 loss:4.7689\n",
      "Episode:575 meanR:9.3100 R:9.0000 loss:4.7397\n",
      "Episode:576 meanR:9.3000 R:9.0000 loss:4.7184\n",
      "Episode:577 meanR:9.3100 R:10.0000 loss:4.7333\n",
      "Episode:578 meanR:9.3200 R:10.0000 loss:4.6880\n",
      "Episode:579 meanR:9.3100 R:9.0000 loss:4.7108\n",
      "Episode:580 meanR:9.3200 R:10.0000 loss:4.7318\n",
      "Episode:581 meanR:9.3200 R:9.0000 loss:4.7579\n",
      "Episode:582 meanR:9.3400 R:10.0000 loss:4.7751\n",
      "Episode:583 meanR:9.3400 R:10.0000 loss:4.7554\n",
      "Episode:584 meanR:9.3400 R:10.0000 loss:4.7636\n",
      "Episode:585 meanR:9.3500 R:10.0000 loss:4.7711\n",
      "Episode:586 meanR:9.3400 R:9.0000 loss:4.7649\n",
      "Episode:587 meanR:9.3400 R:10.0000 loss:4.7290\n",
      "Episode:588 meanR:9.3300 R:9.0000 loss:4.7489\n",
      "Episode:589 meanR:9.3200 R:9.0000 loss:4.7579\n",
      "Episode:590 meanR:9.3200 R:9.0000 loss:4.7653\n",
      "Episode:591 meanR:9.3200 R:9.0000 loss:4.8055\n",
      "Episode:592 meanR:9.3400 R:10.0000 loss:4.8268\n",
      "Episode:593 meanR:9.3400 R:9.0000 loss:4.8232\n",
      "Episode:594 meanR:9.3500 R:10.0000 loss:4.8417\n",
      "Episode:595 meanR:9.3600 R:9.0000 loss:4.8384\n",
      "Episode:596 meanR:9.3700 R:10.0000 loss:4.8599\n",
      "Episode:597 meanR:9.3700 R:9.0000 loss:4.8859\n",
      "Episode:598 meanR:9.3800 R:10.0000 loss:4.9048\n",
      "Episode:599 meanR:9.3800 R:10.0000 loss:4.9123\n",
      "Episode:600 meanR:9.3700 R:9.0000 loss:4.9099\n",
      "Episode:601 meanR:9.3500 R:8.0000 loss:4.9758\n",
      "Episode:602 meanR:9.3500 R:9.0000 loss:4.9874\n",
      "Episode:603 meanR:9.3500 R:10.0000 loss:4.9701\n",
      "Episode:604 meanR:9.3600 R:10.0000 loss:4.9467\n",
      "Episode:605 meanR:9.3600 R:10.0000 loss:4.9277\n",
      "Episode:606 meanR:9.3600 R:10.0000 loss:4.9337\n",
      "Episode:607 meanR:9.3700 R:10.0000 loss:4.9133\n",
      "Episode:608 meanR:9.3700 R:10.0000 loss:4.9188\n",
      "Episode:609 meanR:9.3800 R:10.0000 loss:4.8989\n",
      "Episode:610 meanR:9.3700 R:9.0000 loss:4.9192\n",
      "Episode:611 meanR:9.3800 R:9.0000 loss:4.9251\n",
      "Episode:612 meanR:9.3800 R:10.0000 loss:4.9516\n",
      "Episode:613 meanR:9.3900 R:10.0000 loss:4.9590\n",
      "Episode:614 meanR:9.3700 R:8.0000 loss:4.9649\n",
      "Episode:615 meanR:9.3700 R:10.0000 loss:4.9430\n",
      "Episode:616 meanR:9.3600 R:8.0000 loss:4.9445\n",
      "Episode:617 meanR:9.3700 R:10.0000 loss:4.9907\n",
      "Episode:618 meanR:9.3800 R:10.0000 loss:4.9980\n",
      "Episode:619 meanR:9.3900 R:10.0000 loss:5.0080\n",
      "Episode:620 meanR:9.3800 R:8.0000 loss:5.0519\n",
      "Episode:621 meanR:9.3900 R:10.0000 loss:5.0850\n",
      "Episode:622 meanR:9.4000 R:9.0000 loss:5.1159\n",
      "Episode:623 meanR:9.3800 R:8.0000 loss:5.1865\n",
      "Episode:624 meanR:9.3700 R:9.0000 loss:5.1958\n",
      "Episode:625 meanR:9.3700 R:10.0000 loss:5.1758\n",
      "Episode:626 meanR:9.3700 R:10.0000 loss:5.1809\n",
      "Episode:627 meanR:9.3500 R:8.0000 loss:5.2437\n",
      "Episode:628 meanR:9.3500 R:9.0000 loss:5.2304\n",
      "Episode:629 meanR:9.3400 R:9.0000 loss:5.2573\n",
      "Episode:630 meanR:9.3400 R:9.0000 loss:5.2431\n",
      "Episode:631 meanR:9.3400 R:9.0000 loss:5.2700\n",
      "Episode:632 meanR:9.3400 R:9.0000 loss:5.3022\n",
      "Episode:633 meanR:9.3500 R:11.0000 loss:5.3000\n",
      "Episode:634 meanR:9.3400 R:8.0000 loss:5.2985\n",
      "Episode:635 meanR:9.3500 R:10.0000 loss:5.3009\n",
      "Episode:636 meanR:9.3400 R:9.0000 loss:5.3090\n",
      "Episode:637 meanR:9.3300 R:9.0000 loss:5.2867\n",
      "Episode:638 meanR:9.3200 R:8.0000 loss:5.3159\n",
      "Episode:639 meanR:9.3300 R:9.0000 loss:5.3464\n",
      "Episode:640 meanR:9.3300 R:9.0000 loss:5.3696\n",
      "Episode:641 meanR:9.3400 R:10.0000 loss:5.3813\n",
      "Episode:642 meanR:9.3600 R:10.0000 loss:5.3168\n",
      "Episode:643 meanR:9.3800 R:10.0000 loss:5.2872\n",
      "Episode:644 meanR:9.3700 R:9.0000 loss:5.2894\n",
      "Episode:645 meanR:9.3700 R:9.0000 loss:5.2939\n",
      "Episode:646 meanR:9.3700 R:10.0000 loss:5.2760\n",
      "Episode:647 meanR:9.3500 R:8.0000 loss:5.3721\n",
      "Episode:648 meanR:9.3500 R:9.0000 loss:5.3560\n",
      "Episode:649 meanR:9.3400 R:9.0000 loss:5.3854\n",
      "Episode:650 meanR:9.3500 R:10.0000 loss:5.3715\n",
      "Episode:651 meanR:9.3500 R:10.0000 loss:5.3395\n",
      "Episode:652 meanR:9.3500 R:9.0000 loss:5.3065\n",
      "Episode:653 meanR:9.3700 R:10.0000 loss:5.2879\n",
      "Episode:654 meanR:9.3800 R:10.0000 loss:5.2631\n",
      "Episode:655 meanR:9.3700 R:8.0000 loss:5.3170\n",
      "Episode:656 meanR:9.3700 R:10.0000 loss:5.3421\n",
      "Episode:657 meanR:9.3700 R:10.0000 loss:5.3511\n",
      "Episode:658 meanR:9.3600 R:8.0000 loss:5.3784\n",
      "Episode:659 meanR:9.3600 R:9.0000 loss:5.3906\n",
      "Episode:660 meanR:9.3600 R:10.0000 loss:5.4026\n",
      "Episode:661 meanR:9.3800 R:10.0000 loss:5.3445\n",
      "Episode:662 meanR:9.4000 R:10.0000 loss:5.3196\n",
      "Episode:663 meanR:9.3900 R:9.0000 loss:5.3117\n",
      "Episode:664 meanR:9.4100 R:10.0000 loss:5.3358\n",
      "Episode:665 meanR:9.3900 R:8.0000 loss:5.3876\n",
      "Episode:666 meanR:9.3900 R:10.0000 loss:5.3822\n",
      "Episode:667 meanR:9.3900 R:10.0000 loss:5.3903\n",
      "Episode:668 meanR:9.3800 R:9.0000 loss:5.4220\n",
      "Episode:669 meanR:9.3800 R:9.0000 loss:5.3936\n",
      "Episode:670 meanR:9.3700 R:9.0000 loss:5.4353\n",
      "Episode:671 meanR:9.3800 R:11.0000 loss:5.4284\n",
      "Episode:672 meanR:9.3700 R:8.0000 loss:5.3982\n",
      "Episode:673 meanR:9.3800 R:9.0000 loss:5.4210\n",
      "Episode:674 meanR:9.3700 R:9.0000 loss:5.4647\n",
      "Episode:675 meanR:9.3800 R:10.0000 loss:5.4797\n",
      "Episode:676 meanR:9.3800 R:9.0000 loss:5.5176\n",
      "Episode:677 meanR:9.3800 R:10.0000 loss:5.4959\n",
      "Episode:678 meanR:9.3700 R:9.0000 loss:5.5288\n",
      "Episode:679 meanR:9.3800 R:10.0000 loss:5.4758\n",
      "Episode:680 meanR:9.3700 R:9.0000 loss:5.5059\n",
      "Episode:681 meanR:9.3600 R:8.0000 loss:5.5827\n",
      "Episode:682 meanR:9.3500 R:9.0000 loss:5.5934\n",
      "Episode:683 meanR:9.3500 R:10.0000 loss:5.5684\n",
      "Episode:684 meanR:9.3300 R:8.0000 loss:5.6049\n",
      "Episode:685 meanR:9.3200 R:9.0000 loss:5.6647\n",
      "Episode:686 meanR:9.3300 R:10.0000 loss:5.6409\n",
      "Episode:687 meanR:9.3300 R:10.0000 loss:5.5936\n",
      "Episode:688 meanR:9.3300 R:9.0000 loss:5.5945\n",
      "Episode:689 meanR:9.3300 R:9.0000 loss:5.6369\n",
      "Episode:690 meanR:9.3300 R:9.0000 loss:5.6433\n",
      "Episode:691 meanR:9.3300 R:9.0000 loss:5.6808\n",
      "Episode:692 meanR:9.3200 R:9.0000 loss:5.6927\n",
      "Episode:693 meanR:9.3200 R:9.0000 loss:5.7209\n",
      "Episode:694 meanR:9.3200 R:10.0000 loss:5.7191\n",
      "Episode:695 meanR:9.3300 R:10.0000 loss:5.6456\n",
      "Episode:696 meanR:9.3200 R:9.0000 loss:5.6417\n",
      "Episode:697 meanR:9.3300 R:10.0000 loss:5.6528\n",
      "Episode:698 meanR:9.3200 R:9.0000 loss:5.6168\n",
      "Episode:699 meanR:9.3100 R:9.0000 loss:5.6226\n",
      "Episode:700 meanR:9.3200 R:10.0000 loss:5.6391\n",
      "Episode:701 meanR:9.3400 R:10.0000 loss:5.6454\n",
      "Episode:702 meanR:9.3500 R:10.0000 loss:5.6175\n",
      "Episode:703 meanR:9.3500 R:10.0000 loss:5.5893\n",
      "Episode:704 meanR:9.3400 R:9.0000 loss:5.5809\n",
      "Episode:705 meanR:9.3300 R:9.0000 loss:5.5885\n",
      "Episode:706 meanR:9.3200 R:9.0000 loss:5.5940\n",
      "Episode:707 meanR:9.3200 R:10.0000 loss:5.5840\n",
      "Episode:708 meanR:9.3200 R:10.0000 loss:5.5930\n",
      "Episode:709 meanR:9.3100 R:9.0000 loss:5.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:710 meanR:9.3000 R:8.0000 loss:5.6495\n",
      "Episode:711 meanR:9.3000 R:9.0000 loss:5.7099\n",
      "Episode:712 meanR:9.2900 R:9.0000 loss:5.7167\n",
      "Episode:713 meanR:9.2900 R:10.0000 loss:5.6983\n",
      "Episode:714 meanR:9.3000 R:9.0000 loss:5.7324\n",
      "Episode:715 meanR:9.2900 R:9.0000 loss:5.7777\n",
      "Episode:716 meanR:9.3100 R:10.0000 loss:5.7897\n",
      "Episode:717 meanR:9.3000 R:9.0000 loss:5.8275\n",
      "Episode:718 meanR:9.3000 R:10.0000 loss:5.8015\n",
      "Episode:719 meanR:9.2900 R:9.0000 loss:5.8026\n",
      "Episode:720 meanR:9.3000 R:9.0000 loss:5.8086\n",
      "Episode:721 meanR:9.3000 R:10.0000 loss:5.8208\n",
      "Episode:722 meanR:9.3100 R:10.0000 loss:5.8266\n",
      "Episode:723 meanR:9.3100 R:8.0000 loss:5.8640\n",
      "Episode:724 meanR:9.3100 R:9.0000 loss:5.8334\n",
      "Episode:725 meanR:9.3100 R:10.0000 loss:5.8101\n",
      "Episode:726 meanR:9.3000 R:9.0000 loss:5.8062\n",
      "Episode:727 meanR:9.3100 R:9.0000 loss:5.8505\n",
      "Episode:728 meanR:9.3100 R:9.0000 loss:5.8562\n",
      "Episode:729 meanR:9.3000 R:8.0000 loss:5.9018\n",
      "Episode:730 meanR:9.3100 R:10.0000 loss:5.9115\n",
      "Episode:731 meanR:9.3000 R:8.0000 loss:5.9512\n",
      "Episode:732 meanR:9.3000 R:9.0000 loss:5.9821\n",
      "Episode:733 meanR:9.2900 R:10.0000 loss:5.9774\n",
      "Episode:734 meanR:9.3100 R:10.0000 loss:5.9368\n",
      "Episode:735 meanR:9.3000 R:9.0000 loss:5.9706\n",
      "Episode:736 meanR:9.2900 R:8.0000 loss:6.0104\n",
      "Episode:737 meanR:9.2900 R:9.0000 loss:6.0652\n",
      "Episode:738 meanR:9.3100 R:10.0000 loss:6.0030\n",
      "Episode:739 meanR:9.3100 R:9.0000 loss:6.0178\n",
      "Episode:740 meanR:9.3200 R:10.0000 loss:6.0148\n",
      "Episode:741 meanR:9.3200 R:10.0000 loss:5.9714\n",
      "Episode:742 meanR:9.3100 R:9.0000 loss:5.9690\n",
      "Episode:743 meanR:9.3100 R:10.0000 loss:5.9064\n",
      "Episode:744 meanR:9.3200 R:10.0000 loss:5.9105\n",
      "Episode:745 meanR:9.3300 R:10.0000 loss:5.8432\n",
      "Episode:746 meanR:9.3300 R:10.0000 loss:5.8143\n",
      "Episode:747 meanR:9.3600 R:11.0000 loss:5.8063\n",
      "Episode:748 meanR:9.3700 R:10.0000 loss:5.7925\n",
      "Episode:749 meanR:9.3800 R:10.0000 loss:5.7425\n",
      "Episode:750 meanR:9.3600 R:8.0000 loss:5.7305\n",
      "Episode:751 meanR:9.3600 R:10.0000 loss:5.7441\n",
      "Episode:752 meanR:9.3700 R:10.0000 loss:5.7327\n",
      "Episode:753 meanR:9.3600 R:9.0000 loss:5.7508\n",
      "Episode:754 meanR:9.3400 R:8.0000 loss:5.7852\n",
      "Episode:755 meanR:9.3600 R:10.0000 loss:5.8516\n",
      "Episode:756 meanR:9.3500 R:9.0000 loss:5.8329\n",
      "Episode:757 meanR:9.3400 R:9.0000 loss:5.8847\n",
      "Episode:758 meanR:9.3600 R:10.0000 loss:5.9139\n",
      "Episode:759 meanR:9.3600 R:9.0000 loss:5.9413\n",
      "Episode:760 meanR:9.3600 R:10.0000 loss:5.9663\n",
      "Episode:761 meanR:9.3600 R:10.0000 loss:6.0115\n",
      "Episode:762 meanR:9.3500 R:9.0000 loss:6.0477\n",
      "Episode:763 meanR:9.3600 R:10.0000 loss:6.0612\n",
      "Episode:764 meanR:9.3400 R:8.0000 loss:6.0460\n",
      "Episode:765 meanR:9.3500 R:9.0000 loss:6.1060\n",
      "Episode:766 meanR:9.3500 R:10.0000 loss:6.1174\n",
      "Episode:767 meanR:9.3500 R:10.0000 loss:6.0858\n",
      "Episode:768 meanR:9.3600 R:10.0000 loss:6.0139\n",
      "Episode:769 meanR:9.3700 R:10.0000 loss:6.0234\n",
      "Episode:770 meanR:9.3700 R:9.0000 loss:6.0090\n",
      "Episode:771 meanR:9.3500 R:9.0000 loss:6.0175\n",
      "Episode:772 meanR:9.3600 R:9.0000 loss:6.0663\n",
      "Episode:773 meanR:9.3600 R:9.0000 loss:6.0717\n",
      "Episode:774 meanR:9.3500 R:8.0000 loss:6.1560\n",
      "Episode:775 meanR:9.3500 R:10.0000 loss:6.1739\n",
      "Episode:776 meanR:9.3500 R:9.0000 loss:6.1751\n",
      "Episode:777 meanR:9.3400 R:9.0000 loss:6.2207\n",
      "Episode:778 meanR:9.3400 R:9.0000 loss:6.1862\n",
      "Episode:779 meanR:9.3200 R:8.0000 loss:6.2276\n",
      "Episode:780 meanR:9.3300 R:10.0000 loss:6.2379\n",
      "Episode:781 meanR:9.3600 R:11.0000 loss:6.2110\n",
      "Episode:782 meanR:9.3700 R:10.0000 loss:6.2102\n",
      "Episode:783 meanR:9.3500 R:8.0000 loss:6.2916\n",
      "Episode:784 meanR:9.3700 R:10.0000 loss:6.2626\n",
      "Episode:785 meanR:9.3900 R:11.0000 loss:6.1940\n",
      "Episode:786 meanR:9.3800 R:9.0000 loss:6.1785\n",
      "Episode:787 meanR:9.3700 R:9.0000 loss:6.1857\n",
      "Episode:788 meanR:9.3800 R:10.0000 loss:6.1240\n",
      "Episode:789 meanR:9.3800 R:9.0000 loss:6.1558\n",
      "Episode:790 meanR:9.3900 R:10.0000 loss:6.1369\n",
      "Episode:791 meanR:9.4000 R:10.0000 loss:6.1046\n",
      "Episode:792 meanR:9.3900 R:8.0000 loss:6.1043\n",
      "Episode:793 meanR:9.3900 R:9.0000 loss:6.0942\n",
      "Episode:794 meanR:9.3800 R:9.0000 loss:6.1452\n",
      "Episode:795 meanR:9.3700 R:9.0000 loss:6.2376\n",
      "Episode:796 meanR:9.3700 R:9.0000 loss:6.2863\n",
      "Episode:797 meanR:9.3700 R:10.0000 loss:6.2202\n",
      "Episode:798 meanR:9.3800 R:10.0000 loss:6.2272\n",
      "Episode:799 meanR:9.3800 R:9.0000 loss:6.3036\n",
      "Episode:800 meanR:9.3800 R:10.0000 loss:6.2761\n",
      "Episode:801 meanR:9.3800 R:10.0000 loss:6.2416\n",
      "Episode:802 meanR:9.3800 R:10.0000 loss:6.2482\n",
      "Episode:803 meanR:9.3800 R:10.0000 loss:6.2162\n",
      "Episode:804 meanR:9.3800 R:9.0000 loss:6.2478\n",
      "Episode:805 meanR:9.3700 R:8.0000 loss:6.3303\n",
      "Episode:806 meanR:9.3700 R:9.0000 loss:6.2989\n",
      "Episode:807 meanR:9.3500 R:8.0000 loss:6.3402\n",
      "Episode:808 meanR:9.3400 R:9.0000 loss:6.3522\n",
      "Episode:809 meanR:9.3400 R:9.0000 loss:6.3586\n",
      "Episode:810 meanR:9.3500 R:9.0000 loss:6.3639\n",
      "Episode:811 meanR:9.3600 R:10.0000 loss:6.3741\n",
      "Episode:812 meanR:9.3600 R:9.0000 loss:6.4152\n",
      "Episode:813 meanR:9.3700 R:11.0000 loss:6.3518\n",
      "Episode:814 meanR:9.3600 R:8.0000 loss:6.4209\n",
      "Episode:815 meanR:9.3600 R:9.0000 loss:6.4693\n",
      "Episode:816 meanR:9.3500 R:9.0000 loss:6.5035\n",
      "Episode:817 meanR:9.3500 R:9.0000 loss:6.5271\n",
      "Episode:818 meanR:9.3400 R:9.0000 loss:6.5722\n",
      "Episode:819 meanR:9.3500 R:10.0000 loss:6.5370\n",
      "Episode:820 meanR:9.3600 R:10.0000 loss:6.4484\n",
      "Episode:821 meanR:9.3500 R:9.0000 loss:6.4021\n",
      "Episode:822 meanR:9.3500 R:10.0000 loss:6.3714\n",
      "Episode:823 meanR:9.3500 R:8.0000 loss:6.4009\n",
      "Episode:824 meanR:9.3500 R:9.0000 loss:6.4137\n",
      "Episode:825 meanR:9.3400 R:9.0000 loss:6.4633\n",
      "Episode:826 meanR:9.3300 R:8.0000 loss:6.5108\n",
      "Episode:827 meanR:9.3400 R:10.0000 loss:6.5375\n",
      "Episode:828 meanR:9.3400 R:9.0000 loss:6.5367\n",
      "Episode:829 meanR:9.3600 R:10.0000 loss:6.4832\n",
      "Episode:830 meanR:9.3600 R:10.0000 loss:6.4406\n",
      "Episode:831 meanR:9.3800 R:10.0000 loss:6.4057\n",
      "Episode:832 meanR:9.3800 R:9.0000 loss:6.3989\n",
      "Episode:833 meanR:9.3800 R:10.0000 loss:6.4148\n",
      "Episode:834 meanR:9.3600 R:8.0000 loss:6.4942\n",
      "Episode:835 meanR:9.3500 R:8.0000 loss:6.5455\n",
      "Episode:836 meanR:9.3500 R:8.0000 loss:6.5833\n",
      "Episode:837 meanR:9.3400 R:8.0000 loss:6.6550\n",
      "Episode:838 meanR:9.3200 R:8.0000 loss:6.6572\n",
      "Episode:839 meanR:9.3300 R:10.0000 loss:6.6741\n",
      "Episode:840 meanR:9.3300 R:10.0000 loss:6.6096\n",
      "Episode:841 meanR:9.3200 R:9.0000 loss:6.5849\n",
      "Episode:842 meanR:9.3300 R:10.0000 loss:6.5743\n",
      "Episode:843 meanR:9.3300 R:10.0000 loss:6.5593\n",
      "Episode:844 meanR:9.3200 R:9.0000 loss:6.5913\n",
      "Episode:845 meanR:9.3200 R:10.0000 loss:6.6054\n",
      "Episode:846 meanR:9.3200 R:10.0000 loss:6.5835\n",
      "Episode:847 meanR:9.2900 R:8.0000 loss:6.6054\n",
      "Episode:848 meanR:9.2900 R:10.0000 loss:6.6270\n",
      "Episode:849 meanR:9.2900 R:10.0000 loss:6.4937\n",
      "Episode:850 meanR:9.3100 R:10.0000 loss:6.4133\n",
      "Episode:851 meanR:9.3000 R:9.0000 loss:6.3573\n",
      "Episode:852 meanR:9.2900 R:9.0000 loss:6.3197\n",
      "Episode:853 meanR:9.3000 R:10.0000 loss:6.3493\n",
      "Episode:854 meanR:9.3200 R:10.0000 loss:6.3576\n",
      "Episode:855 meanR:9.3100 R:9.0000 loss:6.3412\n",
      "Episode:856 meanR:9.3000 R:8.0000 loss:6.4153\n",
      "Episode:857 meanR:9.3000 R:9.0000 loss:6.4869\n",
      "Episode:858 meanR:9.2900 R:9.0000 loss:6.4945\n",
      "Episode:859 meanR:9.2900 R:9.0000 loss:6.5453\n",
      "Episode:860 meanR:9.2800 R:9.0000 loss:6.5946\n",
      "Episode:861 meanR:9.2700 R:9.0000 loss:6.5515\n",
      "Episode:862 meanR:9.2800 R:10.0000 loss:6.5634\n",
      "Episode:863 meanR:9.2700 R:9.0000 loss:6.6054\n",
      "Episode:864 meanR:9.2700 R:8.0000 loss:6.6848\n",
      "Episode:865 meanR:9.2800 R:10.0000 loss:6.6717\n",
      "Episode:866 meanR:9.2800 R:10.0000 loss:6.6192\n",
      "Episode:867 meanR:9.2700 R:9.0000 loss:6.6589\n",
      "Episode:868 meanR:9.2700 R:10.0000 loss:6.6627\n",
      "Episode:869 meanR:9.2600 R:9.0000 loss:6.6668\n",
      "Episode:870 meanR:9.2600 R:9.0000 loss:6.6252\n",
      "Episode:871 meanR:9.2600 R:9.0000 loss:6.6250\n",
      "Episode:872 meanR:9.2500 R:8.0000 loss:6.6734\n",
      "Episode:873 meanR:9.2600 R:10.0000 loss:6.6350\n",
      "Episode:874 meanR:9.2800 R:10.0000 loss:6.5937\n",
      "Episode:875 meanR:9.2700 R:9.0000 loss:6.5896\n",
      "Episode:876 meanR:9.2700 R:9.0000 loss:6.6392\n",
      "Episode:877 meanR:9.2700 R:9.0000 loss:6.6412\n",
      "Episode:878 meanR:9.2800 R:10.0000 loss:6.5655\n",
      "Episode:879 meanR:9.2900 R:9.0000 loss:6.6026\n",
      "Episode:880 meanR:9.2900 R:10.0000 loss:6.6142\n",
      "Episode:881 meanR:9.2700 R:9.0000 loss:6.6106\n",
      "Episode:882 meanR:9.2700 R:10.0000 loss:6.6214\n",
      "Episode:883 meanR:9.2900 R:10.0000 loss:6.5825\n",
      "Episode:884 meanR:9.2900 R:10.0000 loss:6.5456\n",
      "Episode:885 meanR:9.2800 R:10.0000 loss:6.5091\n",
      "Episode:886 meanR:9.2800 R:9.0000 loss:6.4469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:887 meanR:9.2700 R:8.0000 loss:6.5256\n",
      "Episode:888 meanR:9.2700 R:10.0000 loss:6.5669\n",
      "Episode:889 meanR:9.2600 R:8.0000 loss:6.5883\n",
      "Episode:890 meanR:9.2500 R:9.0000 loss:6.6083\n",
      "Episode:891 meanR:9.2400 R:9.0000 loss:6.6141\n",
      "Episode:892 meanR:9.2600 R:10.0000 loss:6.6287\n",
      "Episode:893 meanR:9.2500 R:8.0000 loss:6.6603\n",
      "Episode:894 meanR:9.2500 R:9.0000 loss:6.7175\n",
      "Episode:895 meanR:9.2500 R:9.0000 loss:6.7229\n",
      "Episode:896 meanR:9.2600 R:10.0000 loss:6.7263\n",
      "Episode:897 meanR:9.2600 R:10.0000 loss:6.7288\n",
      "Episode:898 meanR:9.2600 R:10.0000 loss:6.7315\n",
      "Episode:899 meanR:9.2600 R:9.0000 loss:6.7750\n",
      "Episode:900 meanR:9.2500 R:9.0000 loss:6.7793\n",
      "Episode:901 meanR:9.2500 R:10.0000 loss:6.6968\n",
      "Episode:902 meanR:9.2600 R:11.0000 loss:6.6636\n",
      "Episode:903 meanR:9.2500 R:9.0000 loss:6.5997\n",
      "Episode:904 meanR:9.2500 R:9.0000 loss:6.6030\n",
      "Episode:905 meanR:9.2600 R:9.0000 loss:6.6082\n",
      "Episode:906 meanR:9.2600 R:9.0000 loss:6.6588\n",
      "Episode:907 meanR:9.2600 R:8.0000 loss:6.6480\n",
      "Episode:908 meanR:9.2700 R:10.0000 loss:6.6376\n",
      "Episode:909 meanR:9.2700 R:9.0000 loss:6.6256\n",
      "Episode:910 meanR:9.2600 R:8.0000 loss:6.7140\n",
      "Episode:911 meanR:9.2500 R:9.0000 loss:6.7750\n",
      "Episode:912 meanR:9.2600 R:10.0000 loss:6.7791\n",
      "Episode:913 meanR:9.2500 R:10.0000 loss:6.7387\n",
      "Episode:914 meanR:9.2600 R:9.0000 loss:6.7352\n",
      "Episode:915 meanR:9.2600 R:9.0000 loss:6.7868\n",
      "Episode:916 meanR:9.2500 R:8.0000 loss:6.8672\n",
      "Episode:917 meanR:9.2400 R:8.0000 loss:6.9437\n",
      "Episode:918 meanR:9.2500 R:10.0000 loss:6.9596\n",
      "Episode:919 meanR:9.2600 R:11.0000 loss:6.8800\n",
      "Episode:920 meanR:9.2500 R:9.0000 loss:6.8300\n",
      "Episode:921 meanR:9.2500 R:9.0000 loss:6.7873\n",
      "Episode:922 meanR:9.2400 R:9.0000 loss:6.8304\n",
      "Episode:923 meanR:9.2500 R:9.0000 loss:6.8328\n",
      "Episode:924 meanR:9.2600 R:10.0000 loss:6.7485\n",
      "Episode:925 meanR:9.2600 R:9.0000 loss:6.7403\n",
      "Episode:926 meanR:9.2600 R:8.0000 loss:6.8383\n",
      "Episode:927 meanR:9.2600 R:10.0000 loss:6.8380\n",
      "Episode:928 meanR:9.2600 R:9.0000 loss:6.8398\n",
      "Episode:929 meanR:9.2500 R:9.0000 loss:6.8409\n",
      "Episode:930 meanR:9.2400 R:9.0000 loss:6.7970\n",
      "Episode:931 meanR:9.2400 R:10.0000 loss:6.7116\n",
      "Episode:932 meanR:9.2400 R:9.0000 loss:6.7513\n",
      "Episode:933 meanR:9.2300 R:9.0000 loss:6.8455\n",
      "Episode:934 meanR:9.2400 R:9.0000 loss:6.8506\n",
      "Episode:935 meanR:9.2600 R:10.0000 loss:6.8087\n",
      "Episode:936 meanR:9.2800 R:10.0000 loss:6.7643\n",
      "Episode:937 meanR:9.3000 R:10.0000 loss:6.7242\n",
      "Episode:938 meanR:9.3200 R:10.0000 loss:6.7260\n",
      "Episode:939 meanR:9.3100 R:9.0000 loss:6.7161\n",
      "Episode:940 meanR:9.3000 R:9.0000 loss:6.6733\n",
      "Episode:941 meanR:9.3000 R:9.0000 loss:6.7257\n",
      "Episode:942 meanR:9.2800 R:8.0000 loss:6.7689\n",
      "Episode:943 meanR:9.2700 R:9.0000 loss:6.7800\n",
      "Episode:944 meanR:9.2700 R:9.0000 loss:6.7833\n",
      "Episode:945 meanR:9.2600 R:9.0000 loss:6.8329\n",
      "Episode:946 meanR:9.2700 R:11.0000 loss:6.7626\n",
      "Episode:947 meanR:9.2800 R:9.0000 loss:6.7406\n",
      "Episode:948 meanR:9.2800 R:10.0000 loss:6.7151\n",
      "Episode:949 meanR:9.2700 R:9.0000 loss:6.7508\n",
      "Episode:950 meanR:9.2700 R:10.0000 loss:6.7664\n",
      "Episode:951 meanR:9.2700 R:9.0000 loss:6.8048\n",
      "Episode:952 meanR:9.2700 R:9.0000 loss:6.8552\n",
      "Episode:953 meanR:9.2500 R:8.0000 loss:6.9044\n",
      "Episode:954 meanR:9.2500 R:10.0000 loss:6.8637\n",
      "Episode:955 meanR:9.2400 R:8.0000 loss:6.9061\n",
      "Episode:956 meanR:9.2500 R:9.0000 loss:6.8610\n",
      "Episode:957 meanR:9.2600 R:10.0000 loss:6.8194\n",
      "Episode:958 meanR:9.2600 R:9.0000 loss:6.8126\n",
      "Episode:959 meanR:9.2600 R:9.0000 loss:6.8169\n",
      "Episode:960 meanR:9.2500 R:8.0000 loss:6.9477\n",
      "Episode:961 meanR:9.2500 R:9.0000 loss:6.9607\n",
      "Episode:962 meanR:9.2300 R:8.0000 loss:6.9683\n",
      "Episode:963 meanR:9.2300 R:9.0000 loss:7.0545\n",
      "Episode:964 meanR:9.2300 R:8.0000 loss:7.0712\n",
      "Episode:965 meanR:9.2400 R:11.0000 loss:7.0966\n",
      "Episode:966 meanR:9.2200 R:8.0000 loss:7.0597\n",
      "Episode:967 meanR:9.2200 R:9.0000 loss:7.0836\n",
      "Episode:968 meanR:9.2200 R:10.0000 loss:7.0150\n",
      "Episode:969 meanR:9.2100 R:8.0000 loss:7.0462\n",
      "Episode:970 meanR:9.2200 R:10.0000 loss:7.0073\n",
      "Episode:971 meanR:9.2200 R:9.0000 loss:6.9712\n",
      "Episode:972 meanR:9.2400 R:10.0000 loss:6.9994\n",
      "Episode:973 meanR:9.2200 R:8.0000 loss:6.9781\n",
      "Episode:974 meanR:9.2200 R:10.0000 loss:6.9905\n",
      "Episode:975 meanR:9.2300 R:10.0000 loss:6.8752\n",
      "Episode:976 meanR:9.2400 R:10.0000 loss:6.7738\n",
      "Episode:977 meanR:9.2400 R:9.0000 loss:6.7657\n",
      "Episode:978 meanR:9.2300 R:9.0000 loss:6.7228\n",
      "Episode:979 meanR:9.2200 R:8.0000 loss:6.8681\n",
      "Episode:980 meanR:9.2200 R:10.0000 loss:6.7829\n",
      "Episode:981 meanR:9.2200 R:9.0000 loss:6.7771\n",
      "Episode:982 meanR:9.2000 R:8.0000 loss:6.8733\n",
      "Episode:983 meanR:9.1900 R:9.0000 loss:6.8286\n",
      "Episode:984 meanR:9.1900 R:10.0000 loss:6.8313\n",
      "Episode:985 meanR:9.1800 R:9.0000 loss:6.8313\n",
      "Episode:986 meanR:9.1900 R:10.0000 loss:6.8343\n",
      "Episode:987 meanR:9.2200 R:11.0000 loss:6.7219\n",
      "Episode:988 meanR:9.2000 R:8.0000 loss:6.7810\n",
      "Episode:989 meanR:9.2200 R:10.0000 loss:6.7989\n",
      "Episode:990 meanR:9.2300 R:10.0000 loss:6.8013\n",
      "Episode:991 meanR:9.2300 R:9.0000 loss:6.7985\n",
      "Episode:992 meanR:9.2300 R:10.0000 loss:6.7642\n",
      "Episode:993 meanR:9.2300 R:8.0000 loss:6.7389\n",
      "Episode:994 meanR:9.2300 R:9.0000 loss:6.8086\n",
      "Episode:995 meanR:9.2300 R:9.0000 loss:6.8101\n",
      "Episode:996 meanR:9.2200 R:9.0000 loss:6.7660\n",
      "Episode:997 meanR:9.2200 R:10.0000 loss:6.7377\n",
      "Episode:998 meanR:9.2000 R:8.0000 loss:6.8120\n",
      "Episode:999 meanR:9.2100 R:10.0000 loss:6.7902\n",
      "Episode:1000 meanR:9.2000 R:8.0000 loss:6.8727\n",
      "Episode:1001 meanR:9.2000 R:10.0000 loss:6.9231\n",
      "Episode:1002 meanR:9.1900 R:10.0000 loss:6.8394\n",
      "Episode:1003 meanR:9.1900 R:9.0000 loss:6.8816\n",
      "Episode:1004 meanR:9.1900 R:9.0000 loss:6.9271\n",
      "Episode:1005 meanR:9.2000 R:10.0000 loss:6.8873\n",
      "Episode:1006 meanR:9.2100 R:10.0000 loss:6.8838\n",
      "Episode:1007 meanR:9.2200 R:9.0000 loss:6.8330\n",
      "Episode:1008 meanR:9.2200 R:10.0000 loss:6.7993\n",
      "Episode:1009 meanR:9.2200 R:9.0000 loss:6.7909\n",
      "Episode:1010 meanR:9.2400 R:10.0000 loss:6.7631\n",
      "Episode:1011 meanR:9.2400 R:9.0000 loss:6.7965\n",
      "Episode:1012 meanR:9.2400 R:10.0000 loss:6.7284\n",
      "Episode:1013 meanR:9.2400 R:10.0000 loss:6.7317\n",
      "Episode:1014 meanR:9.2400 R:9.0000 loss:6.6690\n",
      "Episode:1015 meanR:9.2300 R:8.0000 loss:6.7500\n",
      "Episode:1016 meanR:9.2400 R:9.0000 loss:6.8252\n",
      "Episode:1017 meanR:9.2600 R:10.0000 loss:6.7977\n",
      "Episode:1018 meanR:9.2400 R:8.0000 loss:6.8171\n",
      "Episode:1019 meanR:9.2200 R:9.0000 loss:6.8866\n",
      "Episode:1020 meanR:9.2300 R:10.0000 loss:6.8972\n",
      "Episode:1021 meanR:9.2200 R:8.0000 loss:6.9370\n",
      "Episode:1022 meanR:9.2200 R:9.0000 loss:6.9883\n",
      "Episode:1023 meanR:9.2200 R:9.0000 loss:6.9896\n",
      "Episode:1024 meanR:9.2000 R:8.0000 loss:7.0264\n",
      "Episode:1025 meanR:9.2100 R:10.0000 loss:7.0685\n",
      "Episode:1026 meanR:9.2300 R:10.0000 loss:7.0233\n",
      "Episode:1027 meanR:9.2300 R:10.0000 loss:7.0171\n",
      "Episode:1028 meanR:9.2400 R:10.0000 loss:6.9854\n",
      "Episode:1029 meanR:9.2500 R:10.0000 loss:6.8809\n",
      "Episode:1030 meanR:9.2600 R:10.0000 loss:6.8372\n",
      "Episode:1031 meanR:9.2600 R:10.0000 loss:6.8373\n",
      "Episode:1032 meanR:9.2600 R:9.0000 loss:6.7789\n",
      "Episode:1033 meanR:9.2700 R:10.0000 loss:6.7593\n",
      "Episode:1034 meanR:9.2800 R:10.0000 loss:6.7640\n",
      "Episode:1035 meanR:9.2800 R:10.0000 loss:6.6829\n",
      "Episode:1036 meanR:9.2800 R:10.0000 loss:6.6456\n",
      "Episode:1037 meanR:9.2700 R:9.0000 loss:6.5867\n",
      "Episode:1038 meanR:9.2600 R:9.0000 loss:6.6152\n",
      "Episode:1039 meanR:9.2700 R:10.0000 loss:6.6347\n",
      "Episode:1040 meanR:9.2800 R:10.0000 loss:6.6478\n",
      "Episode:1041 meanR:9.2800 R:9.0000 loss:6.6640\n",
      "Episode:1042 meanR:9.3000 R:10.0000 loss:6.7133\n",
      "Episode:1043 meanR:9.3100 R:10.0000 loss:6.7211\n",
      "Episode:1044 meanR:9.3000 R:8.0000 loss:6.7570\n",
      "Episode:1045 meanR:9.3100 R:10.0000 loss:6.8254\n",
      "Episode:1046 meanR:9.3000 R:10.0000 loss:6.7901\n",
      "Episode:1047 meanR:9.3000 R:9.0000 loss:6.8136\n",
      "Episode:1048 meanR:9.3000 R:10.0000 loss:6.8465\n",
      "Episode:1049 meanR:9.3000 R:9.0000 loss:6.8745\n",
      "Episode:1050 meanR:9.3000 R:10.0000 loss:6.9016\n",
      "Episode:1051 meanR:9.3100 R:10.0000 loss:6.8624\n",
      "Episode:1052 meanR:9.3200 R:10.0000 loss:6.8226\n",
      "Episode:1053 meanR:9.3300 R:9.0000 loss:6.8437\n",
      "Episode:1054 meanR:9.3200 R:9.0000 loss:6.9009\n",
      "Episode:1055 meanR:9.3300 R:9.0000 loss:6.9048\n",
      "Episode:1056 meanR:9.3300 R:9.0000 loss:6.9595\n",
      "Episode:1057 meanR:9.3300 R:10.0000 loss:6.9799\n",
      "Episode:1058 meanR:9.3400 R:10.0000 loss:6.8925\n",
      "Episode:1059 meanR:9.3400 R:9.0000 loss:6.9171\n",
      "Episode:1060 meanR:9.3400 R:8.0000 loss:7.0056\n",
      "Episode:1061 meanR:9.3400 R:9.0000 loss:7.0236\n",
      "Episode:1062 meanR:9.3500 R:9.0000 loss:7.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1063 meanR:9.3600 R:10.0000 loss:7.0364\n",
      "Episode:1064 meanR:9.3800 R:10.0000 loss:7.0356\n",
      "Episode:1065 meanR:9.3700 R:10.0000 loss:7.0361\n",
      "Episode:1066 meanR:9.3900 R:10.0000 loss:7.0352\n",
      "Episode:1067 meanR:9.3900 R:9.0000 loss:7.0206\n",
      "Episode:1068 meanR:9.3900 R:10.0000 loss:6.9895\n",
      "Episode:1069 meanR:9.4000 R:9.0000 loss:6.9729\n",
      "Episode:1070 meanR:9.3900 R:9.0000 loss:6.9727\n",
      "Episode:1071 meanR:9.3900 R:9.0000 loss:7.0261\n",
      "Episode:1072 meanR:9.3800 R:9.0000 loss:7.0748\n",
      "Episode:1073 meanR:9.4000 R:10.0000 loss:7.0375\n",
      "Episode:1074 meanR:9.4000 R:10.0000 loss:6.9480\n",
      "Episode:1075 meanR:9.3900 R:9.0000 loss:6.9279\n",
      "Episode:1076 meanR:9.3900 R:10.0000 loss:6.9083\n",
      "Episode:1077 meanR:9.4000 R:10.0000 loss:6.9128\n",
      "Episode:1078 meanR:9.4000 R:9.0000 loss:6.9377\n",
      "Episode:1079 meanR:9.4200 R:10.0000 loss:6.9656\n",
      "Episode:1080 meanR:9.4000 R:8.0000 loss:7.0274\n",
      "Episode:1081 meanR:9.4100 R:10.0000 loss:7.0153\n",
      "Episode:1082 meanR:9.4200 R:9.0000 loss:7.0473\n",
      "Episode:1083 meanR:9.4100 R:8.0000 loss:7.0857\n",
      "Episode:1084 meanR:9.4100 R:10.0000 loss:7.0600\n",
      "Episode:1085 meanR:9.4100 R:9.0000 loss:7.0457\n",
      "Episode:1086 meanR:9.4100 R:10.0000 loss:7.0135\n",
      "Episode:1087 meanR:9.4000 R:10.0000 loss:7.0146\n",
      "Episode:1088 meanR:9.4200 R:10.0000 loss:7.0154\n",
      "Episode:1089 meanR:9.4100 R:9.0000 loss:6.9968\n",
      "Episode:1090 meanR:9.4000 R:9.0000 loss:7.0478\n",
      "Episode:1091 meanR:9.4000 R:9.0000 loss:7.0987\n",
      "Episode:1092 meanR:9.4000 R:10.0000 loss:7.0612\n",
      "Episode:1093 meanR:9.4200 R:10.0000 loss:7.0582\n",
      "Episode:1094 meanR:9.4200 R:9.0000 loss:6.9945\n",
      "Episode:1095 meanR:9.4200 R:9.0000 loss:7.0472\n",
      "Episode:1096 meanR:9.4300 R:10.0000 loss:7.0137\n",
      "Episode:1097 meanR:9.4300 R:10.0000 loss:6.9236\n",
      "Episode:1098 meanR:9.4500 R:10.0000 loss:6.9287\n",
      "Episode:1099 meanR:9.4600 R:11.0000 loss:6.8731\n",
      "Episode:1100 meanR:9.4800 R:10.0000 loss:6.8484\n",
      "Episode:1101 meanR:9.4700 R:9.0000 loss:6.8678\n",
      "Episode:1102 meanR:9.4700 R:10.0000 loss:6.9088\n",
      "Episode:1103 meanR:9.4800 R:10.0000 loss:6.8697\n",
      "Episode:1104 meanR:9.4800 R:9.0000 loss:6.8384\n",
      "Episode:1105 meanR:9.4900 R:11.0000 loss:6.8043\n",
      "Episode:1106 meanR:9.4900 R:10.0000 loss:6.8059\n",
      "Episode:1107 meanR:9.4900 R:9.0000 loss:6.8186\n",
      "Episode:1108 meanR:9.4800 R:9.0000 loss:6.8276\n",
      "Episode:1109 meanR:9.4900 R:10.0000 loss:6.8347\n",
      "Episode:1110 meanR:9.4800 R:9.0000 loss:6.8839\n",
      "Episode:1111 meanR:9.4900 R:10.0000 loss:6.9006\n",
      "Episode:1112 meanR:9.4900 R:10.0000 loss:6.9115\n",
      "Episode:1113 meanR:9.4800 R:9.0000 loss:6.9741\n",
      "Episode:1114 meanR:9.4900 R:10.0000 loss:7.0150\n",
      "Episode:1115 meanR:9.5000 R:9.0000 loss:6.9851\n",
      "Episode:1116 meanR:9.5000 R:9.0000 loss:7.0430\n",
      "Episode:1117 meanR:9.4800 R:8.0000 loss:7.1234\n",
      "Episode:1118 meanR:9.5000 R:10.0000 loss:7.1221\n",
      "Episode:1119 meanR:9.4900 R:8.0000 loss:7.2416\n",
      "Episode:1120 meanR:9.4800 R:9.0000 loss:7.2998\n",
      "Episode:1121 meanR:9.5000 R:10.0000 loss:7.2519\n",
      "Episode:1122 meanR:9.5100 R:10.0000 loss:7.1978\n",
      "Episode:1123 meanR:9.5200 R:10.0000 loss:7.1934\n",
      "Episode:1124 meanR:9.5400 R:10.0000 loss:7.1440\n",
      "Episode:1125 meanR:9.5300 R:9.0000 loss:7.1726\n",
      "Episode:1126 meanR:9.5300 R:10.0000 loss:7.1841\n",
      "Episode:1127 meanR:9.5100 R:8.0000 loss:7.2061\n",
      "Episode:1128 meanR:9.5000 R:9.0000 loss:7.2656\n",
      "Episode:1129 meanR:9.4900 R:9.0000 loss:7.2583\n",
      "Episode:1130 meanR:9.4800 R:9.0000 loss:7.2547\n",
      "Episode:1131 meanR:9.4800 R:10.0000 loss:7.1593\n",
      "Episode:1132 meanR:9.4800 R:9.0000 loss:7.1895\n",
      "Episode:1133 meanR:9.4600 R:8.0000 loss:7.1744\n",
      "Episode:1134 meanR:9.4500 R:9.0000 loss:7.1812\n",
      "Episode:1135 meanR:9.4500 R:10.0000 loss:7.1877\n",
      "Episode:1136 meanR:9.4500 R:10.0000 loss:7.1825\n",
      "Episode:1137 meanR:9.4400 R:8.0000 loss:7.2729\n",
      "Episode:1138 meanR:9.4500 R:10.0000 loss:7.2629\n",
      "Episode:1139 meanR:9.4400 R:9.0000 loss:7.2556\n",
      "Episode:1140 meanR:9.4200 R:8.0000 loss:7.2925\n",
      "Episode:1141 meanR:9.4100 R:8.0000 loss:7.3537\n",
      "Episode:1142 meanR:9.4000 R:9.0000 loss:7.3312\n",
      "Episode:1143 meanR:9.4000 R:10.0000 loss:7.3079\n",
      "Episode:1144 meanR:9.4100 R:9.0000 loss:7.2553\n",
      "Episode:1145 meanR:9.4100 R:10.0000 loss:7.2393\n",
      "Episode:1146 meanR:9.4200 R:11.0000 loss:7.1513\n",
      "Episode:1147 meanR:9.4300 R:10.0000 loss:7.0401\n",
      "Episode:1148 meanR:9.4200 R:9.0000 loss:7.0216\n",
      "Episode:1149 meanR:9.4200 R:9.0000 loss:7.0714\n",
      "Episode:1150 meanR:9.4000 R:8.0000 loss:7.1706\n",
      "Episode:1151 meanR:9.3800 R:8.0000 loss:7.1686\n",
      "Episode:1152 meanR:9.3800 R:10.0000 loss:7.1611\n",
      "Episode:1153 meanR:9.3900 R:10.0000 loss:7.1103\n",
      "Episode:1154 meanR:9.4100 R:11.0000 loss:6.9814\n",
      "Episode:1155 meanR:9.4000 R:8.0000 loss:6.9253\n",
      "Episode:1156 meanR:9.4100 R:10.0000 loss:6.9233\n",
      "Episode:1157 meanR:9.4100 R:10.0000 loss:6.9257\n",
      "Episode:1158 meanR:9.4000 R:9.0000 loss:6.9056\n",
      "Episode:1159 meanR:9.4100 R:10.0000 loss:6.9357\n",
      "Episode:1160 meanR:9.4100 R:8.0000 loss:7.0546\n",
      "Episode:1161 meanR:9.4200 R:10.0000 loss:7.0734\n",
      "Episode:1162 meanR:9.4200 R:9.0000 loss:7.0629\n",
      "Episode:1163 meanR:9.4100 R:9.0000 loss:7.0622\n",
      "Episode:1164 meanR:9.4100 R:10.0000 loss:6.9775\n",
      "Episode:1165 meanR:9.4000 R:9.0000 loss:6.9131\n",
      "Episode:1166 meanR:9.3900 R:9.0000 loss:6.9665\n",
      "Episode:1167 meanR:9.3900 R:9.0000 loss:7.0172\n",
      "Episode:1168 meanR:9.3800 R:9.0000 loss:7.1166\n",
      "Episode:1169 meanR:9.3900 R:10.0000 loss:7.0281\n",
      "Episode:1170 meanR:9.3900 R:9.0000 loss:7.0643\n",
      "Episode:1171 meanR:9.3900 R:9.0000 loss:7.1134\n",
      "Episode:1172 meanR:9.3900 R:9.0000 loss:7.1088\n",
      "Episode:1173 meanR:9.3800 R:9.0000 loss:7.1539\n",
      "Episode:1174 meanR:9.3700 R:9.0000 loss:7.1008\n",
      "Episode:1175 meanR:9.3800 R:10.0000 loss:7.0992\n",
      "Episode:1176 meanR:9.3800 R:10.0000 loss:7.0494\n",
      "Episode:1177 meanR:9.3800 R:10.0000 loss:6.9999\n",
      "Episode:1178 meanR:9.3800 R:9.0000 loss:7.0343\n",
      "Episode:1179 meanR:9.3700 R:9.0000 loss:7.0329\n",
      "Episode:1180 meanR:9.3700 R:8.0000 loss:7.0762\n",
      "Episode:1181 meanR:9.3600 R:9.0000 loss:7.0801\n",
      "Episode:1182 meanR:9.3700 R:10.0000 loss:7.0383\n",
      "Episode:1183 meanR:9.3800 R:9.0000 loss:7.0767\n",
      "Episode:1184 meanR:9.3800 R:10.0000 loss:7.0308\n",
      "Episode:1185 meanR:9.3900 R:10.0000 loss:6.9840\n",
      "Episode:1186 meanR:9.3900 R:10.0000 loss:6.9382\n",
      "Episode:1187 meanR:9.3900 R:10.0000 loss:6.8967\n",
      "Episode:1188 meanR:9.3900 R:10.0000 loss:6.8549\n",
      "Episode:1189 meanR:9.3900 R:9.0000 loss:6.8814\n",
      "Episode:1190 meanR:9.4000 R:10.0000 loss:6.9112\n",
      "Episode:1191 meanR:9.4000 R:9.0000 loss:6.9412\n",
      "Episode:1192 meanR:9.3900 R:9.0000 loss:6.9447\n",
      "Episode:1193 meanR:9.3700 R:8.0000 loss:6.9792\n",
      "Episode:1194 meanR:9.3900 R:11.0000 loss:6.9037\n",
      "Episode:1195 meanR:9.4000 R:10.0000 loss:6.8397\n",
      "Episode:1196 meanR:9.3900 R:9.0000 loss:6.8612\n",
      "Episode:1197 meanR:9.3900 R:10.0000 loss:6.8534\n",
      "Episode:1198 meanR:9.3800 R:9.0000 loss:6.8785\n",
      "Episode:1199 meanR:9.3600 R:9.0000 loss:6.9356\n",
      "Episode:1200 meanR:9.3600 R:10.0000 loss:6.9640\n",
      "Episode:1201 meanR:9.3500 R:8.0000 loss:7.0253\n",
      "Episode:1202 meanR:9.3500 R:10.0000 loss:7.0582\n",
      "Episode:1203 meanR:9.3400 R:9.0000 loss:7.0456\n",
      "Episode:1204 meanR:9.3400 R:9.0000 loss:7.0959\n",
      "Episode:1205 meanR:9.3300 R:10.0000 loss:7.0568\n",
      "Episode:1206 meanR:9.3100 R:8.0000 loss:7.0821\n",
      "Episode:1207 meanR:9.3100 R:9.0000 loss:7.0412\n",
      "Episode:1208 meanR:9.3100 R:9.0000 loss:7.1392\n",
      "Episode:1209 meanR:9.3100 R:10.0000 loss:7.1388\n",
      "Episode:1210 meanR:9.3300 R:11.0000 loss:7.0556\n",
      "Episode:1211 meanR:9.3100 R:8.0000 loss:7.1232\n",
      "Episode:1212 meanR:9.3100 R:10.0000 loss:7.0816\n",
      "Episode:1213 meanR:9.3000 R:8.0000 loss:7.1153\n",
      "Episode:1214 meanR:9.2900 R:9.0000 loss:7.1648\n",
      "Episode:1215 meanR:9.3000 R:10.0000 loss:7.0701\n",
      "Episode:1216 meanR:9.3000 R:9.0000 loss:7.1062\n",
      "Episode:1217 meanR:9.3000 R:8.0000 loss:7.1532\n",
      "Episode:1218 meanR:9.2900 R:9.0000 loss:7.1476\n",
      "Episode:1219 meanR:9.3000 R:9.0000 loss:7.1794\n",
      "Episode:1220 meanR:9.3100 R:10.0000 loss:7.0955\n",
      "Episode:1221 meanR:9.3100 R:10.0000 loss:7.0359\n",
      "Episode:1222 meanR:9.3100 R:10.0000 loss:6.9853\n",
      "Episode:1223 meanR:9.3000 R:9.0000 loss:7.0219\n",
      "Episode:1224 meanR:9.3000 R:10.0000 loss:7.0721\n",
      "Episode:1225 meanR:9.3100 R:10.0000 loss:6.9806\n",
      "Episode:1226 meanR:9.3000 R:9.0000 loss:7.0162\n",
      "Episode:1227 meanR:9.3200 R:10.0000 loss:6.9333\n",
      "Episode:1228 meanR:9.3300 R:10.0000 loss:6.8924\n",
      "Episode:1229 meanR:9.3300 R:9.0000 loss:6.9200\n",
      "Episode:1230 meanR:9.3400 R:10.0000 loss:6.8982\n",
      "Episode:1231 meanR:9.3300 R:9.0000 loss:6.8296\n",
      "Episode:1232 meanR:9.3400 R:10.0000 loss:6.8204\n",
      "Episode:1233 meanR:9.3600 R:10.0000 loss:6.7870\n",
      "Episode:1234 meanR:9.3600 R:9.0000 loss:6.8078\n",
      "Episode:1235 meanR:9.3600 R:10.0000 loss:6.8493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1236 meanR:9.3500 R:9.0000 loss:6.8744\n",
      "Episode:1237 meanR:9.3500 R:8.0000 loss:6.9037\n",
      "Episode:1238 meanR:9.3400 R:9.0000 loss:6.9887\n",
      "Episode:1239 meanR:9.3300 R:8.0000 loss:7.0813\n",
      "Episode:1240 meanR:9.3500 R:10.0000 loss:7.0574\n",
      "Episode:1241 meanR:9.3700 R:10.0000 loss:7.0569\n",
      "Episode:1242 meanR:9.3800 R:10.0000 loss:7.0548\n",
      "Episode:1243 meanR:9.3700 R:9.0000 loss:7.0391\n",
      "Episode:1244 meanR:9.3800 R:10.0000 loss:7.0522\n",
      "Episode:1245 meanR:9.3700 R:9.0000 loss:7.0380\n",
      "Episode:1246 meanR:9.3400 R:8.0000 loss:7.1319\n",
      "Episode:1247 meanR:9.3400 R:10.0000 loss:7.1381\n",
      "Episode:1248 meanR:9.3500 R:10.0000 loss:7.0874\n",
      "Episode:1249 meanR:9.3400 R:8.0000 loss:7.1752\n",
      "Episode:1250 meanR:9.3600 R:10.0000 loss:7.1225\n",
      "Episode:1251 meanR:9.3800 R:10.0000 loss:7.0255\n",
      "Episode:1252 meanR:9.3700 R:9.0000 loss:7.0082\n",
      "Episode:1253 meanR:9.3600 R:9.0000 loss:6.9591\n",
      "Episode:1254 meanR:9.3500 R:10.0000 loss:6.9788\n",
      "Episode:1255 meanR:9.3700 R:10.0000 loss:6.9812\n",
      "Episode:1256 meanR:9.3700 R:10.0000 loss:6.9808\n",
      "Episode:1257 meanR:9.3500 R:8.0000 loss:6.9978\n",
      "Episode:1258 meanR:9.3400 R:8.0000 loss:7.1125\n",
      "Episode:1259 meanR:9.3400 R:10.0000 loss:7.0727\n",
      "Episode:1260 meanR:9.3500 R:9.0000 loss:7.0106\n",
      "Episode:1261 meanR:9.3500 R:10.0000 loss:7.0239\n",
      "Episode:1262 meanR:9.3600 R:10.0000 loss:7.0235\n",
      "Episode:1263 meanR:9.3600 R:9.0000 loss:6.9592\n",
      "Episode:1264 meanR:9.3600 R:10.0000 loss:6.9799\n",
      "Episode:1265 meanR:9.3600 R:9.0000 loss:7.0103\n",
      "Episode:1266 meanR:9.3600 R:9.0000 loss:7.0127\n",
      "Episode:1267 meanR:9.3500 R:8.0000 loss:7.0520\n",
      "Episode:1268 meanR:9.3600 R:10.0000 loss:7.0709\n",
      "Episode:1269 meanR:9.3600 R:10.0000 loss:7.0680\n",
      "Episode:1270 meanR:9.3600 R:9.0000 loss:7.1058\n",
      "Episode:1271 meanR:9.3700 R:10.0000 loss:7.0163\n",
      "Episode:1272 meanR:9.3800 R:10.0000 loss:6.9263\n",
      "Episode:1273 meanR:9.3900 R:10.0000 loss:6.9260\n",
      "Episode:1274 meanR:9.4000 R:10.0000 loss:6.8862\n",
      "Episode:1275 meanR:9.3900 R:9.0000 loss:6.9122\n",
      "Episode:1276 meanR:9.3800 R:9.0000 loss:6.9667\n",
      "Episode:1277 meanR:9.3700 R:9.0000 loss:6.9707\n",
      "Episode:1278 meanR:9.3800 R:10.0000 loss:6.9919\n",
      "Episode:1279 meanR:9.4000 R:11.0000 loss:6.9285\n",
      "Episode:1280 meanR:9.4200 R:10.0000 loss:6.8639\n",
      "Episode:1281 meanR:9.4200 R:9.0000 loss:6.7898\n",
      "Episode:1282 meanR:9.4200 R:10.0000 loss:6.8386\n",
      "Episode:1283 meanR:9.4400 R:11.0000 loss:6.8062\n",
      "Episode:1284 meanR:9.4300 R:9.0000 loss:6.8124\n",
      "Episode:1285 meanR:9.4200 R:9.0000 loss:6.8350\n",
      "Episode:1286 meanR:9.4000 R:8.0000 loss:6.9086\n",
      "Episode:1287 meanR:9.4000 R:10.0000 loss:6.9825\n",
      "Episode:1288 meanR:9.3900 R:9.0000 loss:7.0078\n",
      "Episode:1289 meanR:9.4000 R:10.0000 loss:6.9925\n",
      "Episode:1290 meanR:9.4000 R:10.0000 loss:6.9508\n",
      "Episode:1291 meanR:9.3900 R:8.0000 loss:6.9363\n",
      "Episode:1292 meanR:9.3900 R:9.0000 loss:7.0293\n",
      "Episode:1293 meanR:9.4100 R:10.0000 loss:7.1025\n",
      "Episode:1294 meanR:9.3900 R:9.0000 loss:7.1357\n",
      "Episode:1295 meanR:9.3800 R:9.0000 loss:7.1342\n",
      "Episode:1296 meanR:9.3800 R:9.0000 loss:7.1825\n",
      "Episode:1297 meanR:9.3800 R:10.0000 loss:7.2303\n",
      "Episode:1298 meanR:9.3700 R:8.0000 loss:7.2718\n",
      "Episode:1299 meanR:9.3800 R:10.0000 loss:7.2153\n",
      "Episode:1300 meanR:9.3800 R:10.0000 loss:7.1158\n",
      "Episode:1301 meanR:9.3900 R:9.0000 loss:7.1455\n",
      "Episode:1302 meanR:9.3800 R:9.0000 loss:7.1420\n",
      "Episode:1303 meanR:9.3800 R:9.0000 loss:7.1891\n",
      "Episode:1304 meanR:9.3800 R:9.0000 loss:7.2302\n",
      "Episode:1305 meanR:9.3700 R:9.0000 loss:7.1732\n",
      "Episode:1306 meanR:9.3700 R:8.0000 loss:7.2180\n",
      "Episode:1307 meanR:9.3700 R:9.0000 loss:7.2505\n",
      "Episode:1308 meanR:9.3900 R:11.0000 loss:7.1618\n",
      "Episode:1309 meanR:9.3800 R:9.0000 loss:7.1381\n",
      "Episode:1310 meanR:9.3700 R:10.0000 loss:7.0912\n",
      "Episode:1311 meanR:9.3900 R:10.0000 loss:7.0829\n",
      "Episode:1312 meanR:9.3800 R:9.0000 loss:7.0214\n",
      "Episode:1313 meanR:9.3900 R:9.0000 loss:7.0685\n",
      "Episode:1314 meanR:9.3800 R:8.0000 loss:7.1693\n",
      "Episode:1315 meanR:9.3700 R:9.0000 loss:7.1625\n",
      "Episode:1316 meanR:9.3700 R:9.0000 loss:7.1555\n",
      "Episode:1317 meanR:9.3900 R:10.0000 loss:7.1013\n",
      "Episode:1318 meanR:9.4000 R:10.0000 loss:7.0503\n",
      "Episode:1319 meanR:9.4100 R:10.0000 loss:6.9999\n",
      "Episode:1320 meanR:9.4100 R:10.0000 loss:6.9101\n",
      "Episode:1321 meanR:9.4000 R:9.0000 loss:6.8896\n",
      "Episode:1322 meanR:9.4000 R:10.0000 loss:6.9608\n",
      "Episode:1323 meanR:9.3900 R:8.0000 loss:6.9767\n",
      "Episode:1324 meanR:9.3700 R:8.0000 loss:7.0909\n",
      "Episode:1325 meanR:9.3700 R:10.0000 loss:7.1003\n",
      "Episode:1326 meanR:9.3700 R:9.0000 loss:7.0920\n",
      "Episode:1327 meanR:9.3700 R:10.0000 loss:7.0468\n",
      "Episode:1328 meanR:9.3600 R:9.0000 loss:6.9831\n",
      "Episode:1329 meanR:9.3500 R:8.0000 loss:7.0213\n",
      "Episode:1330 meanR:9.3400 R:9.0000 loss:7.0317\n",
      "Episode:1331 meanR:9.3400 R:9.0000 loss:7.0803\n",
      "Episode:1332 meanR:9.3300 R:9.0000 loss:7.1263\n",
      "Episode:1333 meanR:9.3200 R:9.0000 loss:7.1620\n",
      "Episode:1334 meanR:9.3100 R:8.0000 loss:7.1701\n",
      "Episode:1335 meanR:9.3000 R:9.0000 loss:7.2535\n",
      "Episode:1336 meanR:9.3100 R:10.0000 loss:7.2222\n",
      "Episode:1337 meanR:9.3300 R:10.0000 loss:7.2065\n",
      "Episode:1338 meanR:9.3200 R:8.0000 loss:7.1189\n",
      "Episode:1339 meanR:9.3400 R:10.0000 loss:7.0962\n",
      "Episode:1340 meanR:9.3500 R:11.0000 loss:7.0088\n",
      "Episode:1341 meanR:9.3500 R:10.0000 loss:6.9920\n",
      "Episode:1342 meanR:9.3500 R:10.0000 loss:6.9442\n",
      "Episode:1343 meanR:9.3500 R:9.0000 loss:6.8854\n",
      "Episode:1344 meanR:9.3500 R:10.0000 loss:6.8565\n",
      "Episode:1345 meanR:9.3500 R:9.0000 loss:6.8419\n",
      "Episode:1346 meanR:9.3700 R:10.0000 loss:6.8204\n",
      "Episode:1347 meanR:9.3600 R:9.0000 loss:6.8031\n",
      "Episode:1348 meanR:9.3500 R:9.0000 loss:6.7623\n",
      "Episode:1349 meanR:9.3600 R:9.0000 loss:6.7718\n",
      "Episode:1350 meanR:9.3500 R:9.0000 loss:6.8309\n",
      "Episode:1351 meanR:9.3500 R:10.0000 loss:6.8623\n",
      "Episode:1352 meanR:9.3500 R:9.0000 loss:6.7964\n",
      "Episode:1353 meanR:9.3500 R:9.0000 loss:6.8558\n",
      "Episode:1354 meanR:9.3400 R:9.0000 loss:6.9603\n",
      "Episode:1355 meanR:9.3200 R:8.0000 loss:7.0583\n",
      "Episode:1356 meanR:9.3200 R:10.0000 loss:7.0651\n",
      "Episode:1357 meanR:9.3200 R:8.0000 loss:7.1101\n",
      "Episode:1358 meanR:9.3300 R:9.0000 loss:7.1463\n",
      "Episode:1359 meanR:9.3200 R:9.0000 loss:7.1466\n",
      "Episode:1360 meanR:9.3200 R:9.0000 loss:7.1400\n",
      "Episode:1361 meanR:9.3000 R:8.0000 loss:7.1919\n",
      "Episode:1362 meanR:9.2900 R:9.0000 loss:7.2167\n",
      "Episode:1363 meanR:9.3100 R:11.0000 loss:7.1734\n",
      "Episode:1364 meanR:9.3100 R:10.0000 loss:7.0481\n",
      "Episode:1365 meanR:9.3200 R:10.0000 loss:7.0321\n",
      "Episode:1366 meanR:9.3300 R:10.0000 loss:6.9821\n",
      "Episode:1367 meanR:9.3500 R:10.0000 loss:6.9335\n",
      "Episode:1368 meanR:9.3500 R:10.0000 loss:6.8866\n",
      "Episode:1369 meanR:9.3500 R:10.0000 loss:6.8017\n",
      "Episode:1370 meanR:9.3400 R:8.0000 loss:6.8623\n",
      "Episode:1371 meanR:9.3300 R:9.0000 loss:6.8370\n",
      "Episode:1372 meanR:9.3300 R:10.0000 loss:6.8171\n",
      "Episode:1373 meanR:9.3300 R:10.0000 loss:6.7793\n",
      "Episode:1374 meanR:9.3200 R:9.0000 loss:6.7587\n",
      "Episode:1375 meanR:9.3200 R:9.0000 loss:6.7227\n",
      "Episode:1376 meanR:9.3200 R:9.0000 loss:6.7329\n",
      "Episode:1377 meanR:9.3300 R:10.0000 loss:6.8222\n",
      "Episode:1378 meanR:9.3100 R:8.0000 loss:6.8789\n",
      "Episode:1379 meanR:9.2900 R:9.0000 loss:6.9570\n",
      "Episode:1380 meanR:9.2900 R:10.0000 loss:6.9759\n",
      "Episode:1381 meanR:9.2800 R:8.0000 loss:7.0585\n",
      "Episode:1382 meanR:9.2800 R:10.0000 loss:7.0648\n",
      "Episode:1383 meanR:9.2600 R:9.0000 loss:7.1067\n",
      "Episode:1384 meanR:9.2700 R:10.0000 loss:7.0110\n",
      "Episode:1385 meanR:9.2800 R:10.0000 loss:6.9634\n",
      "Episode:1386 meanR:9.2800 R:8.0000 loss:7.0427\n",
      "Episode:1387 meanR:9.2800 R:10.0000 loss:7.0493\n",
      "Episode:1388 meanR:9.2900 R:10.0000 loss:7.0004\n",
      "Episode:1389 meanR:9.2800 R:9.0000 loss:6.9890\n",
      "Episode:1390 meanR:9.2700 R:9.0000 loss:6.9879\n",
      "Episode:1391 meanR:9.2700 R:8.0000 loss:7.0861\n",
      "Episode:1392 meanR:9.2700 R:9.0000 loss:7.0331\n",
      "Episode:1393 meanR:9.2600 R:9.0000 loss:7.0299\n",
      "Episode:1394 meanR:9.2700 R:10.0000 loss:7.0295\n",
      "Episode:1395 meanR:9.2800 R:10.0000 loss:6.9370\n",
      "Episode:1396 meanR:9.2900 R:10.0000 loss:6.9361\n",
      "Episode:1397 meanR:9.2800 R:9.0000 loss:6.9224\n",
      "Episode:1398 meanR:9.3000 R:10.0000 loss:6.9386\n",
      "Episode:1399 meanR:9.2800 R:8.0000 loss:7.0186\n",
      "Episode:1400 meanR:9.2700 R:9.0000 loss:6.9745\n",
      "Episode:1401 meanR:9.2700 R:9.0000 loss:7.0238\n",
      "Episode:1402 meanR:9.2600 R:8.0000 loss:7.1192\n",
      "Episode:1403 meanR:9.2600 R:9.0000 loss:7.1154\n",
      "Episode:1404 meanR:9.2700 R:10.0000 loss:7.0648\n",
      "Episode:1405 meanR:9.2700 R:9.0000 loss:7.0028\n",
      "Episode:1406 meanR:9.2800 R:9.0000 loss:6.9966\n",
      "Episode:1407 meanR:9.2800 R:9.0000 loss:6.9942\n",
      "Episode:1408 meanR:9.2700 R:10.0000 loss:6.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1409 meanR:9.2600 R:8.0000 loss:7.0851\n",
      "Episode:1410 meanR:9.2500 R:9.0000 loss:7.0829\n",
      "Episode:1411 meanR:9.2400 R:9.0000 loss:7.1232\n",
      "Episode:1412 meanR:9.2300 R:8.0000 loss:7.1272\n",
      "Episode:1413 meanR:9.2300 R:9.0000 loss:7.1996\n",
      "Episode:1414 meanR:9.2500 R:10.0000 loss:7.1218\n",
      "Episode:1415 meanR:9.2500 R:9.0000 loss:7.0768\n",
      "Episode:1416 meanR:9.2500 R:9.0000 loss:7.0653\n",
      "Episode:1417 meanR:9.2500 R:10.0000 loss:6.9664\n",
      "Episode:1418 meanR:9.2400 R:9.0000 loss:6.9960\n",
      "Episode:1419 meanR:9.2300 R:9.0000 loss:6.9985\n",
      "Episode:1420 meanR:9.2200 R:9.0000 loss:6.9915\n",
      "Episode:1421 meanR:9.2200 R:9.0000 loss:6.9878\n",
      "Episode:1422 meanR:9.2100 R:9.0000 loss:6.9830\n",
      "Episode:1423 meanR:9.2200 R:9.0000 loss:7.0232\n",
      "Episode:1424 meanR:9.2300 R:9.0000 loss:6.9697\n",
      "Episode:1425 meanR:9.2200 R:9.0000 loss:6.9644\n",
      "Episode:1426 meanR:9.2300 R:10.0000 loss:6.8732\n",
      "Episode:1427 meanR:9.2100 R:8.0000 loss:6.9082\n",
      "Episode:1428 meanR:9.2100 R:9.0000 loss:6.9483\n",
      "Episode:1429 meanR:9.2100 R:8.0000 loss:6.9593\n",
      "Episode:1430 meanR:9.2100 R:9.0000 loss:6.9956\n",
      "Episode:1431 meanR:9.2200 R:10.0000 loss:6.9792\n",
      "Episode:1432 meanR:9.2200 R:9.0000 loss:6.9826\n",
      "Episode:1433 meanR:9.2400 R:11.0000 loss:6.9227\n",
      "Episode:1434 meanR:9.2600 R:10.0000 loss:6.8311\n",
      "Episode:1435 meanR:9.2600 R:9.0000 loss:6.8271\n",
      "Episode:1436 meanR:9.2600 R:10.0000 loss:6.7890\n",
      "Episode:1437 meanR:9.2500 R:9.0000 loss:6.7819\n",
      "Episode:1438 meanR:9.2700 R:10.0000 loss:6.7525\n",
      "Episode:1439 meanR:9.2600 R:9.0000 loss:6.7454\n",
      "Episode:1440 meanR:9.2500 R:10.0000 loss:6.7656\n",
      "Episode:1441 meanR:9.2400 R:9.0000 loss:6.7104\n",
      "Episode:1442 meanR:9.2300 R:9.0000 loss:6.7179\n",
      "Episode:1443 meanR:9.2400 R:10.0000 loss:6.6606\n",
      "Episode:1444 meanR:9.2400 R:10.0000 loss:6.6295\n",
      "Episode:1445 meanR:9.2400 R:9.0000 loss:6.6584\n",
      "Episode:1446 meanR:9.2300 R:9.0000 loss:6.6741\n",
      "Episode:1447 meanR:9.2300 R:9.0000 loss:6.7831\n",
      "Episode:1448 meanR:9.2300 R:9.0000 loss:6.8398\n",
      "Episode:1449 meanR:9.2200 R:8.0000 loss:6.8842\n",
      "Episode:1450 meanR:9.2300 R:10.0000 loss:6.9083\n",
      "Episode:1451 meanR:9.2100 R:8.0000 loss:6.9454\n",
      "Episode:1452 meanR:9.2200 R:10.0000 loss:6.9552\n",
      "Episode:1453 meanR:9.2300 R:10.0000 loss:6.9092\n",
      "Episode:1454 meanR:9.2400 R:10.0000 loss:6.9097\n",
      "Episode:1455 meanR:9.2500 R:9.0000 loss:6.9005\n",
      "Episode:1456 meanR:9.2500 R:10.0000 loss:6.8684\n",
      "Episode:1457 meanR:9.2700 R:10.0000 loss:6.8704\n",
      "Episode:1458 meanR:9.2800 R:10.0000 loss:6.8738\n",
      "Episode:1459 meanR:9.2800 R:9.0000 loss:6.8632\n",
      "Episode:1460 meanR:9.2800 R:9.0000 loss:6.8670\n",
      "Episode:1461 meanR:9.2900 R:9.0000 loss:6.8693\n",
      "Episode:1462 meanR:9.3000 R:10.0000 loss:6.8437\n",
      "Episode:1463 meanR:9.2800 R:9.0000 loss:6.7819\n",
      "Episode:1464 meanR:9.2800 R:10.0000 loss:6.8125\n",
      "Episode:1465 meanR:9.2700 R:9.0000 loss:6.7486\n",
      "Episode:1466 meanR:9.2600 R:9.0000 loss:6.8080\n",
      "Episode:1467 meanR:9.2500 R:9.0000 loss:6.8642\n",
      "Episode:1468 meanR:9.2500 R:10.0000 loss:6.8901\n",
      "Episode:1469 meanR:9.2400 R:9.0000 loss:6.8772\n",
      "Episode:1470 meanR:9.2600 R:10.0000 loss:6.8996\n",
      "Episode:1471 meanR:9.2700 R:10.0000 loss:6.9046\n",
      "Episode:1472 meanR:9.2800 R:11.0000 loss:6.8844\n",
      "Episode:1473 meanR:9.2900 R:11.0000 loss:6.8099\n",
      "Episode:1474 meanR:9.3000 R:10.0000 loss:6.7471\n",
      "Episode:1475 meanR:9.3000 R:9.0000 loss:6.7203\n",
      "Episode:1476 meanR:9.3100 R:10.0000 loss:6.7730\n",
      "Episode:1477 meanR:9.3000 R:9.0000 loss:6.7474\n",
      "Episode:1478 meanR:9.3200 R:10.0000 loss:6.7998\n",
      "Episode:1479 meanR:9.3300 R:10.0000 loss:6.7280\n",
      "Episode:1480 meanR:9.3300 R:10.0000 loss:6.6917\n",
      "Episode:1481 meanR:9.3400 R:9.0000 loss:6.7544\n",
      "Episode:1482 meanR:9.3200 R:8.0000 loss:6.8201\n",
      "Episode:1483 meanR:9.3300 R:10.0000 loss:6.8282\n",
      "Episode:1484 meanR:9.3100 R:8.0000 loss:6.8536\n",
      "Episode:1485 meanR:9.3000 R:9.0000 loss:6.9576\n",
      "Episode:1486 meanR:9.3200 R:10.0000 loss:7.0400\n",
      "Episode:1487 meanR:9.3100 R:9.0000 loss:7.1191\n",
      "Episode:1488 meanR:9.3100 R:10.0000 loss:7.1324\n",
      "Episode:1489 meanR:9.3100 R:9.0000 loss:7.1151\n",
      "Episode:1490 meanR:9.3200 R:10.0000 loss:7.1263\n",
      "Episode:1491 meanR:9.3200 R:8.0000 loss:7.1477\n",
      "Episode:1492 meanR:9.3200 R:9.0000 loss:7.2079\n",
      "Episode:1493 meanR:9.3300 R:10.0000 loss:7.2052\n",
      "Episode:1494 meanR:9.3200 R:9.0000 loss:7.2428\n",
      "Episode:1495 meanR:9.3100 R:9.0000 loss:7.2327\n",
      "Episode:1496 meanR:9.3100 R:10.0000 loss:7.1317\n",
      "Episode:1497 meanR:9.3200 R:10.0000 loss:7.1224\n",
      "Episode:1498 meanR:9.3200 R:10.0000 loss:7.0256\n",
      "Episode:1499 meanR:9.3300 R:9.0000 loss:7.0042\n",
      "Episode:1500 meanR:9.3400 R:10.0000 loss:7.0239\n",
      "Episode:1501 meanR:9.3500 R:10.0000 loss:6.9783\n",
      "Episode:1502 meanR:9.3600 R:9.0000 loss:7.0065\n",
      "Episode:1503 meanR:9.3600 R:9.0000 loss:7.0086\n",
      "Episode:1504 meanR:9.3500 R:9.0000 loss:7.0598\n",
      "Episode:1505 meanR:9.3400 R:8.0000 loss:7.0411\n",
      "Episode:1506 meanR:9.3400 R:9.0000 loss:7.0598\n",
      "Episode:1507 meanR:9.3400 R:9.0000 loss:7.1086\n",
      "Episode:1508 meanR:9.3200 R:8.0000 loss:7.1510\n",
      "Episode:1509 meanR:9.3400 R:10.0000 loss:7.1104\n",
      "Episode:1510 meanR:9.3300 R:8.0000 loss:7.1978\n",
      "Episode:1511 meanR:9.3200 R:8.0000 loss:7.2421\n",
      "Episode:1512 meanR:9.3300 R:9.0000 loss:7.2830\n",
      "Episode:1513 meanR:9.3300 R:9.0000 loss:7.3175\n",
      "Episode:1514 meanR:9.3200 R:9.0000 loss:7.3022\n",
      "Episode:1515 meanR:9.3200 R:9.0000 loss:7.3343\n",
      "Episode:1516 meanR:9.3200 R:9.0000 loss:7.3660\n",
      "Episode:1517 meanR:9.3000 R:8.0000 loss:7.3781\n",
      "Episode:1518 meanR:9.3100 R:10.0000 loss:7.3436\n",
      "Episode:1519 meanR:9.3100 R:9.0000 loss:7.3017\n",
      "Episode:1520 meanR:9.3100 R:9.0000 loss:7.2330\n",
      "Episode:1521 meanR:9.3100 R:9.0000 loss:7.2160\n",
      "Episode:1522 meanR:9.3100 R:9.0000 loss:7.2008\n",
      "Episode:1523 meanR:9.3200 R:10.0000 loss:7.1212\n",
      "Episode:1524 meanR:9.3200 R:9.0000 loss:7.1234\n",
      "Episode:1525 meanR:9.3400 R:11.0000 loss:6.9683\n",
      "Episode:1526 meanR:9.3500 R:11.0000 loss:6.8397\n",
      "Episode:1527 meanR:9.3700 R:10.0000 loss:6.7841\n",
      "Episode:1528 meanR:9.3600 R:8.0000 loss:6.8001\n",
      "Episode:1529 meanR:9.3700 R:9.0000 loss:6.8228\n",
      "Episode:1530 meanR:9.3700 R:9.0000 loss:6.8263\n",
      "Episode:1531 meanR:9.3600 R:9.0000 loss:6.7829\n",
      "Episode:1532 meanR:9.3500 R:8.0000 loss:6.8745\n",
      "Episode:1533 meanR:9.3400 R:10.0000 loss:6.8546\n",
      "Episode:1534 meanR:9.3300 R:9.0000 loss:6.8437\n",
      "Episode:1535 meanR:9.3300 R:9.0000 loss:6.8479\n",
      "Episode:1536 meanR:9.3300 R:10.0000 loss:6.8229\n",
      "Episode:1537 meanR:9.3200 R:8.0000 loss:6.8938\n",
      "Episode:1538 meanR:9.3200 R:10.0000 loss:6.8746\n",
      "Episode:1539 meanR:9.3200 R:9.0000 loss:6.9605\n",
      "Episode:1540 meanR:9.3200 R:10.0000 loss:7.0094\n",
      "Episode:1541 meanR:9.3200 R:9.0000 loss:7.0514\n",
      "Episode:1542 meanR:9.3300 R:10.0000 loss:6.9625\n",
      "Episode:1543 meanR:9.3300 R:10.0000 loss:6.9111\n",
      "Episode:1544 meanR:9.3300 R:10.0000 loss:6.8656\n",
      "Episode:1545 meanR:9.3300 R:9.0000 loss:6.8522\n",
      "Episode:1546 meanR:9.3300 R:9.0000 loss:6.8063\n",
      "Episode:1547 meanR:9.3400 R:10.0000 loss:6.8306\n",
      "Episode:1548 meanR:9.3500 R:10.0000 loss:6.7930\n",
      "Episode:1549 meanR:9.3600 R:9.0000 loss:6.7762\n",
      "Episode:1550 meanR:9.3600 R:10.0000 loss:6.8069\n",
      "Episode:1551 meanR:9.3700 R:9.0000 loss:6.7420\n",
      "Episode:1552 meanR:9.3700 R:10.0000 loss:6.7809\n",
      "Episode:1553 meanR:9.3700 R:10.0000 loss:6.7468\n",
      "Episode:1554 meanR:9.3600 R:9.0000 loss:6.7723\n",
      "Episode:1555 meanR:9.3700 R:10.0000 loss:6.7671\n",
      "Episode:1556 meanR:9.3600 R:9.0000 loss:6.7935\n",
      "Episode:1557 meanR:9.3500 R:9.0000 loss:6.8509\n",
      "Episode:1558 meanR:9.3400 R:9.0000 loss:6.9079\n",
      "Episode:1559 meanR:9.3500 R:10.0000 loss:6.8881\n",
      "Episode:1560 meanR:9.3400 R:8.0000 loss:6.8949\n",
      "Episode:1561 meanR:9.3400 R:9.0000 loss:6.9728\n",
      "Episode:1562 meanR:9.3400 R:10.0000 loss:6.9894\n",
      "Episode:1563 meanR:9.3500 R:10.0000 loss:6.9453\n",
      "Episode:1564 meanR:9.3500 R:10.0000 loss:6.9467\n",
      "Episode:1565 meanR:9.3600 R:10.0000 loss:6.9042\n",
      "Episode:1566 meanR:9.3700 R:10.0000 loss:6.9080\n",
      "Episode:1567 meanR:9.3700 R:9.0000 loss:6.9378\n",
      "Episode:1568 meanR:9.3500 R:8.0000 loss:6.9745\n",
      "Episode:1569 meanR:9.3600 R:10.0000 loss:7.0073\n",
      "Episode:1570 meanR:9.3600 R:10.0000 loss:6.9633\n",
      "Episode:1571 meanR:9.3600 R:10.0000 loss:6.9193\n",
      "Episode:1572 meanR:9.3300 R:8.0000 loss:6.9249\n",
      "Episode:1573 meanR:9.3100 R:9.0000 loss:7.0006\n",
      "Episode:1574 meanR:9.3200 R:11.0000 loss:6.9066\n",
      "Episode:1575 meanR:9.3100 R:8.0000 loss:6.8777\n",
      "Episode:1576 meanR:9.3100 R:10.0000 loss:6.9378\n",
      "Episode:1577 meanR:9.3100 R:9.0000 loss:6.9669\n",
      "Episode:1578 meanR:9.3100 R:10.0000 loss:6.9897\n",
      "Episode:1579 meanR:9.3100 R:10.0000 loss:6.9913\n",
      "Episode:1580 meanR:9.3000 R:9.0000 loss:7.0235\n",
      "Episode:1581 meanR:9.3000 R:9.0000 loss:7.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1582 meanR:9.3100 R:9.0000 loss:6.9745\n",
      "Episode:1583 meanR:9.3000 R:9.0000 loss:7.0241\n",
      "Episode:1584 meanR:9.3200 R:10.0000 loss:7.0399\n",
      "Episode:1585 meanR:9.3200 R:9.0000 loss:7.0740\n",
      "Episode:1586 meanR:9.3200 R:10.0000 loss:6.9909\n",
      "Episode:1587 meanR:9.3300 R:10.0000 loss:6.9463\n",
      "Episode:1588 meanR:9.3200 R:9.0000 loss:7.0228\n",
      "Episode:1589 meanR:9.3200 R:9.0000 loss:6.9734\n",
      "Episode:1590 meanR:9.3200 R:10.0000 loss:6.9942\n",
      "Episode:1591 meanR:9.3300 R:9.0000 loss:6.9773\n",
      "Episode:1592 meanR:9.3300 R:9.0000 loss:7.0288\n",
      "Episode:1593 meanR:9.3200 R:9.0000 loss:7.0783\n",
      "Episode:1594 meanR:9.3100 R:8.0000 loss:7.1217\n",
      "Episode:1595 meanR:9.3200 R:10.0000 loss:7.0827\n",
      "Episode:1596 meanR:9.3300 R:11.0000 loss:7.0042\n",
      "Episode:1597 meanR:9.3200 R:9.0000 loss:6.9668\n",
      "Episode:1598 meanR:9.3200 R:10.0000 loss:6.9869\n",
      "Episode:1599 meanR:9.3300 R:10.0000 loss:6.9448\n",
      "Episode:1600 meanR:9.3100 R:8.0000 loss:7.0039\n",
      "Episode:1601 meanR:9.3200 R:11.0000 loss:7.0082\n",
      "Episode:1602 meanR:9.3300 R:10.0000 loss:6.9485\n",
      "Episode:1603 meanR:9.3300 R:9.0000 loss:6.9267\n",
      "Episode:1604 meanR:9.3300 R:9.0000 loss:6.9798\n",
      "Episode:1605 meanR:9.3400 R:9.0000 loss:6.9825\n",
      "Episode:1606 meanR:9.3500 R:10.0000 loss:6.9591\n",
      "Episode:1607 meanR:9.3600 R:10.0000 loss:6.9174\n",
      "Episode:1608 meanR:9.3800 R:10.0000 loss:6.8336\n",
      "Episode:1609 meanR:9.3700 R:9.0000 loss:6.8525\n",
      "Episode:1610 meanR:9.3800 R:9.0000 loss:6.9617\n",
      "Episode:1611 meanR:9.3800 R:8.0000 loss:6.9926\n",
      "Episode:1612 meanR:9.3800 R:9.0000 loss:7.0705\n",
      "Episode:1613 meanR:9.3800 R:9.0000 loss:7.1207\n",
      "Episode:1614 meanR:9.3800 R:9.0000 loss:7.0682\n",
      "Episode:1615 meanR:9.3900 R:10.0000 loss:7.1251\n",
      "Episode:1616 meanR:9.4000 R:10.0000 loss:7.1211\n",
      "Episode:1617 meanR:9.4300 R:11.0000 loss:7.0414\n",
      "Episode:1618 meanR:9.4200 R:9.0000 loss:7.0026\n",
      "Episode:1619 meanR:9.4300 R:10.0000 loss:6.9781\n",
      "Episode:1620 meanR:9.4500 R:11.0000 loss:6.9592\n",
      "Episode:1621 meanR:9.4600 R:10.0000 loss:6.9380\n",
      "Episode:1622 meanR:9.4700 R:10.0000 loss:6.9429\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "        initial_state = sess.run(model.initial_state)\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append(initial_state)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            initial_state = final_state\n",
    "\n",
    "            # Training\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            initial_states = np.array(memory.states)\n",
    "            next_actions_logits = sess.run(model.actions_logits, \n",
    "                                           feed_dict = {model.states: next_states,\n",
    "                                                        model.initial_state: initial_states[1]})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs,\n",
    "                                                                     model.initial_state: initial_states[0]})\n",
    "            # End of training\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        # Outputing: priting out/Potting\n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n",
      "total_reward:500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episode/epoch\n",
    "    for _ in range(10):\n",
    "        total_reward = 0\n",
    "        state = env.reset()\n",
    "        initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "        \n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits, initial_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                    feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                                 model.initial_state: initial_state})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # At the end of each episode\n",
    "        print('total_reward:{}'.format(total_reward))\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

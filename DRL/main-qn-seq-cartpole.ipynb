{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info: [-0.02301832  0.23638743  0.01045034 -0.30979822] 1 1.0 False {}\n",
      "state, action, reward, done, info: [-0.01829057  0.04111816  0.00425438 -0.01383796] 0 1.0 False {}\n",
      "state, action, reward, done, info: [-0.0174682   0.23617884  0.00397762 -0.30517554] 1 1.0 False {}\n",
      "state, action, reward, done, info: [-0.01274463  0.04100043 -0.00212589 -0.01124083] 0 1.0 False {}\n",
      "state, action, reward, done, info: [-0.01192462  0.23615281 -0.00235071 -0.30459374] 1 1.0 False {}\n",
      "state, action, reward, done, info: [-0.00720156  0.43130818 -0.00844258 -0.5980171 ] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.0014246   0.62654724 -0.02040292 -0.89334734] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.01395555  0.82193988 -0.03826987 -1.19237335] 1 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.03039434  0.62733401 -0.06211734 -0.91192688] 0 1.0 False {}\n",
      "state, action, reward, done, info: [ 0.04294102  0.43310503 -0.08035587 -0.63939606] 0 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, lstm_size, batch_size=1):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    # RNN\n",
    "    gru = tf.nn.rnn_cell.GRUCell(lstm_size)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([gru], state_is_tuple=False)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    return states, actions, targetQs, cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN generator or sequence generator\n",
    "def generator(states, initial_state, cell, lstm_size, num_classes, reuse=False): \n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        inputs = tf.layers.dense(inputs=states, units=lstm_size)\n",
    "        print(states.shape, inputs.shape)\n",
    "        \n",
    "        # with tf.variable_scope('dynamic_rnn_', reuse=tf.AUTO_REUSE):\n",
    "        # dynamic means adapt to the batch_size\n",
    "        inputs_rnn = tf.reshape(inputs, [1, -1, lstm_size]) # NxH -> 1xNxH\n",
    "        print(inputs_rnn.shape, initial_state.shape)\n",
    "        outputs_rnn, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=inputs_rnn, initial_state=initial_state)\n",
    "        print(outputs_rnn.shape, final_state.shape)\n",
    "        outputs = tf.reshape(outputs_rnn, [-1, lstm_size]) # 1xNxH -> NxH\n",
    "        print(outputs.shape)\n",
    "\n",
    "        # Last fully connected layer\n",
    "        logits = tf.layers.dense(inputs=outputs, units=num_classes)\n",
    "        print(logits.shape)\n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "        \n",
    "        # logits are the action logits\n",
    "        return logits, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, states, cell, initial_state, actions, targetQs):\n",
    "    actions_logits, final_state = generator(states=states, cell=cell, initial_state=initial_state, \n",
    "                                            lstm_size=hidden_size, num_classes=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_logits, final_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # # Optimize\n",
    "    # with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "    # #opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    #grads, _ = tf.clip_by_global_norm(t_list=tf.gradients(loss, g_vars), clip_norm=5) # usually around 1-5\n",
    "    grads = tf.gradients(loss, g_vars)\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(grads_and_vars=zip(grads, g_vars))\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.targetQs, cell, self.initial_state = model_input(\n",
    "            state_size=state_size, lstm_size=hidden_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.final_state, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, actions=self.actions, \n",
    "            targetQs=self.targetQs, cell=cell, initial_state=self.initial_state)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        self.states = deque(maxlen=max_size)\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx], [self.states[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state:', np.array(states).shape[1], \n",
    "#       'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "action_size = 2\n",
    "state_size = 4\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 128            # memory capacity - 1000 DQN\n",
    "batch_size = 128             # experience mini-batch size - 20 DQN\n",
    "gamma = 0.99                 # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(1, ?, 64) (1, 64)\n",
      "(?, 64)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "# initial_state = np.zeros([1, hidden_size])\n",
    "# final_state = np.zeros([1, hidden_size])\n",
    "for _ in range(batch_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    #memory.states.append([initial_state, final_state])\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.buffer[0], memory.states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states, rewards, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:71.0000 R:71.0 loss:2.0061 exploreP:0.9930\n",
      "Episode:1 meanR:41.5000 R:12.0 loss:4.4033 exploreP:0.9918\n",
      "Episode:2 meanR:31.0000 R:10.0 loss:4.4567 exploreP:0.9908\n",
      "Episode:3 meanR:27.2500 R:16.0 loss:5.4879 exploreP:0.9893\n",
      "Episode:4 meanR:25.0000 R:16.0 loss:7.3702 exploreP:0.9877\n",
      "Episode:5 meanR:22.5000 R:10.0 loss:5.2478 exploreP:0.9867\n",
      "Episode:6 meanR:21.4286 R:15.0 loss:4.6599 exploreP:0.9853\n",
      "Episode:7 meanR:21.8750 R:25.0 loss:4.1861 exploreP:0.9828\n",
      "Episode:8 meanR:22.4444 R:27.0 loss:3.9478 exploreP:0.9802\n",
      "Episode:9 meanR:21.9000 R:17.0 loss:3.6066 exploreP:0.9786\n",
      "Episode:10 meanR:21.2727 R:15.0 loss:3.5123 exploreP:0.9771\n",
      "Episode:11 meanR:21.5833 R:25.0 loss:3.2292 exploreP:0.9747\n",
      "Episode:12 meanR:21.3077 R:18.0 loss:2.0121 exploreP:0.9730\n",
      "Episode:13 meanR:21.6429 R:26.0 loss:2.2170 exploreP:0.9705\n",
      "Episode:14 meanR:21.4667 R:19.0 loss:2.7960 exploreP:0.9686\n",
      "Episode:15 meanR:23.0000 R:46.0 loss:2.8862 exploreP:0.9642\n",
      "Episode:16 meanR:24.4118 R:47.0 loss:2.8574 exploreP:0.9598\n",
      "Episode:17 meanR:23.6111 R:10.0 loss:2.8881 exploreP:0.9588\n",
      "Episode:18 meanR:23.2105 R:16.0 loss:2.7005 exploreP:0.9573\n",
      "Episode:19 meanR:23.3000 R:25.0 loss:2.9564 exploreP:0.9549\n",
      "Episode:20 meanR:23.1905 R:21.0 loss:3.2885 exploreP:0.9529\n",
      "Episode:21 meanR:23.2727 R:25.0 loss:3.4185 exploreP:0.9506\n",
      "Episode:22 meanR:23.4348 R:27.0 loss:3.6696 exploreP:0.9481\n",
      "Episode:23 meanR:23.0417 R:14.0 loss:3.8073 exploreP:0.9467\n",
      "Episode:24 meanR:22.7600 R:16.0 loss:3.8610 exploreP:0.9452\n",
      "Episode:25 meanR:22.5000 R:16.0 loss:3.7422 exploreP:0.9437\n",
      "Episode:26 meanR:22.7407 R:29.0 loss:3.8371 exploreP:0.9410\n",
      "Episode:27 meanR:23.3929 R:41.0 loss:3.8635 exploreP:0.9372\n",
      "Episode:28 meanR:23.2759 R:20.0 loss:4.1715 exploreP:0.9354\n",
      "Episode:29 meanR:22.8667 R:11.0 loss:4.2502 exploreP:0.9344\n",
      "Episode:30 meanR:22.5806 R:14.0 loss:4.4356 exploreP:0.9331\n",
      "Episode:31 meanR:22.4688 R:19.0 loss:4.5354 exploreP:0.9313\n",
      "Episode:32 meanR:22.3030 R:17.0 loss:5.0297 exploreP:0.9298\n",
      "Episode:33 meanR:23.7059 R:70.0 loss:4.9888 exploreP:0.9233\n",
      "Episode:34 meanR:23.8857 R:30.0 loss:4.1794 exploreP:0.9206\n",
      "Episode:35 meanR:23.6111 R:14.0 loss:4.3478 exploreP:0.9193\n",
      "Episode:36 meanR:23.4595 R:18.0 loss:4.4638 exploreP:0.9177\n",
      "Episode:37 meanR:23.2368 R:15.0 loss:4.7601 exploreP:0.9163\n",
      "Episode:38 meanR:23.2051 R:22.0 loss:5.5196 exploreP:0.9143\n",
      "Episode:39 meanR:23.4500 R:33.0 loss:6.0921 exploreP:0.9114\n",
      "Episode:40 meanR:23.3659 R:20.0 loss:6.0039 exploreP:0.9096\n",
      "Episode:41 meanR:23.1190 R:13.0 loss:5.8870 exploreP:0.9084\n",
      "Episode:42 meanR:23.3023 R:31.0 loss:6.0197 exploreP:0.9056\n",
      "Episode:43 meanR:23.9091 R:50.0 loss:5.5007 exploreP:0.9011\n",
      "Episode:44 meanR:23.9556 R:26.0 loss:5.8100 exploreP:0.8988\n",
      "Episode:45 meanR:23.9348 R:23.0 loss:5.5385 exploreP:0.8968\n",
      "Episode:46 meanR:23.8085 R:18.0 loss:5.3479 exploreP:0.8952\n",
      "Episode:47 meanR:23.6875 R:18.0 loss:5.8086 exploreP:0.8936\n",
      "Episode:48 meanR:23.4694 R:13.0 loss:6.0849 exploreP:0.8925\n",
      "Episode:49 meanR:23.3000 R:15.0 loss:7.0690 exploreP:0.8911\n",
      "Episode:50 meanR:23.2353 R:20.0 loss:7.8308 exploreP:0.8894\n",
      "Episode:51 meanR:23.0192 R:12.0 loss:8.0577 exploreP:0.8883\n",
      "Episode:52 meanR:22.7925 R:11.0 loss:8.8517 exploreP:0.8873\n",
      "Episode:53 meanR:22.5741 R:11.0 loss:9.1802 exploreP:0.8864\n",
      "Episode:54 meanR:22.4545 R:16.0 loss:9.7499 exploreP:0.8850\n",
      "Episode:55 meanR:22.5714 R:29.0 loss:9.5225 exploreP:0.8824\n",
      "Episode:56 meanR:22.7895 R:35.0 loss:8.3153 exploreP:0.8794\n",
      "Episode:57 meanR:22.9310 R:31.0 loss:7.4649 exploreP:0.8767\n",
      "Episode:58 meanR:22.7797 R:14.0 loss:6.6883 exploreP:0.8755\n",
      "Episode:59 meanR:22.9833 R:35.0 loss:7.0607 exploreP:0.8725\n",
      "Episode:60 meanR:22.8689 R:16.0 loss:7.6285 exploreP:0.8711\n",
      "Episode:61 meanR:22.7742 R:17.0 loss:7.9730 exploreP:0.8696\n",
      "Episode:62 meanR:22.8889 R:30.0 loss:8.3222 exploreP:0.8671\n",
      "Episode:63 meanR:22.7188 R:12.0 loss:8.7150 exploreP:0.8660\n",
      "Episode:64 meanR:22.5692 R:13.0 loss:9.0202 exploreP:0.8649\n",
      "Episode:65 meanR:22.6061 R:25.0 loss:8.6292 exploreP:0.8628\n",
      "Episode:66 meanR:22.5075 R:16.0 loss:9.4776 exploreP:0.8614\n",
      "Episode:67 meanR:22.5294 R:24.0 loss:9.2382 exploreP:0.8594\n",
      "Episode:68 meanR:22.5652 R:25.0 loss:8.9289 exploreP:0.8573\n",
      "Episode:69 meanR:23.2143 R:68.0 loss:7.4214 exploreP:0.8515\n",
      "Episode:70 meanR:23.0704 R:13.0 loss:6.1117 exploreP:0.8504\n",
      "Episode:71 meanR:22.9722 R:16.0 loss:6.5534 exploreP:0.8491\n",
      "Episode:72 meanR:22.8356 R:13.0 loss:7.3693 exploreP:0.8480\n",
      "Episode:73 meanR:22.8919 R:27.0 loss:7.8388 exploreP:0.8457\n",
      "Episode:74 meanR:22.8667 R:21.0 loss:8.7863 exploreP:0.8440\n",
      "Episode:75 meanR:22.6842 R:9.0 loss:10.5744 exploreP:0.8432\n",
      "Episode:76 meanR:22.5065 R:9.0 loss:12.1619 exploreP:0.8425\n",
      "Episode:77 meanR:22.4231 R:16.0 loss:13.5030 exploreP:0.8411\n",
      "Episode:78 meanR:22.5696 R:34.0 loss:12.8322 exploreP:0.8383\n",
      "Episode:79 meanR:22.5500 R:21.0 loss:11.5055 exploreP:0.8366\n",
      "Episode:80 meanR:22.6543 R:31.0 loss:11.1650 exploreP:0.8340\n",
      "Episode:81 meanR:22.6829 R:25.0 loss:9.8941 exploreP:0.8320\n",
      "Episode:82 meanR:22.8313 R:35.0 loss:7.7961 exploreP:0.8291\n",
      "Episode:83 meanR:22.6905 R:11.0 loss:8.7508 exploreP:0.8282\n",
      "Episode:84 meanR:22.7412 R:27.0 loss:9.0794 exploreP:0.8260\n",
      "Episode:85 meanR:22.6977 R:19.0 loss:9.0677 exploreP:0.8244\n",
      "Episode:86 meanR:22.7241 R:25.0 loss:9.7318 exploreP:0.8224\n",
      "Episode:87 meanR:22.7045 R:21.0 loss:9.9886 exploreP:0.8207\n",
      "Episode:88 meanR:22.6517 R:18.0 loss:10.9242 exploreP:0.8192\n",
      "Episode:89 meanR:22.6000 R:18.0 loss:11.8273 exploreP:0.8178\n",
      "Episode:90 meanR:22.9121 R:51.0 loss:10.5103 exploreP:0.8137\n",
      "Episode:91 meanR:22.8261 R:15.0 loss:9.9752 exploreP:0.8125\n",
      "Episode:92 meanR:22.6882 R:10.0 loss:11.0575 exploreP:0.8117\n",
      "Episode:93 meanR:22.6383 R:18.0 loss:11.7750 exploreP:0.8102\n",
      "Episode:94 meanR:22.5474 R:14.0 loss:12.3257 exploreP:0.8091\n",
      "Episode:95 meanR:22.6458 R:32.0 loss:11.6593 exploreP:0.8066\n",
      "Episode:96 meanR:22.6392 R:22.0 loss:12.1790 exploreP:0.8048\n",
      "Episode:97 meanR:22.5612 R:15.0 loss:13.8385 exploreP:0.8036\n",
      "Episode:98 meanR:22.5657 R:23.0 loss:13.2301 exploreP:0.8018\n",
      "Episode:99 meanR:22.5900 R:25.0 loss:11.5898 exploreP:0.7998\n",
      "Episode:100 meanR:22.4100 R:53.0 loss:9.8628 exploreP:0.7956\n",
      "Episode:101 meanR:22.4000 R:11.0 loss:10.1983 exploreP:0.7948\n",
      "Episode:102 meanR:22.5200 R:22.0 loss:10.0368 exploreP:0.7931\n",
      "Episode:103 meanR:22.5300 R:17.0 loss:10.6976 exploreP:0.7917\n",
      "Episode:104 meanR:22.7500 R:38.0 loss:10.0168 exploreP:0.7888\n",
      "Episode:105 meanR:22.7800 R:13.0 loss:10.3582 exploreP:0.7877\n",
      "Episode:106 meanR:22.7500 R:12.0 loss:12.1680 exploreP:0.7868\n",
      "Episode:107 meanR:22.7200 R:22.0 loss:13.1031 exploreP:0.7851\n",
      "Episode:108 meanR:22.6600 R:21.0 loss:12.1925 exploreP:0.7835\n",
      "Episode:109 meanR:22.6900 R:20.0 loss:12.3124 exploreP:0.7819\n",
      "Episode:110 meanR:22.7700 R:23.0 loss:12.2319 exploreP:0.7802\n",
      "Episode:111 meanR:22.6600 R:14.0 loss:14.2568 exploreP:0.7791\n",
      "Episode:112 meanR:22.6300 R:15.0 loss:14.4508 exploreP:0.7779\n",
      "Episode:113 meanR:22.5300 R:16.0 loss:13.5374 exploreP:0.7767\n",
      "Episode:114 meanR:22.5000 R:16.0 loss:13.4398 exploreP:0.7755\n",
      "Episode:115 meanR:22.2100 R:17.0 loss:13.5143 exploreP:0.7742\n",
      "Episode:116 meanR:21.9200 R:18.0 loss:13.3174 exploreP:0.7728\n",
      "Episode:117 meanR:22.0000 R:18.0 loss:12.9658 exploreP:0.7714\n",
      "Episode:118 meanR:22.0100 R:17.0 loss:12.2647 exploreP:0.7701\n",
      "Episode:119 meanR:22.6700 R:91.0 loss:34.7399 exploreP:0.7633\n",
      "Episode:120 meanR:22.6800 R:22.0 loss:22.3060 exploreP:0.7616\n",
      "Episode:121 meanR:22.8300 R:40.0 loss:35.6016 exploreP:0.7586\n",
      "Episode:122 meanR:22.6600 R:10.0 loss:21.7908 exploreP:0.7579\n",
      "Episode:123 meanR:22.9200 R:40.0 loss:17.8259 exploreP:0.7549\n",
      "Episode:124 meanR:22.8600 R:10.0 loss:20.7138 exploreP:0.7541\n",
      "Episode:125 meanR:22.8100 R:11.0 loss:20.7925 exploreP:0.7533\n",
      "Episode:126 meanR:22.6800 R:16.0 loss:20.7438 exploreP:0.7521\n",
      "Episode:127 meanR:22.5600 R:29.0 loss:18.3138 exploreP:0.7500\n",
      "Episode:128 meanR:22.6500 R:29.0 loss:14.3150 exploreP:0.7478\n",
      "Episode:129 meanR:22.8300 R:29.0 loss:13.0979 exploreP:0.7457\n",
      "Episode:130 meanR:22.9400 R:25.0 loss:13.5360 exploreP:0.7439\n",
      "Episode:131 meanR:22.9100 R:16.0 loss:13.1750 exploreP:0.7427\n",
      "Episode:132 meanR:23.0300 R:29.0 loss:13.1448 exploreP:0.7406\n",
      "Episode:133 meanR:22.6900 R:36.0 loss:13.0296 exploreP:0.7379\n",
      "Episode:134 meanR:22.5800 R:19.0 loss:13.1900 exploreP:0.7365\n",
      "Episode:135 meanR:22.7200 R:28.0 loss:12.3993 exploreP:0.7345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:136 meanR:22.9600 R:42.0 loss:13.2405 exploreP:0.7315\n",
      "Episode:137 meanR:23.0900 R:28.0 loss:15.8385 exploreP:0.7295\n",
      "Episode:138 meanR:23.1700 R:30.0 loss:16.0508 exploreP:0.7273\n",
      "Episode:139 meanR:23.3000 R:46.0 loss:12.1054 exploreP:0.7240\n",
      "Episode:140 meanR:23.4300 R:33.0 loss:9.2890 exploreP:0.7217\n",
      "Episode:141 meanR:23.5300 R:23.0 loss:9.9810 exploreP:0.7200\n",
      "Episode:142 meanR:23.3600 R:14.0 loss:9.8353 exploreP:0.7190\n",
      "Episode:143 meanR:23.1000 R:24.0 loss:11.7200 exploreP:0.7173\n",
      "Episode:144 meanR:23.0800 R:24.0 loss:11.6358 exploreP:0.7156\n",
      "Episode:145 meanR:23.4800 R:63.0 loss:11.4331 exploreP:0.7112\n",
      "Episode:146 meanR:23.7500 R:45.0 loss:9.0003 exploreP:0.7081\n",
      "Episode:147 meanR:24.4500 R:88.0 loss:5.7654 exploreP:0.7019\n",
      "Episode:148 meanR:24.5500 R:23.0 loss:5.4324 exploreP:0.7004\n",
      "Episode:149 meanR:24.6200 R:22.0 loss:7.0173 exploreP:0.6988\n",
      "Episode:150 meanR:24.5800 R:16.0 loss:8.9329 exploreP:0.6977\n",
      "Episode:151 meanR:24.6700 R:21.0 loss:11.8309 exploreP:0.6963\n",
      "Episode:152 meanR:25.0300 R:47.0 loss:11.7190 exploreP:0.6931\n",
      "Episode:153 meanR:25.1500 R:23.0 loss:11.7155 exploreP:0.6915\n",
      "Episode:154 meanR:25.1200 R:13.0 loss:12.0654 exploreP:0.6906\n",
      "Episode:155 meanR:25.1200 R:29.0 loss:12.2564 exploreP:0.6886\n",
      "Episode:156 meanR:24.9400 R:17.0 loss:12.1413 exploreP:0.6875\n",
      "Episode:157 meanR:24.7900 R:16.0 loss:15.0172 exploreP:0.6864\n",
      "Episode:158 meanR:24.7600 R:11.0 loss:17.3584 exploreP:0.6857\n",
      "Episode:159 meanR:24.5900 R:18.0 loss:19.8204 exploreP:0.6845\n",
      "Episode:160 meanR:24.6100 R:18.0 loss:18.3430 exploreP:0.6832\n",
      "Episode:161 meanR:24.5500 R:11.0 loss:19.9328 exploreP:0.6825\n",
      "Episode:162 meanR:24.3900 R:14.0 loss:17.3526 exploreP:0.6816\n",
      "Episode:163 meanR:24.4500 R:18.0 loss:18.0720 exploreP:0.6804\n",
      "Episode:164 meanR:24.4700 R:15.0 loss:18.6183 exploreP:0.6793\n",
      "Episode:165 meanR:24.4300 R:21.0 loss:15.8705 exploreP:0.6779\n",
      "Episode:166 meanR:24.4100 R:14.0 loss:15.1616 exploreP:0.6770\n",
      "Episode:167 meanR:24.3000 R:13.0 loss:17.0308 exploreP:0.6761\n",
      "Episode:168 meanR:24.6000 R:55.0 loss:15.4607 exploreP:0.6725\n",
      "Episode:169 meanR:24.1600 R:24.0 loss:13.6905 exploreP:0.6709\n",
      "Episode:170 meanR:24.1300 R:10.0 loss:14.9509 exploreP:0.6702\n",
      "Episode:171 meanR:24.0900 R:12.0 loss:17.0586 exploreP:0.6694\n",
      "Episode:172 meanR:24.1900 R:23.0 loss:16.2636 exploreP:0.6679\n",
      "Episode:173 meanR:24.0500 R:13.0 loss:15.6800 exploreP:0.6671\n",
      "Episode:174 meanR:24.2600 R:42.0 loss:17.0580 exploreP:0.6643\n",
      "Episode:175 meanR:24.4600 R:29.0 loss:17.6602 exploreP:0.6624\n",
      "Episode:176 meanR:24.4900 R:12.0 loss:16.8442 exploreP:0.6616\n",
      "Episode:177 meanR:24.4700 R:14.0 loss:16.6620 exploreP:0.6607\n",
      "Episode:178 meanR:24.4300 R:30.0 loss:16.7176 exploreP:0.6588\n",
      "Episode:179 meanR:24.4100 R:19.0 loss:15.5839 exploreP:0.6576\n",
      "Episode:180 meanR:24.2400 R:14.0 loss:18.2497 exploreP:0.6566\n",
      "Episode:181 meanR:24.1400 R:15.0 loss:20.2712 exploreP:0.6557\n",
      "Episode:182 meanR:23.8900 R:10.0 loss:21.2127 exploreP:0.6550\n",
      "Episode:183 meanR:23.9800 R:20.0 loss:22.7806 exploreP:0.6537\n",
      "Episode:184 meanR:23.8500 R:14.0 loss:22.1704 exploreP:0.6528\n",
      "Episode:185 meanR:23.9000 R:24.0 loss:21.4627 exploreP:0.6513\n",
      "Episode:186 meanR:23.9500 R:30.0 loss:21.7039 exploreP:0.6494\n",
      "Episode:187 meanR:23.8600 R:12.0 loss:20.9577 exploreP:0.6486\n",
      "Episode:188 meanR:23.9400 R:26.0 loss:20.1260 exploreP:0.6470\n",
      "Episode:189 meanR:23.9300 R:17.0 loss:18.3754 exploreP:0.6459\n",
      "Episode:190 meanR:23.5400 R:12.0 loss:19.0311 exploreP:0.6451\n",
      "Episode:191 meanR:23.5900 R:20.0 loss:18.6406 exploreP:0.6438\n",
      "Episode:192 meanR:23.6900 R:20.0 loss:19.0365 exploreP:0.6426\n",
      "Episode:193 meanR:23.8600 R:35.0 loss:18.6495 exploreP:0.6404\n",
      "Episode:194 meanR:24.0400 R:32.0 loss:16.4418 exploreP:0.6384\n",
      "Episode:195 meanR:24.0500 R:33.0 loss:14.1885 exploreP:0.6363\n",
      "Episode:196 meanR:24.0200 R:19.0 loss:13.1347 exploreP:0.6351\n",
      "Episode:197 meanR:24.6800 R:81.0 loss:8.0913 exploreP:0.6301\n",
      "Episode:198 meanR:24.8000 R:35.0 loss:6.0736 exploreP:0.6279\n",
      "Episode:199 meanR:24.7200 R:17.0 loss:11.8572 exploreP:0.6268\n",
      "Episode:200 meanR:24.6000 R:41.0 loss:12.3383 exploreP:0.6243\n",
      "Episode:201 meanR:24.7700 R:28.0 loss:6.9393 exploreP:0.6226\n",
      "Episode:202 meanR:24.9600 R:41.0 loss:7.1172 exploreP:0.6201\n",
      "Episode:203 meanR:25.3600 R:57.0 loss:7.4585 exploreP:0.6166\n",
      "Episode:204 meanR:25.3100 R:33.0 loss:9.8775 exploreP:0.6146\n",
      "Episode:205 meanR:25.4500 R:27.0 loss:10.2943 exploreP:0.6130\n",
      "Episode:206 meanR:25.5000 R:17.0 loss:12.6935 exploreP:0.6120\n",
      "Episode:207 meanR:25.4400 R:16.0 loss:13.9766 exploreP:0.6110\n",
      "Episode:208 meanR:25.3500 R:12.0 loss:17.3119 exploreP:0.6103\n",
      "Episode:209 meanR:25.3000 R:15.0 loss:20.6024 exploreP:0.6094\n",
      "Episode:210 meanR:25.2500 R:18.0 loss:22.3563 exploreP:0.6083\n",
      "Episode:211 meanR:25.2400 R:13.0 loss:24.2087 exploreP:0.6075\n",
      "Episode:212 meanR:25.2500 R:16.0 loss:26.2614 exploreP:0.6066\n",
      "Episode:213 meanR:25.4400 R:35.0 loss:25.4751 exploreP:0.6045\n",
      "Episode:214 meanR:25.9500 R:67.0 loss:18.8132 exploreP:0.6005\n",
      "Episode:215 meanR:26.8000 R:102.0 loss:7.2859 exploreP:0.5945\n",
      "Episode:216 meanR:27.0200 R:40.0 loss:6.1982 exploreP:0.5922\n",
      "Episode:217 meanR:27.0600 R:22.0 loss:8.0847 exploreP:0.5909\n",
      "Episode:218 meanR:27.0800 R:19.0 loss:11.7623 exploreP:0.5898\n",
      "Episode:219 meanR:26.3300 R:16.0 loss:15.4976 exploreP:0.5889\n",
      "Episode:220 meanR:26.3000 R:19.0 loss:19.1855 exploreP:0.5878\n",
      "Episode:221 meanR:26.0600 R:16.0 loss:22.0706 exploreP:0.5869\n",
      "Episode:222 meanR:26.0800 R:12.0 loss:23.2021 exploreP:0.5862\n",
      "Episode:223 meanR:25.8200 R:14.0 loss:26.8172 exploreP:0.5854\n",
      "Episode:224 meanR:25.8800 R:16.0 loss:28.9329 exploreP:0.5844\n",
      "Episode:225 meanR:25.8900 R:12.0 loss:30.4715 exploreP:0.5838\n",
      "Episode:226 meanR:25.9100 R:18.0 loss:31.4197 exploreP:0.5827\n",
      "Episode:227 meanR:25.7100 R:9.0 loss:32.2946 exploreP:0.5822\n",
      "Episode:228 meanR:25.5300 R:11.0 loss:33.5746 exploreP:0.5816\n",
      "Episode:229 meanR:25.4500 R:21.0 loss:32.9315 exploreP:0.5804\n",
      "Episode:230 meanR:25.3800 R:18.0 loss:31.6281 exploreP:0.5794\n",
      "Episode:231 meanR:25.3800 R:16.0 loss:30.1104 exploreP:0.5784\n",
      "Episode:232 meanR:25.5600 R:47.0 loss:25.5997 exploreP:0.5758\n",
      "Episode:233 meanR:25.4700 R:27.0 loss:17.9103 exploreP:0.5743\n",
      "Episode:234 meanR:25.5100 R:23.0 loss:13.0677 exploreP:0.5730\n",
      "Episode:235 meanR:25.3900 R:16.0 loss:14.7369 exploreP:0.5721\n",
      "Episode:236 meanR:25.0900 R:12.0 loss:13.9019 exploreP:0.5714\n",
      "Episode:237 meanR:25.0000 R:19.0 loss:13.2450 exploreP:0.5703\n",
      "Episode:238 meanR:24.9100 R:21.0 loss:15.5142 exploreP:0.5691\n",
      "Episode:239 meanR:24.5600 R:11.0 loss:20.1312 exploreP:0.5685\n",
      "Episode:240 meanR:24.3900 R:16.0 loss:19.2008 exploreP:0.5676\n",
      "Episode:241 meanR:24.3500 R:19.0 loss:21.4728 exploreP:0.5666\n",
      "Episode:242 meanR:24.3900 R:18.0 loss:23.2552 exploreP:0.5656\n",
      "Episode:243 meanR:24.4000 R:25.0 loss:22.0485 exploreP:0.5642\n",
      "Episode:244 meanR:24.4100 R:25.0 loss:19.7036 exploreP:0.5628\n",
      "Episode:245 meanR:24.1200 R:34.0 loss:18.7187 exploreP:0.5609\n",
      "Episode:246 meanR:23.8800 R:21.0 loss:18.2891 exploreP:0.5598\n",
      "Episode:247 meanR:23.2200 R:22.0 loss:17.8622 exploreP:0.5586\n",
      "Episode:248 meanR:23.2000 R:21.0 loss:17.4040 exploreP:0.5574\n",
      "Episode:249 meanR:23.1300 R:15.0 loss:18.3485 exploreP:0.5566\n",
      "Episode:250 meanR:23.0800 R:11.0 loss:20.4877 exploreP:0.5560\n",
      "Episode:251 meanR:23.0100 R:14.0 loss:21.5042 exploreP:0.5552\n",
      "Episode:252 meanR:22.6900 R:15.0 loss:23.8348 exploreP:0.5544\n",
      "Episode:253 meanR:22.5600 R:10.0 loss:26.7831 exploreP:0.5539\n",
      "Episode:254 meanR:22.5700 R:14.0 loss:27.3208 exploreP:0.5531\n",
      "Episode:255 meanR:22.4000 R:12.0 loss:28.7701 exploreP:0.5525\n",
      "Episode:256 meanR:22.3200 R:9.0 loss:30.0520 exploreP:0.5520\n",
      "Episode:257 meanR:22.2600 R:10.0 loss:31.9278 exploreP:0.5514\n",
      "Episode:258 meanR:22.3100 R:16.0 loss:32.3699 exploreP:0.5506\n",
      "Episode:259 meanR:22.2500 R:12.0 loss:32.3990 exploreP:0.5499\n",
      "Episode:260 meanR:22.1800 R:11.0 loss:32.9336 exploreP:0.5493\n",
      "Episode:261 meanR:22.2600 R:19.0 loss:31.6407 exploreP:0.5483\n",
      "Episode:262 meanR:22.2700 R:15.0 loss:30.5074 exploreP:0.5475\n",
      "Episode:263 meanR:22.2700 R:18.0 loss:28.7949 exploreP:0.5465\n",
      "Episode:264 meanR:22.2600 R:14.0 loss:28.0690 exploreP:0.5458\n",
      "Episode:265 meanR:22.2300 R:18.0 loss:26.6639 exploreP:0.5448\n",
      "Episode:266 meanR:22.2400 R:15.0 loss:25.1698 exploreP:0.5440\n",
      "Episode:267 meanR:22.2200 R:11.0 loss:25.5037 exploreP:0.5434\n",
      "Episode:268 meanR:21.8500 R:18.0 loss:25.0504 exploreP:0.5425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:269 meanR:21.7000 R:9.0 loss:24.6852 exploreP:0.5420\n",
      "Episode:270 meanR:21.6900 R:9.0 loss:27.0805 exploreP:0.5415\n",
      "Episode:271 meanR:21.7200 R:15.0 loss:27.0511 exploreP:0.5407\n",
      "Episode:272 meanR:21.6400 R:15.0 loss:26.7627 exploreP:0.5399\n",
      "Episode:273 meanR:21.6600 R:15.0 loss:26.5549 exploreP:0.5391\n",
      "Episode:274 meanR:21.3600 R:12.0 loss:26.1318 exploreP:0.5385\n",
      "Episode:275 meanR:21.4600 R:39.0 loss:24.6400 exploreP:0.5364\n",
      "Episode:276 meanR:21.5500 R:21.0 loss:21.4751 exploreP:0.5353\n",
      "Episode:277 meanR:21.6700 R:26.0 loss:18.0290 exploreP:0.5340\n",
      "Episode:278 meanR:21.6200 R:25.0 loss:15.7529 exploreP:0.5326\n",
      "Episode:279 meanR:21.5800 R:15.0 loss:15.0250 exploreP:0.5319\n",
      "Episode:280 meanR:21.7000 R:26.0 loss:12.0934 exploreP:0.5305\n",
      "Episode:281 meanR:21.8200 R:27.0 loss:13.1557 exploreP:0.5291\n",
      "Episode:282 meanR:21.8600 R:14.0 loss:13.6083 exploreP:0.5284\n",
      "Episode:283 meanR:21.8000 R:14.0 loss:14.4337 exploreP:0.5277\n",
      "Episode:284 meanR:21.7600 R:10.0 loss:16.4695 exploreP:0.5271\n",
      "Episode:285 meanR:21.6200 R:10.0 loss:17.6850 exploreP:0.5266\n",
      "Episode:286 meanR:21.4300 R:11.0 loss:19.7604 exploreP:0.5261\n",
      "Episode:287 meanR:21.5000 R:19.0 loss:19.7409 exploreP:0.5251\n",
      "Episode:288 meanR:21.3700 R:13.0 loss:22.3366 exploreP:0.5244\n",
      "Episode:289 meanR:21.4000 R:20.0 loss:23.7408 exploreP:0.5234\n",
      "Episode:290 meanR:21.5600 R:28.0 loss:24.1365 exploreP:0.5219\n",
      "Episode:291 meanR:21.4900 R:13.0 loss:23.4673 exploreP:0.5213\n",
      "Episode:292 meanR:21.4400 R:15.0 loss:23.0120 exploreP:0.5205\n",
      "Episode:293 meanR:21.2000 R:11.0 loss:21.8841 exploreP:0.5199\n",
      "Episode:294 meanR:20.9900 R:11.0 loss:21.6850 exploreP:0.5194\n",
      "Episode:295 meanR:20.8300 R:17.0 loss:21.6544 exploreP:0.5185\n",
      "Episode:296 meanR:20.7900 R:15.0 loss:21.2466 exploreP:0.5178\n",
      "Episode:297 meanR:20.2000 R:22.0 loss:20.8762 exploreP:0.5166\n",
      "Episode:298 meanR:19.9800 R:13.0 loss:21.1967 exploreP:0.5160\n",
      "Episode:299 meanR:19.9800 R:17.0 loss:22.6009 exploreP:0.5151\n",
      "Episode:300 meanR:19.6900 R:12.0 loss:22.2575 exploreP:0.5145\n",
      "Episode:301 meanR:19.5300 R:12.0 loss:22.7394 exploreP:0.5139\n",
      "Episode:302 meanR:19.2700 R:15.0 loss:21.9919 exploreP:0.5132\n",
      "Episode:303 meanR:18.8400 R:14.0 loss:21.2270 exploreP:0.5125\n",
      "Episode:304 meanR:18.7200 R:21.0 loss:21.0222 exploreP:0.5114\n",
      "Episode:305 meanR:18.6200 R:17.0 loss:20.1686 exploreP:0.5105\n",
      "Episode:306 meanR:18.6800 R:23.0 loss:20.1222 exploreP:0.5094\n",
      "Episode:307 meanR:18.6500 R:13.0 loss:19.6629 exploreP:0.5087\n",
      "Episode:308 meanR:18.6400 R:11.0 loss:19.7948 exploreP:0.5082\n",
      "Episode:309 meanR:18.6400 R:15.0 loss:19.6483 exploreP:0.5075\n",
      "Episode:310 meanR:18.5900 R:13.0 loss:19.5825 exploreP:0.5068\n",
      "Episode:311 meanR:18.5800 R:12.0 loss:19.6306 exploreP:0.5062\n",
      "Episode:312 meanR:18.5700 R:15.0 loss:19.7351 exploreP:0.5055\n",
      "Episode:313 meanR:18.3600 R:14.0 loss:20.7666 exploreP:0.5048\n",
      "Episode:314 meanR:17.8000 R:11.0 loss:21.6047 exploreP:0.5042\n",
      "Episode:315 meanR:16.9000 R:12.0 loss:21.8916 exploreP:0.5036\n",
      "Episode:316 meanR:16.6200 R:12.0 loss:23.5032 exploreP:0.5030\n",
      "Episode:317 meanR:16.5200 R:12.0 loss:23.4571 exploreP:0.5025\n",
      "Episode:318 meanR:16.4900 R:16.0 loss:22.5928 exploreP:0.5017\n",
      "Episode:319 meanR:16.4800 R:15.0 loss:21.9910 exploreP:0.5009\n",
      "Episode:320 meanR:16.4400 R:15.0 loss:21.3784 exploreP:0.5002\n",
      "Episode:321 meanR:16.4700 R:19.0 loss:20.4832 exploreP:0.4993\n",
      "Episode:322 meanR:16.7100 R:36.0 loss:18.0623 exploreP:0.4975\n",
      "Episode:323 meanR:16.8000 R:23.0 loss:14.9617 exploreP:0.4964\n",
      "Episode:324 meanR:16.8200 R:18.0 loss:13.8561 exploreP:0.4955\n",
      "Episode:325 meanR:16.8600 R:16.0 loss:13.7357 exploreP:0.4947\n",
      "Episode:326 meanR:16.9000 R:22.0 loss:13.0856 exploreP:0.4937\n",
      "Episode:327 meanR:16.9500 R:14.0 loss:13.5039 exploreP:0.4930\n",
      "Episode:328 meanR:16.9900 R:15.0 loss:13.7816 exploreP:0.4923\n",
      "Episode:329 meanR:16.9000 R:12.0 loss:15.9068 exploreP:0.4917\n",
      "Episode:330 meanR:16.8900 R:17.0 loss:16.8015 exploreP:0.4909\n",
      "Episode:331 meanR:16.8600 R:13.0 loss:17.9313 exploreP:0.4902\n",
      "Episode:332 meanR:16.4700 R:8.0 loss:18.3697 exploreP:0.4899\n",
      "Episode:333 meanR:16.4200 R:22.0 loss:18.9267 exploreP:0.4888\n",
      "Episode:334 meanR:16.3000 R:11.0 loss:19.0670 exploreP:0.4883\n",
      "Episode:335 meanR:16.2500 R:11.0 loss:20.0311 exploreP:0.4878\n",
      "Episode:336 meanR:16.2400 R:11.0 loss:20.9332 exploreP:0.4872\n",
      "Episode:337 meanR:16.1500 R:10.0 loss:21.4713 exploreP:0.4868\n",
      "Episode:338 meanR:16.0400 R:10.0 loss:21.9302 exploreP:0.4863\n",
      "Episode:339 meanR:16.0700 R:14.0 loss:22.1592 exploreP:0.4856\n",
      "Episode:340 meanR:16.2400 R:33.0 loss:20.5010 exploreP:0.4840\n",
      "Episode:341 meanR:16.1400 R:9.0 loss:18.7701 exploreP:0.4836\n",
      "Episode:342 meanR:16.1100 R:15.0 loss:19.2138 exploreP:0.4829\n",
      "Episode:343 meanR:16.0300 R:17.0 loss:19.1585 exploreP:0.4821\n",
      "Episode:344 meanR:15.8700 R:9.0 loss:18.6802 exploreP:0.4817\n",
      "Episode:345 meanR:15.6400 R:11.0 loss:18.5439 exploreP:0.4812\n",
      "Episode:346 meanR:15.5900 R:16.0 loss:17.4184 exploreP:0.4804\n",
      "Episode:347 meanR:15.6300 R:26.0 loss:15.4721 exploreP:0.4792\n",
      "Episode:348 meanR:15.6600 R:24.0 loss:15.6947 exploreP:0.4781\n",
      "Episode:349 meanR:15.7400 R:23.0 loss:14.9514 exploreP:0.4770\n",
      "Episode:350 meanR:15.8900 R:26.0 loss:13.9026 exploreP:0.4758\n",
      "Episode:351 meanR:16.0200 R:27.0 loss:11.9221 exploreP:0.4745\n",
      "Episode:352 meanR:16.0300 R:16.0 loss:11.4422 exploreP:0.4738\n",
      "Episode:353 meanR:16.1100 R:18.0 loss:12.5876 exploreP:0.4729\n",
      "Episode:354 meanR:16.1000 R:13.0 loss:13.3784 exploreP:0.4723\n",
      "Episode:355 meanR:16.0900 R:11.0 loss:14.3573 exploreP:0.4718\n",
      "Episode:356 meanR:16.1200 R:12.0 loss:15.3957 exploreP:0.4713\n",
      "Episode:357 meanR:16.1400 R:12.0 loss:16.2392 exploreP:0.4707\n",
      "Episode:358 meanR:16.1700 R:19.0 loss:17.1959 exploreP:0.4699\n",
      "Episode:359 meanR:16.1500 R:10.0 loss:17.4900 exploreP:0.4694\n",
      "Episode:360 meanR:16.1700 R:13.0 loss:18.9787 exploreP:0.4688\n",
      "Episode:361 meanR:16.1300 R:15.0 loss:19.2301 exploreP:0.4681\n",
      "Episode:362 meanR:16.1100 R:13.0 loss:19.6138 exploreP:0.4675\n",
      "Episode:363 meanR:16.0500 R:12.0 loss:20.3358 exploreP:0.4670\n",
      "Episode:364 meanR:16.0800 R:17.0 loss:19.7496 exploreP:0.4662\n",
      "Episode:365 meanR:16.0600 R:16.0 loss:19.1770 exploreP:0.4655\n",
      "Episode:366 meanR:16.0900 R:18.0 loss:18.3522 exploreP:0.4646\n",
      "Episode:367 meanR:16.1800 R:20.0 loss:18.1922 exploreP:0.4637\n",
      "Episode:368 meanR:16.1600 R:16.0 loss:17.5404 exploreP:0.4630\n",
      "Episode:369 meanR:16.1700 R:10.0 loss:17.2185 exploreP:0.4626\n",
      "Episode:370 meanR:16.2300 R:15.0 loss:17.1547 exploreP:0.4619\n",
      "Episode:371 meanR:16.2200 R:14.0 loss:16.5591 exploreP:0.4612\n",
      "Episode:372 meanR:16.3700 R:30.0 loss:15.1782 exploreP:0.4599\n",
      "Episode:373 meanR:16.5800 R:36.0 loss:13.5708 exploreP:0.4583\n",
      "Episode:374 meanR:16.7700 R:31.0 loss:12.2114 exploreP:0.4569\n",
      "Episode:375 meanR:16.6300 R:25.0 loss:10.3523 exploreP:0.4558\n",
      "Episode:376 meanR:16.6800 R:26.0 loss:9.6664 exploreP:0.4546\n",
      "Episode:377 meanR:16.6000 R:18.0 loss:10.5591 exploreP:0.4538\n",
      "Episode:378 meanR:16.8700 R:52.0 loss:10.7288 exploreP:0.4515\n",
      "Episode:379 meanR:16.8400 R:12.0 loss:11.0766 exploreP:0.4510\n",
      "Episode:380 meanR:16.7500 R:17.0 loss:11.9876 exploreP:0.4502\n",
      "Episode:381 meanR:16.6600 R:18.0 loss:12.4165 exploreP:0.4494\n",
      "Episode:382 meanR:16.7400 R:22.0 loss:13.1729 exploreP:0.4485\n",
      "Episode:383 meanR:17.0000 R:40.0 loss:12.7051 exploreP:0.4467\n",
      "Episode:384 meanR:17.0200 R:12.0 loss:14.6211 exploreP:0.4462\n",
      "Episode:385 meanR:17.2300 R:31.0 loss:14.2855 exploreP:0.4449\n",
      "Episode:386 meanR:17.3100 R:19.0 loss:13.0350 exploreP:0.4440\n",
      "Episode:387 meanR:17.4900 R:37.0 loss:12.0555 exploreP:0.4424\n",
      "Episode:388 meanR:17.5400 R:18.0 loss:12.6303 exploreP:0.4416\n",
      "Episode:389 meanR:17.6900 R:35.0 loss:12.6924 exploreP:0.4401\n",
      "Episode:390 meanR:17.5800 R:17.0 loss:12.9898 exploreP:0.4394\n",
      "Episode:391 meanR:17.6200 R:17.0 loss:13.4637 exploreP:0.4387\n",
      "Episode:392 meanR:17.6200 R:15.0 loss:14.0542 exploreP:0.4380\n",
      "Episode:393 meanR:17.7200 R:21.0 loss:15.8161 exploreP:0.4371\n",
      "Episode:394 meanR:17.7600 R:15.0 loss:16.7871 exploreP:0.4365\n",
      "Episode:395 meanR:17.7100 R:12.0 loss:17.6053 exploreP:0.4360\n",
      "Episode:396 meanR:17.6800 R:12.0 loss:18.2100 exploreP:0.4355\n",
      "Episode:397 meanR:17.5700 R:11.0 loss:20.4579 exploreP:0.4350\n",
      "Episode:398 meanR:17.5800 R:14.0 loss:21.5514 exploreP:0.4344\n",
      "Episode:399 meanR:17.5300 R:12.0 loss:22.1084 exploreP:0.4339\n",
      "Episode:400 meanR:17.5000 R:9.0 loss:22.2560 exploreP:0.4335\n",
      "Episode:401 meanR:17.5400 R:16.0 loss:22.8082 exploreP:0.4328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:402 meanR:17.4900 R:10.0 loss:23.0497 exploreP:0.4324\n",
      "Episode:403 meanR:17.4600 R:11.0 loss:23.6121 exploreP:0.4320\n",
      "Episode:404 meanR:17.3400 R:9.0 loss:24.7235 exploreP:0.4316\n",
      "Episode:405 meanR:17.2900 R:12.0 loss:24.8663 exploreP:0.4311\n",
      "Episode:406 meanR:17.1600 R:10.0 loss:24.7697 exploreP:0.4307\n",
      "Episode:407 meanR:17.1400 R:11.0 loss:24.7513 exploreP:0.4302\n",
      "Episode:408 meanR:17.2200 R:19.0 loss:23.6844 exploreP:0.4294\n",
      "Episode:409 meanR:17.1700 R:10.0 loss:23.2299 exploreP:0.4290\n",
      "Episode:410 meanR:17.2600 R:22.0 loss:21.7727 exploreP:0.4281\n",
      "Episode:411 meanR:17.2700 R:13.0 loss:20.4852 exploreP:0.4275\n",
      "Episode:412 meanR:17.2900 R:17.0 loss:19.7990 exploreP:0.4268\n",
      "Episode:413 meanR:17.3000 R:15.0 loss:18.9936 exploreP:0.4262\n",
      "Episode:414 meanR:17.3300 R:14.0 loss:18.1955 exploreP:0.4256\n",
      "Episode:415 meanR:17.3600 R:15.0 loss:17.5665 exploreP:0.4250\n",
      "Episode:416 meanR:17.4400 R:20.0 loss:17.0331 exploreP:0.4241\n",
      "Episode:417 meanR:17.4800 R:16.0 loss:16.4646 exploreP:0.4235\n",
      "Episode:418 meanR:17.5300 R:21.0 loss:16.3740 exploreP:0.4226\n",
      "Episode:419 meanR:17.5600 R:18.0 loss:16.0714 exploreP:0.4219\n",
      "Episode:420 meanR:17.5200 R:11.0 loss:16.5136 exploreP:0.4214\n",
      "Episode:421 meanR:17.4500 R:12.0 loss:16.7170 exploreP:0.4209\n",
      "Episode:422 meanR:17.2000 R:11.0 loss:16.7925 exploreP:0.4205\n",
      "Episode:423 meanR:17.1100 R:14.0 loss:16.9097 exploreP:0.4199\n",
      "Episode:424 meanR:17.0600 R:13.0 loss:16.9187 exploreP:0.4194\n",
      "Episode:425 meanR:17.0400 R:14.0 loss:17.5587 exploreP:0.4188\n",
      "Episode:426 meanR:16.9500 R:13.0 loss:17.6905 exploreP:0.4183\n",
      "Episode:427 meanR:16.9100 R:10.0 loss:17.7504 exploreP:0.4179\n",
      "Episode:428 meanR:16.9100 R:15.0 loss:18.8008 exploreP:0.4172\n",
      "Episode:429 meanR:16.8700 R:8.0 loss:18.9501 exploreP:0.4169\n",
      "Episode:430 meanR:16.8500 R:15.0 loss:19.6785 exploreP:0.4163\n",
      "Episode:431 meanR:16.8600 R:14.0 loss:19.0499 exploreP:0.4157\n",
      "Episode:432 meanR:16.9700 R:19.0 loss:18.0850 exploreP:0.4150\n",
      "Episode:433 meanR:16.8400 R:9.0 loss:18.1447 exploreP:0.4146\n",
      "Episode:434 meanR:16.8800 R:15.0 loss:17.8417 exploreP:0.4140\n",
      "Episode:435 meanR:16.9400 R:17.0 loss:17.3204 exploreP:0.4133\n",
      "Episode:436 meanR:16.9800 R:15.0 loss:16.7805 exploreP:0.4127\n",
      "Episode:437 meanR:17.0100 R:13.0 loss:16.2028 exploreP:0.4122\n",
      "Episode:438 meanR:17.0400 R:13.0 loss:16.2946 exploreP:0.4117\n",
      "Episode:439 meanR:17.0400 R:14.0 loss:16.1010 exploreP:0.4111\n",
      "Episode:440 meanR:16.8400 R:13.0 loss:16.1651 exploreP:0.4106\n",
      "Episode:441 meanR:16.9400 R:19.0 loss:16.0990 exploreP:0.4098\n",
      "Episode:442 meanR:16.9700 R:18.0 loss:15.4218 exploreP:0.4091\n",
      "Episode:443 meanR:16.9700 R:17.0 loss:15.0224 exploreP:0.4084\n",
      "Episode:444 meanR:17.0300 R:15.0 loss:14.9497 exploreP:0.4078\n",
      "Episode:445 meanR:17.1000 R:18.0 loss:14.7325 exploreP:0.4071\n",
      "Episode:446 meanR:17.1200 R:18.0 loss:13.8337 exploreP:0.4064\n",
      "Episode:447 meanR:17.1300 R:27.0 loss:13.1776 exploreP:0.4053\n",
      "Episode:448 meanR:17.0500 R:16.0 loss:13.2683 exploreP:0.4047\n",
      "Episode:449 meanR:16.9700 R:15.0 loss:13.5420 exploreP:0.4041\n",
      "Episode:450 meanR:16.8300 R:12.0 loss:13.9198 exploreP:0.4036\n",
      "Episode:451 meanR:16.6900 R:13.0 loss:14.5520 exploreP:0.4031\n",
      "Episode:452 meanR:16.6600 R:13.0 loss:14.8477 exploreP:0.4026\n",
      "Episode:453 meanR:16.6400 R:16.0 loss:15.1112 exploreP:0.4020\n",
      "Episode:454 meanR:16.6900 R:18.0 loss:15.1178 exploreP:0.4013\n",
      "Episode:455 meanR:16.7200 R:14.0 loss:15.3915 exploreP:0.4007\n",
      "Episode:456 meanR:16.7300 R:13.0 loss:16.2184 exploreP:0.4002\n",
      "Episode:457 meanR:16.8200 R:21.0 loss:15.4532 exploreP:0.3994\n",
      "Episode:458 meanR:16.7400 R:11.0 loss:15.4723 exploreP:0.3990\n",
      "Episode:459 meanR:16.8700 R:23.0 loss:14.6805 exploreP:0.3981\n",
      "Episode:460 meanR:16.9100 R:17.0 loss:13.4335 exploreP:0.3974\n",
      "Episode:461 meanR:17.0200 R:26.0 loss:12.6839 exploreP:0.3964\n",
      "Episode:462 meanR:17.2200 R:33.0 loss:11.3116 exploreP:0.3951\n",
      "Episode:463 meanR:17.6300 R:53.0 loss:9.3899 exploreP:0.3931\n",
      "Episode:464 meanR:17.7500 R:29.0 loss:7.9413 exploreP:0.3920\n",
      "Episode:465 meanR:17.8200 R:23.0 loss:8.3906 exploreP:0.3911\n",
      "Episode:466 meanR:17.8000 R:16.0 loss:9.4265 exploreP:0.3905\n",
      "Episode:467 meanR:17.7900 R:19.0 loss:8.4296 exploreP:0.3898\n",
      "Episode:468 meanR:17.9500 R:32.0 loss:12.2487 exploreP:0.3886\n",
      "Episode:469 meanR:18.2500 R:40.0 loss:7.6827 exploreP:0.3871\n",
      "Episode:470 meanR:18.4000 R:30.0 loss:5.2602 exploreP:0.3859\n",
      "Episode:471 meanR:18.4100 R:15.0 loss:3.5067 exploreP:0.3854\n",
      "Episode:472 meanR:18.9500 R:84.0 loss:4.6841 exploreP:0.3822\n",
      "Episode:473 meanR:19.2500 R:66.0 loss:5.0426 exploreP:0.3798\n",
      "Episode:474 meanR:20.2500 R:131.0 loss:2.7673 exploreP:0.3750\n",
      "Episode:475 meanR:20.9400 R:94.0 loss:3.6489 exploreP:0.3716\n",
      "Episode:476 meanR:21.2000 R:52.0 loss:5.3312 exploreP:0.3697\n",
      "Episode:477 meanR:21.7100 R:69.0 loss:6.6381 exploreP:0.3672\n",
      "Episode:478 meanR:21.6900 R:50.0 loss:8.6274 exploreP:0.3654\n",
      "Episode:479 meanR:21.8400 R:27.0 loss:9.3815 exploreP:0.3645\n",
      "Episode:480 meanR:22.2000 R:53.0 loss:11.4207 exploreP:0.3626\n",
      "Episode:481 meanR:22.3100 R:29.0 loss:11.4208 exploreP:0.3616\n",
      "Episode:482 meanR:22.4100 R:32.0 loss:13.4175 exploreP:0.3604\n",
      "Episode:483 meanR:22.3600 R:35.0 loss:12.7736 exploreP:0.3592\n",
      "Episode:484 meanR:22.5200 R:28.0 loss:15.0472 exploreP:0.3582\n",
      "Episode:485 meanR:22.4200 R:21.0 loss:15.7329 exploreP:0.3575\n",
      "Episode:486 meanR:22.4200 R:19.0 loss:17.3105 exploreP:0.3569\n",
      "Episode:487 meanR:22.2400 R:19.0 loss:18.4906 exploreP:0.3562\n",
      "Episode:488 meanR:22.2300 R:17.0 loss:19.8012 exploreP:0.3556\n",
      "Episode:489 meanR:22.1000 R:22.0 loss:21.8133 exploreP:0.3548\n",
      "Episode:490 meanR:22.1500 R:22.0 loss:21.9200 exploreP:0.3541\n",
      "Episode:491 meanR:22.1300 R:15.0 loss:23.3259 exploreP:0.3536\n",
      "Episode:492 meanR:22.1100 R:13.0 loss:24.6141 exploreP:0.3531\n",
      "Episode:493 meanR:22.0100 R:11.0 loss:24.7009 exploreP:0.3528\n",
      "Episode:494 meanR:21.9800 R:12.0 loss:26.6397 exploreP:0.3523\n",
      "Episode:495 meanR:22.0000 R:14.0 loss:27.1656 exploreP:0.3519\n",
      "Episode:496 meanR:22.0000 R:12.0 loss:27.1391 exploreP:0.3515\n",
      "Episode:497 meanR:22.0500 R:16.0 loss:27.7470 exploreP:0.3509\n",
      "Episode:498 meanR:22.0100 R:10.0 loss:29.2167 exploreP:0.3506\n",
      "Episode:499 meanR:22.0300 R:14.0 loss:29.4892 exploreP:0.3501\n",
      "Episode:500 meanR:22.0700 R:13.0 loss:31.0772 exploreP:0.3496\n",
      "Episode:501 meanR:22.0200 R:11.0 loss:31.3926 exploreP:0.3493\n",
      "Episode:502 meanR:22.0100 R:9.0 loss:31.9577 exploreP:0.3490\n",
      "Episode:503 meanR:22.1000 R:20.0 loss:31.4576 exploreP:0.3483\n",
      "Episode:504 meanR:22.0900 R:8.0 loss:30.6545 exploreP:0.3480\n",
      "Episode:505 meanR:22.0700 R:10.0 loss:30.2681 exploreP:0.3477\n",
      "Episode:506 meanR:22.0700 R:10.0 loss:30.8171 exploreP:0.3473\n",
      "Episode:507 meanR:22.0900 R:13.0 loss:30.2450 exploreP:0.3469\n",
      "Episode:508 meanR:22.0700 R:17.0 loss:29.5115 exploreP:0.3463\n",
      "Episode:509 meanR:22.1100 R:14.0 loss:27.8671 exploreP:0.3459\n",
      "Episode:510 meanR:22.0500 R:16.0 loss:27.4178 exploreP:0.3453\n",
      "Episode:511 meanR:22.0900 R:17.0 loss:26.1571 exploreP:0.3448\n",
      "Episode:512 meanR:22.0800 R:16.0 loss:25.0557 exploreP:0.3442\n",
      "Episode:513 meanR:22.0800 R:15.0 loss:25.8449 exploreP:0.3437\n",
      "Episode:514 meanR:22.1100 R:17.0 loss:23.9519 exploreP:0.3432\n",
      "Episode:515 meanR:22.1600 R:20.0 loss:22.3419 exploreP:0.3425\n",
      "Episode:516 meanR:22.1100 R:15.0 loss:21.9683 exploreP:0.3420\n",
      "Episode:517 meanR:22.0700 R:12.0 loss:22.3175 exploreP:0.3416\n",
      "Episode:518 meanR:21.9800 R:12.0 loss:22.3482 exploreP:0.3412\n",
      "Episode:519 meanR:21.9400 R:14.0 loss:22.7480 exploreP:0.3407\n",
      "Episode:520 meanR:21.9800 R:15.0 loss:22.8854 exploreP:0.3402\n",
      "Episode:521 meanR:22.0400 R:18.0 loss:22.4675 exploreP:0.3396\n",
      "Episode:522 meanR:22.0900 R:16.0 loss:21.8945 exploreP:0.3391\n",
      "Episode:523 meanR:22.0600 R:11.0 loss:22.1886 exploreP:0.3388\n",
      "Episode:524 meanR:22.0500 R:12.0 loss:22.8080 exploreP:0.3384\n",
      "Episode:525 meanR:22.0500 R:14.0 loss:23.1398 exploreP:0.3379\n",
      "Episode:526 meanR:22.0400 R:12.0 loss:23.0676 exploreP:0.3375\n",
      "Episode:527 meanR:22.0400 R:10.0 loss:23.0238 exploreP:0.3372\n",
      "Episode:528 meanR:22.0600 R:17.0 loss:22.6489 exploreP:0.3366\n",
      "Episode:529 meanR:22.1200 R:14.0 loss:22.0772 exploreP:0.3362\n",
      "Episode:530 meanR:22.1100 R:14.0 loss:21.9176 exploreP:0.3357\n",
      "Episode:531 meanR:22.1000 R:13.0 loss:22.3929 exploreP:0.3353\n",
      "Episode:532 meanR:22.0600 R:15.0 loss:22.3941 exploreP:0.3348\n",
      "Episode:533 meanR:22.1900 R:22.0 loss:21.1825 exploreP:0.3341\n",
      "Episode:534 meanR:22.1600 R:12.0 loss:20.5988 exploreP:0.3337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:535 meanR:22.0900 R:10.0 loss:20.7216 exploreP:0.3334\n",
      "Episode:536 meanR:22.1000 R:16.0 loss:20.0621 exploreP:0.3329\n",
      "Episode:537 meanR:22.0700 R:10.0 loss:20.3980 exploreP:0.3325\n",
      "Episode:538 meanR:22.0600 R:12.0 loss:20.5909 exploreP:0.3321\n",
      "Episode:539 meanR:22.0300 R:11.0 loss:20.7945 exploreP:0.3318\n",
      "Episode:540 meanR:22.0100 R:11.0 loss:21.2172 exploreP:0.3314\n",
      "Episode:541 meanR:21.9200 R:10.0 loss:21.4794 exploreP:0.3311\n",
      "Episode:542 meanR:21.8300 R:9.0 loss:21.6287 exploreP:0.3308\n",
      "Episode:543 meanR:21.7600 R:10.0 loss:22.1565 exploreP:0.3305\n",
      "Episode:544 meanR:21.7200 R:11.0 loss:22.4672 exploreP:0.3302\n",
      "Episode:545 meanR:21.6600 R:12.0 loss:23.0261 exploreP:0.3298\n",
      "Episode:546 meanR:21.5900 R:11.0 loss:22.7693 exploreP:0.3294\n",
      "Episode:547 meanR:21.4900 R:17.0 loss:21.9358 exploreP:0.3289\n",
      "Episode:548 meanR:21.4200 R:9.0 loss:21.7585 exploreP:0.3286\n",
      "Episode:549 meanR:21.3700 R:10.0 loss:21.4925 exploreP:0.3283\n",
      "Episode:550 meanR:21.3800 R:13.0 loss:21.1574 exploreP:0.3279\n",
      "Episode:551 meanR:21.4200 R:17.0 loss:20.3728 exploreP:0.3273\n",
      "Episode:552 meanR:21.4100 R:12.0 loss:19.3629 exploreP:0.3269\n",
      "Episode:553 meanR:21.3800 R:13.0 loss:18.7597 exploreP:0.3265\n",
      "Episode:554 meanR:21.3200 R:12.0 loss:18.4511 exploreP:0.3261\n",
      "Episode:555 meanR:21.2900 R:11.0 loss:18.3238 exploreP:0.3258\n",
      "Episode:556 meanR:21.3000 R:14.0 loss:18.3432 exploreP:0.3254\n",
      "Episode:557 meanR:21.2400 R:15.0 loss:18.0598 exploreP:0.3249\n",
      "Episode:558 meanR:21.2800 R:15.0 loss:17.6108 exploreP:0.3244\n",
      "Episode:559 meanR:21.1800 R:13.0 loss:16.9590 exploreP:0.3240\n",
      "Episode:560 meanR:21.1500 R:14.0 loss:16.7456 exploreP:0.3236\n",
      "Episode:561 meanR:21.0000 R:11.0 loss:17.1676 exploreP:0.3232\n",
      "Episode:562 meanR:20.8000 R:13.0 loss:17.0017 exploreP:0.3228\n",
      "Episode:563 meanR:20.4100 R:14.0 loss:16.8021 exploreP:0.3224\n",
      "Episode:564 meanR:20.3100 R:19.0 loss:16.1224 exploreP:0.3218\n",
      "Episode:565 meanR:20.1900 R:11.0 loss:15.3757 exploreP:0.3214\n",
      "Episode:566 meanR:20.1600 R:13.0 loss:15.5857 exploreP:0.3210\n",
      "Episode:567 meanR:20.0700 R:10.0 loss:15.8523 exploreP:0.3207\n",
      "Episode:568 meanR:19.8500 R:10.0 loss:16.3304 exploreP:0.3204\n",
      "Episode:569 meanR:19.5500 R:10.0 loss:16.2069 exploreP:0.3201\n",
      "Episode:570 meanR:19.3500 R:10.0 loss:16.5017 exploreP:0.3198\n",
      "Episode:571 meanR:19.3100 R:11.0 loss:16.8724 exploreP:0.3195\n",
      "Episode:572 meanR:18.5900 R:12.0 loss:16.6434 exploreP:0.3191\n",
      "Episode:573 meanR:18.0300 R:10.0 loss:16.6963 exploreP:0.3188\n",
      "Episode:574 meanR:16.8200 R:10.0 loss:16.6915 exploreP:0.3185\n",
      "Episode:575 meanR:15.9700 R:9.0 loss:16.6892 exploreP:0.3182\n",
      "Episode:576 meanR:15.5700 R:12.0 loss:17.2949 exploreP:0.3178\n",
      "Episode:577 meanR:14.9800 R:10.0 loss:17.1323 exploreP:0.3175\n",
      "Episode:578 meanR:14.6400 R:16.0 loss:16.5664 exploreP:0.3170\n",
      "Episode:579 meanR:14.4800 R:11.0 loss:16.0477 exploreP:0.3167\n",
      "Episode:580 meanR:14.1500 R:20.0 loss:15.1825 exploreP:0.3161\n",
      "Episode:581 meanR:14.0100 R:15.0 loss:14.3858 exploreP:0.3156\n",
      "Episode:582 meanR:13.8900 R:20.0 loss:13.9191 exploreP:0.3150\n",
      "Episode:583 meanR:13.7100 R:17.0 loss:13.4120 exploreP:0.3145\n",
      "Episode:584 meanR:13.5900 R:16.0 loss:12.7581 exploreP:0.3140\n",
      "Episode:585 meanR:13.5300 R:15.0 loss:12.7678 exploreP:0.3135\n",
      "Episode:586 meanR:13.5200 R:18.0 loss:12.5152 exploreP:0.3130\n",
      "Episode:587 meanR:13.5800 R:25.0 loss:12.4373 exploreP:0.3122\n",
      "Episode:588 meanR:13.6000 R:19.0 loss:12.1720 exploreP:0.3117\n",
      "Episode:589 meanR:13.5400 R:16.0 loss:12.0078 exploreP:0.3112\n",
      "Episode:590 meanR:13.4900 R:17.0 loss:12.1161 exploreP:0.3107\n",
      "Episode:591 meanR:13.5500 R:21.0 loss:11.7254 exploreP:0.3100\n",
      "Episode:592 meanR:13.6100 R:19.0 loss:11.1270 exploreP:0.3095\n",
      "Episode:593 meanR:13.6900 R:19.0 loss:11.1531 exploreP:0.3089\n",
      "Episode:594 meanR:13.7300 R:16.0 loss:11.4711 exploreP:0.3084\n",
      "Episode:595 meanR:13.7100 R:12.0 loss:11.7864 exploreP:0.3081\n",
      "Episode:596 meanR:13.7500 R:16.0 loss:12.3039 exploreP:0.3076\n",
      "Episode:597 meanR:13.7600 R:17.0 loss:12.0785 exploreP:0.3071\n",
      "Episode:598 meanR:13.8500 R:19.0 loss:11.9445 exploreP:0.3065\n",
      "Episode:599 meanR:13.9100 R:20.0 loss:11.9922 exploreP:0.3059\n",
      "Episode:600 meanR:13.9700 R:19.0 loss:11.9064 exploreP:0.3054\n",
      "Episode:601 meanR:14.0500 R:19.0 loss:11.6860 exploreP:0.3048\n",
      "Episode:602 meanR:14.1400 R:18.0 loss:11.1120 exploreP:0.3043\n",
      "Episode:603 meanR:14.2200 R:28.0 loss:10.0893 exploreP:0.3034\n",
      "Episode:604 meanR:14.3700 R:23.0 loss:9.6738 exploreP:0.3028\n",
      "Episode:605 meanR:14.5200 R:25.0 loss:9.6430 exploreP:0.3020\n",
      "Episode:606 meanR:14.7500 R:33.0 loss:9.5242 exploreP:0.3011\n",
      "Episode:607 meanR:14.8900 R:27.0 loss:9.1694 exploreP:0.3003\n",
      "Episode:608 meanR:15.0300 R:31.0 loss:9.3366 exploreP:0.2994\n",
      "Episode:609 meanR:15.0700 R:18.0 loss:9.6607 exploreP:0.2989\n",
      "Episode:610 meanR:15.2100 R:30.0 loss:9.6341 exploreP:0.2980\n",
      "Episode:611 meanR:15.1900 R:15.0 loss:10.4957 exploreP:0.2976\n",
      "Episode:612 meanR:15.2200 R:19.0 loss:11.3488 exploreP:0.2970\n",
      "Episode:613 meanR:15.3100 R:24.0 loss:11.7423 exploreP:0.2963\n",
      "Episode:614 meanR:15.4200 R:28.0 loss:12.0839 exploreP:0.2955\n",
      "Episode:615 meanR:15.5100 R:29.0 loss:11.4544 exploreP:0.2947\n",
      "Episode:616 meanR:15.6200 R:26.0 loss:11.7653 exploreP:0.2940\n",
      "Episode:617 meanR:15.8100 R:31.0 loss:10.3922 exploreP:0.2931\n",
      "Episode:618 meanR:15.8700 R:18.0 loss:10.5641 exploreP:0.2926\n",
      "Episode:619 meanR:15.9000 R:17.0 loss:10.9529 exploreP:0.2921\n",
      "Episode:620 meanR:16.0000 R:25.0 loss:11.5336 exploreP:0.2914\n",
      "Episode:621 meanR:15.9900 R:17.0 loss:12.2661 exploreP:0.2909\n",
      "Episode:622 meanR:16.9700 R:114.0 loss:9.0203 exploreP:0.2877\n",
      "Episode:623 meanR:17.7700 R:91.0 loss:3.7465 exploreP:0.2852\n",
      "Episode:624 meanR:18.1900 R:54.0 loss:5.0256 exploreP:0.2837\n",
      "Episode:625 meanR:18.4600 R:41.0 loss:5.7825 exploreP:0.2826\n",
      "Episode:626 meanR:19.1400 R:80.0 loss:6.1468 exploreP:0.2805\n",
      "Episode:627 meanR:19.6000 R:56.0 loss:4.5914 exploreP:0.2789\n",
      "Episode:628 meanR:20.6800 R:125.0 loss:5.8268 exploreP:0.2756\n",
      "Episode:629 meanR:22.6700 R:213.0 loss:3.1742 exploreP:0.2700\n",
      "Episode:630 meanR:24.3300 R:180.0 loss:1.8119 exploreP:0.2654\n",
      "Episode:631 meanR:29.2000 R:500.0 loss:1.7767 exploreP:0.2529\n",
      "Episode:632 meanR:29.9500 R:90.0 loss:6.5421 exploreP:0.2507\n",
      "Episode:633 meanR:30.9000 R:117.0 loss:4.7665 exploreP:0.2479\n",
      "Episode:634 meanR:31.9300 R:115.0 loss:7.1941 exploreP:0.2452\n",
      "Episode:635 meanR:32.2500 R:42.0 loss:9.1459 exploreP:0.2442\n",
      "Episode:636 meanR:32.3300 R:24.0 loss:13.9631 exploreP:0.2437\n",
      "Episode:637 meanR:32.4700 R:24.0 loss:20.6635 exploreP:0.2431\n",
      "Episode:638 meanR:32.5800 R:23.0 loss:27.2883 exploreP:0.2426\n",
      "Episode:639 meanR:32.7000 R:23.0 loss:31.3081 exploreP:0.2420\n",
      "Episode:640 meanR:32.7400 R:15.0 loss:33.6658 exploreP:0.2417\n",
      "Episode:641 meanR:32.8400 R:20.0 loss:39.1597 exploreP:0.2412\n",
      "Episode:642 meanR:32.9600 R:21.0 loss:38.5353 exploreP:0.2407\n",
      "Episode:643 meanR:33.0600 R:20.0 loss:37.1247 exploreP:0.2403\n",
      "Episode:644 meanR:33.1300 R:18.0 loss:36.8242 exploreP:0.2399\n",
      "Episode:645 meanR:33.2700 R:26.0 loss:35.7943 exploreP:0.2393\n",
      "Episode:646 meanR:33.4100 R:25.0 loss:33.2966 exploreP:0.2387\n",
      "Episode:647 meanR:34.2900 R:105.0 loss:20.7017 exploreP:0.2363\n",
      "Episode:648 meanR:35.3300 R:113.0 loss:6.4827 exploreP:0.2338\n",
      "Episode:649 meanR:35.8600 R:63.0 loss:7.8848 exploreP:0.2324\n",
      "Episode:650 meanR:36.2900 R:56.0 loss:13.9581 exploreP:0.2311\n",
      "Episode:651 meanR:36.5600 R:44.0 loss:15.5691 exploreP:0.2301\n",
      "Episode:652 meanR:36.7300 R:29.0 loss:20.4704 exploreP:0.2295\n",
      "Episode:653 meanR:36.9200 R:32.0 loss:19.5313 exploreP:0.2288\n",
      "Episode:654 meanR:37.1700 R:37.0 loss:23.3014 exploreP:0.2280\n",
      "Episode:655 meanR:37.4100 R:35.0 loss:24.4184 exploreP:0.2272\n",
      "Episode:656 meanR:37.4000 R:13.0 loss:25.4038 exploreP:0.2270\n",
      "Episode:657 meanR:37.6200 R:37.0 loss:22.1925 exploreP:0.2262\n",
      "Episode:658 meanR:37.7800 R:31.0 loss:22.0198 exploreP:0.2255\n",
      "Episode:659 meanR:37.9200 R:27.0 loss:23.1551 exploreP:0.2249\n",
      "Episode:660 meanR:38.2100 R:43.0 loss:22.3415 exploreP:0.2240\n",
      "Episode:661 meanR:38.7300 R:63.0 loss:21.1731 exploreP:0.2226\n",
      "Episode:662 meanR:39.1000 R:50.0 loss:15.8168 exploreP:0.2216\n",
      "Episode:663 meanR:40.1600 R:120.0 loss:11.8127 exploreP:0.2191\n",
      "Episode:664 meanR:40.0700 R:10.0 loss:14.1911 exploreP:0.2188\n",
      "Episode:665 meanR:40.3900 R:43.0 loss:10.6123 exploreP:0.2180\n",
      "Episode:666 meanR:40.3700 R:11.0 loss:17.9958 exploreP:0.2177\n",
      "Episode:667 meanR:40.4400 R:17.0 loss:19.3036 exploreP:0.2174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:668 meanR:40.5900 R:25.0 loss:20.3530 exploreP:0.2169\n",
      "Episode:669 meanR:40.6900 R:20.0 loss:25.8930 exploreP:0.2164\n",
      "Episode:670 meanR:40.8100 R:22.0 loss:24.8430 exploreP:0.2160\n",
      "Episode:671 meanR:40.9000 R:20.0 loss:29.2047 exploreP:0.2156\n",
      "Episode:672 meanR:40.9800 R:20.0 loss:32.0448 exploreP:0.2152\n",
      "Episode:673 meanR:41.0300 R:15.0 loss:32.6576 exploreP:0.2149\n",
      "Episode:674 meanR:41.1100 R:18.0 loss:37.6643 exploreP:0.2145\n",
      "Episode:675 meanR:41.2200 R:20.0 loss:39.8722 exploreP:0.2141\n",
      "Episode:676 meanR:41.2400 R:14.0 loss:40.6113 exploreP:0.2138\n",
      "Episode:677 meanR:41.3300 R:19.0 loss:39.9932 exploreP:0.2134\n",
      "Episode:678 meanR:41.3500 R:18.0 loss:39.6812 exploreP:0.2130\n",
      "Episode:679 meanR:41.4600 R:22.0 loss:39.0914 exploreP:0.2126\n",
      "Episode:680 meanR:41.4400 R:18.0 loss:37.5114 exploreP:0.2122\n",
      "Episode:681 meanR:41.5000 R:21.0 loss:35.5654 exploreP:0.2118\n",
      "Episode:682 meanR:41.5000 R:20.0 loss:34.6045 exploreP:0.2114\n",
      "Episode:683 meanR:41.5500 R:22.0 loss:32.4144 exploreP:0.2110\n",
      "Episode:684 meanR:41.6300 R:24.0 loss:30.9859 exploreP:0.2105\n",
      "Episode:685 meanR:41.6600 R:18.0 loss:29.4902 exploreP:0.2101\n",
      "Episode:686 meanR:41.6900 R:21.0 loss:29.9831 exploreP:0.2097\n",
      "Episode:687 meanR:41.7200 R:28.0 loss:27.9634 exploreP:0.2091\n",
      "Episode:688 meanR:41.7300 R:20.0 loss:27.3337 exploreP:0.2087\n",
      "Episode:689 meanR:41.8600 R:29.0 loss:26.2951 exploreP:0.2082\n",
      "Episode:690 meanR:41.9000 R:21.0 loss:26.0861 exploreP:0.2078\n",
      "Episode:691 meanR:41.9800 R:29.0 loss:24.5200 exploreP:0.2072\n",
      "Episode:692 meanR:41.9800 R:19.0 loss:23.1768 exploreP:0.2068\n",
      "Episode:693 meanR:42.0400 R:25.0 loss:24.4028 exploreP:0.2063\n",
      "Episode:694 meanR:42.1100 R:23.0 loss:23.3896 exploreP:0.2059\n",
      "Episode:695 meanR:42.1100 R:12.0 loss:26.3578 exploreP:0.2056\n",
      "Episode:696 meanR:42.1100 R:16.0 loss:26.5557 exploreP:0.2053\n",
      "Episode:697 meanR:42.0600 R:12.0 loss:27.7120 exploreP:0.2051\n",
      "Episode:698 meanR:41.9900 R:12.0 loss:30.2599 exploreP:0.2048\n",
      "Episode:699 meanR:41.9000 R:11.0 loss:33.1795 exploreP:0.2046\n",
      "Episode:700 meanR:41.9200 R:21.0 loss:33.0387 exploreP:0.2042\n",
      "Episode:701 meanR:41.8300 R:10.0 loss:33.6209 exploreP:0.2040\n",
      "Episode:702 meanR:41.7600 R:11.0 loss:36.8952 exploreP:0.2038\n",
      "Episode:703 meanR:41.5800 R:10.0 loss:36.7384 exploreP:0.2036\n",
      "Episode:704 meanR:41.4400 R:9.0 loss:40.0017 exploreP:0.2034\n",
      "Episode:705 meanR:41.2700 R:8.0 loss:41.1909 exploreP:0.2033\n",
      "Episode:706 meanR:41.0600 R:12.0 loss:41.0777 exploreP:0.2031\n",
      "Episode:707 meanR:40.8900 R:10.0 loss:41.6398 exploreP:0.2029\n",
      "Episode:708 meanR:40.6900 R:11.0 loss:41.2089 exploreP:0.2027\n",
      "Episode:709 meanR:40.6000 R:9.0 loss:40.9140 exploreP:0.2025\n",
      "Episode:710 meanR:40.3900 R:9.0 loss:41.3119 exploreP:0.2023\n",
      "Episode:711 meanR:40.3400 R:10.0 loss:40.9144 exploreP:0.2021\n",
      "Episode:712 meanR:40.2500 R:10.0 loss:40.7423 exploreP:0.2019\n",
      "Episode:713 meanR:40.1800 R:17.0 loss:41.0267 exploreP:0.2016\n",
      "Episode:714 meanR:40.1900 R:29.0 loss:36.0680 exploreP:0.2010\n",
      "Episode:715 meanR:40.4300 R:53.0 loss:25.6465 exploreP:0.2000\n",
      "Episode:716 meanR:40.4500 R:28.0 loss:16.5232 exploreP:0.1995\n",
      "Episode:717 meanR:40.4200 R:28.0 loss:13.3443 exploreP:0.1990\n",
      "Episode:718 meanR:40.4900 R:25.0 loss:14.2277 exploreP:0.1985\n",
      "Episode:719 meanR:40.7100 R:39.0 loss:15.2134 exploreP:0.1978\n",
      "Episode:720 meanR:40.8200 R:36.0 loss:15.9309 exploreP:0.1971\n",
      "Episode:721 meanR:40.9300 R:28.0 loss:15.2492 exploreP:0.1966\n",
      "Episode:722 meanR:40.0500 R:26.0 loss:15.0783 exploreP:0.1961\n",
      "Episode:723 meanR:39.3600 R:22.0 loss:15.1939 exploreP:0.1957\n",
      "Episode:724 meanR:39.7300 R:91.0 loss:13.5556 exploreP:0.1940\n",
      "Episode:725 meanR:40.3100 R:99.0 loss:6.2161 exploreP:0.1922\n",
      "Episode:726 meanR:40.8400 R:133.0 loss:5.3159 exploreP:0.1898\n",
      "Episode:727 meanR:40.8400 R:56.0 loss:5.6900 exploreP:0.1888\n",
      "Episode:728 meanR:40.2200 R:63.0 loss:10.8863 exploreP:0.1876\n",
      "Episode:729 meanR:38.9900 R:90.0 loss:10.0062 exploreP:0.1861\n",
      "Episode:730 meanR:37.7200 R:53.0 loss:9.1958 exploreP:0.1851\n",
      "Episode:731 meanR:33.0900 R:37.0 loss:11.5968 exploreP:0.1845\n",
      "Episode:732 meanR:32.4500 R:26.0 loss:17.2079 exploreP:0.1840\n",
      "Episode:733 meanR:31.5400 R:26.0 loss:18.9613 exploreP:0.1836\n",
      "Episode:734 meanR:30.6400 R:25.0 loss:21.7719 exploreP:0.1831\n",
      "Episode:735 meanR:31.0400 R:82.0 loss:18.5255 exploreP:0.1817\n",
      "Episode:736 meanR:31.0300 R:23.0 loss:15.0953 exploreP:0.1813\n",
      "Episode:737 meanR:31.0300 R:24.0 loss:15.6390 exploreP:0.1809\n",
      "Episode:738 meanR:31.1600 R:36.0 loss:15.7739 exploreP:0.1803\n",
      "Episode:739 meanR:31.1700 R:24.0 loss:19.5041 exploreP:0.1799\n",
      "Episode:740 meanR:32.1800 R:116.0 loss:13.7435 exploreP:0.1779\n",
      "Episode:741 meanR:36.0800 R:410.0 loss:2.1282 exploreP:0.1712\n",
      "Episode:742 meanR:36.3300 R:46.0 loss:6.6734 exploreP:0.1705\n",
      "Episode:743 meanR:36.5400 R:41.0 loss:12.9281 exploreP:0.1698\n",
      "Episode:744 meanR:37.5600 R:120.0 loss:13.3584 exploreP:0.1679\n",
      "Episode:745 meanR:38.8900 R:159.0 loss:5.8320 exploreP:0.1654\n",
      "Episode:746 meanR:39.7100 R:107.0 loss:6.3809 exploreP:0.1637\n",
      "Episode:747 meanR:39.0100 R:35.0 loss:8.7444 exploreP:0.1632\n",
      "Episode:748 meanR:38.1500 R:27.0 loss:13.1389 exploreP:0.1628\n",
      "Episode:749 meanR:38.4700 R:95.0 loss:11.8499 exploreP:0.1614\n",
      "Episode:750 meanR:38.1000 R:19.0 loss:14.6124 exploreP:0.1611\n",
      "Episode:751 meanR:37.8200 R:16.0 loss:18.8648 exploreP:0.1608\n",
      "Episode:752 meanR:37.7200 R:19.0 loss:23.3427 exploreP:0.1605\n",
      "Episode:753 meanR:37.8400 R:44.0 loss:25.2035 exploreP:0.1599\n",
      "Episode:754 meanR:38.5500 R:108.0 loss:20.0934 exploreP:0.1583\n",
      "Episode:755 meanR:39.4200 R:122.0 loss:2.8092 exploreP:0.1565\n",
      "Episode:756 meanR:39.7400 R:45.0 loss:10.1501 exploreP:0.1558\n",
      "Episode:757 meanR:39.6700 R:30.0 loss:19.0699 exploreP:0.1554\n",
      "Episode:758 meanR:39.6800 R:32.0 loss:27.2426 exploreP:0.1549\n",
      "Episode:759 meanR:40.4600 R:105.0 loss:20.8325 exploreP:0.1534\n",
      "Episode:760 meanR:41.2600 R:123.0 loss:4.3055 exploreP:0.1516\n",
      "Episode:761 meanR:41.4400 R:81.0 loss:6.8711 exploreP:0.1505\n",
      "Episode:762 meanR:41.5800 R:64.0 loss:13.2951 exploreP:0.1496\n",
      "Episode:763 meanR:43.4900 R:311.0 loss:5.2744 exploreP:0.1453\n",
      "Episode:764 meanR:44.5000 R:111.0 loss:106.7041 exploreP:0.1438\n",
      "Episode:765 meanR:45.0700 R:100.0 loss:36.9106 exploreP:0.1425\n",
      "Episode:766 meanR:45.6400 R:68.0 loss:6.5965 exploreP:0.1416\n",
      "Episode:767 meanR:46.0900 R:62.0 loss:9.0873 exploreP:0.1408\n",
      "Episode:768 meanR:46.1100 R:27.0 loss:176.0643 exploreP:0.1404\n",
      "Episode:769 meanR:46.1600 R:25.0 loss:222.1904 exploreP:0.1401\n",
      "Episode:770 meanR:46.1900 R:25.0 loss:164.8197 exploreP:0.1398\n",
      "Episode:771 meanR:46.1900 R:20.0 loss:131.8853 exploreP:0.1395\n",
      "Episode:772 meanR:46.2400 R:25.0 loss:160.0163 exploreP:0.1392\n",
      "Episode:773 meanR:46.2700 R:18.0 loss:123.6522 exploreP:0.1390\n",
      "Episode:774 meanR:46.5600 R:47.0 loss:44.3777 exploreP:0.1384\n",
      "Episode:775 meanR:46.6200 R:26.0 loss:36.1521 exploreP:0.1380\n",
      "Episode:776 meanR:46.7400 R:26.0 loss:31.5643 exploreP:0.1377\n",
      "Episode:777 meanR:46.7400 R:19.0 loss:30.6595 exploreP:0.1375\n",
      "Episode:778 meanR:46.8300 R:27.0 loss:27.2543 exploreP:0.1371\n",
      "Episode:779 meanR:46.8600 R:25.0 loss:29.6891 exploreP:0.1368\n",
      "Episode:780 meanR:46.8500 R:17.0 loss:31.6461 exploreP:0.1366\n",
      "Episode:781 meanR:46.8300 R:19.0 loss:33.8195 exploreP:0.1363\n",
      "Episode:782 meanR:46.8300 R:20.0 loss:34.5050 exploreP:0.1361\n",
      "Episode:783 meanR:46.7800 R:17.0 loss:33.1848 exploreP:0.1359\n",
      "Episode:784 meanR:46.7100 R:17.0 loss:34.0466 exploreP:0.1357\n",
      "Episode:785 meanR:46.6600 R:13.0 loss:37.0521 exploreP:0.1355\n",
      "Episode:786 meanR:46.5900 R:14.0 loss:36.3430 exploreP:0.1353\n",
      "Episode:787 meanR:46.4600 R:15.0 loss:38.0306 exploreP:0.1351\n",
      "Episode:788 meanR:46.4000 R:14.0 loss:37.8106 exploreP:0.1350\n",
      "Episode:789 meanR:46.2500 R:14.0 loss:37.4943 exploreP:0.1348\n",
      "Episode:790 meanR:46.1500 R:11.0 loss:38.4071 exploreP:0.1346\n",
      "Episode:791 meanR:46.0100 R:15.0 loss:38.5565 exploreP:0.1345\n",
      "Episode:792 meanR:45.9400 R:12.0 loss:37.7442 exploreP:0.1343\n",
      "Episode:793 meanR:45.8000 R:11.0 loss:36.7186 exploreP:0.1342\n",
      "Episode:794 meanR:45.6700 R:10.0 loss:36.8927 exploreP:0.1341\n",
      "Episode:795 meanR:45.6700 R:12.0 loss:35.2535 exploreP:0.1339\n",
      "Episode:796 meanR:45.6200 R:11.0 loss:33.9474 exploreP:0.1338\n",
      "Episode:797 meanR:45.6000 R:10.0 loss:34.0219 exploreP:0.1336\n",
      "Episode:798 meanR:45.6000 R:12.0 loss:33.0586 exploreP:0.1335\n",
      "Episode:799 meanR:45.5900 R:10.0 loss:31.3194 exploreP:0.1334\n",
      "Episode:800 meanR:45.4600 R:8.0 loss:28.9775 exploreP:0.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:801 meanR:45.4600 R:10.0 loss:27.3338 exploreP:0.1332\n",
      "Episode:802 meanR:45.4600 R:11.0 loss:23.7661 exploreP:0.1330\n",
      "Episode:803 meanR:45.4600 R:10.0 loss:20.4787 exploreP:0.1329\n",
      "Episode:804 meanR:45.4900 R:12.0 loss:15.6901 exploreP:0.1327\n",
      "Episode:805 meanR:45.4900 R:8.0 loss:23.5647 exploreP:0.1326\n",
      "Episode:806 meanR:45.4600 R:9.0 loss:23.6103 exploreP:0.1325\n",
      "Episode:807 meanR:45.4800 R:12.0 loss:22.8719 exploreP:0.1324\n",
      "Episode:808 meanR:45.4900 R:12.0 loss:19.6772 exploreP:0.1322\n",
      "Episode:809 meanR:45.5200 R:12.0 loss:16.5328 exploreP:0.1321\n",
      "Episode:810 meanR:45.5300 R:10.0 loss:14.0625 exploreP:0.1320\n",
      "Episode:811 meanR:45.5600 R:13.0 loss:12.8378 exploreP:0.1318\n",
      "Episode:812 meanR:45.6000 R:14.0 loss:11.5607 exploreP:0.1316\n",
      "Episode:813 meanR:45.5700 R:14.0 loss:11.0183 exploreP:0.1315\n",
      "Episode:814 meanR:45.4300 R:15.0 loss:11.0899 exploreP:0.1313\n",
      "Episode:815 meanR:45.0700 R:17.0 loss:11.1636 exploreP:0.1311\n",
      "Episode:816 meanR:44.9400 R:15.0 loss:11.6818 exploreP:0.1309\n",
      "Episode:817 meanR:44.8000 R:14.0 loss:12.5670 exploreP:0.1307\n",
      "Episode:818 meanR:44.6700 R:12.0 loss:13.1973 exploreP:0.1306\n",
      "Episode:819 meanR:44.4300 R:15.0 loss:13.3866 exploreP:0.1304\n",
      "Episode:820 meanR:44.2700 R:20.0 loss:12.8822 exploreP:0.1302\n",
      "Episode:821 meanR:44.2100 R:22.0 loss:12.6137 exploreP:0.1299\n",
      "Episode:822 meanR:44.3200 R:37.0 loss:13.8099 exploreP:0.1295\n",
      "Episode:823 meanR:44.4600 R:36.0 loss:12.4249 exploreP:0.1290\n",
      "Episode:824 meanR:44.0200 R:47.0 loss:9.4314 exploreP:0.1285\n",
      "Episode:825 meanR:43.9400 R:91.0 loss:6.3389 exploreP:0.1274\n",
      "Episode:826 meanR:43.0100 R:40.0 loss:4.9090 exploreP:0.1269\n",
      "Episode:827 meanR:42.7200 R:27.0 loss:10.1290 exploreP:0.1266\n",
      "Episode:828 meanR:42.7300 R:64.0 loss:11.2661 exploreP:0.1259\n",
      "Episode:829 meanR:42.3900 R:56.0 loss:9.9478 exploreP:0.1252\n",
      "Episode:830 meanR:43.4300 R:157.0 loss:3.7083 exploreP:0.1234\n",
      "Episode:831 meanR:43.9100 R:85.0 loss:3.5550 exploreP:0.1225\n",
      "Episode:832 meanR:45.4000 R:175.0 loss:2.1825 exploreP:0.1205\n",
      "Episode:833 meanR:46.2800 R:114.0 loss:2.2784 exploreP:0.1193\n",
      "Episode:834 meanR:47.1700 R:114.0 loss:5.7919 exploreP:0.1180\n",
      "Episode:835 meanR:47.5800 R:123.0 loss:8.1604 exploreP:0.1167\n",
      "Episode:836 meanR:49.0400 R:169.0 loss:2.2574 exploreP:0.1149\n",
      "Episode:837 meanR:49.0200 R:22.0 loss:2.7643 exploreP:0.1147\n",
      "Episode:838 meanR:48.9200 R:26.0 loss:15.9786 exploreP:0.1144\n",
      "Episode:839 meanR:48.8500 R:17.0 loss:28.8377 exploreP:0.1142\n",
      "Episode:840 meanR:47.8900 R:20.0 loss:41.2033 exploreP:0.1140\n",
      "Episode:841 meanR:44.0500 R:26.0 loss:50.0036 exploreP:0.1138\n",
      "Episode:842 meanR:46.3800 R:279.0 loss:6.0754 exploreP:0.1109\n",
      "Episode:843 meanR:46.1900 R:22.0 loss:15.3422 exploreP:0.1107\n",
      "Episode:844 meanR:45.2400 R:25.0 loss:28.5715 exploreP:0.1104\n",
      "Episode:845 meanR:43.8300 R:18.0 loss:41.1414 exploreP:0.1103\n",
      "Episode:846 meanR:42.9300 R:17.0 loss:51.9469 exploreP:0.1101\n",
      "Episode:847 meanR:42.8200 R:24.0 loss:55.6735 exploreP:0.1098\n",
      "Episode:848 meanR:43.7200 R:117.0 loss:27.2286 exploreP:0.1087\n",
      "Episode:849 meanR:44.7200 R:195.0 loss:3.3303 exploreP:0.1068\n",
      "Episode:850 meanR:45.6900 R:116.0 loss:5.6134 exploreP:0.1057\n",
      "Episode:851 meanR:45.7700 R:24.0 loss:16.9562 exploreP:0.1054\n",
      "Episode:852 meanR:45.7100 R:13.0 loss:29.4317 exploreP:0.1053\n",
      "Episode:853 meanR:45.4600 R:19.0 loss:38.0385 exploreP:0.1051\n",
      "Episode:854 meanR:45.4700 R:109.0 loss:22.5506 exploreP:0.1041\n",
      "Episode:855 meanR:46.6100 R:236.0 loss:3.9712 exploreP:0.1019\n",
      "Episode:856 meanR:48.9200 R:276.0 loss:4.3322 exploreP:0.0994\n",
      "Episode:857 meanR:50.0100 R:139.0 loss:156.8354 exploreP:0.0982\n",
      "Episode:858 meanR:53.0100 R:332.0 loss:2.8919 exploreP:0.0953\n",
      "Episode:859 meanR:53.3800 R:142.0 loss:14.9635 exploreP:0.0941\n",
      "Episode:860 meanR:53.4900 R:134.0 loss:141.7300 exploreP:0.0930\n",
      "Episode:861 meanR:54.1700 R:149.0 loss:8.0168 exploreP:0.0917\n",
      "Episode:862 meanR:54.6600 R:113.0 loss:9.1150 exploreP:0.0908\n",
      "Episode:863 meanR:53.8600 R:231.0 loss:145.2828 exploreP:0.0890\n",
      "Episode:864 meanR:54.3600 R:161.0 loss:179.4270 exploreP:0.0877\n",
      "Episode:865 meanR:54.7600 R:140.0 loss:10.1437 exploreP:0.0866\n",
      "Episode:866 meanR:56.5500 R:247.0 loss:16.3996 exploreP:0.0848\n",
      "Episode:867 meanR:59.0200 R:309.0 loss:2.0708 exploreP:0.0825\n",
      "Episode:868 meanR:60.4900 R:174.0 loss:3.3047 exploreP:0.0812\n",
      "Episode:869 meanR:61.6200 R:138.0 loss:11.5876 exploreP:0.0803\n",
      "Episode:870 meanR:62.7200 R:135.0 loss:26.7253 exploreP:0.0793\n",
      "Episode:871 meanR:63.6700 R:115.0 loss:21.1849 exploreP:0.0785\n",
      "Episode:872 meanR:68.4200 R:500.0 loss:12.6494 exploreP:0.0752\n",
      "Episode:873 meanR:69.1100 R:87.0 loss:18.3253 exploreP:0.0746\n",
      "Episode:874 meanR:73.2800 R:464.0 loss:1.8438 exploreP:0.0717\n",
      "Episode:875 meanR:74.0500 R:103.0 loss:10.6650 exploreP:0.0711\n",
      "Episode:876 meanR:76.8700 R:308.0 loss:4.3882 exploreP:0.0692\n",
      "Episode:877 meanR:77.6700 R:99.0 loss:83.2579 exploreP:0.0686\n",
      "Episode:878 meanR:80.5600 R:316.0 loss:89.7781 exploreP:0.0668\n",
      "Episode:879 meanR:82.1900 R:188.0 loss:152.7254 exploreP:0.0657\n",
      "Episode:880 meanR:83.0000 R:98.0 loss:195.7866 exploreP:0.0652\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "        initial_state = sess.run(model.initial_state)\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            action_logits, final_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                  feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                               model.initial_state: initial_state})\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.states.append([initial_state, final_state])\n",
    "            total_reward += reward\n",
    "            initial_state = final_state\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            #batch, rnn_states = memory.sample(batch_size)\n",
    "            batch = memory.buffer\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            rnn_states = memory.states\n",
    "            initial_states = np.array([each[0] for each in rnn_states])\n",
    "            final_states = np.array([each[1] for each in rnn_states])\n",
    "            next_actions_logits = sess.run(model.actions_logits, \n",
    "                                           feed_dict = {model.states: next_states, \n",
    "                                                        model.initial_state: final_states[0].reshape([1, -1])})\n",
    "            nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "            targetQs = rewards + (gamma * nextQs)\n",
    "            loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                     model.actions: actions,\n",
    "                                                                     model.targetQs: targetQs,\n",
    "                                                        model.initial_state: initial_states[0].reshape([1, -1])})\n",
    "            loss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model-qn-seq.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average losses')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward:120.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-seq.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    initial_state = sess.run(model.initial_state) # Qs or current batch or states[:-1]\n",
    "    \n",
    "    # Episode/epoch\n",
    "    for _ in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        \n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits, initial_state = sess.run([model.actions_logits, model.final_state],\n",
    "                                                    feed_dict = {model.states: state.reshape([1, -1]), \n",
    "                                                                 model.initial_state: initial_state})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # At the end of each episode\n",
    "        print('total_reward:{}'.format(total_reward))\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

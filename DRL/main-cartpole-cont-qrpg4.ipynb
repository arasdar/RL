{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    rewards = tf.placeholder(tf.float32, [None], name='rewards')\n",
    "    dones = tf.placeholder(tf.float32, [None], name='dones')\n",
    "    rates = tf.placeholder(tf.float32, [None], name='rates')\n",
    "    return states, actions, next_states, rewards, dones, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # Input layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Hidden layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        actions_logits = tf.layers.dense(inputs=nl2, units=action_size)\n",
    "        return actions_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(states, actions, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Input layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=action_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Hidden layer\n",
    "        nl1_fused = tf.concat(axis=1, values=[nl1, actions])\n",
    "        h2 = tf.layers.dense(inputs=nl1_fused, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        Qs_logits = tf.layers.dense(inputs=nl2, units=1)\n",
    "        return Qs_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(state_size, action_size, hidden_size, states, actions, next_states, rewards, dones, rates):\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    gloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                      labels=actions_labels))\n",
    "    dQs = discriminator(states=states, actions=actions_labels, action_size=action_size, hidden_size=hidden_size)\n",
    "    rates = tf.reshape(rates, shape=[-1, 1])\n",
    "    dloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs,\n",
    "                                                                   labels=rates)) # [0, 1]\n",
    "    next_actions_logits = generator(states=next_states, hidden_size=hidden_size, action_size=action_size, \n",
    "                                    reuse=True)\n",
    "    nextQs_logits = discriminator(states=next_states, actions=next_actions_logits, action_size=action_size, \n",
    "                                  hidden_size=hidden_size, reuse=True)\n",
    "    nextQs = tf.reshape(nextQs_logits, shape=[-1])\n",
    "    targetQs = rewards + (0.99 * nextQs * (1-dones))\n",
    "    targetQs = tf.reshape(targetQs, shape=[-1, 1])\n",
    "    glossQ = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dQs,\n",
    "                                                                    labels=tf.nn.sigmoid(targetQs))) # [0, 1]\n",
    "    return actions_logits, gloss, dloss, glossQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(g_loss, d_loss, g_lossQ, g_learning_rate, d_learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        g_opt = tf.train.AdamOptimizer(g_learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        g_optQ = tf.train.AdamOptimizer(g_learning_rate).minimize(g_lossQ, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(d_learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "    return g_opt, d_opt, g_optQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, g_learning_rate, d_learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.next_states, self.rewards, self.dones, self.rates = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.g_loss, self.d_loss, self.g_lossQ = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, state_size=state_size, # model init parameters\n",
    "            states=self.states, actions=self.actions, next_states=self.next_states, rewards=self.rewards, \n",
    "            dones=self.dones, rates=self.rates) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_opt, self.d_opt, self.g_optQ = model_opt(g_loss=self.g_loss, \n",
    "                                                        d_loss=self.d_loss,\n",
    "                                                        g_lossQ=self.g_lossQ,\n",
    "                                                        g_learning_rate=g_learning_rate, \n",
    "                                                        d_learning_rate=d_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size) # data batch\n",
    "        self.rates = deque(maxlen=max_size) # rates\n",
    "#     def sample(self, batch_size):\n",
    "#         idx = np.random.choice(np.arange(len(self.buffer)), # ==  self.rates\n",
    "#                                size=batch_size, \n",
    "#                                replace=False)\n",
    "#         return [self.buffer[ii] for ii in idx], [self.rates[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(4,), Discrete(2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "hidden_size = 4*2             # number of units in each Q-network hidden layer\n",
    "g_learning_rate = 1e-4         # Q-network learning rate\n",
    "d_learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e3)             # experience mini-batch size: 200/500 a successfull episode size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size,\n",
    "              g_learning_rate=g_learning_rate, d_learning_rate=d_learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "total_reward = 0\n",
    "num_step = 0\n",
    "for _ in range(memory_size):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    memory.rates.append(-1) # empty\n",
    "    num_step += 1 # memory incremented\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    if done is True:\n",
    "        state = env.reset()\n",
    "        rate = total_reward/500\n",
    "        total_reward = 0 # reset\n",
    "        for idx in range(num_step): # episode length\n",
    "            if memory.rates[-1-idx] == -1:\n",
    "                memory.rates[-1-idx] = rate\n",
    "        num_step = 0 # reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:16.0000 R:16.0000 rate:0.0320 gloss:0.6927 dloss:0.8816 glossQ:0.6797 exploreP:0.9984\n",
      "Episode:1 meanR:21.0000 R:26.0000 rate:0.0520 gloss:0.7005 dloss:0.9063 glossQ:0.6736 exploreP:0.9959\n",
      "Episode:2 meanR:17.0000 R:9.0000 rate:0.0180 gloss:0.7061 dloss:0.8917 glossQ:0.6790 exploreP:0.9950\n",
      "Episode:3 meanR:17.0000 R:17.0000 rate:0.0340 gloss:0.6955 dloss:0.8719 glossQ:0.6831 exploreP:0.9933\n",
      "Episode:4 meanR:16.0000 R:12.0000 rate:0.0240 gloss:0.6887 dloss:0.8666 glossQ:0.6809 exploreP:0.9921\n",
      "Episode:5 meanR:15.3333 R:12.0000 rate:0.0240 gloss:0.6854 dloss:0.8560 glossQ:0.6868 exploreP:0.9909\n",
      "Episode:6 meanR:17.7143 R:32.0000 rate:0.0640 gloss:0.6912 dloss:0.8398 glossQ:0.6944 exploreP:0.9878\n",
      "Episode:7 meanR:17.7500 R:18.0000 rate:0.0360 gloss:0.7246 dloss:0.8360 glossQ:0.6971 exploreP:0.9860\n",
      "Episode:8 meanR:18.0000 R:20.0000 rate:0.0400 gloss:0.6889 dloss:0.8064 glossQ:0.7064 exploreP:0.9841\n",
      "Episode:9 meanR:20.9000 R:47.0000 rate:0.0940 gloss:0.6877 dloss:0.7810 glossQ:0.7176 exploreP:0.9795\n",
      "Episode:10 meanR:20.4545 R:16.0000 rate:0.0320 gloss:0.6862 dloss:0.7745 glossQ:0.7215 exploreP:0.9780\n",
      "Episode:11 meanR:20.8333 R:25.0000 rate:0.0500 gloss:0.7005 dloss:0.7665 glossQ:0.7253 exploreP:0.9756\n",
      "Episode:12 meanR:20.7692 R:20.0000 rate:0.0400 gloss:0.6901 dloss:0.7528 glossQ:0.7318 exploreP:0.9736\n",
      "Episode:13 meanR:20.0000 R:10.0000 rate:0.0200 gloss:0.6823 dloss:0.7397 glossQ:0.7385 exploreP:0.9727\n",
      "Episode:14 meanR:22.0667 R:51.0000 rate:0.1020 gloss:0.6922 dloss:0.7276 glossQ:0.7446 exploreP:0.9678\n",
      "Episode:15 meanR:21.3750 R:11.0000 rate:0.0220 gloss:0.6909 dloss:0.7223 glossQ:0.7474 exploreP:0.9667\n",
      "Episode:16 meanR:21.0588 R:16.0000 rate:0.0320 gloss:0.6899 dloss:0.7117 glossQ:0.7517 exploreP:0.9652\n",
      "Episode:17 meanR:20.9444 R:19.0000 rate:0.0380 gloss:0.6856 dloss:0.7092 glossQ:0.7560 exploreP:0.9634\n",
      "Episode:18 meanR:20.7368 R:17.0000 rate:0.0340 gloss:0.6925 dloss:0.6822 glossQ:0.7655 exploreP:0.9618\n",
      "Episode:19 meanR:20.4000 R:14.0000 rate:0.0280 gloss:0.6900 dloss:0.6816 glossQ:0.7667 exploreP:0.9604\n",
      "Episode:20 meanR:20.9524 R:32.0000 rate:0.0640 gloss:0.6907 dloss:0.6681 glossQ:0.7725 exploreP:0.9574\n",
      "Episode:21 meanR:20.7273 R:16.0000 rate:0.0320 gloss:0.6986 dloss:0.6689 glossQ:0.7724 exploreP:0.9559\n",
      "Episode:22 meanR:20.6087 R:18.0000 rate:0.0360 gloss:0.6922 dloss:0.6540 glossQ:0.7795 exploreP:0.9542\n",
      "Episode:23 meanR:20.4583 R:17.0000 rate:0.0340 gloss:0.6915 dloss:0.6462 glossQ:0.7844 exploreP:0.9526\n",
      "Episode:24 meanR:20.2000 R:14.0000 rate:0.0280 gloss:0.6953 dloss:0.6466 glossQ:0.7822 exploreP:0.9512\n",
      "Episode:25 meanR:20.8462 R:37.0000 rate:0.0740 gloss:0.6927 dloss:0.6322 glossQ:0.7897 exploreP:0.9478\n",
      "Episode:26 meanR:20.6667 R:16.0000 rate:0.0320 gloss:0.6936 dloss:0.6325 glossQ:0.7892 exploreP:0.9463\n",
      "Episode:27 meanR:20.4643 R:15.0000 rate:0.0300 gloss:0.7055 dloss:0.6257 glossQ:0.7900 exploreP:0.9449\n",
      "Episode:28 meanR:20.1724 R:12.0000 rate:0.0240 gloss:0.6958 dloss:0.6110 glossQ:0.7933 exploreP:0.9437\n",
      "Episode:29 meanR:20.1667 R:20.0000 rate:0.0400 gloss:0.7042 dloss:0.6201 glossQ:0.7927 exploreP:0.9419\n",
      "Episode:30 meanR:19.9677 R:14.0000 rate:0.0280 gloss:0.7017 dloss:0.6060 glossQ:0.7975 exploreP:0.9406\n",
      "Episode:31 meanR:19.7500 R:13.0000 rate:0.0260 gloss:0.6974 dloss:0.6072 glossQ:0.7982 exploreP:0.9394\n",
      "Episode:32 meanR:19.7576 R:20.0000 rate:0.0400 gloss:0.7091 dloss:0.5935 glossQ:0.7964 exploreP:0.9375\n",
      "Episode:33 meanR:19.4706 R:10.0000 rate:0.0200 gloss:0.7093 dloss:0.5870 glossQ:0.7998 exploreP:0.9366\n",
      "Episode:34 meanR:19.8857 R:34.0000 rate:0.0680 gloss:0.7071 dloss:0.5833 glossQ:0.7999 exploreP:0.9334\n",
      "Episode:35 meanR:19.7222 R:14.0000 rate:0.0280 gloss:0.7104 dloss:0.5696 glossQ:0.8002 exploreP:0.9321\n",
      "Episode:36 meanR:19.6216 R:16.0000 rate:0.0320 gloss:0.7013 dloss:0.5805 glossQ:0.8033 exploreP:0.9307\n",
      "Episode:37 meanR:19.3947 R:11.0000 rate:0.0220 gloss:0.6968 dloss:0.5604 glossQ:0.8088 exploreP:0.9297\n",
      "Episode:38 meanR:19.1538 R:10.0000 rate:0.0200 gloss:0.7135 dloss:0.5687 glossQ:0.8018 exploreP:0.9287\n",
      "Episode:39 meanR:19.1250 R:18.0000 rate:0.0360 gloss:0.7195 dloss:0.5575 glossQ:0.7997 exploreP:0.9271\n",
      "Episode:40 meanR:19.2683 R:25.0000 rate:0.0500 gloss:0.7135 dloss:0.5534 glossQ:0.8010 exploreP:0.9248\n",
      "Episode:41 meanR:19.7143 R:38.0000 rate:0.0760 gloss:0.7155 dloss:0.5449 glossQ:0.7962 exploreP:0.9213\n",
      "Episode:42 meanR:19.5349 R:12.0000 rate:0.0240 gloss:0.7061 dloss:0.5350 glossQ:0.7964 exploreP:0.9202\n",
      "Episode:43 meanR:19.6591 R:25.0000 rate:0.0500 gloss:0.7071 dloss:0.5382 glossQ:0.8022 exploreP:0.9180\n",
      "Episode:44 meanR:19.7111 R:22.0000 rate:0.0440 gloss:0.7373 dloss:0.5336 glossQ:0.7921 exploreP:0.9160\n",
      "Episode:45 meanR:20.7826 R:69.0000 rate:0.1380 gloss:0.7367 dloss:0.5193 glossQ:0.7867 exploreP:0.9097\n",
      "Episode:46 meanR:20.6809 R:16.0000 rate:0.0320 gloss:0.7406 dloss:0.5111 glossQ:0.7752 exploreP:0.9083\n",
      "Episode:47 meanR:20.6042 R:17.0000 rate:0.0340 gloss:0.7604 dloss:0.5083 glossQ:0.7774 exploreP:0.9068\n",
      "Episode:48 meanR:20.4694 R:14.0000 rate:0.0280 gloss:0.7308 dloss:0.5032 glossQ:0.7801 exploreP:0.9055\n",
      "Episode:49 meanR:20.3600 R:15.0000 rate:0.0300 gloss:0.7361 dloss:0.4909 glossQ:0.7759 exploreP:0.9042\n",
      "Episode:50 meanR:20.1961 R:12.0000 rate:0.0240 gloss:0.7295 dloss:0.4960 glossQ:0.7811 exploreP:0.9031\n",
      "Episode:51 meanR:20.4231 R:32.0000 rate:0.0640 gloss:0.7419 dloss:0.5031 glossQ:0.7744 exploreP:0.9003\n",
      "Episode:52 meanR:20.4528 R:22.0000 rate:0.0440 gloss:0.7542 dloss:0.4875 glossQ:0.7621 exploreP:0.8983\n",
      "Episode:53 meanR:20.6667 R:32.0000 rate:0.0640 gloss:0.7344 dloss:0.4871 glossQ:0.7632 exploreP:0.8955\n",
      "Episode:54 meanR:21.1273 R:46.0000 rate:0.0920 gloss:0.7541 dloss:0.4699 glossQ:0.7559 exploreP:0.8914\n",
      "Episode:55 meanR:21.3750 R:35.0000 rate:0.0700 gloss:0.7582 dloss:0.4744 glossQ:0.7354 exploreP:0.8883\n",
      "Episode:56 meanR:21.4211 R:24.0000 rate:0.0480 gloss:0.7533 dloss:0.4617 glossQ:0.7307 exploreP:0.8862\n",
      "Episode:57 meanR:21.2931 R:14.0000 rate:0.0280 gloss:0.7327 dloss:0.4487 glossQ:0.7350 exploreP:0.8850\n",
      "Episode:58 meanR:21.3390 R:24.0000 rate:0.0480 gloss:0.7640 dloss:0.4653 glossQ:0.7234 exploreP:0.8829\n",
      "Episode:59 meanR:21.1833 R:12.0000 rate:0.0240 gloss:0.7486 dloss:0.4643 glossQ:0.7283 exploreP:0.8818\n",
      "Episode:60 meanR:21.4262 R:36.0000 rate:0.0720 gloss:0.7531 dloss:0.4594 glossQ:0.7150 exploreP:0.8787\n",
      "Episode:61 meanR:21.7258 R:40.0000 rate:0.0800 gloss:0.7655 dloss:0.4444 glossQ:0.7015 exploreP:0.8752\n",
      "Episode:62 meanR:21.6667 R:18.0000 rate:0.0360 gloss:0.7710 dloss:0.4454 glossQ:0.6920 exploreP:0.8737\n",
      "Episode:63 meanR:21.6719 R:22.0000 rate:0.0440 gloss:0.7718 dloss:0.4424 glossQ:0.6904 exploreP:0.8718\n",
      "Episode:64 meanR:21.5077 R:11.0000 rate:0.0220 gloss:0.7503 dloss:0.4501 glossQ:0.6930 exploreP:0.8708\n",
      "Episode:65 meanR:21.4091 R:15.0000 rate:0.0300 gloss:0.7549 dloss:0.4391 glossQ:0.6821 exploreP:0.8695\n",
      "Episode:66 meanR:21.2836 R:13.0000 rate:0.0260 gloss:0.7757 dloss:0.4425 glossQ:0.6771 exploreP:0.8684\n",
      "Episode:67 meanR:21.1471 R:12.0000 rate:0.0240 gloss:0.7702 dloss:0.4427 glossQ:0.6717 exploreP:0.8674\n",
      "Episode:68 meanR:21.6377 R:55.0000 rate:0.1100 gloss:0.7753 dloss:0.4395 glossQ:0.6571 exploreP:0.8627\n",
      "Episode:69 meanR:21.7286 R:28.0000 rate:0.0560 gloss:0.8022 dloss:0.4302 glossQ:0.6321 exploreP:0.8603\n",
      "Episode:70 meanR:21.6338 R:15.0000 rate:0.0300 gloss:0.7911 dloss:0.4327 glossQ:0.6297 exploreP:0.8590\n",
      "Episode:71 meanR:21.5278 R:14.0000 rate:0.0280 gloss:0.7820 dloss:0.4469 glossQ:0.6503 exploreP:0.8579\n",
      "Episode:72 meanR:22.0685 R:61.0000 rate:0.1220 gloss:0.7729 dloss:0.4297 glossQ:0.6346 exploreP:0.8527\n",
      "Episode:73 meanR:21.9459 R:13.0000 rate:0.0260 gloss:0.7944 dloss:0.4106 glossQ:0.6163 exploreP:0.8516\n",
      "Episode:74 meanR:21.9200 R:20.0000 rate:0.0400 gloss:0.7723 dloss:0.4212 glossQ:0.6237 exploreP:0.8499\n",
      "Episode:75 meanR:21.7895 R:12.0000 rate:0.0240 gloss:0.7673 dloss:0.4108 glossQ:0.6205 exploreP:0.8489\n",
      "Episode:76 meanR:21.9091 R:31.0000 rate:0.0620 gloss:0.7836 dloss:0.4299 glossQ:0.6055 exploreP:0.8463\n",
      "Episode:77 meanR:21.8846 R:20.0000 rate:0.0400 gloss:0.7845 dloss:0.4297 glossQ:0.5957 exploreP:0.8446\n",
      "Episode:78 meanR:21.8354 R:18.0000 rate:0.0360 gloss:0.7881 dloss:0.4164 glossQ:0.5924 exploreP:0.8431\n",
      "Episode:79 meanR:21.7500 R:15.0000 rate:0.0300 gloss:0.7717 dloss:0.4062 glossQ:0.5876 exploreP:0.8419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:80 meanR:21.7901 R:25.0000 rate:0.0500 gloss:0.7715 dloss:0.3945 glossQ:0.5814 exploreP:0.8398\n",
      "Episode:81 meanR:21.8537 R:27.0000 rate:0.0540 gloss:0.7898 dloss:0.4118 glossQ:0.5694 exploreP:0.8376\n",
      "Episode:82 meanR:21.7711 R:15.0000 rate:0.0300 gloss:0.7982 dloss:0.4149 glossQ:0.5695 exploreP:0.8363\n",
      "Episode:83 meanR:21.8452 R:28.0000 rate:0.0560 gloss:0.7832 dloss:0.4124 glossQ:0.5566 exploreP:0.8340\n",
      "Episode:84 meanR:22.0000 R:35.0000 rate:0.0700 gloss:0.8094 dloss:0.4147 glossQ:0.5497 exploreP:0.8311\n",
      "Episode:85 meanR:22.3605 R:53.0000 rate:0.1060 gloss:0.7963 dloss:0.4069 glossQ:0.5422 exploreP:0.8268\n",
      "Episode:86 meanR:22.2644 R:14.0000 rate:0.0280 gloss:0.7691 dloss:0.4031 glossQ:0.5245 exploreP:0.8257\n",
      "Episode:87 meanR:22.1136 R:9.0000 rate:0.0180 gloss:0.7966 dloss:0.4089 glossQ:0.5243 exploreP:0.8249\n",
      "Episode:88 meanR:22.0562 R:17.0000 rate:0.0340 gloss:0.7501 dloss:0.4000 glossQ:0.5296 exploreP:0.8235\n",
      "Episode:89 meanR:22.0222 R:19.0000 rate:0.0380 gloss:0.7845 dloss:0.4157 glossQ:0.5182 exploreP:0.8220\n",
      "Episode:90 meanR:22.0110 R:21.0000 rate:0.0420 gloss:0.8052 dloss:0.3904 glossQ:0.5012 exploreP:0.8203\n",
      "Episode:91 meanR:21.9130 R:13.0000 rate:0.0260 gloss:0.7740 dloss:0.4110 glossQ:0.5094 exploreP:0.8192\n",
      "Episode:92 meanR:21.9462 R:25.0000 rate:0.0500 gloss:0.7729 dloss:0.4127 glossQ:0.5022 exploreP:0.8172\n",
      "Episode:93 meanR:21.8404 R:12.0000 rate:0.0240 gloss:0.7763 dloss:0.4148 glossQ:0.4919 exploreP:0.8163\n",
      "Episode:94 meanR:21.7474 R:13.0000 rate:0.0260 gloss:0.7759 dloss:0.3978 glossQ:0.4933 exploreP:0.8152\n",
      "Episode:95 meanR:21.6979 R:17.0000 rate:0.0340 gloss:0.7887 dloss:0.4009 glossQ:0.4738 exploreP:0.8138\n",
      "Episode:96 meanR:21.6392 R:16.0000 rate:0.0320 gloss:0.8526 dloss:0.3914 glossQ:0.4814 exploreP:0.8126\n",
      "Episode:97 meanR:21.5306 R:11.0000 rate:0.0220 gloss:0.7419 dloss:0.4012 glossQ:0.4636 exploreP:0.8117\n",
      "Episode:98 meanR:21.4646 R:15.0000 rate:0.0300 gloss:0.7758 dloss:0.3857 glossQ:0.4740 exploreP:0.8105\n",
      "Episode:99 meanR:21.6000 R:35.0000 rate:0.0700 gloss:0.7540 dloss:0.3947 glossQ:0.4568 exploreP:0.8077\n",
      "Episode:100 meanR:21.5500 R:11.0000 rate:0.0220 gloss:0.7718 dloss:0.4079 glossQ:0.4482 exploreP:0.8068\n",
      "Episode:101 meanR:21.4000 R:11.0000 rate:0.0220 gloss:0.7437 dloss:0.3818 glossQ:0.4507 exploreP:0.8059\n",
      "Episode:102 meanR:21.4100 R:10.0000 rate:0.0200 gloss:0.7647 dloss:0.3955 glossQ:0.4421 exploreP:0.8051\n",
      "Episode:103 meanR:21.4200 R:18.0000 rate:0.0360 gloss:0.8127 dloss:0.3951 glossQ:0.4067 exploreP:0.8037\n",
      "Episode:104 meanR:21.4800 R:18.0000 rate:0.0360 gloss:0.7333 dloss:0.3958 glossQ:0.4359 exploreP:0.8023\n",
      "Episode:105 meanR:21.5000 R:14.0000 rate:0.0280 gloss:0.7671 dloss:0.3848 glossQ:0.4275 exploreP:0.8012\n",
      "Episode:106 meanR:21.4300 R:25.0000 rate:0.0500 gloss:0.7444 dloss:0.3932 glossQ:0.4209 exploreP:0.7992\n",
      "Episode:107 meanR:21.4500 R:20.0000 rate:0.0400 gloss:0.7386 dloss:0.4033 glossQ:0.4335 exploreP:0.7976\n",
      "Episode:108 meanR:21.4000 R:15.0000 rate:0.0300 gloss:0.7412 dloss:0.3848 glossQ:0.4021 exploreP:0.7964\n",
      "Episode:109 meanR:21.0600 R:13.0000 rate:0.0260 gloss:0.7222 dloss:0.3923 glossQ:0.3957 exploreP:0.7954\n",
      "Episode:110 meanR:21.4300 R:53.0000 rate:0.1060 gloss:0.7397 dloss:0.3994 glossQ:0.3788 exploreP:0.7913\n",
      "Episode:111 meanR:21.2900 R:11.0000 rate:0.0220 gloss:0.7554 dloss:0.3671 glossQ:0.3700 exploreP:0.7904\n",
      "Episode:112 meanR:21.2600 R:17.0000 rate:0.0340 gloss:0.7300 dloss:0.3999 glossQ:0.3663 exploreP:0.7891\n",
      "Episode:113 meanR:21.3200 R:16.0000 rate:0.0320 gloss:0.7162 dloss:0.3792 glossQ:0.3701 exploreP:0.7878\n",
      "Episode:114 meanR:21.0100 R:20.0000 rate:0.0400 gloss:0.7457 dloss:0.3833 glossQ:0.3583 exploreP:0.7863\n",
      "Episode:115 meanR:21.0500 R:15.0000 rate:0.0300 gloss:0.7396 dloss:0.3902 glossQ:0.3479 exploreP:0.7851\n",
      "Episode:116 meanR:21.0100 R:12.0000 rate:0.0240 gloss:0.7378 dloss:0.3735 glossQ:0.3445 exploreP:0.7842\n",
      "Episode:117 meanR:21.0600 R:24.0000 rate:0.0480 gloss:0.7249 dloss:0.3911 glossQ:0.3434 exploreP:0.7823\n",
      "Episode:118 meanR:21.0100 R:12.0000 rate:0.0240 gloss:0.7160 dloss:0.3691 glossQ:0.3477 exploreP:0.7814\n",
      "Episode:119 meanR:21.1000 R:23.0000 rate:0.0460 gloss:0.7346 dloss:0.3842 glossQ:0.3326 exploreP:0.7796\n",
      "Episode:120 meanR:21.1600 R:38.0000 rate:0.0760 gloss:0.7260 dloss:0.3952 glossQ:0.3242 exploreP:0.7767\n",
      "Episode:121 meanR:21.3600 R:36.0000 rate:0.0720 gloss:0.7519 dloss:0.3783 glossQ:0.3112 exploreP:0.7740\n",
      "Episode:122 meanR:21.3400 R:16.0000 rate:0.0320 gloss:0.7153 dloss:0.4030 glossQ:0.3020 exploreP:0.7727\n",
      "Episode:123 meanR:21.3400 R:17.0000 rate:0.0340 gloss:0.7260 dloss:0.3828 glossQ:0.2998 exploreP:0.7714\n",
      "Episode:124 meanR:21.3300 R:13.0000 rate:0.0260 gloss:0.7406 dloss:0.3851 glossQ:0.3037 exploreP:0.7704\n",
      "Episode:125 meanR:21.4100 R:45.0000 rate:0.0900 gloss:0.7213 dloss:0.3899 glossQ:0.2920 exploreP:0.7670\n",
      "Episode:126 meanR:21.3900 R:14.0000 rate:0.0280 gloss:0.7125 dloss:0.3789 glossQ:0.2908 exploreP:0.7660\n",
      "Episode:127 meanR:21.3400 R:10.0000 rate:0.0200 gloss:0.7125 dloss:0.3773 glossQ:0.2867 exploreP:0.7652\n",
      "Episode:128 meanR:21.3600 R:14.0000 rate:0.0280 gloss:0.7161 dloss:0.3981 glossQ:0.2877 exploreP:0.7642\n",
      "Episode:129 meanR:21.3400 R:18.0000 rate:0.0360 gloss:0.7301 dloss:0.3671 glossQ:0.2869 exploreP:0.7628\n",
      "Episode:130 meanR:21.5900 R:39.0000 rate:0.0780 gloss:0.7199 dloss:0.3758 glossQ:0.2774 exploreP:0.7599\n",
      "Episode:131 meanR:21.7000 R:24.0000 rate:0.0480 gloss:0.6985 dloss:0.3749 glossQ:0.2718 exploreP:0.7581\n",
      "Episode:132 meanR:21.6900 R:19.0000 rate:0.0380 gloss:0.7172 dloss:0.3827 glossQ:0.2642 exploreP:0.7567\n",
      "Episode:133 meanR:21.8800 R:29.0000 rate:0.0580 gloss:0.7303 dloss:0.3725 glossQ:0.2643 exploreP:0.7545\n",
      "Episode:134 meanR:21.6500 R:11.0000 rate:0.0220 gloss:0.7071 dloss:0.3900 glossQ:0.2522 exploreP:0.7537\n",
      "Episode:135 meanR:21.6900 R:18.0000 rate:0.0360 gloss:0.6912 dloss:0.3816 glossQ:0.2621 exploreP:0.7523\n",
      "Episode:136 meanR:21.6800 R:15.0000 rate:0.0300 gloss:0.6964 dloss:0.3715 glossQ:0.2530 exploreP:0.7512\n",
      "Episode:137 meanR:21.9800 R:41.0000 rate:0.0820 gloss:0.7178 dloss:0.3779 glossQ:0.2443 exploreP:0.7482\n",
      "Episode:138 meanR:22.3100 R:43.0000 rate:0.0860 gloss:0.7010 dloss:0.3763 glossQ:0.2390 exploreP:0.7450\n",
      "Episode:139 meanR:22.8300 R:70.0000 rate:0.1400 gloss:0.7027 dloss:0.3911 glossQ:0.2357 exploreP:0.7399\n",
      "Episode:140 meanR:23.0500 R:47.0000 rate:0.0940 gloss:0.6933 dloss:0.3888 glossQ:0.2336 exploreP:0.7365\n",
      "Episode:141 meanR:22.9200 R:25.0000 rate:0.0500 gloss:0.6971 dloss:0.3577 glossQ:0.2280 exploreP:0.7347\n",
      "Episode:142 meanR:22.9300 R:13.0000 rate:0.0260 gloss:0.8091 dloss:0.3449 glossQ:0.2662 exploreP:0.7337\n",
      "Episode:143 meanR:22.9500 R:27.0000 rate:0.0540 gloss:0.7027 dloss:0.3690 glossQ:0.2238 exploreP:0.7318\n",
      "Episode:144 meanR:23.1200 R:39.0000 rate:0.0780 gloss:0.6911 dloss:0.3784 glossQ:0.2198 exploreP:0.7290\n",
      "Episode:145 meanR:22.7100 R:28.0000 rate:0.0560 gloss:0.6940 dloss:0.3590 glossQ:0.2171 exploreP:0.7269\n",
      "Episode:146 meanR:23.0900 R:54.0000 rate:0.1080 gloss:0.6855 dloss:0.3726 glossQ:0.2094 exploreP:0.7231\n",
      "Episode:147 meanR:23.2100 R:29.0000 rate:0.0580 gloss:0.6894 dloss:0.3679 glossQ:0.2040 exploreP:0.7210\n",
      "Episode:148 meanR:23.3800 R:31.0000 rate:0.0620 gloss:0.6840 dloss:0.3860 glossQ:0.2031 exploreP:0.7188\n",
      "Episode:149 meanR:23.6500 R:42.0000 rate:0.0840 gloss:0.6905 dloss:0.3784 glossQ:0.2044 exploreP:0.7159\n",
      "Episode:150 meanR:23.8000 R:27.0000 rate:0.0540 gloss:0.6882 dloss:0.3688 glossQ:0.2023 exploreP:0.7139\n",
      "Episode:151 meanR:23.5700 R:9.0000 rate:0.0180 gloss:0.6955 dloss:0.3796 glossQ:0.2007 exploreP:0.7133\n",
      "Episode:152 meanR:23.5700 R:22.0000 rate:0.0440 gloss:0.6964 dloss:0.3868 glossQ:0.2003 exploreP:0.7118\n",
      "Episode:153 meanR:23.4700 R:22.0000 rate:0.0440 gloss:0.6930 dloss:0.3720 glossQ:0.2005 exploreP:0.7102\n",
      "Episode:154 meanR:23.1900 R:18.0000 rate:0.0360 gloss:0.6846 dloss:0.3646 glossQ:0.1950 exploreP:0.7090\n",
      "Episode:155 meanR:23.0400 R:20.0000 rate:0.0400 gloss:0.6837 dloss:0.3713 glossQ:0.1973 exploreP:0.7076\n",
      "Episode:156 meanR:22.9600 R:16.0000 rate:0.0320 gloss:0.6898 dloss:0.3649 glossQ:0.1957 exploreP:0.7065\n",
      "Episode:157 meanR:23.2900 R:47.0000 rate:0.0940 gloss:0.6873 dloss:0.3704 glossQ:0.2005 exploreP:0.7032\n",
      "Episode:158 meanR:23.4900 R:44.0000 rate:0.0880 gloss:0.6838 dloss:0.3748 glossQ:0.1919 exploreP:0.7001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:159 meanR:23.9000 R:53.0000 rate:0.1060 gloss:0.6894 dloss:0.3714 glossQ:0.2097 exploreP:0.6965\n",
      "Episode:160 meanR:23.6900 R:15.0000 rate:0.0300 gloss:0.6886 dloss:0.3695 glossQ:0.1903 exploreP:0.6955\n",
      "Episode:161 meanR:23.9200 R:63.0000 rate:0.1260 gloss:0.6805 dloss:0.3727 glossQ:0.1857 exploreP:0.6912\n",
      "Episode:162 meanR:24.4300 R:69.0000 rate:0.1380 gloss:0.6783 dloss:0.3775 glossQ:0.1878 exploreP:0.6865\n",
      "Episode:163 meanR:24.5500 R:34.0000 rate:0.0680 gloss:0.6821 dloss:0.3779 glossQ:0.1862 exploreP:0.6842\n",
      "Episode:164 meanR:24.6500 R:21.0000 rate:0.0420 gloss:0.6771 dloss:0.3761 glossQ:0.1839 exploreP:0.6828\n",
      "Episode:165 meanR:24.9600 R:46.0000 rate:0.0920 gloss:0.6876 dloss:0.3655 glossQ:0.1832 exploreP:0.6797\n",
      "Episode:166 meanR:25.6100 R:78.0000 rate:0.1560 gloss:0.6835 dloss:0.3767 glossQ:0.1789 exploreP:0.6745\n",
      "Episode:167 meanR:26.1000 R:61.0000 rate:0.1220 gloss:0.6834 dloss:0.3721 glossQ:0.1765 exploreP:0.6704\n",
      "Episode:168 meanR:26.1700 R:62.0000 rate:0.1240 gloss:0.6947 dloss:0.3740 glossQ:0.1985 exploreP:0.6664\n",
      "Episode:169 meanR:26.3400 R:45.0000 rate:0.0900 gloss:0.6756 dloss:0.3838 glossQ:0.1743 exploreP:0.6634\n",
      "Episode:170 meanR:26.9000 R:71.0000 rate:0.1420 gloss:0.6783 dloss:0.3671 glossQ:0.1732 exploreP:0.6588\n",
      "Episode:171 meanR:27.1200 R:36.0000 rate:0.0720 gloss:0.6762 dloss:0.3717 glossQ:0.1730 exploreP:0.6565\n",
      "Episode:172 meanR:26.9900 R:48.0000 rate:0.0960 gloss:0.6779 dloss:0.3783 glossQ:0.1706 exploreP:0.6534\n",
      "Episode:173 meanR:27.6500 R:79.0000 rate:0.1580 gloss:0.6810 dloss:0.3751 glossQ:0.1876 exploreP:0.6483\n",
      "Episode:174 meanR:27.5900 R:14.0000 rate:0.0280 gloss:0.6753 dloss:0.3647 glossQ:0.1739 exploreP:0.6474\n",
      "Episode:175 meanR:28.1100 R:64.0000 rate:0.1280 gloss:0.6781 dloss:0.3764 glossQ:0.1690 exploreP:0.6433\n",
      "Episode:176 meanR:28.1800 R:38.0000 rate:0.0760 gloss:0.6842 dloss:0.3626 glossQ:0.1706 exploreP:0.6409\n",
      "Episode:177 meanR:28.5900 R:61.0000 rate:0.1220 gloss:0.6774 dloss:0.3674 glossQ:0.1731 exploreP:0.6371\n",
      "Episode:178 meanR:28.5700 R:16.0000 rate:0.0320 gloss:0.6805 dloss:0.3687 glossQ:0.1644 exploreP:0.6361\n",
      "Episode:179 meanR:29.1200 R:70.0000 rate:0.1400 gloss:0.6777 dloss:0.3794 glossQ:0.1649 exploreP:0.6317\n",
      "Episode:180 meanR:29.0200 R:15.0000 rate:0.0300 gloss:0.6761 dloss:0.3675 glossQ:0.1656 exploreP:0.6308\n",
      "Episode:181 meanR:28.9400 R:19.0000 rate:0.0380 gloss:0.6776 dloss:0.3825 glossQ:0.1661 exploreP:0.6296\n",
      "Episode:182 meanR:29.0600 R:27.0000 rate:0.0540 gloss:0.6782 dloss:0.3567 glossQ:0.1668 exploreP:0.6279\n",
      "Episode:183 meanR:29.6200 R:84.0000 rate:0.1680 gloss:0.6756 dloss:0.3780 glossQ:0.1652 exploreP:0.6228\n",
      "Episode:184 meanR:29.6000 R:33.0000 rate:0.0660 gloss:0.6742 dloss:0.3719 glossQ:0.1644 exploreP:0.6208\n",
      "Episode:185 meanR:29.2200 R:15.0000 rate:0.0300 gloss:0.6694 dloss:0.3676 glossQ:0.1632 exploreP:0.6198\n",
      "Episode:186 meanR:30.0900 R:101.0000 rate:0.2020 gloss:0.6788 dloss:0.3688 glossQ:0.1761 exploreP:0.6137\n",
      "Episode:187 meanR:30.7600 R:76.0000 rate:0.1520 gloss:0.6809 dloss:0.3667 glossQ:0.1651 exploreP:0.6091\n",
      "Episode:188 meanR:31.7000 R:111.0000 rate:0.2220 gloss:0.6757 dloss:0.3747 glossQ:0.1625 exploreP:0.6025\n",
      "Episode:189 meanR:31.7200 R:21.0000 rate:0.0420 gloss:0.6724 dloss:0.3702 glossQ:0.1618 exploreP:0.6013\n",
      "Episode:190 meanR:31.9500 R:44.0000 rate:0.0880 gloss:0.6738 dloss:0.3724 glossQ:0.1937 exploreP:0.5987\n",
      "Episode:191 meanR:33.0800 R:126.0000 rate:0.2520 gloss:0.6718 dloss:0.3686 glossQ:0.1610 exploreP:0.5913\n",
      "Episode:192 meanR:34.3900 R:156.0000 rate:0.3120 gloss:0.6714 dloss:0.3718 glossQ:0.1687 exploreP:0.5823\n",
      "Episode:193 meanR:34.9500 R:68.0000 rate:0.1360 gloss:0.6740 dloss:0.3834 glossQ:0.1602 exploreP:0.5784\n",
      "Episode:194 meanR:35.4600 R:64.0000 rate:0.1280 gloss:0.6727 dloss:0.3656 glossQ:0.1613 exploreP:0.5748\n",
      "Episode:195 meanR:36.1900 R:90.0000 rate:0.1800 gloss:0.6717 dloss:0.3751 glossQ:0.1612 exploreP:0.5698\n",
      "Episode:196 meanR:37.4900 R:146.0000 rate:0.2920 gloss:0.6738 dloss:0.3746 glossQ:0.1672 exploreP:0.5616\n",
      "Episode:197 meanR:38.2200 R:84.0000 rate:0.1680 gloss:0.6852 dloss:0.3642 glossQ:0.1782 exploreP:0.5570\n",
      "Episode:198 meanR:38.3900 R:32.0000 rate:0.0640 gloss:0.6710 dloss:0.3901 glossQ:0.1585 exploreP:0.5553\n",
      "Episode:199 meanR:38.4500 R:41.0000 rate:0.0820 gloss:0.6724 dloss:0.3900 glossQ:0.1624 exploreP:0.5531\n",
      "Episode:200 meanR:39.0100 R:67.0000 rate:0.1340 gloss:0.6688 dloss:0.3753 glossQ:0.1592 exploreP:0.5494\n",
      "Episode:201 meanR:40.6500 R:175.0000 rate:0.3500 gloss:0.6696 dloss:0.3805 glossQ:0.1625 exploreP:0.5401\n",
      "Episode:202 meanR:40.8400 R:29.0000 rate:0.0580 gloss:0.6675 dloss:0.3959 glossQ:0.1590 exploreP:0.5385\n",
      "Episode:203 meanR:41.1000 R:44.0000 rate:0.0880 gloss:0.6676 dloss:0.3731 glossQ:0.1614 exploreP:0.5362\n",
      "Episode:204 meanR:41.4000 R:48.0000 rate:0.0960 gloss:0.6692 dloss:0.3728 glossQ:0.1607 exploreP:0.5337\n",
      "Episode:205 meanR:42.3700 R:111.0000 rate:0.2220 gloss:0.6710 dloss:0.3722 glossQ:0.1595 exploreP:0.5279\n",
      "Episode:206 meanR:42.5100 R:39.0000 rate:0.0780 gloss:0.6798 dloss:0.3887 glossQ:0.1643 exploreP:0.5259\n",
      "Episode:207 meanR:43.6300 R:132.0000 rate:0.2640 gloss:0.6716 dloss:0.3825 glossQ:0.1652 exploreP:0.5191\n",
      "Episode:208 meanR:44.5500 R:107.0000 rate:0.2140 gloss:0.6694 dloss:0.3707 glossQ:0.1585 exploreP:0.5137\n",
      "Episode:209 meanR:45.1000 R:68.0000 rate:0.1360 gloss:0.6695 dloss:0.3976 glossQ:0.1587 exploreP:0.5103\n",
      "Episode:210 meanR:45.2400 R:67.0000 rate:0.1340 gloss:0.6685 dloss:0.3870 glossQ:0.1623 exploreP:0.5070\n",
      "Episode:211 meanR:45.9700 R:84.0000 rate:0.1680 gloss:0.6682 dloss:0.3713 glossQ:0.1610 exploreP:0.5028\n",
      "Episode:212 meanR:46.5100 R:71.0000 rate:0.1420 gloss:0.6695 dloss:0.3791 glossQ:0.1601 exploreP:0.4993\n",
      "Episode:213 meanR:46.7100 R:36.0000 rate:0.0720 gloss:0.6698 dloss:0.3819 glossQ:0.1626 exploreP:0.4976\n",
      "Episode:214 meanR:46.7800 R:27.0000 rate:0.0540 gloss:0.6706 dloss:0.3843 glossQ:0.1613 exploreP:0.4962\n",
      "Episode:215 meanR:46.7300 R:10.0000 rate:0.0200 gloss:0.6619 dloss:0.3572 glossQ:0.1622 exploreP:0.4958\n",
      "Episode:216 meanR:46.7900 R:18.0000 rate:0.0360 gloss:0.7363 dloss:0.3700 glossQ:0.2170 exploreP:0.4949\n",
      "Episode:217 meanR:46.8700 R:32.0000 rate:0.0640 gloss:0.6711 dloss:0.4050 glossQ:0.1595 exploreP:0.4933\n",
      "Episode:218 meanR:47.0700 R:32.0000 rate:0.0640 gloss:0.6717 dloss:0.3775 glossQ:0.1606 exploreP:0.4918\n",
      "Episode:219 meanR:47.6600 R:82.0000 rate:0.1640 gloss:0.6718 dloss:0.3651 glossQ:0.1604 exploreP:0.4879\n",
      "Episode:220 meanR:47.8800 R:60.0000 rate:0.1200 gloss:0.6685 dloss:0.3721 glossQ:0.1587 exploreP:0.4850\n",
      "Episode:221 meanR:48.5300 R:101.0000 rate:0.2020 gloss:0.6678 dloss:0.3827 glossQ:0.1568 exploreP:0.4802\n",
      "Episode:222 meanR:49.4600 R:109.0000 rate:0.2180 gloss:0.6690 dloss:0.3732 glossQ:0.1570 exploreP:0.4751\n",
      "Episode:223 meanR:50.5900 R:130.0000 rate:0.2600 gloss:0.6711 dloss:0.3934 glossQ:0.1652 exploreP:0.4691\n",
      "Episode:224 meanR:51.1500 R:69.0000 rate:0.1380 gloss:0.6716 dloss:0.3634 glossQ:0.1639 exploreP:0.4660\n",
      "Episode:225 meanR:51.9400 R:124.0000 rate:0.2480 gloss:0.6676 dloss:0.3807 glossQ:0.1608 exploreP:0.4603\n",
      "Episode:226 meanR:52.3300 R:53.0000 rate:0.1060 gloss:0.6691 dloss:0.3721 glossQ:0.1603 exploreP:0.4580\n",
      "Episode:227 meanR:53.7100 R:148.0000 rate:0.2960 gloss:0.6694 dloss:0.3840 glossQ:0.1607 exploreP:0.4514\n",
      "Episode:228 meanR:53.9100 R:34.0000 rate:0.0680 gloss:0.6760 dloss:0.3535 glossQ:0.1621 exploreP:0.4499\n",
      "Episode:229 meanR:54.6300 R:90.0000 rate:0.1800 gloss:0.6700 dloss:0.3943 glossQ:0.1606 exploreP:0.4459\n",
      "Episode:230 meanR:55.6500 R:141.0000 rate:0.2820 gloss:0.6721 dloss:0.3809 glossQ:0.1614 exploreP:0.4398\n",
      "Episode:231 meanR:56.3600 R:95.0000 rate:0.1900 gloss:0.6623 dloss:0.4064 glossQ:0.1614 exploreP:0.4358\n",
      "Episode:232 meanR:58.2800 R:211.0000 rate:0.4220 gloss:0.6683 dloss:0.3828 glossQ:0.1640 exploreP:0.4269\n",
      "Episode:233 meanR:59.6500 R:166.0000 rate:0.3320 gloss:0.6698 dloss:0.4021 glossQ:0.1647 exploreP:0.4200\n",
      "Episode:234 meanR:60.8900 R:135.0000 rate:0.2700 gloss:0.6703 dloss:0.3995 glossQ:0.1693 exploreP:0.4145\n",
      "Episode:235 meanR:61.7200 R:101.0000 rate:0.2020 gloss:0.6707 dloss:0.3892 glossQ:0.1694 exploreP:0.4105\n",
      "Episode:236 meanR:62.2500 R:68.0000 rate:0.1360 gloss:0.6741 dloss:0.3839 glossQ:0.1686 exploreP:0.4077\n",
      "Episode:237 meanR:62.8300 R:99.0000 rate:0.1980 gloss:0.6652 dloss:0.3906 glossQ:0.1655 exploreP:0.4038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:238 meanR:63.7400 R:134.0000 rate:0.2680 gloss:0.6684 dloss:0.3814 glossQ:0.1660 exploreP:0.3986\n",
      "Episode:239 meanR:64.3500 R:131.0000 rate:0.2620 gloss:0.6689 dloss:0.3783 glossQ:0.1634 exploreP:0.3935\n",
      "Episode:240 meanR:65.0700 R:119.0000 rate:0.2380 gloss:0.6699 dloss:0.3997 glossQ:0.1608 exploreP:0.3890\n",
      "Episode:241 meanR:65.8800 R:106.0000 rate:0.2120 gloss:0.6692 dloss:0.4027 glossQ:0.1692 exploreP:0.3850\n",
      "Episode:242 meanR:66.9800 R:123.0000 rate:0.2460 gloss:0.6744 dloss:0.3862 glossQ:0.1724 exploreP:0.3804\n",
      "Episode:243 meanR:67.8700 R:116.0000 rate:0.2320 gloss:0.6702 dloss:0.3783 glossQ:0.1642 exploreP:0.3761\n",
      "Episode:244 meanR:69.2300 R:175.0000 rate:0.3500 gloss:0.6700 dloss:0.4009 glossQ:0.1662 exploreP:0.3698\n",
      "Episode:245 meanR:69.0700 R:12.0000 rate:0.0240 gloss:0.6734 dloss:0.3596 glossQ:0.1682 exploreP:0.3694\n",
      "Episode:246 meanR:68.9700 R:44.0000 rate:0.0880 gloss:0.6706 dloss:0.3850 glossQ:0.1673 exploreP:0.3678\n",
      "Episode:247 meanR:69.5600 R:88.0000 rate:0.1760 gloss:0.6675 dloss:0.3956 glossQ:0.1653 exploreP:0.3646\n",
      "Episode:248 meanR:70.1400 R:89.0000 rate:0.1780 gloss:0.6674 dloss:0.3972 glossQ:0.1658 exploreP:0.3615\n",
      "Episode:249 meanR:70.8200 R:110.0000 rate:0.2200 gloss:0.6682 dloss:0.4074 glossQ:0.1696 exploreP:0.3577\n",
      "Episode:250 meanR:72.0500 R:150.0000 rate:0.3000 gloss:0.6679 dloss:0.4071 glossQ:0.1728 exploreP:0.3525\n",
      "Episode:251 meanR:73.8000 R:184.0000 rate:0.3680 gloss:0.6682 dloss:0.4056 glossQ:0.1775 exploreP:0.3462\n",
      "Episode:252 meanR:75.6800 R:210.0000 rate:0.4200 gloss:0.6700 dloss:0.3872 glossQ:0.1691 exploreP:0.3392\n",
      "Episode:253 meanR:76.6700 R:121.0000 rate:0.2420 gloss:0.6685 dloss:0.3974 glossQ:0.1690 exploreP:0.3353\n",
      "Episode:254 meanR:78.9500 R:246.0000 rate:0.4920 gloss:0.6655 dloss:0.4146 glossQ:0.1695 exploreP:0.3274\n",
      "Episode:255 meanR:79.6000 R:85.0000 rate:0.1700 gloss:0.6629 dloss:0.4238 glossQ:0.1741 exploreP:0.3247\n",
      "Episode:256 meanR:80.7200 R:128.0000 rate:0.2560 gloss:0.6665 dloss:0.3916 glossQ:0.1779 exploreP:0.3207\n",
      "Episode:257 meanR:81.3100 R:106.0000 rate:0.2120 gloss:0.6694 dloss:0.3819 glossQ:0.1727 exploreP:0.3174\n",
      "Episode:258 meanR:82.3700 R:150.0000 rate:0.3000 gloss:0.6675 dloss:0.3929 glossQ:0.1695 exploreP:0.3128\n",
      "Episode:259 meanR:83.0900 R:125.0000 rate:0.2500 gloss:0.6714 dloss:0.3939 glossQ:0.1710 exploreP:0.3091\n",
      "Episode:260 meanR:84.8400 R:190.0000 rate:0.3800 gloss:0.6694 dloss:0.3895 glossQ:0.1674 exploreP:0.3034\n",
      "Episode:261 meanR:85.0900 R:88.0000 rate:0.1760 gloss:0.6670 dloss:0.4066 glossQ:0.1745 exploreP:0.3009\n",
      "Episode:262 meanR:86.0900 R:169.0000 rate:0.3380 gloss:0.6648 dloss:0.4029 glossQ:0.1677 exploreP:0.2960\n",
      "Episode:263 meanR:87.9500 R:220.0000 rate:0.4400 gloss:0.6680 dloss:0.4099 glossQ:0.1710 exploreP:0.2898\n",
      "Episode:264 meanR:88.5300 R:79.0000 rate:0.1580 gloss:0.6678 dloss:0.4036 glossQ:0.1717 exploreP:0.2876\n",
      "Episode:265 meanR:89.1500 R:108.0000 rate:0.2160 gloss:0.6689 dloss:0.3986 glossQ:0.1737 exploreP:0.2846\n",
      "Episode:266 meanR:89.9400 R:157.0000 rate:0.3140 gloss:0.6712 dloss:0.3916 glossQ:0.1760 exploreP:0.2803\n",
      "Episode:267 meanR:90.6200 R:129.0000 rate:0.2580 gloss:0.6708 dloss:0.4182 glossQ:0.1696 exploreP:0.2769\n",
      "Episode:268 meanR:90.7000 R:70.0000 rate:0.1400 gloss:0.6695 dloss:0.3988 glossQ:0.1735 exploreP:0.2750\n",
      "Episode:269 meanR:91.1000 R:85.0000 rate:0.1700 gloss:0.6632 dloss:0.4116 glossQ:0.1711 exploreP:0.2728\n",
      "Episode:270 meanR:91.4100 R:102.0000 rate:0.2040 gloss:0.6649 dloss:0.4134 glossQ:0.1732 exploreP:0.2701\n",
      "Episode:271 meanR:92.2800 R:123.0000 rate:0.2460 gloss:0.6706 dloss:0.4395 glossQ:0.1786 exploreP:0.2669\n",
      "Episode:272 meanR:92.9400 R:114.0000 rate:0.2280 gloss:0.6655 dloss:0.4243 glossQ:0.1796 exploreP:0.2640\n",
      "Episode:273 meanR:93.1700 R:102.0000 rate:0.2040 gloss:0.6682 dloss:0.3983 glossQ:0.1801 exploreP:0.2614\n",
      "Episode:274 meanR:95.3100 R:228.0000 rate:0.4560 gloss:0.6682 dloss:0.4187 glossQ:0.1823 exploreP:0.2557\n",
      "Episode:275 meanR:95.7700 R:110.0000 rate:0.2200 gloss:0.6721 dloss:0.3938 glossQ:0.1788 exploreP:0.2531\n",
      "Episode:276 meanR:96.5500 R:116.0000 rate:0.2320 gloss:0.6703 dloss:0.3845 glossQ:0.1763 exploreP:0.2503\n",
      "Episode:277 meanR:98.2900 R:235.0000 rate:0.4700 gloss:0.6668 dloss:0.4097 glossQ:0.1721 exploreP:0.2447\n",
      "Episode:278 meanR:100.8400 R:271.0000 rate:0.5420 gloss:0.6637 dloss:0.4300 glossQ:0.1772 exploreP:0.2384\n",
      "Episode:279 meanR:101.7900 R:165.0000 rate:0.3300 gloss:0.6663 dloss:0.4150 glossQ:0.1844 exploreP:0.2347\n",
      "Episode:280 meanR:102.5500 R:91.0000 rate:0.1820 gloss:0.6666 dloss:0.4184 glossQ:0.1794 exploreP:0.2326\n",
      "Episode:281 meanR:103.5600 R:120.0000 rate:0.2400 gloss:0.6634 dloss:0.4233 glossQ:0.1803 exploreP:0.2300\n",
      "Episode:282 meanR:104.6500 R:136.0000 rate:0.2720 gloss:0.6646 dloss:0.4255 glossQ:0.1803 exploreP:0.2270\n",
      "Episode:283 meanR:104.7400 R:93.0000 rate:0.1860 gloss:0.6618 dloss:0.4410 glossQ:0.1812 exploreP:0.2250\n",
      "Episode:284 meanR:106.1000 R:169.0000 rate:0.3380 gloss:0.6659 dloss:0.4122 glossQ:0.1853 exploreP:0.2214\n",
      "Episode:285 meanR:106.7200 R:77.0000 rate:0.1540 gloss:0.6640 dloss:0.4412 glossQ:0.1820 exploreP:0.2198\n",
      "Episode:286 meanR:106.8900 R:118.0000 rate:0.2360 gloss:0.6627 dloss:0.4223 glossQ:0.1858 exploreP:0.2173\n",
      "Episode:287 meanR:107.2900 R:116.0000 rate:0.2320 gloss:0.6690 dloss:0.4279 glossQ:0.1867 exploreP:0.2149\n",
      "Episode:288 meanR:107.7100 R:153.0000 rate:0.3060 gloss:0.6648 dloss:0.4190 glossQ:0.1838 exploreP:0.2118\n",
      "Episode:289 meanR:108.8700 R:137.0000 rate:0.2740 gloss:0.6689 dloss:0.4168 glossQ:0.1845 exploreP:0.2091\n",
      "Episode:290 meanR:110.5700 R:214.0000 rate:0.4280 gloss:0.6666 dloss:0.4128 glossQ:0.1843 exploreP:0.2048\n",
      "Episode:291 meanR:110.4100 R:110.0000 rate:0.2200 gloss:0.6616 dloss:0.4449 glossQ:0.1791 exploreP:0.2027\n",
      "Episode:292 meanR:109.9400 R:109.0000 rate:0.2180 gloss:0.6675 dloss:0.4235 glossQ:0.1962 exploreP:0.2006\n",
      "Episode:293 meanR:110.9800 R:172.0000 rate:0.3440 gloss:0.6646 dloss:0.4340 glossQ:0.1847 exploreP:0.1974\n",
      "Episode:294 meanR:111.7800 R:144.0000 rate:0.2880 gloss:0.6656 dloss:0.4242 glossQ:0.1870 exploreP:0.1947\n",
      "Episode:295 meanR:112.5200 R:164.0000 rate:0.3280 gloss:0.6655 dloss:0.4149 glossQ:0.1843 exploreP:0.1917\n",
      "Episode:296 meanR:112.4000 R:134.0000 rate:0.2680 gloss:0.6625 dloss:0.4418 glossQ:0.1842 exploreP:0.1893\n",
      "Episode:297 meanR:112.7400 R:118.0000 rate:0.2360 gloss:0.6696 dloss:0.4206 glossQ:0.1864 exploreP:0.1872\n",
      "Episode:298 meanR:113.6400 R:122.0000 rate:0.2440 gloss:0.6603 dloss:0.4386 glossQ:0.1836 exploreP:0.1850\n",
      "Episode:299 meanR:115.3800 R:215.0000 rate:0.4300 gloss:0.6627 dloss:0.4491 glossQ:0.1868 exploreP:0.1813\n",
      "Episode:300 meanR:115.8800 R:117.0000 rate:0.2340 gloss:0.6608 dloss:0.4525 glossQ:0.1928 exploreP:0.1793\n",
      "Episode:301 meanR:115.5600 R:143.0000 rate:0.2860 gloss:0.6617 dloss:0.4571 glossQ:0.1960 exploreP:0.1769\n",
      "Episode:302 meanR:116.8200 R:155.0000 rate:0.3100 gloss:0.6618 dloss:0.4478 glossQ:0.1982 exploreP:0.1743\n",
      "Episode:303 meanR:117.4000 R:102.0000 rate:0.2040 gloss:0.6640 dloss:0.4424 glossQ:0.1967 exploreP:0.1727\n",
      "Episode:304 meanR:118.5600 R:164.0000 rate:0.3280 gloss:0.6620 dloss:0.4457 glossQ:0.1976 exploreP:0.1700\n",
      "Episode:305 meanR:118.8000 R:135.0000 rate:0.2700 gloss:0.6640 dloss:0.4320 glossQ:0.1953 exploreP:0.1679\n",
      "Episode:306 meanR:119.5700 R:116.0000 rate:0.2320 gloss:0.6585 dloss:0.4560 glossQ:0.1968 exploreP:0.1661\n",
      "Episode:307 meanR:119.4600 R:121.0000 rate:0.2420 gloss:0.6662 dloss:0.4499 glossQ:0.1978 exploreP:0.1642\n",
      "Episode:308 meanR:119.5000 R:111.0000 rate:0.2220 gloss:0.6611 dloss:0.4309 glossQ:0.1973 exploreP:0.1625\n",
      "Episode:309 meanR:119.7900 R:97.0000 rate:0.1940 gloss:0.6605 dloss:0.4386 glossQ:0.1943 exploreP:0.1610\n",
      "Episode:310 meanR:120.5600 R:144.0000 rate:0.2880 gloss:0.6623 dloss:0.4372 glossQ:0.1975 exploreP:0.1588\n",
      "Episode:311 meanR:121.0100 R:129.0000 rate:0.2580 gloss:0.6730 dloss:0.4554 glossQ:0.2017 exploreP:0.1569\n",
      "Episode:312 meanR:121.5700 R:127.0000 rate:0.2540 gloss:0.6628 dloss:0.4487 glossQ:0.2003 exploreP:0.1551\n",
      "Episode:313 meanR:123.6200 R:241.0000 rate:0.4820 gloss:0.6641 dloss:0.4245 glossQ:0.1957 exploreP:0.1516\n",
      "Episode:314 meanR:124.8400 R:149.0000 rate:0.2980 gloss:0.6602 dloss:0.4489 glossQ:0.1907 exploreP:0.1495\n",
      "Episode:315 meanR:125.9400 R:120.0000 rate:0.2400 gloss:0.6646 dloss:0.4335 glossQ:0.1949 exploreP:0.1479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:316 meanR:127.0400 R:128.0000 rate:0.2560 gloss:0.6618 dloss:0.4584 glossQ:0.1976 exploreP:0.1461\n",
      "Episode:317 meanR:127.8500 R:113.0000 rate:0.2260 gloss:0.6666 dloss:0.4336 glossQ:0.1988 exploreP:0.1446\n",
      "Episode:318 meanR:129.0100 R:148.0000 rate:0.2960 gloss:0.6621 dloss:0.4628 glossQ:0.1946 exploreP:0.1426\n",
      "Episode:319 meanR:129.3600 R:117.0000 rate:0.2340 gloss:0.6614 dloss:0.4666 glossQ:0.1989 exploreP:0.1411\n",
      "Episode:320 meanR:132.2300 R:347.0000 rate:0.6940 gloss:0.6661 dloss:0.4486 glossQ:0.2065 exploreP:0.1366\n",
      "Episode:321 meanR:132.8300 R:161.0000 rate:0.3220 gloss:0.6639 dloss:0.4597 glossQ:0.2020 exploreP:0.1346\n",
      "Episode:322 meanR:133.2000 R:146.0000 rate:0.2920 gloss:0.6602 dloss:0.4449 glossQ:0.2031 exploreP:0.1328\n",
      "Episode:323 meanR:133.5300 R:163.0000 rate:0.3260 gloss:0.6616 dloss:0.4613 glossQ:0.2073 exploreP:0.1308\n",
      "Episode:324 meanR:134.5500 R:171.0000 rate:0.3420 gloss:0.6620 dloss:0.4659 glossQ:0.2038 exploreP:0.1287\n",
      "Episode:325 meanR:136.1200 R:281.0000 rate:0.5620 gloss:0.6606 dloss:0.4478 glossQ:0.2023 exploreP:0.1254\n",
      "Episode:326 meanR:137.4300 R:184.0000 rate:0.3680 gloss:0.6608 dloss:0.4483 glossQ:0.2009 exploreP:0.1233\n",
      "Episode:327 meanR:138.2300 R:228.0000 rate:0.4560 gloss:0.6605 dloss:0.4590 glossQ:0.2036 exploreP:0.1208\n",
      "Episode:328 meanR:139.4000 R:151.0000 rate:0.3020 gloss:0.6574 dloss:0.4626 glossQ:0.2103 exploreP:0.1191\n",
      "Episode:329 meanR:139.8800 R:138.0000 rate:0.2760 gloss:0.6674 dloss:0.4623 glossQ:0.2080 exploreP:0.1176\n",
      "Episode:330 meanR:140.0600 R:159.0000 rate:0.3180 gloss:0.6596 dloss:0.4497 glossQ:0.2035 exploreP:0.1159\n",
      "Episode:331 meanR:141.5700 R:246.0000 rate:0.4920 gloss:0.6576 dloss:0.4845 glossQ:0.2098 exploreP:0.1134\n",
      "Episode:332 meanR:142.8000 R:334.0000 rate:0.6680 gloss:0.6595 dloss:0.4759 glossQ:0.2146 exploreP:0.1100\n",
      "Episode:333 meanR:142.9200 R:178.0000 rate:0.3560 gloss:0.6590 dloss:0.4604 glossQ:0.2245 exploreP:0.1082\n",
      "Episode:334 meanR:144.6100 R:304.0000 rate:0.6080 gloss:0.6597 dloss:0.4749 glossQ:0.2189 exploreP:0.1053\n",
      "Episode:335 meanR:144.8700 R:127.0000 rate:0.2540 gloss:0.6556 dloss:0.5192 glossQ:0.2203 exploreP:0.1041\n",
      "Episode:336 meanR:145.3200 R:113.0000 rate:0.2260 gloss:0.6603 dloss:0.4565 glossQ:0.2208 exploreP:0.1030\n",
      "Episode:337 meanR:146.5700 R:224.0000 rate:0.4480 gloss:0.6592 dloss:0.4725 glossQ:0.2204 exploreP:0.1009\n",
      "Episode:338 meanR:146.5200 R:129.0000 rate:0.2580 gloss:0.6563 dloss:0.4975 glossQ:0.2216 exploreP:0.0998\n",
      "Episode:339 meanR:146.6100 R:140.0000 rate:0.2800 gloss:0.6651 dloss:0.4807 glossQ:0.2291 exploreP:0.0985\n",
      "Episode:340 meanR:148.7100 R:329.0000 rate:0.6580 gloss:0.6588 dloss:0.4827 glossQ:0.2236 exploreP:0.0957\n",
      "Episode:341 meanR:150.4100 R:276.0000 rate:0.5520 gloss:0.6582 dloss:0.4751 glossQ:0.2246 exploreP:0.0933\n",
      "Episode:342 meanR:150.8100 R:163.0000 rate:0.3260 gloss:0.6619 dloss:0.4500 glossQ:0.2222 exploreP:0.0920\n",
      "Episode:343 meanR:150.8900 R:124.0000 rate:0.2480 gloss:0.6566 dloss:0.5067 glossQ:0.2192 exploreP:0.0910\n",
      "Episode:344 meanR:150.7700 R:163.0000 rate:0.3260 gloss:0.6610 dloss:0.4756 glossQ:0.2261 exploreP:0.0897\n",
      "Episode:345 meanR:152.6400 R:199.0000 rate:0.3980 gloss:0.6608 dloss:0.4693 glossQ:0.2229 exploreP:0.0881\n",
      "Episode:346 meanR:153.3800 R:118.0000 rate:0.2360 gloss:0.6569 dloss:0.4957 glossQ:0.2261 exploreP:0.0872\n",
      "Episode:347 meanR:154.2000 R:170.0000 rate:0.3400 gloss:0.6550 dloss:0.5094 glossQ:0.2287 exploreP:0.0859\n",
      "Episode:348 meanR:155.6800 R:237.0000 rate:0.4740 gloss:0.6579 dloss:0.4747 glossQ:0.2280 exploreP:0.0841\n",
      "Episode:349 meanR:156.2200 R:164.0000 rate:0.3280 gloss:0.6568 dloss:0.5185 glossQ:0.2310 exploreP:0.0829\n",
      "Episode:350 meanR:157.1700 R:245.0000 rate:0.4900 gloss:0.6570 dloss:0.4833 glossQ:0.2292 exploreP:0.0811\n",
      "Episode:351 meanR:157.5400 R:221.0000 rate:0.4420 gloss:0.6591 dloss:0.4661 glossQ:0.2290 exploreP:0.0796\n",
      "Episode:352 meanR:158.1700 R:273.0000 rate:0.5460 gloss:0.6555 dloss:0.5018 glossQ:0.2290 exploreP:0.0777\n",
      "Episode:353 meanR:159.0200 R:206.0000 rate:0.4120 gloss:0.6554 dloss:0.5110 glossQ:0.2333 exploreP:0.0763\n",
      "Episode:354 meanR:158.0100 R:145.0000 rate:0.2900 gloss:0.6561 dloss:0.5038 glossQ:0.2385 exploreP:0.0754\n",
      "Episode:355 meanR:158.7500 R:159.0000 rate:0.3180 gloss:0.6560 dloss:0.4828 glossQ:0.2386 exploreP:0.0743\n",
      "Episode:356 meanR:159.2100 R:174.0000 rate:0.3480 gloss:0.6547 dloss:0.5031 glossQ:0.2374 exploreP:0.0732\n",
      "Episode:357 meanR:159.7100 R:156.0000 rate:0.3120 gloss:0.6497 dloss:0.5185 glossQ:0.2386 exploreP:0.0722\n",
      "Episode:358 meanR:159.6000 R:139.0000 rate:0.2780 gloss:0.6494 dloss:0.5177 glossQ:0.2521 exploreP:0.0714\n",
      "Episode:359 meanR:161.6100 R:326.0000 rate:0.6520 gloss:0.6554 dloss:0.4895 glossQ:0.2441 exploreP:0.0694\n",
      "Episode:360 meanR:161.1400 R:143.0000 rate:0.2860 gloss:0.6531 dloss:0.4957 glossQ:0.2396 exploreP:0.0686\n",
      "Episode:361 meanR:161.5600 R:130.0000 rate:0.2600 gloss:0.6535 dloss:0.5063 glossQ:0.2388 exploreP:0.0678\n",
      "Episode:362 meanR:161.0700 R:120.0000 rate:0.2400 gloss:0.6527 dloss:0.5178 glossQ:0.2419 exploreP:0.0671\n",
      "Episode:363 meanR:160.4300 R:156.0000 rate:0.3120 gloss:0.6499 dloss:0.5255 glossQ:0.2500 exploreP:0.0662\n",
      "Episode:364 meanR:162.3700 R:273.0000 rate:0.5460 gloss:0.6585 dloss:0.5108 glossQ:0.2562 exploreP:0.0647\n",
      "Episode:365 meanR:165.6300 R:434.0000 rate:0.8680 gloss:0.6522 dloss:0.5159 glossQ:0.2525 exploreP:0.0624\n",
      "Episode:366 meanR:165.4100 R:135.0000 rate:0.2700 gloss:0.6496 dloss:0.5322 glossQ:0.2550 exploreP:0.0617\n",
      "Episode:367 meanR:168.9900 R:487.0000 rate:0.9740 gloss:0.6475 dloss:0.5318 glossQ:0.2664 exploreP:0.0592\n",
      "Episode:368 meanR:170.9000 R:261.0000 rate:0.5220 gloss:0.6534 dloss:0.5033 glossQ:0.2615 exploreP:0.0580\n",
      "Episode:369 meanR:173.3900 R:334.0000 rate:0.6680 gloss:0.6510 dloss:0.5438 glossQ:0.2630 exploreP:0.0564\n",
      "Episode:370 meanR:174.0400 R:167.0000 rate:0.3340 gloss:0.6478 dloss:0.5322 glossQ:0.2702 exploreP:0.0556\n",
      "Episode:371 meanR:174.3400 R:153.0000 rate:0.3060 gloss:0.6434 dloss:0.5850 glossQ:0.2798 exploreP:0.0549\n",
      "Episode:372 meanR:174.8000 R:160.0000 rate:0.3200 gloss:0.6550 dloss:0.5472 glossQ:0.2890 exploreP:0.0542\n",
      "Episode:373 meanR:175.6500 R:187.0000 rate:0.3740 gloss:0.6541 dloss:0.5143 glossQ:0.2773 exploreP:0.0534\n",
      "Episode:374 meanR:176.3000 R:293.0000 rate:0.5860 gloss:0.6505 dloss:0.5396 glossQ:0.2809 exploreP:0.0522\n",
      "Episode:375 meanR:176.8200 R:162.0000 rate:0.3240 gloss:0.6571 dloss:0.5290 glossQ:0.2861 exploreP:0.0515\n",
      "Episode:376 meanR:178.2800 R:262.0000 rate:0.5240 gloss:0.6499 dloss:0.5625 glossQ:0.2872 exploreP:0.0504\n",
      "Episode:377 meanR:176.9200 R:99.0000 rate:0.1980 gloss:0.6562 dloss:0.5215 glossQ:0.2909 exploreP:0.0500\n",
      "Episode:378 meanR:179.2100 R:500.0000 rate:1.0000 gloss:0.6533 dloss:0.5292 glossQ:0.2839 exploreP:0.0481\n",
      "Episode:379 meanR:180.7100 R:315.0000 rate:0.6300 gloss:0.6511 dloss:0.5383 glossQ:0.2840 exploreP:0.0469\n",
      "Episode:380 meanR:181.6000 R:180.0000 rate:0.3600 gloss:0.6497 dloss:0.5414 glossQ:0.2820 exploreP:0.0462\n",
      "Episode:381 meanR:181.4600 R:106.0000 rate:0.2120 gloss:0.6558 dloss:0.5100 glossQ:0.2826 exploreP:0.0458\n",
      "Episode:382 meanR:183.2300 R:313.0000 rate:0.6260 gloss:0.6504 dloss:0.5490 glossQ:0.2785 exploreP:0.0447\n",
      "Episode:383 meanR:184.8000 R:250.0000 rate:0.5000 gloss:0.6461 dloss:0.5382 glossQ:0.2947 exploreP:0.0439\n",
      "Episode:384 meanR:188.1100 R:500.0000 rate:1.0000 gloss:0.6479 dloss:0.5419 glossQ:0.2877 exploreP:0.0422\n",
      "Episode:385 meanR:188.6400 R:130.0000 rate:0.2600 gloss:0.6356 dloss:0.5896 glossQ:0.2913 exploreP:0.0418\n",
      "Episode:386 meanR:188.7600 R:130.0000 rate:0.2600 gloss:0.6417 dloss:0.5740 glossQ:0.2981 exploreP:0.0414\n",
      "Episode:387 meanR:190.8400 R:324.0000 rate:0.6480 gloss:0.6485 dloss:0.5292 glossQ:0.2975 exploreP:0.0404\n",
      "Episode:388 meanR:192.5600 R:325.0000 rate:0.6500 gloss:0.6424 dloss:0.5676 glossQ:0.2988 exploreP:0.0394\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list = [], []\n",
    "# gloss_list, dloss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    for ep in range(1111*3):\n",
    "        total_reward = 0 # each episode\n",
    "        gloss_batch, dloss_batch, glossQ_batch = [], [], []\n",
    "        state = env.reset() # each episode\n",
    "        num_step = 0 # each episode\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "                action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            memory.rates.append(-1) # empty\n",
    "            num_step += 1 # momory added\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            # Rating the memory\n",
    "            if done is True:\n",
    "                rate = total_reward/500 # update rate at the end/ when episode is done\n",
    "                for idx in range(num_step): # episode length\n",
    "                    if memory.rates[-1-idx] == -1: # double-check the landmark/marked indexes\n",
    "                        memory.rates[-1-idx] = rate # rate the trajectory/data\n",
    "                        \n",
    "            # Training with the maxrated minibatch\n",
    "            batch = memory.buffer\n",
    "            percentage = 0.9\n",
    "            #for idx in range(memory_size// batch_size):\n",
    "            idx_arr = np.arange(memory_size// batch_size)\n",
    "            idx = np.random.choice(idx_arr)\n",
    "            states = np.array([each[0] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            actions = np.array([each[1] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            next_states = np.array([each[2] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rewards = np.array([each[3] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            dones = np.array([each[4] for each in batch])[idx*batch_size:(idx+1)*batch_size]\n",
    "            rates = np.array(memory.rates)[idx*batch_size:(idx+1)*batch_size]\n",
    "            #print(states.shape, actions.shape, next_states.shape, rewards.shape, dones.shape, rates.shape)\n",
    "            states = states[rates >= (np.max(rates)*percentage)]\n",
    "            actions = actions[rates >= (np.max(rates)*percentage)]\n",
    "            next_states = next_states[rates >= (np.max(rates)*percentage)]\n",
    "            rewards = rewards[rates >= (np.max(rates)*percentage)]\n",
    "            dones = dones[rates >= (np.max(rates)*percentage)]\n",
    "            rates = rates[rates >= (np.max(rates)*percentage)]\n",
    "            gloss, _, dloss, _ = sess.run([model.g_loss, model.g_opt, model.d_loss, model.d_opt], \n",
    "                                          feed_dict = {model.states: states, \n",
    "                                                       model.actions: actions,\n",
    "                                                       model.next_states: next_states,\n",
    "                                                       model.rewards: rewards,\n",
    "                                                       model.dones: dones, \n",
    "                                                       model.rates: rates})\n",
    "            glossQ, _ = sess.run([model.g_lossQ, model.g_optQ], feed_dict = {model.states: states, \n",
    "                                                                             model.actions: actions,\n",
    "                                                                             model.next_states: next_states,\n",
    "                                                                             model.rewards: rewards,\n",
    "                                                                             model.dones: dones, \n",
    "                                                                             model.rates: rates})\n",
    "            dloss_batch.append(dloss)\n",
    "            gloss_batch.append(gloss)\n",
    "            glossQ_batch.append(glossQ)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'rate:{:.4f}'.format(rate),\n",
    "              'gloss:{:.4f}'.format(np.mean(gloss_batch)),\n",
    "              'dloss:{:.4f}'.format(np.mean(dloss_batch)),\n",
    "              'glossQ:{:.4f}'.format(np.mean(glossQ_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        # gloss_list.append([ep, np.mean(gloss_batch)])\n",
    "        # dloss_list.append([ep, np.mean(dloss_batch)])\n",
    "        \n",
    "        # Break episode/epoch loop\n",
    "        ## Option 1: Solve the First Version\n",
    "        #The task is episodic, and in order to solve the environment, \n",
    "        #your agent must get an average score of +30 over 100 consecutive episodes.\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-a0b0af09d9f3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-a0b0af09d9f3>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    plt.ylabel('G losses')`\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "eps, arr = np.array(gloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(dloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print('total_reward: {}'.format(total_reward))\n",
    "                break\n",
    "                \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAQL for Acrobat\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(3,), Box(1,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = env.reset()\n",
    "# batch = []\n",
    "# for _ in range(1111):\n",
    "#     #env.render()\n",
    "#     action = env.action_space.sample()\n",
    "#     next_state, reward, done, _ = env.step(action) # take a random action\n",
    "#     batch.append([state, action, next_state, reward, float(done)])\n",
    "#     state = next_state\n",
    "#     if done:\n",
    "#         state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.], dtype=float32), array([-2.], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.high, env.action_space.low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size, action_size):\n",
    "    #states = tf.placeholder(tf.float32, [None, *state_shape], name='states')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.float32, [None, action_size], name='actions')\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_state')\n",
    "    rewards = tf.placeholder(tf.float32, [None], name='rewards')\n",
    "    dones = tf.placeholder(tf.float32, [None], name='dones')\n",
    "    return states, actions, next_states, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = act(s)\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False, trainable=True):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size, trainable=trainable)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training, trainable=trainable)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size, trainable=trainable)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training, trainable=trainable)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "                \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size, trainable=trainable)        \n",
    "        pred = tf.tanh(logits)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q = env(s, a)\n",
    "def discriminator(states, actions, state_size, action_size, hidden_size, reuse=False, alpha=0.1, training=False, \n",
    "                  trainable=True):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=action_size, trainable=trainable)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training, trainable=trainable)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        fused = tf.concat(axis=1, values=[nl1, actions])\n",
    "        h2 = tf.layers.dense(inputs=fused, units=hidden_size, trainable=trainable)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training, trainable=trainable)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "                \n",
    "        # Output layer\n",
    "        #next_states_logits = tf.layers.dense(inputs=nl2, units=state_size, trainable=trainable)        \n",
    "        logits = tf.layers.dense(inputs=nl2, units=1, trainable=trainable)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, state_size, gamma,\n",
    "               states, actions, next_states, rewards, dones):\n",
    "    #########################################################\n",
    "    actions_pred = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    #########################################\n",
    "    Qlogits = discriminator(actions=actions, states=states, hidden_size=hidden_size, \n",
    "                            action_size=action_size, state_size=state_size)\n",
    "    Qs = tf.reshape(Qlogits, shape=[-1])\n",
    "    print('Qs.shape, Qlogits.shape:', Qs.shape, Qlogits.shape)\n",
    "    ########################################\n",
    "    next_actions_pred = generator(states=next_states, hidden_size=hidden_size, action_size=action_size, \n",
    "                                  reuse=True)\n",
    "    nextQlogits = discriminator(actions=next_actions_pred, states=next_states, hidden_size=hidden_size,\n",
    "                                action_size=action_size, state_size=state_size, reuse=True)\n",
    "    nextQs = tf.reshape(nextQlogits, shape=[-1])\n",
    "    targetQs = rewards + (gamma * nextQs * (1-dones))\n",
    "    print('nextQlogits.shape, nextQs.shape, targetQs.shape:', nextQlogits.shape, nextQs.shape, targetQs.shape)\n",
    "    #loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    loss = tf.reduce_mean(tf.square(Qs - targetQs))\n",
    "    return actions_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizating/training/learning G & D\n",
    "def model_opt(loss, g_learning_rate, d_learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        g_opt = tf.train.AdamOptimizer(g_learning_rate).minimize(-loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(d_learning_rate).minimize(loss, var_list=d_vars)\n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, g_learning_rate, d_learning_rate, gamma):\n",
    "        \n",
    "        # Model inputs\n",
    "        self.states, self.actions, self.next_states, self.rewards, self.dones = model_input(\n",
    "            state_size=state_size, action_size=action_size)\n",
    "\n",
    "        # Model loss/objective\n",
    "        self.actions_pred, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, state_size=state_size, gamma=gamma,\n",
    "            states=self.states, actions=self.actions, next_states=self.next_states,\n",
    "            rewards=self.rewards, dones=self.dones)\n",
    "        \n",
    "        # Model optimization/update\n",
    "        self.g_opt, self.d_opt = model_opt(loss=self.loss,\n",
    "                                           g_learning_rate=g_learning_rate, \n",
    "                                           d_learning_rate=d_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(3,), Box(1,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01           # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 3\n",
    "action_size = 1\n",
    "hidden_size = 24*2             # number of units in each Q-network hidden layer\n",
    "g_learning_rate = 1e-4         # Q-network learning rate\n",
    "d_learning_rate = 1e-4         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = int(1e5)            # memory capacity\n",
    "batch_size = int(1e2)             # experience mini-batch size == one episode size is 1000/int(1e3) steps\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qs.shape, Qlogits.shape: (?,) (?, 1)\n",
      "nextQlogits.shape, nextQs.shape, targetQs.shape: (?, 1) (?,) (?,)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, state_size=state_size, hidden_size=hidden_size, gamma=gamma,\n",
    "              g_learning_rate=g_learning_rate, d_learning_rate=d_learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 8.], dtype=float32),\n",
       " array([-1., -1., -8.], dtype=float32),\n",
       " Box(3,),\n",
       " array([2.], dtype=float32),\n",
       " array([-2.], dtype=float32),\n",
       " Box(1,),\n",
       " (-inf, inf))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.high, env.observation_space.low, env.observation_space, \\\n",
    "env.action_space.high, env.action_space.low, env.action_space, \\\n",
    "env.reward_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00199\n",
      "Progress: 0.00399\n",
      "Progress: 0.00599\n",
      "Progress: 0.00799\n",
      "Progress: 0.00999\n",
      "Progress: 0.01199\n",
      "Progress: 0.01399\n",
      "Progress: 0.01599\n",
      "Progress: 0.01799\n",
      "Progress: 0.01999\n",
      "Progress: 0.02199\n",
      "Progress: 0.02399\n",
      "Progress: 0.02599\n",
      "Progress: 0.02799\n",
      "Progress: 0.02999\n",
      "Progress: 0.03199\n",
      "Progress: 0.03399\n",
      "Progress: 0.03599\n",
      "Progress: 0.03799\n",
      "Progress: 0.03999\n",
      "Progress: 0.04199\n",
      "Progress: 0.04399\n",
      "Progress: 0.04599\n",
      "Progress: 0.04799\n",
      "Progress: 0.04999\n",
      "Progress: 0.05199\n",
      "Progress: 0.05399\n",
      "Progress: 0.05599\n",
      "Progress: 0.05799\n",
      "Progress: 0.05999\n",
      "Progress: 0.06199\n",
      "Progress: 0.06399\n",
      "Progress: 0.06599\n",
      "Progress: 0.06799\n",
      "Progress: 0.06999\n",
      "Progress: 0.07199\n",
      "Progress: 0.07399\n",
      "Progress: 0.07599\n",
      "Progress: 0.07799\n",
      "Progress: 0.07999\n",
      "Progress: 0.08199\n",
      "Progress: 0.08399\n",
      "Progress: 0.08599\n",
      "Progress: 0.08799\n",
      "Progress: 0.08999\n",
      "Progress: 0.09199\n",
      "Progress: 0.09399\n",
      "Progress: 0.09599\n",
      "Progress: 0.09799\n",
      "Progress: 0.09999\n",
      "Progress: 0.10199\n",
      "Progress: 0.10399\n",
      "Progress: 0.10599\n",
      "Progress: 0.10799\n",
      "Progress: 0.10999\n",
      "Progress: 0.11199\n",
      "Progress: 0.11399\n",
      "Progress: 0.11599\n",
      "Progress: 0.11799\n",
      "Progress: 0.11999\n",
      "Progress: 0.12199\n",
      "Progress: 0.12399\n",
      "Progress: 0.12599\n",
      "Progress: 0.12799\n",
      "Progress: 0.12999\n",
      "Progress: 0.13199\n",
      "Progress: 0.13399\n",
      "Progress: 0.13599\n",
      "Progress: 0.13799\n",
      "Progress: 0.13999\n",
      "Progress: 0.14199\n",
      "Progress: 0.14399\n",
      "Progress: 0.14599\n",
      "Progress: 0.14799\n",
      "Progress: 0.14999\n",
      "Progress: 0.15199\n",
      "Progress: 0.15399\n",
      "Progress: 0.15599\n",
      "Progress: 0.15799\n",
      "Progress: 0.15999\n",
      "Progress: 0.16199\n",
      "Progress: 0.16399\n",
      "Progress: 0.16599\n",
      "Progress: 0.16799\n",
      "Progress: 0.16999\n",
      "Progress: 0.17199\n",
      "Progress: 0.17399\n",
      "Progress: 0.17599\n",
      "Progress: 0.17799\n",
      "Progress: 0.17999\n",
      "Progress: 0.18199\n",
      "Progress: 0.18399\n",
      "Progress: 0.18599\n",
      "Progress: 0.18799\n",
      "Progress: 0.18999\n",
      "Progress: 0.19199\n",
      "Progress: 0.19399\n",
      "Progress: 0.19599\n",
      "Progress: 0.19799\n",
      "Progress: 0.19999\n",
      "Progress: 0.20199\n",
      "Progress: 0.20399\n",
      "Progress: 0.20599\n",
      "Progress: 0.20799\n",
      "Progress: 0.20999\n",
      "Progress: 0.21199\n",
      "Progress: 0.21399\n",
      "Progress: 0.21599\n",
      "Progress: 0.21799\n",
      "Progress: 0.21999\n",
      "Progress: 0.22199\n",
      "Progress: 0.22399\n",
      "Progress: 0.22599\n",
      "Progress: 0.22799\n",
      "Progress: 0.22999\n",
      "Progress: 0.23199\n",
      "Progress: 0.23399\n",
      "Progress: 0.23599\n",
      "Progress: 0.23799\n",
      "Progress: 0.23999\n",
      "Progress: 0.24199\n",
      "Progress: 0.24399\n",
      "Progress: 0.24599\n",
      "Progress: 0.24799\n",
      "Progress: 0.24999\n",
      "Progress: 0.25199\n",
      "Progress: 0.25399\n",
      "Progress: 0.25599\n",
      "Progress: 0.25799\n",
      "Progress: 0.25999\n",
      "Progress: 0.26199\n",
      "Progress: 0.26399\n",
      "Progress: 0.26599\n",
      "Progress: 0.26799\n",
      "Progress: 0.26999\n",
      "Progress: 0.27199\n",
      "Progress: 0.27399\n",
      "Progress: 0.27599\n",
      "Progress: 0.27799\n",
      "Progress: 0.27999\n",
      "Progress: 0.28199\n",
      "Progress: 0.28399\n",
      "Progress: 0.28599\n",
      "Progress: 0.28799\n",
      "Progress: 0.28999\n",
      "Progress: 0.29199\n",
      "Progress: 0.29399\n",
      "Progress: 0.29599\n",
      "Progress: 0.29799\n",
      "Progress: 0.29999\n",
      "Progress: 0.30199\n",
      "Progress: 0.30399\n",
      "Progress: 0.30599\n",
      "Progress: 0.30799\n",
      "Progress: 0.30999\n",
      "Progress: 0.31199\n",
      "Progress: 0.31399\n",
      "Progress: 0.31599\n",
      "Progress: 0.31799\n",
      "Progress: 0.31999\n",
      "Progress: 0.32199\n",
      "Progress: 0.32399\n",
      "Progress: 0.32599\n",
      "Progress: 0.32799\n",
      "Progress: 0.32999\n",
      "Progress: 0.33199\n",
      "Progress: 0.33399\n",
      "Progress: 0.33599\n",
      "Progress: 0.33799\n",
      "Progress: 0.33999\n",
      "Progress: 0.34199\n",
      "Progress: 0.34399\n",
      "Progress: 0.34599\n",
      "Progress: 0.34799\n",
      "Progress: 0.34999\n",
      "Progress: 0.35199\n",
      "Progress: 0.35399\n",
      "Progress: 0.35599\n",
      "Progress: 0.35799\n",
      "Progress: 0.35999\n",
      "Progress: 0.36199\n",
      "Progress: 0.36399\n",
      "Progress: 0.36599\n",
      "Progress: 0.36799\n",
      "Progress: 0.36999\n",
      "Progress: 0.37199\n",
      "Progress: 0.37399\n",
      "Progress: 0.37599\n",
      "Progress: 0.37799\n",
      "Progress: 0.37999\n",
      "Progress: 0.38199\n",
      "Progress: 0.38399\n",
      "Progress: 0.38599\n",
      "Progress: 0.38799\n",
      "Progress: 0.38999\n",
      "Progress: 0.39199\n",
      "Progress: 0.39399\n",
      "Progress: 0.39599\n",
      "Progress: 0.39799\n",
      "Progress: 0.39999\n",
      "Progress: 0.40199\n",
      "Progress: 0.40399\n",
      "Progress: 0.40599\n",
      "Progress: 0.40799\n",
      "Progress: 0.40999\n",
      "Progress: 0.41199\n",
      "Progress: 0.41399\n",
      "Progress: 0.41599\n",
      "Progress: 0.41799\n",
      "Progress: 0.41999\n",
      "Progress: 0.42199\n",
      "Progress: 0.42399\n",
      "Progress: 0.42599\n",
      "Progress: 0.42799\n",
      "Progress: 0.42999\n",
      "Progress: 0.43199\n",
      "Progress: 0.43399\n",
      "Progress: 0.43599\n",
      "Progress: 0.43799\n",
      "Progress: 0.43999\n",
      "Progress: 0.44199\n",
      "Progress: 0.44399\n",
      "Progress: 0.44599\n",
      "Progress: 0.44799\n",
      "Progress: 0.44999\n",
      "Progress: 0.45199\n",
      "Progress: 0.45399\n",
      "Progress: 0.45599\n",
      "Progress: 0.45799\n",
      "Progress: 0.45999\n",
      "Progress: 0.46199\n",
      "Progress: 0.46399\n",
      "Progress: 0.46599\n",
      "Progress: 0.46799\n",
      "Progress: 0.46999\n",
      "Progress: 0.47199\n",
      "Progress: 0.47399\n",
      "Progress: 0.47599\n",
      "Progress: 0.47799\n",
      "Progress: 0.47999\n",
      "Progress: 0.48199\n",
      "Progress: 0.48399\n",
      "Progress: 0.48599\n",
      "Progress: 0.48799\n",
      "Progress: 0.48999\n",
      "Progress: 0.49199\n",
      "Progress: 0.49399\n",
      "Progress: 0.49599\n",
      "Progress: 0.49799\n",
      "Progress: 0.49999\n",
      "Progress: 0.50199\n",
      "Progress: 0.50399\n",
      "Progress: 0.50599\n",
      "Progress: 0.50799\n",
      "Progress: 0.50999\n",
      "Progress: 0.51199\n",
      "Progress: 0.51399\n",
      "Progress: 0.51599\n",
      "Progress: 0.51799\n",
      "Progress: 0.51999\n",
      "Progress: 0.52199\n",
      "Progress: 0.52399\n",
      "Progress: 0.52599\n",
      "Progress: 0.52799\n",
      "Progress: 0.52999\n",
      "Progress: 0.53199\n",
      "Progress: 0.53399\n",
      "Progress: 0.53599\n",
      "Progress: 0.53799\n",
      "Progress: 0.53999\n",
      "Progress: 0.54199\n",
      "Progress: 0.54399\n",
      "Progress: 0.54599\n",
      "Progress: 0.54799\n",
      "Progress: 0.54999\n",
      "Progress: 0.55199\n",
      "Progress: 0.55399\n",
      "Progress: 0.55599\n",
      "Progress: 0.55799\n",
      "Progress: 0.55999\n",
      "Progress: 0.56199\n",
      "Progress: 0.56399\n",
      "Progress: 0.56599\n",
      "Progress: 0.56799\n",
      "Progress: 0.56999\n",
      "Progress: 0.57199\n",
      "Progress: 0.57399\n",
      "Progress: 0.57599\n",
      "Progress: 0.57799\n",
      "Progress: 0.57999\n",
      "Progress: 0.58199\n",
      "Progress: 0.58399\n",
      "Progress: 0.58599\n",
      "Progress: 0.58799\n",
      "Progress: 0.58999\n",
      "Progress: 0.59199\n",
      "Progress: 0.59399\n",
      "Progress: 0.59599\n",
      "Progress: 0.59799\n",
      "Progress: 0.59999\n",
      "Progress: 0.60199\n",
      "Progress: 0.60399\n",
      "Progress: 0.60599\n",
      "Progress: 0.60799\n",
      "Progress: 0.60999\n",
      "Progress: 0.61199\n",
      "Progress: 0.61399\n",
      "Progress: 0.61599\n",
      "Progress: 0.61799\n",
      "Progress: 0.61999\n",
      "Progress: 0.62199\n",
      "Progress: 0.62399\n",
      "Progress: 0.62599\n",
      "Progress: 0.62799\n",
      "Progress: 0.62999\n",
      "Progress: 0.63199\n",
      "Progress: 0.63399\n",
      "Progress: 0.63599\n",
      "Progress: 0.63799\n",
      "Progress: 0.63999\n",
      "Progress: 0.64199\n",
      "Progress: 0.64399\n",
      "Progress: 0.64599\n",
      "Progress: 0.64799\n",
      "Progress: 0.64999\n",
      "Progress: 0.65199\n",
      "Progress: 0.65399\n",
      "Progress: 0.65599\n",
      "Progress: 0.65799\n",
      "Progress: 0.65999\n",
      "Progress: 0.66199\n",
      "Progress: 0.66399\n",
      "Progress: 0.66599\n",
      "Progress: 0.66799\n",
      "Progress: 0.66999\n",
      "Progress: 0.67199\n",
      "Progress: 0.67399\n",
      "Progress: 0.67599\n",
      "Progress: 0.67799\n",
      "Progress: 0.67999\n",
      "Progress: 0.68199\n",
      "Progress: 0.68399\n",
      "Progress: 0.68599\n",
      "Progress: 0.68799\n",
      "Progress: 0.68999\n",
      "Progress: 0.69199\n",
      "Progress: 0.69399\n",
      "Progress: 0.69599\n",
      "Progress: 0.69799\n",
      "Progress: 0.69999\n",
      "Progress: 0.70199\n",
      "Progress: 0.70399\n",
      "Progress: 0.70599\n",
      "Progress: 0.70799\n",
      "Progress: 0.70999\n",
      "Progress: 0.71199\n",
      "Progress: 0.71399\n",
      "Progress: 0.71599\n",
      "Progress: 0.71799\n",
      "Progress: 0.71999\n",
      "Progress: 0.72199\n",
      "Progress: 0.72399\n",
      "Progress: 0.72599\n",
      "Progress: 0.72799\n",
      "Progress: 0.72999\n",
      "Progress: 0.73199\n",
      "Progress: 0.73399\n",
      "Progress: 0.73599\n",
      "Progress: 0.73799\n",
      "Progress: 0.73999\n",
      "Progress: 0.74199\n",
      "Progress: 0.74399\n",
      "Progress: 0.74599\n",
      "Progress: 0.74799\n",
      "Progress: 0.74999\n",
      "Progress: 0.75199\n",
      "Progress: 0.75399\n",
      "Progress: 0.75599\n",
      "Progress: 0.75799\n",
      "Progress: 0.75999\n",
      "Progress: 0.76199\n",
      "Progress: 0.76399\n",
      "Progress: 0.76599\n",
      "Progress: 0.76799\n",
      "Progress: 0.76999\n",
      "Progress: 0.77199\n",
      "Progress: 0.77399\n",
      "Progress: 0.77599\n",
      "Progress: 0.77799\n",
      "Progress: 0.77999\n",
      "Progress: 0.78199\n",
      "Progress: 0.78399\n",
      "Progress: 0.78599\n",
      "Progress: 0.78799\n",
      "Progress: 0.78999\n",
      "Progress: 0.79199\n",
      "Progress: 0.79399\n",
      "Progress: 0.79599\n",
      "Progress: 0.79799\n",
      "Progress: 0.79999\n",
      "Progress: 0.80199\n",
      "Progress: 0.80399\n",
      "Progress: 0.80599\n",
      "Progress: 0.80799\n",
      "Progress: 0.80999\n",
      "Progress: 0.81199\n",
      "Progress: 0.81399\n",
      "Progress: 0.81599\n",
      "Progress: 0.81799\n",
      "Progress: 0.81999\n",
      "Progress: 0.82199\n",
      "Progress: 0.82399\n",
      "Progress: 0.82599\n",
      "Progress: 0.82799\n",
      "Progress: 0.82999\n",
      "Progress: 0.83199\n",
      "Progress: 0.83399\n",
      "Progress: 0.83599\n",
      "Progress: 0.83799\n",
      "Progress: 0.83999\n",
      "Progress: 0.84199\n",
      "Progress: 0.84399\n",
      "Progress: 0.84599\n",
      "Progress: 0.84799\n",
      "Progress: 0.84999\n",
      "Progress: 0.85199\n",
      "Progress: 0.85399\n",
      "Progress: 0.85599\n",
      "Progress: 0.85799\n",
      "Progress: 0.85999\n",
      "Progress: 0.86199\n",
      "Progress: 0.86399\n",
      "Progress: 0.86599\n",
      "Progress: 0.86799\n",
      "Progress: 0.86999\n",
      "Progress: 0.87199\n",
      "Progress: 0.87399\n",
      "Progress: 0.87599\n",
      "Progress: 0.87799\n",
      "Progress: 0.87999\n",
      "Progress: 0.88199\n",
      "Progress: 0.88399\n",
      "Progress: 0.88599\n",
      "Progress: 0.88799\n",
      "Progress: 0.88999\n",
      "Progress: 0.89199\n",
      "Progress: 0.89399\n",
      "Progress: 0.89599\n",
      "Progress: 0.89799\n",
      "Progress: 0.89999\n",
      "Progress: 0.90199\n",
      "Progress: 0.90399\n",
      "Progress: 0.90599\n",
      "Progress: 0.90799\n",
      "Progress: 0.90999\n",
      "Progress: 0.91199\n",
      "Progress: 0.91399\n",
      "Progress: 0.91599\n",
      "Progress: 0.91799\n",
      "Progress: 0.91999\n",
      "Progress: 0.92199\n",
      "Progress: 0.92399\n",
      "Progress: 0.92599\n",
      "Progress: 0.92799\n",
      "Progress: 0.92999\n",
      "Progress: 0.93199\n",
      "Progress: 0.93399\n",
      "Progress: 0.93599\n",
      "Progress: 0.93799\n",
      "Progress: 0.93999\n",
      "Progress: 0.94199\n",
      "Progress: 0.94399\n",
      "Progress: 0.94599\n",
      "Progress: 0.94799\n",
      "Progress: 0.94999\n",
      "Progress: 0.95199\n",
      "Progress: 0.95399\n",
      "Progress: 0.95599\n",
      "Progress: 0.95799\n",
      "Progress: 0.95999\n",
      "Progress: 0.96199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.96399\n",
      "Progress: 0.96599\n",
      "Progress: 0.96799\n",
      "Progress: 0.96999\n",
      "Progress: 0.97199\n",
      "Progress: 0.97399\n",
      "Progress: 0.97599\n",
      "Progress: 0.97799\n",
      "Progress: 0.97999\n",
      "Progress: 0.98199\n",
      "Progress: 0.98399\n",
      "Progress: 0.98599\n",
      "Progress: 0.98799\n",
      "Progress: 0.98999\n",
      "Progress: 0.99199\n",
      "Progress: 0.99399\n",
      "Progress: 0.99599\n",
      "Progress: 0.99799\n",
      "Progress: 0.99999\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "for each_step in range(memory_size):\n",
    "    #env.render()\n",
    "\n",
    "    action = env.action_space.sample() # randomness\n",
    "    action = np.clip(action, -2, 2) # clipped: [-2, +2]\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    state = next_state\n",
    "    \n",
    "    if done is True:\n",
    "        print('Progress:', each_step/memory_size)\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory.buffer), memory.buffer.maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:-1558.3876 R:-1558.3876 gloss:-49.8854 dloss:49.8854\n",
      "Episode:1 meanR:-1632.8479 R:-1707.3081 gloss:-50.1747 dloss:50.1747\n",
      "Episode:2 meanR:-1519.8231 R:-1293.7735 gloss:-50.1909 dloss:50.1909\n",
      "Episode:3 meanR:-1535.0705 R:-1580.8129 gloss:-48.3300 dloss:48.3300\n",
      "Episode:4 meanR:-1464.3175 R:-1181.3053 gloss:-51.1917 dloss:51.1917\n",
      "Episode:5 meanR:-1493.8941 R:-1641.7769 gloss:-47.2204 dloss:47.2204\n",
      "Episode:6 meanR:-1472.8032 R:-1346.2581 gloss:-42.5222 dloss:42.5222\n",
      "Episode:7 meanR:-1450.7133 R:-1296.0842 gloss:-41.3973 dloss:41.3973\n",
      "Episode:8 meanR:-1487.5449 R:-1782.1978 gloss:-58.6790 dloss:58.6790\n",
      "Episode:9 meanR:-1466.7998 R:-1280.0934 gloss:-54.1786 dloss:54.1786\n",
      "Episode:10 meanR:-1439.7472 R:-1169.2217 gloss:-48.9611 dloss:48.9611\n",
      "Episode:11 meanR:-1435.9749 R:-1394.4797 gloss:-44.0393 dloss:44.0393\n",
      "Episode:12 meanR:-1433.5880 R:-1404.9442 gloss:-40.1840 dloss:40.1840\n",
      "Episode:13 meanR:-1425.7067 R:-1323.2499 gloss:-37.1215 dloss:37.1215\n",
      "Episode:14 meanR:-1416.3577 R:-1285.4726 gloss:-35.0232 dloss:35.0232\n",
      "Episode:15 meanR:-1440.6685 R:-1805.3301 gloss:-57.4870 dloss:57.4870\n",
      "Episode:16 meanR:-1435.7528 R:-1357.1011 gloss:-62.9912 dloss:62.9912\n",
      "Episode:17 meanR:-1451.1619 R:-1713.1163 gloss:-53.3055 dloss:53.3055\n",
      "Episode:18 meanR:-1435.6597 R:-1156.6205 gloss:-46.3837 dloss:46.3837\n",
      "Episode:19 meanR:-1427.8967 R:-1280.4007 gloss:-41.6006 dloss:41.6006\n",
      "Episode:20 meanR:-1428.2985 R:-1436.3345 gloss:-37.9363 dloss:37.9363\n",
      "Episode:21 meanR:-1425.6535 R:-1370.1072 gloss:-34.4283 dloss:34.4283\n",
      "Episode:22 meanR:-1439.6955 R:-1748.6205 gloss:-33.3962 dloss:33.3962\n",
      "Episode:23 meanR:-1435.9658 R:-1350.1830 gloss:-33.0432 dloss:33.0432\n",
      "Episode:24 meanR:-1428.4860 R:-1248.9699 gloss:-59.5124 dloss:59.5124\n",
      "Episode:25 meanR:-1422.6668 R:-1277.1880 gloss:-62.4479 dloss:62.4479\n",
      "Episode:26 meanR:-1401.8333 R:-860.1625 gloss:-51.1627 dloss:51.1627\n",
      "Episode:27 meanR:-1394.6985 R:-1202.0592 gloss:-43.1788 dloss:43.1788\n",
      "Episode:28 meanR:-1399.6607 R:-1538.5997 gloss:-37.1161 dloss:37.1161\n",
      "Episode:29 meanR:-1387.4340 R:-1032.8619 gloss:-33.6874 dloss:33.6874\n",
      "Episode:30 meanR:-1376.8366 R:-1058.9152 gloss:-31.5946 dloss:31.5946\n",
      "Episode:31 meanR:-1373.8721 R:-1281.9714 gloss:-30.0950 dloss:30.0950\n",
      "Episode:32 meanR:-1361.2181 R:-956.2908 gloss:-29.5773 dloss:29.5773\n",
      "Episode:33 meanR:-1356.2134 R:-1191.0559 gloss:-37.7931 dloss:37.7931\n",
      "Episode:34 meanR:-1352.6832 R:-1232.6564 gloss:-68.3067 dloss:68.3067\n",
      "Episode:35 meanR:-1353.8813 R:-1395.8166 gloss:-54.4156 dloss:54.4156\n",
      "Episode:36 meanR:-1364.4745 R:-1745.8278 gloss:-44.5068 dloss:44.5068\n",
      "Episode:37 meanR:-1374.3906 R:-1741.2865 gloss:-37.4675 dloss:37.4675\n",
      "Episode:38 meanR:-1368.9518 R:-1162.2777 gloss:-34.4470 dloss:34.4470\n",
      "Episode:39 meanR:-1370.9385 R:-1448.4211 gloss:-32.1185 dloss:32.1185\n",
      "Episode:40 meanR:-1370.6137 R:-1357.6224 gloss:-32.9472 dloss:32.9472\n",
      "Episode:41 meanR:-1365.4516 R:-1153.8057 gloss:-60.6690 dloss:60.6690\n",
      "Episode:42 meanR:-1368.9840 R:-1517.3450 gloss:-52.9363 dloss:52.9363\n",
      "Episode:43 meanR:-1369.0276 R:-1370.9025 gloss:-42.1057 dloss:42.1057\n",
      "Episode:44 meanR:-1362.2538 R:-1064.2066 gloss:-34.7845 dloss:34.7845\n",
      "Episode:45 meanR:-1367.2101 R:-1590.2414 gloss:-30.7210 dloss:30.7210\n",
      "Episode:46 meanR:-1367.2843 R:-1370.6963 gloss:-29.6894 dloss:29.6894\n",
      "Episode:47 meanR:-1368.4575 R:-1423.5985 gloss:-30.9432 dloss:30.9432\n",
      "Episode:48 meanR:-1370.0407 R:-1446.0371 gloss:-56.3569 dloss:56.3569\n",
      "Episode:49 meanR:-1374.6366 R:-1599.8329 gloss:-56.0478 dloss:56.0478\n",
      "Episode:50 meanR:-1376.1709 R:-1452.8864 gloss:-43.3001 dloss:43.3001\n",
      "Episode:51 meanR:-1375.5278 R:-1342.7280 gloss:-36.6817 dloss:36.6817\n",
      "Episode:52 meanR:-1379.7239 R:-1597.9234 gloss:-32.9241 dloss:32.9241\n",
      "Episode:53 meanR:-1381.6340 R:-1482.8717 gloss:-43.6579 dloss:43.6579\n",
      "Episode:54 meanR:-1380.3646 R:-1311.8145 gloss:-53.9862 dloss:53.9862\n",
      "Episode:55 meanR:-1379.3498 R:-1323.5364 gloss:-42.5340 dloss:42.5340\n",
      "Episode:56 meanR:-1379.8888 R:-1410.0698 gloss:-36.6578 dloss:36.6578\n",
      "Episode:57 meanR:-1378.7165 R:-1311.8979 gloss:-41.9540 dloss:41.9540\n",
      "Episode:58 meanR:-1377.5641 R:-1310.7273 gloss:-45.3786 dloss:45.3786\n",
      "Episode:59 meanR:-1375.3291 R:-1243.4630 gloss:-46.3950 dloss:46.3950\n",
      "Episode:60 meanR:-1374.7293 R:-1338.7391 gloss:-40.8517 dloss:40.8517\n",
      "Episode:61 meanR:-1373.2804 R:-1284.9000 gloss:-41.5870 dloss:41.5870\n",
      "Episode:62 meanR:-1372.6526 R:-1333.7286 gloss:-46.2198 dloss:46.2198\n",
      "Episode:63 meanR:-1372.1604 R:-1341.1529 gloss:-41.8304 dloss:41.8304\n",
      "Episode:64 meanR:-1366.0099 R:-972.3787 gloss:-43.5296 dloss:43.5296\n",
      "Episode:65 meanR:-1362.5239 R:-1135.9311 gloss:-43.0614 dloss:43.0614\n",
      "Episode:66 meanR:-1360.6842 R:-1239.2669 gloss:-40.4463 dloss:40.4463\n",
      "Episode:67 meanR:-1357.2645 R:-1128.1427 gloss:-42.8443 dloss:42.8443\n",
      "Episode:68 meanR:-1356.7714 R:-1323.2424 gloss:-43.1891 dloss:43.1891\n",
      "Episode:69 meanR:-1356.2452 R:-1319.9335 gloss:-42.0952 dloss:42.0952\n",
      "Episode:70 meanR:-1355.9931 R:-1338.3498 gloss:-41.7708 dloss:41.7708\n",
      "Episode:71 meanR:-1356.1540 R:-1367.5784 gloss:-41.6682 dloss:41.6682\n",
      "Episode:72 meanR:-1355.9328 R:-1340.0065 gloss:-41.5905 dloss:41.5905\n",
      "Episode:73 meanR:-1351.2222 R:-1007.3445 gloss:-41.9766 dloss:41.9766\n",
      "Episode:74 meanR:-1346.9836 R:-1033.3260 gloss:-41.4276 dloss:41.4276\n",
      "Episode:75 meanR:-1342.0091 R:-968.9204 gloss:-40.8761 dloss:40.8761\n",
      "Episode:76 meanR:-1342.7358 R:-1397.9715 gloss:-40.9823 dloss:40.9823\n",
      "Episode:77 meanR:-1342.7854 R:-1346.5985 gloss:-40.8663 dloss:40.8663\n",
      "Episode:78 meanR:-1343.9406 R:-1434.0490 gloss:-40.2576 dloss:40.2576\n",
      "Episode:79 meanR:-1341.8863 R:-1179.5921 gloss:-39.9847 dloss:39.9847\n",
      "Episode:80 meanR:-1337.3488 R:-974.3521 gloss:-39.6469 dloss:39.6469\n",
      "Episode:81 meanR:-1334.7560 R:-1124.7412 gloss:-39.6617 dloss:39.6617\n",
      "Episode:82 meanR:-1334.9895 R:-1354.1329 gloss:-39.1757 dloss:39.1757\n",
      "Episode:83 meanR:-1335.1969 R:-1352.4165 gloss:-39.2540 dloss:39.2540\n",
      "Episode:84 meanR:-1335.1582 R:-1331.9074 gloss:-38.2745 dloss:38.2745\n",
      "Episode:85 meanR:-1331.9305 R:-1057.5752 gloss:-38.6612 dloss:38.6612\n",
      "Episode:86 meanR:-1327.8663 R:-978.3405 gloss:-38.7980 dloss:38.7980\n",
      "Episode:87 meanR:-1325.1205 R:-1086.2391 gloss:-37.8336 dloss:37.8336\n",
      "Episode:88 meanR:-1325.4333 R:-1352.9629 gloss:-37.9524 dloss:37.9524\n",
      "Episode:89 meanR:-1326.0627 R:-1382.0791 gloss:-37.7366 dloss:37.7366\n",
      "Episode:90 meanR:-1323.6755 R:-1108.8278 gloss:-37.1993 dloss:37.1993\n",
      "Episode:91 meanR:-1323.1627 R:-1276.4941 gloss:-37.3084 dloss:37.3084\n",
      "Episode:92 meanR:-1320.5688 R:-1081.9313 gloss:-36.8434 dloss:36.8434\n",
      "Episode:93 meanR:-1322.1985 R:-1473.7599 gloss:-36.4297 dloss:36.4297\n",
      "Episode:94 meanR:-1322.5696 R:-1357.4473 gloss:-36.2188 dloss:36.2188\n",
      "Episode:95 meanR:-1322.9704 R:-1361.0472 gloss:-36.4144 dloss:36.4144\n",
      "Episode:96 meanR:-1323.4969 R:-1374.0487 gloss:-36.4816 dloss:36.4816\n",
      "Episode:97 meanR:-1322.6997 R:-1245.3666 gloss:-36.1829 dloss:36.1829\n",
      "Episode:98 meanR:-1319.7211 R:-1027.8231 gloss:-36.4720 dloss:36.4720\n",
      "Episode:99 meanR:-1319.2960 R:-1277.2065 gloss:-36.1456 dloss:36.1456\n",
      "Episode:100 meanR:-1317.0366 R:-1332.4451 gloss:-36.0304 dloss:36.0304\n",
      "Episode:101 meanR:-1313.2439 R:-1328.0370 gloss:-35.7402 dloss:35.7402\n",
      "Episode:102 meanR:-1313.7029 R:-1339.6818 gloss:-35.5595 dloss:35.5595\n",
      "Episode:103 meanR:-1310.8655 R:-1297.0722 gloss:-35.5960 dloss:35.5960\n",
      "Episode:104 meanR:-1317.9134 R:-1886.0945 gloss:-35.7137 dloss:35.7137\n",
      "Episode:105 meanR:-1314.5264 R:-1303.0719 gloss:-35.1204 dloss:35.1204\n",
      "Episode:106 meanR:-1313.5513 R:-1248.7526 gloss:-35.8162 dloss:35.8162\n",
      "Episode:107 meanR:-1313.2210 R:-1263.0532 gloss:-35.6050 dloss:35.6050\n",
      "Episode:108 meanR:-1308.4168 R:-1301.7780 gloss:-35.1629 dloss:35.1629\n",
      "Episode:109 meanR:-1305.7338 R:-1011.7963 gloss:-35.1702 dloss:35.1702\n",
      "Episode:110 meanR:-1307.3794 R:-1333.7727 gloss:-35.3945 dloss:35.3945\n",
      "Episode:111 meanR:-1306.5433 R:-1310.8767 gloss:-35.1625 dloss:35.1625\n",
      "Episode:112 meanR:-1304.4122 R:-1191.8275 gloss:-35.1374 dloss:35.1374\n",
      "Episode:113 meanR:-1308.1222 R:-1694.2506 gloss:-35.2926 dloss:35.2926\n",
      "Episode:114 meanR:-1308.9147 R:-1364.7236 gloss:-35.2769 dloss:35.2769\n",
      "Episode:115 meanR:-1302.0056 R:-1114.4265 gloss:-34.9694 dloss:34.9694\n",
      "Episode:116 meanR:-1300.8160 R:-1238.1385 gloss:-34.7809 dloss:34.7809\n",
      "Episode:117 meanR:-1294.7090 R:-1102.4167 gloss:-35.3512 dloss:35.3512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:118 meanR:-1294.6625 R:-1151.9733 gloss:-35.4804 dloss:35.4804\n",
      "Episode:119 meanR:-1292.3909 R:-1053.2319 gloss:-34.5654 dloss:34.5654\n",
      "Episode:120 meanR:-1291.3490 R:-1332.1465 gloss:-34.6424 dloss:34.6424\n",
      "Episode:121 meanR:-1291.1471 R:-1349.9150 gloss:-34.7134 dloss:34.7134\n",
      "Episode:122 meanR:-1284.2550 R:-1059.4173 gloss:-34.5392 dloss:34.5392\n",
      "Episode:123 meanR:-1285.1899 R:-1443.6753 gloss:-34.9497 dloss:34.9497\n",
      "Episode:124 meanR:-1286.3049 R:-1360.4665 gloss:-35.1007 dloss:35.1007\n",
      "Episode:125 meanR:-1286.6023 R:-1306.9252 gloss:-34.8189 dloss:34.8189\n",
      "Episode:126 meanR:-1288.3378 R:-1033.7160 gloss:-34.3138 dloss:34.3138\n",
      "Episode:127 meanR:-1289.6808 R:-1336.3527 gloss:-34.9979 dloss:34.9979\n",
      "Episode:128 meanR:-1286.0321 R:-1173.7377 gloss:-34.7754 dloss:34.7754\n",
      "Episode:129 meanR:-1288.0332 R:-1232.9721 gloss:-34.4988 dloss:34.4988\n",
      "Episode:130 meanR:-1289.1510 R:-1170.6898 gloss:-34.2318 dloss:34.2318\n",
      "Episode:131 meanR:-1292.0815 R:-1575.0262 gloss:-35.0103 dloss:35.0103\n",
      "Episode:132 meanR:-1296.0522 R:-1353.3578 gloss:-35.1046 dloss:35.1046\n",
      "Episode:133 meanR:-1296.5368 R:-1239.5183 gloss:-34.8987 dloss:34.8987\n",
      "Episode:134 meanR:-1295.9404 R:-1173.0165 gloss:-34.2076 dloss:34.2076\n",
      "Episode:135 meanR:-1296.4228 R:-1444.0511 gloss:-34.6182 dloss:34.6182\n",
      "Episode:136 meanR:-1292.3659 R:-1340.1431 gloss:-35.0152 dloss:35.0152\n",
      "Episode:137 meanR:-1288.3202 R:-1336.7166 gloss:-34.8241 dloss:34.8241\n",
      "Episode:138 meanR:-1287.5428 R:-1084.5351 gloss:-34.3806 dloss:34.3806\n",
      "Episode:139 meanR:-1286.7296 R:-1367.1059 gloss:-34.6239 dloss:34.6239\n",
      "Episode:140 meanR:-1286.5597 R:-1340.6235 gloss:-34.5484 dloss:34.5484\n",
      "Episode:141 meanR:-1288.3262 R:-1330.4618 gloss:-34.2250 dloss:34.2250\n",
      "Episode:142 meanR:-1284.2812 R:-1112.8474 gloss:-34.4423 dloss:34.4423\n",
      "Episode:143 meanR:-1283.0463 R:-1247.4131 gloss:-34.3918 dloss:34.3918\n",
      "Episode:144 meanR:-1286.1020 R:-1369.7696 gloss:-34.1725 dloss:34.1725\n",
      "Episode:145 meanR:-1283.6084 R:-1340.8821 gloss:-34.5508 dloss:34.5508\n",
      "Episode:146 meanR:-1283.2136 R:-1331.2151 gloss:-34.5146 dloss:34.5146\n",
      "Episode:147 meanR:-1282.6755 R:-1369.7907 gloss:-34.5137 dloss:34.5137\n",
      "Episode:148 meanR:-1281.7331 R:-1351.7942 gloss:-34.3870 dloss:34.3870\n",
      "Episode:149 meanR:-1277.7874 R:-1205.2663 gloss:-34.9728 dloss:34.9728\n",
      "Episode:150 meanR:-1275.9956 R:-1273.7021 gloss:-34.5649 dloss:34.5649\n",
      "Episode:151 meanR:-1273.5355 R:-1096.7183 gloss:-34.3671 dloss:34.3671\n",
      "Episode:152 meanR:-1270.9987 R:-1344.2502 gloss:-34.2164 dloss:34.2164\n",
      "Episode:153 meanR:-1268.5022 R:-1233.2177 gloss:-34.2981 dloss:34.2981\n",
      "Episode:154 meanR:-1271.1715 R:-1578.7421 gloss:-34.2271 dloss:34.2271\n",
      "Episode:155 meanR:-1271.4141 R:-1347.8047 gloss:-34.2270 dloss:34.2270\n",
      "Episode:156 meanR:-1268.4296 R:-1111.6173 gloss:-34.5806 dloss:34.5806\n",
      "Episode:157 meanR:-1271.0526 R:-1574.1947 gloss:-34.0307 dloss:34.0307\n",
      "Episode:158 meanR:-1271.5390 R:-1359.3707 gloss:-34.0345 dloss:34.0345\n",
      "Episode:159 meanR:-1272.6906 R:-1358.6240 gloss:-34.5098 dloss:34.5098\n",
      "Episode:160 meanR:-1271.9633 R:-1266.0101 gloss:-34.0564 dloss:34.0564\n",
      "Episode:161 meanR:-1272.6226 R:-1350.8306 gloss:-34.4788 dloss:34.4788\n",
      "Episode:162 meanR:-1272.5749 R:-1328.9579 gloss:-34.3474 dloss:34.3474\n",
      "Episode:163 meanR:-1271.5530 R:-1238.9628 gloss:-34.1014 dloss:34.1014\n",
      "Episode:164 meanR:-1274.1153 R:-1228.6085 gloss:-34.2678 dloss:34.2678\n",
      "Episode:165 meanR:-1276.2049 R:-1344.8907 gloss:-34.2551 dloss:34.2551\n",
      "Episode:166 meanR:-1277.2885 R:-1347.6283 gloss:-34.3666 dloss:34.3666\n",
      "Episode:167 meanR:-1279.3038 R:-1329.6715 gloss:-34.0208 dloss:34.0208\n",
      "Episode:168 meanR:-1279.6341 R:-1356.2704 gloss:-34.2858 dloss:34.2858\n",
      "Episode:169 meanR:-1279.7088 R:-1327.3974 gloss:-34.4417 dloss:34.4417\n",
      "Episode:170 meanR:-1279.5407 R:-1321.5448 gloss:-34.4315 dloss:34.4315\n",
      "Episode:171 meanR:-1279.2790 R:-1341.4065 gloss:-34.4533 dloss:34.4533\n",
      "Episode:172 meanR:-1279.3375 R:-1345.8553 gloss:-33.9924 dloss:33.9924\n",
      "Episode:173 meanR:-1282.9677 R:-1370.3641 gloss:-34.2540 dloss:34.2540\n",
      "Episode:174 meanR:-1288.8502 R:-1621.5751 gloss:-34.6311 dloss:34.6311\n",
      "Episode:175 meanR:-1292.6882 R:-1352.7233 gloss:-34.5680 dloss:34.5680\n",
      "Episode:176 meanR:-1288.5584 R:-984.9923 gloss:-34.2800 dloss:34.2800\n",
      "Episode:177 meanR:-1288.7850 R:-1369.2616 gloss:-34.4106 dloss:34.4106\n",
      "Episode:178 meanR:-1285.5128 R:-1106.8279 gloss:-34.8684 dloss:34.8684\n",
      "Episode:179 meanR:-1287.0610 R:-1334.4076 gloss:-34.6142 dloss:34.6142\n",
      "Episode:180 meanR:-1291.1052 R:-1378.7728 gloss:-34.4863 dloss:34.4863\n",
      "Episode:181 meanR:-1293.6263 R:-1376.8511 gloss:-34.0483 dloss:34.0483\n",
      "Episode:182 meanR:-1292.7891 R:-1270.4164 gloss:-34.2795 dloss:34.2795\n",
      "Episode:183 meanR:-1292.5908 R:-1332.5875 gloss:-34.4948 dloss:34.4948\n",
      "Episode:184 meanR:-1298.5171 R:-1924.5373 gloss:-34.2304 dloss:34.2304\n",
      "Episode:185 meanR:-1301.2312 R:-1328.9824 gloss:-34.5693 dloss:34.5693\n",
      "Episode:186 meanR:-1302.3008 R:-1085.3057 gloss:-34.5065 dloss:34.5065\n",
      "Episode:187 meanR:-1303.8869 R:-1244.8430 gloss:-34.2070 dloss:34.2070\n",
      "Episode:188 meanR:-1299.6958 R:-933.8579 gloss:-34.5854 dloss:34.5854\n",
      "Episode:189 meanR:-1299.5104 R:-1363.5323 gloss:-34.3869 dloss:34.3869\n",
      "Episode:190 meanR:-1297.6145 R:-919.2393 gloss:-34.8306 dloss:34.8306\n",
      "Episode:191 meanR:-1295.6497 R:-1080.0148 gloss:-34.3268 dloss:34.3268\n",
      "Episode:192 meanR:-1296.9252 R:-1209.4802 gloss:-34.3454 dloss:34.3454\n",
      "Episode:193 meanR:-1299.3337 R:-1714.6156 gloss:-34.7180 dloss:34.7180\n",
      "Episode:194 meanR:-1299.4768 R:-1371.7587 gloss:-34.5662 dloss:34.5662\n",
      "Episode:195 meanR:-1299.2596 R:-1339.3199 gloss:-34.6408 dloss:34.6408\n",
      "Episode:196 meanR:-1299.1140 R:-1359.4905 gloss:-34.6164 dloss:34.6164\n",
      "Episode:197 meanR:-1299.3446 R:-1268.4281 gloss:-34.3546 dloss:34.3546\n",
      "Episode:198 meanR:-1302.4513 R:-1338.4940 gloss:-34.5533 dloss:34.5533\n",
      "Episode:199 meanR:-1302.4362 R:-1275.6998 gloss:-35.1186 dloss:35.1186\n",
      "Episode:200 meanR:-1302.7298 R:-1361.8045 gloss:-35.3540 dloss:35.3540\n",
      "Episode:201 meanR:-1301.6465 R:-1219.6986 gloss:-35.1755 dloss:35.1755\n",
      "Episode:202 meanR:-1301.5050 R:-1325.5320 gloss:-34.5164 dloss:34.5164\n",
      "Episode:203 meanR:-1300.4634 R:-1192.9146 gloss:-34.4122 dloss:34.4122\n",
      "Episode:204 meanR:-1294.7080 R:-1310.5580 gloss:-34.8465 dloss:34.8465\n",
      "Episode:205 meanR:-1294.8558 R:-1317.8491 gloss:-34.7421 dloss:34.7421\n",
      "Episode:206 meanR:-1295.9270 R:-1355.8689 gloss:-34.9937 dloss:34.9937\n",
      "Episode:207 meanR:-1297.7394 R:-1444.2949 gloss:-34.8402 dloss:34.8402\n",
      "Episode:208 meanR:-1298.3087 R:-1358.7072 gloss:-34.8894 dloss:34.8894\n",
      "Episode:209 meanR:-1301.7713 R:-1358.0564 gloss:-34.8644 dloss:34.8644\n",
      "Episode:210 meanR:-1304.8198 R:-1638.6294 gloss:-34.7822 dloss:34.7822\n",
      "Episode:211 meanR:-1304.0741 R:-1236.3049 gloss:-34.7661 dloss:34.7661\n",
      "Episode:212 meanR:-1302.5237 R:-1036.7888 gloss:-34.7934 dloss:34.7934\n",
      "Episode:213 meanR:-1298.8365 R:-1325.5246 gloss:-34.9863 dloss:34.9863\n",
      "Episode:214 meanR:-1297.0175 R:-1182.8292 gloss:-35.0190 dloss:35.0190\n",
      "Episode:215 meanR:-1298.3551 R:-1248.1882 gloss:-35.5181 dloss:35.5181\n",
      "Episode:216 meanR:-1302.5091 R:-1653.5354 gloss:-34.9390 dloss:34.9390\n",
      "Episode:217 meanR:-1303.5885 R:-1210.3575 gloss:-35.6624 dloss:35.6624\n",
      "Episode:218 meanR:-1303.8785 R:-1180.9751 gloss:-35.3662 dloss:35.3662\n",
      "Episode:219 meanR:-1310.0632 R:-1671.6990 gloss:-35.3892 dloss:35.3892\n",
      "Episode:220 meanR:-1310.1481 R:-1340.6353 gloss:-35.2130 dloss:35.2130\n",
      "Episode:221 meanR:-1313.1283 R:-1647.9361 gloss:-35.4849 dloss:35.4849\n",
      "Episode:222 meanR:-1311.4796 R:-894.5449 gloss:-35.4942 dloss:35.4942\n",
      "Episode:223 meanR:-1310.6545 R:-1361.1657 gloss:-35.6483 dloss:35.6483\n",
      "Episode:224 meanR:-1308.4798 R:-1142.9938 gloss:-35.8359 dloss:35.8359\n",
      "Episode:225 meanR:-1309.0988 R:-1368.8303 gloss:-35.6307 dloss:35.6307\n",
      "Episode:226 meanR:-1310.8043 R:-1204.2606 gloss:-35.5834 dloss:35.5834\n",
      "Episode:227 meanR:-1310.9486 R:-1350.7917 gloss:-35.9696 dloss:35.9696\n",
      "Episode:228 meanR:-1309.3599 R:-1014.8635 gloss:-35.8332 dloss:35.8332\n",
      "Episode:229 meanR:-1310.5069 R:-1347.6676 gloss:-35.7747 dloss:35.7747\n",
      "Episode:230 meanR:-1312.1843 R:-1338.4389 gloss:-35.9192 dloss:35.9192\n",
      "Episode:231 meanR:-1310.1241 R:-1369.0012 gloss:-35.8269 dloss:35.8269\n",
      "Episode:232 meanR:-1309.3468 R:-1275.6310 gloss:-35.7052 dloss:35.7052\n",
      "Episode:233 meanR:-1310.1448 R:-1319.3118 gloss:-35.7878 dloss:35.7878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:234 meanR:-1311.4653 R:-1305.0745 gloss:-35.6213 dloss:35.6213\n",
      "Episode:235 meanR:-1310.7570 R:-1373.2202 gloss:-36.0473 dloss:36.0473\n",
      "Episode:236 meanR:-1310.6022 R:-1324.6558 gloss:-35.7912 dloss:35.7912\n",
      "Episode:237 meanR:-1307.5410 R:-1030.5988 gloss:-35.7260 dloss:35.7260\n",
      "Episode:238 meanR:-1310.1128 R:-1341.7192 gloss:-35.9011 dloss:35.9011\n",
      "Episode:239 meanR:-1309.9603 R:-1351.8502 gloss:-35.8958 dloss:35.8958\n",
      "Episode:240 meanR:-1307.1054 R:-1055.1413 gloss:-35.7818 dloss:35.7818\n",
      "Episode:241 meanR:-1307.4247 R:-1362.3918 gloss:-36.0994 dloss:36.0994\n",
      "Episode:242 meanR:-1309.8865 R:-1359.0273 gloss:-35.9712 dloss:35.9712\n",
      "Episode:243 meanR:-1309.5904 R:-1217.8014 gloss:-36.0090 dloss:36.0090\n",
      "Episode:244 meanR:-1306.7054 R:-1081.2658 gloss:-36.1018 dloss:36.1018\n",
      "Episode:245 meanR:-1306.8867 R:-1359.0082 gloss:-36.3253 dloss:36.3253\n",
      "Episode:246 meanR:-1306.8671 R:-1329.2562 gloss:-36.0866 dloss:36.0866\n",
      "Episode:247 meanR:-1305.3665 R:-1219.7358 gloss:-36.4698 dloss:36.4698\n",
      "Episode:248 meanR:-1308.2781 R:-1642.9509 gloss:-36.2491 dloss:36.2491\n",
      "Episode:249 meanR:-1309.6014 R:-1337.6025 gloss:-35.9521 dloss:35.9521\n",
      "Episode:250 meanR:-1310.4184 R:-1355.3962 gloss:-36.2022 dloss:36.2022\n",
      "Episode:251 meanR:-1311.0501 R:-1159.8884 gloss:-36.3183 dloss:36.3183\n",
      "Episode:252 meanR:-1311.3365 R:-1372.8899 gloss:-36.4011 dloss:36.4011\n",
      "Episode:253 meanR:-1312.5095 R:-1350.5186 gloss:-36.2404 dloss:36.2404\n",
      "Episode:254 meanR:-1310.4399 R:-1371.7795 gloss:-36.2352 dloss:36.2352\n",
      "Episode:255 meanR:-1310.6426 R:-1368.0809 gloss:-36.5659 dloss:36.5659\n",
      "Episode:256 meanR:-1313.4324 R:-1390.5964 gloss:-36.4006 dloss:36.4006\n",
      "Episode:257 meanR:-1307.7320 R:-1004.1507 gloss:-36.2867 dloss:36.2867\n",
      "Episode:258 meanR:-1307.5645 R:-1342.6220 gloss:-36.3523 dloss:36.3523\n",
      "Episode:259 meanR:-1305.0920 R:-1111.3713 gloss:-36.5161 dloss:36.5161\n",
      "Episode:260 meanR:-1303.9005 R:-1146.8588 gloss:-36.2721 dloss:36.2721\n",
      "Episode:261 meanR:-1304.0173 R:-1362.5202 gloss:-36.6371 dloss:36.6371\n",
      "Episode:262 meanR:-1304.5352 R:-1380.7383 gloss:-36.5544 dloss:36.5544\n",
      "Episode:263 meanR:-1309.0347 R:-1688.9140 gloss:-36.9448 dloss:36.9448\n",
      "Episode:264 meanR:-1310.1573 R:-1340.8686 gloss:-36.9050 dloss:36.9050\n",
      "Episode:265 meanR:-1312.3303 R:-1562.1934 gloss:-36.2889 dloss:36.2889\n",
      "Episode:266 meanR:-1312.3319 R:-1347.7886 gloss:-36.5482 dloss:36.5482\n",
      "Episode:267 meanR:-1312.6991 R:-1366.3945 gloss:-36.5787 dloss:36.5787\n",
      "Episode:268 meanR:-1312.8235 R:-1368.7030 gloss:-36.8504 dloss:36.8504\n",
      "Episode:269 meanR:-1315.1963 R:-1564.6834 gloss:-36.9147 dloss:36.9147\n",
      "Episode:270 meanR:-1315.7167 R:-1373.5795 gloss:-37.0947 dloss:37.0947\n",
      "Episode:271 meanR:-1315.8413 R:-1353.8662 gloss:-36.7901 dloss:36.7901\n",
      "Episode:272 meanR:-1315.5906 R:-1320.7940 gloss:-36.7905 dloss:36.7905\n",
      "Episode:273 meanR:-1315.3914 R:-1350.4447 gloss:-37.4201 dloss:37.4201\n",
      "Episode:274 meanR:-1313.3901 R:-1421.4359 gloss:-37.2115 dloss:37.2115\n",
      "Episode:275 meanR:-1312.2872 R:-1242.4416 gloss:-37.0429 dloss:37.0429\n",
      "Episode:276 meanR:-1315.9236 R:-1348.6321 gloss:-37.0338 dloss:37.0338\n",
      "Episode:277 meanR:-1315.4959 R:-1326.4855 gloss:-37.2667 dloss:37.2667\n",
      "Episode:278 meanR:-1321.2380 R:-1681.0419 gloss:-37.4582 dloss:37.4582\n",
      "Episode:279 meanR:-1322.8135 R:-1491.9594 gloss:-37.5772 dloss:37.5772\n",
      "Episode:280 meanR:-1322.4908 R:-1346.5017 gloss:-37.1644 dloss:37.1644\n",
      "Episode:281 meanR:-1320.6799 R:-1195.7590 gloss:-37.3993 dloss:37.3993\n",
      "Episode:282 meanR:-1323.4389 R:-1546.3200 gloss:-37.3841 dloss:37.3841\n",
      "Episode:283 meanR:-1325.4214 R:-1530.8309 gloss:-37.3764 dloss:37.3764\n",
      "Episode:284 meanR:-1316.2349 R:-1005.8903 gloss:-37.5711 dloss:37.5711\n",
      "Episode:285 meanR:-1313.8408 R:-1089.5734 gloss:-37.2934 dloss:37.2934\n",
      "Episode:286 meanR:-1315.8705 R:-1288.2731 gloss:-37.5002 dloss:37.5002\n",
      "Episode:287 meanR:-1316.9608 R:-1353.8721 gloss:-37.4191 dloss:37.4191\n",
      "Episode:288 meanR:-1320.8779 R:-1325.5694 gloss:-37.2494 dloss:37.2494\n",
      "Episode:289 meanR:-1320.7982 R:-1355.5616 gloss:-37.6692 dloss:37.6692\n",
      "Episode:290 meanR:-1324.5843 R:-1297.8520 gloss:-37.6504 dloss:37.6504\n",
      "Episode:291 meanR:-1327.4204 R:-1363.6272 gloss:-37.3445 dloss:37.3445\n",
      "Episode:292 meanR:-1328.7906 R:-1346.5010 gloss:-37.2794 dloss:37.2794\n",
      "Episode:293 meanR:-1325.3004 R:-1365.5893 gloss:-37.6153 dloss:37.6153\n",
      "Episode:294 meanR:-1325.2338 R:-1365.0965 gloss:-37.8932 dloss:37.8932\n",
      "Episode:295 meanR:-1325.3716 R:-1353.0990 gloss:-37.4488 dloss:37.4488\n",
      "Episode:296 meanR:-1327.0644 R:-1528.7781 gloss:-37.4839 dloss:37.4839\n",
      "Episode:297 meanR:-1327.5351 R:-1315.4951 gloss:-37.7248 dloss:37.7248\n",
      "Episode:298 meanR:-1326.9816 R:-1283.1441 gloss:-37.8606 dloss:37.8606\n",
      "Episode:299 meanR:-1328.5136 R:-1428.8984 gloss:-37.7781 dloss:37.7781\n",
      "Episode:300 meanR:-1327.3864 R:-1249.0859 gloss:-37.8578 dloss:37.8578\n",
      "Episode:301 meanR:-1328.3007 R:-1311.1274 gloss:-37.9142 dloss:37.9142\n",
      "Episode:302 meanR:-1326.1921 R:-1114.6724 gloss:-37.8135 dloss:37.8135\n",
      "Episode:303 meanR:-1327.4807 R:-1321.7721 gloss:-37.8195 dloss:37.8195\n",
      "Episode:304 meanR:-1324.3700 R:-999.4948 gloss:-37.9466 dloss:37.9466\n",
      "Episode:305 meanR:-1324.4115 R:-1321.9992 gloss:-37.9713 dloss:37.9713\n",
      "Episode:306 meanR:-1323.8123 R:-1295.9444 gloss:-37.9037 dloss:37.9037\n",
      "Episode:307 meanR:-1324.7176 R:-1534.8292 gloss:-38.0316 dloss:38.0316\n",
      "Episode:308 meanR:-1324.7006 R:-1357.0053 gloss:-38.0286 dloss:38.0286\n",
      "Episode:309 meanR:-1324.4385 R:-1331.8485 gloss:-38.0061 dloss:38.0061\n",
      "Episode:310 meanR:-1321.7904 R:-1373.8141 gloss:-38.4172 dloss:38.4172\n",
      "Episode:311 meanR:-1322.8954 R:-1346.8075 gloss:-38.0556 dloss:38.0556\n",
      "Episode:312 meanR:-1327.1506 R:-1462.3065 gloss:-38.4643 dloss:38.4643\n",
      "Episode:313 meanR:-1325.5800 R:-1168.4627 gloss:-38.5420 dloss:38.5420\n",
      "Episode:314 meanR:-1326.9944 R:-1324.2741 gloss:-38.1871 dloss:38.1871\n",
      "Episode:315 meanR:-1324.5781 R:-1006.5595 gloss:-38.1471 dloss:38.1471\n",
      "Episode:316 meanR:-1320.7740 R:-1273.1241 gloss:-38.4199 dloss:38.4199\n",
      "Episode:317 meanR:-1322.1721 R:-1350.1679 gloss:-38.0169 dloss:38.0169\n",
      "Episode:318 meanR:-1323.1585 R:-1279.6178 gloss:-38.5607 dloss:38.5607\n",
      "Episode:319 meanR:-1320.6645 R:-1422.2940 gloss:-38.4867 dloss:38.4867\n",
      "Episode:320 meanR:-1321.1281 R:-1386.9930 gloss:-38.8199 dloss:38.8199\n",
      "Episode:321 meanR:-1316.3566 R:-1170.7885 gloss:-38.1430 dloss:38.1430\n",
      "Episode:322 meanR:-1319.2184 R:-1180.7273 gloss:-38.5401 dloss:38.5401\n",
      "Episode:323 meanR:-1319.0570 R:-1345.0210 gloss:-38.8028 dloss:38.8028\n",
      "Episode:324 meanR:-1317.6144 R:-998.7399 gloss:-38.4136 dloss:38.4136\n",
      "Episode:325 meanR:-1313.0164 R:-909.0256 gloss:-38.6684 dloss:38.6684\n",
      "Episode:326 meanR:-1314.2804 R:-1330.6576 gloss:-38.4629 dloss:38.4629\n",
      "Episode:327 meanR:-1315.1607 R:-1438.8286 gloss:-38.7129 dloss:38.7129\n",
      "Episode:328 meanR:-1318.9898 R:-1397.7700 gloss:-38.2694 dloss:38.2694\n",
      "Episode:329 meanR:-1318.8363 R:-1332.3205 gloss:-39.1018 dloss:39.1018\n",
      "Episode:330 meanR:-1318.9850 R:-1353.3087 gloss:-38.4626 dloss:38.4626\n",
      "Episode:331 meanR:-1315.6644 R:-1036.9378 gloss:-38.3905 dloss:38.3905\n",
      "Episode:332 meanR:-1316.4462 R:-1353.8132 gloss:-38.6705 dloss:38.6705\n",
      "Episode:333 meanR:-1316.7858 R:-1353.2754 gloss:-38.8987 dloss:38.8987\n",
      "Episode:334 meanR:-1316.8427 R:-1310.7614 gloss:-38.6986 dloss:38.6986\n",
      "Episode:335 meanR:-1316.5385 R:-1342.8011 gloss:-38.6024 dloss:38.6024\n",
      "Episode:336 meanR:-1316.6199 R:-1332.7914 gloss:-39.0516 dloss:39.0516\n",
      "Episode:337 meanR:-1319.8078 R:-1349.3875 gloss:-38.6455 dloss:38.6455\n",
      "Episode:338 meanR:-1320.5803 R:-1418.9715 gloss:-38.4017 dloss:38.4017\n",
      "Episode:339 meanR:-1320.4186 R:-1335.6846 gloss:-39.0175 dloss:39.0175\n",
      "Episode:340 meanR:-1323.4959 R:-1362.8666 gloss:-38.7205 dloss:38.7205\n",
      "Episode:341 meanR:-1323.2063 R:-1333.4302 gloss:-38.8873 dloss:38.8873\n",
      "Episode:342 meanR:-1323.0836 R:-1346.7572 gloss:-38.9080 dloss:38.9080\n",
      "Episode:343 meanR:-1324.5562 R:-1365.0611 gloss:-39.1051 dloss:39.1051\n",
      "Episode:344 meanR:-1327.3261 R:-1358.2631 gloss:-38.9341 dloss:38.9341\n",
      "Episode:345 meanR:-1327.4814 R:-1374.5315 gloss:-39.2062 dloss:39.2062\n",
      "Episode:346 meanR:-1327.6434 R:-1345.4623 gloss:-39.4401 dloss:39.4401\n",
      "Episode:347 meanR:-1325.7674 R:-1032.1348 gloss:-39.1630 dloss:39.1630\n",
      "Episode:348 meanR:-1319.7188 R:-1038.0875 gloss:-39.0037 dloss:39.0037\n",
      "Episode:349 meanR:-1319.5672 R:-1322.4451 gloss:-39.2525 dloss:39.2525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:350 meanR:-1319.5676 R:-1355.4385 gloss:-39.0389 dloss:39.0389\n",
      "Episode:351 meanR:-1321.1687 R:-1319.9971 gloss:-39.6011 dloss:39.6011\n",
      "Episode:352 meanR:-1317.7713 R:-1033.1478 gloss:-38.8182 dloss:38.8182\n",
      "Episode:353 meanR:-1317.7254 R:-1345.9282 gloss:-38.9711 dloss:38.9711\n",
      "Episode:354 meanR:-1317.6596 R:-1365.2032 gloss:-39.0272 dloss:39.0272\n",
      "Episode:355 meanR:-1317.2532 R:-1327.4365 gloss:-39.5257 dloss:39.5257\n",
      "Episode:356 meanR:-1316.6691 R:-1332.1894 gloss:-39.4970 dloss:39.4970\n",
      "Episode:357 meanR:-1320.0005 R:-1337.2902 gloss:-39.2539 dloss:39.2539\n",
      "Episode:358 meanR:-1320.0441 R:-1346.9842 gloss:-38.8866 dloss:38.8866\n",
      "Episode:359 meanR:-1322.3076 R:-1337.7218 gloss:-39.7110 dloss:39.7110\n",
      "Episode:360 meanR:-1324.1460 R:-1330.6913 gloss:-39.4224 dloss:39.4224\n",
      "Episode:361 meanR:-1323.8298 R:-1330.9008 gloss:-39.5844 dloss:39.5844\n",
      "Episode:362 meanR:-1323.3418 R:-1331.9439 gloss:-39.1707 dloss:39.1707\n",
      "Episode:363 meanR:-1320.7631 R:-1431.0451 gloss:-39.7222 dloss:39.7222\n",
      "Episode:364 meanR:-1320.9085 R:-1355.4096 gloss:-39.5589 dloss:39.5589\n",
      "Episode:365 meanR:-1318.8117 R:-1352.5083 gloss:-39.1620 dloss:39.1620\n",
      "Episode:366 meanR:-1321.3372 R:-1600.3412 gloss:-39.6317 dloss:39.6317\n",
      "Episode:367 meanR:-1316.7139 R:-904.0586 gloss:-39.2203 dloss:39.2203\n",
      "Episode:368 meanR:-1316.3386 R:-1331.1767 gloss:-39.2804 dloss:39.2804\n",
      "Episode:369 meanR:-1313.9018 R:-1321.0036 gloss:-39.2550 dloss:39.2550\n",
      "Episode:370 meanR:-1314.0426 R:-1387.6603 gloss:-39.3997 dloss:39.3997\n",
      "Episode:371 meanR:-1310.9985 R:-1049.4600 gloss:-39.3173 dloss:39.3173\n",
      "Episode:372 meanR:-1311.2727 R:-1348.2097 gloss:-39.5417 dloss:39.5417\n",
      "Episode:373 meanR:-1311.1985 R:-1343.0258 gloss:-39.4736 dloss:39.4736\n",
      "Episode:374 meanR:-1308.8294 R:-1184.5281 gloss:-39.3303 dloss:39.3303\n",
      "Episode:375 meanR:-1310.1610 R:-1375.5989 gloss:-39.7307 dloss:39.7307\n",
      "Episode:376 meanR:-1308.3028 R:-1162.8133 gloss:-39.4535 dloss:39.4535\n",
      "Episode:377 meanR:-1305.2876 R:-1024.9667 gloss:-39.3556 dloss:39.3556\n",
      "Episode:378 meanR:-1302.6505 R:-1417.3241 gloss:-40.0046 dloss:40.0046\n",
      "Episode:379 meanR:-1301.3489 R:-1361.8005 gloss:-39.8163 dloss:39.8163\n",
      "Episode:380 meanR:-1301.7504 R:-1386.6544 gloss:-39.9769 dloss:39.9769\n",
      "Episode:381 meanR:-1303.2193 R:-1342.6455 gloss:-39.7228 dloss:39.7228\n",
      "Episode:382 meanR:-1301.2615 R:-1350.5460 gloss:-39.7939 dloss:39.7939\n",
      "Episode:383 meanR:-1296.0533 R:-1010.0135 gloss:-39.8695 dloss:39.8695\n",
      "Episode:384 meanR:-1299.4618 R:-1346.7367 gloss:-40.2183 dloss:40.2183\n",
      "Episode:385 meanR:-1302.1315 R:-1356.5386 gloss:-39.9451 dloss:39.9451\n",
      "Episode:386 meanR:-1302.2026 R:-1295.3876 gloss:-40.2962 dloss:40.2962\n",
      "Episode:387 meanR:-1302.0195 R:-1335.5583 gloss:-40.1103 dloss:40.1103\n",
      "Episode:388 meanR:-1299.7443 R:-1098.0535 gloss:-40.0130 dloss:40.0130\n",
      "Episode:389 meanR:-1299.2367 R:-1304.8027 gloss:-40.2590 dloss:40.2590\n",
      "Episode:390 meanR:-1300.0588 R:-1380.0610 gloss:-40.0242 dloss:40.0242\n",
      "Episode:391 meanR:-1299.7129 R:-1329.0384 gloss:-39.7354 dloss:39.7354\n",
      "Episode:392 meanR:-1299.6106 R:-1336.2730 gloss:-40.0512 dloss:40.0512\n",
      "Episode:393 meanR:-1299.2216 R:-1326.6872 gloss:-39.8462 dloss:39.8462\n",
      "Episode:394 meanR:-1298.6272 R:-1305.6508 gloss:-40.4517 dloss:40.4517\n",
      "Episode:395 meanR:-1298.2615 R:-1316.5284 gloss:-40.2358 dloss:40.2358\n",
      "Episode:396 meanR:-1296.6519 R:-1367.8182 gloss:-40.3477 dloss:40.3477\n",
      "Episode:397 meanR:-1296.8490 R:-1335.2055 gloss:-40.3062 dloss:40.3062\n",
      "Episode:398 meanR:-1296.8224 R:-1280.4830 gloss:-39.8072 dloss:39.8072\n",
      "Episode:399 meanR:-1296.0035 R:-1347.0154 gloss:-40.4771 dloss:40.4771\n",
      "Episode:400 meanR:-1296.4004 R:-1288.7767 gloss:-39.7724 dloss:39.7724\n",
      "Episode:401 meanR:-1296.8272 R:-1353.8044 gloss:-39.9704 dloss:39.9704\n",
      "Episode:402 meanR:-1299.0858 R:-1340.5323 gloss:-40.6508 dloss:40.6508\n",
      "Episode:403 meanR:-1299.1268 R:-1325.8720 gloss:-40.2173 dloss:40.2173\n",
      "Episode:404 meanR:-1302.3502 R:-1321.8383 gloss:-40.2478 dloss:40.2478\n",
      "Episode:405 meanR:-1302.2581 R:-1312.7822 gloss:-40.5459 dloss:40.5459\n",
      "Episode:406 meanR:-1302.0536 R:-1275.4944 gloss:-40.1643 dloss:40.1643\n",
      "Episode:407 meanR:-1300.2249 R:-1351.9605 gloss:-40.4191 dloss:40.4191\n",
      "Episode:408 meanR:-1299.6230 R:-1296.8158 gloss:-40.4233 dloss:40.4233\n",
      "Episode:409 meanR:-1299.6815 R:-1337.7000 gloss:-40.7009 dloss:40.7009\n",
      "Episode:410 meanR:-1300.0131 R:-1406.9768 gloss:-40.6174 dloss:40.6174\n",
      "Episode:411 meanR:-1299.6295 R:-1308.4487 gloss:-40.9833 dloss:40.9833\n",
      "Episode:412 meanR:-1296.8564 R:-1184.9936 gloss:-40.5218 dloss:40.5218\n",
      "Episode:413 meanR:-1299.5823 R:-1441.0476 gloss:-40.7395 dloss:40.7395\n",
      "Episode:414 meanR:-1295.9669 R:-962.7347 gloss:-40.4825 dloss:40.4825\n",
      "Episode:415 meanR:-1298.6288 R:-1272.7543 gloss:-40.7122 dloss:40.7122\n",
      "Episode:416 meanR:-1299.1792 R:-1328.1646 gloss:-40.6547 dloss:40.6547\n",
      "Episode:417 meanR:-1299.0779 R:-1340.0358 gloss:-41.0989 dloss:41.0989\n",
      "Episode:418 meanR:-1299.6471 R:-1336.5351 gloss:-40.2565 dloss:40.2565\n",
      "Episode:419 meanR:-1299.1659 R:-1374.1795 gloss:-40.4767 dloss:40.4767\n",
      "Episode:420 meanR:-1298.4492 R:-1315.3202 gloss:-40.8803 dloss:40.8803\n",
      "Episode:421 meanR:-1299.9189 R:-1317.7556 gloss:-40.9451 dloss:40.9451\n",
      "Episode:422 meanR:-1301.3249 R:-1321.3338 gloss:-41.0681 dloss:41.0681\n",
      "Episode:423 meanR:-1298.1869 R:-1031.2185 gloss:-40.8735 dloss:40.8735\n",
      "Episode:424 meanR:-1303.5162 R:-1531.6668 gloss:-40.9943 dloss:40.9943\n",
      "Episode:425 meanR:-1308.5545 R:-1412.8596 gloss:-40.9581 dloss:40.9581\n",
      "Episode:426 meanR:-1308.7146 R:-1346.6638 gloss:-40.7743 dloss:40.7743\n",
      "Episode:427 meanR:-1307.9983 R:-1367.1989 gloss:-41.0775 dloss:41.0775\n",
      "Episode:428 meanR:-1307.6408 R:-1362.0228 gloss:-40.6351 dloss:40.6351\n",
      "Episode:429 meanR:-1307.8523 R:-1353.4664 gloss:-40.6648 dloss:40.6648\n",
      "Episode:430 meanR:-1307.8309 R:-1351.1717 gloss:-40.9682 dloss:40.9682\n",
      "Episode:431 meanR:-1310.7687 R:-1330.7156 gloss:-40.7347 dloss:40.7347\n",
      "Episode:432 meanR:-1310.8589 R:-1362.8384 gloss:-40.9255 dloss:40.9255\n",
      "Episode:433 meanR:-1310.7000 R:-1337.3871 gloss:-40.7327 dloss:40.7327\n",
      "Episode:434 meanR:-1309.0064 R:-1141.3948 gloss:-40.7334 dloss:40.7334\n",
      "Episode:435 meanR:-1308.6268 R:-1304.8454 gloss:-40.5998 dloss:40.5998\n",
      "Episode:436 meanR:-1308.5856 R:-1328.6660 gloss:-40.5576 dloss:40.5576\n",
      "Episode:437 meanR:-1308.6568 R:-1356.5067 gloss:-41.0936 dloss:41.0936\n",
      "Episode:438 meanR:-1307.7739 R:-1330.6864 gloss:-40.7411 dloss:40.7411\n",
      "Episode:439 meanR:-1302.0824 R:-766.5347 gloss:-41.3447 dloss:41.3447\n",
      "Episode:440 meanR:-1301.9771 R:-1352.3370 gloss:-40.9507 dloss:40.9507\n",
      "Episode:441 meanR:-1301.1615 R:-1251.8678 gloss:-41.0995 dloss:41.0995\n",
      "Episode:442 meanR:-1301.1514 R:-1345.7456 gloss:-41.1380 dloss:41.1380\n",
      "Episode:443 meanR:-1297.3761 R:-987.5317 gloss:-41.4245 dloss:41.4245\n",
      "Episode:444 meanR:-1297.2101 R:-1341.6654 gloss:-41.3881 dloss:41.3881\n",
      "Episode:445 meanR:-1296.9900 R:-1352.5200 gloss:-40.9796 dloss:40.9796\n",
      "Episode:446 meanR:-1297.1018 R:-1356.6461 gloss:-41.0763 dloss:41.0763\n",
      "Episode:447 meanR:-1295.3468 R:-856.6353 gloss:-41.1955 dloss:41.1955\n",
      "Episode:448 meanR:-1298.7748 R:-1380.8871 gloss:-40.8463 dloss:40.8463\n",
      "Episode:449 meanR:-1298.8648 R:-1331.4421 gloss:-41.0476 dloss:41.0476\n",
      "Episode:450 meanR:-1298.6790 R:-1336.8539 gloss:-41.0133 dloss:41.0133\n",
      "Episode:451 meanR:-1298.4288 R:-1294.9843 gloss:-41.0463 dloss:41.0463\n",
      "Episode:452 meanR:-1301.5133 R:-1341.5974 gloss:-41.2882 dloss:41.2882\n",
      "Episode:453 meanR:-1298.3468 R:-1029.2791 gloss:-41.1851 dloss:41.1851\n",
      "Episode:454 meanR:-1298.0125 R:-1331.7675 gloss:-41.3654 dloss:41.3654\n",
      "Episode:455 meanR:-1298.4713 R:-1373.3220 gloss:-41.3305 dloss:41.3305\n",
      "Episode:456 meanR:-1298.0929 R:-1294.3479 gloss:-41.0938 dloss:41.0938\n",
      "Episode:457 meanR:-1297.5059 R:-1278.5873 gloss:-41.4994 dloss:41.4994\n",
      "Episode:458 meanR:-1297.3734 R:-1333.7406 gloss:-41.2958 dloss:41.2958\n",
      "Episode:459 meanR:-1297.3865 R:-1339.0320 gloss:-41.3063 dloss:41.3063\n",
      "Episode:460 meanR:-1296.8499 R:-1277.0232 gloss:-41.3383 dloss:41.3383\n",
      "Episode:461 meanR:-1296.6018 R:-1306.0909 gloss:-41.1606 dloss:41.1606\n",
      "Episode:462 meanR:-1296.6945 R:-1341.2175 gloss:-41.4242 dloss:41.4242\n",
      "Episode:463 meanR:-1291.3507 R:-896.6612 gloss:-41.5214 dloss:41.5214\n",
      "Episode:464 meanR:-1291.3162 R:-1351.9634 gloss:-41.6645 dloss:41.6645\n",
      "Episode:465 meanR:-1291.0540 R:-1326.2832 gloss:-41.5475 dloss:41.5475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:466 meanR:-1288.4058 R:-1335.5222 gloss:-41.6954 dloss:41.6954\n",
      "Episode:467 meanR:-1293.5252 R:-1416.0068 gloss:-41.1922 dloss:41.1922\n",
      "Episode:468 meanR:-1293.5108 R:-1329.7279 gloss:-41.6470 dloss:41.6470\n",
      "Episode:469 meanR:-1294.2949 R:-1399.4206 gloss:-41.4835 dloss:41.4835\n",
      "Episode:470 meanR:-1294.0012 R:-1358.2918 gloss:-41.1784 dloss:41.1784\n",
      "Episode:471 meanR:-1292.4046 R:-889.7927 gloss:-41.6900 dloss:41.6900\n",
      "Episode:472 meanR:-1292.3007 R:-1337.8226 gloss:-41.0915 dloss:41.0915\n",
      "Episode:473 meanR:-1291.2651 R:-1239.4622 gloss:-41.4897 dloss:41.4897\n",
      "Episode:474 meanR:-1290.0301 R:-1061.0355 gloss:-41.4888 dloss:41.4888\n",
      "Episode:475 meanR:-1289.8185 R:-1354.4326 gloss:-41.8967 dloss:41.8967\n",
      "Episode:476 meanR:-1291.9776 R:-1378.7278 gloss:-41.6475 dloss:41.6475\n",
      "Episode:477 meanR:-1294.7999 R:-1307.1992 gloss:-41.5080 dloss:41.5080\n",
      "Episode:478 meanR:-1294.1358 R:-1350.9068 gloss:-41.8903 dloss:41.8903\n",
      "Episode:479 meanR:-1293.9983 R:-1348.0552 gloss:-41.8623 dloss:41.8623\n",
      "Episode:480 meanR:-1292.7491 R:-1261.7317 gloss:-41.2150 dloss:41.2150\n",
      "Episode:481 meanR:-1291.7178 R:-1239.5204 gloss:-41.9216 dloss:41.9216\n",
      "Episode:482 meanR:-1291.5823 R:-1336.9939 gloss:-41.4982 dloss:41.4982\n",
      "Episode:483 meanR:-1294.7739 R:-1329.1736 gloss:-41.5246 dloss:41.5246\n",
      "Episode:484 meanR:-1293.2805 R:-1197.3969 gloss:-41.4445 dloss:41.4445\n",
      "Episode:485 meanR:-1291.2678 R:-1155.2650 gloss:-41.8206 dloss:41.8206\n",
      "Episode:486 meanR:-1291.6065 R:-1329.2595 gloss:-41.3192 dloss:41.3192\n",
      "Episode:487 meanR:-1291.5348 R:-1328.3918 gloss:-41.9665 dloss:41.9665\n",
      "Episode:488 meanR:-1289.7398 R:-918.5520 gloss:-42.0688 dloss:42.0688\n",
      "Episode:489 meanR:-1290.3790 R:-1368.7168 gloss:-41.5444 dloss:41.5444\n",
      "Episode:490 meanR:-1290.0636 R:-1348.5275 gloss:-41.8088 dloss:41.8088\n",
      "Episode:491 meanR:-1290.1161 R:-1334.2899 gloss:-41.6680 dloss:41.6680\n",
      "Episode:492 meanR:-1295.2195 R:-1846.6135 gloss:-41.6907 dloss:41.6907\n",
      "Episode:493 meanR:-1295.3753 R:-1342.2575 gloss:-42.1960 dloss:42.1960\n",
      "Episode:494 meanR:-1295.7553 R:-1343.6562 gloss:-41.9251 dloss:41.9251\n",
      "Episode:495 meanR:-1295.9828 R:-1339.2825 gloss:-41.7059 dloss:41.7059\n",
      "Episode:496 meanR:-1295.8688 R:-1356.4174 gloss:-41.8470 dloss:41.8470\n",
      "Episode:497 meanR:-1293.5073 R:-1099.0561 gloss:-41.4243 dloss:41.4243\n",
      "Episode:498 meanR:-1296.0085 R:-1530.5983 gloss:-41.7399 dloss:41.7399\n",
      "Episode:499 meanR:-1296.6091 R:-1407.0786 gloss:-41.8230 dloss:41.8230\n",
      "Episode:500 meanR:-1296.4924 R:-1277.0997 gloss:-42.1623 dloss:42.1623\n",
      "Episode:501 meanR:-1296.4687 R:-1351.4370 gloss:-41.8162 dloss:41.8162\n",
      "Episode:502 meanR:-1296.8942 R:-1383.0849 gloss:-41.5233 dloss:41.5233\n",
      "Episode:503 meanR:-1295.4050 R:-1176.9529 gloss:-41.0140 dloss:41.0140\n",
      "Episode:504 meanR:-1295.5260 R:-1333.9372 gloss:-41.8508 dloss:41.8508\n",
      "Episode:505 meanR:-1295.7277 R:-1332.9471 gloss:-41.4666 dloss:41.4666\n",
      "Episode:506 meanR:-1296.2194 R:-1324.6731 gloss:-41.7728 dloss:41.7728\n",
      "Episode:507 meanR:-1296.0636 R:-1336.3767 gloss:-41.1126 dloss:41.1126\n",
      "Episode:508 meanR:-1295.2342 R:-1213.8747 gloss:-40.9725 dloss:40.9725\n",
      "Episode:509 meanR:-1295.2089 R:-1335.1717 gloss:-41.2027 dloss:41.2027\n",
      "Episode:510 meanR:-1294.7261 R:-1358.6949 gloss:-41.4877 dloss:41.4877\n",
      "Episode:511 meanR:-1295.0712 R:-1342.9604 gloss:-41.6538 dloss:41.6538\n",
      "Episode:512 meanR:-1297.2336 R:-1401.2361 gloss:-41.1372 dloss:41.1372\n",
      "Episode:513 meanR:-1294.2952 R:-1147.2056 gloss:-41.3133 dloss:41.3133\n",
      "Episode:514 meanR:-1296.7686 R:-1210.0738 gloss:-41.7247 dloss:41.7247\n",
      "Episode:515 meanR:-1296.2973 R:-1225.6224 gloss:-41.6351 dloss:41.6351\n",
      "Episode:516 meanR:-1296.0936 R:-1307.7997 gloss:-41.6150 dloss:41.6150\n",
      "Episode:517 meanR:-1296.1704 R:-1347.7124 gloss:-41.4983 dloss:41.4983\n",
      "Episode:518 meanR:-1296.4526 R:-1364.7519 gloss:-41.3860 dloss:41.3860\n",
      "Episode:519 meanR:-1295.3695 R:-1265.8725 gloss:-40.9672 dloss:40.9672\n",
      "Episode:520 meanR:-1295.2552 R:-1303.8854 gloss:-41.4163 dloss:41.4163\n",
      "Episode:521 meanR:-1291.2343 R:-915.6736 gloss:-41.1773 dloss:41.1773\n",
      "Episode:522 meanR:-1285.6999 R:-767.8866 gloss:-41.3426 dloss:41.3426\n",
      "Episode:523 meanR:-1289.1989 R:-1381.1179 gloss:-41.4033 dloss:41.4033\n",
      "Episode:524 meanR:-1285.5904 R:-1170.8207 gloss:-40.9258 dloss:40.9258\n",
      "Episode:525 meanR:-1284.6859 R:-1322.4138 gloss:-41.6144 dloss:41.6144\n",
      "Episode:526 meanR:-1284.7364 R:-1351.7105 gloss:-40.7765 dloss:40.7765\n",
      "Episode:527 meanR:-1283.9720 R:-1290.7630 gloss:-40.8876 dloss:40.8876\n",
      "Episode:528 meanR:-1283.2868 R:-1293.4989 gloss:-41.1354 dloss:41.1354\n",
      "Episode:529 meanR:-1281.5821 R:-1182.9972 gloss:-41.1054 dloss:41.1054\n",
      "Episode:530 meanR:-1281.3270 R:-1325.6576 gloss:-40.8282 dloss:40.8282\n",
      "Episode:531 meanR:-1280.7394 R:-1271.9625 gloss:-41.5918 dloss:41.5918\n",
      "Episode:532 meanR:-1280.7459 R:-1363.4818 gloss:-40.8899 dloss:40.8899\n",
      "Episode:533 meanR:-1279.8901 R:-1251.8076 gloss:-40.7556 dloss:40.7556\n",
      "Episode:534 meanR:-1281.7617 R:-1328.5605 gloss:-41.0901 dloss:41.0901\n",
      "Episode:535 meanR:-1276.3282 R:-761.4916 gloss:-40.1469 dloss:40.1469\n",
      "Episode:536 meanR:-1276.3263 R:-1328.4765 gloss:-41.3776 dloss:41.3776\n",
      "Episode:537 meanR:-1274.7979 R:-1203.6702 gloss:-40.6040 dloss:40.6040\n",
      "Episode:538 meanR:-1275.1163 R:-1362.5209 gloss:-41.2613 dloss:41.2613\n",
      "Episode:539 meanR:-1281.0703 R:-1361.9319 gloss:-40.9410 dloss:40.9410\n",
      "Episode:540 meanR:-1281.1031 R:-1355.6219 gloss:-40.3572 dloss:40.3572\n",
      "Episode:541 meanR:-1282.2082 R:-1362.3752 gloss:-40.7956 dloss:40.7956\n",
      "Episode:542 meanR:-1276.3429 R:-759.2127 gloss:-40.8853 dloss:40.8853\n",
      "Episode:543 meanR:-1280.0996 R:-1363.2028 gloss:-40.9313 dloss:40.9313\n",
      "Episode:544 meanR:-1278.6168 R:-1193.3931 gloss:-40.6811 dloss:40.6811\n",
      "Episode:545 meanR:-1278.3950 R:-1330.3317 gloss:-41.0301 dloss:41.0301\n",
      "Episode:546 meanR:-1277.9829 R:-1315.4421 gloss:-40.9811 dloss:40.9811\n",
      "Episode:547 meanR:-1282.1511 R:-1273.4579 gloss:-41.0554 dloss:41.0554\n",
      "Episode:548 meanR:-1278.1911 R:-984.8787 gloss:-40.1791 dloss:40.1791\n",
      "Episode:549 meanR:-1277.6704 R:-1279.3768 gloss:-40.4044 dloss:40.4044\n",
      "Episode:550 meanR:-1280.5880 R:-1628.6094 gloss:-41.2312 dloss:41.2312\n",
      "Episode:551 meanR:-1277.5839 R:-994.5804 gloss:-40.0894 dloss:40.0894\n",
      "Episode:552 meanR:-1277.3903 R:-1322.2354 gloss:-40.6510 dloss:40.6510\n",
      "Episode:553 meanR:-1280.6041 R:-1350.6630 gloss:-40.4711 dloss:40.4711\n",
      "Episode:554 meanR:-1280.6688 R:-1338.2329 gloss:-40.8345 dloss:40.8345\n",
      "Episode:555 meanR:-1280.4171 R:-1348.1491 gloss:-40.3877 dloss:40.3877\n",
      "Episode:556 meanR:-1280.0219 R:-1254.8294 gloss:-40.7739 dloss:40.7739\n",
      "Episode:557 meanR:-1280.7215 R:-1348.5454 gloss:-39.9617 dloss:39.9617\n",
      "Episode:558 meanR:-1281.0195 R:-1363.5461 gloss:-40.4646 dloss:40.4646\n",
      "Episode:559 meanR:-1283.7732 R:-1614.4029 gloss:-40.2466 dloss:40.2466\n",
      "Episode:560 meanR:-1284.1415 R:-1313.8527 gloss:-40.4562 dloss:40.4562\n",
      "Episode:561 meanR:-1284.1775 R:-1309.6869 gloss:-40.5535 dloss:40.5535\n",
      "Episode:562 meanR:-1284.2669 R:-1350.1627 gloss:-39.4523 dloss:39.4523\n",
      "Episode:563 meanR:-1288.7420 R:-1344.1702 gloss:-40.1605 dloss:40.1605\n",
      "Episode:564 meanR:-1285.8320 R:-1060.9563 gloss:-40.0699 dloss:40.0699\n",
      "Episode:565 meanR:-1285.9062 R:-1333.7091 gloss:-40.7126 dloss:40.7126\n",
      "Episode:566 meanR:-1285.7339 R:-1318.2949 gloss:-40.7221 dloss:40.7221\n",
      "Episode:567 meanR:-1285.7244 R:-1415.0566 gloss:-40.0083 dloss:40.0083\n",
      "Episode:568 meanR:-1283.2416 R:-1081.4488 gloss:-40.2493 dloss:40.2493\n",
      "Episode:569 meanR:-1282.1031 R:-1285.5678 gloss:-40.3834 dloss:40.3834\n",
      "Episode:570 meanR:-1279.7569 R:-1123.6722 gloss:-40.5387 dloss:40.5387\n",
      "Episode:571 meanR:-1283.8024 R:-1294.3440 gloss:-40.1964 dloss:40.1964\n",
      "Episode:572 meanR:-1283.8108 R:-1338.6569 gloss:-40.5278 dloss:40.5278\n",
      "Episode:573 meanR:-1285.2205 R:-1380.4366 gloss:-40.1590 dloss:40.1590\n",
      "Episode:574 meanR:-1287.8336 R:-1322.3432 gloss:-40.4982 dloss:40.4982\n",
      "Episode:575 meanR:-1287.9456 R:-1365.6311 gloss:-39.6966 dloss:39.6966\n",
      "Episode:576 meanR:-1285.5908 R:-1143.2490 gloss:-39.7990 dloss:39.7990\n",
      "Episode:577 meanR:-1285.8283 R:-1330.9463 gloss:-39.7477 dloss:39.7477\n",
      "Episode:578 meanR:-1282.6954 R:-1037.6226 gloss:-39.6466 dloss:39.6466\n",
      "Episode:579 meanR:-1285.4084 R:-1619.3537 gloss:-40.0623 dloss:40.0623\n",
      "Episode:580 meanR:-1286.3933 R:-1360.2177 gloss:-40.2222 dloss:40.2222\n",
      "Episode:581 meanR:-1285.1361 R:-1113.8051 gloss:-40.5069 dloss:40.5069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:582 meanR:-1282.1325 R:-1036.6318 gloss:-40.4430 dloss:40.4430\n",
      "Episode:583 meanR:-1282.4655 R:-1362.4744 gloss:-39.9216 dloss:39.9216\n",
      "Episode:584 meanR:-1281.7733 R:-1128.1721 gloss:-40.2860 dloss:40.2860\n",
      "Episode:585 meanR:-1283.1721 R:-1295.1481 gloss:-40.6032 dloss:40.6032\n",
      "Episode:586 meanR:-1283.1606 R:-1328.1092 gloss:-40.5472 dloss:40.5472\n",
      "Episode:587 meanR:-1283.5253 R:-1364.8653 gloss:-39.9564 dloss:39.9564\n",
      "Episode:588 meanR:-1285.1404 R:-1080.0612 gloss:-39.8919 dloss:39.8919\n",
      "Episode:589 meanR:-1285.1835 R:-1373.0243 gloss:-39.9810 dloss:39.9810\n",
      "Episode:590 meanR:-1284.8326 R:-1313.4350 gloss:-40.5480 dloss:40.5480\n",
      "Episode:591 meanR:-1284.9131 R:-1342.3438 gloss:-40.4874 dloss:40.4874\n",
      "Episode:592 meanR:-1279.9446 R:-1349.7608 gloss:-40.7594 dloss:40.7594\n",
      "Episode:593 meanR:-1280.0098 R:-1348.7793 gloss:-39.4965 dloss:39.4965\n",
      "Episode:594 meanR:-1280.0462 R:-1347.2971 gloss:-39.8543 dloss:39.8543\n",
      "Episode:595 meanR:-1279.9171 R:-1326.3759 gloss:-40.0373 dloss:40.0373\n",
      "Episode:596 meanR:-1283.3094 R:-1695.6386 gloss:-40.0643 dloss:40.0643\n",
      "Episode:597 meanR:-1289.9821 R:-1766.3354 gloss:-39.8565 dloss:39.8565\n",
      "Episode:598 meanR:-1287.9773 R:-1330.1102 gloss:-40.8897 dloss:40.8897\n",
      "Episode:599 meanR:-1286.4964 R:-1258.9920 gloss:-40.1510 dloss:40.1510\n",
      "Episode:600 meanR:-1287.1770 R:-1345.1572 gloss:-40.4450 dloss:40.4450\n",
      "Episode:601 meanR:-1287.3031 R:-1364.0514 gloss:-40.7967 dloss:40.7967\n",
      "Episode:602 meanR:-1286.3245 R:-1285.2211 gloss:-40.1112 dloss:40.1112\n",
      "Episode:603 meanR:-1287.9125 R:-1335.7525 gloss:-39.8647 dloss:39.8647\n",
      "Episode:604 meanR:-1287.9903 R:-1341.7173 gloss:-40.5899 dloss:40.5899\n",
      "Episode:605 meanR:-1287.5938 R:-1293.3018 gloss:-40.4695 dloss:40.4695\n",
      "Episode:606 meanR:-1291.6675 R:-1732.0427 gloss:-39.9901 dloss:39.9901\n",
      "Episode:607 meanR:-1290.3605 R:-1205.6783 gloss:-40.1887 dloss:40.1887\n",
      "Episode:608 meanR:-1289.8207 R:-1159.8943 gloss:-40.1872 dloss:40.1872\n",
      "Episode:609 meanR:-1287.1964 R:-1072.7420 gloss:-39.8059 dloss:39.8059\n",
      "Episode:610 meanR:-1286.7231 R:-1311.3610 gloss:-40.7878 dloss:40.7878\n",
      "Episode:611 meanR:-1286.9336 R:-1364.0087 gloss:-40.3464 dloss:40.3464\n",
      "Episode:612 meanR:-1287.8913 R:-1497.0050 gloss:-39.4008 dloss:39.4008\n",
      "Episode:613 meanR:-1289.9722 R:-1355.3022 gloss:-40.5235 dloss:40.5235\n",
      "Episode:614 meanR:-1289.2683 R:-1139.6773 gloss:-39.5597 dloss:39.5597\n",
      "Episode:615 meanR:-1292.5125 R:-1550.0411 gloss:-40.2766 dloss:40.2766\n",
      "Episode:616 meanR:-1293.2295 R:-1379.5041 gloss:-40.1840 dloss:40.1840\n",
      "Episode:617 meanR:-1297.4704 R:-1771.7978 gloss:-39.9597 dloss:39.9597\n",
      "Episode:618 meanR:-1300.2951 R:-1647.2277 gloss:-40.4623 dloss:40.4623\n",
      "Episode:619 meanR:-1301.1522 R:-1351.5859 gloss:-40.5912 dloss:40.5912\n",
      "Episode:620 meanR:-1301.6591 R:-1354.5737 gloss:-40.1401 dloss:40.1401\n",
      "Episode:621 meanR:-1305.8709 R:-1336.8510 gloss:-40.6235 dloss:40.6235\n",
      "Episode:622 meanR:-1308.8660 R:-1067.3946 gloss:-40.1132 dloss:40.1132\n",
      "Episode:623 meanR:-1308.6598 R:-1360.4956 gloss:-39.6343 dloss:39.6343\n",
      "Episode:624 meanR:-1308.8312 R:-1187.9607 gloss:-40.4687 dloss:40.4687\n",
      "Episode:625 meanR:-1309.0474 R:-1344.0341 gloss:-39.9585 dloss:39.9585\n",
      "Episode:626 meanR:-1306.3085 R:-1077.8203 gloss:-40.1927 dloss:40.1927\n",
      "Episode:627 meanR:-1307.0242 R:-1362.3325 gloss:-40.2893 dloss:40.2893\n",
      "Episode:628 meanR:-1303.2988 R:-920.9593 gloss:-40.2222 dloss:40.2222\n",
      "Episode:629 meanR:-1300.5379 R:-906.9164 gloss:-40.1691 dloss:40.1691\n",
      "Episode:630 meanR:-1302.4370 R:-1515.5608 gloss:-39.8981 dloss:39.8981\n",
      "Episode:631 meanR:-1303.3001 R:-1358.2728 gloss:-40.5980 dloss:40.5980\n",
      "Episode:632 meanR:-1301.9118 R:-1224.6562 gloss:-40.5363 dloss:40.5363\n",
      "Episode:633 meanR:-1306.0015 R:-1660.7756 gloss:-40.1246 dloss:40.1246\n",
      "Episode:634 meanR:-1303.9690 R:-1125.3064 gloss:-40.5127 dloss:40.5127\n",
      "Episode:635 meanR:-1307.9184 R:-1156.4299 gloss:-40.5931 dloss:40.5931\n",
      "Episode:636 meanR:-1307.9633 R:-1332.9715 gloss:-40.1386 dloss:40.1386\n",
      "Episode:637 meanR:-1309.3227 R:-1339.6136 gloss:-39.8363 dloss:39.8363\n",
      "Episode:638 meanR:-1309.4519 R:-1375.4406 gloss:-40.6545 dloss:40.6545\n",
      "Episode:639 meanR:-1310.3882 R:-1455.5582 gloss:-40.4698 dloss:40.4698\n",
      "Episode:640 meanR:-1312.0034 R:-1517.1420 gloss:-39.5814 dloss:39.5814\n",
      "Episode:641 meanR:-1313.8475 R:-1546.7856 gloss:-40.9745 dloss:40.9745\n",
      "Episode:642 meanR:-1322.1756 R:-1592.0224 gloss:-40.3112 dloss:40.3112\n",
      "Episode:643 meanR:-1327.1636 R:-1862.0069 gloss:-40.5897 dloss:40.5897\n",
      "Episode:644 meanR:-1328.0874 R:-1285.7676 gloss:-40.5761 dloss:40.5761\n",
      "Episode:645 meanR:-1322.0037 R:-721.9671 gloss:-39.9912 dloss:39.9912\n",
      "Episode:646 meanR:-1324.6256 R:-1577.6289 gloss:-41.1181 dloss:41.1181\n",
      "Episode:647 meanR:-1325.6797 R:-1378.8688 gloss:-41.4726 dloss:41.4726\n",
      "Episode:648 meanR:-1329.3363 R:-1350.5409 gloss:-40.5461 dloss:40.5461\n",
      "Episode:649 meanR:-1330.1230 R:-1358.0403 gloss:-40.9250 dloss:40.9250\n",
      "Episode:650 meanR:-1327.5616 R:-1372.4684 gloss:-40.5141 dloss:40.5141\n",
      "Episode:651 meanR:-1329.5539 R:-1193.8122 gloss:-40.4650 dloss:40.4650\n",
      "Episode:652 meanR:-1328.5745 R:-1224.2926 gloss:-41.1270 dloss:41.1270\n",
      "Episode:653 meanR:-1327.1561 R:-1208.8231 gloss:-40.7640 dloss:40.7640\n",
      "Episode:654 meanR:-1325.2409 R:-1146.7130 gloss:-40.1012 dloss:40.1012\n",
      "Episode:655 meanR:-1324.2480 R:-1248.8680 gloss:-39.8634 dloss:39.8634\n",
      "Episode:656 meanR:-1324.8564 R:-1315.6613 gloss:-40.4107 dloss:40.4107\n",
      "Episode:657 meanR:-1323.9052 R:-1253.4287 gloss:-40.7764 dloss:40.7764\n",
      "Episode:658 meanR:-1322.9253 R:-1265.5601 gloss:-40.6556 dloss:40.6556\n",
      "Episode:659 meanR:-1319.9984 R:-1321.7129 gloss:-40.3478 dloss:40.3478\n",
      "Episode:660 meanR:-1320.2919 R:-1343.1969 gloss:-40.4930 dloss:40.4930\n",
      "Episode:661 meanR:-1324.9695 R:-1777.4491 gloss:-40.0789 dloss:40.0789\n",
      "Episode:662 meanR:-1324.6778 R:-1320.9931 gloss:-40.3233 dloss:40.3233\n",
      "Episode:663 meanR:-1326.8381 R:-1560.1955 gloss:-39.7101 dloss:39.7101\n",
      "Episode:664 meanR:-1332.3415 R:-1611.3043 gloss:-39.9637 dloss:39.9637\n",
      "Episode:665 meanR:-1326.6902 R:-768.5778 gloss:-39.9901 dloss:39.9901\n",
      "Episode:666 meanR:-1323.3841 R:-987.6817 gloss:-40.3782 dloss:40.3782\n",
      "Episode:667 meanR:-1322.7983 R:-1356.4804 gloss:-40.3928 dloss:40.3928\n",
      "Episode:668 meanR:-1325.2937 R:-1330.9874 gloss:-40.3539 dloss:40.3539\n",
      "Episode:669 meanR:-1326.1609 R:-1372.2895 gloss:-40.9375 dloss:40.9375\n",
      "Episode:670 meanR:-1327.9686 R:-1304.4419 gloss:-40.7597 dloss:40.7597\n",
      "Episode:671 meanR:-1330.8011 R:-1577.5883 gloss:-40.5524 dloss:40.5524\n",
      "Episode:672 meanR:-1329.9187 R:-1250.4233 gloss:-40.5114 dloss:40.5114\n",
      "Episode:673 meanR:-1328.9946 R:-1288.0239 gloss:-40.7110 dloss:40.7110\n",
      "Episode:674 meanR:-1327.8747 R:-1210.3477 gloss:-40.1494 dloss:40.1494\n",
      "Episode:675 meanR:-1330.5907 R:-1637.2336 gloss:-40.8658 dloss:40.8658\n",
      "Episode:676 meanR:-1336.7063 R:-1754.8158 gloss:-40.7718 dloss:40.7718\n",
      "Episode:677 meanR:-1336.5551 R:-1315.8212 gloss:-40.6087 dloss:40.6087\n",
      "Episode:678 meanR:-1341.3731 R:-1519.4276 gloss:-40.4617 dloss:40.4617\n",
      "Episode:679 meanR:-1335.5132 R:-1033.3635 gloss:-40.9824 dloss:40.9824\n",
      "Episode:680 meanR:-1335.1123 R:-1320.1233 gloss:-40.3985 dloss:40.3985\n",
      "Episode:681 meanR:-1333.8970 R:-992.2709 gloss:-40.1684 dloss:40.1684\n",
      "Episode:682 meanR:-1341.2451 R:-1771.4421 gloss:-40.7171 dloss:40.7171\n",
      "Episode:683 meanR:-1339.7163 R:-1209.6011 gloss:-40.9975 dloss:40.9975\n",
      "Episode:684 meanR:-1343.8485 R:-1541.3865 gloss:-41.4411 dloss:41.4411\n",
      "Episode:685 meanR:-1347.4101 R:-1651.3070 gloss:-40.9953 dloss:40.9953\n",
      "Episode:686 meanR:-1347.4774 R:-1334.8404 gloss:-40.3937 dloss:40.3937\n",
      "Episode:687 meanR:-1348.6595 R:-1483.0744 gloss:-40.9615 dloss:40.9615\n",
      "Episode:688 meanR:-1349.6790 R:-1182.0149 gloss:-41.5349 dloss:41.5349\n",
      "Episode:689 meanR:-1349.1551 R:-1320.6379 gloss:-41.0085 dloss:41.0085\n",
      "Episode:690 meanR:-1352.6437 R:-1662.2882 gloss:-41.0890 dloss:41.0890\n",
      "Episode:691 meanR:-1357.7415 R:-1852.1271 gloss:-41.0057 dloss:41.0057\n",
      "Episode:692 meanR:-1360.5314 R:-1628.7493 gloss:-40.8917 dloss:40.8917\n",
      "Episode:693 meanR:-1360.4096 R:-1336.6041 gloss:-40.7623 dloss:40.7623\n",
      "Episode:694 meanR:-1361.3015 R:-1436.4875 gloss:-41.5657 dloss:41.5657\n",
      "Episode:695 meanR:-1362.9265 R:-1488.8762 gloss:-40.8647 dloss:40.8647\n",
      "Episode:696 meanR:-1359.8600 R:-1388.9816 gloss:-41.0454 dloss:41.0454\n",
      "Episode:697 meanR:-1355.2841 R:-1308.7450 gloss:-40.3077 dloss:40.3077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:698 meanR:-1353.6135 R:-1163.0504 gloss:-40.5851 dloss:40.5851\n",
      "Episode:699 meanR:-1352.6707 R:-1164.7117 gloss:-40.8243 dloss:40.8243\n",
      "Episode:700 meanR:-1348.8293 R:-961.0187 gloss:-40.6435 dloss:40.6435\n",
      "Episode:701 meanR:-1346.9944 R:-1180.5594 gloss:-41.1760 dloss:41.1760\n",
      "Episode:702 meanR:-1344.4100 R:-1026.7826 gloss:-41.5758 dloss:41.5758\n",
      "Episode:703 meanR:-1341.5136 R:-1046.1161 gloss:-40.6525 dloss:40.6525\n",
      "Episode:704 meanR:-1340.2469 R:-1215.0512 gloss:-41.1168 dloss:41.1168\n",
      "Episode:705 meanR:-1338.4816 R:-1116.7678 gloss:-41.0991 dloss:41.0991\n",
      "Episode:706 meanR:-1334.4032 R:-1324.2070 gloss:-40.4546 dloss:40.4546\n",
      "Episode:707 meanR:-1337.6167 R:-1527.0219 gloss:-40.9311 dloss:40.9311\n",
      "Episode:708 meanR:-1339.2272 R:-1320.9493 gloss:-41.2652 dloss:41.2652\n",
      "Episode:709 meanR:-1340.1348 R:-1163.4960 gloss:-40.8656 dloss:40.8656\n",
      "Episode:710 meanR:-1343.0700 R:-1604.8869 gloss:-40.3496 dloss:40.3496\n",
      "Episode:711 meanR:-1341.6974 R:-1226.7461 gloss:-40.2039 dloss:40.2039\n",
      "Episode:712 meanR:-1339.8791 R:-1315.1743 gloss:-40.5774 dloss:40.5774\n",
      "Episode:713 meanR:-1341.3351 R:-1500.9013 gloss:-41.3840 dloss:41.3840\n",
      "Episode:714 meanR:-1338.9459 R:-900.7600 gloss:-40.5875 dloss:40.5875\n",
      "Episode:715 meanR:-1338.3936 R:-1494.8113 gloss:-41.0322 dloss:41.0322\n",
      "Episode:716 meanR:-1338.0974 R:-1349.8789 gloss:-41.1828 dloss:41.1828\n",
      "Episode:717 meanR:-1333.3074 R:-1292.7978 gloss:-40.9639 dloss:40.9639\n",
      "Episode:718 meanR:-1330.1973 R:-1336.2243 gloss:-40.1265 dloss:40.1265\n",
      "Episode:719 meanR:-1329.6577 R:-1297.6244 gloss:-40.3123 dloss:40.3123\n",
      "Episode:720 meanR:-1334.1184 R:-1800.6464 gloss:-40.5833 dloss:40.5833\n",
      "Episode:721 meanR:-1337.2649 R:-1651.4998 gloss:-41.2749 dloss:41.2749\n",
      "Episode:722 meanR:-1343.5757 R:-1698.4679 gloss:-40.8543 dloss:40.8543\n",
      "Episode:723 meanR:-1342.9953 R:-1302.4582 gloss:-40.5351 dloss:40.5351\n",
      "Episode:724 meanR:-1342.3888 R:-1127.3072 gloss:-40.7655 dloss:40.7655\n",
      "Episode:725 meanR:-1342.1547 R:-1320.6294 gloss:-40.4024 dloss:40.4024\n",
      "Episode:726 meanR:-1344.1637 R:-1278.7180 gloss:-40.7316 dloss:40.7316\n",
      "Episode:727 meanR:-1348.0435 R:-1750.3143 gloss:-41.5106 dloss:41.5106\n",
      "Episode:728 meanR:-1349.8553 R:-1102.1402 gloss:-41.2154 dloss:41.2154\n",
      "Episode:729 meanR:-1357.6483 R:-1686.2147 gloss:-41.0354 dloss:41.0354\n",
      "Episode:730 meanR:-1358.6304 R:-1613.7671 gloss:-41.1712 dloss:41.1712\n",
      "Episode:731 meanR:-1356.2227 R:-1117.5043 gloss:-40.5606 dloss:40.5606\n",
      "Episode:732 meanR:-1357.4862 R:-1351.0037 gloss:-41.8165 dloss:41.8165\n",
      "Episode:733 meanR:-1359.0017 R:-1812.3325 gloss:-41.1794 dloss:41.1794\n",
      "Episode:734 meanR:-1363.9892 R:-1624.0498 gloss:-41.0754 dloss:41.0754\n",
      "Episode:735 meanR:-1365.7914 R:-1336.6569 gloss:-40.8762 dloss:40.8762\n",
      "Episode:736 meanR:-1365.9511 R:-1348.9398 gloss:-40.7279 dloss:40.7279\n",
      "Episode:737 meanR:-1365.8050 R:-1324.9993 gloss:-40.9409 dloss:40.9409\n",
      "Episode:738 meanR:-1364.5473 R:-1249.6758 gloss:-40.6817 dloss:40.6817\n",
      "Episode:739 meanR:-1360.0187 R:-1002.6934 gloss:-40.6220 dloss:40.6220\n",
      "Episode:740 meanR:-1356.8342 R:-1198.6925 gloss:-40.5936 dloss:40.5936\n",
      "Episode:741 meanR:-1358.9840 R:-1761.7670 gloss:-40.6200 dloss:40.6200\n",
      "Episode:742 meanR:-1359.7538 R:-1669.0065 gloss:-41.7765 dloss:41.7765\n",
      "Episode:743 meanR:-1354.7509 R:-1361.7143 gloss:-41.4771 dloss:41.4771\n",
      "Episode:744 meanR:-1355.6908 R:-1379.7534 gloss:-40.7456 dloss:40.7456\n",
      "Episode:745 meanR:-1365.0391 R:-1656.8058 gloss:-40.9216 dloss:40.9216\n",
      "Episode:746 meanR:-1363.0390 R:-1377.6166 gloss:-41.0119 dloss:41.0119\n",
      "Episode:747 meanR:-1362.8579 R:-1360.7603 gloss:-40.5942 dloss:40.5942\n",
      "Episode:748 meanR:-1362.8013 R:-1344.8772 gloss:-41.2628 dloss:41.2628\n",
      "Episode:749 meanR:-1363.7127 R:-1449.1783 gloss:-41.1284 dloss:41.1284\n",
      "Episode:750 meanR:-1361.6679 R:-1167.9952 gloss:-40.8818 dloss:40.8818\n",
      "Episode:751 meanR:-1367.6326 R:-1790.2766 gloss:-41.5549 dloss:41.5549\n",
      "Episode:752 meanR:-1372.2525 R:-1686.2830 gloss:-41.9056 dloss:41.9056\n",
      "Episode:753 meanR:-1377.4132 R:-1724.8931 gloss:-41.0665 dloss:41.0665\n",
      "Episode:754 meanR:-1379.2880 R:-1334.1913 gloss:-41.2061 dloss:41.2061\n",
      "Episode:755 meanR:-1380.1093 R:-1330.9972 gloss:-41.2817 dloss:41.2817\n",
      "Episode:756 meanR:-1380.4160 R:-1346.3386 gloss:-40.5569 dloss:40.5569\n",
      "Episode:757 meanR:-1384.4068 R:-1652.5058 gloss:-41.4394 dloss:41.4394\n",
      "Episode:758 meanR:-1389.1200 R:-1736.8812 gloss:-41.6890 dloss:41.6890\n",
      "Episode:759 meanR:-1393.3341 R:-1743.1214 gloss:-41.5263 dloss:41.5263\n",
      "Episode:760 meanR:-1391.5692 R:-1166.7050 gloss:-41.1217 dloss:41.1217\n",
      "Episode:761 meanR:-1390.8192 R:-1702.4462 gloss:-41.8303 dloss:41.8303\n",
      "Episode:762 meanR:-1395.0458 R:-1743.6606 gloss:-41.1057 dloss:41.1057\n",
      "Episode:763 meanR:-1390.2631 R:-1081.9202 gloss:-41.2193 dloss:41.2193\n",
      "Episode:764 meanR:-1386.4569 R:-1230.6885 gloss:-41.5815 dloss:41.5815\n",
      "Episode:765 meanR:-1396.4748 R:-1770.3670 gloss:-40.9843 dloss:40.9843\n",
      "Episode:766 meanR:-1399.2261 R:-1262.8150 gloss:-41.3697 dloss:41.3697\n",
      "Episode:767 meanR:-1402.5593 R:-1689.7928 gloss:-42.0320 dloss:42.0320\n",
      "Episode:768 meanR:-1406.8836 R:-1763.4166 gloss:-41.2993 dloss:41.2993\n",
      "Episode:769 meanR:-1411.0592 R:-1789.8486 gloss:-41.5751 dloss:41.5751\n",
      "Episode:770 meanR:-1410.8728 R:-1285.8055 gloss:-41.6450 dloss:41.6450\n",
      "Episode:771 meanR:-1408.7759 R:-1367.9002 gloss:-42.1879 dloss:42.1879\n",
      "Episode:772 meanR:-1412.7972 R:-1652.5549 gloss:-41.7275 dloss:41.7275\n",
      "Episode:773 meanR:-1413.3127 R:-1339.5705 gloss:-41.6722 dloss:41.6722\n",
      "Episode:774 meanR:-1414.8809 R:-1367.1701 gloss:-42.2905 dloss:42.2905\n",
      "Episode:775 meanR:-1410.2203 R:-1171.1698 gloss:-41.6269 dloss:41.6269\n",
      "Episode:776 meanR:-1410.2556 R:-1758.3522 gloss:-41.7368 dloss:41.7368\n",
      "Episode:777 meanR:-1410.2064 R:-1310.9000 gloss:-41.5085 dloss:41.5085\n",
      "Episode:778 meanR:-1406.7670 R:-1175.4836 gloss:-41.9123 dloss:41.9123\n",
      "Episode:779 meanR:-1413.7968 R:-1736.3422 gloss:-41.8356 dloss:41.8356\n",
      "Episode:780 meanR:-1413.4549 R:-1285.9333 gloss:-42.0610 dloss:42.0610\n",
      "Episode:781 meanR:-1416.0965 R:-1256.4284 gloss:-41.9179 dloss:41.9179\n",
      "Episode:782 meanR:-1410.4857 R:-1210.3696 gloss:-40.6258 dloss:40.6258\n",
      "Episode:783 meanR:-1411.3991 R:-1300.9372 gloss:-41.5736 dloss:41.5736\n",
      "Episode:784 meanR:-1413.3668 R:-1738.1565 gloss:-42.5811 dloss:42.5811\n",
      "Episode:785 meanR:-1414.1704 R:-1731.6666 gloss:-41.1928 dloss:41.1928\n",
      "Episode:786 meanR:-1417.9083 R:-1708.6334 gloss:-41.4331 dloss:41.4331\n",
      "Episode:787 meanR:-1416.0903 R:-1301.2710 gloss:-41.6364 dloss:41.6364\n",
      "Episode:788 meanR:-1416.9930 R:-1272.2899 gloss:-41.1313 dloss:41.1313\n",
      "Episode:789 meanR:-1416.8824 R:-1309.5702 gloss:-41.6175 dloss:41.6175\n",
      "Episode:790 meanR:-1412.8312 R:-1257.1733 gloss:-41.5182 dloss:41.5182\n",
      "Episode:791 meanR:-1411.3038 R:-1699.3867 gloss:-41.4160 dloss:41.4160\n",
      "Episode:792 meanR:-1411.9191 R:-1690.2788 gloss:-41.5965 dloss:41.5965\n",
      "Episode:793 meanR:-1411.5505 R:-1299.7414 gloss:-42.0070 dloss:42.0070\n",
      "Episode:794 meanR:-1410.3310 R:-1314.5356 gloss:-41.5181 dloss:41.5181\n",
      "Episode:795 meanR:-1407.8310 R:-1238.8854 gloss:-41.9780 dloss:41.9780\n",
      "Episode:796 meanR:-1406.0419 R:-1210.0670 gloss:-41.8560 dloss:41.8560\n",
      "Episode:797 meanR:-1406.3995 R:-1344.5043 gloss:-41.4919 dloss:41.4919\n",
      "Episode:798 meanR:-1408.2172 R:-1344.8216 gloss:-41.4067 dloss:41.4067\n",
      "Episode:799 meanR:-1410.0241 R:-1345.4063 gloss:-41.7062 dloss:41.7062\n",
      "Episode:800 meanR:-1418.1178 R:-1770.3879 gloss:-41.8312 dloss:41.8312\n",
      "Episode:801 meanR:-1424.0610 R:-1774.8797 gloss:-41.7717 dloss:41.7717\n",
      "Episode:802 meanR:-1430.5829 R:-1678.9730 gloss:-42.0542 dloss:42.0542\n",
      "Episode:803 meanR:-1432.3166 R:-1219.4836 gloss:-41.8291 dloss:41.8291\n",
      "Episode:804 meanR:-1438.0587 R:-1789.2599 gloss:-42.0208 dloss:42.0208\n",
      "Episode:805 meanR:-1444.6849 R:-1779.3912 gloss:-42.2299 dloss:42.2299\n",
      "Episode:806 meanR:-1447.1406 R:-1569.7755 gloss:-41.9980 dloss:41.9980\n",
      "Episode:807 meanR:-1444.9370 R:-1306.6641 gloss:-42.0284 dloss:42.0284\n",
      "Episode:808 meanR:-1448.9476 R:-1722.0070 gloss:-41.6431 dloss:41.6431\n",
      "Episode:809 meanR:-1451.4669 R:-1415.4195 gloss:-41.6935 dloss:41.6935\n",
      "Episode:810 meanR:-1448.7145 R:-1329.6483 gloss:-42.1858 dloss:42.1858\n",
      "Episode:811 meanR:-1445.8243 R:-937.7286 gloss:-42.8815 dloss:42.8815\n",
      "Episode:812 meanR:-1449.1253 R:-1645.2748 gloss:-41.4079 dloss:41.4079\n",
      "Episode:813 meanR:-1445.4399 R:-1132.3590 gloss:-42.5004 dloss:42.5004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:814 meanR:-1445.2478 R:-881.5521 gloss:-42.6583 dloss:42.6583\n",
      "Episode:815 meanR:-1442.1207 R:-1182.1046 gloss:-42.1058 dloss:42.1058\n",
      "Episode:816 meanR:-1440.6370 R:-1201.5078 gloss:-42.2982 dloss:42.2982\n",
      "Episode:817 meanR:-1441.0716 R:-1336.2514 gloss:-41.5415 dloss:41.5415\n",
      "Episode:818 meanR:-1444.1157 R:-1640.6342 gloss:-42.5736 dloss:42.5736\n",
      "Episode:819 meanR:-1443.8636 R:-1272.4225 gloss:-41.9557 dloss:41.9557\n",
      "Episode:820 meanR:-1438.9508 R:-1309.3622 gloss:-41.9277 dloss:41.9277\n",
      "Episode:821 meanR:-1434.1722 R:-1173.6380 gloss:-41.9470 dloss:41.9470\n",
      "Episode:822 meanR:-1435.0017 R:-1781.4231 gloss:-42.6147 dloss:42.6147\n",
      "Episode:823 meanR:-1433.9249 R:-1194.7735 gloss:-42.3424 dloss:42.3424\n",
      "Episode:824 meanR:-1439.7157 R:-1706.3903 gloss:-41.6721 dloss:41.6721\n",
      "Episode:825 meanR:-1438.9263 R:-1241.6880 gloss:-42.9913 dloss:42.9913\n",
      "Episode:826 meanR:-1443.6480 R:-1750.8926 gloss:-41.9499 dloss:41.9499\n",
      "Episode:827 meanR:-1439.2297 R:-1308.4749 gloss:-42.1729 dloss:42.1729\n",
      "Episode:828 meanR:-1439.2201 R:-1101.1833 gloss:-42.6272 dloss:42.6272\n",
      "Episode:829 meanR:-1440.2220 R:-1786.4075 gloss:-42.3053 dloss:42.3053\n",
      "Episode:830 meanR:-1436.4470 R:-1236.2659 gloss:-42.5979 dloss:42.5979\n",
      "Episode:831 meanR:-1443.3074 R:-1803.5425 gloss:-42.9472 dloss:42.9472\n",
      "Episode:832 meanR:-1443.2988 R:-1350.1431 gloss:-41.8319 dloss:41.8319\n",
      "Episode:833 meanR:-1443.2320 R:-1805.6571 gloss:-42.3992 dloss:42.3992\n",
      "Episode:834 meanR:-1443.8460 R:-1685.4501 gloss:-41.9164 dloss:41.9164\n",
      "Episode:835 meanR:-1442.4936 R:-1201.4096 gloss:-41.7266 dloss:41.7266\n",
      "Episode:836 meanR:-1441.6430 R:-1263.8864 gloss:-42.6087 dloss:42.6087\n",
      "Episode:837 meanR:-1440.0671 R:-1167.4032 gloss:-41.9217 dloss:41.9217\n",
      "Episode:838 meanR:-1445.7052 R:-1813.4905 gloss:-43.2369 dloss:43.2369\n",
      "Episode:839 meanR:-1448.9226 R:-1324.4379 gloss:-42.4431 dloss:42.4431\n",
      "Episode:840 meanR:-1449.8481 R:-1291.2364 gloss:-41.9398 dloss:41.9398\n",
      "Episode:841 meanR:-1450.0280 R:-1779.7535 gloss:-42.8590 dloss:42.8590\n",
      "Episode:842 meanR:-1444.5235 R:-1118.5620 gloss:-42.5246 dloss:42.5246\n",
      "Episode:843 meanR:-1447.7655 R:-1685.9149 gloss:-42.6943 dloss:42.6943\n",
      "Episode:844 meanR:-1452.1531 R:-1818.5156 gloss:-42.6382 dloss:42.6382\n",
      "Episode:845 meanR:-1446.8361 R:-1125.1069 gloss:-43.0405 dloss:43.0405\n",
      "Episode:846 meanR:-1445.4176 R:-1235.7627 gloss:-43.0691 dloss:43.0691\n",
      "Episode:847 meanR:-1443.3250 R:-1151.4979 gloss:-42.6021 dloss:42.6021\n",
      "Episode:848 meanR:-1443.0735 R:-1319.7286 gloss:-42.4695 dloss:42.4695\n",
      "Episode:849 meanR:-1439.0295 R:-1044.7795 gloss:-42.3684 dloss:42.3684\n",
      "Episode:850 meanR:-1438.5631 R:-1121.3566 gloss:-42.6303 dloss:42.6303\n",
      "Episode:851 meanR:-1432.8601 R:-1219.9763 gloss:-42.3149 dloss:42.3149\n",
      "Episode:852 meanR:-1432.7374 R:-1674.0066 gloss:-42.7470 dloss:42.7470\n",
      "Episode:853 meanR:-1433.0498 R:-1756.1414 gloss:-42.8028 dloss:42.8028\n",
      "Episode:854 meanR:-1433.2447 R:-1353.6750 gloss:-43.2601 dloss:43.2601\n",
      "Episode:855 meanR:-1430.7521 R:-1081.7358 gloss:-43.0981 dloss:43.0981\n",
      "Episode:856 meanR:-1428.5017 R:-1121.2982 gloss:-43.1160 dloss:43.1160\n",
      "Episode:857 meanR:-1429.6268 R:-1765.0151 gloss:-42.2839 dloss:42.2839\n",
      "Episode:858 meanR:-1423.7719 R:-1151.3976 gloss:-42.6686 dloss:42.6686\n",
      "Episode:859 meanR:-1423.4698 R:-1712.9062 gloss:-42.9771 dloss:42.9771\n",
      "Episode:860 meanR:-1429.6206 R:-1781.7880 gloss:-43.1206 dloss:43.1206\n",
      "Episode:861 meanR:-1429.5377 R:-1694.1606 gloss:-42.9754 dloss:42.9754\n",
      "Episode:862 meanR:-1425.5896 R:-1348.8471 gloss:-42.2944 dloss:42.2944\n",
      "Episode:863 meanR:-1426.1558 R:-1138.5403 gloss:-43.5563 dloss:43.5563\n",
      "Episode:864 meanR:-1430.4046 R:-1655.5651 gloss:-42.3975 dloss:42.3975\n",
      "Episode:865 meanR:-1424.7640 R:-1206.3050 gloss:-42.7479 dloss:42.7479\n",
      "Episode:866 meanR:-1423.0067 R:-1087.0882 gloss:-42.5755 dloss:42.5755\n",
      "Episode:867 meanR:-1424.0532 R:-1794.4463 gloss:-42.8691 dloss:42.8691\n",
      "Episode:868 meanR:-1422.4907 R:-1607.1598 gloss:-42.8606 dloss:42.8606\n",
      "Episode:869 meanR:-1417.7120 R:-1311.9800 gloss:-43.1395 dloss:43.1395\n",
      "Episode:870 meanR:-1417.6317 R:-1277.7770 gloss:-43.1912 dloss:43.1912\n",
      "Episode:871 meanR:-1417.5845 R:-1363.1848 gloss:-43.1206 dloss:43.1206\n",
      "Episode:872 meanR:-1413.8414 R:-1278.2404 gloss:-42.9463 dloss:42.9463\n",
      "Episode:873 meanR:-1417.9089 R:-1746.3208 gloss:-42.8276 dloss:42.8276\n",
      "Episode:874 meanR:-1422.1327 R:-1789.5532 gloss:-42.7896 dloss:42.7896\n",
      "Episode:875 meanR:-1422.3709 R:-1194.9856 gloss:-43.4384 dloss:43.4384\n",
      "Episode:876 meanR:-1422.9175 R:-1813.0139 gloss:-43.4466 dloss:43.4466\n",
      "Episode:877 meanR:-1421.8368 R:-1202.8349 gloss:-43.3997 dloss:43.3997\n",
      "Episode:878 meanR:-1423.3845 R:-1330.2513 gloss:-43.3707 dloss:43.3707\n",
      "Episode:879 meanR:-1419.1811 R:-1315.9994 gloss:-42.5457 dloss:42.5457\n",
      "Episode:880 meanR:-1418.3771 R:-1205.5312 gloss:-43.1570 dloss:43.1570\n",
      "Episode:881 meanR:-1423.9201 R:-1810.7267 gloss:-42.5528 dloss:42.5528\n",
      "Episode:882 meanR:-1423.4674 R:-1165.1058 gloss:-43.0783 dloss:43.0783\n",
      "Episode:883 meanR:-1423.7263 R:-1326.8265 gloss:-43.3356 dloss:43.3356\n",
      "Episode:884 meanR:-1419.7408 R:-1339.6009 gloss:-43.0070 dloss:43.0070\n",
      "Episode:885 meanR:-1414.5934 R:-1216.9269 gloss:-42.9344 dloss:42.9344\n",
      "Episode:886 meanR:-1408.6123 R:-1110.5299 gloss:-42.4127 dloss:42.4127\n",
      "Episode:887 meanR:-1413.0466 R:-1744.6965 gloss:-42.8026 dloss:42.8026\n",
      "Episode:888 meanR:-1418.6919 R:-1836.8274 gloss:-43.1493 dloss:43.1493\n",
      "Episode:889 meanR:-1417.8182 R:-1222.1933 gloss:-42.7886 dloss:42.7886\n",
      "Episode:890 meanR:-1417.8074 R:-1256.0985 gloss:-43.2071 dloss:43.2071\n",
      "Episode:891 meanR:-1412.4639 R:-1165.0304 gloss:-42.8554 dloss:42.8554\n",
      "Episode:892 meanR:-1408.5875 R:-1302.6429 gloss:-42.7453 dloss:42.7453\n",
      "Episode:893 meanR:-1413.2393 R:-1764.9188 gloss:-43.1596 dloss:43.1596\n",
      "Episode:894 meanR:-1411.0360 R:-1094.2042 gloss:-42.9558 dloss:42.9558\n",
      "Episode:895 meanR:-1409.2428 R:-1059.5693 gloss:-42.6574 dloss:42.6574\n",
      "Episode:896 meanR:-1409.2011 R:-1205.8993 gloss:-43.4622 dloss:43.4622\n",
      "Episode:897 meanR:-1407.1210 R:-1136.4866 gloss:-42.4991 dloss:42.4991\n",
      "Episode:898 meanR:-1406.1563 R:-1248.3550 gloss:-42.6494 dloss:42.6494\n",
      "Episode:899 meanR:-1404.1104 R:-1140.8146 gloss:-43.9425 dloss:43.9425\n",
      "Episode:900 meanR:-1399.7672 R:-1336.0704 gloss:-42.9718 dloss:42.9718\n",
      "Episode:901 meanR:-1395.4247 R:-1340.6297 gloss:-43.4200 dloss:43.4200\n",
      "Episode:902 meanR:-1392.0746 R:-1343.9595 gloss:-43.0281 dloss:43.0281\n",
      "Episode:903 meanR:-1392.1891 R:-1230.9407 gloss:-43.3664 dloss:43.3664\n",
      "Episode:904 meanR:-1386.3761 R:-1207.9576 gloss:-43.0280 dloss:43.0280\n",
      "Episode:905 meanR:-1381.3470 R:-1276.4789 gloss:-42.8101 dloss:42.8101\n",
      "Episode:906 meanR:-1377.5225 R:-1187.3305 gloss:-43.0185 dloss:43.0185\n",
      "Episode:907 meanR:-1375.5887 R:-1113.2808 gloss:-43.6783 dloss:43.6783\n",
      "Episode:908 meanR:-1369.6359 R:-1126.7230 gloss:-43.3516 dloss:43.3516\n",
      "Episode:909 meanR:-1366.6063 R:-1112.4646 gloss:-42.4241 dloss:42.4241\n",
      "Episode:910 meanR:-1364.6055 R:-1129.5648 gloss:-43.0218 dloss:43.0218\n",
      "Episode:911 meanR:-1372.7864 R:-1755.8205 gloss:-43.6081 dloss:43.6081\n",
      "Episode:912 meanR:-1367.3893 R:-1105.5636 gloss:-42.8899 dloss:42.8899\n",
      "Episode:913 meanR:-1369.5724 R:-1350.6711 gloss:-43.0292 dloss:43.0292\n",
      "Episode:914 meanR:-1374.1928 R:-1343.5862 gloss:-43.3480 dloss:43.3480\n",
      "Episode:915 meanR:-1375.7421 R:-1337.0355 gloss:-42.8983 dloss:42.8983\n",
      "Episode:916 meanR:-1376.4752 R:-1274.8204 gloss:-43.3135 dloss:43.3135\n",
      "Episode:917 meanR:-1380.2832 R:-1717.0552 gloss:-43.3541 dloss:43.3541\n",
      "Episode:918 meanR:-1380.7587 R:-1688.1776 gloss:-42.4150 dloss:42.4150\n",
      "Episode:919 meanR:-1379.4309 R:-1139.6491 gloss:-43.6583 dloss:43.6583\n",
      "Episode:920 meanR:-1379.7682 R:-1343.0919 gloss:-43.1591 dloss:43.1591\n",
      "Episode:921 meanR:-1379.7702 R:-1173.8380 gloss:-42.8182 dloss:42.8182\n",
      "Episode:922 meanR:-1375.1016 R:-1314.5611 gloss:-42.6189 dloss:42.6189\n",
      "Episode:923 meanR:-1374.5952 R:-1144.1290 gloss:-42.6165 dloss:42.6165\n",
      "Episode:924 meanR:-1367.5157 R:-998.4422 gloss:-43.1477 dloss:43.1477\n",
      "Episode:925 meanR:-1372.9042 R:-1780.5381 gloss:-43.0542 dloss:43.0542\n",
      "Episode:926 meanR:-1367.7101 R:-1231.4884 gloss:-43.3565 dloss:43.3565\n",
      "Episode:927 meanR:-1371.9587 R:-1733.3263 gloss:-42.6864 dloss:42.6864\n",
      "Episode:928 meanR:-1379.2980 R:-1835.1130 gloss:-43.4642 dloss:43.4642\n",
      "Episode:929 meanR:-1379.4952 R:-1806.1279 gloss:-43.4041 dloss:43.4041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:930 meanR:-1379.1040 R:-1197.1473 gloss:-43.3916 dloss:43.3916\n",
      "Episode:931 meanR:-1373.3770 R:-1230.8504 gloss:-43.2055 dloss:43.2055\n",
      "Episode:932 meanR:-1370.1751 R:-1029.9460 gloss:-43.1879 dloss:43.1879\n",
      "Episode:933 meanR:-1365.5508 R:-1343.2307 gloss:-43.1584 dloss:43.1584\n",
      "Episode:934 meanR:-1366.5651 R:-1786.8827 gloss:-43.5320 dloss:43.5320\n",
      "Episode:935 meanR:-1372.2473 R:-1769.6213 gloss:-43.1859 dloss:43.1859\n",
      "Episode:936 meanR:-1377.4588 R:-1785.0385 gloss:-42.7629 dloss:42.7629\n",
      "Episode:937 meanR:-1378.2570 R:-1247.2260 gloss:-43.7365 dloss:43.7365\n",
      "Episode:938 meanR:-1373.3868 R:-1326.4686 gloss:-43.4384 dloss:43.4384\n",
      "Episode:939 meanR:-1378.4614 R:-1831.9033 gloss:-43.5243 dloss:43.5243\n",
      "Episode:940 meanR:-1376.5759 R:-1102.6794 gloss:-43.4310 dloss:43.4310\n",
      "Episode:941 meanR:-1369.7908 R:-1101.2433 gloss:-43.2023 dloss:43.2023\n",
      "Episode:942 meanR:-1377.0411 R:-1843.5953 gloss:-43.0465 dloss:43.0465\n",
      "Episode:943 meanR:-1370.0921 R:-991.0173 gloss:-42.9952 dloss:42.9952\n",
      "Episode:944 meanR:-1369.8690 R:-1796.1999 gloss:-43.2697 dloss:43.2697\n",
      "Episode:945 meanR:-1370.7273 R:-1210.9361 gloss:-43.3820 dloss:43.3820\n",
      "Episode:946 meanR:-1375.9855 R:-1761.5838 gloss:-43.7544 dloss:43.7544\n",
      "Episode:947 meanR:-1376.1164 R:-1164.5899 gloss:-43.3201 dloss:43.3201\n",
      "Episode:948 meanR:-1381.5484 R:-1862.9304 gloss:-43.4131 dloss:43.4131\n",
      "Episode:949 meanR:-1389.7333 R:-1863.2641 gloss:-43.1773 dloss:43.1773\n",
      "Episode:950 meanR:-1391.0436 R:-1252.3923 gloss:-43.7299 dloss:43.7299\n",
      "Episode:951 meanR:-1390.2220 R:-1137.8104 gloss:-43.6470 dloss:43.6470\n",
      "Episode:952 meanR:-1385.6482 R:-1216.6295 gloss:-43.7119 dloss:43.7119\n",
      "Episode:953 meanR:-1380.9939 R:-1290.7154 gloss:-44.5116 dloss:44.5116\n",
      "Episode:954 meanR:-1384.9522 R:-1749.4979 gloss:-43.9194 dloss:43.9194\n",
      "Episode:955 meanR:-1384.9044 R:-1076.9653 gloss:-43.1473 dloss:43.1473\n",
      "Episode:956 meanR:-1391.6635 R:-1797.2018 gloss:-43.7608 dloss:43.7608\n",
      "Episode:957 meanR:-1385.7189 R:-1170.5530 gloss:-43.9149 dloss:43.9149\n",
      "Episode:958 meanR:-1384.7476 R:-1054.2736 gloss:-43.5136 dloss:43.5136\n",
      "Episode:959 meanR:-1379.4317 R:-1181.3108 gloss:-43.9720 dloss:43.9720\n",
      "Episode:960 meanR:-1372.9144 R:-1130.0610 gloss:-43.8528 dloss:43.8528\n",
      "Episode:961 meanR:-1365.8206 R:-984.7804 gloss:-44.2170 dloss:44.2170\n",
      "Episode:962 meanR:-1364.7733 R:-1244.1147 gloss:-43.6607 dloss:43.6607\n",
      "Episode:963 meanR:-1365.7445 R:-1235.6660 gloss:-43.6505 dloss:43.6505\n",
      "Episode:964 meanR:-1362.4127 R:-1322.3826 gloss:-43.5884 dloss:43.5884\n",
      "Episode:965 meanR:-1362.2285 R:-1187.8893 gloss:-43.5559 dloss:43.5559\n",
      "Episode:966 meanR:-1362.2711 R:-1091.3434 gloss:-43.8208 dloss:43.8208\n",
      "Episode:967 meanR:-1356.8003 R:-1247.3619 gloss:-43.3907 dloss:43.3907\n",
      "Episode:968 meanR:-1352.5505 R:-1182.1840 gloss:-42.8583 dloss:42.8583\n",
      "Episode:969 meanR:-1349.5214 R:-1009.0736 gloss:-43.1262 dloss:43.1262\n",
      "Episode:970 meanR:-1354.6449 R:-1790.1231 gloss:-43.5665 dloss:43.5665\n",
      "Episode:971 meanR:-1359.4522 R:-1843.9182 gloss:-43.6463 dloss:43.6463\n",
      "Episode:972 meanR:-1365.0508 R:-1838.0975 gloss:-43.8760 dloss:43.8760\n",
      "Episode:973 meanR:-1358.0585 R:-1047.0950 gloss:-43.6310 dloss:43.6310\n",
      "Episode:974 meanR:-1351.8509 R:-1168.7915 gloss:-44.0531 dloss:44.0531\n",
      "Episode:975 meanR:-1357.8743 R:-1797.3245 gloss:-43.8581 dloss:43.8581\n",
      "Episode:976 meanR:-1351.9538 R:-1220.9632 gloss:-44.1190 dloss:44.1190\n",
      "Episode:977 meanR:-1352.0561 R:-1213.0624 gloss:-43.9344 dloss:43.9344\n",
      "Episode:978 meanR:-1351.7979 R:-1304.4368 gloss:-43.8629 dloss:43.8629\n",
      "Episode:979 meanR:-1350.2436 R:-1160.5612 gloss:-43.4023 dloss:43.4023\n",
      "Episode:980 meanR:-1349.5144 R:-1132.6109 gloss:-43.9007 dloss:43.9007\n",
      "Episode:981 meanR:-1349.4966 R:-1808.9563 gloss:-43.4098 dloss:43.4098\n",
      "Episode:982 meanR:-1348.7862 R:-1094.0564 gloss:-43.5485 dloss:43.5485\n",
      "Episode:983 meanR:-1347.1596 R:-1164.1690 gloss:-43.1514 dloss:43.1514\n",
      "Episode:984 meanR:-1345.6182 R:-1185.4662 gloss:-44.0151 dloss:44.0151\n",
      "Episode:985 meanR:-1346.4621 R:-1301.3176 gloss:-44.0760 dloss:44.0760\n",
      "Episode:986 meanR:-1354.1017 R:-1874.4849 gloss:-44.2060 dloss:44.2060\n",
      "Episode:987 meanR:-1348.7417 R:-1208.6929 gloss:-43.4368 dloss:43.4368\n",
      "Episode:988 meanR:-1348.7808 R:-1840.7442 gloss:-43.9614 dloss:43.9614\n",
      "Episode:989 meanR:-1348.1681 R:-1160.9259 gloss:-43.9755 dloss:43.9755\n",
      "Episode:990 meanR:-1353.9235 R:-1831.6332 gloss:-44.1404 dloss:44.1404\n",
      "Episode:991 meanR:-1353.5880 R:-1131.4776 gloss:-44.5142 dloss:44.5142\n",
      "Episode:992 meanR:-1358.5386 R:-1797.7039 gloss:-43.9955 dloss:43.9955\n",
      "Episode:993 meanR:-1352.1647 R:-1127.5311 gloss:-44.2565 dloss:44.2565\n",
      "Episode:994 meanR:-1352.7679 R:-1154.5202 gloss:-43.7908 dloss:43.7908\n",
      "Episode:995 meanR:-1360.0378 R:-1786.5637 gloss:-44.5456 dloss:44.5456\n",
      "Episode:996 meanR:-1359.6472 R:-1166.8403 gloss:-43.6305 dloss:43.6305\n",
      "Episode:997 meanR:-1361.8760 R:-1359.3645 gloss:-44.6318 dloss:44.6318\n",
      "Episode:998 meanR:-1361.3948 R:-1200.2358 gloss:-43.6886 dloss:43.6886\n",
      "Episode:999 meanR:-1361.3381 R:-1135.1415 gloss:-44.0168 dloss:44.0168\n",
      "Episode:1000 meanR:-1365.5392 R:-1756.1813 gloss:-44.2108 dloss:44.2108\n",
      "Episode:1001 meanR:-1363.8257 R:-1169.2794 gloss:-44.1465 dloss:44.1465\n",
      "Episode:1002 meanR:-1363.1471 R:-1276.1001 gloss:-44.3839 dloss:44.3839\n",
      "Episode:1003 meanR:-1368.4198 R:-1758.2116 gloss:-43.7376 dloss:43.7376\n",
      "Episode:1004 meanR:-1374.5817 R:-1824.1522 gloss:-43.8530 dloss:43.8530\n",
      "Episode:1005 meanR:-1373.8277 R:-1201.0773 gloss:-43.5918 dloss:43.5918\n",
      "Episode:1006 meanR:-1373.0942 R:-1113.9762 gloss:-43.8265 dloss:43.8265\n",
      "Episode:1007 meanR:-1374.0327 R:-1207.1332 gloss:-44.2357 dloss:44.2357\n",
      "Episode:1008 meanR:-1373.6091 R:-1084.3669 gloss:-43.7812 dloss:43.7812\n",
      "Episode:1009 meanR:-1374.7735 R:-1228.8994 gloss:-44.3766 dloss:44.3766\n",
      "Episode:1010 meanR:-1374.4274 R:-1094.9568 gloss:-44.0299 dloss:44.0299\n",
      "Episode:1011 meanR:-1368.2562 R:-1138.7018 gloss:-43.9257 dloss:43.9257\n",
      "Episode:1012 meanR:-1368.5373 R:-1133.6716 gloss:-43.8080 dloss:43.8080\n",
      "Episode:1013 meanR:-1366.7411 R:-1171.0552 gloss:-43.8559 dloss:43.8559\n",
      "Episode:1014 meanR:-1364.5760 R:-1127.0762 gloss:-44.1018 dloss:44.1018\n",
      "Episode:1015 meanR:-1363.3205 R:-1211.4778 gloss:-43.6315 dloss:43.6315\n",
      "Episode:1016 meanR:-1362.5501 R:-1197.7868 gloss:-43.6972 dloss:43.6972\n",
      "Episode:1017 meanR:-1355.3401 R:-996.0531 gloss:-43.8808 dloss:43.8808\n",
      "Episode:1018 meanR:-1348.7137 R:-1025.5388 gloss:-43.3480 dloss:43.3480\n",
      "Episode:1019 meanR:-1347.7531 R:-1043.5874 gloss:-43.5677 dloss:43.5677\n",
      "Episode:1020 meanR:-1344.1350 R:-981.2805 gloss:-43.7746 dloss:43.7746\n",
      "Episode:1021 meanR:-1342.9490 R:-1055.2368 gloss:-44.0320 dloss:44.0320\n",
      "Episode:1022 meanR:-1347.2645 R:-1746.1159 gloss:-44.7850 dloss:44.7850\n",
      "Episode:1023 meanR:-1346.7689 R:-1094.5666 gloss:-43.8119 dloss:43.8119\n",
      "Episode:1024 meanR:-1348.5505 R:-1176.6020 gloss:-44.0794 dloss:44.0794\n",
      "Episode:1025 meanR:-1341.8240 R:-1107.8869 gloss:-43.6425 dloss:43.6425\n",
      "Episode:1026 meanR:-1340.6920 R:-1118.2914 gloss:-43.9332 dloss:43.9332\n",
      "Episode:1027 meanR:-1341.5787 R:-1821.9960 gloss:-44.1624 dloss:44.1624\n",
      "Episode:1028 meanR:-1340.2095 R:-1698.1949 gloss:-44.0307 dloss:44.0307\n",
      "Episode:1029 meanR:-1334.1636 R:-1201.5393 gloss:-43.3093 dloss:43.3093\n",
      "Episode:1030 meanR:-1333.8289 R:-1163.6692 gloss:-44.1616 dloss:44.1616\n",
      "Episode:1031 meanR:-1339.7109 R:-1819.0534 gloss:-44.3153 dloss:44.3153\n",
      "Episode:1032 meanR:-1339.8837 R:-1047.2306 gloss:-43.7624 dloss:43.7624\n",
      "Episode:1033 meanR:-1338.4796 R:-1202.8200 gloss:-43.8909 dloss:43.8909\n",
      "Episode:1034 meanR:-1332.5114 R:-1190.0639 gloss:-44.0033 dloss:44.0033\n",
      "Episode:1035 meanR:-1326.5609 R:-1174.5634 gloss:-43.9664 dloss:43.9664\n",
      "Episode:1036 meanR:-1320.1226 R:-1141.2077 gloss:-43.7971 dloss:43.7971\n",
      "Episode:1037 meanR:-1319.5592 R:-1190.8888 gloss:-43.7687 dloss:43.7687\n",
      "Episode:1038 meanR:-1316.2600 R:-996.5505 gloss:-43.3501 dloss:43.3501\n",
      "Episode:1039 meanR:-1313.6662 R:-1572.5253 gloss:-43.7924 dloss:43.7924\n",
      "Episode:1040 meanR:-1313.0738 R:-1043.4387 gloss:-44.1283 dloss:44.1283\n",
      "Episode:1041 meanR:-1312.6733 R:-1061.1939 gloss:-43.4771 dloss:43.4771\n",
      "Episode:1042 meanR:-1312.1096 R:-1787.2210 gloss:-43.7946 dloss:43.7946\n",
      "Episode:1043 meanR:-1314.1122 R:-1191.2824 gloss:-44.2238 dloss:44.2238\n",
      "Episode:1044 meanR:-1308.1400 R:-1198.9796 gloss:-43.6008 dloss:43.6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1045 meanR:-1306.5295 R:-1049.8873 gloss:-44.3206 dloss:44.3206\n",
      "Episode:1046 meanR:-1300.8155 R:-1190.1759 gloss:-43.9507 dloss:43.9507\n",
      "Episode:1047 meanR:-1300.8519 R:-1168.2304 gloss:-43.7695 dloss:43.7695\n",
      "Episode:1048 meanR:-1292.1142 R:-989.1681 gloss:-44.4037 dloss:44.4037\n",
      "Episode:1049 meanR:-1285.0391 R:-1155.7541 gloss:-43.7772 dloss:43.7772\n",
      "Episode:1050 meanR:-1290.2056 R:-1769.0414 gloss:-43.7591 dloss:43.7591\n",
      "Episode:1051 meanR:-1297.3955 R:-1856.7997 gloss:-43.9201 dloss:43.9201\n",
      "Episode:1052 meanR:-1296.9364 R:-1170.7131 gloss:-43.7494 dloss:43.7494\n",
      "Episode:1053 meanR:-1302.1292 R:-1810.0034 gloss:-43.9686 dloss:43.9686\n",
      "Episode:1054 meanR:-1296.3705 R:-1173.6280 gloss:-43.5921 dloss:43.5921\n",
      "Episode:1055 meanR:-1297.0721 R:-1147.1186 gloss:-43.9826 dloss:43.9826\n",
      "Episode:1056 meanR:-1297.3710 R:-1827.0921 gloss:-43.9385 dloss:43.9385\n",
      "Episode:1057 meanR:-1297.5331 R:-1186.7626 gloss:-43.8505 dloss:43.8505\n",
      "Episode:1058 meanR:-1300.3762 R:-1338.5841 gloss:-43.5008 dloss:43.5008\n",
      "Episode:1059 meanR:-1299.0986 R:-1053.5492 gloss:-44.1971 dloss:44.1971\n",
      "Episode:1060 meanR:-1305.7152 R:-1791.7218 gloss:-44.6372 dloss:44.6372\n",
      "Episode:1061 meanR:-1313.5069 R:-1763.9498 gloss:-43.6712 dloss:43.6712\n",
      "Episode:1062 meanR:-1313.1534 R:-1208.7642 gloss:-43.9679 dloss:43.9679\n",
      "Episode:1063 meanR:-1311.3955 R:-1059.8807 gloss:-44.2339 dloss:44.2339\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, gloss_list, dloss_list = [], [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    episode_reward = deque(maxlen=100)\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(1111):\n",
    "        gloss_batch, dloss_batch = [], []\n",
    "        total_reward = 0\n",
    "        state = env.reset()\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            \n",
    "            action_pred = sess.run(model.actions_pred, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            noise = np.random.normal(loc=0, scale=0.1, size=action_size) # randomness\n",
    "            action = action_pred.reshape([-1]) + noise\n",
    "            #print(action.shape, action_logits.shape, noise.shape)\n",
    "            action = np.clip(action, -2, 2) # clipped: [-2, +2]\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            # reward_in_pred = sess.run(model.rewards_in_pred, feed_dict={model.states: state.reshape([1, -1]), \n",
    "            #                                                              model.actions: action.reshape([1, -1]), \n",
    "            #                                                              model.next_states: next_state.reshape([1, -1])})\n",
    "\n",
    "            # reward_in = reward_in_pred[0]\n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            #print('reward, reward_in:', reward, reward_in)\n",
    "            \n",
    "            # Training\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            next_states = np.array([each[2] for each in batch])\n",
    "            rewards = np.array([each[3] for each in batch])\n",
    "            dones = np.array([each[4] for each in batch])\n",
    "            feed_dict = {model.states: states, \n",
    "                         model.actions: actions,\n",
    "                         model.next_states: next_states, \n",
    "                         model.rewards: rewards, \n",
    "                         model.dones: dones}\n",
    "            loss, _, _ = sess.run([model.loss, model.d_opt, model.g_opt], feed_dict)\n",
    "            gloss_batch.append(-loss)\n",
    "            dloss_batch.append(loss)\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{:.4f}'.format(total_reward),\n",
    "              'gloss:{:.4f}'.format(np.mean(gloss_batch)),\n",
    "              'dloss:{:.4f}'.format(np.mean(dloss_batch)))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        gloss_list.append([ep, np.mean(gloss_batch)])\n",
    "        dloss_list.append([ep, np.mean(dloss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        # Did not solve the environment. \n",
    "        # Best 100-episode average reward was 220.62 ± 0.69. \n",
    "        #  when the agent obtains an average reward of at least 300 over 100 consecutive episodes.)        \n",
    "        if np.mean(episode_reward) >= 300:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(gloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(dloss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "total_reward: -104.69566602519279\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('BipedalWalker-v2')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model2.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            actions_pred = sess.run(model.actions_pred, feed_dict={model.states: state.reshape([1, -1])})\n",
    "            action = action_pred.reshape([-1])\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print('total_reward: {}'.format(total_reward))\n",
    "                break\n",
    "                \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

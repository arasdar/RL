{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy/P-Value/Q network \n",
    "\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    rewards = tf.placeholder(tf.float32, [None], name='rewards') # env rewards\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator/Controller: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(action_size, hidden_size, # model init\n",
    "               states, actions, rewards): # model input \n",
    "    # policy learning/gradient\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits,labels=actions_labels)        \n",
    "    g_loss = tf.reduce_mean(-log_prob * rewards)\n",
    "    # total_reward = tf.reduce_sum(rewards)\n",
    "    # #g_loss = tf.reduce_mean(-log_prob * total_reward)\n",
    "    # g_loss = -tf.reduce_mean(log_prob) * total_reward\n",
    "    \n",
    "    # Returning/outputing actions, sum of rewards, rewards, and loss\n",
    "    return actions_logits, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizating/training/learning G & D\n",
    "def model_opt(g_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param g_loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    return g_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions, self.rewards = model_input(state_size=state_size)\n",
    "        \n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.g_loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init \n",
    "            actions=self.actions, states=self.states, rewards=self.rewards) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_opt = model_opt(g_loss=self.g_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 300000000          # max steps in an episode\n",
    "learning_rate = 0.001          # learning rate for adam\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 total_reward: 57.0 g_loss: -39.3278\n",
      "Episode: 1 total_reward: 16.0 g_loss: -10.7552\n",
      "Episode: 2 total_reward: 10.0 g_loss: -6.7420\n",
      "Episode: 3 total_reward: 52.0 g_loss: -35.5407\n",
      "Episode: 4 total_reward: 9.0 g_loss: -6.1677\n",
      "Episode: 5 total_reward: 10.0 g_loss: -6.7558\n",
      "Episode: 6 total_reward: 52.0 g_loss: -35.4415\n",
      "Episode: 7 total_reward: 62.0 g_loss: -42.2541\n",
      "Episode: 8 total_reward: 13.0 g_loss: -8.9347\n",
      "Episode: 9 total_reward: 15.0 g_loss: -10.2967\n",
      "Episode: 10 total_reward: 23.0 g_loss: -15.7841\n",
      "Episode: 11 total_reward: 11.0 g_loss: -7.5391\n",
      "Episode: 12 total_reward: 11.0 g_loss: -7.5236\n",
      "Episode: 13 total_reward: 9.0 g_loss: -6.1566\n",
      "Episode: 14 total_reward: 9.0 g_loss: -6.1648\n",
      "Episode: 15 total_reward: 9.0 g_loss: -6.1987\n",
      "Episode: 16 total_reward: 13.0 g_loss: -8.9696\n",
      "Episode: 17 total_reward: 13.0 g_loss: -8.9781\n",
      "Episode: 18 total_reward: 12.0 g_loss: -8.2777\n",
      "Episode: 19 total_reward: 14.0 g_loss: -9.6631\n",
      "Episode: 20 total_reward: 31.0 g_loss: -21.3199\n",
      "Episode: 21 total_reward: 37.0 g_loss: -25.4793\n",
      "Episode: 22 total_reward: 26.0 g_loss: -17.8545\n",
      "Episode: 23 total_reward: 23.0 g_loss: -15.7989\n",
      "Episode: 24 total_reward: 12.0 g_loss: -8.2520\n",
      "Episode: 25 total_reward: 20.0 g_loss: -13.8028\n",
      "Episode: 26 total_reward: 10.0 g_loss: -6.8945\n",
      "Episode: 27 total_reward: 10.0 g_loss: -6.8554\n",
      "Episode: 28 total_reward: 9.0 g_loss: -6.1123\n",
      "Episode: 29 total_reward: 21.0 g_loss: -14.4719\n",
      "Episode: 30 total_reward: 12.0 g_loss: -8.2633\n",
      "Episode: 31 total_reward: 14.0 g_loss: -9.6474\n",
      "Episode: 32 total_reward: 16.0 g_loss: -11.0314\n",
      "Episode: 33 total_reward: 18.0 g_loss: -12.4370\n",
      "Episode: 34 total_reward: 15.0 g_loss: -10.3287\n",
      "Episode: 35 total_reward: 18.0 g_loss: -12.3875\n",
      "Episode: 36 total_reward: 21.0 g_loss: -14.4586\n",
      "Episode: 37 total_reward: 42.0 g_loss: -28.9438\n",
      "Episode: 38 total_reward: 12.0 g_loss: -8.2838\n",
      "Episode: 39 total_reward: 13.0 g_loss: -8.9719\n",
      "Episode: 40 total_reward: 142.0 g_loss: -97.6132\n",
      "Episode: 41 total_reward: 24.0 g_loss: -16.5535\n",
      "Episode: 42 total_reward: 10.0 g_loss: -6.7879\n",
      "Episode: 43 total_reward: 26.0 g_loss: -17.9510\n",
      "Episode: 44 total_reward: 10.0 g_loss: -6.8304\n",
      "Episode: 45 total_reward: 19.0 g_loss: -13.1282\n",
      "Episode: 46 total_reward: 10.0 g_loss: -6.8736\n",
      "Episode: 47 total_reward: 8.0 g_loss: -5.4815\n",
      "Episode: 48 total_reward: 10.0 g_loss: -6.8702\n",
      "Episode: 49 total_reward: 13.0 g_loss: -8.9583\n",
      "Episode: 50 total_reward: 18.0 g_loss: -12.4195\n",
      "Episode: 51 total_reward: 23.0 g_loss: -15.8592\n",
      "Episode: 52 total_reward: 19.0 g_loss: -13.1182\n",
      "Episode: 53 total_reward: 27.0 g_loss: -18.6334\n",
      "Episode: 54 total_reward: 63.0 g_loss: -43.3638\n",
      "Episode: 55 total_reward: 67.0 g_loss: -46.0927\n",
      "Episode: 56 total_reward: 41.0 g_loss: -28.1647\n",
      "Episode: 57 total_reward: 34.0 g_loss: -23.3800\n",
      "Episode: 58 total_reward: 18.0 g_loss: -12.3711\n",
      "Episode: 59 total_reward: 13.0 g_loss: -8.9328\n",
      "Episode: 60 total_reward: 9.0 g_loss: -6.1490\n",
      "Episode: 61 total_reward: 9.0 g_loss: -6.0993\n",
      "Episode: 62 total_reward: 9.0 g_loss: -6.0707\n",
      "Episode: 63 total_reward: 9.0 g_loss: -6.1076\n",
      "Episode: 64 total_reward: 11.0 g_loss: -7.5091\n",
      "Episode: 65 total_reward: 11.0 g_loss: -7.5298\n",
      "Episode: 66 total_reward: 11.0 g_loss: -7.5362\n",
      "Episode: 67 total_reward: 16.0 g_loss: -10.9749\n",
      "Episode: 68 total_reward: 21.0 g_loss: -14.4169\n",
      "Episode: 69 total_reward: 15.0 g_loss: -10.2941\n",
      "Episode: 70 total_reward: 21.0 g_loss: -14.4144\n",
      "Episode: 71 total_reward: 26.0 g_loss: -17.8827\n",
      "Episode: 72 total_reward: 20.0 g_loss: -13.7546\n",
      "Episode: 73 total_reward: 20.0 g_loss: -13.7759\n",
      "Episode: 74 total_reward: 25.0 g_loss: -17.2301\n",
      "Episode: 75 total_reward: 24.0 g_loss: -16.5667\n",
      "Episode: 76 total_reward: 37.0 g_loss: -25.3938\n",
      "Episode: 77 total_reward: 59.0 g_loss: -40.5433\n",
      "Episode: 78 total_reward: 22.0 g_loss: -15.2052\n",
      "Episode: 79 total_reward: 13.0 g_loss: -8.9810\n",
      "Episode: 80 total_reward: 15.0 g_loss: -10.3707\n",
      "Episode: 81 total_reward: 15.0 g_loss: -10.3582\n",
      "Episode: 82 total_reward: 31.0 g_loss: -21.3596\n",
      "Episode: 83 total_reward: 84.0 g_loss: -57.7433\n",
      "Episode: 84 total_reward: 36.0 g_loss: -24.8375\n",
      "Episode: 85 total_reward: 33.0 g_loss: -22.7588\n",
      "Episode: 86 total_reward: 40.0 g_loss: -27.5655\n",
      "Episode: 87 total_reward: 13.0 g_loss: -8.9459\n",
      "Episode: 88 total_reward: 13.0 g_loss: -8.9115\n",
      "Episode: 89 total_reward: 10.0 g_loss: -6.8532\n",
      "Episode: 90 total_reward: 8.0 g_loss: -5.4618\n",
      "Episode: 91 total_reward: 10.0 g_loss: -6.8420\n",
      "Episode: 92 total_reward: 13.0 g_loss: -8.9201\n",
      "Episode: 93 total_reward: 16.0 g_loss: -11.0097\n",
      "Episode: 94 total_reward: 17.0 g_loss: -11.6904\n",
      "Episode: 95 total_reward: 18.0 g_loss: -12.3923\n",
      "Episode: 96 total_reward: 19.0 g_loss: -13.0818\n",
      "Episode: 97 total_reward: 20.0 g_loss: -13.7923\n",
      "Episode: 98 total_reward: 18.0 g_loss: -12.4091\n",
      "Episode: 99 total_reward: 22.0 g_loss: -15.1713\n",
      "Episode: 100 total_reward: 16.0 g_loss: -11.0457\n",
      "Episode: 101 total_reward: 13.0 g_loss: -8.9803\n",
      "Episode: 102 total_reward: 26.0 g_loss: -17.9327\n",
      "Episode: 103 total_reward: 18.0 g_loss: -12.4418\n",
      "Episode: 104 total_reward: 48.0 g_loss: -33.1358\n",
      "Episode: 105 total_reward: 54.0 g_loss: -37.2725\n",
      "Episode: 106 total_reward: 10.0 g_loss: -6.8683\n",
      "Episode: 107 total_reward: 11.0 g_loss: -7.5955\n",
      "Episode: 108 total_reward: 200.0 g_loss: -138.1561\n",
      "Episode: 109 total_reward: 18.0 g_loss: -12.4613\n",
      "Episode: 110 total_reward: 10.0 g_loss: -6.9031\n",
      "Episode: 111 total_reward: 8.0 g_loss: -5.4808\n",
      "Episode: 112 total_reward: 9.0 g_loss: -6.2030\n",
      "Episode: 113 total_reward: 10.0 g_loss: -6.8091\n",
      "Episode: 114 total_reward: 16.0 g_loss: -11.0470\n",
      "Episode: 115 total_reward: 20.0 g_loss: -13.8116\n",
      "Episode: 116 total_reward: 18.0 g_loss: -12.4210\n",
      "Episode: 117 total_reward: 25.0 g_loss: -17.2542\n",
      "Episode: 118 total_reward: 46.0 g_loss: -31.7379\n",
      "Episode: 119 total_reward: 26.0 g_loss: -17.9507\n",
      "Episode: 120 total_reward: 19.0 g_loss: -13.1162\n",
      "Episode: 121 total_reward: 22.0 g_loss: -15.1704\n",
      "Episode: 122 total_reward: 17.0 g_loss: -11.7293\n",
      "Episode: 123 total_reward: 13.0 g_loss: -8.9811\n",
      "Episode: 124 total_reward: 14.0 g_loss: -9.6615\n",
      "Episode: 125 total_reward: 11.0 g_loss: -7.5952\n",
      "Episode: 126 total_reward: 17.0 g_loss: -11.7358\n",
      "Episode: 127 total_reward: 10.0 g_loss: -6.9016\n",
      "Episode: 128 total_reward: 16.0 g_loss: -11.0576\n",
      "Episode: 129 total_reward: 15.0 g_loss: -10.3478\n",
      "Episode: 130 total_reward: 14.0 g_loss: -9.6678\n",
      "Episode: 131 total_reward: 17.0 g_loss: -11.7419\n",
      "Episode: 132 total_reward: 17.0 g_loss: -11.7539\n",
      "Episode: 133 total_reward: 22.0 g_loss: -15.1730\n",
      "Episode: 134 total_reward: 35.0 g_loss: -24.1834\n",
      "Episode: 135 total_reward: 18.0 g_loss: -12.4437\n",
      "Episode: 136 total_reward: 11.0 g_loss: -7.6057\n",
      "Episode: 137 total_reward: 14.0 g_loss: -9.6813\n",
      "Episode: 138 total_reward: 13.0 g_loss: -8.9723\n",
      "Episode: 139 total_reward: 19.0 g_loss: -13.1365\n",
      "Episode: 140 total_reward: 20.0 g_loss: -13.8235\n",
      "Episode: 141 total_reward: 39.0 g_loss: -26.9609\n",
      "Episode: 142 total_reward: 19.0 g_loss: -13.1412\n",
      "Episode: 143 total_reward: 16.0 g_loss: -11.0650\n",
      "Episode: 144 total_reward: 18.0 g_loss: -12.4422\n",
      "Episode: 145 total_reward: 13.0 g_loss: -8.9799\n",
      "Episode: 146 total_reward: 13.0 g_loss: -8.9802\n",
      "Episode: 147 total_reward: 11.0 g_loss: -7.6026\n",
      "Episode: 148 total_reward: 83.0 g_loss: -57.3119\n",
      "Episode: 149 total_reward: 51.0 g_loss: -35.1829\n",
      "Episode: 150 total_reward: 56.0 g_loss: -38.6377\n",
      "Episode: 151 total_reward: 25.0 g_loss: -17.2478\n",
      "Episode: 152 total_reward: 21.0 g_loss: -14.4843\n",
      "Episode: 153 total_reward: 11.0 g_loss: -7.5769\n",
      "Episode: 154 total_reward: 11.0 g_loss: -7.5817\n",
      "Episode: 155 total_reward: 10.0 g_loss: -6.8731\n",
      "Episode: 156 total_reward: 9.0 g_loss: -6.1779\n",
      "Episode: 157 total_reward: 9.0 g_loss: -6.1682\n",
      "Episode: 158 total_reward: 9.0 g_loss: -6.1667\n",
      "Episode: 159 total_reward: 13.0 g_loss: -8.9568\n",
      "Episode: 160 total_reward: 21.0 g_loss: -14.4727\n",
      "Episode: 161 total_reward: 14.0 g_loss: -9.6528\n",
      "Episode: 162 total_reward: 15.0 g_loss: -10.3445\n",
      "Episode: 163 total_reward: 22.0 g_loss: -15.1627\n",
      "Episode: 164 total_reward: 20.0 g_loss: -13.7842\n",
      "Episode: 165 total_reward: 20.0 g_loss: -13.7970\n",
      "Episode: 166 total_reward: 15.0 g_loss: -10.3618\n",
      "Episode: 167 total_reward: 18.0 g_loss: -12.4340\n",
      "Episode: 168 total_reward: 18.0 g_loss: -12.4382\n",
      "Episode: 169 total_reward: 19.0 g_loss: -13.1380\n",
      "Episode: 170 total_reward: 63.0 g_loss: -43.3327\n",
      "Episode: 171 total_reward: 25.0 g_loss: -17.2562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 172 total_reward: 83.0 g_loss: -57.3418\n",
      "Episode: 173 total_reward: 21.0 g_loss: -14.4621\n",
      "Episode: 174 total_reward: 17.0 g_loss: -11.7058\n",
      "Episode: 175 total_reward: 19.0 g_loss: -13.0811\n",
      "Episode: 176 total_reward: 17.0 g_loss: -11.6812\n",
      "Episode: 177 total_reward: 11.0 g_loss: -7.5610\n",
      "Episode: 178 total_reward: 12.0 g_loss: -8.2200\n",
      "Episode: 179 total_reward: 9.0 g_loss: -6.1486\n",
      "Episode: 180 total_reward: 9.0 g_loss: -6.1416\n",
      "Episode: 181 total_reward: 12.0 g_loss: -8.2260\n",
      "Episode: 182 total_reward: 13.0 g_loss: -8.9213\n",
      "Episode: 183 total_reward: 11.0 g_loss: -7.5635\n",
      "Episode: 184 total_reward: 16.0 g_loss: -11.0138\n",
      "Episode: 185 total_reward: 21.0 g_loss: -14.4865\n",
      "Episode: 186 total_reward: 14.0 g_loss: -9.6492\n",
      "Episode: 187 total_reward: 13.0 g_loss: -8.9614\n",
      "Episode: 188 total_reward: 14.0 g_loss: -9.6622\n",
      "Episode: 189 total_reward: 14.0 g_loss: -9.6833\n",
      "Episode: 190 total_reward: 10.0 g_loss: -6.8624\n",
      "Episode: 191 total_reward: 47.0 g_loss: -32.4691\n",
      "Episode: 192 total_reward: 22.0 g_loss: -15.2095\n",
      "Episode: 193 total_reward: 32.0 g_loss: -22.1097\n",
      "Episode: 194 total_reward: 16.0 g_loss: -11.0635\n",
      "Episode: 195 total_reward: 13.0 g_loss: -8.9919\n",
      "Episode: 196 total_reward: 35.0 g_loss: -24.1798\n",
      "Episode: 197 total_reward: 28.0 g_loss: -19.3491\n",
      "Episode: 198 total_reward: 32.0 g_loss: -22.0977\n",
      "Episode: 199 total_reward: 23.0 g_loss: -15.8549\n",
      "Episode: 200 total_reward: 14.0 g_loss: -9.6630\n",
      "Episode: 201 total_reward: 15.0 g_loss: -10.3633\n",
      "Episode: 202 total_reward: 11.0 g_loss: -7.5851\n",
      "Episode: 203 total_reward: 9.0 g_loss: -6.1910\n",
      "Episode: 204 total_reward: 11.0 g_loss: -7.5564\n",
      "Episode: 205 total_reward: 12.0 g_loss: -8.2738\n",
      "Episode: 206 total_reward: 11.0 g_loss: -7.5465\n",
      "Episode: 207 total_reward: 10.0 g_loss: -6.9062\n",
      "Episode: 208 total_reward: 10.0 g_loss: -6.6853\n",
      "Episode: 209 total_reward: 10.0 g_loss: -6.9117\n",
      "Episode: 210 total_reward: 10.0 g_loss: -6.7777\n",
      "Episode: 211 total_reward: 10.0 g_loss: -6.9083\n",
      "Episode: 212 total_reward: 12.0 g_loss: -8.2946\n",
      "Episode: 213 total_reward: 21.0 g_loss: -14.5083\n",
      "Episode: 214 total_reward: 17.0 g_loss: -11.7398\n",
      "Episode: 215 total_reward: 17.0 g_loss: -11.7536\n",
      "Episode: 216 total_reward: 22.0 g_loss: -15.2166\n",
      "Episode: 217 total_reward: 33.0 g_loss: -22.8138\n",
      "Episode: 218 total_reward: 43.0 g_loss: -29.7271\n",
      "Episode: 219 total_reward: 13.0 g_loss: -8.9948\n",
      "Episode: 220 total_reward: 23.0 g_loss: -15.9004\n",
      "Episode: 221 total_reward: 21.0 g_loss: -14.5210\n",
      "Episode: 222 total_reward: 17.0 g_loss: -11.7539\n",
      "Episode: 223 total_reward: 16.0 g_loss: -11.0587\n",
      "Episode: 224 total_reward: 37.0 g_loss: -25.5831\n",
      "Episode: 225 total_reward: 18.0 g_loss: -12.4371\n",
      "Episode: 226 total_reward: 12.0 g_loss: -8.2639\n",
      "Episode: 227 total_reward: 9.0 g_loss: -6.1949\n",
      "Episode: 228 total_reward: 11.0 g_loss: -7.5885\n",
      "Episode: 229 total_reward: 10.0 g_loss: -6.9030\n",
      "Episode: 230 total_reward: 15.0 g_loss: -10.3705\n",
      "Episode: 231 total_reward: 12.0 g_loss: -8.2983\n",
      "Episode: 232 total_reward: 20.0 g_loss: -13.8355\n",
      "Episode: 233 total_reward: 35.0 g_loss: -24.1333\n",
      "Episode: 234 total_reward: 27.0 g_loss: -18.6632\n",
      "Episode: 235 total_reward: 40.0 g_loss: -27.6611\n",
      "Episode: 236 total_reward: 82.0 g_loss: -56.7292\n",
      "Episode: 237 total_reward: 52.0 g_loss: -35.9066\n",
      "Episode: 238 total_reward: 59.0 g_loss: -40.7419\n",
      "Episode: 239 total_reward: 12.0 g_loss: -8.2993\n",
      "Episode: 240 total_reward: 10.0 g_loss: -6.8537\n",
      "Episode: 241 total_reward: 15.0 g_loss: -10.3624\n",
      "Episode: 242 total_reward: 12.0 g_loss: -8.2859\n",
      "Episode: 243 total_reward: 16.0 g_loss: -11.0571\n",
      "Episode: 244 total_reward: 11.0 g_loss: -7.5905\n",
      "Episode: 245 total_reward: 40.0 g_loss: -27.5176\n",
      "Episode: 246 total_reward: 49.0 g_loss: -33.7747\n",
      "Episode: 247 total_reward: 11.0 g_loss: -7.5988\n",
      "Episode: 248 total_reward: 10.0 g_loss: -6.9152\n",
      "Episode: 249 total_reward: 15.0 g_loss: -10.3681\n",
      "Episode: 250 total_reward: 10.0 g_loss: -6.9089\n",
      "Episode: 251 total_reward: 90.0 g_loss: -62.0636\n",
      "Episode: 252 total_reward: 56.0 g_loss: -38.6243\n",
      "Episode: 253 total_reward: 11.0 g_loss: -7.5775\n",
      "Episode: 254 total_reward: 11.0 g_loss: -7.5613\n",
      "Episode: 255 total_reward: 11.0 g_loss: -7.5787\n",
      "Episode: 256 total_reward: 9.0 g_loss: -6.1849\n",
      "Episode: 257 total_reward: 11.0 g_loss: -7.5654\n",
      "Episode: 258 total_reward: 9.0 g_loss: -6.2024\n",
      "Episode: 259 total_reward: 21.0 g_loss: -14.4981\n",
      "Episode: 260 total_reward: 8.0 g_loss: -5.5257\n",
      "Episode: 261 total_reward: 90.0 g_loss: -62.1362\n",
      "Episode: 262 total_reward: 13.0 g_loss: -8.9732\n",
      "Episode: 263 total_reward: 17.0 g_loss: -11.7506\n",
      "Episode: 264 total_reward: 11.0 g_loss: -7.6068\n",
      "Episode: 265 total_reward: 13.0 g_loss: -8.9957\n",
      "Episode: 266 total_reward: 14.0 g_loss: -9.6896\n",
      "Episode: 267 total_reward: 16.0 g_loss: -11.0491\n",
      "Episode: 268 total_reward: 13.0 g_loss: -8.9807\n",
      "Episode: 269 total_reward: 14.0 g_loss: -9.6827\n",
      "Episode: 270 total_reward: 33.0 g_loss: -22.8365\n",
      "Episode: 271 total_reward: 87.0 g_loss: -60.0317\n",
      "Episode: 272 total_reward: 22.0 g_loss: -15.2221\n",
      "Episode: 273 total_reward: 18.0 g_loss: -12.4539\n",
      "Episode: 274 total_reward: 13.0 g_loss: -8.9874\n",
      "Episode: 275 total_reward: 15.0 g_loss: -10.3618\n",
      "Episode: 276 total_reward: 15.0 g_loss: -10.3666\n",
      "Episode: 277 total_reward: 11.0 g_loss: -7.5953\n",
      "Episode: 278 total_reward: 10.0 g_loss: -6.9080\n",
      "Episode: 279 total_reward: 11.0 g_loss: -7.6018\n",
      "Episode: 280 total_reward: 17.0 g_loss: -11.7586\n",
      "Episode: 281 total_reward: 19.0 g_loss: -13.1460\n",
      "Episode: 282 total_reward: 21.0 g_loss: -14.5194\n",
      "Episode: 283 total_reward: 30.0 g_loss: -20.7084\n",
      "Episode: 284 total_reward: 44.0 g_loss: -30.3316\n",
      "Episode: 285 total_reward: 28.0 g_loss: -19.2418\n",
      "Episode: 286 total_reward: 57.0 g_loss: -39.2627\n",
      "Episode: 287 total_reward: 25.0 g_loss: -17.1821\n",
      "Episode: 288 total_reward: 42.0 g_loss: -28.9802\n",
      "Episode: 289 total_reward: 22.0 g_loss: -15.1658\n",
      "Episode: 290 total_reward: 13.0 g_loss: -8.9271\n",
      "Episode: 291 total_reward: 13.0 g_loss: -8.9353\n",
      "Episode: 292 total_reward: 15.0 g_loss: -10.3088\n",
      "Episode: 293 total_reward: 12.0 g_loss: -8.2409\n",
      "Episode: 294 total_reward: 9.0 g_loss: -6.1547\n",
      "Episode: 295 total_reward: 9.0 g_loss: -6.1220\n",
      "Episode: 296 total_reward: 10.0 g_loss: -6.7850\n",
      "Episode: 297 total_reward: 8.0 g_loss: -5.4577\n",
      "Episode: 298 total_reward: 14.0 g_loss: -9.6166\n",
      "Episode: 299 total_reward: 11.0 g_loss: -7.5567\n",
      "Episode: 300 total_reward: 13.0 g_loss: -8.9748\n",
      "Episode: 301 total_reward: 18.0 g_loss: -12.4193\n",
      "Episode: 302 total_reward: 23.0 g_loss: -15.8950\n",
      "Episode: 303 total_reward: 18.0 g_loss: -12.4371\n",
      "Episode: 304 total_reward: 31.0 g_loss: -21.4199\n",
      "Episode: 305 total_reward: 16.0 g_loss: -11.0584\n",
      "Episode: 306 total_reward: 25.0 g_loss: -17.2691\n",
      "Episode: 307 total_reward: 20.0 g_loss: -13.8255\n",
      "Episode: 308 total_reward: 12.0 g_loss: -8.2861\n",
      "Episode: 309 total_reward: 18.0 g_loss: -12.4376\n",
      "Episode: 310 total_reward: 12.0 g_loss: -8.2819\n",
      "Episode: 311 total_reward: 10.0 g_loss: -6.8868\n",
      "Episode: 312 total_reward: 10.0 g_loss: -6.8725\n",
      "Episode: 313 total_reward: 11.0 g_loss: -7.5979\n",
      "Episode: 314 total_reward: 13.0 g_loss: -8.9825\n",
      "Episode: 315 total_reward: 29.0 g_loss: -20.0660\n",
      "Episode: 316 total_reward: 61.0 g_loss: -42.2025\n",
      "Episode: 317 total_reward: 91.0 g_loss: -62.7751\n",
      "Episode: 318 total_reward: 113.0 g_loss: -77.9989\n",
      "Episode: 319 total_reward: 67.0 g_loss: -46.1498\n",
      "Episode: 320 total_reward: 23.0 g_loss: -15.8293\n",
      "Episode: 321 total_reward: 52.0 g_loss: -35.8425\n",
      "Episode: 322 total_reward: 19.0 g_loss: -13.0779\n",
      "Episode: 323 total_reward: 16.0 g_loss: -11.0218\n",
      "Episode: 324 total_reward: 10.0 g_loss: -6.8714\n",
      "Episode: 325 total_reward: 9.0 g_loss: -6.1816\n",
      "Episode: 326 total_reward: 9.0 g_loss: -6.1752\n",
      "Episode: 327 total_reward: 10.0 g_loss: -6.8515\n",
      "Episode: 328 total_reward: 12.0 g_loss: -8.2384\n",
      "Episode: 329 total_reward: 13.0 g_loss: -8.9409\n",
      "Episode: 330 total_reward: 14.0 g_loss: -9.6536\n",
      "Episode: 331 total_reward: 70.0 g_loss: -48.4052\n",
      "Episode: 332 total_reward: 36.0 g_loss: -24.8613\n",
      "Episode: 333 total_reward: 29.0 g_loss: -20.0277\n",
      "Episode: 334 total_reward: 11.0 g_loss: -7.5973\n",
      "Episode: 335 total_reward: 9.0 g_loss: -6.2151\n",
      "Episode: 336 total_reward: 11.0 g_loss: -7.5983\n",
      "Episode: 337 total_reward: 37.0 g_loss: -25.5566\n",
      "Episode: 338 total_reward: 19.0 g_loss: -13.1508\n",
      "Episode: 339 total_reward: 18.0 g_loss: -12.4331\n",
      "Episode: 340 total_reward: 10.0 g_loss: -6.9062\n",
      "Episode: 341 total_reward: 10.0 g_loss: -6.9041\n",
      "Episode: 342 total_reward: 44.0 g_loss: -30.3922\n",
      "Episode: 343 total_reward: 40.0 g_loss: -27.6714\n",
      "Episode: 344 total_reward: 48.0 g_loss: -33.2014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 345 total_reward: 39.0 g_loss: -26.9898\n",
      "Episode: 346 total_reward: 40.0 g_loss: -27.6560\n",
      "Episode: 347 total_reward: 45.0 g_loss: -31.1134\n",
      "Episode: 348 total_reward: 50.0 g_loss: -34.5112\n",
      "Episode: 349 total_reward: 17.0 g_loss: -11.7367\n",
      "Episode: 350 total_reward: 10.0 g_loss: -6.8965\n",
      "Episode: 351 total_reward: 14.0 g_loss: -9.6521\n",
      "Episode: 352 total_reward: 11.0 g_loss: -7.5836\n",
      "Episode: 353 total_reward: 14.0 g_loss: -9.6552\n",
      "Episode: 354 total_reward: 15.0 g_loss: -10.3463\n",
      "Episode: 355 total_reward: 18.0 g_loss: -12.4233\n",
      "Episode: 356 total_reward: 14.0 g_loss: -9.6696\n",
      "Episode: 357 total_reward: 23.0 g_loss: -15.8773\n",
      "Episode: 358 total_reward: 23.0 g_loss: -15.8827\n",
      "Episode: 359 total_reward: 20.0 g_loss: -13.8155\n",
      "Episode: 360 total_reward: 8.0 g_loss: -5.5079\n",
      "Episode: 361 total_reward: 9.0 g_loss: -6.1893\n",
      "Episode: 362 total_reward: 19.0 g_loss: -13.1337\n",
      "Episode: 363 total_reward: 26.0 g_loss: -17.9593\n",
      "Episode: 364 total_reward: 28.0 g_loss: -19.3406\n",
      "Episode: 365 total_reward: 35.0 g_loss: -24.1642\n",
      "Episode: 366 total_reward: 34.0 g_loss: -23.4792\n",
      "Episode: 367 total_reward: 15.0 g_loss: -10.3693\n",
      "Episode: 368 total_reward: 16.0 g_loss: -11.0616\n",
      "Episode: 369 total_reward: 11.0 g_loss: -7.6043\n",
      "Episode: 370 total_reward: 10.0 g_loss: -6.8984\n",
      "Episode: 371 total_reward: 14.0 g_loss: -9.6796\n",
      "Episode: 372 total_reward: 34.0 g_loss: -23.4311\n",
      "Episode: 373 total_reward: 28.0 g_loss: -19.3259\n",
      "Episode: 374 total_reward: 10.0 g_loss: -6.9206\n",
      "Episode: 375 total_reward: 52.0 g_loss: -35.8015\n",
      "Episode: 376 total_reward: 200.0 g_loss: -138.1826\n",
      "Episode: 377 total_reward: 82.0 g_loss: -56.6602\n",
      "Episode: 378 total_reward: 32.0 g_loss: -22.0958\n",
      "Episode: 379 total_reward: 19.0 g_loss: -13.1166\n",
      "Episode: 380 total_reward: 15.0 g_loss: -10.3413\n",
      "Episode: 381 total_reward: 11.0 g_loss: -7.5709\n",
      "Episode: 382 total_reward: 9.0 g_loss: -6.1392\n",
      "Episode: 383 total_reward: 9.0 g_loss: -6.1132\n",
      "Episode: 384 total_reward: 9.0 g_loss: -6.1468\n",
      "Episode: 385 total_reward: 10.0 g_loss: -6.8633\n",
      "Episode: 386 total_reward: 13.0 g_loss: -8.9534\n",
      "Episode: 387 total_reward: 14.0 g_loss: -9.6501\n",
      "Episode: 388 total_reward: 14.0 g_loss: -9.6484\n",
      "Episode: 389 total_reward: 12.0 g_loss: -8.2762\n",
      "Episode: 390 total_reward: 9.0 g_loss: -6.2094\n",
      "Episode: 391 total_reward: 15.0 g_loss: -10.3646\n",
      "Episode: 392 total_reward: 15.0 g_loss: -10.3634\n",
      "Episode: 393 total_reward: 19.0 g_loss: -13.0969\n",
      "Episode: 394 total_reward: 25.0 g_loss: -17.2367\n",
      "Episode: 395 total_reward: 21.0 g_loss: -14.4779\n",
      "Episode: 396 total_reward: 77.0 g_loss: -52.9533\n",
      "Episode: 397 total_reward: 60.0 g_loss: -41.2767\n",
      "Episode: 398 total_reward: 46.0 g_loss: -31.6782\n",
      "Episode: 399 total_reward: 42.0 g_loss: -28.9457\n",
      "Episode: 400 total_reward: 21.0 g_loss: -14.4695\n",
      "Episode: 401 total_reward: 33.0 g_loss: -22.7667\n",
      "Episode: 402 total_reward: 10.0 g_loss: -6.8055\n",
      "Episode: 403 total_reward: 15.0 g_loss: -10.3334\n",
      "Episode: 404 total_reward: 13.0 g_loss: -8.9455\n",
      "Episode: 405 total_reward: 13.0 g_loss: -8.9471\n",
      "Episode: 406 total_reward: 13.0 g_loss: -8.9454\n",
      "Episode: 407 total_reward: 9.0 g_loss: -6.1800\n",
      "Episode: 408 total_reward: 11.0 g_loss: -7.5665\n",
      "Episode: 409 total_reward: 11.0 g_loss: -7.5276\n",
      "Episode: 410 total_reward: 9.0 g_loss: -6.1866\n",
      "Episode: 411 total_reward: 13.0 g_loss: -8.9576\n",
      "Episode: 412 total_reward: 15.0 g_loss: -10.3466\n",
      "Episode: 413 total_reward: 16.0 g_loss: -11.0594\n",
      "Episode: 414 total_reward: 17.0 g_loss: -11.7434\n",
      "Episode: 415 total_reward: 19.0 g_loss: -13.0887\n",
      "Episode: 416 total_reward: 200.0 g_loss: -137.0371\n",
      "Episode: 417 total_reward: 19.0 g_loss: -13.1388\n",
      "Episode: 418 total_reward: 15.0 g_loss: -10.3245\n",
      "Episode: 419 total_reward: 12.0 g_loss: -8.2549\n",
      "Episode: 420 total_reward: 11.0 g_loss: -7.5616\n",
      "Episode: 421 total_reward: 10.0 g_loss: -6.8550\n",
      "Episode: 422 total_reward: 11.0 g_loss: -7.5671\n",
      "Episode: 423 total_reward: 12.0 g_loss: -8.2583\n",
      "Episode: 424 total_reward: 15.0 g_loss: -10.3436\n",
      "Episode: 425 total_reward: 11.0 g_loss: -7.5823\n",
      "Episode: 426 total_reward: 10.0 g_loss: -6.7473\n",
      "Episode: 427 total_reward: 8.0 g_loss: -5.4280\n",
      "Episode: 428 total_reward: 9.0 g_loss: -6.1339\n",
      "Episode: 429 total_reward: 11.0 g_loss: -7.5855\n",
      "Episode: 430 total_reward: 17.0 g_loss: -11.7437\n",
      "Episode: 431 total_reward: 14.0 g_loss: -9.6670\n",
      "Episode: 432 total_reward: 21.0 g_loss: -14.5097\n",
      "Episode: 433 total_reward: 12.0 g_loss: -8.2900\n",
      "Episode: 434 total_reward: 18.0 g_loss: -12.4276\n",
      "Episode: 435 total_reward: 15.0 g_loss: -10.3579\n",
      "Episode: 436 total_reward: 12.0 g_loss: -8.2893\n",
      "Episode: 437 total_reward: 15.0 g_loss: -10.3464\n",
      "Episode: 438 total_reward: 14.0 g_loss: -9.6605\n",
      "Episode: 439 total_reward: 14.0 g_loss: -9.6625\n",
      "Episode: 440 total_reward: 14.0 g_loss: -9.6682\n",
      "Episode: 441 total_reward: 9.0 g_loss: -6.2156\n",
      "Episode: 442 total_reward: 10.0 g_loss: -6.9083\n",
      "Episode: 443 total_reward: 20.0 g_loss: -13.8228\n",
      "Episode: 444 total_reward: 50.0 g_loss: -34.4519\n",
      "Episode: 445 total_reward: 48.0 g_loss: -33.1515\n",
      "Episode: 446 total_reward: 22.0 g_loss: -15.1706\n",
      "Episode: 447 total_reward: 28.0 g_loss: -19.2871\n",
      "Episode: 448 total_reward: 15.0 g_loss: -10.3269\n",
      "Episode: 449 total_reward: 18.0 g_loss: -12.3722\n",
      "Episode: 450 total_reward: 15.0 g_loss: -10.3158\n",
      "Episode: 451 total_reward: 12.0 g_loss: -8.2564\n",
      "Episode: 452 total_reward: 14.0 g_loss: -9.6356\n",
      "Episode: 453 total_reward: 11.0 g_loss: -7.5602\n",
      "Episode: 454 total_reward: 12.0 g_loss: -8.2455\n",
      "Episode: 455 total_reward: 9.0 g_loss: -6.1795\n",
      "Episode: 456 total_reward: 12.0 g_loss: -8.2451\n",
      "Episode: 457 total_reward: 12.0 g_loss: -8.2426\n",
      "Episode: 458 total_reward: 9.0 g_loss: -6.1820\n",
      "Episode: 459 total_reward: 9.0 g_loss: -6.1895\n",
      "Episode: 460 total_reward: 10.0 g_loss: -6.8848\n",
      "Episode: 461 total_reward: 12.0 g_loss: -8.2716\n",
      "Episode: 462 total_reward: 13.0 g_loss: -8.9685\n",
      "Episode: 463 total_reward: 13.0 g_loss: -8.9782\n",
      "Episode: 464 total_reward: 22.0 g_loss: -15.2151\n",
      "Episode: 465 total_reward: 35.0 g_loss: -24.1552\n",
      "Episode: 466 total_reward: 48.0 g_loss: -33.1307\n",
      "Episode: 467 total_reward: 46.0 g_loss: -31.7667\n",
      "Episode: 468 total_reward: 19.0 g_loss: -13.1195\n",
      "Episode: 469 total_reward: 18.0 g_loss: -12.4321\n",
      "Episode: 470 total_reward: 14.0 g_loss: -9.6737\n",
      "Episode: 471 total_reward: 10.0 g_loss: -6.8937\n",
      "Episode: 472 total_reward: 9.0 g_loss: -6.1926\n",
      "Episode: 473 total_reward: 9.0 g_loss: -6.1618\n",
      "Episode: 474 total_reward: 10.0 g_loss: -6.8848\n",
      "Episode: 475 total_reward: 12.0 g_loss: -8.2844\n",
      "Episode: 476 total_reward: 12.0 g_loss: -8.2907\n",
      "Episode: 477 total_reward: 18.0 g_loss: -12.4348\n",
      "Episode: 478 total_reward: 19.0 g_loss: -13.1324\n",
      "Episode: 479 total_reward: 23.0 g_loss: -15.9096\n",
      "Episode: 480 total_reward: 27.0 g_loss: -18.6849\n",
      "Episode: 481 total_reward: 25.0 g_loss: -17.2929\n",
      "Episode: 482 total_reward: 28.0 g_loss: -19.3721\n",
      "Episode: 483 total_reward: 11.0 g_loss: -7.6028\n",
      "Episode: 484 total_reward: 10.0 g_loss: -6.9185\n",
      "Episode: 485 total_reward: 13.0 g_loss: -8.9923\n",
      "Episode: 486 total_reward: 10.0 g_loss: -6.9137\n",
      "Episode: 487 total_reward: 15.0 g_loss: -10.3840\n",
      "Episode: 488 total_reward: 10.0 g_loss: -6.9087\n",
      "Episode: 489 total_reward: 19.0 g_loss: -13.1503\n",
      "Episode: 490 total_reward: 74.0 g_loss: -51.2550\n",
      "Episode: 491 total_reward: 12.0 g_loss: -8.2853\n",
      "Episode: 492 total_reward: 10.0 g_loss: -6.9032\n",
      "Episode: 493 total_reward: 14.0 g_loss: -9.6852\n",
      "Episode: 494 total_reward: 39.0 g_loss: -27.0157\n",
      "Episode: 495 total_reward: 16.0 g_loss: -11.0776\n",
      "Episode: 496 total_reward: 18.0 g_loss: -12.4650\n",
      "Episode: 497 total_reward: 14.0 g_loss: -9.6943\n",
      "Episode: 498 total_reward: 29.0 g_loss: -20.0871\n",
      "Episode: 499 total_reward: 45.0 g_loss: -31.1736\n",
      "Episode: 500 total_reward: 68.0 g_loss: -47.0419\n",
      "Episode: 501 total_reward: 49.0 g_loss: -33.9174\n",
      "Episode: 502 total_reward: 12.0 g_loss: -8.2924\n",
      "Episode: 503 total_reward: 11.0 g_loss: -7.5993\n",
      "Episode: 504 total_reward: 15.0 g_loss: -10.3527\n",
      "Episode: 505 total_reward: 12.0 g_loss: -8.2832\n",
      "Episode: 506 total_reward: 12.0 g_loss: -8.2823\n",
      "Episode: 507 total_reward: 10.0 g_loss: -6.9023\n",
      "Episode: 508 total_reward: 11.0 g_loss: -7.5956\n",
      "Episode: 509 total_reward: 9.0 g_loss: -6.2102\n",
      "Episode: 510 total_reward: 10.0 g_loss: -6.9109\n",
      "Episode: 511 total_reward: 13.0 g_loss: -8.9843\n",
      "Episode: 512 total_reward: 16.0 g_loss: -11.0665\n",
      "Episode: 513 total_reward: 17.0 g_loss: -11.7663\n",
      "Episode: 514 total_reward: 10.0 g_loss: -6.8882\n",
      "Episode: 515 total_reward: 10.0 g_loss: -6.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 516 total_reward: 180.0 g_loss: -124.4924\n",
      "Episode: 517 total_reward: 139.0 g_loss: -96.2525\n",
      "Episode: 518 total_reward: 9.0 g_loss: -6.2227\n",
      "Episode: 519 total_reward: 11.0 g_loss: -7.5868\n",
      "Episode: 520 total_reward: 10.0 g_loss: -6.8858\n",
      "Episode: 521 total_reward: 12.0 g_loss: -8.3012\n",
      "Episode: 522 total_reward: 149.0 g_loss: -103.1240\n",
      "Episode: 523 total_reward: 11.0 g_loss: -7.6116\n",
      "Episode: 524 total_reward: 10.0 g_loss: -6.9003\n",
      "Episode: 525 total_reward: 8.0 g_loss: -5.5246\n",
      "Episode: 526 total_reward: 9.0 g_loss: -6.2217\n",
      "Episode: 527 total_reward: 11.0 g_loss: -7.6152\n",
      "Episode: 528 total_reward: 14.0 g_loss: -9.6934\n",
      "Episode: 529 total_reward: 43.0 g_loss: -29.7670\n",
      "Episode: 530 total_reward: 43.0 g_loss: -29.7599\n",
      "Episode: 531 total_reward: 22.0 g_loss: -15.2300\n",
      "Episode: 532 total_reward: 15.0 g_loss: -10.3900\n",
      "Episode: 533 total_reward: 12.0 g_loss: -8.3104\n",
      "Episode: 534 total_reward: 10.0 g_loss: -6.9199\n",
      "Episode: 535 total_reward: 11.0 g_loss: -7.6147\n",
      "Episode: 536 total_reward: 22.0 g_loss: -15.2338\n",
      "Episode: 537 total_reward: 53.0 g_loss: -36.7002\n",
      "Episode: 538 total_reward: 25.0 g_loss: -17.3101\n",
      "Episode: 539 total_reward: 13.0 g_loss: -8.9992\n",
      "Episode: 540 total_reward: 12.0 g_loss: -8.3030\n",
      "Episode: 541 total_reward: 12.0 g_loss: -8.2906\n",
      "Episode: 542 total_reward: 12.0 g_loss: -8.2971\n",
      "Episode: 543 total_reward: 11.0 g_loss: -7.6028\n",
      "Episode: 544 total_reward: 11.0 g_loss: -7.6154\n",
      "Episode: 545 total_reward: 15.0 g_loss: -10.3874\n",
      "Episode: 546 total_reward: 194.0 g_loss: -134.3686\n",
      "Episode: 547 total_reward: 26.0 g_loss: -18.0025\n",
      "Episode: 548 total_reward: 8.0 g_loss: -5.5279\n",
      "Episode: 549 total_reward: 10.0 g_loss: -6.9013\n",
      "Episode: 550 total_reward: 10.0 g_loss: -6.9013\n",
      "Episode: 551 total_reward: 11.0 g_loss: -7.6095\n",
      "Episode: 552 total_reward: 10.0 g_loss: -6.9212\n",
      "Episode: 553 total_reward: 9.0 g_loss: -6.1980\n",
      "Episode: 554 total_reward: 9.0 g_loss: -6.2241\n",
      "Episode: 555 total_reward: 12.0 g_loss: -8.3125\n",
      "Episode: 556 total_reward: 46.0 g_loss: -31.8321\n",
      "Episode: 557 total_reward: 19.0 g_loss: -13.1354\n",
      "Episode: 558 total_reward: 19.0 g_loss: -13.1390\n",
      "Episode: 559 total_reward: 13.0 g_loss: -8.9836\n",
      "Episode: 560 total_reward: 14.0 g_loss: -9.6736\n",
      "Episode: 561 total_reward: 14.0 g_loss: -9.6802\n",
      "Episode: 562 total_reward: 13.0 g_loss: -8.9864\n",
      "Episode: 563 total_reward: 8.0 g_loss: -5.5267\n",
      "Episode: 564 total_reward: 11.0 g_loss: -7.5969\n",
      "Episode: 565 total_reward: 27.0 g_loss: -18.6679\n",
      "Episode: 566 total_reward: 68.0 g_loss: -47.0058\n",
      "Episode: 567 total_reward: 34.0 g_loss: -23.4880\n",
      "Episode: 568 total_reward: 24.0 g_loss: -16.5656\n",
      "Episode: 569 total_reward: 19.0 g_loss: -13.1075\n",
      "Episode: 570 total_reward: 18.0 g_loss: -12.4304\n",
      "Episode: 571 total_reward: 14.0 g_loss: -9.6692\n",
      "Episode: 572 total_reward: 12.0 g_loss: -8.2826\n",
      "Episode: 573 total_reward: 9.0 g_loss: -6.2048\n",
      "Episode: 574 total_reward: 10.0 g_loss: -6.8932\n",
      "Episode: 575 total_reward: 11.0 g_loss: -7.5864\n",
      "Episode: 576 total_reward: 10.0 g_loss: -6.8942\n",
      "Episode: 577 total_reward: 10.0 g_loss: -6.8992\n",
      "Episode: 578 total_reward: 13.0 g_loss: -8.9809\n",
      "Episode: 579 total_reward: 16.0 g_loss: -11.0592\n",
      "Episode: 580 total_reward: 20.0 g_loss: -13.8298\n",
      "Episode: 581 total_reward: 23.0 g_loss: -15.8878\n",
      "Episode: 582 total_reward: 21.0 g_loss: -14.5147\n",
      "Episode: 583 total_reward: 17.0 g_loss: -11.7570\n",
      "Episode: 584 total_reward: 29.0 g_loss: -20.0733\n",
      "Episode: 585 total_reward: 10.0 g_loss: -6.8864\n",
      "Episode: 586 total_reward: 10.0 g_loss: -6.9130\n",
      "Episode: 587 total_reward: 34.0 g_loss: -23.5321\n",
      "Episode: 588 total_reward: 81.0 g_loss: -56.0932\n",
      "Episode: 589 total_reward: 12.0 g_loss: -8.3077\n",
      "Episode: 590 total_reward: 10.0 g_loss: -6.9265\n",
      "Episode: 591 total_reward: 35.0 g_loss: -24.2473\n",
      "Episode: 592 total_reward: 36.0 g_loss: -24.9177\n",
      "Episode: 593 total_reward: 27.0 g_loss: -18.6719\n",
      "Episode: 594 total_reward: 26.0 g_loss: -17.9817\n",
      "Episode: 595 total_reward: 27.0 g_loss: -18.6588\n",
      "Episode: 596 total_reward: 20.0 g_loss: -13.8206\n",
      "Episode: 597 total_reward: 12.0 g_loss: -8.2842\n",
      "Episode: 598 total_reward: 12.0 g_loss: -8.2812\n",
      "Episode: 599 total_reward: 16.0 g_loss: -11.0352\n",
      "Episode: 600 total_reward: 13.0 g_loss: -8.9575\n",
      "Episode: 601 total_reward: 11.0 g_loss: -7.5789\n",
      "Episode: 602 total_reward: 10.0 g_loss: -6.8857\n",
      "Episode: 603 total_reward: 12.0 g_loss: -8.2639\n",
      "Episode: 604 total_reward: 10.0 g_loss: -6.8829\n",
      "Episode: 605 total_reward: 10.0 g_loss: -6.8856\n",
      "Episode: 606 total_reward: 10.0 g_loss: -6.8942\n",
      "Episode: 607 total_reward: 12.0 g_loss: -8.2783\n",
      "Episode: 608 total_reward: 13.0 g_loss: -8.9734\n",
      "Episode: 609 total_reward: 14.0 g_loss: -9.6798\n",
      "Episode: 610 total_reward: 25.0 g_loss: -17.3074\n",
      "Episode: 611 total_reward: 51.0 g_loss: -35.2975\n",
      "Episode: 612 total_reward: 32.0 g_loss: -22.1371\n",
      "Episode: 613 total_reward: 24.0 g_loss: -16.6002\n",
      "Episode: 614 total_reward: 16.0 g_loss: -11.0678\n",
      "Episode: 615 total_reward: 17.0 g_loss: -11.7573\n",
      "Episode: 616 total_reward: 12.0 g_loss: -8.2939\n",
      "Episode: 617 total_reward: 10.0 g_loss: -6.9119\n",
      "Episode: 618 total_reward: 11.0 g_loss: -7.5964\n",
      "Episode: 619 total_reward: 9.0 g_loss: -6.2175\n",
      "Episode: 620 total_reward: 10.0 g_loss: -6.9104\n",
      "Episode: 621 total_reward: 12.0 g_loss: -8.2933\n",
      "Episode: 622 total_reward: 15.0 g_loss: -10.3826\n",
      "Episode: 623 total_reward: 23.0 g_loss: -15.9260\n",
      "Episode: 624 total_reward: 80.0 g_loss: -55.3766\n",
      "Episode: 625 total_reward: 36.0 g_loss: -24.8933\n",
      "Episode: 626 total_reward: 14.0 g_loss: -9.6902\n",
      "Episode: 627 total_reward: 10.0 g_loss: -6.9252\n",
      "Episode: 628 total_reward: 12.0 g_loss: -8.3009\n",
      "Episode: 629 total_reward: 10.0 g_loss: -6.9193\n",
      "Episode: 630 total_reward: 12.0 g_loss: -8.3030\n",
      "Episode: 631 total_reward: 11.0 g_loss: -7.6158\n",
      "Episode: 632 total_reward: 87.0 g_loss: -60.1954\n",
      "Episode: 633 total_reward: 11.0 g_loss: -7.6136\n",
      "Episode: 634 total_reward: 11.0 g_loss: -7.6112\n",
      "Episode: 635 total_reward: 11.0 g_loss: -7.6186\n",
      "Episode: 636 total_reward: 200.0 g_loss: -138.4879\n",
      "Episode: 637 total_reward: 11.0 g_loss: -7.6156\n",
      "Episode: 638 total_reward: 28.0 g_loss: -19.3768\n",
      "Episode: 639 total_reward: 10.0 g_loss: -6.9064\n",
      "Episode: 640 total_reward: 9.0 g_loss: -6.2220\n",
      "Episode: 641 total_reward: 9.0 g_loss: -6.2283\n",
      "Episode: 642 total_reward: 74.0 g_loss: -51.2416\n",
      "Episode: 643 total_reward: 20.0 g_loss: -13.8494\n",
      "Episode: 644 total_reward: 69.0 g_loss: -47.7671\n",
      "Episode: 645 total_reward: 29.0 g_loss: -20.0788\n",
      "Episode: 646 total_reward: 26.0 g_loss: -17.9982\n",
      "Episode: 647 total_reward: 19.0 g_loss: -13.1454\n",
      "Episode: 648 total_reward: 16.0 g_loss: -11.0654\n",
      "Episode: 649 total_reward: 17.0 g_loss: -11.7637\n",
      "Episode: 650 total_reward: 18.0 g_loss: -12.4524\n",
      "Episode: 651 total_reward: 10.0 g_loss: -6.9211\n",
      "Episode: 652 total_reward: 11.0 g_loss: -7.5982\n",
      "Episode: 653 total_reward: 9.0 g_loss: -6.2276\n",
      "Episode: 654 total_reward: 55.0 g_loss: -38.0910\n",
      "Episode: 655 total_reward: 35.0 g_loss: -24.2221\n",
      "Episode: 656 total_reward: 16.0 g_loss: -11.0693\n",
      "Episode: 657 total_reward: 17.0 g_loss: -11.7635\n",
      "Episode: 658 total_reward: 11.0 g_loss: -7.6075\n",
      "Episode: 659 total_reward: 13.0 g_loss: -8.9873\n",
      "Episode: 660 total_reward: 10.0 g_loss: -6.9138\n",
      "Episode: 661 total_reward: 12.0 g_loss: -8.2937\n",
      "Episode: 662 total_reward: 10.0 g_loss: -6.9146\n",
      "Episode: 663 total_reward: 13.0 g_loss: -8.9940\n",
      "Episode: 664 total_reward: 15.0 g_loss: -10.3837\n",
      "Episode: 665 total_reward: 48.0 g_loss: -33.2268\n",
      "Episode: 666 total_reward: 13.0 g_loss: -8.9918\n",
      "Episode: 667 total_reward: 18.0 g_loss: -12.4567\n",
      "Episode: 668 total_reward: 16.0 g_loss: -11.0708\n",
      "Episode: 669 total_reward: 12.0 g_loss: -8.3043\n",
      "Episode: 670 total_reward: 11.0 g_loss: -7.6069\n",
      "Episode: 671 total_reward: 11.0 g_loss: -7.6118\n",
      "Episode: 672 total_reward: 9.0 g_loss: -6.2263\n",
      "Episode: 673 total_reward: 12.0 g_loss: -8.3104\n",
      "Episode: 674 total_reward: 31.0 g_loss: -21.4626\n",
      "Episode: 675 total_reward: 200.0 g_loss: -138.4604\n",
      "Episode: 676 total_reward: 31.0 g_loss: -21.4640\n",
      "Episode: 677 total_reward: 18.0 g_loss: -12.4666\n",
      "Episode: 678 total_reward: 11.0 g_loss: -7.6063\n",
      "Episode: 679 total_reward: 9.0 g_loss: -6.2162\n",
      "Episode: 680 total_reward: 9.0 g_loss: -6.2204\n",
      "Episode: 681 total_reward: 8.0 g_loss: -5.4968\n",
      "Episode: 682 total_reward: 9.0 g_loss: -6.1856\n",
      "Episode: 683 total_reward: 10.0 g_loss: -6.9097\n",
      "Episode: 684 total_reward: 17.0 g_loss: -11.7686\n",
      "Episode: 685 total_reward: 21.0 g_loss: -14.5387\n",
      "Episode: 686 total_reward: 17.0 g_loss: -11.7649\n",
      "Episode: 687 total_reward: 19.0 g_loss: -13.1436\n",
      "Episode: 688 total_reward: 18.0 g_loss: -12.4515\n",
      "Episode: 689 total_reward: 13.0 g_loss: -8.9927\n",
      "Episode: 690 total_reward: 13.0 g_loss: -8.9918\n",
      "Episode: 691 total_reward: 13.0 g_loss: -8.9930\n",
      "Episode: 692 total_reward: 12.0 g_loss: -8.3020\n",
      "Episode: 693 total_reward: 12.0 g_loss: -8.3016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 694 total_reward: 32.0 g_loss: -22.1238\n",
      "Episode: 695 total_reward: 61.0 g_loss: -42.2383\n",
      "Episode: 696 total_reward: 29.0 g_loss: -20.0571\n",
      "Episode: 697 total_reward: 22.0 g_loss: -15.1812\n",
      "Episode: 698 total_reward: 25.0 g_loss: -17.2531\n",
      "Episode: 699 total_reward: 21.0 g_loss: -14.4743\n",
      "Episode: 700 total_reward: 20.0 g_loss: -13.7896\n",
      "Episode: 701 total_reward: 15.0 g_loss: -10.3395\n",
      "Episode: 702 total_reward: 17.0 g_loss: -11.7213\n",
      "Episode: 703 total_reward: 12.0 g_loss: -8.2719\n",
      "Episode: 704 total_reward: 11.0 g_loss: -7.5891\n",
      "Episode: 705 total_reward: 12.0 g_loss: -8.2720\n",
      "Episode: 706 total_reward: 10.0 g_loss: -6.8915\n",
      "Episode: 707 total_reward: 10.0 g_loss: -6.8919\n",
      "Episode: 708 total_reward: 9.0 g_loss: -6.2029\n",
      "Episode: 709 total_reward: 11.0 g_loss: -7.5962\n",
      "Episode: 710 total_reward: 12.0 g_loss: -8.2882\n",
      "Episode: 711 total_reward: 11.0 g_loss: -7.6038\n",
      "Episode: 712 total_reward: 16.0 g_loss: -11.0672\n",
      "Episode: 713 total_reward: 9.0 g_loss: -6.2097\n",
      "Episode: 714 total_reward: 9.0 g_loss: -6.2152\n",
      "Episode: 715 total_reward: 12.0 g_loss: -8.3078\n",
      "Episode: 716 total_reward: 19.0 g_loss: -13.1584\n",
      "Episode: 717 total_reward: 50.0 g_loss: -34.5672\n",
      "Episode: 718 total_reward: 85.0 g_loss: -58.8531\n",
      "Episode: 719 total_reward: 99.0 g_loss: -68.5479\n",
      "Episode: 720 total_reward: 25.0 g_loss: -17.3105\n",
      "Episode: 721 total_reward: 44.0 g_loss: -30.4639\n",
      "Episode: 722 total_reward: 23.0 g_loss: -15.9185\n",
      "Episode: 723 total_reward: 32.0 g_loss: -22.1522\n",
      "Episode: 724 total_reward: 37.0 g_loss: -25.6108\n",
      "Episode: 725 total_reward: 33.0 g_loss: -22.8286\n",
      "Episode: 726 total_reward: 17.0 g_loss: -11.7476\n",
      "Episode: 727 total_reward: 12.0 g_loss: -8.2898\n",
      "Episode: 728 total_reward: 16.0 g_loss: -11.0523\n",
      "Episode: 729 total_reward: 12.0 g_loss: -8.2839\n",
      "Episode: 730 total_reward: 10.0 g_loss: -6.9021\n",
      "Episode: 731 total_reward: 13.0 g_loss: -8.9728\n",
      "Episode: 732 total_reward: 10.0 g_loss: -6.9021\n",
      "Episode: 733 total_reward: 11.0 g_loss: -7.5931\n",
      "Episode: 734 total_reward: 11.0 g_loss: -7.5924\n",
      "Episode: 735 total_reward: 11.0 g_loss: -7.6024\n",
      "Episode: 736 total_reward: 15.0 g_loss: -10.3711\n",
      "Episode: 737 total_reward: 12.0 g_loss: -8.3020\n",
      "Episode: 738 total_reward: 9.0 g_loss: -6.1568\n",
      "Episode: 739 total_reward: 9.0 g_loss: -6.1660\n",
      "Episode: 740 total_reward: 9.0 g_loss: -6.2053\n",
      "Episode: 741 total_reward: 10.0 g_loss: -6.9193\n",
      "Episode: 742 total_reward: 12.0 g_loss: -8.3036\n",
      "Episode: 743 total_reward: 20.0 g_loss: -13.8336\n",
      "Episode: 744 total_reward: 34.0 g_loss: -23.5344\n",
      "Episode: 745 total_reward: 22.0 g_loss: -15.2102\n",
      "Episode: 746 total_reward: 23.0 g_loss: -15.9213\n",
      "Episode: 747 total_reward: 13.0 g_loss: -8.9930\n",
      "Episode: 748 total_reward: 13.0 g_loss: -8.9929\n",
      "Episode: 749 total_reward: 13.0 g_loss: -8.9927\n",
      "Episode: 750 total_reward: 12.0 g_loss: -8.3037\n",
      "Episode: 751 total_reward: 19.0 g_loss: -13.1448\n",
      "Episode: 752 total_reward: 41.0 g_loss: -28.3478\n",
      "Episode: 753 total_reward: 54.0 g_loss: -37.3345\n",
      "Episode: 754 total_reward: 35.0 g_loss: -24.1970\n",
      "Episode: 755 total_reward: 28.0 g_loss: -19.3476\n",
      "Episode: 756 total_reward: 26.0 g_loss: -17.9488\n",
      "Episode: 757 total_reward: 19.0 g_loss: -13.0967\n",
      "Episode: 758 total_reward: 20.0 g_loss: -13.7983\n",
      "Episode: 759 total_reward: 18.0 g_loss: -12.3965\n",
      "Episode: 760 total_reward: 15.0 g_loss: -10.3388\n",
      "Episode: 761 total_reward: 14.0 g_loss: -9.6408\n",
      "Episode: 762 total_reward: 13.0 g_loss: -8.9580\n",
      "Episode: 763 total_reward: 13.0 g_loss: -8.9595\n",
      "Episode: 764 total_reward: 13.0 g_loss: -8.9632\n",
      "Episode: 765 total_reward: 11.0 g_loss: -7.5840\n",
      "Episode: 766 total_reward: 10.0 g_loss: -6.8906\n",
      "Episode: 767 total_reward: 8.0 g_loss: -5.5082\n",
      "Episode: 768 total_reward: 9.0 g_loss: -6.2104\n",
      "Episode: 769 total_reward: 12.0 g_loss: -8.2862\n",
      "Episode: 770 total_reward: 11.0 g_loss: -7.6052\n",
      "Episode: 771 total_reward: 13.0 g_loss: -8.9973\n",
      "Episode: 772 total_reward: 9.0 g_loss: -6.2025\n",
      "Episode: 773 total_reward: 9.0 g_loss: -6.2079\n",
      "Episode: 774 total_reward: 11.0 g_loss: -7.6081\n",
      "Episode: 775 total_reward: 14.0 g_loss: -9.6885\n",
      "Episode: 776 total_reward: 17.0 g_loss: -11.7684\n",
      "Episode: 777 total_reward: 29.0 g_loss: -20.0788\n",
      "Episode: 778 total_reward: 35.0 g_loss: -24.2097\n",
      "Episode: 779 total_reward: 63.0 g_loss: -43.5697\n",
      "Episode: 780 total_reward: 51.0 g_loss: -35.2717\n",
      "Episode: 781 total_reward: 53.0 g_loss: -36.6872\n",
      "Episode: 782 total_reward: 58.0 g_loss: -40.1399\n",
      "Episode: 783 total_reward: 27.0 g_loss: -18.6681\n",
      "Episode: 784 total_reward: 38.0 g_loss: -26.2939\n",
      "Episode: 785 total_reward: 18.0 g_loss: -12.4358\n",
      "Episode: 786 total_reward: 13.0 g_loss: -8.9853\n",
      "Episode: 787 total_reward: 13.0 g_loss: -8.9861\n",
      "Episode: 788 total_reward: 10.0 g_loss: -6.9122\n",
      "Episode: 789 total_reward: 13.0 g_loss: -8.9868\n",
      "Episode: 790 total_reward: 12.0 g_loss: -8.2999\n",
      "Episode: 791 total_reward: 11.0 g_loss: -7.6086\n",
      "Episode: 792 total_reward: 10.0 g_loss: -6.9146\n",
      "Episode: 793 total_reward: 9.0 g_loss: -6.2270\n",
      "Episode: 794 total_reward: 12.0 g_loss: -8.3066\n",
      "Episode: 795 total_reward: 14.0 g_loss: -9.6951\n",
      "Episode: 796 total_reward: 19.0 g_loss: -13.1558\n",
      "Episode: 797 total_reward: 18.0 g_loss: -12.4566\n",
      "Episode: 798 total_reward: 17.0 g_loss: -11.7736\n",
      "Episode: 799 total_reward: 19.0 g_loss: -13.1588\n",
      "Episode: 800 total_reward: 28.0 g_loss: -19.3871\n",
      "Episode: 801 total_reward: 31.0 g_loss: -21.4664\n",
      "Episode: 802 total_reward: 32.0 g_loss: -22.1637\n",
      "Episode: 803 total_reward: 20.0 g_loss: -13.8420\n",
      "Episode: 804 total_reward: 26.0 g_loss: -17.9985\n",
      "Episode: 805 total_reward: 36.0 g_loss: -24.9281\n",
      "Episode: 806 total_reward: 23.0 g_loss: -15.9241\n",
      "Episode: 807 total_reward: 10.0 g_loss: -6.9225\n",
      "Episode: 808 total_reward: 12.0 g_loss: -8.3040\n",
      "Episode: 809 total_reward: 13.0 g_loss: -9.0073\n",
      "Episode: 810 total_reward: 43.0 g_loss: -29.7474\n",
      "Episode: 811 total_reward: 17.0 g_loss: -11.7677\n",
      "Episode: 812 total_reward: 51.0 g_loss: -35.3035\n",
      "Episode: 813 total_reward: 53.0 g_loss: -36.6690\n",
      "Episode: 814 total_reward: 13.0 g_loss: -8.9996\n",
      "Episode: 815 total_reward: 39.0 g_loss: -27.0040\n",
      "Episode: 816 total_reward: 15.0 g_loss: -10.3864\n",
      "Episode: 817 total_reward: 13.0 g_loss: -9.0029\n",
      "Episode: 818 total_reward: 9.0 g_loss: -6.2291\n",
      "Episode: 819 total_reward: 9.0 g_loss: -6.2276\n",
      "Episode: 820 total_reward: 20.0 g_loss: -13.8331\n",
      "Episode: 821 total_reward: 14.0 g_loss: -9.6958\n",
      "Episode: 822 total_reward: 12.0 g_loss: -8.3115\n",
      "Episode: 823 total_reward: 13.0 g_loss: -8.9993\n",
      "Episode: 824 total_reward: 67.0 g_loss: -46.3528\n",
      "Episode: 825 total_reward: 65.0 g_loss: -45.0088\n",
      "Episode: 826 total_reward: 12.0 g_loss: -8.3038\n",
      "Episode: 827 total_reward: 51.0 g_loss: -35.3063\n",
      "Episode: 828 total_reward: 12.0 g_loss: -8.2982\n",
      "Episode: 829 total_reward: 9.0 g_loss: -6.2278\n",
      "Episode: 830 total_reward: 10.0 g_loss: -6.9217\n",
      "Episode: 831 total_reward: 20.0 g_loss: -13.8523\n",
      "Episode: 832 total_reward: 17.0 g_loss: -11.7707\n",
      "Episode: 833 total_reward: 14.0 g_loss: -9.6953\n",
      "Episode: 834 total_reward: 14.0 g_loss: -9.6927\n",
      "Episode: 835 total_reward: 11.0 g_loss: -7.6160\n",
      "Episode: 836 total_reward: 11.0 g_loss: -7.6081\n",
      "Episode: 837 total_reward: 38.0 g_loss: -26.3026\n",
      "Episode: 838 total_reward: 15.0 g_loss: -10.3807\n",
      "Episode: 839 total_reward: 11.0 g_loss: -7.6150\n",
      "Episode: 840 total_reward: 14.0 g_loss: -9.6886\n",
      "Episode: 841 total_reward: 9.0 g_loss: -6.2260\n",
      "Episode: 842 total_reward: 13.0 g_loss: -8.9986\n",
      "Episode: 843 total_reward: 13.0 g_loss: -8.9951\n",
      "Episode: 844 total_reward: 14.0 g_loss: -9.6866\n",
      "Episode: 845 total_reward: 19.0 g_loss: -13.1577\n",
      "Episode: 846 total_reward: 23.0 g_loss: -15.9289\n",
      "Episode: 847 total_reward: 17.0 g_loss: -11.7766\n",
      "Episode: 848 total_reward: 60.0 g_loss: -41.5224\n",
      "Episode: 849 total_reward: 59.0 g_loss: -40.8334\n",
      "Episode: 850 total_reward: 62.0 g_loss: -42.9070\n",
      "Episode: 851 total_reward: 10.0 g_loss: -6.8993\n",
      "Episode: 852 total_reward: 10.0 g_loss: -6.8997\n",
      "Episode: 853 total_reward: 12.0 g_loss: -8.2991\n",
      "Episode: 854 total_reward: 14.0 g_loss: -9.6929\n",
      "Episode: 855 total_reward: 21.0 g_loss: -14.5460\n",
      "Episode: 856 total_reward: 79.0 g_loss: -54.6919\n",
      "Episode: 857 total_reward: 20.0 g_loss: -13.8233\n",
      "Episode: 858 total_reward: 17.0 g_loss: -11.7478\n",
      "Episode: 859 total_reward: 16.0 g_loss: -11.0673\n",
      "Episode: 860 total_reward: 41.0 g_loss: -28.3935\n",
      "Episode: 861 total_reward: 55.0 g_loss: -38.0881\n",
      "Episode: 862 total_reward: 24.0 g_loss: -16.6123\n",
      "Episode: 863 total_reward: 21.0 g_loss: -14.5383\n",
      "Episode: 864 total_reward: 12.0 g_loss: -8.3108\n",
      "Episode: 865 total_reward: 44.0 g_loss: -30.4686\n",
      "Episode: 866 total_reward: 42.0 g_loss: -29.0710\n",
      "Episode: 867 total_reward: 20.0 g_loss: -13.8380\n",
      "Episode: 868 total_reward: 24.0 g_loss: -16.6078\n",
      "Episode: 869 total_reward: 15.0 g_loss: -10.3799\n",
      "Episode: 870 total_reward: 21.0 g_loss: -14.5353\n",
      "Episode: 871 total_reward: 13.0 g_loss: -8.9945\n",
      "Episode: 872 total_reward: 14.0 g_loss: -9.6788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 873 total_reward: 9.0 g_loss: -6.1806\n",
      "Episode: 874 total_reward: 12.0 g_loss: -8.2982\n",
      "Episode: 875 total_reward: 9.0 g_loss: -6.1963\n",
      "Episode: 876 total_reward: 10.0 g_loss: -6.9186\n",
      "Episode: 877 total_reward: 12.0 g_loss: -8.2863\n",
      "Episode: 878 total_reward: 12.0 g_loss: -8.2867\n",
      "Episode: 879 total_reward: 9.0 g_loss: -6.2153\n",
      "Episode: 880 total_reward: 11.0 g_loss: -7.6068\n",
      "Episode: 881 total_reward: 13.0 g_loss: -8.9940\n",
      "Episode: 882 total_reward: 17.0 g_loss: -11.7753\n",
      "Episode: 883 total_reward: 49.0 g_loss: -33.9224\n",
      "Episode: 884 total_reward: 36.0 g_loss: -24.9142\n",
      "Episode: 885 total_reward: 28.0 g_loss: -19.3659\n",
      "Episode: 886 total_reward: 33.0 g_loss: -22.8190\n",
      "Episode: 887 total_reward: 17.0 g_loss: -11.7396\n",
      "Episode: 888 total_reward: 18.0 g_loss: -12.4415\n",
      "Episode: 889 total_reward: 19.0 g_loss: -13.1258\n",
      "Episode: 890 total_reward: 13.0 g_loss: -8.9822\n",
      "Episode: 891 total_reward: 13.0 g_loss: -8.9807\n",
      "Episode: 892 total_reward: 11.0 g_loss: -7.5984\n",
      "Episode: 893 total_reward: 14.0 g_loss: -9.6733\n",
      "Episode: 894 total_reward: 10.0 g_loss: -6.9093\n",
      "Episode: 895 total_reward: 12.0 g_loss: -8.2955\n",
      "Episode: 896 total_reward: 12.0 g_loss: -8.2977\n",
      "Episode: 897 total_reward: 11.0 g_loss: -7.6070\n",
      "Episode: 898 total_reward: 11.0 g_loss: -7.6176\n",
      "Episode: 899 total_reward: 13.0 g_loss: -9.0002\n",
      "Episode: 900 total_reward: 18.0 g_loss: -12.4621\n",
      "Episode: 901 total_reward: 11.0 g_loss: -7.6112\n",
      "Episode: 902 total_reward: 11.0 g_loss: -7.6123\n",
      "Episode: 903 total_reward: 9.0 g_loss: -6.2271\n",
      "Episode: 904 total_reward: 10.0 g_loss: -6.9215\n",
      "Episode: 905 total_reward: 12.0 g_loss: -8.3095\n",
      "Episode: 906 total_reward: 21.0 g_loss: -14.5370\n",
      "Episode: 907 total_reward: 16.0 g_loss: -11.0783\n",
      "Episode: 908 total_reward: 24.0 g_loss: -16.6225\n",
      "Episode: 909 total_reward: 11.0 g_loss: -7.6123\n",
      "Episode: 910 total_reward: 12.0 g_loss: -8.3001\n",
      "Episode: 911 total_reward: 11.0 g_loss: -7.6125\n",
      "Episode: 912 total_reward: 42.0 g_loss: -29.0837\n",
      "Episode: 913 total_reward: 43.0 g_loss: -29.7823\n",
      "Episode: 914 total_reward: 59.0 g_loss: -40.8618\n",
      "Episode: 915 total_reward: 28.0 g_loss: -19.3914\n",
      "Episode: 916 total_reward: 37.0 g_loss: -25.6285\n",
      "Episode: 917 total_reward: 46.0 g_loss: -31.8667\n",
      "Episode: 918 total_reward: 44.0 g_loss: -30.4818\n",
      "Episode: 919 total_reward: 55.0 g_loss: -38.0839\n",
      "Episode: 920 total_reward: 25.0 g_loss: -17.3136\n",
      "Episode: 921 total_reward: 16.0 g_loss: -11.0782\n",
      "Episode: 922 total_reward: 18.0 g_loss: -12.4665\n",
      "Episode: 923 total_reward: 16.0 g_loss: -11.0678\n",
      "Episode: 924 total_reward: 13.0 g_loss: -8.9950\n",
      "Episode: 925 total_reward: 14.0 g_loss: -9.6904\n",
      "Episode: 926 total_reward: 12.0 g_loss: -8.3049\n",
      "Episode: 927 total_reward: 16.0 g_loss: -11.0754\n",
      "Episode: 928 total_reward: 10.0 g_loss: -6.8727\n",
      "Episode: 929 total_reward: 33.0 g_loss: -22.8312\n",
      "Episode: 930 total_reward: 15.0 g_loss: -10.3850\n",
      "Episode: 931 total_reward: 11.0 g_loss: -7.6129\n",
      "Episode: 932 total_reward: 9.0 g_loss: -6.2295\n",
      "Episode: 933 total_reward: 10.0 g_loss: -6.9236\n",
      "Episode: 934 total_reward: 11.0 g_loss: -7.6157\n",
      "Episode: 935 total_reward: 22.0 g_loss: -15.2234\n",
      "Episode: 936 total_reward: 14.0 g_loss: -9.6914\n",
      "Episode: 937 total_reward: 12.0 g_loss: -8.3055\n",
      "Episode: 938 total_reward: 14.0 g_loss: -9.6866\n",
      "Episode: 939 total_reward: 14.0 g_loss: -9.6845\n",
      "Episode: 940 total_reward: 17.0 g_loss: -11.7608\n",
      "Episode: 941 total_reward: 19.0 g_loss: -13.1405\n",
      "Episode: 942 total_reward: 14.0 g_loss: -9.6885\n",
      "Episode: 943 total_reward: 13.0 g_loss: -8.9988\n",
      "Episode: 944 total_reward: 12.0 g_loss: -8.3077\n",
      "Episode: 945 total_reward: 15.0 g_loss: -10.3829\n",
      "Episode: 946 total_reward: 15.0 g_loss: -10.3841\n",
      "Episode: 947 total_reward: 11.0 g_loss: -7.6192\n",
      "Episode: 948 total_reward: 20.0 g_loss: -13.8544\n",
      "Episode: 949 total_reward: 26.0 g_loss: -18.0126\n",
      "Episode: 950 total_reward: 10.0 g_loss: -6.9272\n",
      "Episode: 951 total_reward: 13.0 g_loss: -9.0035\n",
      "Episode: 952 total_reward: 14.0 g_loss: -9.6949\n",
      "Episode: 953 total_reward: 14.0 g_loss: -9.6934\n",
      "Episode: 954 total_reward: 13.0 g_loss: -9.0034\n",
      "Episode: 955 total_reward: 12.0 g_loss: -8.3132\n",
      "Episode: 956 total_reward: 26.0 g_loss: -17.9966\n",
      "Episode: 957 total_reward: 11.0 g_loss: -7.6060\n",
      "Episode: 958 total_reward: 18.0 g_loss: -12.4507\n",
      "Episode: 959 total_reward: 26.0 g_loss: -18.0098\n",
      "Episode: 960 total_reward: 50.0 g_loss: -34.6408\n",
      "Episode: 961 total_reward: 55.0 g_loss: -38.0903\n",
      "Episode: 962 total_reward: 36.0 g_loss: -24.9236\n",
      "Episode: 963 total_reward: 20.0 g_loss: -13.8550\n",
      "Episode: 964 total_reward: 86.0 g_loss: -59.5504\n",
      "Episode: 965 total_reward: 200.0 g_loss: -138.5464\n",
      "Episode: 966 total_reward: 58.0 g_loss: -40.1557\n",
      "Episode: 967 total_reward: 18.0 g_loss: -12.4645\n",
      "Episode: 968 total_reward: 10.0 g_loss: -6.9185\n",
      "Episode: 969 total_reward: 9.0 g_loss: -6.2311\n",
      "Episode: 970 total_reward: 13.0 g_loss: -8.9972\n",
      "Episode: 971 total_reward: 10.0 g_loss: -6.9008\n",
      "Episode: 972 total_reward: 10.0 g_loss: -6.9087\n",
      "Episode: 973 total_reward: 49.0 g_loss: -33.9214\n",
      "Episode: 974 total_reward: 8.0 g_loss: -5.5366\n",
      "Episode: 975 total_reward: 9.0 g_loss: -6.2280\n",
      "Episode: 976 total_reward: 11.0 g_loss: -7.6123\n",
      "Episode: 977 total_reward: 15.0 g_loss: -10.3863\n",
      "Episode: 978 total_reward: 18.0 g_loss: -12.4607\n",
      "Episode: 979 total_reward: 11.0 g_loss: -7.6170\n",
      "Episode: 980 total_reward: 10.0 g_loss: -6.9246\n",
      "Episode: 981 total_reward: 9.0 g_loss: -6.2309\n",
      "Episode: 982 total_reward: 8.0 g_loss: -5.5374\n",
      "Episode: 983 total_reward: 11.0 g_loss: -7.6113\n",
      "Episode: 984 total_reward: 12.0 g_loss: -8.3124\n",
      "Episode: 985 total_reward: 48.0 g_loss: -33.2231\n",
      "Episode: 986 total_reward: 22.0 g_loss: -15.2225\n",
      "Episode: 987 total_reward: 18.0 g_loss: -12.4576\n",
      "Episode: 988 total_reward: 15.0 g_loss: -10.3764\n",
      "Episode: 989 total_reward: 12.0 g_loss: -8.2979\n",
      "Episode: 990 total_reward: 12.0 g_loss: -8.2937\n",
      "Episode: 991 total_reward: 10.0 g_loss: -6.9079\n",
      "Episode: 992 total_reward: 10.0 g_loss: -6.9075\n",
      "Episode: 993 total_reward: 10.0 g_loss: -6.9068\n",
      "Episode: 994 total_reward: 11.0 g_loss: -7.6036\n",
      "Episode: 995 total_reward: 13.0 g_loss: -8.9905\n",
      "Episode: 996 total_reward: 12.0 g_loss: -8.3060\n",
      "Episode: 997 total_reward: 75.0 g_loss: -51.8415\n",
      "Episode: 998 total_reward: 49.0 g_loss: -33.8670\n",
      "Episode: 999 total_reward: 34.0 g_loss: -23.5335\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Env reward, action logits reward, action labels/onehot reward\n",
    "rewards_list, g_loss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Rstoring/loading the trained/learned controller SA/SM\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(train_episodes):\n",
    "        state = env.reset() # env first state\n",
    "        batch = [] # every data batch\n",
    "        total_reward = 0 # reward env\n",
    "\n",
    "        # Training steps/batches\n",
    "        for _ in range(max_steps): # start=0, step=1, stop=max_steps/done/reward\n",
    "            action_logits = sess.run([model.actions_logits], feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward # env\n",
    "            #reward *= 1- float(done)\n",
    "            #action *= 1- float(done)\n",
    "            batch.append([state, action, reward])\n",
    "            state = next_state\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        #batch = memory.buffer\n",
    "        states = np.array([each[0] for each in batch])\n",
    "        actions = np.array([each[1] for each in batch])\n",
    "        rewards = np.array([each[2] for each in batch])\n",
    "        g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict = {model.states: states, \n",
    "                                                                       model.actions: actions, \n",
    "                                                                       model.rewards:rewards})\n",
    "        print('Episode: {}'.format(ep),\n",
    "              'total_reward: {}'.format(total_reward),\n",
    "              'g_loss: {:.4f}'.format(g_loss))\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        g_loss_list.append([ep, g_loss])\n",
    "        \n",
    "    # Save the trained/learned D using G/SM/SA\n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model-pqa.ckpt')\n",
    "    #saver.save(sess, tf.train.latest_checkpoint('checkpoints'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total env rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Gloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy gradients\n",
    "\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.1\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### >**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "batch = []\n",
    "for _ in range(1000):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    batch.append([action, state, reward, done, info])\n",
    "    #print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1,\n",
       "  array([-0.03178076,  0.20450818, -0.03191318, -0.25472181]),\n",
       "  1.0,\n",
       "  False,\n",
       "  {}],\n",
       " (4,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0], batch[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "actions = np.array([each[0] for each in batch])\n",
    "states = np.array([each[1] for each in batch])\n",
    "rewards = np.array([each[2] for each in batch])\n",
    "dones = np.array([each[3] for each in batch])\n",
    "infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(1000,) (1000, 4) (1000,) (1000,)\n",
      "float64 float64 int64 bool\n",
      "1 0\n",
      "2\n",
      "1.0 1.0\n",
      "2.847612962323384 -2.564437279425898\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    return states, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator: Generating/prediting the actions\n",
    "def generator(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, actions, # model input\n",
    "               action_size, hidden_size): # model init\n",
    "    actions_logits = generator(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=actions_logits, \n",
    "                                                                     labels=actions_labels))        \n",
    "    return actions_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param loss: Generator loss Tensor for action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=g_vars)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.actions = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, actions=self.actions) # model input\n",
    "        \n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size:(1000, 4) actions:(1000,)\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('state size:{}'.format(states.shape), \n",
    "      'actions:{}'.format(actions.shape)) \n",
    "print(np.max(actions) - np.min(actions)+1)\n",
    "print(np.max(actions))\n",
    "print(np.min(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 300000000          # max steps in an episode\n",
    "learning_rate = 0.001          # learning rate for adam\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/init the graph/session\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04917259,  0.01885179, -0.03928554, -0.02142823])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02601117,  0.02127447,  0.03192817,  0.01514245]), 1.0, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, reward, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model-pg.ckpt\n",
      "Episode: 0 Total reward: 500.0 Batch loss: 0.133787870\n",
      "Episode: 1 Total reward: 500.0 Batch loss: 0.130888402\n",
      "Episode: 2 Total reward: 500.0 Batch loss: 0.135102078\n",
      "Episode: 3 Total reward: 500.0 Batch loss: 0.132383496\n",
      "Episode: 4 Total reward: 391.0 Batch loss: 0.129079565\n",
      "Episode: 5 Total reward: 500.0 Batch loss: 0.137109160\n",
      "Episode: 6 Total reward: 337.0 Batch loss: 0.123683423\n",
      "Episode: 7 Total reward: 340.0 Batch loss: 0.121749640\n",
      "Episode: 8 Total reward: 500.0 Batch loss: 0.133638874\n",
      "Episode: 9 Total reward: 462.0 Batch loss: 0.125235185\n",
      "Episode: 10 Total reward: 500.0 Batch loss: 0.132475004\n",
      "Episode: 11 Total reward: 500.0 Batch loss: 0.131751314\n",
      "Episode: 12 Total reward: 500.0 Batch loss: 0.118884347\n",
      "Episode: 13 Total reward: 500.0 Batch loss: 0.127472103\n",
      "Episode: 14 Total reward: 397.0 Batch loss: 0.101415657\n",
      "Episode: 15 Total reward: 500.0 Batch loss: 0.130942836\n",
      "Episode: 16 Total reward: 500.0 Batch loss: 0.132455364\n",
      "Episode: 17 Total reward: 500.0 Batch loss: 0.132245868\n",
      "Episode: 18 Total reward: 500.0 Batch loss: 0.133118421\n",
      "Episode: 19 Total reward: 500.0 Batch loss: 0.134526908\n",
      "Episode: 20 Total reward: 500.0 Batch loss: 0.121963337\n",
      "Episode: 21 Total reward: 328.0 Batch loss: 0.100943029\n",
      "Episode: 22 Total reward: 500.0 Batch loss: 0.127614707\n",
      "Episode: 23 Total reward: 500.0 Batch loss: 0.116274342\n",
      "Episode: 24 Total reward: 500.0 Batch loss: 0.127522707\n",
      "Episode: 25 Total reward: 453.0 Batch loss: 0.106451668\n",
      "Episode: 26 Total reward: 500.0 Batch loss: 0.148973048\n",
      "Episode: 27 Total reward: 402.0 Batch loss: 0.090736225\n",
      "Episode: 28 Total reward: 500.0 Batch loss: 0.125641957\n",
      "Episode: 29 Total reward: 500.0 Batch loss: 0.126750454\n",
      "Episode: 30 Total reward: 500.0 Batch loss: 0.155597866\n",
      "Episode: 31 Total reward: 500.0 Batch loss: 0.147505820\n",
      "Episode: 32 Total reward: 500.0 Batch loss: 0.121170029\n",
      "Episode: 33 Total reward: 500.0 Batch loss: 0.112289593\n",
      "Episode: 34 Total reward: 500.0 Batch loss: 0.114571102\n",
      "Episode: 35 Total reward: 500.0 Batch loss: 0.119482726\n",
      "Episode: 36 Total reward: 500.0 Batch loss: 0.119264074\n",
      "Episode: 37 Total reward: 500.0 Batch loss: 0.119514592\n",
      "Episode: 38 Total reward: 500.0 Batch loss: 0.116829604\n",
      "Episode: 39 Total reward: 500.0 Batch loss: 0.133157715\n",
      "Episode: 40 Total reward: 500.0 Batch loss: 0.108226046\n",
      "Episode: 41 Total reward: 500.0 Batch loss: 0.122429475\n",
      "Episode: 42 Total reward: 500.0 Batch loss: 0.124591589\n",
      "Episode: 43 Total reward: 500.0 Batch loss: 0.108162224\n",
      "Episode: 44 Total reward: 500.0 Batch loss: 0.111351095\n",
      "Episode: 45 Total reward: 500.0 Batch loss: 0.108606577\n",
      "Episode: 46 Total reward: 500.0 Batch loss: 0.116702355\n",
      "Episode: 47 Total reward: 500.0 Batch loss: 0.117667526\n",
      "Episode: 48 Total reward: 500.0 Batch loss: 0.118058205\n",
      "Episode: 49 Total reward: 471.0 Batch loss: 0.082595617\n",
      "Episode: 50 Total reward: 500.0 Batch loss: 0.117373653\n",
      "Episode: 51 Total reward: 500.0 Batch loss: 0.112875402\n",
      "Episode: 52 Total reward: 500.0 Batch loss: 0.107005544\n",
      "Episode: 53 Total reward: 500.0 Batch loss: 0.112958223\n",
      "Episode: 54 Total reward: 500.0 Batch loss: 0.113012351\n",
      "Episode: 55 Total reward: 500.0 Batch loss: 0.114089899\n",
      "Episode: 56 Total reward: 500.0 Batch loss: 0.115115799\n",
      "Episode: 57 Total reward: 500.0 Batch loss: 0.116010867\n",
      "Episode: 58 Total reward: 500.0 Batch loss: 0.114700779\n",
      "Episode: 59 Total reward: 500.0 Batch loss: 0.114266276\n",
      "Episode: 60 Total reward: 500.0 Batch loss: 0.112080835\n",
      "Episode: 61 Total reward: 500.0 Batch loss: 0.118842013\n",
      "Episode: 62 Total reward: 500.0 Batch loss: 0.113848150\n",
      "Episode: 63 Total reward: 500.0 Batch loss: 0.115070798\n",
      "Episode: 64 Total reward: 500.0 Batch loss: 0.111788183\n",
      "Episode: 65 Total reward: 500.0 Batch loss: 0.112579204\n",
      "Episode: 66 Total reward: 500.0 Batch loss: 0.113244407\n",
      "Episode: 67 Total reward: 500.0 Batch loss: 0.110935092\n",
      "Episode: 68 Total reward: 500.0 Batch loss: 0.113419205\n",
      "Episode: 69 Total reward: 500.0 Batch loss: 0.105608851\n",
      "Episode: 70 Total reward: 500.0 Batch loss: 0.090299390\n",
      "Episode: 71 Total reward: 500.0 Batch loss: 0.108804382\n",
      "Episode: 72 Total reward: 500.0 Batch loss: 0.109216511\n",
      "Episode: 73 Total reward: 500.0 Batch loss: 0.110796079\n",
      "Episode: 74 Total reward: 500.0 Batch loss: 0.105416380\n",
      "Episode: 75 Total reward: 500.0 Batch loss: 0.112075135\n",
      "Episode: 76 Total reward: 500.0 Batch loss: 0.107962355\n",
      "Episode: 77 Total reward: 500.0 Batch loss: 0.102020457\n",
      "Episode: 78 Total reward: 500.0 Batch loss: 0.094638631\n",
      "Episode: 79 Total reward: 500.0 Batch loss: 0.099525332\n",
      "Episode: 80 Total reward: 500.0 Batch loss: 0.101112202\n",
      "Episode: 81 Total reward: 500.0 Batch loss: 0.114667386\n",
      "Episode: 82 Total reward: 500.0 Batch loss: 0.106487617\n",
      "Episode: 83 Total reward: 500.0 Batch loss: 0.105290860\n",
      "Episode: 84 Total reward: 500.0 Batch loss: 0.106938794\n",
      "Episode: 85 Total reward: 500.0 Batch loss: 0.113760822\n",
      "Episode: 86 Total reward: 500.0 Batch loss: 0.105569206\n",
      "Episode: 87 Total reward: 500.0 Batch loss: 0.098487370\n",
      "Episode: 88 Total reward: 500.0 Batch loss: 0.099034011\n",
      "Episode: 89 Total reward: 500.0 Batch loss: 0.106844351\n",
      "Episode: 90 Total reward: 500.0 Batch loss: 0.107710831\n",
      "Episode: 91 Total reward: 500.0 Batch loss: 0.099999279\n",
      "Episode: 92 Total reward: 500.0 Batch loss: 0.099566497\n",
      "Episode: 93 Total reward: 500.0 Batch loss: 0.108069256\n",
      "Episode: 94 Total reward: 500.0 Batch loss: 0.099790283\n",
      "Episode: 95 Total reward: 500.0 Batch loss: 0.103233702\n",
      "Episode: 96 Total reward: 500.0 Batch loss: 0.092124775\n",
      "Episode: 97 Total reward: 500.0 Batch loss: 0.103998557\n",
      "Episode: 98 Total reward: 500.0 Batch loss: 0.106317058\n",
      "Episode: 99 Total reward: 500.0 Batch loss: 0.103401810\n",
      "Episode: 100 Total reward: 500.0 Batch loss: 0.089526832\n",
      "Episode: 101 Total reward: 500.0 Batch loss: 0.098439679\n",
      "Episode: 102 Total reward: 500.0 Batch loss: 0.110153571\n",
      "Episode: 103 Total reward: 500.0 Batch loss: 0.095553324\n",
      "Episode: 104 Total reward: 500.0 Batch loss: 0.104135729\n",
      "Episode: 105 Total reward: 500.0 Batch loss: 0.100750498\n",
      "Episode: 106 Total reward: 500.0 Batch loss: 0.097337775\n",
      "Episode: 107 Total reward: 500.0 Batch loss: 0.099640124\n",
      "Episode: 108 Total reward: 500.0 Batch loss: 0.099405453\n",
      "Episode: 109 Total reward: 500.0 Batch loss: 0.096057028\n",
      "Episode: 110 Total reward: 500.0 Batch loss: 0.090736404\n",
      "Episode: 111 Total reward: 500.0 Batch loss: 0.101221249\n",
      "Episode: 112 Total reward: 500.0 Batch loss: 0.099636212\n",
      "Episode: 113 Total reward: 500.0 Batch loss: 0.098450072\n",
      "Episode: 114 Total reward: 500.0 Batch loss: 0.099611200\n",
      "Episode: 115 Total reward: 500.0 Batch loss: 0.094127320\n",
      "Episode: 116 Total reward: 500.0 Batch loss: 0.094433725\n",
      "Episode: 117 Total reward: 500.0 Batch loss: 0.093381412\n",
      "Episode: 118 Total reward: 500.0 Batch loss: 0.099451952\n",
      "Episode: 119 Total reward: 500.0 Batch loss: 0.095178083\n",
      "Episode: 120 Total reward: 500.0 Batch loss: 0.093456283\n",
      "Episode: 121 Total reward: 500.0 Batch loss: 0.097763434\n",
      "Episode: 122 Total reward: 500.0 Batch loss: 0.098844089\n",
      "Episode: 123 Total reward: 500.0 Batch loss: 0.091015883\n",
      "Episode: 124 Total reward: 500.0 Batch loss: 0.099903218\n",
      "Episode: 125 Total reward: 500.0 Batch loss: 0.095375903\n",
      "Episode: 126 Total reward: 500.0 Batch loss: 0.091745228\n",
      "Episode: 127 Total reward: 500.0 Batch loss: 0.089999728\n",
      "Episode: 128 Total reward: 500.0 Batch loss: 0.092744924\n",
      "Episode: 129 Total reward: 500.0 Batch loss: 0.096782126\n",
      "Episode: 130 Total reward: 500.0 Batch loss: 0.100681745\n",
      "Episode: 131 Total reward: 500.0 Batch loss: 0.085367844\n",
      "Episode: 132 Total reward: 500.0 Batch loss: 0.092899986\n",
      "Episode: 133 Total reward: 500.0 Batch loss: 0.096637353\n",
      "Episode: 134 Total reward: 500.0 Batch loss: 0.091509327\n",
      "Episode: 135 Total reward: 500.0 Batch loss: 0.089035377\n",
      "Episode: 136 Total reward: 500.0 Batch loss: 0.093428493\n",
      "Episode: 137 Total reward: 500.0 Batch loss: 0.086970761\n",
      "Episode: 138 Total reward: 500.0 Batch loss: 0.088795163\n",
      "Episode: 139 Total reward: 500.0 Batch loss: 0.086044535\n",
      "Episode: 140 Total reward: 500.0 Batch loss: 0.095316693\n",
      "Episode: 141 Total reward: 500.0 Batch loss: 0.091150343\n",
      "Episode: 142 Total reward: 500.0 Batch loss: 0.089442827\n",
      "Episode: 143 Total reward: 500.0 Batch loss: 0.089018494\n",
      "Episode: 144 Total reward: 500.0 Batch loss: 0.091382571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 145 Total reward: 500.0 Batch loss: 0.094781034\n",
      "Episode: 146 Total reward: 500.0 Batch loss: 0.090362027\n",
      "Episode: 147 Total reward: 500.0 Batch loss: 0.091875181\n",
      "Episode: 148 Total reward: 500.0 Batch loss: 0.092328012\n",
      "Episode: 149 Total reward: 500.0 Batch loss: 0.091960877\n",
      "Episode: 150 Total reward: 500.0 Batch loss: 0.088023387\n",
      "Episode: 151 Total reward: 500.0 Batch loss: 0.094386362\n",
      "Episode: 152 Total reward: 500.0 Batch loss: 0.093381464\n",
      "Episode: 153 Total reward: 500.0 Batch loss: 0.085554130\n",
      "Episode: 154 Total reward: 500.0 Batch loss: 0.072813109\n",
      "Episode: 155 Total reward: 500.0 Batch loss: 0.088906884\n",
      "Episode: 156 Total reward: 500.0 Batch loss: 0.094522297\n",
      "Episode: 157 Total reward: 500.0 Batch loss: 0.079722524\n",
      "Episode: 158 Total reward: 500.0 Batch loss: 0.081496321\n",
      "Episode: 159 Total reward: 500.0 Batch loss: 0.090100862\n",
      "Episode: 160 Total reward: 500.0 Batch loss: 0.090370134\n",
      "Episode: 161 Total reward: 500.0 Batch loss: 0.092096791\n",
      "Episode: 162 Total reward: 500.0 Batch loss: 0.083938055\n",
      "Episode: 163 Total reward: 500.0 Batch loss: 0.078110866\n",
      "Episode: 164 Total reward: 500.0 Batch loss: 0.080946296\n",
      "Episode: 165 Total reward: 500.0 Batch loss: 0.086378627\n",
      "Episode: 166 Total reward: 500.0 Batch loss: 0.091936491\n",
      "Episode: 167 Total reward: 500.0 Batch loss: 0.081178285\n",
      "Episode: 168 Total reward: 500.0 Batch loss: 0.086012773\n",
      "Episode: 169 Total reward: 500.0 Batch loss: 0.086931825\n",
      "Episode: 170 Total reward: 500.0 Batch loss: 0.085459098\n",
      "Episode: 171 Total reward: 500.0 Batch loss: 0.091887474\n",
      "Episode: 172 Total reward: 500.0 Batch loss: 0.083888344\n",
      "Episode: 173 Total reward: 500.0 Batch loss: 0.088207774\n",
      "Episode: 174 Total reward: 500.0 Batch loss: 0.086826824\n",
      "Episode: 175 Total reward: 500.0 Batch loss: 0.086279742\n",
      "Episode: 176 Total reward: 500.0 Batch loss: 0.081581183\n",
      "Episode: 177 Total reward: 500.0 Batch loss: 0.079682857\n",
      "Episode: 178 Total reward: 500.0 Batch loss: 0.081357010\n",
      "Episode: 179 Total reward: 500.0 Batch loss: 0.091874048\n",
      "Episode: 180 Total reward: 500.0 Batch loss: 0.087236859\n",
      "Episode: 181 Total reward: 500.0 Batch loss: 0.072645694\n",
      "Episode: 182 Total reward: 500.0 Batch loss: 0.084365867\n",
      "Episode: 183 Total reward: 500.0 Batch loss: 0.083591245\n",
      "Episode: 184 Total reward: 500.0 Batch loss: 0.088361591\n",
      "Episode: 185 Total reward: 500.0 Batch loss: 0.088533796\n",
      "Episode: 186 Total reward: 500.0 Batch loss: 0.088548690\n",
      "Episode: 187 Total reward: 500.0 Batch loss: 0.085828327\n",
      "Episode: 188 Total reward: 500.0 Batch loss: 0.093169346\n",
      "Episode: 189 Total reward: 500.0 Batch loss: 0.084482908\n",
      "Episode: 190 Total reward: 500.0 Batch loss: 0.085237280\n",
      "Episode: 191 Total reward: 500.0 Batch loss: 0.083938867\n",
      "Episode: 192 Total reward: 500.0 Batch loss: 0.086601898\n",
      "Episode: 193 Total reward: 500.0 Batch loss: 0.080581404\n",
      "Episode: 194 Total reward: 500.0 Batch loss: 0.070732318\n",
      "Episode: 195 Total reward: 500.0 Batch loss: 0.082112953\n",
      "Episode: 196 Total reward: 500.0 Batch loss: 0.084111527\n",
      "Episode: 197 Total reward: 500.0 Batch loss: 0.077191457\n",
      "Episode: 198 Total reward: 500.0 Batch loss: 0.083664112\n",
      "Episode: 199 Total reward: 500.0 Batch loss: 0.085491911\n",
      "Episode: 200 Total reward: 500.0 Batch loss: 0.083996147\n",
      "Episode: 201 Total reward: 500.0 Batch loss: 0.085125163\n",
      "Episode: 202 Total reward: 500.0 Batch loss: 0.089212611\n",
      "Episode: 203 Total reward: 500.0 Batch loss: 0.079734184\n",
      "Episode: 204 Total reward: 500.0 Batch loss: 0.081965677\n",
      "Episode: 205 Total reward: 500.0 Batch loss: 0.081562936\n",
      "Episode: 206 Total reward: 500.0 Batch loss: 0.085952111\n",
      "Episode: 207 Total reward: 500.0 Batch loss: 0.086066708\n",
      "Episode: 208 Total reward: 500.0 Batch loss: 0.085174441\n",
      "Episode: 209 Total reward: 500.0 Batch loss: 0.083176330\n",
      "Episode: 210 Total reward: 500.0 Batch loss: 0.088339597\n",
      "Episode: 211 Total reward: 500.0 Batch loss: 0.084352165\n",
      "Episode: 212 Total reward: 500.0 Batch loss: 0.080962211\n",
      "Episode: 213 Total reward: 500.0 Batch loss: 0.073373541\n",
      "Episode: 214 Total reward: 500.0 Batch loss: 0.081764825\n",
      "Episode: 215 Total reward: 500.0 Batch loss: 0.083670989\n",
      "Episode: 216 Total reward: 500.0 Batch loss: 0.084833041\n",
      "Episode: 217 Total reward: 500.0 Batch loss: 0.079390995\n",
      "Episode: 218 Total reward: 500.0 Batch loss: 0.086896583\n",
      "Episode: 219 Total reward: 500.0 Batch loss: 0.085636273\n",
      "Episode: 220 Total reward: 500.0 Batch loss: 0.084611803\n",
      "Episode: 221 Total reward: 500.0 Batch loss: 0.090691768\n",
      "Episode: 222 Total reward: 500.0 Batch loss: 0.084531717\n",
      "Episode: 223 Total reward: 500.0 Batch loss: 0.074411370\n",
      "Episode: 224 Total reward: 500.0 Batch loss: 0.070302740\n",
      "Episode: 225 Total reward: 500.0 Batch loss: 0.084138334\n",
      "Episode: 226 Total reward: 500.0 Batch loss: 0.076816693\n",
      "Episode: 227 Total reward: 500.0 Batch loss: 0.078626364\n",
      "Episode: 228 Total reward: 500.0 Batch loss: 0.074429467\n",
      "Episode: 229 Total reward: 500.0 Batch loss: 0.079510756\n",
      "Episode: 230 Total reward: 500.0 Batch loss: 0.075201295\n",
      "Episode: 231 Total reward: 500.0 Batch loss: 0.075886078\n",
      "Episode: 232 Total reward: 500.0 Batch loss: 0.083528645\n",
      "Episode: 233 Total reward: 500.0 Batch loss: 0.083968028\n",
      "Episode: 234 Total reward: 500.0 Batch loss: 0.083684802\n",
      "Episode: 235 Total reward: 500.0 Batch loss: 0.072993703\n",
      "Episode: 236 Total reward: 500.0 Batch loss: 0.075812653\n",
      "Episode: 237 Total reward: 500.0 Batch loss: 0.081649661\n",
      "Episode: 238 Total reward: 500.0 Batch loss: 0.075436927\n",
      "Episode: 239 Total reward: 500.0 Batch loss: 0.078199551\n",
      "Episode: 240 Total reward: 500.0 Batch loss: 0.073882461\n",
      "Episode: 241 Total reward: 500.0 Batch loss: 0.076760612\n",
      "Episode: 242 Total reward: 500.0 Batch loss: 0.074568488\n",
      "Episode: 243 Total reward: 500.0 Batch loss: 0.078536287\n",
      "Episode: 244 Total reward: 500.0 Batch loss: 0.084819563\n",
      "Episode: 245 Total reward: 500.0 Batch loss: 0.078030489\n",
      "Episode: 246 Total reward: 500.0 Batch loss: 0.076347575\n",
      "Episode: 247 Total reward: 500.0 Batch loss: 0.085537061\n",
      "Episode: 248 Total reward: 500.0 Batch loss: 0.084278747\n",
      "Episode: 249 Total reward: 500.0 Batch loss: 0.076127701\n",
      "Episode: 250 Total reward: 500.0 Batch loss: 0.075801454\n",
      "Episode: 251 Total reward: 500.0 Batch loss: 0.075344309\n",
      "Episode: 252 Total reward: 500.0 Batch loss: 0.073160581\n",
      "Episode: 253 Total reward: 500.0 Batch loss: 0.079980075\n",
      "Episode: 254 Total reward: 500.0 Batch loss: 0.075279176\n",
      "Episode: 255 Total reward: 500.0 Batch loss: 0.075248837\n",
      "Episode: 256 Total reward: 500.0 Batch loss: 0.074526191\n",
      "Episode: 257 Total reward: 500.0 Batch loss: 0.074533738\n",
      "Episode: 258 Total reward: 500.0 Batch loss: 0.075487584\n",
      "Episode: 259 Total reward: 500.0 Batch loss: 0.072432898\n",
      "Episode: 260 Total reward: 500.0 Batch loss: 0.073607571\n",
      "Episode: 261 Total reward: 500.0 Batch loss: 0.077260584\n",
      "Episode: 262 Total reward: 500.0 Batch loss: 0.069808379\n",
      "Episode: 263 Total reward: 500.0 Batch loss: 0.078674041\n",
      "Episode: 264 Total reward: 500.0 Batch loss: 0.072123304\n",
      "Episode: 265 Total reward: 500.0 Batch loss: 0.078057691\n",
      "Episode: 266 Total reward: 500.0 Batch loss: 0.065861985\n",
      "Episode: 267 Total reward: 500.0 Batch loss: 0.062810786\n",
      "Episode: 268 Total reward: 500.0 Batch loss: 0.077402741\n",
      "Episode: 269 Total reward: 500.0 Batch loss: 0.073404424\n",
      "Episode: 270 Total reward: 500.0 Batch loss: 0.073023014\n",
      "Episode: 271 Total reward: 500.0 Batch loss: 0.079335950\n",
      "Episode: 272 Total reward: 500.0 Batch loss: 0.064804405\n",
      "Episode: 273 Total reward: 500.0 Batch loss: 0.078026980\n",
      "Episode: 274 Total reward: 500.0 Batch loss: 0.079408675\n",
      "Episode: 275 Total reward: 500.0 Batch loss: 0.061288022\n",
      "Episode: 276 Total reward: 488.0 Batch loss: 0.067889154\n",
      "Episode: 277 Total reward: 500.0 Batch loss: 0.061423104\n",
      "Episode: 278 Total reward: 500.0 Batch loss: 0.065811455\n",
      "Episode: 279 Total reward: 500.0 Batch loss: 0.058105659\n",
      "Episode: 280 Total reward: 500.0 Batch loss: 0.067269221\n",
      "Episode: 281 Total reward: 500.0 Batch loss: 0.062735438\n",
      "Episode: 282 Total reward: 500.0 Batch loss: 0.071647033\n",
      "Episode: 283 Total reward: 500.0 Batch loss: 0.060632985\n",
      "Episode: 284 Total reward: 500.0 Batch loss: 0.073069386\n",
      "Episode: 285 Total reward: 500.0 Batch loss: 0.066316359\n",
      "Episode: 286 Total reward: 500.0 Batch loss: 0.056010198\n",
      "Episode: 287 Total reward: 500.0 Batch loss: 0.069294810\n",
      "Episode: 288 Total reward: 500.0 Batch loss: 0.072023921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 289 Total reward: 500.0 Batch loss: 0.072905928\n",
      "Episode: 290 Total reward: 500.0 Batch loss: 0.061060745\n",
      "Episode: 291 Total reward: 500.0 Batch loss: 0.059625216\n",
      "Episode: 292 Total reward: 500.0 Batch loss: 0.074171573\n",
      "Episode: 293 Total reward: 500.0 Batch loss: 0.064743705\n",
      "Episode: 294 Total reward: 500.0 Batch loss: 0.066074908\n",
      "Episode: 295 Total reward: 500.0 Batch loss: 0.058893714\n",
      "Episode: 296 Total reward: 493.0 Batch loss: 0.063090831\n",
      "Episode: 297 Total reward: 500.0 Batch loss: 0.065526545\n",
      "Episode: 298 Total reward: 500.0 Batch loss: 0.072183229\n",
      "Episode: 299 Total reward: 500.0 Batch loss: 0.067937687\n",
      "Episode: 300 Total reward: 500.0 Batch loss: 0.076319292\n",
      "Episode: 301 Total reward: 500.0 Batch loss: 0.062547028\n",
      "Episode: 302 Total reward: 500.0 Batch loss: 0.061623238\n",
      "Episode: 303 Total reward: 500.0 Batch loss: 0.071167000\n",
      "Episode: 304 Total reward: 500.0 Batch loss: 0.069864400\n",
      "Episode: 305 Total reward: 500.0 Batch loss: 0.065160953\n",
      "Episode: 306 Total reward: 500.0 Batch loss: 0.070833258\n",
      "Episode: 307 Total reward: 500.0 Batch loss: 0.065184198\n",
      "Episode: 308 Total reward: 500.0 Batch loss: 0.067800343\n",
      "Episode: 309 Total reward: 500.0 Batch loss: 0.063014582\n",
      "Episode: 310 Total reward: 500.0 Batch loss: 0.073234595\n",
      "Episode: 311 Total reward: 500.0 Batch loss: 0.074193701\n",
      "Episode: 312 Total reward: 500.0 Batch loss: 0.070481315\n",
      "Episode: 313 Total reward: 500.0 Batch loss: 0.066411294\n",
      "Episode: 314 Total reward: 500.0 Batch loss: 0.061630957\n",
      "Episode: 315 Total reward: 500.0 Batch loss: 0.058647346\n",
      "Episode: 316 Total reward: 500.0 Batch loss: 0.068079531\n",
      "Episode: 317 Total reward: 500.0 Batch loss: 0.061661098\n",
      "Episode: 318 Total reward: 500.0 Batch loss: 0.060829937\n",
      "Episode: 319 Total reward: 500.0 Batch loss: 0.058841500\n",
      "Episode: 320 Total reward: 500.0 Batch loss: 0.054940104\n",
      "Episode: 321 Total reward: 500.0 Batch loss: 0.063926883\n",
      "Episode: 322 Total reward: 500.0 Batch loss: 0.060194787\n",
      "Episode: 323 Total reward: 500.0 Batch loss: 0.052631751\n",
      "Episode: 324 Total reward: 500.0 Batch loss: 0.060275007\n",
      "Episode: 325 Total reward: 500.0 Batch loss: 0.064741917\n",
      "Episode: 326 Total reward: 500.0 Batch loss: 0.063490763\n",
      "Episode: 327 Total reward: 500.0 Batch loss: 0.058052387\n",
      "Episode: 328 Total reward: 500.0 Batch loss: 0.065694496\n",
      "Episode: 329 Total reward: 500.0 Batch loss: 0.057952177\n",
      "Episode: 330 Total reward: 500.0 Batch loss: 0.063967645\n",
      "Episode: 331 Total reward: 500.0 Batch loss: 0.050967406\n",
      "Episode: 332 Total reward: 500.0 Batch loss: 0.058497269\n",
      "Episode: 333 Total reward: 500.0 Batch loss: 0.055810176\n",
      "Episode: 334 Total reward: 500.0 Batch loss: 0.067153871\n",
      "Episode: 335 Total reward: 500.0 Batch loss: 0.064282127\n",
      "Episode: 336 Total reward: 500.0 Batch loss: 0.062436089\n",
      "Episode: 337 Total reward: 500.0 Batch loss: 0.059864506\n",
      "Episode: 338 Total reward: 500.0 Batch loss: 0.056573804\n",
      "Episode: 339 Total reward: 500.0 Batch loss: 0.071917549\n",
      "Episode: 340 Total reward: 500.0 Batch loss: 0.061561737\n",
      "Episode: 341 Total reward: 500.0 Batch loss: 0.060054339\n",
      "Episode: 342 Total reward: 500.0 Batch loss: 0.061999056\n",
      "Episode: 343 Total reward: 500.0 Batch loss: 0.059014473\n",
      "Episode: 344 Total reward: 500.0 Batch loss: 0.064125359\n",
      "Episode: 345 Total reward: 500.0 Batch loss: 0.067325883\n",
      "Episode: 346 Total reward: 500.0 Batch loss: 0.067478329\n",
      "Episode: 347 Total reward: 500.0 Batch loss: 0.070493087\n",
      "Episode: 348 Total reward: 500.0 Batch loss: 0.064016074\n",
      "Episode: 349 Total reward: 500.0 Batch loss: 0.069417268\n",
      "Episode: 350 Total reward: 500.0 Batch loss: 0.064514428\n",
      "Episode: 351 Total reward: 500.0 Batch loss: 0.066907421\n",
      "Episode: 352 Total reward: 500.0 Batch loss: 0.056523383\n",
      "Episode: 353 Total reward: 500.0 Batch loss: 0.063706279\n",
      "Episode: 354 Total reward: 500.0 Batch loss: 0.065904781\n",
      "Episode: 355 Total reward: 500.0 Batch loss: 0.059658479\n",
      "Episode: 356 Total reward: 500.0 Batch loss: 0.062370356\n",
      "Episode: 357 Total reward: 500.0 Batch loss: 0.066729255\n",
      "Episode: 358 Total reward: 500.0 Batch loss: 0.057906333\n",
      "Episode: 359 Total reward: 500.0 Batch loss: 0.064897545\n",
      "Episode: 360 Total reward: 500.0 Batch loss: 0.063641250\n",
      "Episode: 361 Total reward: 500.0 Batch loss: 0.063162141\n",
      "Episode: 362 Total reward: 500.0 Batch loss: 0.065518051\n",
      "Episode: 363 Total reward: 500.0 Batch loss: 0.059037894\n",
      "Episode: 364 Total reward: 500.0 Batch loss: 0.062804691\n",
      "Episode: 365 Total reward: 500.0 Batch loss: 0.065122366\n",
      "Episode: 366 Total reward: 500.0 Batch loss: 0.059459262\n",
      "Episode: 367 Total reward: 500.0 Batch loss: 0.054763958\n",
      "Episode: 368 Total reward: 500.0 Batch loss: 0.063308187\n",
      "Episode: 369 Total reward: 500.0 Batch loss: 0.066444881\n",
      "Episode: 370 Total reward: 500.0 Batch loss: 0.059763066\n",
      "Episode: 371 Total reward: 500.0 Batch loss: 0.057540532\n",
      "Episode: 372 Total reward: 500.0 Batch loss: 0.068815283\n",
      "Episode: 373 Total reward: 500.0 Batch loss: 0.067850441\n",
      "Episode: 374 Total reward: 500.0 Batch loss: 0.060090370\n",
      "Episode: 375 Total reward: 500.0 Batch loss: 0.051229768\n",
      "Episode: 376 Total reward: 500.0 Batch loss: 0.066991672\n",
      "Episode: 377 Total reward: 500.0 Batch loss: 0.062090777\n",
      "Episode: 378 Total reward: 500.0 Batch loss: 0.053980488\n",
      "Episode: 379 Total reward: 500.0 Batch loss: 0.057186611\n",
      "Episode: 380 Total reward: 500.0 Batch loss: 0.060811799\n",
      "Episode: 381 Total reward: 500.0 Batch loss: 0.053488027\n",
      "Episode: 382 Total reward: 500.0 Batch loss: 0.058133088\n",
      "Episode: 383 Total reward: 500.0 Batch loss: 0.059118528\n",
      "Episode: 384 Total reward: 500.0 Batch loss: 0.062143184\n",
      "Episode: 385 Total reward: 500.0 Batch loss: 0.070391171\n",
      "Episode: 386 Total reward: 500.0 Batch loss: 0.051729646\n",
      "Episode: 387 Total reward: 500.0 Batch loss: 0.068872787\n",
      "Episode: 388 Total reward: 500.0 Batch loss: 0.073288456\n",
      "Episode: 389 Total reward: 500.0 Batch loss: 0.052842166\n",
      "Episode: 390 Total reward: 500.0 Batch loss: 0.060056888\n",
      "Episode: 391 Total reward: 500.0 Batch loss: 0.064022653\n",
      "Episode: 392 Total reward: 500.0 Batch loss: 0.065645121\n",
      "Episode: 393 Total reward: 500.0 Batch loss: 0.055672128\n",
      "Episode: 394 Total reward: 500.0 Batch loss: 0.061314564\n",
      "Episode: 395 Total reward: 500.0 Batch loss: 0.056915030\n",
      "Episode: 396 Total reward: 500.0 Batch loss: 0.058704369\n",
      "Episode: 397 Total reward: 500.0 Batch loss: 0.061091080\n",
      "Episode: 398 Total reward: 500.0 Batch loss: 0.056618694\n",
      "Episode: 399 Total reward: 500.0 Batch loss: 0.062011488\n",
      "Episode: 400 Total reward: 500.0 Batch loss: 0.051275499\n",
      "Episode: 401 Total reward: 500.0 Batch loss: 0.060315665\n",
      "Episode: 402 Total reward: 500.0 Batch loss: 0.054188371\n",
      "Episode: 403 Total reward: 500.0 Batch loss: 0.056166939\n",
      "Episode: 404 Total reward: 500.0 Batch loss: 0.062844299\n",
      "Episode: 405 Total reward: 500.0 Batch loss: 0.064544372\n",
      "Episode: 406 Total reward: 500.0 Batch loss: 0.062406573\n",
      "Episode: 407 Total reward: 500.0 Batch loss: 0.057537287\n",
      "Episode: 408 Total reward: 500.0 Batch loss: 0.049403418\n",
      "Episode: 409 Total reward: 500.0 Batch loss: 0.051561248\n",
      "Episode: 410 Total reward: 500.0 Batch loss: 0.055311296\n",
      "Episode: 411 Total reward: 500.0 Batch loss: 0.048032269\n",
      "Episode: 412 Total reward: 500.0 Batch loss: 0.058416646\n",
      "Episode: 413 Total reward: 500.0 Batch loss: 0.064018331\n",
      "Episode: 414 Total reward: 500.0 Batch loss: 0.068407938\n",
      "Episode: 415 Total reward: 500.0 Batch loss: 0.060427912\n",
      "Episode: 416 Total reward: 500.0 Batch loss: 0.062416881\n",
      "Episode: 417 Total reward: 500.0 Batch loss: 0.063917629\n",
      "Episode: 418 Total reward: 500.0 Batch loss: 0.060878184\n",
      "Episode: 419 Total reward: 500.0 Batch loss: 0.061628513\n",
      "Episode: 420 Total reward: 500.0 Batch loss: 0.056182198\n",
      "Episode: 421 Total reward: 500.0 Batch loss: 0.051338680\n",
      "Episode: 422 Total reward: 500.0 Batch loss: 0.061999738\n",
      "Episode: 423 Total reward: 500.0 Batch loss: 0.054117627\n",
      "Episode: 424 Total reward: 500.0 Batch loss: 0.049692765\n",
      "Episode: 425 Total reward: 500.0 Batch loss: 0.061590265\n",
      "Episode: 426 Total reward: 500.0 Batch loss: 0.055033710\n",
      "Episode: 427 Total reward: 500.0 Batch loss: 0.063654214\n",
      "Episode: 428 Total reward: 500.0 Batch loss: 0.058980860\n",
      "Episode: 429 Total reward: 500.0 Batch loss: 0.062964261\n",
      "Episode: 430 Total reward: 500.0 Batch loss: 0.065841638\n",
      "Episode: 431 Total reward: 500.0 Batch loss: 0.059587859\n",
      "Episode: 432 Total reward: 500.0 Batch loss: 0.064333953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 433 Total reward: 500.0 Batch loss: 0.054724917\n",
      "Episode: 434 Total reward: 500.0 Batch loss: 0.052678559\n",
      "Episode: 435 Total reward: 500.0 Batch loss: 0.070726961\n",
      "Episode: 436 Total reward: 500.0 Batch loss: 0.059695367\n",
      "Episode: 437 Total reward: 500.0 Batch loss: 0.058006816\n",
      "Episode: 438 Total reward: 500.0 Batch loss: 0.064731047\n",
      "Episode: 439 Total reward: 500.0 Batch loss: 0.065357514\n",
      "Episode: 440 Total reward: 500.0 Batch loss: 0.061416745\n",
      "Episode: 441 Total reward: 500.0 Batch loss: 0.067572676\n",
      "Episode: 442 Total reward: 500.0 Batch loss: 0.063025251\n",
      "Episode: 443 Total reward: 500.0 Batch loss: 0.055951584\n",
      "Episode: 444 Total reward: 500.0 Batch loss: 0.056913663\n",
      "Episode: 445 Total reward: 500.0 Batch loss: 0.044504918\n",
      "Episode: 446 Total reward: 500.0 Batch loss: 0.062216368\n",
      "Episode: 447 Total reward: 500.0 Batch loss: 0.072020836\n",
      "Episode: 448 Total reward: 500.0 Batch loss: 0.062334552\n",
      "Episode: 449 Total reward: 500.0 Batch loss: 0.051479809\n",
      "Episode: 450 Total reward: 500.0 Batch loss: 0.053188313\n",
      "Episode: 451 Total reward: 500.0 Batch loss: 0.063029028\n",
      "Episode: 452 Total reward: 500.0 Batch loss: 0.052983437\n",
      "Episode: 453 Total reward: 500.0 Batch loss: 0.055686943\n",
      "Episode: 454 Total reward: 500.0 Batch loss: 0.058112808\n",
      "Episode: 455 Total reward: 500.0 Batch loss: 0.050085351\n",
      "Episode: 456 Total reward: 500.0 Batch loss: 0.056318410\n",
      "Episode: 457 Total reward: 500.0 Batch loss: 0.060567841\n",
      "Episode: 458 Total reward: 500.0 Batch loss: 0.050944183\n",
      "Episode: 459 Total reward: 500.0 Batch loss: 0.054661386\n",
      "Episode: 460 Total reward: 500.0 Batch loss: 0.055747811\n",
      "Episode: 461 Total reward: 500.0 Batch loss: 0.050619230\n",
      "Episode: 462 Total reward: 500.0 Batch loss: 0.053016834\n",
      "Episode: 463 Total reward: 500.0 Batch loss: 0.054627519\n",
      "Episode: 464 Total reward: 500.0 Batch loss: 0.049454525\n",
      "Episode: 465 Total reward: 500.0 Batch loss: 0.049914889\n",
      "Episode: 466 Total reward: 500.0 Batch loss: 0.045906868\n",
      "Episode: 467 Total reward: 500.0 Batch loss: 0.052410468\n",
      "Episode: 468 Total reward: 500.0 Batch loss: 0.056942798\n",
      "Episode: 469 Total reward: 500.0 Batch loss: 0.053191397\n",
      "Episode: 470 Total reward: 500.0 Batch loss: 0.047326662\n",
      "Episode: 471 Total reward: 500.0 Batch loss: 0.053715404\n",
      "Episode: 472 Total reward: 500.0 Batch loss: 0.050596498\n",
      "Episode: 473 Total reward: 500.0 Batch loss: 0.054224871\n",
      "Episode: 474 Total reward: 500.0 Batch loss: 0.056769639\n",
      "Episode: 475 Total reward: 500.0 Batch loss: 0.051814064\n",
      "Episode: 476 Total reward: 500.0 Batch loss: 0.058429576\n",
      "Episode: 477 Total reward: 500.0 Batch loss: 0.059271842\n",
      "Episode: 478 Total reward: 500.0 Batch loss: 0.055095833\n",
      "Episode: 479 Total reward: 500.0 Batch loss: 0.053582862\n",
      "Episode: 480 Total reward: 500.0 Batch loss: 0.047072276\n",
      "Episode: 481 Total reward: 500.0 Batch loss: 0.054206073\n",
      "Episode: 482 Total reward: 500.0 Batch loss: 0.055129729\n",
      "Episode: 483 Total reward: 500.0 Batch loss: 0.057076868\n",
      "Episode: 484 Total reward: 500.0 Batch loss: 0.052757975\n",
      "Episode: 485 Total reward: 500.0 Batch loss: 0.044084940\n",
      "Episode: 486 Total reward: 500.0 Batch loss: 0.055103835\n",
      "Episode: 487 Total reward: 500.0 Batch loss: 0.046921078\n",
      "Episode: 488 Total reward: 500.0 Batch loss: 0.053831000\n",
      "Episode: 489 Total reward: 500.0 Batch loss: 0.050705515\n",
      "Episode: 490 Total reward: 500.0 Batch loss: 0.063581452\n",
      "Episode: 491 Total reward: 500.0 Batch loss: 0.062391926\n",
      "Episode: 492 Total reward: 500.0 Batch loss: 0.058054164\n",
      "Episode: 493 Total reward: 500.0 Batch loss: 0.049000490\n",
      "Episode: 494 Total reward: 500.0 Batch loss: 0.054991990\n",
      "Episode: 495 Total reward: 500.0 Batch loss: 0.054039177\n",
      "Episode: 496 Total reward: 500.0 Batch loss: 0.053733416\n",
      "Episode: 497 Total reward: 500.0 Batch loss: 0.056258038\n",
      "Episode: 498 Total reward: 500.0 Batch loss: 0.060770411\n",
      "Episode: 499 Total reward: 500.0 Batch loss: 0.052124098\n",
      "Episode: 500 Total reward: 500.0 Batch loss: 0.055251617\n",
      "Episode: 501 Total reward: 500.0 Batch loss: 0.056763150\n",
      "Episode: 502 Total reward: 500.0 Batch loss: 0.058938757\n",
      "Episode: 503 Total reward: 500.0 Batch loss: 0.049063411\n",
      "Episode: 504 Total reward: 500.0 Batch loss: 0.051794045\n",
      "Episode: 505 Total reward: 500.0 Batch loss: 0.046323169\n",
      "Episode: 506 Total reward: 500.0 Batch loss: 0.049620979\n",
      "Episode: 507 Total reward: 500.0 Batch loss: 0.057524305\n",
      "Episode: 508 Total reward: 500.0 Batch loss: 0.046809360\n",
      "Episode: 509 Total reward: 500.0 Batch loss: 0.046727296\n",
      "Episode: 510 Total reward: 500.0 Batch loss: 0.063464366\n",
      "Episode: 511 Total reward: 500.0 Batch loss: 0.052218370\n",
      "Episode: 512 Total reward: 500.0 Batch loss: 0.051345065\n",
      "Episode: 513 Total reward: 500.0 Batch loss: 0.055262763\n",
      "Episode: 514 Total reward: 500.0 Batch loss: 0.048745852\n",
      "Episode: 515 Total reward: 500.0 Batch loss: 0.054615352\n",
      "Episode: 516 Total reward: 500.0 Batch loss: 0.051932607\n",
      "Episode: 517 Total reward: 500.0 Batch loss: 0.047898781\n",
      "Episode: 518 Total reward: 500.0 Batch loss: 0.050738599\n",
      "Episode: 519 Total reward: 500.0 Batch loss: 0.050748933\n",
      "Episode: 520 Total reward: 500.0 Batch loss: 0.048417773\n",
      "Episode: 521 Total reward: 500.0 Batch loss: 0.051679105\n",
      "Episode: 522 Total reward: 500.0 Batch loss: 0.055021118\n",
      "Episode: 523 Total reward: 500.0 Batch loss: 0.062437318\n",
      "Episode: 524 Total reward: 500.0 Batch loss: 0.056131471\n",
      "Episode: 525 Total reward: 500.0 Batch loss: 0.050212558\n",
      "Episode: 526 Total reward: 500.0 Batch loss: 0.050351746\n",
      "Episode: 527 Total reward: 500.0 Batch loss: 0.051821511\n",
      "Episode: 528 Total reward: 500.0 Batch loss: 0.052344982\n",
      "Episode: 529 Total reward: 500.0 Batch loss: 0.051215380\n",
      "Episode: 530 Total reward: 500.0 Batch loss: 0.049781993\n",
      "Episode: 531 Total reward: 500.0 Batch loss: 0.047233365\n",
      "Episode: 532 Total reward: 500.0 Batch loss: 0.048611380\n",
      "Episode: 533 Total reward: 500.0 Batch loss: 0.062775709\n",
      "Episode: 534 Total reward: 500.0 Batch loss: 0.062624559\n",
      "Episode: 535 Total reward: 500.0 Batch loss: 0.062293716\n",
      "Episode: 536 Total reward: 500.0 Batch loss: 0.050611623\n",
      "Episode: 537 Total reward: 500.0 Batch loss: 0.050574362\n",
      "Episode: 538 Total reward: 500.0 Batch loss: 0.046260204\n",
      "Episode: 539 Total reward: 500.0 Batch loss: 0.048596568\n",
      "Episode: 540 Total reward: 500.0 Batch loss: 0.048346028\n",
      "Episode: 541 Total reward: 500.0 Batch loss: 0.049989805\n",
      "Episode: 542 Total reward: 500.0 Batch loss: 0.046350103\n",
      "Episode: 543 Total reward: 500.0 Batch loss: 0.059051249\n",
      "Episode: 544 Total reward: 500.0 Batch loss: 0.043508064\n",
      "Episode: 545 Total reward: 500.0 Batch loss: 0.056743823\n",
      "Episode: 546 Total reward: 500.0 Batch loss: 0.053256962\n",
      "Episode: 547 Total reward: 500.0 Batch loss: 0.059341259\n",
      "Episode: 548 Total reward: 500.0 Batch loss: 0.055261735\n",
      "Episode: 549 Total reward: 500.0 Batch loss: 0.061984170\n",
      "Episode: 550 Total reward: 500.0 Batch loss: 0.057604529\n",
      "Episode: 551 Total reward: 500.0 Batch loss: 0.058096018\n",
      "Episode: 552 Total reward: 500.0 Batch loss: 0.044671495\n",
      "Episode: 553 Total reward: 500.0 Batch loss: 0.049326509\n",
      "Episode: 554 Total reward: 500.0 Batch loss: 0.049906362\n",
      "Episode: 555 Total reward: 500.0 Batch loss: 0.055890013\n",
      "Episode: 556 Total reward: 500.0 Batch loss: 0.050590750\n",
      "Episode: 557 Total reward: 500.0 Batch loss: 0.046505742\n",
      "Episode: 558 Total reward: 500.0 Batch loss: 0.049237646\n",
      "Episode: 559 Total reward: 500.0 Batch loss: 0.047142264\n",
      "Episode: 560 Total reward: 500.0 Batch loss: 0.054159533\n",
      "Episode: 561 Total reward: 500.0 Batch loss: 0.059122026\n",
      "Episode: 562 Total reward: 500.0 Batch loss: 0.050727371\n",
      "Episode: 563 Total reward: 500.0 Batch loss: 0.050780632\n",
      "Episode: 564 Total reward: 500.0 Batch loss: 0.045524485\n",
      "Episode: 565 Total reward: 500.0 Batch loss: 0.048978254\n",
      "Episode: 566 Total reward: 500.0 Batch loss: 0.048096653\n",
      "Episode: 567 Total reward: 500.0 Batch loss: 0.057991225\n",
      "Episode: 568 Total reward: 500.0 Batch loss: 0.054068286\n",
      "Episode: 569 Total reward: 500.0 Batch loss: 0.055693500\n",
      "Episode: 570 Total reward: 500.0 Batch loss: 0.048932604\n",
      "Episode: 571 Total reward: 500.0 Batch loss: 0.048254997\n",
      "Episode: 572 Total reward: 500.0 Batch loss: 0.051526152\n",
      "Episode: 573 Total reward: 500.0 Batch loss: 0.047215659\n",
      "Episode: 574 Total reward: 500.0 Batch loss: 0.048392225\n",
      "Episode: 575 Total reward: 500.0 Batch loss: 0.048063729\n",
      "Episode: 576 Total reward: 500.0 Batch loss: 0.056051027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 577 Total reward: 500.0 Batch loss: 0.048036121\n",
      "Episode: 578 Total reward: 500.0 Batch loss: 0.047002811\n",
      "Episode: 579 Total reward: 500.0 Batch loss: 0.049827270\n",
      "Episode: 580 Total reward: 500.0 Batch loss: 0.047267608\n",
      "Episode: 581 Total reward: 500.0 Batch loss: 0.049652904\n",
      "Episode: 582 Total reward: 500.0 Batch loss: 0.044196650\n",
      "Episode: 583 Total reward: 500.0 Batch loss: 0.047446169\n",
      "Episode: 584 Total reward: 500.0 Batch loss: 0.044155940\n",
      "Episode: 585 Total reward: 500.0 Batch loss: 0.048502356\n",
      "Episode: 586 Total reward: 500.0 Batch loss: 0.045664471\n",
      "Episode: 587 Total reward: 500.0 Batch loss: 0.055121996\n",
      "Episode: 588 Total reward: 500.0 Batch loss: 0.047078047\n",
      "Episode: 589 Total reward: 500.0 Batch loss: 0.049804386\n",
      "Episode: 590 Total reward: 500.0 Batch loss: 0.042617656\n",
      "Episode: 591 Total reward: 500.0 Batch loss: 0.049566209\n",
      "Episode: 592 Total reward: 500.0 Batch loss: 0.054948278\n",
      "Episode: 593 Total reward: 500.0 Batch loss: 0.039921571\n",
      "Episode: 594 Total reward: 500.0 Batch loss: 0.053343192\n",
      "Episode: 595 Total reward: 500.0 Batch loss: 0.052052785\n",
      "Episode: 596 Total reward: 500.0 Batch loss: 0.059312992\n",
      "Episode: 597 Total reward: 500.0 Batch loss: 0.055655926\n",
      "Episode: 598 Total reward: 500.0 Batch loss: 0.048213951\n",
      "Episode: 599 Total reward: 500.0 Batch loss: 0.046089150\n",
      "Episode: 600 Total reward: 500.0 Batch loss: 0.050696857\n",
      "Episode: 601 Total reward: 500.0 Batch loss: 0.042012595\n",
      "Episode: 602 Total reward: 500.0 Batch loss: 0.047561470\n",
      "Episode: 603 Total reward: 500.0 Batch loss: 0.048913833\n",
      "Episode: 604 Total reward: 500.0 Batch loss: 0.052148491\n",
      "Episode: 605 Total reward: 500.0 Batch loss: 0.052408073\n",
      "Episode: 606 Total reward: 500.0 Batch loss: 0.041968379\n",
      "Episode: 607 Total reward: 500.0 Batch loss: 0.041839641\n",
      "Episode: 608 Total reward: 500.0 Batch loss: 0.044140503\n",
      "Episode: 609 Total reward: 500.0 Batch loss: 0.053628694\n",
      "Episode: 610 Total reward: 500.0 Batch loss: 0.041951802\n",
      "Episode: 611 Total reward: 500.0 Batch loss: 0.048711035\n",
      "Episode: 612 Total reward: 500.0 Batch loss: 0.043741915\n",
      "Episode: 613 Total reward: 500.0 Batch loss: 0.049834684\n",
      "Episode: 614 Total reward: 500.0 Batch loss: 0.049659271\n",
      "Episode: 615 Total reward: 500.0 Batch loss: 0.053845182\n",
      "Episode: 616 Total reward: 500.0 Batch loss: 0.051766708\n",
      "Episode: 617 Total reward: 500.0 Batch loss: 0.052896902\n",
      "Episode: 618 Total reward: 500.0 Batch loss: 0.052294757\n",
      "Episode: 619 Total reward: 500.0 Batch loss: 0.044118140\n",
      "Episode: 620 Total reward: 500.0 Batch loss: 0.056984458\n",
      "Episode: 621 Total reward: 500.0 Batch loss: 0.044756856\n",
      "Episode: 622 Total reward: 500.0 Batch loss: 0.043925419\n",
      "Episode: 623 Total reward: 500.0 Batch loss: 0.051628526\n",
      "Episode: 624 Total reward: 500.0 Batch loss: 0.038797174\n",
      "Episode: 625 Total reward: 500.0 Batch loss: 0.063311309\n",
      "Episode: 626 Total reward: 500.0 Batch loss: 0.058774475\n",
      "Episode: 627 Total reward: 500.0 Batch loss: 0.043682650\n",
      "Episode: 628 Total reward: 500.0 Batch loss: 0.040576331\n",
      "Episode: 629 Total reward: 500.0 Batch loss: 0.053539075\n",
      "Episode: 630 Total reward: 500.0 Batch loss: 0.039394066\n",
      "Episode: 631 Total reward: 500.0 Batch loss: 0.061040238\n",
      "Episode: 632 Total reward: 500.0 Batch loss: 0.044792272\n",
      "Episode: 633 Total reward: 500.0 Batch loss: 0.045444541\n",
      "Episode: 634 Total reward: 500.0 Batch loss: 0.045077465\n",
      "Episode: 635 Total reward: 500.0 Batch loss: 0.051419176\n",
      "Episode: 636 Total reward: 500.0 Batch loss: 0.044075612\n",
      "Episode: 637 Total reward: 500.0 Batch loss: 0.044379167\n",
      "Episode: 638 Total reward: 500.0 Batch loss: 0.051298518\n",
      "Episode: 639 Total reward: 500.0 Batch loss: 0.051107679\n",
      "Episode: 640 Total reward: 500.0 Batch loss: 0.047847442\n",
      "Episode: 641 Total reward: 500.0 Batch loss: 0.048598260\n",
      "Episode: 642 Total reward: 500.0 Batch loss: 0.040764168\n",
      "Episode: 643 Total reward: 500.0 Batch loss: 0.041585304\n",
      "Episode: 644 Total reward: 500.0 Batch loss: 0.040404011\n",
      "Episode: 645 Total reward: 500.0 Batch loss: 0.046806067\n",
      "Episode: 646 Total reward: 500.0 Batch loss: 0.045431152\n",
      "Episode: 647 Total reward: 500.0 Batch loss: 0.039210148\n",
      "Episode: 648 Total reward: 500.0 Batch loss: 0.044446249\n",
      "Episode: 649 Total reward: 500.0 Batch loss: 0.047535799\n",
      "Episode: 650 Total reward: 500.0 Batch loss: 0.042864781\n",
      "Episode: 651 Total reward: 500.0 Batch loss: 0.046928875\n",
      "Episode: 652 Total reward: 500.0 Batch loss: 0.055971492\n",
      "Episode: 653 Total reward: 500.0 Batch loss: 0.044429161\n",
      "Episode: 654 Total reward: 500.0 Batch loss: 0.040430583\n",
      "Episode: 655 Total reward: 500.0 Batch loss: 0.048937343\n",
      "Episode: 656 Total reward: 500.0 Batch loss: 0.049093127\n",
      "Episode: 657 Total reward: 500.0 Batch loss: 0.056523789\n",
      "Episode: 658 Total reward: 500.0 Batch loss: 0.044526365\n",
      "Episode: 659 Total reward: 500.0 Batch loss: 0.044444978\n",
      "Episode: 660 Total reward: 500.0 Batch loss: 0.046303168\n",
      "Episode: 661 Total reward: 500.0 Batch loss: 0.038479362\n",
      "Episode: 662 Total reward: 500.0 Batch loss: 0.052790176\n",
      "Episode: 663 Total reward: 500.0 Batch loss: 0.044517372\n",
      "Episode: 664 Total reward: 500.0 Batch loss: 0.043988775\n",
      "Episode: 665 Total reward: 500.0 Batch loss: 0.048115369\n",
      "Episode: 666 Total reward: 500.0 Batch loss: 0.042272426\n",
      "Episode: 667 Total reward: 500.0 Batch loss: 0.045286331\n",
      "Episode: 668 Total reward: 500.0 Batch loss: 0.053961210\n",
      "Episode: 669 Total reward: 500.0 Batch loss: 0.046682432\n",
      "Episode: 670 Total reward: 500.0 Batch loss: 0.046168938\n",
      "Episode: 671 Total reward: 500.0 Batch loss: 0.044520639\n",
      "Episode: 672 Total reward: 500.0 Batch loss: 0.048548996\n",
      "Episode: 673 Total reward: 500.0 Batch loss: 0.049417745\n",
      "Episode: 674 Total reward: 500.0 Batch loss: 0.041749503\n",
      "Episode: 675 Total reward: 500.0 Batch loss: 0.049993798\n",
      "Episode: 676 Total reward: 500.0 Batch loss: 0.052845810\n",
      "Episode: 677 Total reward: 500.0 Batch loss: 0.049043830\n",
      "Episode: 678 Total reward: 500.0 Batch loss: 0.043967888\n",
      "Episode: 679 Total reward: 500.0 Batch loss: 0.042319980\n",
      "Episode: 680 Total reward: 500.0 Batch loss: 0.049002782\n",
      "Episode: 681 Total reward: 500.0 Batch loss: 0.051005051\n",
      "Episode: 682 Total reward: 500.0 Batch loss: 0.048389573\n",
      "Episode: 683 Total reward: 500.0 Batch loss: 0.039681777\n",
      "Episode: 684 Total reward: 500.0 Batch loss: 0.038569536\n",
      "Episode: 685 Total reward: 500.0 Batch loss: 0.044483174\n",
      "Episode: 686 Total reward: 500.0 Batch loss: 0.038374301\n",
      "Episode: 687 Total reward: 500.0 Batch loss: 0.036097232\n",
      "Episode: 688 Total reward: 500.0 Batch loss: 0.044758789\n",
      "Episode: 689 Total reward: 500.0 Batch loss: 0.039545923\n",
      "Episode: 690 Total reward: 500.0 Batch loss: 0.045442078\n",
      "Episode: 691 Total reward: 500.0 Batch loss: 0.049577851\n",
      "Episode: 692 Total reward: 500.0 Batch loss: 0.041279119\n",
      "Episode: 693 Total reward: 500.0 Batch loss: 0.042248204\n",
      "Episode: 694 Total reward: 500.0 Batch loss: 0.047125611\n",
      "Episode: 695 Total reward: 500.0 Batch loss: 0.042603694\n",
      "Episode: 696 Total reward: 500.0 Batch loss: 0.040683053\n",
      "Episode: 697 Total reward: 500.0 Batch loss: 0.039912000\n",
      "Episode: 698 Total reward: 500.0 Batch loss: 0.051489573\n",
      "Episode: 699 Total reward: 500.0 Batch loss: 0.047034748\n",
      "Episode: 700 Total reward: 500.0 Batch loss: 0.045058399\n",
      "Episode: 701 Total reward: 500.0 Batch loss: 0.043749336\n",
      "Episode: 702 Total reward: 500.0 Batch loss: 0.043502927\n",
      "Episode: 703 Total reward: 500.0 Batch loss: 0.039165676\n",
      "Episode: 704 Total reward: 500.0 Batch loss: 0.045089487\n",
      "Episode: 705 Total reward: 500.0 Batch loss: 0.050695710\n",
      "Episode: 706 Total reward: 500.0 Batch loss: 0.046915479\n",
      "Episode: 707 Total reward: 500.0 Batch loss: 0.039073952\n",
      "Episode: 708 Total reward: 500.0 Batch loss: 0.038487781\n",
      "Episode: 709 Total reward: 500.0 Batch loss: 0.049076706\n",
      "Episode: 710 Total reward: 500.0 Batch loss: 0.041702773\n",
      "Episode: 711 Total reward: 500.0 Batch loss: 0.041824136\n",
      "Episode: 712 Total reward: 500.0 Batch loss: 0.042224582\n",
      "Episode: 713 Total reward: 500.0 Batch loss: 0.050901193\n",
      "Episode: 714 Total reward: 500.0 Batch loss: 0.039107133\n",
      "Episode: 715 Total reward: 500.0 Batch loss: 0.034507688\n",
      "Episode: 716 Total reward: 500.0 Batch loss: 0.045451321\n",
      "Episode: 717 Total reward: 500.0 Batch loss: 0.037395511\n",
      "Episode: 718 Total reward: 500.0 Batch loss: 0.050168525\n",
      "Episode: 719 Total reward: 500.0 Batch loss: 0.040644050\n",
      "Episode: 720 Total reward: 500.0 Batch loss: 0.043711159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 721 Total reward: 500.0 Batch loss: 0.052179247\n",
      "Episode: 722 Total reward: 500.0 Batch loss: 0.045352802\n",
      "Episode: 723 Total reward: 500.0 Batch loss: 0.045027830\n",
      "Episode: 724 Total reward: 500.0 Batch loss: 0.044184074\n",
      "Episode: 725 Total reward: 500.0 Batch loss: 0.042202882\n",
      "Episode: 726 Total reward: 500.0 Batch loss: 0.035081960\n",
      "Episode: 727 Total reward: 500.0 Batch loss: 0.042570524\n",
      "Episode: 728 Total reward: 500.0 Batch loss: 0.046213888\n",
      "Episode: 729 Total reward: 500.0 Batch loss: 0.029669868\n",
      "Episode: 730 Total reward: 500.0 Batch loss: 0.037195340\n",
      "Episode: 731 Total reward: 500.0 Batch loss: 0.045659766\n",
      "Episode: 732 Total reward: 500.0 Batch loss: 0.035983935\n",
      "Episode: 733 Total reward: 500.0 Batch loss: 0.036672924\n",
      "Episode: 734 Total reward: 500.0 Batch loss: 0.038529545\n",
      "Episode: 735 Total reward: 500.0 Batch loss: 0.039664961\n",
      "Episode: 736 Total reward: 500.0 Batch loss: 0.043966170\n",
      "Episode: 737 Total reward: 500.0 Batch loss: 0.041152477\n",
      "Episode: 738 Total reward: 500.0 Batch loss: 0.045036569\n",
      "Episode: 739 Total reward: 500.0 Batch loss: 0.046652928\n",
      "Episode: 740 Total reward: 500.0 Batch loss: 0.040894680\n",
      "Episode: 741 Total reward: 500.0 Batch loss: 0.039034393\n",
      "Episode: 742 Total reward: 500.0 Batch loss: 0.038626462\n",
      "Episode: 743 Total reward: 500.0 Batch loss: 0.042717453\n",
      "Episode: 744 Total reward: 500.0 Batch loss: 0.042874597\n",
      "Episode: 745 Total reward: 500.0 Batch loss: 0.043385409\n",
      "Episode: 746 Total reward: 500.0 Batch loss: 0.036636911\n",
      "Episode: 747 Total reward: 500.0 Batch loss: 0.044645052\n",
      "Episode: 748 Total reward: 500.0 Batch loss: 0.040307954\n",
      "Episode: 749 Total reward: 500.0 Batch loss: 0.039239760\n",
      "Episode: 750 Total reward: 500.0 Batch loss: 0.050639573\n",
      "Episode: 751 Total reward: 500.0 Batch loss: 0.045422129\n",
      "Episode: 752 Total reward: 500.0 Batch loss: 0.037508391\n",
      "Episode: 753 Total reward: 500.0 Batch loss: 0.047039185\n",
      "Episode: 754 Total reward: 500.0 Batch loss: 0.042856645\n",
      "Episode: 755 Total reward: 500.0 Batch loss: 0.043934364\n",
      "Episode: 756 Total reward: 500.0 Batch loss: 0.043519761\n",
      "Episode: 757 Total reward: 500.0 Batch loss: 0.042328652\n",
      "Episode: 758 Total reward: 500.0 Batch loss: 0.042675130\n",
      "Episode: 759 Total reward: 500.0 Batch loss: 0.037185539\n",
      "Episode: 760 Total reward: 500.0 Batch loss: 0.046198003\n",
      "Episode: 761 Total reward: 500.0 Batch loss: 0.038234714\n",
      "Episode: 762 Total reward: 500.0 Batch loss: 0.045118984\n",
      "Episode: 763 Total reward: 500.0 Batch loss: 0.044063974\n",
      "Episode: 764 Total reward: 500.0 Batch loss: 0.044206139\n",
      "Episode: 765 Total reward: 500.0 Batch loss: 0.045632958\n",
      "Episode: 766 Total reward: 500.0 Batch loss: 0.043498337\n",
      "Episode: 767 Total reward: 500.0 Batch loss: 0.043396432\n",
      "Episode: 768 Total reward: 500.0 Batch loss: 0.031917389\n",
      "Episode: 769 Total reward: 500.0 Batch loss: 0.049222387\n",
      "Episode: 770 Total reward: 500.0 Batch loss: 0.038961958\n",
      "Episode: 771 Total reward: 500.0 Batch loss: 0.048315968\n",
      "Episode: 772 Total reward: 500.0 Batch loss: 0.034206975\n",
      "Episode: 773 Total reward: 500.0 Batch loss: 0.042243976\n",
      "Episode: 774 Total reward: 500.0 Batch loss: 0.037607141\n",
      "Episode: 775 Total reward: 500.0 Batch loss: 0.030716088\n",
      "Episode: 776 Total reward: 500.0 Batch loss: 0.036418520\n",
      "Episode: 777 Total reward: 500.0 Batch loss: 0.048979152\n",
      "Episode: 778 Total reward: 500.0 Batch loss: 0.031239005\n",
      "Episode: 779 Total reward: 500.0 Batch loss: 0.040732659\n",
      "Episode: 780 Total reward: 500.0 Batch loss: 0.044527549\n",
      "Episode: 781 Total reward: 500.0 Batch loss: 0.036556661\n",
      "Episode: 782 Total reward: 500.0 Batch loss: 0.038824979\n",
      "Episode: 783 Total reward: 500.0 Batch loss: 0.037748277\n",
      "Episode: 784 Total reward: 500.0 Batch loss: 0.041678399\n",
      "Episode: 785 Total reward: 500.0 Batch loss: 0.029609142\n",
      "Episode: 786 Total reward: 500.0 Batch loss: 0.039130390\n",
      "Episode: 787 Total reward: 500.0 Batch loss: 0.036234446\n",
      "Episode: 788 Total reward: 500.0 Batch loss: 0.033045951\n",
      "Episode: 789 Total reward: 500.0 Batch loss: 0.039780360\n",
      "Episode: 790 Total reward: 500.0 Batch loss: 0.047537424\n",
      "Episode: 791 Total reward: 500.0 Batch loss: 0.043494705\n",
      "Episode: 792 Total reward: 500.0 Batch loss: 0.043111518\n",
      "Episode: 793 Total reward: 500.0 Batch loss: 0.038169362\n",
      "Episode: 794 Total reward: 500.0 Batch loss: 0.045122698\n",
      "Episode: 795 Total reward: 500.0 Batch loss: 0.038994849\n",
      "Episode: 796 Total reward: 500.0 Batch loss: 0.043262497\n",
      "Episode: 797 Total reward: 500.0 Batch loss: 0.042567477\n",
      "Episode: 798 Total reward: 500.0 Batch loss: 0.038331278\n",
      "Episode: 799 Total reward: 500.0 Batch loss: 0.039407566\n",
      "Episode: 800 Total reward: 500.0 Batch loss: 0.040042024\n",
      "Episode: 801 Total reward: 500.0 Batch loss: 0.043152325\n",
      "Episode: 802 Total reward: 500.0 Batch loss: 0.036520753\n",
      "Episode: 803 Total reward: 500.0 Batch loss: 0.039230980\n",
      "Episode: 804 Total reward: 500.0 Batch loss: 0.036798801\n",
      "Episode: 805 Total reward: 500.0 Batch loss: 0.037167642\n",
      "Episode: 806 Total reward: 500.0 Batch loss: 0.041510951\n",
      "Episode: 807 Total reward: 500.0 Batch loss: 0.034189936\n",
      "Episode: 808 Total reward: 500.0 Batch loss: 0.040112741\n",
      "Episode: 809 Total reward: 500.0 Batch loss: 0.033969160\n",
      "Episode: 810 Total reward: 500.0 Batch loss: 0.039226908\n",
      "Episode: 811 Total reward: 500.0 Batch loss: 0.037834607\n",
      "Episode: 812 Total reward: 500.0 Batch loss: 0.042554244\n",
      "Episode: 813 Total reward: 500.0 Batch loss: 0.028417611\n",
      "Episode: 814 Total reward: 500.0 Batch loss: 0.038200997\n",
      "Episode: 815 Total reward: 500.0 Batch loss: 0.042773888\n",
      "Episode: 816 Total reward: 500.0 Batch loss: 0.033824779\n",
      "Episode: 817 Total reward: 500.0 Batch loss: 0.035768714\n",
      "Episode: 818 Total reward: 500.0 Batch loss: 0.039662901\n",
      "Episode: 819 Total reward: 500.0 Batch loss: 0.036546096\n",
      "Episode: 820 Total reward: 500.0 Batch loss: 0.045812730\n",
      "Episode: 821 Total reward: 500.0 Batch loss: 0.042913914\n",
      "Episode: 822 Total reward: 500.0 Batch loss: 0.035450637\n",
      "Episode: 823 Total reward: 500.0 Batch loss: 0.033128992\n",
      "Episode: 824 Total reward: 500.0 Batch loss: 0.039766692\n",
      "Episode: 825 Total reward: 500.0 Batch loss: 0.040855028\n",
      "Episode: 826 Total reward: 500.0 Batch loss: 0.034826815\n",
      "Episode: 827 Total reward: 500.0 Batch loss: 0.039171956\n",
      "Episode: 828 Total reward: 500.0 Batch loss: 0.045312036\n",
      "Episode: 829 Total reward: 500.0 Batch loss: 0.036228083\n",
      "Episode: 830 Total reward: 500.0 Batch loss: 0.045843545\n",
      "Episode: 831 Total reward: 500.0 Batch loss: 0.036293667\n",
      "Episode: 832 Total reward: 500.0 Batch loss: 0.037254862\n",
      "Episode: 833 Total reward: 500.0 Batch loss: 0.052406643\n",
      "Episode: 834 Total reward: 500.0 Batch loss: 0.035720356\n",
      "Episode: 835 Total reward: 500.0 Batch loss: 0.037014421\n",
      "Episode: 836 Total reward: 500.0 Batch loss: 0.034535311\n",
      "Episode: 837 Total reward: 500.0 Batch loss: 0.041792363\n",
      "Episode: 838 Total reward: 500.0 Batch loss: 0.038280439\n",
      "Episode: 839 Total reward: 500.0 Batch loss: 0.034663584\n",
      "Episode: 840 Total reward: 500.0 Batch loss: 0.042328648\n",
      "Episode: 841 Total reward: 500.0 Batch loss: 0.044125669\n",
      "Episode: 842 Total reward: 500.0 Batch loss: 0.035380844\n",
      "Episode: 843 Total reward: 500.0 Batch loss: 0.042839374\n",
      "Episode: 844 Total reward: 500.0 Batch loss: 0.040147830\n",
      "Episode: 845 Total reward: 500.0 Batch loss: 0.033598904\n",
      "Episode: 846 Total reward: 500.0 Batch loss: 0.037814032\n",
      "Episode: 847 Total reward: 500.0 Batch loss: 0.033457324\n",
      "Episode: 848 Total reward: 500.0 Batch loss: 0.037851341\n",
      "Episode: 849 Total reward: 500.0 Batch loss: 0.033346511\n",
      "Episode: 850 Total reward: 500.0 Batch loss: 0.040382519\n",
      "Episode: 851 Total reward: 500.0 Batch loss: 0.035131108\n",
      "Episode: 852 Total reward: 500.0 Batch loss: 0.038132451\n",
      "Episode: 853 Total reward: 500.0 Batch loss: 0.046555191\n",
      "Episode: 854 Total reward: 500.0 Batch loss: 0.052554652\n",
      "Episode: 855 Total reward: 500.0 Batch loss: 0.036975663\n",
      "Episode: 856 Total reward: 500.0 Batch loss: 0.037673488\n",
      "Episode: 857 Total reward: 500.0 Batch loss: 0.037261084\n",
      "Episode: 858 Total reward: 500.0 Batch loss: 0.039039787\n",
      "Episode: 859 Total reward: 500.0 Batch loss: 0.035566453\n",
      "Episode: 860 Total reward: 500.0 Batch loss: 0.033531081\n",
      "Episode: 861 Total reward: 500.0 Batch loss: 0.037681624\n",
      "Episode: 862 Total reward: 500.0 Batch loss: 0.040593408\n",
      "Episode: 863 Total reward: 500.0 Batch loss: 0.039680764\n",
      "Episode: 864 Total reward: 500.0 Batch loss: 0.040537804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 865 Total reward: 500.0 Batch loss: 0.037563309\n",
      "Episode: 866 Total reward: 500.0 Batch loss: 0.032531947\n",
      "Episode: 867 Total reward: 500.0 Batch loss: 0.038493980\n",
      "Episode: 868 Total reward: 500.0 Batch loss: 0.038072374\n",
      "Episode: 869 Total reward: 500.0 Batch loss: 0.039620548\n",
      "Episode: 870 Total reward: 500.0 Batch loss: 0.038655292\n",
      "Episode: 871 Total reward: 500.0 Batch loss: 0.046135768\n",
      "Episode: 872 Total reward: 500.0 Batch loss: 0.041858044\n",
      "Episode: 873 Total reward: 500.0 Batch loss: 0.035481542\n",
      "Episode: 874 Total reward: 500.0 Batch loss: 0.038225267\n",
      "Episode: 875 Total reward: 500.0 Batch loss: 0.038152277\n",
      "Episode: 876 Total reward: 500.0 Batch loss: 0.035640310\n",
      "Episode: 877 Total reward: 500.0 Batch loss: 0.041512370\n",
      "Episode: 878 Total reward: 500.0 Batch loss: 0.036924191\n",
      "Episode: 879 Total reward: 500.0 Batch loss: 0.036047112\n",
      "Episode: 880 Total reward: 500.0 Batch loss: 0.044330116\n",
      "Episode: 881 Total reward: 500.0 Batch loss: 0.036589172\n",
      "Episode: 882 Total reward: 500.0 Batch loss: 0.034368742\n",
      "Episode: 883 Total reward: 500.0 Batch loss: 0.035224717\n",
      "Episode: 884 Total reward: 500.0 Batch loss: 0.035094630\n",
      "Episode: 885 Total reward: 500.0 Batch loss: 0.035605941\n",
      "Episode: 886 Total reward: 500.0 Batch loss: 0.043362778\n",
      "Episode: 887 Total reward: 500.0 Batch loss: 0.029861007\n",
      "Episode: 888 Total reward: 500.0 Batch loss: 0.037976597\n",
      "Episode: 889 Total reward: 500.0 Batch loss: 0.034208890\n",
      "Episode: 890 Total reward: 500.0 Batch loss: 0.044783562\n",
      "Episode: 891 Total reward: 500.0 Batch loss: 0.036459781\n",
      "Episode: 892 Total reward: 500.0 Batch loss: 0.038928799\n",
      "Episode: 893 Total reward: 500.0 Batch loss: 0.042377748\n",
      "Episode: 894 Total reward: 500.0 Batch loss: 0.035418220\n",
      "Episode: 895 Total reward: 500.0 Batch loss: 0.032994565\n",
      "Episode: 896 Total reward: 500.0 Batch loss: 0.033520263\n",
      "Episode: 897 Total reward: 500.0 Batch loss: 0.033187646\n",
      "Episode: 898 Total reward: 500.0 Batch loss: 0.036967341\n",
      "Episode: 899 Total reward: 500.0 Batch loss: 0.034336325\n",
      "Episode: 900 Total reward: 500.0 Batch loss: 0.034378245\n",
      "Episode: 901 Total reward: 500.0 Batch loss: 0.036908679\n",
      "Episode: 902 Total reward: 500.0 Batch loss: 0.040421251\n",
      "Episode: 903 Total reward: 500.0 Batch loss: 0.032305200\n",
      "Episode: 904 Total reward: 500.0 Batch loss: 0.037901696\n",
      "Episode: 905 Total reward: 500.0 Batch loss: 0.034172371\n",
      "Episode: 906 Total reward: 500.0 Batch loss: 0.031792726\n",
      "Episode: 907 Total reward: 500.0 Batch loss: 0.036730252\n",
      "Episode: 908 Total reward: 500.0 Batch loss: 0.028797016\n",
      "Episode: 909 Total reward: 500.0 Batch loss: 0.034156881\n",
      "Episode: 910 Total reward: 500.0 Batch loss: 0.031426121\n",
      "Episode: 911 Total reward: 500.0 Batch loss: 0.029848658\n",
      "Episode: 912 Total reward: 500.0 Batch loss: 0.035185095\n",
      "Episode: 913 Total reward: 500.0 Batch loss: 0.036501814\n",
      "Episode: 914 Total reward: 500.0 Batch loss: 0.031811051\n",
      "Episode: 915 Total reward: 500.0 Batch loss: 0.036558177\n",
      "Episode: 916 Total reward: 500.0 Batch loss: 0.035364926\n",
      "Episode: 917 Total reward: 500.0 Batch loss: 0.039638937\n",
      "Episode: 918 Total reward: 500.0 Batch loss: 0.034512050\n",
      "Episode: 919 Total reward: 500.0 Batch loss: 0.033090759\n",
      "Episode: 920 Total reward: 500.0 Batch loss: 0.034278117\n",
      "Episode: 921 Total reward: 500.0 Batch loss: 0.026354408\n",
      "Episode: 922 Total reward: 500.0 Batch loss: 0.026755791\n",
      "Episode: 923 Total reward: 500.0 Batch loss: 0.029894015\n",
      "Episode: 924 Total reward: 500.0 Batch loss: 0.033033747\n",
      "Episode: 925 Total reward: 500.0 Batch loss: 0.040829364\n",
      "Episode: 926 Total reward: 500.0 Batch loss: 0.033025406\n",
      "Episode: 927 Total reward: 500.0 Batch loss: 0.038185496\n",
      "Episode: 928 Total reward: 500.0 Batch loss: 0.039215118\n",
      "Episode: 929 Total reward: 500.0 Batch loss: 0.036130086\n",
      "Episode: 930 Total reward: 500.0 Batch loss: 0.034922190\n",
      "Episode: 931 Total reward: 500.0 Batch loss: 0.042386260\n",
      "Episode: 932 Total reward: 500.0 Batch loss: 0.035676498\n",
      "Episode: 933 Total reward: 500.0 Batch loss: 0.043313552\n",
      "Episode: 934 Total reward: 500.0 Batch loss: 0.036585759\n",
      "Episode: 935 Total reward: 500.0 Batch loss: 0.039593678\n",
      "Episode: 936 Total reward: 500.0 Batch loss: 0.032954108\n",
      "Episode: 937 Total reward: 500.0 Batch loss: 0.040774509\n",
      "Episode: 938 Total reward: 500.0 Batch loss: 0.032390267\n",
      "Episode: 939 Total reward: 500.0 Batch loss: 0.034429666\n",
      "Episode: 940 Total reward: 500.0 Batch loss: 0.030439885\n",
      "Episode: 941 Total reward: 500.0 Batch loss: 0.034791052\n",
      "Episode: 942 Total reward: 500.0 Batch loss: 0.031342283\n",
      "Episode: 943 Total reward: 500.0 Batch loss: 0.037653558\n",
      "Episode: 944 Total reward: 500.0 Batch loss: 0.029002398\n",
      "Episode: 945 Total reward: 500.0 Batch loss: 0.032984633\n",
      "Episode: 946 Total reward: 500.0 Batch loss: 0.026484318\n",
      "Episode: 947 Total reward: 500.0 Batch loss: 0.026838101\n",
      "Episode: 948 Total reward: 500.0 Batch loss: 0.036475118\n",
      "Episode: 949 Total reward: 500.0 Batch loss: 0.031441595\n",
      "Episode: 950 Total reward: 500.0 Batch loss: 0.032931820\n",
      "Episode: 951 Total reward: 500.0 Batch loss: 0.036541112\n",
      "Episode: 952 Total reward: 500.0 Batch loss: 0.036286745\n",
      "Episode: 953 Total reward: 500.0 Batch loss: 0.030191630\n",
      "Episode: 954 Total reward: 500.0 Batch loss: 0.036250308\n",
      "Episode: 955 Total reward: 500.0 Batch loss: 0.034205239\n",
      "Episode: 956 Total reward: 500.0 Batch loss: 0.039686937\n",
      "Episode: 957 Total reward: 500.0 Batch loss: 0.034825318\n",
      "Episode: 958 Total reward: 500.0 Batch loss: 0.043517962\n",
      "Episode: 959 Total reward: 500.0 Batch loss: 0.033342596\n",
      "Episode: 960 Total reward: 500.0 Batch loss: 0.031724401\n",
      "Episode: 961 Total reward: 500.0 Batch loss: 0.039318059\n",
      "Episode: 962 Total reward: 500.0 Batch loss: 0.037163273\n",
      "Episode: 963 Total reward: 500.0 Batch loss: 0.033498723\n",
      "Episode: 964 Total reward: 500.0 Batch loss: 0.036544103\n",
      "Episode: 965 Total reward: 500.0 Batch loss: 0.037277181\n",
      "Episode: 966 Total reward: 500.0 Batch loss: 0.033415753\n",
      "Episode: 967 Total reward: 500.0 Batch loss: 0.040980741\n",
      "Episode: 968 Total reward: 500.0 Batch loss: 0.032796849\n",
      "Episode: 969 Total reward: 500.0 Batch loss: 0.038936161\n",
      "Episode: 970 Total reward: 500.0 Batch loss: 0.037473608\n",
      "Episode: 971 Total reward: 500.0 Batch loss: 0.030229200\n",
      "Episode: 972 Total reward: 500.0 Batch loss: 0.030493323\n",
      "Episode: 973 Total reward: 500.0 Batch loss: 0.033100594\n",
      "Episode: 974 Total reward: 500.0 Batch loss: 0.037865154\n",
      "Episode: 975 Total reward: 500.0 Batch loss: 0.042406697\n",
      "Episode: 976 Total reward: 500.0 Batch loss: 0.044686928\n",
      "Episode: 977 Total reward: 500.0 Batch loss: 0.037620068\n",
      "Episode: 978 Total reward: 500.0 Batch loss: 0.032787859\n",
      "Episode: 979 Total reward: 500.0 Batch loss: 0.034768481\n",
      "Episode: 980 Total reward: 500.0 Batch loss: 0.034905538\n",
      "Episode: 981 Total reward: 500.0 Batch loss: 0.035276793\n",
      "Episode: 982 Total reward: 500.0 Batch loss: 0.027435752\n",
      "Episode: 983 Total reward: 500.0 Batch loss: 0.035278101\n",
      "Episode: 984 Total reward: 500.0 Batch loss: 0.038357232\n",
      "Episode: 985 Total reward: 500.0 Batch loss: 0.033995200\n",
      "Episode: 986 Total reward: 500.0 Batch loss: 0.034251232\n",
      "Episode: 987 Total reward: 500.0 Batch loss: 0.028177697\n",
      "Episode: 988 Total reward: 500.0 Batch loss: 0.034308381\n",
      "Episode: 989 Total reward: 500.0 Batch loss: 0.027242664\n",
      "Episode: 990 Total reward: 500.0 Batch loss: 0.028420242\n",
      "Episode: 991 Total reward: 500.0 Batch loss: 0.028532231\n",
      "Episode: 992 Total reward: 500.0 Batch loss: 0.031436346\n",
      "Episode: 993 Total reward: 500.0 Batch loss: 0.032121751\n",
      "Episode: 994 Total reward: 500.0 Batch loss: 0.033033315\n",
      "Episode: 995 Total reward: 500.0 Batch loss: 0.034730230\n",
      "Episode: 996 Total reward: 500.0 Batch loss: 0.032236125\n",
      "Episode: 997 Total reward: 500.0 Batch loss: 0.035844155\n",
      "Episode: 998 Total reward: 500.0 Batch loss: 0.028555667\n",
      "Episode: 999 Total reward: 500.0 Batch loss: 0.033249546\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "rewards_list, loss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, 'checkpoints/model-pg.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(train_episodes):\n",
    "        state = env.reset() # env first state\n",
    "        batch = [] # every data batch\n",
    "        total_reward = 0\n",
    "\n",
    "        # Training steps/batches\n",
    "        for _ in range(max_steps): # start=0, step=1, stop=max_steps/done/reward\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            #action *= 1 - float(done) # last action is always 0\n",
    "            batch.append([state, action])\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        #batch = memory.buffer\n",
    "        states = np.array([each[0] for each in batch])\n",
    "        actions = np.array([each[1] for each in batch])\n",
    "        loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                                 model.actions: actions})\n",
    "        print('Episode: {}'.format(ep),\n",
    "              'Total reward: {}'.format(total_reward),\n",
    "              'Batch loss: {:.9f}'.format(loss))\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, loss])\n",
    "        \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model-pg2.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Batch losses')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Batch losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/model-pg2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 500.00\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-pg.ckpt')    \n",
    "    saver.restore(sess, 'checkpoints/model-pg2.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(1):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        for _ in range(111111111111111111):\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        # Closing the env\n",
    "        print('total_reward: {:.2f}'.format(total_reward))\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

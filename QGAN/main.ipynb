{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# QGAN: (Q-Net) + GAN (G-Net and D-Net)\n",
    "\n",
    "More specifically, we'll use Q-GAN to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command 'pip install -e gym/[all]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "rewards, states, actions, dones = [], [], [], []\n",
    "for _ in range(10):\n",
    "    #env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    states.append(state)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    dones.append(done)\n",
    "    #     print('state, action, reward, done, info')\n",
    "    #     print(state, action, reward, done, info)\n",
    "    if done:\n",
    "    #         print('state, action, reward, done, info')\n",
    "    #         print(state, action, reward, done, info)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        dones.append(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(10,) (10, 4) (10,) (10,)\n",
      "float64 float64 int64 bool\n",
      "actions: 1 0\n",
      "rewards min and max: 1.0 1.0\n",
      "state size: (10, 4) action size: 2\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print('actions:', np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print('rewards min and max:', np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print('state size:', np.array(states).shape, \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    # Current states given\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    \n",
    "    # Next states given\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    \n",
    "    # Current actions given\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # TargetQs/values\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    \n",
    "    # returning the given data to the model\n",
    "    return states, next_states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Qfunction/Encoder/Classifier\n",
    "def qfunction(states, action_size, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('qfunction', reuse=reuse):        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: Generator/Decoder: actions can be given actions, generated actions\n",
    "def generator(actions, state_size, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=actions, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=state_size)        \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return next_states_logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D: Descriminator/Reward function\n",
    "def discriminator(states, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)   \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return reward logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, action_size, hidden_size, actions, targetQs, state_size, next_states):\n",
    "    # DQN: Q-learning - Bellman equations: loss (targetQ - Q)^2\n",
    "    actions_logits = qfunction(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_real = tf.one_hot(indices=actions, depth=action_size)\n",
    "    Qs = tf.reduce_sum(tf.multiply(actions_logits, actions_real), axis=1)\n",
    "    q_loss = tf.reduce_mean(tf.square(targetQs - Qs))\n",
    "\n",
    "    # GAN: Generate next states\n",
    "    actions_fake = tf.nn.softmax(actions_logits)\n",
    "    next_states_logits = generator(actions=actions_fake, state_size=state_size, hidden_size=hidden_size)\n",
    "    \n",
    "    # GAN: Discriminate between fake and real\n",
    "    next_states_fake = tf.sigmoid(x=next_states_logits)\n",
    "    d_logits_fake = discriminator(states=next_states_fake, hidden_size=hidden_size, reuse=False)\n",
    "    next_states_real = tf.sigmoid(x=next_states) \n",
    "    d_logits_real = discriminator(states=next_states_real, hidden_size=hidden_size, reuse=True)\n",
    "\n",
    "    # GAN: Adverserial training - G-learning\n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "    \n",
    "    # GAN: Adverserial training - D-learning\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # Rewards fake/real\n",
    "    rewards_fake = tf.sigmoid(d_logits_fake)\n",
    "    rewards_real = tf.sigmoid(d_logits_real)\n",
    "\n",
    "    return actions_logits, q_loss, g_loss, d_loss, rewards_fake, rewards_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(q_loss, g_loss, d_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param q_loss: Qfunction/Value loss Tensor for next action prediction\n",
    "    :param g_loss: Generator/Decoder loss Tensor for next state prediction\n",
    "    :param d_loss: Discriminator/Reward loss Tensor for current reward function\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    q_vars = [var for var in t_vars if var.name.startswith('qfunction')] # Q: action At/at\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')] # G: next state St/st\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        q_opt = tf.train.AdamOptimizer(learning_rate).minimize(q_loss, var_list=q_vars)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return q_opt, g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGAN:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.next_states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.q_loss, self.g_loss, self.d_loss, self.rewards_fake, self.rewards_real = model_loss(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, next_states=self.next_states, actions=self.actions, targetQs=self.targetQs) # model input data\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.q_opt, self.g_opt, self.d_opt = model_opt(q_loss=self.q_loss, g_loss=self.g_loss, d_loss=self.d_loss, \n",
    "                                                       learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size: 4 action size: 2\n"
     ]
    }
   ],
   "source": [
    "print('state size:', np.array(states).shape[1], \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 500           # max number of episodes to learn from\n",
    "max_steps = 2000000000000000   # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000           # memory capacity\n",
    "batch_size = 200               # experience mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = QGAN(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 0 Total reward: 15.0 Average reward fake: 0.4461037516593933 Average reward real: 0.5270993709564209 Training q_loss: 267211.1250 Training g_loss: 0.7946 Training d_loss: 1.3752 Explore P: 0.9985\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 1 Total reward: 55.0 Average reward fake: 0.4937914311885834 Average reward real: 0.5037266612052917 Training q_loss: 60448.6562 Training g_loss: 0.7056 Training d_loss: 1.4800 Explore P: 0.9931\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 2 Total reward: 16.0 Average reward fake: 0.48187094926834106 Average reward real: 0.4758217930793762 Training q_loss: 52531.1484 Training g_loss: 0.6798 Training d_loss: 1.6547 Explore P: 0.9915\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 3 Total reward: 12.0 Average reward fake: 0.45567816495895386 Average reward real: 0.4987315833568573 Training q_loss: 243278.2969 Training g_loss: 0.7874 Training d_loss: 1.4474 Explore P: 0.9903\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 4 Total reward: 14.0 Average reward fake: 0.510090708732605 Average reward real: 0.5658120512962341 Training q_loss: 229673.0469 Training g_loss: 0.6953 Training d_loss: 1.4779 Explore P: 0.9890\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 5 Total reward: 33.0 Average reward fake: 0.50860196352005 Average reward real: 0.5494245290756226 Training q_loss: 235429.7031 Training g_loss: 0.7308 Training d_loss: 1.4197 Explore P: 0.9857\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 6 Total reward: 10.0 Average reward fake: 0.4410932660102844 Average reward real: 0.5215187668800354 Training q_loss: 77334.3828 Training g_loss: 0.8403 Training d_loss: 1.3601 Explore P: 0.9848\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 7 Total reward: 40.0 Average reward fake: 0.40172889828681946 Average reward real: 0.6025314927101135 Training q_loss: 38987.7148 Training g_loss: 0.9182 Training d_loss: 1.0807 Explore P: 0.9809\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 8 Total reward: 12.0 Average reward fake: 0.44978201389312744 Average reward real: 0.5496919751167297 Training q_loss: 37166.8164 Training g_loss: 0.8001 Training d_loss: 1.2809 Explore P: 0.9797\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 9 Total reward: 12.0 Average reward fake: 0.5001858472824097 Average reward real: 0.5445586442947388 Training q_loss: 113944.9062 Training g_loss: 0.6735 Training d_loss: 1.4255 Explore P: 0.9786\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 10 Total reward: 33.0 Average reward fake: 0.5128776431083679 Average reward real: 0.47141197323799133 Training q_loss: 65302.1406 Training g_loss: 0.6727 Training d_loss: 1.5402 Explore P: 0.9754\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 11 Total reward: 35.0 Average reward fake: 0.4092947244644165 Average reward real: 0.5893232822418213 Training q_loss: 48172.5898 Training g_loss: 0.9123 Training d_loss: 1.5103 Explore P: 0.9720\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 12 Total reward: 29.0 Average reward fake: 0.4591294825077057 Average reward real: 0.4118804633617401 Training q_loss: 57999.1055 Training g_loss: 0.7751 Training d_loss: 1.5630 Explore P: 0.9692\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 13 Total reward: 11.0 Average reward fake: 0.5334423780441284 Average reward real: 0.5236367583274841 Training q_loss: 33679.8438 Training g_loss: 0.6280 Training d_loss: 1.4383 Explore P: 0.9682\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 14 Total reward: 23.0 Average reward fake: 0.39280959963798523 Average reward real: 0.5400118827819824 Training q_loss: 51360.8906 Training g_loss: 0.9372 Training d_loss: 1.1956 Explore P: 0.9659\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 15 Total reward: 15.0 Average reward fake: 0.5051159262657166 Average reward real: 0.49222487211227417 Training q_loss: 336024.1875 Training g_loss: 0.6834 Training d_loss: 1.4633 Explore P: 0.9645\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 16 Total reward: 25.0 Average reward fake: 0.5424869060516357 Average reward real: 0.4697054624557495 Training q_loss: 39211.3164 Training g_loss: 0.6729 Training d_loss: 2.0903 Explore P: 0.9621\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 17 Total reward: 11.0 Average reward fake: 0.531980574131012 Average reward real: 0.39517104625701904 Training q_loss: 40520.2891 Training g_loss: 0.6351 Training d_loss: 1.7833 Explore P: 0.9611\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 18 Total reward: 30.0 Average reward fake: 0.6399384140968323 Average reward real: 0.4646105170249939 Training q_loss: 57676.0234 Training g_loss: 0.4836 Training d_loss: 1.8714 Explore P: 0.9582\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 19 Total reward: 21.0 Average reward fake: 0.476582795381546 Average reward real: 0.5420747399330139 Training q_loss: 202157.9375 Training g_loss: 0.7418 Training d_loss: 1.2801 Explore P: 0.9562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 20 Total reward: 28.0 Average reward fake: 0.4158863425254822 Average reward real: 0.5917727947235107 Training q_loss: 29560.2051 Training g_loss: 0.8771 Training d_loss: 1.0936 Explore P: 0.9536\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 21 Total reward: 18.0 Average reward fake: 0.4004595875740051 Average reward real: 0.6288700699806213 Training q_loss: 181419.2969 Training g_loss: 0.9127 Training d_loss: 1.0185 Explore P: 0.9519\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 22 Total reward: 35.0 Average reward fake: 0.4008079469203949 Average reward real: 0.5653717517852783 Training q_loss: 35137.7422 Training g_loss: 0.9199 Training d_loss: 1.1390 Explore P: 0.9486\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 23 Total reward: 14.0 Average reward fake: 0.44245827198028564 Average reward real: 0.536939799785614 Training q_loss: 31624.7754 Training g_loss: 0.8164 Training d_loss: 1.2776 Explore P: 0.9473\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 24 Total reward: 23.0 Average reward fake: 0.480072021484375 Average reward real: 0.4678882658481598 Training q_loss: 102197.1406 Training g_loss: 0.7483 Training d_loss: 1.5195 Explore P: 0.9451\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 25 Total reward: 9.0 Average reward fake: 0.5092902183532715 Average reward real: 0.4526597261428833 Training q_loss: 114560.0391 Training g_loss: 0.7006 Training d_loss: 1.7495 Explore P: 0.9443\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 26 Total reward: 23.0 Average reward fake: 0.4609967768192291 Average reward real: 0.5109424591064453 Training q_loss: 95040.1484 Training g_loss: 0.7977 Training d_loss: 1.4791 Explore P: 0.9422\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 27 Total reward: 19.0 Average reward fake: 0.4838918447494507 Average reward real: 0.46749192476272583 Training q_loss: 114569.0000 Training g_loss: 0.7438 Training d_loss: 2.0045 Explore P: 0.9404\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 28 Total reward: 33.0 Average reward fake: 0.3971177041530609 Average reward real: 0.6468309164047241 Training q_loss: 200117.1875 Training g_loss: 1.0745 Training d_loss: 1.1647 Explore P: 0.9373\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 29 Total reward: 52.0 Average reward fake: 0.5163137316703796 Average reward real: 0.5207051038742065 Training q_loss: 77194.4219 Training g_loss: 0.6637 Training d_loss: 1.5477 Explore P: 0.9325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 30 Total reward: 18.0 Average reward fake: 0.5066909790039062 Average reward real: 0.48837020993232727 Training q_loss: 46345.7969 Training g_loss: 0.7821 Training d_loss: 1.7354 Explore P: 0.9309\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 31 Total reward: 17.0 Average reward fake: 0.4520939588546753 Average reward real: 0.5481320023536682 Training q_loss: 125212.7734 Training g_loss: 0.8123 Training d_loss: 1.3093 Explore P: 0.9293\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 32 Total reward: 19.0 Average reward fake: 0.41680285334587097 Average reward real: 0.5980923175811768 Training q_loss: 45364.2656 Training g_loss: 0.8830 Training d_loss: 1.1572 Explore P: 0.9275\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 33 Total reward: 16.0 Average reward fake: 0.45660218596458435 Average reward real: 0.563107967376709 Training q_loss: 34114.0156 Training g_loss: 0.8033 Training d_loss: 1.3491 Explore P: 0.9261\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 34 Total reward: 10.0 Average reward fake: 0.47151148319244385 Average reward real: 0.48020949959754944 Training q_loss: 67332.8516 Training g_loss: 0.7507 Training d_loss: 1.4894 Explore P: 0.9252\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 35 Total reward: 30.0 Average reward fake: 0.5270726680755615 Average reward real: 0.5486170053482056 Training q_loss: 116956.4375 Training g_loss: 0.5892 Training d_loss: 1.6948 Explore P: 0.9224\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 36 Total reward: 14.0 Average reward fake: 0.3413022756576538 Average reward real: 0.6129319667816162 Training q_loss: 135813.5625 Training g_loss: 1.1064 Training d_loss: 1.0609 Explore P: 0.9211\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 37 Total reward: 43.0 Average reward fake: 0.5163309574127197 Average reward real: 0.44405776262283325 Training q_loss: 208654.5469 Training g_loss: 0.6590 Training d_loss: 1.6289 Explore P: 0.9172\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 38 Total reward: 36.0 Average reward fake: 0.43711626529693604 Average reward real: 0.579335629940033 Training q_loss: 378725.0938 Training g_loss: 0.8386 Training d_loss: 1.2494 Explore P: 0.9140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 39 Total reward: 16.0 Average reward fake: 0.5119588375091553 Average reward real: 0.5102090239524841 Training q_loss: 47811.2344 Training g_loss: 0.6786 Training d_loss: 1.4652 Explore P: 0.9125\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 40 Total reward: 19.0 Average reward fake: 0.5346969962120056 Average reward real: 0.4671972692012787 Training q_loss: 40503.0742 Training g_loss: 0.6230 Training d_loss: 1.6172 Explore P: 0.9108\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 41 Total reward: 19.0 Average reward fake: 0.4867039620876312 Average reward real: 0.47240960597991943 Training q_loss: 40880.4453 Training g_loss: 0.7157 Training d_loss: 1.4832 Explore P: 0.9091\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 42 Total reward: 20.0 Average reward fake: 0.4471474587917328 Average reward real: 0.5083402991294861 Training q_loss: 67308.5312 Training g_loss: 0.7801 Training d_loss: 1.3472 Explore P: 0.9073\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 43 Total reward: 10.0 Average reward fake: 0.4557131826877594 Average reward real: 0.4661431908607483 Training q_loss: 35662.8906 Training g_loss: 0.7904 Training d_loss: 1.4102 Explore P: 0.9064\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 44 Total reward: 52.0 Average reward fake: 0.5022056102752686 Average reward real: 0.47788330912590027 Training q_loss: 76141.4922 Training g_loss: 0.6899 Training d_loss: 1.4689 Explore P: 0.9018\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 45 Total reward: 15.0 Average reward fake: 0.42112404108047485 Average reward real: 0.5591939687728882 Training q_loss: 119752.3203 Training g_loss: 0.8650 Training d_loss: 1.1562 Explore P: 0.9004\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 46 Total reward: 27.0 Average reward fake: 0.441208153963089 Average reward real: 0.5532833337783813 Training q_loss: 50589.6289 Training g_loss: 0.8268 Training d_loss: 1.2085 Explore P: 0.8980\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 47 Total reward: 14.0 Average reward fake: 0.3824586868286133 Average reward real: 0.5762400031089783 Training q_loss: 54409.3906 Training g_loss: 0.9555 Training d_loss: 1.1573 Explore P: 0.8968\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 48 Total reward: 24.0 Average reward fake: 0.35667237639427185 Average reward real: 0.584847629070282 Training q_loss: 76704.7031 Training g_loss: 1.0311 Training d_loss: 1.0287 Explore P: 0.8947\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 49 Total reward: 22.0 Average reward fake: 0.3723091781139374 Average reward real: 0.6035258173942566 Training q_loss: 66302.5547 Training g_loss: 0.9971 Training d_loss: 1.0315 Explore P: 0.8927\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 50 Total reward: 47.0 Average reward fake: 0.46118026971817017 Average reward real: 0.5397297143936157 Training q_loss: 66366.8281 Training g_loss: 0.7866 Training d_loss: 1.3363 Explore P: 0.8886\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 51 Total reward: 11.0 Average reward fake: 0.3652760982513428 Average reward real: 0.5854994058609009 Training q_loss: 39257.2344 Training g_loss: 1.0330 Training d_loss: 1.0661 Explore P: 0.8876\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 52 Total reward: 21.0 Average reward fake: 0.47048419713974 Average reward real: 0.581978976726532 Training q_loss: 232510.7656 Training g_loss: 0.7917 Training d_loss: 1.3105 Explore P: 0.8858\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 53 Total reward: 40.0 Average reward fake: 0.3928075432777405 Average reward real: 0.5872213244438171 Training q_loss: 100828.2266 Training g_loss: 0.9494 Training d_loss: 1.0863 Explore P: 0.8823\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 54 Total reward: 15.0 Average reward fake: 0.40534549951553345 Average reward real: 0.6427923440933228 Training q_loss: 98137.9297 Training g_loss: 0.9432 Training d_loss: 1.1624 Explore P: 0.8810\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 55 Total reward: 15.0 Average reward fake: 0.41268086433410645 Average reward real: 0.5878339409828186 Training q_loss: 274204.7812 Training g_loss: 0.8832 Training d_loss: 1.1352 Explore P: 0.8797\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 56 Total reward: 20.0 Average reward fake: 0.41576939821243286 Average reward real: 0.5553684830665588 Training q_loss: 56519.2148 Training g_loss: 0.9082 Training d_loss: 1.2271 Explore P: 0.8779\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 57 Total reward: 11.0 Average reward fake: 0.46072056889533997 Average reward real: 0.5291454195976257 Training q_loss: 110053.5938 Training g_loss: 0.7772 Training d_loss: 1.3090 Explore P: 0.8770\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 58 Total reward: 30.0 Average reward fake: 0.4085870683193207 Average reward real: 0.5984663963317871 Training q_loss: 79900.9922 Training g_loss: 0.9089 Training d_loss: 1.1332 Explore P: 0.8744\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 59 Total reward: 9.0 Average reward fake: 0.4459189474582672 Average reward real: 0.5523717403411865 Training q_loss: 71429.4609 Training g_loss: 0.8092 Training d_loss: 1.2356 Explore P: 0.8736\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 60 Total reward: 13.0 Average reward fake: 0.2966822683811188 Average reward real: 0.6244315505027771 Training q_loss: 326220.2812 Training g_loss: 1.4246 Training d_loss: 1.1425 Explore P: 0.8725\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 61 Total reward: 23.0 Average reward fake: 0.4944012463092804 Average reward real: 0.5316236019134521 Training q_loss: 42680.4766 Training g_loss: 0.7067 Training d_loss: 1.3523 Explore P: 0.8705\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 62 Total reward: 31.0 Average reward fake: 0.4388291835784912 Average reward real: 0.5599833726882935 Training q_loss: 201255.7812 Training g_loss: 0.8224 Training d_loss: 1.2090 Explore P: 0.8678\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 63 Total reward: 27.0 Average reward fake: 0.46276456117630005 Average reward real: 0.528799295425415 Training q_loss: 26569.2695 Training g_loss: 0.7765 Training d_loss: 1.3682 Explore P: 0.8655\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 64 Total reward: 26.0 Average reward fake: 0.4428315758705139 Average reward real: 0.5133662223815918 Training q_loss: 27183.0195 Training g_loss: 0.8097 Training d_loss: 1.2975 Explore P: 0.8633\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 65 Total reward: 14.0 Average reward fake: 0.3872760832309723 Average reward real: 0.5682499408721924 Training q_loss: 48083.0898 Training g_loss: 0.9351 Training d_loss: 1.0945 Explore P: 0.8621\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 66 Total reward: 50.0 Average reward fake: 0.40247154235839844 Average reward real: 0.5941429138183594 Training q_loss: 30447.7969 Training g_loss: 0.9102 Training d_loss: 1.1019 Explore P: 0.8579\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 67 Total reward: 27.0 Average reward fake: 0.344035267829895 Average reward real: 0.5917112231254578 Training q_loss: 117736.1484 Training g_loss: 1.0740 Training d_loss: 0.9977 Explore P: 0.8556\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 68 Total reward: 16.0 Average reward fake: 0.37934768199920654 Average reward real: 0.5785283446311951 Training q_loss: 62704.7617 Training g_loss: 0.9713 Training d_loss: 1.1686 Explore P: 0.8542\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 69 Total reward: 38.0 Average reward fake: 0.4203847646713257 Average reward real: 0.5599262118339539 Training q_loss: 87785.4375 Training g_loss: 0.8695 Training d_loss: 1.1938 Explore P: 0.8510\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 70 Total reward: 64.0 Average reward fake: 0.383637011051178 Average reward real: 0.5691230893135071 Training q_loss: 47115.4141 Training g_loss: 0.9622 Training d_loss: 1.0950 Explore P: 0.8456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 71 Total reward: 26.0 Average reward fake: 0.3992692530155182 Average reward real: 0.5829483270645142 Training q_loss: 85395.3984 Training g_loss: 0.9267 Training d_loss: 1.0974 Explore P: 0.8435\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 72 Total reward: 22.0 Average reward fake: 0.3825766444206238 Average reward real: 0.6429197788238525 Training q_loss: 34281.9805 Training g_loss: 0.9759 Training d_loss: 0.9711 Explore P: 0.8416\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 73 Total reward: 10.0 Average reward fake: 0.3455701470375061 Average reward real: 0.5984346270561218 Training q_loss: 57761.4492 Training g_loss: 1.0768 Training d_loss: 0.9999 Explore P: 0.8408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 74 Total reward: 12.0 Average reward fake: 0.37165459990501404 Average reward real: 0.6261829137802124 Training q_loss: 39590.7578 Training g_loss: 0.9889 Training d_loss: 0.9761 Explore P: 0.8398\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 75 Total reward: 51.0 Average reward fake: 0.46024054288864136 Average reward real: 0.6453076004981995 Training q_loss: 30801.6855 Training g_loss: 0.7772 Training d_loss: 1.1182 Explore P: 0.8356\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 76 Total reward: 17.0 Average reward fake: 0.35780608654022217 Average reward real: 0.6463337540626526 Training q_loss: 43762.6758 Training g_loss: 1.0752 Training d_loss: 0.9493 Explore P: 0.8342\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 77 Total reward: 36.0 Average reward fake: 0.37008199095726013 Average reward real: 0.6134517192840576 Training q_loss: 37637.8711 Training g_loss: 1.0076 Training d_loss: 1.0282 Explore P: 0.8312\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 78 Total reward: 16.0 Average reward fake: 0.39818358421325684 Average reward real: 0.6453884840011597 Training q_loss: 137983.9219 Training g_loss: 0.9199 Training d_loss: 1.0019 Explore P: 0.8299\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 79 Total reward: 23.0 Average reward fake: 0.3263293504714966 Average reward real: 0.6489282250404358 Training q_loss: 62751.6484 Training g_loss: 1.1978 Training d_loss: 0.9936 Explore P: 0.8280\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 80 Total reward: 10.0 Average reward fake: 0.4656984806060791 Average reward real: 0.5235877633094788 Training q_loss: 59565.2188 Training g_loss: 0.7899 Training d_loss: 1.5794 Explore P: 0.8272\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 81 Total reward: 23.0 Average reward fake: 0.41100847721099854 Average reward real: 0.4920651912689209 Training q_loss: 87719.1875 Training g_loss: 1.1975 Training d_loss: 1.5565 Explore P: 0.8253\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 82 Total reward: 18.0 Average reward fake: 0.33023396134376526 Average reward real: 0.6698918342590332 Training q_loss: 100159.4375 Training g_loss: 1.0970 Training d_loss: 0.8792 Explore P: 0.8239\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 83 Total reward: 25.0 Average reward fake: 0.3967278301715851 Average reward real: 0.6461361050605774 Training q_loss: 73791.0078 Training g_loss: 0.9218 Training d_loss: 1.0010 Explore P: 0.8218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 84 Total reward: 8.0 Average reward fake: 0.2707687020301819 Average reward real: 0.7372299432754517 Training q_loss: 1329589.8750 Training g_loss: 1.3434 Training d_loss: 0.6963 Explore P: 0.8212\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 85 Total reward: 42.0 Average reward fake: 0.43058404326438904 Average reward real: 0.5596166849136353 Training q_loss: 296322.4688 Training g_loss: 0.8779 Training d_loss: 1.2440 Explore P: 0.8178\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 86 Total reward: 73.0 Average reward fake: 0.34855687618255615 Average reward real: 0.7226636409759521 Training q_loss: 157696.6250 Training g_loss: 1.0783 Training d_loss: 0.8232 Explore P: 0.8119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 87 Total reward: 35.0 Average reward fake: 0.35363808274269104 Average reward real: 0.6262683272361755 Training q_loss: 63400.9062 Training g_loss: 1.0395 Training d_loss: 1.0439 Explore P: 0.8091\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 88 Total reward: 18.0 Average reward fake: 0.3673971891403198 Average reward real: 0.6116822361946106 Training q_loss: 419124.0312 Training g_loss: 1.0006 Training d_loss: 1.0803 Explore P: 0.8077\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 89 Total reward: 49.0 Average reward fake: 0.46623513102531433 Average reward real: 0.5006113648414612 Training q_loss: 46349.0859 Training g_loss: 0.7644 Training d_loss: 1.4924 Explore P: 0.8038\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 90 Total reward: 32.0 Average reward fake: 0.424922913312912 Average reward real: 0.5721895098686218 Training q_loss: 265683.1875 Training g_loss: 0.8674 Training d_loss: 1.2176 Explore P: 0.8012\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 91 Total reward: 28.0 Average reward fake: 0.40470051765441895 Average reward real: 0.48228463530540466 Training q_loss: 183583.2656 Training g_loss: 0.9050 Training d_loss: 1.3314 Explore P: 0.7990\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 92 Total reward: 26.0 Average reward fake: 0.45968079566955566 Average reward real: 0.5354779958724976 Training q_loss: 174795.2969 Training g_loss: 0.7981 Training d_loss: 1.4554 Explore P: 0.7970\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 93 Total reward: 43.0 Average reward fake: 0.42968255281448364 Average reward real: 0.4836581349372864 Training q_loss: 52567.5586 Training g_loss: 0.8208 Training d_loss: 1.4765 Explore P: 0.7936\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 94 Total reward: 24.0 Average reward fake: 0.4217546880245209 Average reward real: 0.5489733219146729 Training q_loss: 61892.5391 Training g_loss: 1.2446 Training d_loss: 1.5843 Explore P: 0.7917\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 95 Total reward: 23.0 Average reward fake: 0.3795357644557953 Average reward real: 0.5268951654434204 Training q_loss: 102504.1797 Training g_loss: 1.0204 Training d_loss: 1.3873 Explore P: 0.7899\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 96 Total reward: 23.0 Average reward fake: 0.4404117465019226 Average reward real: 0.6382514834403992 Training q_loss: 48421.7852 Training g_loss: 0.8197 Training d_loss: 1.0854 Explore P: 0.7881\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 97 Total reward: 23.0 Average reward fake: 0.38740578293800354 Average reward real: 0.5821697115898132 Training q_loss: 166800.7031 Training g_loss: 1.0665 Training d_loss: 1.3439 Explore P: 0.7864\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 98 Total reward: 18.0 Average reward fake: 0.42591533064842224 Average reward real: 0.5269774794578552 Training q_loss: 43654.0898 Training g_loss: 0.8871 Training d_loss: 1.2667 Explore P: 0.7850\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 99 Total reward: 10.0 Average reward fake: 0.3333936035633087 Average reward real: 0.6033338904380798 Training q_loss: 50073.5195 Training g_loss: 1.0980 Training d_loss: 0.9518 Explore P: 0.7842\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 100 Total reward: 50.0 Average reward fake: 0.3996942639350891 Average reward real: 0.6398837566375732 Training q_loss: 426982.5312 Training g_loss: 0.9422 Training d_loss: 1.0904 Explore P: 0.7803\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 101 Total reward: 15.0 Average reward fake: 0.3832157552242279 Average reward real: 0.6063624620437622 Training q_loss: 163347.9531 Training g_loss: 0.9673 Training d_loss: 1.1684 Explore P: 0.7792\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 102 Total reward: 11.0 Average reward fake: 0.36404693126678467 Average reward real: 0.6277632713317871 Training q_loss: 87084.0078 Training g_loss: 1.0145 Training d_loss: 0.9871 Explore P: 0.7783\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 103 Total reward: 17.0 Average reward fake: 0.3372281789779663 Average reward real: 0.6373023390769958 Training q_loss: 99819.0469 Training g_loss: 1.0923 Training d_loss: 0.9557 Explore P: 0.7770\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 104 Total reward: 19.0 Average reward fake: 0.2751855254173279 Average reward real: 0.6090884208679199 Training q_loss: 32609.6855 Training g_loss: 1.3839 Training d_loss: 0.9911 Explore P: 0.7756\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 105 Total reward: 11.0 Average reward fake: 0.3671109080314636 Average reward real: 0.6975769996643066 Training q_loss: 120994.6562 Training g_loss: 1.1123 Training d_loss: 0.9752 Explore P: 0.7747\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 106 Total reward: 52.0 Average reward fake: 0.3340502083301544 Average reward real: 0.6250975131988525 Training q_loss: 36596.0234 Training g_loss: 1.1092 Training d_loss: 0.9844 Explore P: 0.7708\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 107 Total reward: 13.0 Average reward fake: 0.37179499864578247 Average reward real: 0.6305656433105469 Training q_loss: 37689.2383 Training g_loss: 1.0034 Training d_loss: 1.0520 Explore P: 0.7698\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 108 Total reward: 17.0 Average reward fake: 0.3677328824996948 Average reward real: 0.6665791273117065 Training q_loss: 23009.0098 Training g_loss: 1.0046 Training d_loss: 0.9382 Explore P: 0.7685\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 109 Total reward: 14.0 Average reward fake: 0.27169549465179443 Average reward real: 0.7367746233940125 Training q_loss: 30638.8945 Training g_loss: 1.3283 Training d_loss: 0.6749 Explore P: 0.7674\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 110 Total reward: 14.0 Average reward fake: 0.3229491710662842 Average reward real: 0.6734894514083862 Training q_loss: 95810.2734 Training g_loss: 1.1299 Training d_loss: 0.8716 Explore P: 0.7664\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 111 Total reward: 9.0 Average reward fake: 0.318315327167511 Average reward real: 0.6396163105964661 Training q_loss: 22641.7305 Training g_loss: 1.2175 Training d_loss: 0.9524 Explore P: 0.7657\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 112 Total reward: 14.0 Average reward fake: 0.36840495467185974 Average reward real: 0.6248155236244202 Training q_loss: 27453.4473 Training g_loss: 1.0018 Training d_loss: 1.0529 Explore P: 0.7646\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 113 Total reward: 47.0 Average reward fake: 0.32438361644744873 Average reward real: 0.6335174441337585 Training q_loss: 30605.2520 Training g_loss: 1.1280 Training d_loss: 0.9408 Explore P: 0.7611\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 114 Total reward: 20.0 Average reward fake: 0.33257922530174255 Average reward real: 0.6116893291473389 Training q_loss: 72822.5078 Training g_loss: 1.1057 Training d_loss: 0.9954 Explore P: 0.7596\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 115 Total reward: 13.0 Average reward fake: 0.3555157482624054 Average reward real: 0.6485493183135986 Training q_loss: 68196.4766 Training g_loss: 1.0334 Training d_loss: 0.9729 Explore P: 0.7586\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 116 Total reward: 31.0 Average reward fake: 0.2787701487541199 Average reward real: 0.6905471682548523 Training q_loss: 26231.0977 Training g_loss: 1.3306 Training d_loss: 0.7859 Explore P: 0.7563\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 117 Total reward: 44.0 Average reward fake: 0.43700268864631653 Average reward real: 0.5826237201690674 Training q_loss: 81870.1250 Training g_loss: 0.8617 Training d_loss: 1.4646 Explore P: 0.7530\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 118 Total reward: 17.0 Average reward fake: 0.12889209389686584 Average reward real: 0.8767572045326233 Training q_loss: 35315.4258 Training g_loss: 2.8180 Training d_loss: 0.6847 Explore P: 0.7517\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 119 Total reward: 37.0 Average reward fake: 0.5106639266014099 Average reward real: 0.6353699564933777 Training q_loss: 142511.9062 Training g_loss: 0.9487 Training d_loss: 1.5991 Explore P: 0.7490\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 120 Total reward: 22.0 Average reward fake: 0.5572800040245056 Average reward real: 0.44136959314346313 Training q_loss: 102181.3828 Training g_loss: 0.6791 Training d_loss: 1.9350 Explore P: 0.7474\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 121 Total reward: 54.0 Average reward fake: 0.19290462136268616 Average reward real: 0.8947097659111023 Training q_loss: 68080.6484 Training g_loss: 1.8643 Training d_loss: 0.4234 Explore P: 0.7434\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 122 Total reward: 36.0 Average reward fake: 0.4133630394935608 Average reward real: 0.5140032768249512 Training q_loss: 89619.5469 Training g_loss: 0.9334 Training d_loss: 1.6138 Explore P: 0.7408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 123 Total reward: 13.0 Average reward fake: 0.5191494822502136 Average reward real: 0.511256992816925 Training q_loss: 28195.4453 Training g_loss: 0.6538 Training d_loss: 1.6783 Explore P: 0.7398\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 124 Total reward: 13.0 Average reward fake: 0.5135703086853027 Average reward real: 0.48151329159736633 Training q_loss: 36981.5469 Training g_loss: 0.6677 Training d_loss: 1.6208 Explore P: 0.7389\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 125 Total reward: 13.0 Average reward fake: 0.4404950439929962 Average reward real: 0.4807833731174469 Training q_loss: 59424.7109 Training g_loss: 0.8185 Training d_loss: 1.4399 Explore P: 0.7379\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 126 Total reward: 30.0 Average reward fake: 0.4229045808315277 Average reward real: 0.5151435136795044 Training q_loss: 34186.1992 Training g_loss: 0.9079 Training d_loss: 1.4947 Explore P: 0.7357\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 127 Total reward: 27.0 Average reward fake: 0.5155310034751892 Average reward real: 0.5174218416213989 Training q_loss: 23894.1191 Training g_loss: 0.6750 Training d_loss: 1.5797 Explore P: 0.7338\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 128 Total reward: 29.0 Average reward fake: 0.4274170696735382 Average reward real: 0.5254322290420532 Training q_loss: 29690.2129 Training g_loss: 0.8518 Training d_loss: 1.3195 Explore P: 0.7317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 129 Total reward: 45.0 Average reward fake: 0.575857400894165 Average reward real: 0.4146497845649719 Training q_loss: 47952.9219 Training g_loss: 0.5512 Training d_loss: 1.8482 Explore P: 0.7285\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 130 Total reward: 19.0 Average reward fake: 0.5813396573066711 Average reward real: 0.4603598713874817 Training q_loss: 41006.9961 Training g_loss: 0.5077 Training d_loss: 1.8943 Explore P: 0.7271\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 131 Total reward: 42.0 Average reward fake: 0.3974430561065674 Average reward real: 0.5605266690254211 Training q_loss: 201432.6562 Training g_loss: 1.0174 Training d_loss: 1.1849 Explore P: 0.7241\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 132 Total reward: 38.0 Average reward fake: 0.46400803327560425 Average reward real: 0.5206618309020996 Training q_loss: 40636.0742 Training g_loss: 0.7964 Training d_loss: 1.3683 Explore P: 0.7214\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 133 Total reward: 33.0 Average reward fake: 0.4476257562637329 Average reward real: 0.5130007266998291 Training q_loss: 51893.0391 Training g_loss: 0.7982 Training d_loss: 1.4321 Explore P: 0.7190\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 134 Total reward: 15.0 Average reward fake: 0.5138199329376221 Average reward real: 0.45854878425598145 Training q_loss: 45802.8555 Training g_loss: 0.6683 Training d_loss: 1.5764 Explore P: 0.7180\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 135 Total reward: 32.0 Average reward fake: 0.501156747341156 Average reward real: 0.49940991401672363 Training q_loss: 25988.3926 Training g_loss: 0.7034 Training d_loss: 1.4429 Explore P: 0.7157\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 136 Total reward: 19.0 Average reward fake: 0.4424034059047699 Average reward real: 0.5359627604484558 Training q_loss: 66604.3516 Training g_loss: 0.8222 Training d_loss: 1.2346 Explore P: 0.7144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 137 Total reward: 21.0 Average reward fake: 0.46095559000968933 Average reward real: 0.5364087820053101 Training q_loss: 23494.0273 Training g_loss: 0.7818 Training d_loss: 1.3062 Explore P: 0.7129\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 138 Total reward: 27.0 Average reward fake: 0.40453705191612244 Average reward real: 0.5559080243110657 Training q_loss: 42504.1797 Training g_loss: 0.9076 Training d_loss: 1.1568 Explore P: 0.7110\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 139 Total reward: 22.0 Average reward fake: 0.46963709592819214 Average reward real: 0.5478001832962036 Training q_loss: 477866.6250 Training g_loss: 0.7567 Training d_loss: 1.3472 Explore P: 0.7095\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 140 Total reward: 10.0 Average reward fake: 0.5360584855079651 Average reward real: 0.5163268446922302 Training q_loss: 138953.0625 Training g_loss: 0.6274 Training d_loss: 1.5201 Explore P: 0.7088\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 141 Total reward: 60.0 Average reward fake: 0.4482209384441376 Average reward real: 0.5477283000946045 Training q_loss: 241813.5156 Training g_loss: 0.8031 Training d_loss: 1.2510 Explore P: 0.7046\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 142 Total reward: 25.0 Average reward fake: 0.46459418535232544 Average reward real: 0.4798399806022644 Training q_loss: 70291.3516 Training g_loss: 0.7863 Training d_loss: 1.4766 Explore P: 0.7028\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 143 Total reward: 21.0 Average reward fake: 0.4530399441719055 Average reward real: 0.5130448937416077 Training q_loss: 71107.1406 Training g_loss: 0.7840 Training d_loss: 1.3348 Explore P: 0.7014\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 144 Total reward: 32.0 Average reward fake: 0.42463570833206177 Average reward real: 0.5217291712760925 Training q_loss: 44088.1953 Training g_loss: 0.8553 Training d_loss: 1.2604 Explore P: 0.6992\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 145 Total reward: 48.0 Average reward fake: 0.4013305604457855 Average reward real: 0.6434246897697449 Training q_loss: 40118.3516 Training g_loss: 0.9159 Training d_loss: 1.0263 Explore P: 0.6959\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 146 Total reward: 14.0 Average reward fake: 0.3541492819786072 Average reward real: 0.6567402482032776 Training q_loss: 23743.9277 Training g_loss: 1.0710 Training d_loss: 0.9501 Explore P: 0.6949\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 147 Total reward: 14.0 Average reward fake: 0.3565312623977661 Average reward real: 0.545238733291626 Training q_loss: 25437.5684 Training g_loss: 1.0786 Training d_loss: 1.2479 Explore P: 0.6940\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 148 Total reward: 13.0 Average reward fake: 0.38506537675857544 Average reward real: 0.6381798386573792 Training q_loss: 50405.1953 Training g_loss: 0.9569 Training d_loss: 1.0027 Explore P: 0.6931\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 149 Total reward: 60.0 Average reward fake: 0.3707899749279022 Average reward real: 0.48939162492752075 Training q_loss: 23567.0176 Training g_loss: 0.9941 Training d_loss: 1.3346 Explore P: 0.6890\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 150 Total reward: 17.0 Average reward fake: 0.41661468148231506 Average reward real: 0.5899854898452759 Training q_loss: 172246.7031 Training g_loss: 0.9088 Training d_loss: 1.1528 Explore P: 0.6878\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 151 Total reward: 9.0 Average reward fake: 0.45259177684783936 Average reward real: 0.5519056916236877 Training q_loss: 32019.0176 Training g_loss: 0.8548 Training d_loss: 1.3408 Explore P: 0.6872\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 152 Total reward: 14.0 Average reward fake: 0.39874017238616943 Average reward real: 0.5861881375312805 Training q_loss: 125569.6328 Training g_loss: 0.9576 Training d_loss: 1.1480 Explore P: 0.6863\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 153 Total reward: 18.0 Average reward fake: 0.4148372709751129 Average reward real: 0.5555557012557983 Training q_loss: 64851.9102 Training g_loss: 0.8777 Training d_loss: 1.1723 Explore P: 0.6851\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 154 Total reward: 24.0 Average reward fake: 0.41236361861228943 Average reward real: 0.5544803142547607 Training q_loss: 87446.7422 Training g_loss: 0.8871 Training d_loss: 1.1643 Explore P: 0.6834\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 155 Total reward: 104.0 Average reward fake: 0.4268149435520172 Average reward real: 0.5096641778945923 Training q_loss: 49708.4414 Training g_loss: 0.8903 Training d_loss: 1.3190 Explore P: 0.6765\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 156 Total reward: 82.0 Average reward fake: 0.4282238483428955 Average reward real: 0.6585896015167236 Training q_loss: 90915.7812 Training g_loss: 0.8550 Training d_loss: 1.1236 Explore P: 0.6710\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 157 Total reward: 13.0 Average reward fake: 0.4579600393772125 Average reward real: 0.6120595335960388 Training q_loss: 150656.0156 Training g_loss: 0.7713 Training d_loss: 1.1568 Explore P: 0.6702\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 158 Total reward: 21.0 Average reward fake: 0.4111776351928711 Average reward real: 0.6024159789085388 Training q_loss: 47502.2500 Training g_loss: 0.8695 Training d_loss: 1.0911 Explore P: 0.6688\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 159 Total reward: 15.0 Average reward fake: 0.41897785663604736 Average reward real: 0.6005474925041199 Training q_loss: 56883.1211 Training g_loss: 0.8700 Training d_loss: 1.0797 Explore P: 0.6678\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 160 Total reward: 13.0 Average reward fake: 0.41357025504112244 Average reward real: 0.5684837102890015 Training q_loss: 21426.1445 Training g_loss: 0.8825 Training d_loss: 1.1379 Explore P: 0.6669\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 161 Total reward: 58.0 Average reward fake: 0.3683297038078308 Average reward real: 0.5798335075378418 Training q_loss: 62011.5742 Training g_loss: 0.9944 Training d_loss: 1.0921 Explore P: 0.6631\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 162 Total reward: 45.0 Average reward fake: 0.3627297282218933 Average reward real: 0.618854284286499 Training q_loss: 43759.0469 Training g_loss: 1.0199 Training d_loss: 1.0031 Explore P: 0.6602\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 163 Total reward: 16.0 Average reward fake: 0.38861221075057983 Average reward real: 0.6296108961105347 Training q_loss: 85080.2422 Training g_loss: 0.9463 Training d_loss: 0.9997 Explore P: 0.6592\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 164 Total reward: 14.0 Average reward fake: 0.34198448061943054 Average reward real: 0.6361629962921143 Training q_loss: 124421.3203 Training g_loss: 1.1555 Training d_loss: 0.9847 Explore P: 0.6583\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 165 Total reward: 39.0 Average reward fake: 0.3977489471435547 Average reward real: 0.6195372939109802 Training q_loss: 28609.0801 Training g_loss: 0.9508 Training d_loss: 1.0482 Explore P: 0.6557\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 166 Total reward: 26.0 Average reward fake: 0.36354896426200867 Average reward real: 0.7377039194107056 Training q_loss: 113876.6719 Training g_loss: 1.1949 Training d_loss: 1.2164 Explore P: 0.6541\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 167 Total reward: 73.0 Average reward fake: 0.3696454167366028 Average reward real: 0.7153435349464417 Training q_loss: 176346.0469 Training g_loss: 1.6039 Training d_loss: 0.9852 Explore P: 0.6494\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 168 Total reward: 39.0 Average reward fake: 0.4081799387931824 Average reward real: 0.6233445405960083 Training q_loss: 109372.5312 Training g_loss: 0.9079 Training d_loss: 1.1047 Explore P: 0.6469\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 169 Total reward: 15.0 Average reward fake: 0.3845621347427368 Average reward real: 0.6480710506439209 Training q_loss: 56009.2891 Training g_loss: 1.0678 Training d_loss: 1.1204 Explore P: 0.6459\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 170 Total reward: 14.0 Average reward fake: 0.4339679479598999 Average reward real: 0.6185401678085327 Training q_loss: 22912.4492 Training g_loss: 0.8454 Training d_loss: 1.3461 Explore P: 0.6451\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 171 Total reward: 45.0 Average reward fake: 0.3848435580730438 Average reward real: 0.5848315954208374 Training q_loss: 30514.2402 Training g_loss: 1.0672 Training d_loss: 1.1115 Explore P: 0.6422\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 172 Total reward: 21.0 Average reward fake: 0.32928138971328735 Average reward real: 0.6674847602844238 Training q_loss: 61705.4258 Training g_loss: 1.2326 Training d_loss: 0.9266 Explore P: 0.6409\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 173 Total reward: 13.0 Average reward fake: 0.33740365505218506 Average reward real: 0.6516367197036743 Training q_loss: 232224.3125 Training g_loss: 1.1810 Training d_loss: 0.9916 Explore P: 0.6401\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 174 Total reward: 14.0 Average reward fake: 0.3901499807834625 Average reward real: 0.6340709924697876 Training q_loss: 62585.8867 Training g_loss: 1.0351 Training d_loss: 1.2061 Explore P: 0.6392\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 175 Total reward: 49.0 Average reward fake: 0.4594501554965973 Average reward real: 0.5289852619171143 Training q_loss: 359941.9062 Training g_loss: 0.8367 Training d_loss: 1.4525 Explore P: 0.6361\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 176 Total reward: 68.0 Average reward fake: 0.49478232860565186 Average reward real: 0.6318598985671997 Training q_loss: 54914.3633 Training g_loss: 0.7035 Training d_loss: 1.1919 Explore P: 0.6319\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 177 Total reward: 100.0 Average reward fake: 0.1756627857685089 Average reward real: 0.8742969036102295 Training q_loss: 51875.7617 Training g_loss: 2.8507 Training d_loss: 0.5190 Explore P: 0.6257\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 178 Total reward: 19.0 Average reward fake: 0.41516587138175964 Average reward real: 0.728749692440033 Training q_loss: 55434.8398 Training g_loss: 0.9917 Training d_loss: 1.0587 Explore P: 0.6245\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 179 Total reward: 29.0 Average reward fake: 0.1048169881105423 Average reward real: 0.8902103304862976 Training q_loss: 34676.6406 Training g_loss: 6.4401 Training d_loss: 0.3554 Explore P: 0.6227\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 180 Total reward: 17.0 Average reward fake: 0.5151104927062988 Average reward real: 0.3969750702381134 Training q_loss: 26688.1309 Training g_loss: 2.8853 Training d_loss: 2.1955 Explore P: 0.6217\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 181 Total reward: 88.0 Average reward fake: 0.4275002181529999 Average reward real: 0.602193295955658 Training q_loss: 97139.2734 Training g_loss: 0.8896 Training d_loss: 1.8021 Explore P: 0.6163\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 182 Total reward: 112.0 Average reward fake: 0.38112860918045044 Average reward real: 0.5162021517753601 Training q_loss: 154532.4375 Training g_loss: 0.9648 Training d_loss: 1.2682 Explore P: 0.6096\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 183 Total reward: 11.0 Average reward fake: 0.5000789761543274 Average reward real: 0.48952093720436096 Training q_loss: 400945.9688 Training g_loss: 0.6922 Training d_loss: 1.5815 Explore P: 0.6089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 184 Total reward: 11.0 Average reward fake: 0.5986156463623047 Average reward real: 0.4023088216781616 Training q_loss: 489068.0000 Training g_loss: 0.5161 Training d_loss: 2.0482 Explore P: 0.6082\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 185 Total reward: 52.0 Average reward fake: 0.39326751232147217 Average reward real: 0.5777636766433716 Training q_loss: 115261.1797 Training g_loss: 0.9517 Training d_loss: 1.1326 Explore P: 0.6051\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 186 Total reward: 10.0 Average reward fake: 0.33933135867118835 Average reward real: 0.5746566653251648 Training q_loss: 520611.8750 Training g_loss: 1.0819 Training d_loss: 1.0889 Explore P: 0.6046\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 187 Total reward: 35.0 Average reward fake: 0.3607122004032135 Average reward real: 0.5838484764099121 Training q_loss: 641995.1875 Training g_loss: 1.0299 Training d_loss: 1.1600 Explore P: 0.6025\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 188 Total reward: 45.0 Average reward fake: 0.459809273481369 Average reward real: 0.545833945274353 Training q_loss: 1189401.1250 Training g_loss: 0.8189 Training d_loss: 1.3517 Explore P: 0.5998\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 189 Total reward: 99.0 Average reward fake: 0.39776530861854553 Average reward real: 0.5317176580429077 Training q_loss: 123807.4609 Training g_loss: 0.9251 Training d_loss: 1.2186 Explore P: 0.5940\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 190 Total reward: 61.0 Average reward fake: 0.4568457305431366 Average reward real: 0.489900678396225 Training q_loss: 160224.6562 Training g_loss: 0.7996 Training d_loss: 1.3856 Explore P: 0.5905\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 191 Total reward: 74.0 Average reward fake: 0.4606338441371918 Average reward real: 0.5386340618133545 Training q_loss: 126551.7500 Training g_loss: 0.7851 Training d_loss: 1.3131 Explore P: 0.5862\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 192 Total reward: 12.0 Average reward fake: 0.42214295268058777 Average reward real: 0.5418596863746643 Training q_loss: 106166.8906 Training g_loss: 0.8656 Training d_loss: 1.2169 Explore P: 0.5855\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 193 Total reward: 74.0 Average reward fake: 0.408457487821579 Average reward real: 0.5542587041854858 Training q_loss: 81225.8672 Training g_loss: 0.8953 Training d_loss: 1.1691 Explore P: 0.5812\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 194 Total reward: 27.0 Average reward fake: 0.42503979802131653 Average reward real: 0.5141637921333313 Training q_loss: 254172.8594 Training g_loss: 0.8525 Training d_loss: 1.2804 Explore P: 0.5797\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 195 Total reward: 59.0 Average reward fake: 0.462673157453537 Average reward real: 0.6270700693130493 Training q_loss: 44457.5039 Training g_loss: 0.8044 Training d_loss: 1.1202 Explore P: 0.5763\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 196 Total reward: 16.0 Average reward fake: 0.548356294631958 Average reward real: 0.5744451284408569 Training q_loss: 102753.8906 Training g_loss: 0.6138 Training d_loss: 1.4749 Explore P: 0.5754\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 197 Total reward: 30.0 Average reward fake: 0.3263123035430908 Average reward real: 0.6627556085586548 Training q_loss: 47251.7812 Training g_loss: 1.2219 Training d_loss: 1.0477 Explore P: 0.5737\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 198 Total reward: 16.0 Average reward fake: 0.3309267461299896 Average reward real: 0.6725834608078003 Training q_loss: 60498.8008 Training g_loss: 1.1939 Training d_loss: 0.9994 Explore P: 0.5728\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 199 Total reward: 21.0 Average reward fake: 0.29754364490509033 Average reward real: 0.6844664216041565 Training q_loss: 134195.4844 Training g_loss: 1.6154 Training d_loss: 1.4202 Explore P: 0.5717\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 200 Total reward: 10.0 Average reward fake: 0.4145023822784424 Average reward real: 0.6335607767105103 Training q_loss: 383492.3125 Training g_loss: 1.0181 Training d_loss: 1.1576 Explore P: 0.5711\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 201 Total reward: 15.0 Average reward fake: 0.5208909511566162 Average reward real: 0.555429220199585 Training q_loss: 53207.5156 Training g_loss: 0.6652 Training d_loss: 1.4141 Explore P: 0.5703\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 202 Total reward: 14.0 Average reward fake: 0.41931626200675964 Average reward real: 0.6689918041229248 Training q_loss: 41270.7031 Training g_loss: 0.9451 Training d_loss: 1.1893 Explore P: 0.5695\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 203 Total reward: 26.0 Average reward fake: 0.385709673166275 Average reward real: 0.6545864343643188 Training q_loss: 287370.0000 Training g_loss: 0.9991 Training d_loss: 0.9419 Explore P: 0.5680\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 204 Total reward: 90.0 Average reward fake: 0.4086117446422577 Average reward real: 0.5503407120704651 Training q_loss: 48805.8398 Training g_loss: 0.9873 Training d_loss: 1.2143 Explore P: 0.5630\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 205 Total reward: 47.0 Average reward fake: 0.5137032270431519 Average reward real: 0.4697217643260956 Training q_loss: 185546.2344 Training g_loss: 0.6681 Training d_loss: 1.5499 Explore P: 0.5604\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 206 Total reward: 92.0 Average reward fake: 0.38571372628211975 Average reward real: 0.561312735080719 Training q_loss: 114432.7891 Training g_loss: 0.9654 Training d_loss: 1.1387 Explore P: 0.5554\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 207 Total reward: 51.0 Average reward fake: 0.43090111017227173 Average reward real: 0.5406792163848877 Training q_loss: 26032.2773 Training g_loss: 0.8857 Training d_loss: 1.2496 Explore P: 0.5526\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 208 Total reward: 32.0 Average reward fake: 0.41553446650505066 Average reward real: 0.5896679759025574 Training q_loss: 37220.5938 Training g_loss: 0.8806 Training d_loss: 1.1159 Explore P: 0.5509\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 209 Total reward: 23.0 Average reward fake: 0.3969380855560303 Average reward real: 0.5781344771385193 Training q_loss: 88822.6094 Training g_loss: 0.9222 Training d_loss: 1.1000 Explore P: 0.5496\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 210 Total reward: 11.0 Average reward fake: 0.4215860664844513 Average reward real: 0.5721902251243591 Training q_loss: 173313.9375 Training g_loss: 0.8634 Training d_loss: 1.1562 Explore P: 0.5490\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 211 Total reward: 39.0 Average reward fake: 0.5143389105796814 Average reward real: 0.5064956545829773 Training q_loss: 65782.5781 Training g_loss: 0.6682 Training d_loss: 1.4931 Explore P: 0.5469\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 212 Total reward: 13.0 Average reward fake: 0.4579278528690338 Average reward real: 0.5537068843841553 Training q_loss: 93778.4375 Training g_loss: 0.9110 Training d_loss: 1.3684 Explore P: 0.5463\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 213 Total reward: 29.0 Average reward fake: 0.40298721194267273 Average reward real: 0.5466541051864624 Training q_loss: 64148.1094 Training g_loss: 0.9283 Training d_loss: 1.2085 Explore P: 0.5447\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 214 Total reward: 46.0 Average reward fake: 0.43785354495048523 Average reward real: 0.582838237285614 Training q_loss: 25150.7148 Training g_loss: 0.8587 Training d_loss: 1.2085 Explore P: 0.5422\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 215 Total reward: 55.0 Average reward fake: 0.4540555477142334 Average reward real: 0.575121283531189 Training q_loss: 73367.9688 Training g_loss: 1.1108 Training d_loss: 1.4093 Explore P: 0.5393\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 216 Total reward: 29.0 Average reward fake: 0.37161579728126526 Average reward real: 0.6387112140655518 Training q_loss: 41539.8789 Training g_loss: 1.3447 Training d_loss: 1.1210 Explore P: 0.5378\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 217 Total reward: 21.0 Average reward fake: 0.3469429016113281 Average reward real: 0.6391412019729614 Training q_loss: 287005.4375 Training g_loss: 1.0575 Training d_loss: 1.0149 Explore P: 0.5367\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 218 Total reward: 9.0 Average reward fake: 0.4052893817424774 Average reward real: 0.622473955154419 Training q_loss: 72090.8672 Training g_loss: 0.9023 Training d_loss: 1.1990 Explore P: 0.5362\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 219 Total reward: 63.0 Average reward fake: 0.1720472276210785 Average reward real: 0.8711608052253723 Training q_loss: 55351.1016 Training g_loss: 4.9625 Training d_loss: 0.6938 Explore P: 0.5329\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 220 Total reward: 20.0 Average reward fake: 0.18575778603553772 Average reward real: 0.7417954802513123 Training q_loss: 181998.5469 Training g_loss: 1.8164 Training d_loss: 1.0343 Explore P: 0.5319\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 221 Total reward: 20.0 Average reward fake: 0.2698844075202942 Average reward real: 0.728933572769165 Training q_loss: 171389.7188 Training g_loss: 1.7685 Training d_loss: 1.3633 Explore P: 0.5308\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 222 Total reward: 67.0 Average reward fake: 0.09959887713193893 Average reward real: 0.9181862473487854 Training q_loss: 33620.3164 Training g_loss: 2.5004 Training d_loss: 0.2677 Explore P: 0.5273\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 223 Total reward: 75.0 Average reward fake: 0.4675706624984741 Average reward real: 0.5099875926971436 Training q_loss: 138330.5156 Training g_loss: 0.7781 Training d_loss: 1.4351 Explore P: 0.5235\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 224 Total reward: 92.0 Average reward fake: 0.4975995719432831 Average reward real: 0.49754729866981506 Training q_loss: 22833.6758 Training g_loss: 0.6886 Training d_loss: 1.4909 Explore P: 0.5188\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 225 Total reward: 20.0 Average reward fake: 0.4353586435317993 Average reward real: 0.577279269695282 Training q_loss: 24786.1172 Training g_loss: 0.8421 Training d_loss: 1.1743 Explore P: 0.5178\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 226 Total reward: 15.0 Average reward fake: 0.4646664559841156 Average reward real: 0.5507090091705322 Training q_loss: 68270.0781 Training g_loss: 0.7694 Training d_loss: 1.3281 Explore P: 0.5170\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 227 Total reward: 52.0 Average reward fake: 0.504579484462738 Average reward real: 0.45139458775520325 Training q_loss: 53933.9062 Training g_loss: 0.6660 Training d_loss: 1.8104 Explore P: 0.5144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 228 Total reward: 57.0 Average reward fake: 0.4082576632499695 Average reward real: 0.6178790926933289 Training q_loss: 56796.8008 Training g_loss: 0.8977 Training d_loss: 1.0504 Explore P: 0.5115\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 229 Total reward: 26.0 Average reward fake: 0.40730419754981995 Average reward real: 0.6053823232650757 Training q_loss: 45894.1641 Training g_loss: 0.8992 Training d_loss: 1.0936 Explore P: 0.5102\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 230 Total reward: 19.0 Average reward fake: 0.4368455111980438 Average reward real: 0.5422880053520203 Training q_loss: 91830.3594 Training g_loss: 0.8279 Training d_loss: 1.2922 Explore P: 0.5092\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 231 Total reward: 45.0 Average reward fake: 0.5125295519828796 Average reward real: 0.456210732460022 Training q_loss: 75769.4688 Training g_loss: 0.6729 Training d_loss: 1.5634 Explore P: 0.5070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 232 Total reward: 41.0 Average reward fake: 0.41352835297584534 Average reward real: 0.5060954093933105 Training q_loss: 107206.9219 Training g_loss: 0.8837 Training d_loss: 1.4280 Explore P: 0.5050\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 233 Total reward: 14.0 Average reward fake: 0.5094266533851624 Average reward real: 0.4328859746456146 Training q_loss: 74172.3984 Training g_loss: 0.6762 Training d_loss: 1.7942 Explore P: 0.5043\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 234 Total reward: 30.0 Average reward fake: 0.5823348760604858 Average reward real: 0.3228245675563812 Training q_loss: 70106.5625 Training g_loss: 0.5416 Training d_loss: 2.1600 Explore P: 0.5028\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 235 Total reward: 21.0 Average reward fake: 0.4339952766895294 Average reward real: 0.6043704152107239 Training q_loss: 97790.5625 Training g_loss: 0.8340 Training d_loss: 1.0972 Explore P: 0.5018\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 236 Total reward: 48.0 Average reward fake: 0.42645981907844543 Average reward real: 0.5491248369216919 Training q_loss: 51911.6719 Training g_loss: 0.8619 Training d_loss: 1.2340 Explore P: 0.4994\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 237 Total reward: 26.0 Average reward fake: 0.5496777296066284 Average reward real: 0.5050101280212402 Training q_loss: 90096.2500 Training g_loss: 0.6182 Training d_loss: 1.5611 Explore P: 0.4981\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 238 Total reward: 37.0 Average reward fake: 0.561514139175415 Average reward real: 0.5014211535453796 Training q_loss: 126457.7969 Training g_loss: 0.5798 Training d_loss: 1.5467 Explore P: 0.4963\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 239 Total reward: 62.0 Average reward fake: 0.47387003898620605 Average reward real: 0.5722222924232483 Training q_loss: 20028.1152 Training g_loss: 0.7480 Training d_loss: 1.2540 Explore P: 0.4933\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 240 Total reward: 16.0 Average reward fake: 0.456735223531723 Average reward real: 0.5061630010604858 Training q_loss: 99714.4531 Training g_loss: 0.7917 Training d_loss: 1.3387 Explore P: 0.4926\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 241 Total reward: 33.0 Average reward fake: 0.510108232498169 Average reward real: 0.5306230187416077 Training q_loss: 37638.4688 Training g_loss: 0.7008 Training d_loss: 1.3978 Explore P: 0.4910\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 242 Total reward: 177.0 Average reward fake: 0.499288946390152 Average reward real: 0.45118004083633423 Training q_loss: 41974.4219 Training g_loss: 0.6945 Training d_loss: 1.5074 Explore P: 0.4825\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 243 Total reward: 57.0 Average reward fake: 0.3963448703289032 Average reward real: 0.5651323795318604 Training q_loss: 32352.4043 Training g_loss: 0.9472 Training d_loss: 1.1481 Explore P: 0.4798\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 244 Total reward: 74.0 Average reward fake: 0.5400877594947815 Average reward real: 0.4063979387283325 Training q_loss: 96570.1875 Training g_loss: 0.6189 Training d_loss: 1.7731 Explore P: 0.4764\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 245 Total reward: 11.0 Average reward fake: 0.5193064212799072 Average reward real: 0.4806562662124634 Training q_loss: 231896.6250 Training g_loss: 0.6465 Training d_loss: 1.5415 Explore P: 0.4759\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 246 Total reward: 60.0 Average reward fake: 0.5170378684997559 Average reward real: 0.4951261878013611 Training q_loss: 60290.8242 Training g_loss: 0.6641 Training d_loss: 1.4526 Explore P: 0.4731\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 247 Total reward: 26.0 Average reward fake: 0.4637628197669983 Average reward real: 0.5728279948234558 Training q_loss: 114421.1562 Training g_loss: 0.7693 Training d_loss: 1.1944 Explore P: 0.4719\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 248 Total reward: 19.0 Average reward fake: 0.4173804521560669 Average reward real: 0.5592259764671326 Training q_loss: 179857.3438 Training g_loss: 0.8744 Training d_loss: 1.1392 Explore P: 0.4710\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 249 Total reward: 56.0 Average reward fake: 0.49743661284446716 Average reward real: 0.4868942201137543 Training q_loss: 37466.3281 Training g_loss: 0.6964 Training d_loss: 1.4391 Explore P: 0.4684\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 250 Total reward: 95.0 Average reward fake: 0.4948202967643738 Average reward real: 0.4483683705329895 Training q_loss: 287022.6875 Training g_loss: 0.7054 Training d_loss: 1.5142 Explore P: 0.4641\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 251 Total reward: 52.0 Average reward fake: 0.42388778924942017 Average reward real: 0.5301885008811951 Training q_loss: 37143.3086 Training g_loss: 0.8615 Training d_loss: 1.2052 Explore P: 0.4617\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 252 Total reward: 45.0 Average reward fake: 0.4797991216182709 Average reward real: 0.4871174097061157 Training q_loss: 110026.2812 Training g_loss: 0.7382 Training d_loss: 1.4731 Explore P: 0.4597\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 253 Total reward: 52.0 Average reward fake: 0.46836361289024353 Average reward real: 0.6165931224822998 Training q_loss: 21224.2168 Training g_loss: 0.7766 Training d_loss: 1.2036 Explore P: 0.4574\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 254 Total reward: 84.0 Average reward fake: 0.27034255862236023 Average reward real: 0.6246132850646973 Training q_loss: 48795.5000 Training g_loss: 1.3500 Training d_loss: 1.0727 Explore P: 0.4536\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 255 Total reward: 15.0 Average reward fake: 0.37104636430740356 Average reward real: 0.522761881351471 Training q_loss: 216959.7031 Training g_loss: 1.0047 Training d_loss: 1.3899 Explore P: 0.4530\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 256 Total reward: 32.0 Average reward fake: 0.5782473087310791 Average reward real: 0.38575926423072815 Training q_loss: 184874.0469 Training g_loss: 0.5484 Training d_loss: 2.3959 Explore P: 0.4516\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 257 Total reward: 14.0 Average reward fake: 0.34783875942230225 Average reward real: 0.5909976959228516 Training q_loss: 21131.8730 Training g_loss: 1.1376 Training d_loss: 1.3106 Explore P: 0.4509\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 258 Total reward: 33.0 Average reward fake: 0.8081297874450684 Average reward real: 0.2614668905735016 Training q_loss: 21927.3574 Training g_loss: 0.2630 Training d_loss: 4.8024 Explore P: 0.4495\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 259 Total reward: 14.0 Average reward fake: 0.5751708149909973 Average reward real: 0.39947158098220825 Training q_loss: 247051.0469 Training g_loss: 0.5539 Training d_loss: 1.9988 Explore P: 0.4489\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 260 Total reward: 20.0 Average reward fake: 0.22063373029232025 Average reward real: 0.5723209381103516 Training q_loss: 45296.0156 Training g_loss: 1.5934 Training d_loss: 1.2543 Explore P: 0.4480\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 261 Total reward: 87.0 Average reward fake: 0.521880567073822 Average reward real: 0.47522950172424316 Training q_loss: 52749.3438 Training g_loss: 0.6509 Training d_loss: 1.4848 Explore P: 0.4442\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 262 Total reward: 68.0 Average reward fake: 0.40830233693122864 Average reward real: 0.6057822704315186 Training q_loss: 398614.2812 Training g_loss: 0.8969 Training d_loss: 1.0888 Explore P: 0.4413\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 263 Total reward: 49.0 Average reward fake: 0.4909169673919678 Average reward real: 0.49358800053596497 Training q_loss: 57275.7695 Training g_loss: 0.7126 Training d_loss: 1.4723 Explore P: 0.4391\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 264 Total reward: 23.0 Average reward fake: 0.527833878993988 Average reward real: 0.5008302330970764 Training q_loss: 63454.2031 Training g_loss: 0.6400 Training d_loss: 1.5033 Explore P: 0.4382\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 265 Total reward: 69.0 Average reward fake: 0.5524373650550842 Average reward real: 0.46457135677337646 Training q_loss: 196579.0156 Training g_loss: 0.5937 Training d_loss: 1.5772 Explore P: 0.4352\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 266 Total reward: 11.0 Average reward fake: 0.5574080944061279 Average reward real: 0.47799769043922424 Training q_loss: 53409.8633 Training g_loss: 0.5846 Training d_loss: 1.5592 Explore P: 0.4348\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 267 Total reward: 63.0 Average reward fake: 0.4341733157634735 Average reward real: 0.5700580477714539 Training q_loss: 85278.7422 Training g_loss: 0.8347 Training d_loss: 1.1406 Explore P: 0.4321\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 268 Total reward: 31.0 Average reward fake: 0.4312547445297241 Average reward real: 0.5888627767562866 Training q_loss: 69640.3438 Training g_loss: 0.8411 Training d_loss: 1.1148 Explore P: 0.4308\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 269 Total reward: 98.0 Average reward fake: 0.4894200265407562 Average reward real: 0.5196323990821838 Training q_loss: 91794.2500 Training g_loss: 0.7270 Training d_loss: 1.4107 Explore P: 0.4267\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 270 Total reward: 47.0 Average reward fake: 0.49395790696144104 Average reward real: 0.5121566653251648 Training q_loss: 29824.3418 Training g_loss: 0.7168 Training d_loss: 1.3972 Explore P: 0.4247\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 271 Total reward: 74.0 Average reward fake: 0.45158541202545166 Average reward real: 0.5646166801452637 Training q_loss: 95793.4375 Training g_loss: 0.7944 Training d_loss: 1.2128 Explore P: 0.4217\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 272 Total reward: 44.0 Average reward fake: 0.38781869411468506 Average reward real: 0.5899322628974915 Training q_loss: 33698.6211 Training g_loss: 0.9502 Training d_loss: 1.0967 Explore P: 0.4199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 273 Total reward: 92.0 Average reward fake: 0.3928859829902649 Average reward real: 0.5746937394142151 Training q_loss: 68213.5859 Training g_loss: 0.9778 Training d_loss: 1.1742 Explore P: 0.4161\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 274 Total reward: 71.0 Average reward fake: 0.3349260091781616 Average reward real: 0.6173391938209534 Training q_loss: 36807.9844 Training g_loss: 1.1000 Training d_loss: 1.0124 Explore P: 0.4132\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 275 Total reward: 115.0 Average reward fake: 0.44247666001319885 Average reward real: 0.5071457624435425 Training q_loss: 24694.5859 Training g_loss: 0.8199 Training d_loss: 1.3563 Explore P: 0.4086\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 276 Total reward: 64.0 Average reward fake: 0.42357856035232544 Average reward real: 0.6037788987159729 Training q_loss: 32701.2246 Training g_loss: 0.9407 Training d_loss: 1.1410 Explore P: 0.4061\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 277 Total reward: 10.0 Average reward fake: 0.40401703119277954 Average reward real: 0.6174315214157104 Training q_loss: 29877.1797 Training g_loss: 0.9713 Training d_loss: 1.1665 Explore P: 0.4057\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 278 Total reward: 31.0 Average reward fake: 0.3990017771720886 Average reward real: 0.6371720433235168 Training q_loss: 55049.3750 Training g_loss: 1.1010 Training d_loss: 1.1928 Explore P: 0.4045\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 279 Total reward: 12.0 Average reward fake: 0.35886722803115845 Average reward real: 0.5733404159545898 Training q_loss: 66343.9688 Training g_loss: 1.1168 Training d_loss: 1.2222 Explore P: 0.4040\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 280 Total reward: 25.0 Average reward fake: 0.4114294946193695 Average reward real: 0.6199837327003479 Training q_loss: 63905.3203 Training g_loss: 0.9088 Training d_loss: 1.0898 Explore P: 0.4030\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 281 Total reward: 34.0 Average reward fake: 0.42759475111961365 Average reward real: 0.6220790147781372 Training q_loss: 191424.4219 Training g_loss: 0.8775 Training d_loss: 1.1471 Explore P: 0.4017\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 282 Total reward: 23.0 Average reward fake: 0.41287145018577576 Average reward real: 0.5741568803787231 Training q_loss: 50641.6250 Training g_loss: 0.8883 Training d_loss: 1.1467 Explore P: 0.4008\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 283 Total reward: 72.0 Average reward fake: 0.49179577827453613 Average reward real: 0.5256911516189575 Training q_loss: 183939.4844 Training g_loss: 0.7115 Training d_loss: 1.3869 Explore P: 0.3980\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 284 Total reward: 174.0 Average reward fake: 0.6304482817649841 Average reward real: 0.5481515526771545 Training q_loss: 63677.3633 Training g_loss: 0.4622 Training d_loss: 1.6707 Explore P: 0.3913\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 285 Total reward: 9.0 Average reward fake: 0.4093543589115143 Average reward real: 0.5440022349357605 Training q_loss: 192118.2344 Training g_loss: 0.9578 Training d_loss: 1.4348 Explore P: 0.3909\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 286 Total reward: 135.0 Average reward fake: 0.5149897933006287 Average reward real: 0.4901138246059418 Training q_loss: 24347.1133 Training g_loss: 0.6606 Training d_loss: 1.4616 Explore P: 0.3858\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 287 Total reward: 18.0 Average reward fake: 0.4963993430137634 Average reward real: 0.48606571555137634 Training q_loss: 150305.3281 Training g_loss: 0.7015 Training d_loss: 1.4167 Explore P: 0.3851\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 288 Total reward: 75.0 Average reward fake: 0.4933001697063446 Average reward real: 0.5359363555908203 Training q_loss: 68750.7891 Training g_loss: 0.7123 Training d_loss: 1.3415 Explore P: 0.3823\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 289 Total reward: 133.0 Average reward fake: 0.5052193403244019 Average reward real: 0.5275360941886902 Training q_loss: 47456.8047 Training g_loss: 0.6828 Training d_loss: 1.3530 Explore P: 0.3774\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 290 Total reward: 56.0 Average reward fake: 0.5172975063323975 Average reward real: 0.5111587643623352 Training q_loss: 34148.8750 Training g_loss: 0.6509 Training d_loss: 1.4150 Explore P: 0.3754\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 291 Total reward: 17.0 Average reward fake: 0.4819961190223694 Average reward real: 0.5061669945716858 Training q_loss: 56310.3750 Training g_loss: 0.7317 Training d_loss: 1.3451 Explore P: 0.3747\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 292 Total reward: 36.0 Average reward fake: 0.4919586181640625 Average reward real: 0.48831871151924133 Training q_loss: 36564.4492 Training g_loss: 0.6984 Training d_loss: 1.4514 Explore P: 0.3734\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 293 Total reward: 10.0 Average reward fake: 0.5148587822914124 Average reward real: 0.4667985439300537 Training q_loss: 24502.3320 Training g_loss: 0.6672 Training d_loss: 1.5118 Explore P: 0.3731\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 294 Total reward: 9.0 Average reward fake: 0.5009294748306274 Average reward real: 0.4561542570590973 Training q_loss: 246641.5938 Training g_loss: 0.6912 Training d_loss: 1.4937 Explore P: 0.3727\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 295 Total reward: 15.0 Average reward fake: 0.4998047649860382 Average reward real: 0.4903230369091034 Training q_loss: 33261.1484 Training g_loss: 0.6936 Training d_loss: 1.4425 Explore P: 0.3722\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 296 Total reward: 36.0 Average reward fake: 0.4558555483818054 Average reward real: 0.5150152444839478 Training q_loss: 284832.2500 Training g_loss: 0.7859 Training d_loss: 1.2761 Explore P: 0.3709\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 297 Total reward: 155.0 Average reward fake: 0.4649236798286438 Average reward real: 0.5103604793548584 Training q_loss: 34576.7070 Training g_loss: 0.7746 Training d_loss: 1.3200 Explore P: 0.3654\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 298 Total reward: 29.0 Average reward fake: 0.4921448826789856 Average reward real: 0.5066992044448853 Training q_loss: 17562.1289 Training g_loss: 0.6902 Training d_loss: 1.4164 Explore P: 0.3643\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 299 Total reward: 16.0 Average reward fake: 0.5106298923492432 Average reward real: 0.5036954283714294 Training q_loss: 83028.0156 Training g_loss: 0.6723 Training d_loss: 1.4191 Explore P: 0.3638\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 300 Total reward: 17.0 Average reward fake: 0.5618863105773926 Average reward real: 0.47553542256355286 Training q_loss: 114429.8906 Training g_loss: 0.6043 Training d_loss: 1.6291 Explore P: 0.3632\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 301 Total reward: 20.0 Average reward fake: 0.4880529046058655 Average reward real: 0.4714718759059906 Training q_loss: 51907.7695 Training g_loss: 0.7041 Training d_loss: 1.4622 Explore P: 0.3624\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 302 Total reward: 128.0 Average reward fake: 0.4950679540634155 Average reward real: 0.5227892994880676 Training q_loss: 44392.4414 Training g_loss: 0.7069 Training d_loss: 1.3443 Explore P: 0.3580\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 303 Total reward: 18.0 Average reward fake: 0.47328463196754456 Average reward real: 0.5009274482727051 Training q_loss: 33857.3047 Training g_loss: 0.7476 Training d_loss: 1.3405 Explore P: 0.3573\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 304 Total reward: 19.0 Average reward fake: 0.47222501039505005 Average reward real: 0.5279025435447693 Training q_loss: 140344.0938 Training g_loss: 0.7539 Training d_loss: 1.3039 Explore P: 0.3567\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 305 Total reward: 72.0 Average reward fake: 0.48880714178085327 Average reward real: 0.5300616025924683 Training q_loss: 417105.5312 Training g_loss: 0.7182 Training d_loss: 1.3299 Explore P: 0.3542\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 306 Total reward: 107.0 Average reward fake: 0.504669189453125 Average reward real: 0.5367529392242432 Training q_loss: 60598.8789 Training g_loss: 0.6787 Training d_loss: 1.3547 Explore P: 0.3505\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 307 Total reward: 66.0 Average reward fake: 0.4662092328071594 Average reward real: 0.5754509568214417 Training q_loss: 184481.9531 Training g_loss: 0.7857 Training d_loss: 1.2535 Explore P: 0.3483\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 308 Total reward: 8.0 Average reward fake: 0.46463412046432495 Average reward real: 0.5567870140075684 Training q_loss: 56909.3359 Training g_loss: 0.7989 Training d_loss: 1.3472 Explore P: 0.3480\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 309 Total reward: 37.0 Average reward fake: 0.5132606029510498 Average reward real: 0.4713205099105835 Training q_loss: 155097.9062 Training g_loss: 0.6744 Training d_loss: 1.4824 Explore P: 0.3468\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 310 Total reward: 26.0 Average reward fake: 0.4920367896556854 Average reward real: 0.5360074639320374 Training q_loss: 115436.0781 Training g_loss: 0.7103 Training d_loss: 1.3134 Explore P: 0.3459\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 311 Total reward: 52.0 Average reward fake: 0.46326568722724915 Average reward real: 0.5340339541435242 Training q_loss: 23619.6230 Training g_loss: 0.7100 Training d_loss: 1.3466 Explore P: 0.3442\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 312 Total reward: 54.0 Average reward fake: 0.5125579833984375 Average reward real: 0.5275770425796509 Training q_loss: 77193.7969 Training g_loss: 0.6726 Training d_loss: 1.4048 Explore P: 0.3424\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 313 Total reward: 120.0 Average reward fake: 0.4622703492641449 Average reward real: 0.5072760581970215 Training q_loss: 29967.8691 Training g_loss: 0.7772 Training d_loss: 1.3332 Explore P: 0.3384\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 314 Total reward: 51.0 Average reward fake: 0.48867881298065186 Average reward real: 0.49964281916618347 Training q_loss: 45584.7266 Training g_loss: 0.7235 Training d_loss: 1.4447 Explore P: 0.3367\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 315 Total reward: 86.0 Average reward fake: 0.5003856420516968 Average reward real: 0.5317049026489258 Training q_loss: 198876.3594 Training g_loss: 0.6947 Training d_loss: 1.4281 Explore P: 0.3339\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 316 Total reward: 56.0 Average reward fake: 0.4730379581451416 Average reward real: 0.5443986654281616 Training q_loss: 28357.5957 Training g_loss: 0.7527 Training d_loss: 1.2748 Explore P: 0.3321\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 317 Total reward: 52.0 Average reward fake: 0.5017967224121094 Average reward real: 0.4757692813873291 Training q_loss: 41529.4961 Training g_loss: 0.7875 Training d_loss: 1.6174 Explore P: 0.3304\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 318 Total reward: 138.0 Average reward fake: 0.4876635670661926 Average reward real: 0.5212182402610779 Training q_loss: 33850.3125 Training g_loss: 0.7444 Training d_loss: 1.3245 Explore P: 0.3261\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 319 Total reward: 49.0 Average reward fake: 0.5007582902908325 Average reward real: 0.5120643377304077 Training q_loss: 53893.1719 Training g_loss: 0.7731 Training d_loss: 1.4059 Explore P: 0.3245\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 320 Total reward: 152.0 Average reward fake: 0.41035568714141846 Average reward real: 0.5978128910064697 Training q_loss: 40234.4805 Training g_loss: 0.8904 Training d_loss: 1.0838 Explore P: 0.3198\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 321 Total reward: 16.0 Average reward fake: 0.4280773103237152 Average reward real: 0.6245277523994446 Training q_loss: 47418.7539 Training g_loss: 0.8690 Training d_loss: 1.0693 Explore P: 0.3193\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 322 Total reward: 175.0 Average reward fake: 0.3818042278289795 Average reward real: 0.44590163230895996 Training q_loss: 50387.7695 Training g_loss: 1.0276 Training d_loss: 1.6581 Explore P: 0.3139\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 323 Total reward: 55.0 Average reward fake: 0.5148491263389587 Average reward real: 0.486601859331131 Training q_loss: 208174.4062 Training g_loss: 0.7095 Training d_loss: 1.7114 Explore P: 0.3122\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 324 Total reward: 112.0 Average reward fake: 0.45223838090896606 Average reward real: 0.5073229074478149 Training q_loss: 24800.1582 Training g_loss: 0.7968 Training d_loss: 1.3703 Explore P: 0.3089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 325 Total reward: 62.0 Average reward fake: 0.4932177662849426 Average reward real: 0.42863890528678894 Training q_loss: 103711.1328 Training g_loss: 0.7156 Training d_loss: 1.6391 Explore P: 0.3070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 326 Total reward: 14.0 Average reward fake: 0.5359867811203003 Average reward real: 0.39268919825553894 Training q_loss: 1369515.6250 Training g_loss: 0.6021 Training d_loss: 1.8678 Explore P: 0.3066\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 327 Total reward: 13.0 Average reward fake: 0.49018236994743347 Average reward real: 0.5937126874923706 Training q_loss: 183362.5625 Training g_loss: 0.7213 Training d_loss: 1.2212 Explore P: 0.3062\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 328 Total reward: 199.0 Average reward fake: 0.4503503441810608 Average reward real: 0.4972795248031616 Training q_loss: 37085.1367 Training g_loss: 0.7978 Training d_loss: 1.3664 Explore P: 0.3004\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 329 Total reward: 57.0 Average reward fake: 0.43811312317848206 Average reward real: 0.5429359674453735 Training q_loss: 273487.8125 Training g_loss: 0.8310 Training d_loss: 1.2618 Explore P: 0.2987\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 330 Total reward: 34.0 Average reward fake: 0.5463889837265015 Average reward real: 0.47223010659217834 Training q_loss: 43340.6484 Training g_loss: 0.6151 Training d_loss: 1.6507 Explore P: 0.2978\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 331 Total reward: 17.0 Average reward fake: 0.48095497488975525 Average reward real: 0.513731062412262 Training q_loss: 76347.3203 Training g_loss: 0.7505 Training d_loss: 1.3983 Explore P: 0.2973\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 332 Total reward: 20.0 Average reward fake: 0.45347797870635986 Average reward real: 0.6211364269256592 Training q_loss: 27588.9180 Training g_loss: 0.8073 Training d_loss: 1.0971 Explore P: 0.2967\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 333 Total reward: 176.0 Average reward fake: 0.3982621729373932 Average reward real: 0.5832953453063965 Training q_loss: 114363.1562 Training g_loss: 0.9444 Training d_loss: 1.1093 Explore P: 0.2917\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 334 Total reward: 52.0 Average reward fake: 0.49274957180023193 Average reward real: 0.463492214679718 Training q_loss: 46201.5586 Training g_loss: 0.7209 Training d_loss: 1.5004 Explore P: 0.2902\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 335 Total reward: 12.0 Average reward fake: 0.4968777596950531 Average reward real: 0.4886837303638458 Training q_loss: 40732.9102 Training g_loss: 0.7250 Training d_loss: 1.4697 Explore P: 0.2899\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 336 Total reward: 12.0 Average reward fake: 0.44894731044769287 Average reward real: 0.522795557975769 Training q_loss: 202154.3750 Training g_loss: 0.8367 Training d_loss: 1.3469 Explore P: 0.2896\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 337 Total reward: 188.0 Average reward fake: 0.3984156548976898 Average reward real: 0.5580739378929138 Training q_loss: 162358.5312 Training g_loss: 0.9229 Training d_loss: 1.1502 Explore P: 0.2844\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 338 Total reward: 137.0 Average reward fake: 0.42969807982444763 Average reward real: 0.5847991108894348 Training q_loss: 27071.9727 Training g_loss: 0.8867 Training d_loss: 1.1662 Explore P: 0.2806\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 339 Total reward: 112.0 Average reward fake: 0.47605404257774353 Average reward real: 0.523735761642456 Training q_loss: 36782.9375 Training g_loss: 0.7438 Training d_loss: 1.3142 Explore P: 0.2776\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 340 Total reward: 57.0 Average reward fake: 0.4574366509914398 Average reward real: 0.5526909828186035 Training q_loss: 389935.4062 Training g_loss: 0.7746 Training d_loss: 1.2472 Explore P: 0.2761\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 341 Total reward: 119.0 Average reward fake: 0.421297162771225 Average reward real: 0.5399346351623535 Training q_loss: 409493.2500 Training g_loss: 0.9379 Training d_loss: 1.3061 Explore P: 0.2729\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 342 Total reward: 46.0 Average reward fake: 0.4948342442512512 Average reward real: 0.5204816460609436 Training q_loss: 31225.9668 Training g_loss: 0.7057 Training d_loss: 1.3625 Explore P: 0.2717\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 343 Total reward: 68.0 Average reward fake: 0.45273837447166443 Average reward real: 0.5399884581565857 Training q_loss: 62513.2969 Training g_loss: 0.8047 Training d_loss: 1.2364 Explore P: 0.2700\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 344 Total reward: 74.0 Average reward fake: 0.27057695388793945 Average reward real: 0.6784678101539612 Training q_loss: 94994.2891 Training g_loss: 2.6899 Training d_loss: 1.2066 Explore P: 0.2680\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 345 Total reward: 110.0 Average reward fake: 0.4610360860824585 Average reward real: 0.542624294757843 Training q_loss: 235757.4375 Training g_loss: 0.7933 Training d_loss: 1.2770 Explore P: 0.2652\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 346 Total reward: 120.0 Average reward fake: 0.5115384459495544 Average reward real: 0.5030354857444763 Training q_loss: 156322.8750 Training g_loss: 0.6685 Training d_loss: 1.4437 Explore P: 0.2622\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 347 Total reward: 41.0 Average reward fake: 0.47753646969795227 Average reward real: 0.5132618546485901 Training q_loss: 481917.0938 Training g_loss: 0.7590 Training d_loss: 1.3759 Explore P: 0.2611\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 348 Total reward: 137.0 Average reward fake: 0.539053201675415 Average reward real: 0.5064117312431335 Training q_loss: 26033.4082 Training g_loss: 0.6163 Training d_loss: 1.4770 Explore P: 0.2577\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 349 Total reward: 199.0 Average reward fake: 0.44644707441329956 Average reward real: 0.4953012466430664 Training q_loss: 64564.8398 Training g_loss: 0.8064 Training d_loss: 1.2983 Explore P: 0.2528\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 350 Total reward: 24.0 Average reward fake: 0.38029420375823975 Average reward real: 0.5635999441146851 Training q_loss: 675098.5625 Training g_loss: 0.9863 Training d_loss: 1.1371 Explore P: 0.2523\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 351 Total reward: 199.0 Average reward fake: 0.45530834794044495 Average reward real: 0.6262979507446289 Training q_loss: 27072.7793 Training g_loss: 1.2772 Training d_loss: 1.5935 Explore P: 0.2475\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 352 Total reward: 28.0 Average reward fake: 0.5547390580177307 Average reward real: 0.3458143472671509 Training q_loss: 22931.2031 Training g_loss: 0.6308 Training d_loss: 2.0072 Explore P: 0.2468\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 353 Total reward: 15.0 Average reward fake: 0.36732810735702515 Average reward real: 0.6669061779975891 Training q_loss: 36293.8242 Training g_loss: 1.3561 Training d_loss: 1.0056 Explore P: 0.2465\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 354 Total reward: 26.0 Average reward fake: 0.4454226791858673 Average reward real: 0.6064485907554626 Training q_loss: 26908.3555 Training g_loss: 0.9440 Training d_loss: 1.1638 Explore P: 0.2459\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 355 Total reward: 61.0 Average reward fake: 0.43263471126556396 Average reward real: 0.5605553984642029 Training q_loss: 54219.7617 Training g_loss: 0.8431 Training d_loss: 1.1881 Explore P: 0.2444\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 356 Total reward: 11.0 Average reward fake: 0.47401711344718933 Average reward real: 0.5214551091194153 Training q_loss: 33728.6992 Training g_loss: 0.7327 Training d_loss: 1.4028 Explore P: 0.2442\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 357 Total reward: 199.0 Average reward fake: 0.4066880941390991 Average reward real: 0.5290789604187012 Training q_loss: 75428.4531 Training g_loss: 0.9315 Training d_loss: 1.2125 Explore P: 0.2395\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 358 Total reward: 74.0 Average reward fake: 0.5036118030548096 Average reward real: 0.5075827836990356 Training q_loss: 82076.2734 Training g_loss: 0.6917 Training d_loss: 1.4407 Explore P: 0.2379\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 359 Total reward: 42.0 Average reward fake: 0.49025917053222656 Average reward real: 0.47942885756492615 Training q_loss: 109367.6328 Training g_loss: 0.7110 Training d_loss: 1.4553 Explore P: 0.2369\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 360 Total reward: 18.0 Average reward fake: 0.5242645740509033 Average reward real: 0.4987836182117462 Training q_loss: 286458.2812 Training g_loss: 0.6444 Training d_loss: 1.4630 Explore P: 0.2365\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 361 Total reward: 12.0 Average reward fake: 0.5153083205223083 Average reward real: 0.4684228003025055 Training q_loss: 51317.5234 Training g_loss: 0.6678 Training d_loss: 1.5085 Explore P: 0.2362\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 362 Total reward: 199.0 Average reward fake: 0.46758636832237244 Average reward real: 0.45616546273231506 Training q_loss: 124013.3203 Training g_loss: 0.7598 Training d_loss: 1.5174 Explore P: 0.2318\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 363 Total reward: 176.0 Average reward fake: 0.333283007144928 Average reward real: 0.7274799942970276 Training q_loss: 33384.8164 Training g_loss: 1.0997 Training d_loss: 0.8104 Explore P: 0.2279\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 364 Total reward: 199.0 Average reward fake: 0.3317056894302368 Average reward real: 0.5098119974136353 Training q_loss: 18453.9473 Training g_loss: 1.2530 Training d_loss: 1.4142 Explore P: 0.2236\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 365 Total reward: 13.0 Average reward fake: 0.406113862991333 Average reward real: 0.6363265514373779 Training q_loss: 113264.1094 Training g_loss: 1.0777 Training d_loss: 1.4508 Explore P: 0.2233\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 366 Total reward: 45.0 Average reward fake: 0.36369797587394714 Average reward real: 0.6427425146102905 Training q_loss: 59707.3281 Training g_loss: 1.0185 Training d_loss: 0.9791 Explore P: 0.2224\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 367 Total reward: 115.0 Average reward fake: 0.4937279522418976 Average reward real: 0.5141642689704895 Training q_loss: 106671.1406 Training g_loss: 0.7056 Training d_loss: 1.3865 Explore P: 0.2199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 368 Total reward: 51.0 Average reward fake: 0.40119078755378723 Average reward real: 0.5432077646255493 Training q_loss: 87412.6172 Training g_loss: 0.9140 Training d_loss: 1.2206 Explore P: 0.2189\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 369 Total reward: 150.0 Average reward fake: 0.415414035320282 Average reward real: 0.5622451305389404 Training q_loss: 276266.9062 Training g_loss: 0.8793 Training d_loss: 1.1672 Explore P: 0.2158\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 370 Total reward: 199.0 Average reward fake: 0.38694486021995544 Average reward real: 0.5911282300949097 Training q_loss: 39082.2852 Training g_loss: 0.9515 Training d_loss: 1.0634 Explore P: 0.2117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 371 Total reward: 67.0 Average reward fake: 0.4882165193557739 Average reward real: 0.5271481871604919 Training q_loss: 160574.4844 Training g_loss: 0.7174 Training d_loss: 1.3375 Explore P: 0.2104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 372 Total reward: 132.0 Average reward fake: 0.3758843243122101 Average reward real: 0.6132045984268188 Training q_loss: 166422.1875 Training g_loss: 0.9899 Training d_loss: 1.0189 Explore P: 0.2077\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 373 Total reward: 131.0 Average reward fake: 0.35333624482154846 Average reward real: 0.7308238744735718 Training q_loss: 23558.1152 Training g_loss: 1.2657 Training d_loss: 1.3066 Explore P: 0.2052\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 374 Total reward: 58.0 Average reward fake: 0.36455070972442627 Average reward real: 0.5839511752128601 Training q_loss: 40737.6680 Training g_loss: 1.0106 Training d_loss: 1.1335 Explore P: 0.2040\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 375 Total reward: 173.0 Average reward fake: 0.4788331687450409 Average reward real: 0.5392467975616455 Training q_loss: 234082.7969 Training g_loss: 0.7382 Training d_loss: 1.3285 Explore P: 0.2007\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 376 Total reward: 170.0 Average reward fake: 0.4563569724559784 Average reward real: 0.5868571400642395 Training q_loss: 105242.6016 Training g_loss: 0.7874 Training d_loss: 1.1775 Explore P: 0.1975\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 377 Total reward: 64.0 Average reward fake: 0.4201546609401703 Average reward real: 0.5970463752746582 Training q_loss: 26246.1172 Training g_loss: 0.8615 Training d_loss: 1.1182 Explore P: 0.1963\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 378 Total reward: 108.0 Average reward fake: 0.29079052805900574 Average reward real: 0.7469245195388794 Training q_loss: 23169.5098 Training g_loss: 1.4209 Training d_loss: 0.6944 Explore P: 0.1943\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 379 Total reward: 85.0 Average reward fake: 0.4002797603607178 Average reward real: 0.5169293284416199 Training q_loss: 117870.5625 Training g_loss: 1.5522 Training d_loss: 1.3192 Explore P: 0.1927\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 380 Total reward: 75.0 Average reward fake: 0.45932498574256897 Average reward real: 0.5692633390426636 Training q_loss: 79970.0156 Training g_loss: 0.8837 Training d_loss: 1.2199 Explore P: 0.1914\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 381 Total reward: 140.0 Average reward fake: 0.44632434844970703 Average reward real: 0.5507457852363586 Training q_loss: 22669.2656 Training g_loss: 0.8075 Training d_loss: 1.2063 Explore P: 0.1888\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 382 Total reward: 13.0 Average reward fake: 0.45141762495040894 Average reward real: 0.5720477104187012 Training q_loss: 41539.5820 Training g_loss: 0.7970 Training d_loss: 1.1805 Explore P: 0.1886\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 383 Total reward: 19.0 Average reward fake: 0.45793211460113525 Average reward real: 0.5440915822982788 Training q_loss: 33054.3477 Training g_loss: 0.7823 Training d_loss: 1.2708 Explore P: 0.1883\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 384 Total reward: 85.0 Average reward fake: 0.46958550810813904 Average reward real: 0.5039744973182678 Training q_loss: 41565.0938 Training g_loss: 0.7663 Training d_loss: 1.3460 Explore P: 0.1868\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 385 Total reward: 115.0 Average reward fake: 0.47490566968917847 Average reward real: 0.5967117547988892 Training q_loss: 57904.2539 Training g_loss: 0.7581 Training d_loss: 1.2062 Explore P: 0.1847\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 386 Total reward: 197.0 Average reward fake: 0.4097231924533844 Average reward real: 0.5779200196266174 Training q_loss: 21649.2598 Training g_loss: 0.9313 Training d_loss: 1.1253 Explore P: 0.1813\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 387 Total reward: 199.0 Average reward fake: 0.3649049401283264 Average reward real: 0.6065981984138489 Training q_loss: 46233.0000 Training g_loss: 1.0534 Training d_loss: 1.0454 Explore P: 0.1780\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 388 Total reward: 194.0 Average reward fake: 0.4089376926422119 Average reward real: 0.6011000871658325 Training q_loss: 29183.0605 Training g_loss: 0.8967 Training d_loss: 1.0860 Explore P: 0.1747\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 389 Total reward: 44.0 Average reward fake: 0.3018464744091034 Average reward real: 0.5616788268089294 Training q_loss: 28281.9746 Training g_loss: 1.2473 Training d_loss: 1.0646 Explore P: 0.1740\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 390 Total reward: 169.0 Average reward fake: 0.13932403922080994 Average reward real: 0.44541874527931213 Training q_loss: 96939.9688 Training g_loss: 3.4540 Training d_loss: 1.1297 Explore P: 0.1713\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 391 Total reward: 166.0 Average reward fake: 0.5688669681549072 Average reward real: 0.42355355620384216 Training q_loss: 93590.3281 Training g_loss: 0.5794 Training d_loss: 1.9147 Explore P: 0.1686\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 392 Total reward: 191.0 Average reward fake: 0.41405293345451355 Average reward real: 0.5944864749908447 Training q_loss: 18855.5352 Training g_loss: 0.8804 Training d_loss: 1.1089 Explore P: 0.1656\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 393 Total reward: 199.0 Average reward fake: 0.48910048604011536 Average reward real: 0.5086431503295898 Training q_loss: 316926.0000 Training g_loss: 0.7196 Training d_loss: 1.4153 Explore P: 0.1625\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 394 Total reward: 186.0 Average reward fake: 0.5428667664527893 Average reward real: 0.47739723324775696 Training q_loss: 25397.4375 Training g_loss: 0.6231 Training d_loss: 1.6514 Explore P: 0.1597\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 395 Total reward: 23.0 Average reward fake: 0.5033090710639954 Average reward real: 0.5136786699295044 Training q_loss: 138349.7344 Training g_loss: 0.7252 Training d_loss: 1.6114 Explore P: 0.1594\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 396 Total reward: 199.0 Average reward fake: 0.47282546758651733 Average reward real: 0.4729393720626831 Training q_loss: 101392.3594 Training g_loss: 0.7535 Training d_loss: 1.4444 Explore P: 0.1564\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 397 Total reward: 199.0 Average reward fake: 0.4198512136936188 Average reward real: 0.5161307454109192 Training q_loss: 82449.2656 Training g_loss: 0.8671 Training d_loss: 1.2701 Explore P: 0.1536\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 398 Total reward: 199.0 Average reward fake: 0.3766983151435852 Average reward real: 0.5963813066482544 Training q_loss: 191392.7812 Training g_loss: 0.9966 Training d_loss: 1.1410 Explore P: 0.1507\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 399 Total reward: 141.0 Average reward fake: 0.4191318452358246 Average reward real: 0.5082193613052368 Training q_loss: 38082.4531 Training g_loss: 0.8720 Training d_loss: 1.2588 Explore P: 0.1488\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 400 Total reward: 81.0 Average reward fake: 0.4444258511066437 Average reward real: 0.6071032285690308 Training q_loss: 131782.4062 Training g_loss: 0.8121 Training d_loss: 1.2247 Explore P: 0.1476\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 401 Total reward: 45.0 Average reward fake: 0.38820022344589233 Average reward real: 0.6067907810211182 Training q_loss: 240723.5000 Training g_loss: 0.9591 Training d_loss: 1.0857 Explore P: 0.1470\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 402 Total reward: 197.0 Average reward fake: 0.42639052867889404 Average reward real: 0.5709902048110962 Training q_loss: 59898.8594 Training g_loss: 0.8520 Training d_loss: 1.2015 Explore P: 0.1443\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 403 Total reward: 190.0 Average reward fake: 0.5286935567855835 Average reward real: 0.465525358915329 Training q_loss: 41032.4141 Training g_loss: 0.6374 Training d_loss: 1.5388 Explore P: 0.1418\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 404 Total reward: 199.0 Average reward fake: 0.46095138788223267 Average reward real: 0.5440036058425903 Training q_loss: 33039.7695 Training g_loss: 0.7697 Training d_loss: 1.2769 Explore P: 0.1392\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 405 Total reward: 199.0 Average reward fake: 0.5036767721176147 Average reward real: 0.4814274311065674 Training q_loss: 79098.4141 Training g_loss: 0.7406 Training d_loss: 1.6403 Explore P: 0.1367\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 406 Total reward: 11.0 Average reward fake: 0.45267271995544434 Average reward real: 0.5823806524276733 Training q_loss: 53764.2617 Training g_loss: 0.7937 Training d_loss: 1.2228 Explore P: 0.1365\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 407 Total reward: 98.0 Average reward fake: 0.5012983679771423 Average reward real: 0.5367223620414734 Training q_loss: 343196.9062 Training g_loss: 0.7032 Training d_loss: 1.4065 Explore P: 0.1353\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 408 Total reward: 178.0 Average reward fake: 0.389657586812973 Average reward real: 0.6307843923568726 Training q_loss: 38532.9180 Training g_loss: 0.9434 Training d_loss: 0.9965 Explore P: 0.1331\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 409 Total reward: 199.0 Average reward fake: 0.5650225281715393 Average reward real: 0.34543558955192566 Training q_loss: 33683.0469 Training g_loss: 0.5710 Training d_loss: 2.2141 Explore P: 0.1307\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 410 Total reward: 199.0 Average reward fake: 0.45196205377578735 Average reward real: 0.5817248821258545 Training q_loss: 138184.0625 Training g_loss: 0.9081 Training d_loss: 1.3511 Explore P: 0.1283\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 411 Total reward: 199.0 Average reward fake: 0.3874988555908203 Average reward real: 0.6105287075042725 Training q_loss: 45410.8594 Training g_loss: 0.9634 Training d_loss: 1.0789 Explore P: 0.1260\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 412 Total reward: 199.0 Average reward fake: 0.41943359375 Average reward real: 0.572777509689331 Training q_loss: 29297.1680 Training g_loss: 0.9387 Training d_loss: 1.1675 Explore P: 0.1237\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 413 Total reward: 47.0 Average reward fake: 0.49557697772979736 Average reward real: 0.5410616993904114 Training q_loss: 35698.4219 Training g_loss: 0.7409 Training d_loss: 1.3260 Explore P: 0.1231\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 414 Total reward: 173.0 Average reward fake: 0.37914931774139404 Average reward real: 0.5764615535736084 Training q_loss: 70377.7188 Training g_loss: 1.0711 Training d_loss: 1.1124 Explore P: 0.1212\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 415 Total reward: 173.0 Average reward fake: 0.48290306329727173 Average reward real: 0.5860592126846313 Training q_loss: 83043.0312 Training g_loss: 0.7338 Training d_loss: 1.2395 Explore P: 0.1193\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 416 Total reward: 199.0 Average reward fake: 0.37881454825401306 Average reward real: 0.5507543087005615 Training q_loss: 191308.7188 Training g_loss: 0.9792 Training d_loss: 1.1325 Explore P: 0.1171\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 417 Total reward: 199.0 Average reward fake: 0.4535426199436188 Average reward real: 0.5417377352714539 Training q_loss: 224072.7656 Training g_loss: 0.8617 Training d_loss: 1.4194 Explore P: 0.1150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 418 Total reward: 199.0 Average reward fake: 0.5867812633514404 Average reward real: 0.4046725928783417 Training q_loss: 169130.5156 Training g_loss: 0.5386 Training d_loss: 2.0392 Explore P: 0.1130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 419 Total reward: 199.0 Average reward fake: 0.4762040972709656 Average reward real: 0.5143377780914307 Training q_loss: 131358.3125 Training g_loss: 0.8045 Training d_loss: 1.3613 Explore P: 0.1109\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 420 Total reward: 199.0 Average reward fake: 0.41658785939216614 Average reward real: 0.5029421448707581 Training q_loss: 97918.2188 Training g_loss: 0.8909 Training d_loss: 1.3114 Explore P: 0.1089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 421 Total reward: 177.0 Average reward fake: 0.4368992745876312 Average reward real: 0.6342270374298096 Training q_loss: 245585.0469 Training g_loss: 0.8630 Training d_loss: 1.1383 Explore P: 0.1072\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 422 Total reward: 199.0 Average reward fake: 0.37966644763946533 Average reward real: 0.5672011375427246 Training q_loss: 150605.4844 Training g_loss: 1.0019 Training d_loss: 1.0985 Explore P: 0.1053\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 423 Total reward: 159.0 Average reward fake: 0.30151909589767456 Average reward real: 0.6654371619224548 Training q_loss: 95674.7969 Training g_loss: 2.1580 Training d_loss: 1.2003 Explore P: 0.1038\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 424 Total reward: 90.0 Average reward fake: 0.26327526569366455 Average reward real: 0.7356454730033875 Training q_loss: 401123.7188 Training g_loss: 2.6556 Training d_loss: 0.8271 Explore P: 0.1029\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 425 Total reward: 199.0 Average reward fake: 0.35821107029914856 Average reward real: 0.6862762570381165 Training q_loss: 127330.8984 Training g_loss: 1.1343 Training d_loss: 0.9068 Explore P: 0.1011\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 426 Total reward: 27.0 Average reward fake: 0.4100269675254822 Average reward real: 0.5585445165634155 Training q_loss: 47621.2109 Training g_loss: 0.9253 Training d_loss: 1.2989 Explore P: 0.1009\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 427 Total reward: 199.0 Average reward fake: 0.44331783056259155 Average reward real: 0.5019479393959045 Training q_loss: 214588.1562 Training g_loss: 0.8279 Training d_loss: 1.3661 Explore P: 0.0991\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 428 Total reward: 199.0 Average reward fake: 0.5468499064445496 Average reward real: 0.46054208278656006 Training q_loss: 315804.2812 Training g_loss: 0.6190 Training d_loss: 1.8418 Explore P: 0.0973\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 429 Total reward: 199.0 Average reward fake: 0.49478253722190857 Average reward real: 0.5055248141288757 Training q_loss: 46815.6406 Training g_loss: 0.7038 Training d_loss: 1.4332 Explore P: 0.0956\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 430 Total reward: 199.0 Average reward fake: 0.3758724331855774 Average reward real: 0.6222010850906372 Training q_loss: 224081.5625 Training g_loss: 0.9807 Training d_loss: 0.9766 Explore P: 0.0939\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 431 Total reward: 110.0 Average reward fake: 0.5035315752029419 Average reward real: 0.47803643345832825 Training q_loss: 148137.6562 Training g_loss: 0.6935 Training d_loss: 1.5092 Explore P: 0.0930\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 432 Total reward: 23.0 Average reward fake: 0.5031148791313171 Average reward real: 0.5017635822296143 Training q_loss: 72015.3438 Training g_loss: 0.6857 Training d_loss: 1.4157 Explore P: 0.0928\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 433 Total reward: 199.0 Average reward fake: 0.47935283184051514 Average reward real: 0.528770387172699 Training q_loss: 144715.5625 Training g_loss: 0.7447 Training d_loss: 1.2939 Explore P: 0.0912\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 434 Total reward: 142.0 Average reward fake: 0.43245577812194824 Average reward real: 0.5578967332839966 Training q_loss: 184626.7344 Training g_loss: 0.8600 Training d_loss: 1.4246 Explore P: 0.0900\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 435 Total reward: 199.0 Average reward fake: 0.43901360034942627 Average reward real: 0.5562564134597778 Training q_loss: 120658.3281 Training g_loss: 0.8628 Training d_loss: 1.2010 Explore P: 0.0885\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 436 Total reward: 156.0 Average reward fake: 0.5124927759170532 Average reward real: 0.4994758665561676 Training q_loss: 44438.0469 Training g_loss: 0.7261 Training d_loss: 1.6028 Explore P: 0.0872\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 437 Total reward: 97.0 Average reward fake: 0.49622008204460144 Average reward real: 0.5139579772949219 Training q_loss: 255627.2344 Training g_loss: 0.7086 Training d_loss: 1.3952 Explore P: 0.0865\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 438 Total reward: 104.0 Average reward fake: 0.41428142786026 Average reward real: 0.5432083010673523 Training q_loss: 66154.1484 Training g_loss: 0.8948 Training d_loss: 1.1748 Explore P: 0.0857\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 439 Total reward: 103.0 Average reward fake: 0.4139382541179657 Average reward real: 0.531566858291626 Training q_loss: 29515.2227 Training g_loss: 0.9112 Training d_loss: 1.2178 Explore P: 0.0849\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 440 Total reward: 199.0 Average reward fake: 0.43154770135879517 Average reward real: 0.5370628237724304 Training q_loss: 25062.3867 Training g_loss: 0.8708 Training d_loss: 1.2137 Explore P: 0.0835\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 441 Total reward: 148.0 Average reward fake: 0.5525180101394653 Average reward real: 0.5408799052238464 Training q_loss: 347705.6875 Training g_loss: 0.5995 Training d_loss: 1.5358 Explore P: 0.0824\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 442 Total reward: 199.0 Average reward fake: 0.38416942954063416 Average reward real: 0.6029402017593384 Training q_loss: 20055.0176 Training g_loss: 1.0765 Training d_loss: 1.1285 Explore P: 0.0809\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 443 Total reward: 199.0 Average reward fake: 0.4508899748325348 Average reward real: 0.4839240312576294 Training q_loss: 25523.4082 Training g_loss: 0.8009 Training d_loss: 1.3530 Explore P: 0.0795\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 444 Total reward: 199.0 Average reward fake: 0.4289819300174713 Average reward real: 0.5747536420822144 Training q_loss: 106922.9297 Training g_loss: 0.8442 Training d_loss: 1.1584 Explore P: 0.0782\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 445 Total reward: 199.0 Average reward fake: 0.42706596851348877 Average reward real: 0.5733436346054077 Training q_loss: 244047.3125 Training g_loss: 0.8522 Training d_loss: 1.1844 Explore P: 0.0768\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 446 Total reward: 199.0 Average reward fake: 0.3639944791793823 Average reward real: 0.6741456389427185 Training q_loss: 93720.5312 Training g_loss: 1.0505 Training d_loss: 0.9491 Explore P: 0.0755\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 447 Total reward: 145.0 Average reward fake: 0.3484172523021698 Average reward real: 0.6138652563095093 Training q_loss: 20377.4434 Training g_loss: 1.0665 Training d_loss: 0.9849 Explore P: 0.0746\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 448 Total reward: 199.0 Average reward fake: 0.3708203434944153 Average reward real: 0.5567346811294556 Training q_loss: 68752.3438 Training g_loss: 0.9932 Training d_loss: 1.2479 Explore P: 0.0733\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 449 Total reward: 199.0 Average reward fake: 0.3375053107738495 Average reward real: 0.6299034953117371 Training q_loss: 38868.1016 Training g_loss: 1.1351 Training d_loss: 0.9635 Explore P: 0.0721\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 450 Total reward: 133.0 Average reward fake: 0.29365596175193787 Average reward real: 0.6774360537528992 Training q_loss: 317368.6875 Training g_loss: 1.3102 Training d_loss: 0.8931 Explore P: 0.0712\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 451 Total reward: 199.0 Average reward fake: 0.4677561819553375 Average reward real: 0.576650857925415 Training q_loss: 64095.4102 Training g_loss: 0.8028 Training d_loss: 1.4093 Explore P: 0.0700\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 452 Total reward: 199.0 Average reward fake: 0.3975070118904114 Average reward real: 0.6070406436920166 Training q_loss: 73090.5781 Training g_loss: 0.9327 Training d_loss: 1.1050 Explore P: 0.0688\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 453 Total reward: 152.0 Average reward fake: 0.2588200867176056 Average reward real: 0.8720138669013977 Training q_loss: 392401.2812 Training g_loss: 4.8453 Training d_loss: 1.9096 Explore P: 0.0680\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 454 Total reward: 190.0 Average reward fake: 0.1531829982995987 Average reward real: 0.860586404800415 Training q_loss: 33187.2617 Training g_loss: 6.0366 Training d_loss: 0.5061 Explore P: 0.0669\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 455 Total reward: 199.0 Average reward fake: 0.36453115940093994 Average reward real: 0.5462458729743958 Training q_loss: 39813.8281 Training g_loss: 1.0166 Training d_loss: 1.2891 Explore P: 0.0657\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 456 Total reward: 190.0 Average reward fake: 0.4389474391937256 Average reward real: 0.6172534823417664 Training q_loss: 14809.0195 Training g_loss: 0.8463 Training d_loss: 1.1124 Explore P: 0.0647\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 457 Total reward: 199.0 Average reward fake: 0.44703078269958496 Average reward real: 0.5790616273880005 Training q_loss: 26589.7871 Training g_loss: 0.8035 Training d_loss: 1.1675 Explore P: 0.0636\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 458 Total reward: 102.0 Average reward fake: 0.42814624309539795 Average reward real: 0.5396589636802673 Training q_loss: 22023.8359 Training g_loss: 0.8544 Training d_loss: 1.2402 Explore P: 0.0631\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 459 Total reward: 199.0 Average reward fake: 0.4174966514110565 Average reward real: 0.6087827682495117 Training q_loss: 151640.5469 Training g_loss: 0.8780 Training d_loss: 1.1003 Explore P: 0.0620\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 460 Total reward: 92.0 Average reward fake: 0.37949812412261963 Average reward real: 0.6130208373069763 Training q_loss: 92676.0234 Training g_loss: 0.9690 Training d_loss: 1.0389 Explore P: 0.0616\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 461 Total reward: 199.0 Average reward fake: 0.4302898049354553 Average reward real: 0.5685127377510071 Training q_loss: 42653.6094 Training g_loss: 0.8247 Training d_loss: 1.2098 Explore P: 0.0605\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 462 Total reward: 199.0 Average reward fake: 0.3673638105392456 Average reward real: 0.6343520879745483 Training q_loss: 35936.8398 Training g_loss: 1.0175 Training d_loss: 0.9507 Explore P: 0.0595\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 463 Total reward: 120.0 Average reward fake: 0.40685150027275085 Average reward real: 0.6085755825042725 Training q_loss: 37755.2891 Training g_loss: 0.9249 Training d_loss: 1.1431 Explore P: 0.0590\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 464 Total reward: 199.0 Average reward fake: 0.5260998606681824 Average reward real: 0.47742506861686707 Training q_loss: 70593.7812 Training g_loss: 0.6622 Training d_loss: 1.5613 Explore P: 0.0580\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 465 Total reward: 199.0 Average reward fake: 0.4004102647304535 Average reward real: 0.6011796593666077 Training q_loss: 56000.5391 Training g_loss: 0.9090 Training d_loss: 1.0693 Explore P: 0.0570\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 466 Total reward: 91.0 Average reward fake: 0.4801442623138428 Average reward real: 0.6395666599273682 Training q_loss: 12478.9326 Training g_loss: 0.7489 Training d_loss: 1.1707 Explore P: 0.0566\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 467 Total reward: 31.0 Average reward fake: 0.3489121198654175 Average reward real: 0.6238364577293396 Training q_loss: 61511.2695 Training g_loss: 1.1315 Training d_loss: 1.0434 Explore P: 0.0565\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 468 Total reward: 199.0 Average reward fake: 0.4155919551849365 Average reward real: 0.6326775550842285 Training q_loss: 33391.2031 Training g_loss: 0.8742 Training d_loss: 1.0794 Explore P: 0.0556\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 469 Total reward: 199.0 Average reward fake: 0.4212632477283478 Average reward real: 0.519879937171936 Training q_loss: 215489.1875 Training g_loss: 0.8958 Training d_loss: 1.3967 Explore P: 0.0547\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 470 Total reward: 195.0 Average reward fake: 0.48579925298690796 Average reward real: 0.5126503109931946 Training q_loss: 382238.1875 Training g_loss: 0.6689 Training d_loss: 2.0868 Explore P: 0.0538\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 471 Total reward: 199.0 Average reward fake: 0.43525978922843933 Average reward real: 0.569771945476532 Training q_loss: 78783.8984 Training g_loss: 0.8974 Training d_loss: 1.2478 Explore P: 0.0529\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 472 Total reward: 199.0 Average reward fake: 0.293932169675827 Average reward real: 0.6878393292427063 Training q_loss: 83265.8359 Training g_loss: 1.3369 Training d_loss: 0.8548 Explore P: 0.0521\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 473 Total reward: 199.0 Average reward fake: 0.46197327971458435 Average reward real: 0.5042141675949097 Training q_loss: 171891.4844 Training g_loss: 0.7900 Training d_loss: 1.4631 Explore P: 0.0513\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 474 Total reward: 179.0 Average reward fake: 0.44902151823043823 Average reward real: 0.6123626828193665 Training q_loss: 24793.9492 Training g_loss: 0.8005 Training d_loss: 1.1498 Explore P: 0.0505\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 475 Total reward: 199.0 Average reward fake: 0.46051526069641113 Average reward real: 0.5654289722442627 Training q_loss: 78321.9219 Training g_loss: 0.9116 Training d_loss: 1.3575 Explore P: 0.0497\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 476 Total reward: 108.0 Average reward fake: 0.3270225524902344 Average reward real: 0.6506608724594116 Training q_loss: 41508.5117 Training g_loss: 1.1967 Training d_loss: 0.9473 Explore P: 0.0493\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 477 Total reward: 107.0 Average reward fake: 0.4490392208099365 Average reward real: 0.5601370930671692 Training q_loss: 92004.6016 Training g_loss: 0.7965 Training d_loss: 1.2287 Explore P: 0.0489\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 478 Total reward: 199.0 Average reward fake: 0.3865358829498291 Average reward real: 0.5735450387001038 Training q_loss: 106525.2578 Training g_loss: 0.9517 Training d_loss: 1.1006 Explore P: 0.0481\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 479 Total reward: 199.0 Average reward fake: 0.4852312505245209 Average reward real: 0.5556799173355103 Training q_loss: 63610.0039 Training g_loss: 0.7401 Training d_loss: 1.3035 Explore P: 0.0474\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 480 Total reward: 174.0 Average reward fake: 0.4306771755218506 Average reward real: 0.592715322971344 Training q_loss: 15712.0986 Training g_loss: 0.8454 Training d_loss: 1.1493 Explore P: 0.0467\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 481 Total reward: 199.0 Average reward fake: 0.4415384531021118 Average reward real: 0.5006144642829895 Training q_loss: 226427.3438 Training g_loss: 0.8105 Training d_loss: 1.3810 Explore P: 0.0460\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 482 Total reward: 157.0 Average reward fake: 0.4013468027114868 Average reward real: 0.6239154934883118 Training q_loss: 32468.0781 Training g_loss: 1.0106 Training d_loss: 1.0243 Explore P: 0.0454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 483 Total reward: 199.0 Average reward fake: 0.4329601228237152 Average reward real: 0.5392753481864929 Training q_loss: 82299.3281 Training g_loss: 0.8419 Training d_loss: 1.2449 Explore P: 0.0447\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 484 Total reward: 152.0 Average reward fake: 0.40436771512031555 Average reward real: 0.5812719464302063 Training q_loss: 239675.4844 Training g_loss: 0.9944 Training d_loss: 1.2513 Explore P: 0.0442\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 485 Total reward: 199.0 Average reward fake: 0.3782581686973572 Average reward real: 0.6830610632896423 Training q_loss: 25685.0332 Training g_loss: 0.9624 Training d_loss: 0.9823 Explore P: 0.0435\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 486 Total reward: 199.0 Average reward fake: 0.32588231563568115 Average reward real: 0.6405627727508545 Training q_loss: 44553.4414 Training g_loss: 1.1298 Training d_loss: 0.8917 Explore P: 0.0429\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 487 Total reward: 199.0 Average reward fake: 0.3953200578689575 Average reward real: 0.6448988914489746 Training q_loss: 31667.2305 Training g_loss: 0.9501 Training d_loss: 0.9900 Explore P: 0.0422\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 488 Total reward: 173.0 Average reward fake: 0.3956359028816223 Average reward real: 0.5163432359695435 Training q_loss: 220093.7656 Training g_loss: 0.9215 Training d_loss: 1.5961 Explore P: 0.0417\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 489 Total reward: 199.0 Average reward fake: 0.03950902447104454 Average reward real: 0.9827970266342163 Training q_loss: 14194.1846 Training g_loss: 5.4060 Training d_loss: 0.0768 Explore P: 0.0411\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 490 Total reward: 199.0 Average reward fake: 0.3282488286495209 Average reward real: 0.6643283367156982 Training q_loss: 34075.4688 Training g_loss: 2.5615 Training d_loss: 0.9757 Explore P: 0.0404\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 491 Total reward: 199.0 Average reward fake: 0.3152220547199249 Average reward real: 0.6987394690513611 Training q_loss: 17198.5000 Training g_loss: 1.5939 Training d_loss: 0.9039 Explore P: 0.0398\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 492 Total reward: 199.0 Average reward fake: 0.5245954990386963 Average reward real: 0.42654433846473694 Training q_loss: 25247.7949 Training g_loss: 0.6391 Training d_loss: 1.7638 Explore P: 0.0393\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 493 Total reward: 192.0 Average reward fake: 0.3833841383457184 Average reward real: 0.6069907546043396 Training q_loss: 77341.5938 Training g_loss: 0.9669 Training d_loss: 1.0904 Explore P: 0.0387\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 494 Total reward: 199.0 Average reward fake: 0.5343547463417053 Average reward real: 0.47222769260406494 Training q_loss: 36817.2617 Training g_loss: 0.6293 Training d_loss: 1.6260 Explore P: 0.0381\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 495 Total reward: 199.0 Average reward fake: 0.5254296660423279 Average reward real: 0.47342926263809204 Training q_loss: 41564.5312 Training g_loss: 0.6494 Training d_loss: 1.5284 Explore P: 0.0376\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 496 Total reward: 149.0 Average reward fake: 0.5182042121887207 Average reward real: 0.4629780650138855 Training q_loss: 37598.6719 Training g_loss: 0.6575 Training d_loss: 1.5181 Explore P: 0.0372\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 497 Total reward: 144.0 Average reward fake: 0.5185964703559875 Average reward real: 0.47768867015838623 Training q_loss: 33489.7031 Training g_loss: 0.6547 Training d_loss: 1.5417 Explore P: 0.0368\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 498 Total reward: 199.0 Average reward fake: 0.4667387306690216 Average reward real: 0.47827279567718506 Training q_loss: 30450.9492 Training g_loss: 0.7616 Training d_loss: 1.3883 Explore P: 0.0363\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 499 Total reward: 13.0 Average reward fake: 0.45022132992744446 Average reward real: 0.5402811169624329 Training q_loss: 123921.5938 Training g_loss: 0.8046 Training d_loss: 1.2274 Explore P: 0.0362\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards and losses list for plotting\n",
    "rewards_list, rewards_fake_list, rewards_real_list = [], [], []\n",
    "q_loss_list, g_loss_list, d_loss_list = [], [], [] \n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #     # Initialize variables\n",
    "    #     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Restore/load the trained model \n",
    "    #saver.restore(sess, 'checkpoints/Q-GAN-cartpole.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        \n",
    "        # Env/agent steps/batches/minibatches\n",
    "        total_reward, rewards_fake_mean, rewards_real_mean = 0, 0, 0\n",
    "        q_loss, g_loss, d_loss = 0, 0, 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from model\n",
    "                feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "                actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "                action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Episode/epoch training is done/failed!\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Average reward fake: {}'.format(rewards_fake_mean),\n",
    "                      'Average reward real: {}'.format(rewards_real_mean),\n",
    "                      'Training q_loss: {:.4f}'.format(q_loss),\n",
    "                      'Training g_loss: {:.4f}'.format(g_loss),\n",
    "                      'Training d_loss: {:.4f}'.format(d_loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                \n",
    "                # total rewards and losses for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                rewards_fake_list.append((ep, rewards_fake_mean))\n",
    "                q_loss_list.append((ep, q_loss))\n",
    "                g_loss_list.append((ep, g_loss))\n",
    "                d_loss_list.append((ep, d_loss))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            #rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train the model\n",
    "            feed_dict = {model.states: states, model.next_states: next_states}\n",
    "            rewards_fake, rewards_real = sess.run([model.rewards_fake, model.rewards_real], feed_dict)\n",
    "            feed_dict={model.states: next_states}\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "\n",
    "            # Mean/average fake and real rewards or rewarded generated/given actions\n",
    "            rewards_fake_mean = np.mean(rewards_fake.reshape(-1))\n",
    "            rewards_real_mean = np.mean(rewards_real.reshape(-1))\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            next_actions_logits[episode_ends] = (0, 0) # NOTE: action size\n",
    "\n",
    "            # Bellman equation: Qt = Rt + max(Qt+1)\n",
    "            targetQs = rewards_fake.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "\n",
    "            # Updating the model\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions, \n",
    "                         model.targetQs: targetQs}\n",
    "            q_loss, _ = sess.run([model.q_loss, model.q_opt], feed_dict)\n",
    "            g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict)\n",
    "            d_loss, _ = sess.run([model.d_loss, model.d_opt], feed_dict)\n",
    "            \n",
    "    # Save the trained model\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Q losses')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(q_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Q losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'G losses')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXd8pFd5779nepFGXau2RVvd12uvu7GxDRiMcYCYgEMIcJM4QAglOFyThHZJ7k1uwKEluXFCDcU0gx3buMQ2mOK2Xtdt2qLVNvVVm97O/eOddzQzGkkzkmak0Tzfz2c/q3nnnfect/3Oc57znOcorTWCIAjC6sey3BUQBEEQyoMIviAIQpUggi8IglAliOALgiBUCSL4giAIVYIIviAIQpUggi8IglAliOALgiBUCSL4giAIVYJtuSuQSXNzs96wYcNyV0MQBKFieO6550a01i2F7LuiBH/Dhg3s2rVruashCIJQMSil+grdV1w6giAIVYIIviAIQpUggi8IglAliOALgiBUCSL4giAIVYIIviAIQpUggi8IglAliOALglAQ0WiUQCCw3NUQFoEIviAIBdHb28uJEyeWuxrCIhDBFwRBqBJE8AVBEKoEEXxBEIQqQQRfEAShShDBFwRBqBJE8AVBEKqEkgm+UmqbUuqFjH+TSqmPlKo8QRAEYW5KtgCK1voAcD6AUsoKnAR+WqryBEEQhLkpl0vnOuCw1rrglVkEQRCEpaVcgv8O4PtlKksQBEHIQ8kFXynlAG4CfjTL97cqpXYppXYNDw+XujqCIAhVSzks/DcAu7XWg/m+1FrfqbXeqbXe2dJS0MLrgiAIwgIoh+DfgrhzBEEQlp2SCr5SygO8Fri7lOUIgiAI81OysEwArXUQaCplGYIgCEJhyExbQRCEKkEEXxAEoUoQwRcEQagSRPAFQSgKrfVyV0FYICL4giAIVYIIviAIQpUggi8IglAliOALgiBUCSL4giAUhQzaVi4i+IIgCFWCCL4gCEKVIIIvCIJQJYjgC4JQFOLDr1xE8AVBEKoEEXxBEIQqQQRfEAShShDBFwShKLTWjI2NkUwml7sqQpGI4AuCUBR+v5+hoSFGRkaWuypCkYjgC4JQFPF4HJBonUqk1IuY1yulfqyU2q+U2qeUuqyU5QmCUHpMwbdarctcE6FYSrqIOfAl4EGt9c1KKQfgKXF5giCUmEQiAYjgVyIlE3yllA+4CngPgNY6CkRLVZ4gCOVBBL9yKaVLZyMwDHxDKfW8Uuo/lFLeEpYnCEIZMAVfqDxKKfg24ALgX7XWO4AAcHvuTkqpW5VSu5RSu4aHh0tYHUEQlgIR/MqllIJ/AjihtX469fnHGA1AFlrrO7XWO7XWO1taWkpYHUEQlgJT8CVKp/IomeBrrQeA40qpbalN1wF7S1WeIAiCMDeljtL5c+C7qQidI8B7S1yeIAiCMAslFXyt9QvAzlKWIQiCIBSGzLQVBEGoEkTwBUEQqgQRfKHiCYfDHDhwgEgkstxVEYQVjQi+UPH4/X4Apqamlrkm1YWEZVYeIvhCxWOxGI+xCJAgzI0IvlDxKKUAEXxBmA8RfKHiEcEXhMIQwRcqHhF8QSgMEXyh4hHBF4TCEMEXKh5T8GVR7fIiDWzlIYIvVDxi4QtCYYjgC6sGEXxBmBsRfGHVIIIvCHMjgi+sGkTwBWFuRPCFVYMIviDMjQi+sGoQwReEuRHBFyoeU+glLLO8SANbeYjgC6sGESBBmBsRfGHVIIIvCHNT0jVtlVJHgSkgAcS11rK+rVAyRPAFYW5KKvgprtFaj5ShHKHKEcGvDqamphgeHqa7uzs9y1ooDHHpCBWPCH11MTAwQCwWk0H6BVBqwdfAw0qp55RSt5a4LEEQyshyNbQi9Aun1C6dK7TWp5RSrcAjSqn9WusnMndINQS3Aqxbt67E1REEYbUgPbviKamFr7U+lfp/CPgpcHGefe7UWu/UWu9saWkpZXUEQRCqmpIJvlLKq5SqNf8GXge8UqryBEFY/YhVvzhK6dJZA/w0NYpuA76ntX6whOUJgrDKyRR8Ef/iKZnga62PANtLdXxBMJEXv3qQe704JCxTEISKRMS/eETwBUFYECK4lYcIviBUKYlEoqJj2qXBKR4RfEGoUg4dOsShQ4eWuxpCGRHBF4QqptKs5Eqr70pDBF+oeEQEys9KSFom9714RPAFQRCqhKIEXyllUUr5SlUZQRCEQhELv3jmFXyl1PeUUr5UeoS9wAGl1F+WvmqCIKxklkNwReQXRyEW/lla60ngzcADwDrgXSWtlSAIgrDkFCL4dqWUHUPw79FaxzDy3AvCikCsvupE7nvxFCL4/wYcBbzAE0qp9cBkKSslCIIgLD3zCr7W+sta606t9Q3aoA+4pgx1E4SiEauvPCxXWKZky1wchQzarlFKfU0p9fPU57OAd5e8ZoIgrBhEXFcHhbh0vgk8BHSkPvcAHylVhQRBqAykEag8ChH8Zq31D4EkgNY6DiRKWitBWCAiQtWD3OviKUTwA0qpJlKROUqpS4GJktZKEIpAXnxBKIxCVrz6C+BeYJNS6jdAC3BzSWslCIKQBxm0XRzzCr7WerdS6mpgG6CAA6lYfEFYcYgIFI/Wet6om9zruhKSpwnFU0iUztsAt9Z6D8bkqx8opS4otACllFUp9bxS6r5F1FMQBCELadyLpxAf/ie11lNKqSuB64FvAf9aRBkfBvYtpHKCIJSehQqnCG7lUYjgmxE5bwT+VWt9D+Ao5OBKqa7U7/5jYdUThOIQESoeuWbVQyGCf1Ip9W/A7wEPKKWcBf4O4IvAx0mFdApCKRDBWhyVdP1k0HZxFCLcv4cx8er1WutxoBGYNz2yUupGYEhr/dw8+92qlNqllNo1PDxcSJ0FQVhCChFOEdfVQSGC3w7cr7U+qJR6NfA24JkCfncFcJNS6ihwF3CtUuo7uTtpre/UWu/UWu9saWkpvOaCkAcRpvIgUTqVSSGC/xMgoZTaDHwN6Aa+N9+PtNaf0Fp3aa03AO8AHtNa/8FiKisIwtJTqY1kpdZ7OSlE8JOpdApvBb6otf4ohtUvCMIqoJKidETkF0chM21jSqlbgD8E3pTaZi+mEK31L4BfFFUzQVgAIgjFU6nXrFLrvZwUYuG/F7gM+Dutda9SqhuY4YsXhOVCXvzFIdeveihkAZS9wG3Ay0qpc4ATWuu/L3nNBEFYMazERmEl1qlYtNZlPY95XTqpyJxvYSxzqIC1Sql3a62fKG3VBEEoB5UknJVU10Lo6enB4XDQ3d1dlvIK8eF/AXid1voAgFJqK/B94MJSVkwQFsJqE4RysJBrJmGZS0c0Gi1bWYX48O2m2ANorXsoctBWEISVS6U2kpVa7+WkEAt/l1Lqa8B/pj6/E5hz9qwgCKsfEdzKoxAL//3AHuBDGJkv9wLvK2WlBKEYJL9K8Sz2mj1/bIxoovwpsuReL45CFkCJAHek/gmCUIVkiuvAZJjPP9zD+T1j/OutnctYK6FYZhV8pdTLpNaxzYfW+ryS1EgQhBVNKGpkTH+m9zSxRBK7tdDkucJyM5eFf2PZaiEIS4R084un2GsWiSfSfz91ZJRXbVmepIdyr4tnVsHXWveVsyKCIJSPxYhlJD7tu//qY4e4fFMzVouEaVYC0hcTKp5M8Tp27FjJLb94PE5PTw+RSKSk5awkMq+p1dsIwO/s6OTp3tM8vGdgWeohFn7xiOALq454PF7S4/v9frTWjI2NlbSclUh7ezsJqwuAG89tp6vBzfefPb7MtRIKRQRfEKqQxVjKwWgcDbgdVnaub+DIsH+JayeUilkFXyn1O0qpP8v4/LRS6kjq383lqZ4gFE+1T/svdUKuYMwYtHXZrKypczE0GZHc+BXCXBb+x4F7Mz47gYuAV2NMxhIEYQXS399PT09PyY4fiiZQChw2RZvPRTSR5HSgfPlghIUzl+A7tNaZzrlfa61HtdbHAG+J6yUIK5aV3oOYmpoq6fGD0QQOqxWlDMEHYzJWOZBB28Uxl+A3ZH7QWn8w46OsNi6sGHJffBGC+SlWOM19lFIEowlcdkM61tQZgj9YJsEXFsdcgv+0UupPcjcqpf4UeKZ0VRIEYSUTisZx2ixorWmtdQIwPFU9IaqVzFwzbT8K/Ewp9fvA7tS2CzF8+W+e78BKKRfwRGp/G/BjrfWnF1ddQRCWm2A0gdNmBcDrMCTETLdQTqQnVzxzzbQdAi5XSl0LnJ3afL/W+rECjx0BrtVa+5VSduDXSqmfa62fWlyVBWFuRAiKo9jrFYolcNoNwXemXDvheHkyZ8q9XRyFZMt8DChU5DN/pwEzQNee+id3SxDKhNZ61gHmxQhnMJqg3mYIvStl6YdjYuFXAiWdeKWUsiqlXgCGgEe01k+XsjxBEEqLUopAJI4rZeFbLAqH1UI4Vt7c+Cs9UmqlUlLB11ontNbnA13AxUqpc3L3UUrdqpTapZTaNTw8XMrqCKsUsfRKT+Y1DkYTuFOCD+C0WbIyaJYDpZTc9wVQltQKWutx4BfA6/N8d6fWeqfWemdLi0R7CotHhMBgruuw2NQKzkzBt1vLZuHLvV0cJRN8pVSLUqo+9bcbeA2wv1TlCYJQHgKRBG67JS2+LruFSJl9+OLSWRiFLGK+UNqBbymlrBgNyw+11veVsDxBKCsr3dosRf0SSU0olkj78AFcdithcelUBCUTfK31S8COUh1fEGZDhKA4iplpa0bjuHJ9+GUetBUWhqRHFoQiqRR3QqE+/GIIpYR9JVj4QvGI4AsVj1j05SMYNRaXyRb88oVlZub0qfT7vhz1F8EXVgWZFl+lC8FKxLym0xb+tHQ4bdZlmXglFI8IviAUSaU0KIXWsxgffjCVM8edY+FHypRawWQ1WPjLgQi+sCoQn25xLNqH77BNh2WKhV8xiOALwiplKS1g81iBiOHDd9syXDrLMPFqNVj44sMXhAVSTh9+pQvNYgilLHmnIzcsU6J0KgERfKHiqWYBnouS+vBt2WGZ5fbhCwtDBF9YFYjFVxwL9uGnBN+VYeF7HFaiiSSxRPlEX1w6C0MEX1h1iEtn6Un78GMJHFYLduu0dDR47ACMBaNlq4808AtDBF8QFshKF/6ldOmYhCIJPE5r1u8avA4AxgKxImtYPIvJ8imI4AurBKvVSmNj43JXY9WSaeGb69iaNHoMwT8dEAt/pSOCL1Q8phjV1tZmfS51eSudUuTSCUQSeDL89wCNNeUX/NWA+PAFQViRpKN0Ygk8zlks/DL78Cul4V1JiOALqwbp5mdTCh9+MJLA67BmXet6j+nDX1rBHx8fJ5nMjvzJnHglFI8IvrDqEJfO/BR7DmkffjSBN8fCd9gs1DptS+rSCQaDDA4OMjQ0NG+dhMIRwReEMjAyMkI4HC55OaWOYglG43hzfPgAdR47E6Gli9IxLftEIv8M3tVg4YsPXxAWyEoWAK01o6OjHDt2bLmrkpdiZtoGIsm0Dz/zdzVOG/5Unh1h5SKCL1Q8mcITSyRXrEunHBZdqcsIzGLhe522dGK1UrKakqctByVb01YptRb4NtAGJIE7tdZfKlV5gvDzVwb4wk9209XZz2u3d7NlTQ071zfiziNQS0EpBkWXkqUMy9RaE09ogrEENU77jO+9ThsTMtO2KJbjuSiZ4ANx4GNa691KqVrgOaXUI1rrvSUsU6hiDg/5QcHgZIT/dZ/xmN1wbhv/8s4Ll7Ve5YwsKaWITKUs+OZax4zvapxWTo6V16UjFn7xlEzwtdb9QH/q7yml1D6gExDBF0rC6WCUGoeVb916KVNJO7f96EUGJpZ+oLRShGaps2VOhmKAornGiVLZg6leh41ApDwpkleDdb9clMWHr5TaAOwAni5HeUL1oZTidCBGjcuG02ZhU0sNrbXOdDrfUrASXTqlLGsybEThNNc4Z3xXLh++SSKpOTLsX3GNbzgcnjF3oBDKdR4lF3ylVA3wE+AjWuvJPN/fqpTapZTaNTw8XOrqCKuY08Eota5p/7LXYSMQra7IkULDMhfiw58MGdeyJSX4mcfwOq0EovGyDZj/3QP7+Nx9e/mrn768YqKDtNb09fVx8uTJgvcvNyUVfKWUHUPsv6u1vjvfPlrrO7XWO7XWO1taWkpZHWGVczoQpTZjQNHjtOZ1M0SjUUKh0ILLMV/UlWjhL4RC6zcZnt2H73XaSGrKttThi8cnAPj+M8d5578/lV5TN5lMcuzYsbLMecjFvI6LebZKTckEXxmOtq8B+7TWd5SqHEEwX7SxQIxa9/Ti2rO5GXp7e8saE78aXDpaa6bCMTwOKx7HzKG/mlRsfjms7VhCMxGO85bzO7jj97bz4okJPvbDFwlG44TDYUKhEMvhLaiEtA+ltPCvAN4FXKuUeiH174YSlidUMUmtGQtF8WVM+/c6bETiSeIlWompki33hYhTMJrE55oZkgmkUyabDWw0GiUQCBR87Nnqlw8zhUNjjZO3XtDFba/byv0v9/O5+5Y3HmSlPw9Q2iidXwMrt6kTVhXjwRhag8+d4dJJxd8HYwl81qWzbRaah6YclNLCjyWTuOz5JcObY+H39vYCsG3btiWvh5mkrdFjR2vNB6/dQt9okJ89f4pPvn7zkpZXbN0Wur/Wuiw9A5lpK6wKhv2GCDTVOLJcOmBkeFxOlkvwCym3mBmr0bjGmVq8PFecTJfOUkVFzWnhpyZ4NXino4U6G9yEYomS9eYKodpdOoJQNoanImigKUMETAu/VH7lldiFL6mFn0jitOeXDLfD2B4sQ1TUZCiOBuoyxmvMBseMyloO0V2Jz0MuIvhCxaO1ZmQqAhgWvonpV15qEVpo173cM22X2ocfS2qctmnJyDy+O+XqMaNlCqnDXMz1u3AsgVJk1aXWZY4hLG9vrhiWY31eEXxhVTDsD1PnduCyT+fNMV06pRKBlRiWWUxZWmueODiMPzJ/WuO0hW/Ln5fIzFeU69IpxbmHYkncdluWO2r6Xi9fTP5CJlyVGxH8KqOnp2dZQtZKzWQoTpPXsO6nRcAUoZUxMaccFCOwx06H+I9f9fK+/3yOZHL+30UTySyrOhPTfRYqsYWvtSYcT8xIiFezAgS/EhDBrzK01pw+fXq5q7HkhGKJ9EtvYsaLL7UPfyVH6WRamfOVa6ZK8Ifj/GDX8Tn31VoTi+s5fPgpwc+x8Bdq9c7n0sldSN106RTSWykVMmgrrCgqYVApmUxy4MABJiYmivpdJJacMSFo2sKvHpdOoWit8YfjaBRNXgd/9dOXufbzv+Bz9+2dtb7RxOxROm57fsEvxbkbgp+9CMt0RNbyWfiLDcssByL4VcRKFJ5c4nHjhR0dHS3qd6H4tNVnnqfHMXc3vxKuR7EUIyJTKWv4f77hDK7e2oLDZuFrv+7lnhdO5T1ubA6Xjt1qwW5VBGPlsPCT6UFik7RLJ9Vrmc/KHhkZWfIUCJXwPIngr0D8fn9JBoAq4YFcCFprw8LPcel4ZxlIzPzdQssr5vfL5dKZbz9/JI5Sik0tXr753ot54EOv4uwOH1/87x4SeXz6hoU/u2S47FZC0cSSWK5z+fBDsSQeZ34fvr/A8ZpClpzUWhc9CA7i0hGKIBKJcPLkSYaGhpb82KVqRFZCQxKKJdLdehOb1YLTZpk1Y2a56r0SJ14lk0n84QRelyMtUBaL4r1XdHN0NMi+/uzEtoYPP4kzIwoq9/gex0zBL8Uzl+nDL8alE4/HGR0dLfh+9PT00NfXV3C9VvLYjkkpV7wSFkAsZnRJTdfGUlKKB6ynpwe73c7GjRuX5HgLrWMkNh25kZ22t7x52pebQq+fYeEn8LlsWb/pqHcB0wO6mcedK0oHDD9+KFZaCx8MwXfnjNfYrRZcdsucgn/q1ClCoRAej6fgekQikYL3Xcz7VS7xF8FfYZgWkcWy9J2vUj1UZiO1FCx08YhQLIHXYZvRnfY4rLOmVii3S6fcE6/u+tVejsfr6Gr0cPnmJi5c35j+LpFIMBlJZK0fAJnhjYn08fr6+giGwiRhbsF32AhGE0VFCi2EYEZvLvP4NfM07ma9ShUvvxJ6uvOx6gU/kTAeQLs9f5a/hVIqYS7VcbXW9Pf3L+kxS8FCXppYIklSm6GB2S9z7iIoyxEZUU7MJFzReIIfPHucweQYUWx860knD3z4SlprDQvetPDX1GevXpU7gSmRSBCJRIglkoCadeIVgNtuIRxbGpfObI1qPJEgltB48iRxq3Ha0nMu8jWu5rZ8911rzfHjx2lpacHtdi+qzsU07MNTEexLmNhvPla9D7+3t5cjR44s+XGPHj3KwYMHl/y4pRL8YDBYVPd0uSjWeobpRTe8jpli5HFaqyos0xT8l04YYa1//9Zz+Nq7d+KPxPjAd3an90smkwSiM0NZc/PaJxLGtYslkmhIx+HnEzWPwxDcUlr4Zs+jxpXHwndNC/5c5ZrnlIm5KM7g4OCC61bIueYaHJ+4+2Vu+9GLCy6zWFa94Oe7uUvBUroxMjFflqXu/q/kyIFMFiIQxuxOlY7Smaubv5T+ZfNeDU2F2XNq9nkDyyH4Tx0Zxee2c83WZq47cw23XrWJ3cfGmEr55hOJBP5oEo/DOmPMA7ItfDAWHUHP59KxEoolS2rhT4SM+jd4ZvbYvQ7bnLOqzXegkDot5J7Nl7tocnKSnp4exsbGSCaTWdpUrvkDq17wTUr10i31cUsxWAurW/CjcePF8TiseX34mbl0ltKlo7XmkT0DXPV/H+fGr/yaH80zW7XYY4+OjhYtmFpr+kaD/PyY5tKNjeikce471zeQ1PDC8XHAEPJALJlOMGfiSUXh5BN8DVkundzr57ZbCS2RhT+f4Nd7Zy6zWOuyEYoszMLP3X+pBf/06dNpl+rQ0BB9fX1ZLtYHXp4596EUVI3gx2Kxklj7S31M83iV4F8uRR0XbuEzQ7zMbbP58BdLIBLnth89z/pGL1taa/jLH7/E7T95acZ+CylzamqKkZGRoiegJZNJfnVoBJvVxo3ndaSfp+1d9QDsPTWZqnuMhFYz5i5YLAqvw8rUDME3/p/LwjfCMuNZRstSGzCTaQs/O28SGL0T032X75qbxkCWZR0M5t1/vnumtZ7x7s/ljsy9DtFolEh8umH8wsM9ZYkmqxrB7+3tTa/Cs5QsteCXKpJgsSFj+VxYK0XwIykffm5sNsz04S+VS2df/ySfvGcPoWicL9+yg+/80SUA/PbwTIFeSDnm/S/m+RofH2dqaoqJYIT2Ohc+jzP9e5/bhttuZSiVRjoQjqFhhksHDF94roVviJPKykaai8tuxRbzMzAwABgCW4zg9/f3MzIyAswunuPBKBpo9Dpzf06N00a4gIlXmdf0+HGjV5b7vs3XSzl16hSHDh0q+HnK18M2x0netL2DO//wwhnzSEpB1Qg+GDc6FAotWKSDweCMdTqX2oLJffBisdiSCOtijnHy5Mm8A9+lCG9byDHDsURKvGaGZda7HUyEYumVkJZK8O965jiToRgfvW4L29pqafW5eO8VG9LL7y0VxbjizGfTH4rRVOPAarWmn3WlFK0+J0NTEeM9iCZIYJlh4YM5dyFBIpFIC/BYIEYCRVuda9byPQ4r1ng4/dlutxf1fkxOTs7bo0m7dPJY+PMN2uaz8E1y98/cJ/eZTCQS+P1+IPv9LzbgwHQ1rmt0c3ZHXUG/WSwlE3yl1NeVUkNKqVdKVcZCOHbsWFGz5zI5fvw4J06cyNq21BZ+5kOTTCY5cuTIoiIHco872+e5MIVkKfyc87GQMsxFN3Kn2wN0NbhJJDX9E+EZx1to/Y+fDnFyPMS7LlvPm8+qS7/0zTVOpiLxBS8CMjIywuSk4XLJ91yZAjxbo2i1Guc/FY7T6HVgs9myjtNa62R4KkwsFiMcT5DQlhlZJ8GwlP2ReFrsAUb8EZIoOhtmD1l0263GYGQqLYPdbl9wcEPme6C1ZmhoiGg0ymQoisthx5HHtVTjsBFPJIknNKFQaNZF1PNdv8xtyWQySyNy7180Ot2oZyb5SyQS7D01mXY7ZZLZcNts2QPjXufShozPRSkt/G8Cry/h8RdM5kOYSCQ4cOAA4+PjM/Y7duwYU1NTeY9hhk2WysLPHMUvNnNkPpZCrHNflFLEtOces6enZ16rz/SF5nPprG00ZlUeHwsuSf0ARvxhNEZjMjk5ycmTJwFoTq22NeLPDn/NtfwGBgbSFmIsFuPEiROEw2FGR0fTA3nmvc+85qYFfPDgwbTvORPzmZyKxGj0OrFarVnPZ2uti6GpCPF4nGA0QQKVlXVydHSUUChEM1MEwlH8fj9erxeXy8VoIILbaceXmqiVr+fhdlhRQCTVm3I4HIz5w/x09wmePbrwlNzhcJixsTEGBgY4PDhJnWd6wLa/vz99LcxQzXBqED/XODPJbUwTiUTWPQqHp3spvz40wmfufi4r1USmfoyOjhIIBIhGo5wcOs0dj/Twufv2zHk+drsdfyTOHY/0GPXOY6iUipIJvtb6CWDFJl43b7B583IFP5lMEgqFOHVq5uh5PB4vKsRrIfUq5NjmS1pIL6MYwZ+YmEhbmpkcOnQoy7rJtYqWgswXzxSrfI1xJmkLP49LpytlkZ4YC2UdH4z7ePz48aIb7clgBI1K+1wjkQjJZDK9nu6oP9uto7Xm4JA/bdFNTEykG4nh4WECgcCMXqd5TzPvbabQDAwMZJ1LNBolmTRCIv2RBM05Lh2AlhoHI5MhYrEYoWiCOBZqnEZqhVAoxMjICMeOHaPGliQSCpJMJnE6nVgsFkb9UVrrvHNeFzO1RTQ1pvLogVE+dc8r3PbD3bzt/z3JX/zwhRk5emYj8zmIxWIkkpq//68XOTo0wU3nr03f51gslvbD1zhtKPSMHlbuMXPfl6NDUwQiMX5xYJgn9venj3fPC6f45m+O8ssXDnHDl57goT3G2ERuz+GlY6P88yN72Ns/SRQrg5MRPvi93Vkhopnvh81m4wfPTEd0+dzls/BX/Uxbi8WSV4wCgQA1NTWz/m4uATt8+HDamlpqwTePZ7p0TBKJRLrLbhIOhxkZGSEcDtPZ2Zn1XSQSYXx8nNbW1qyl4JqamuZNIGVwiyErAAAgAElEQVQOuvl8vhnfBQIBHI6Z/tOltvAzB4pzzzuXacGfuV9HvRuLghOnZ0ZjTE5OEgwGGR0dZc2aNTN+G4/HsVgsWZPgBgYGGA8YjUetM9s6bq51ApqhySBgRMWEw2EGhkb4h5/vRwNvu9bKebWh9IzX3MbGLCvXwtda4/f7cblc+Hw+hoaGmApFqXHZiUaj6QYjEE0wGPfQ6DUE32wElFI02yPUxU7Tc6yfyXCcZLrRyk6AV+O0MTlsNGIWi4XRqTC9IwG6NzRl1TVTQKPRaPr6R+NJ+kaDfPb+PrY32vn22y/k60+d4u7dJ/nlK8e4673b2dK9Pu+x8n2ORqP89PmTvHxykrft7OJN52c/6yY+h8Kt4kyF4zTXzBzUzZ0/kdSaR/YO8s/P7GNjgwP/xBgA48EYm1tr+K+XTnFeVx21Lhu/OTTKR+96ni/efBbrnKF0g7O/f5LPP7wLMAatHTYrbzxrDf/vhX5ePjnBvR+8kjq3Petd3n18gid7R7lySxMXb2hKN7rlYNkFXyl1K3ArwLp16xZ1rKGhIcbGxti2bVt6W74L+UzvafY8M8CH3nQx9Y78F3o+q3m+KIqFzJjNTIucTCazHpJ4PJ4lfJnlZopGIpFAKUV/fz+RSISGhgYcDkf6OgSjCU6OhRg5MkIzU/z4pWEGY26+fMuOguo4m8gX+8BGo1F6e3vp7OxMN7yZjVymhT+f4EfiSWxWS3qKemZd7FYLTTVOBicjaX+wyXy9tMOHD+N0Olm/fj1KKZLJJBMTE/gjcWyW6QbGZrMxNjZGc0sXjSrE3v0Hec1Z7SilCAaDnJqYdhF88b8P0GWZpKvRw4ecLaxR2YJv+nfN+xsKhUgmkwwNDTERDPOD54fxJ62ExkfpGdzFuZ0+brl8E62eVPx8wkIYO001zvR1i8fj2O12drY7+YlVcfdzxxgOxNnYXEOj10EkEsl6hmpdNogYRsGQP8rHfvQCsWic91yRP0Ge6ZJy2Xyp+5Hglz3DOB12br9hK5s6avniO87nHx86wONPv8ijLx2je21n+lxnuwcnxoL0jY1x7yt7GB2b4OptLVx/dhs228yeHEBjSuOfPnKa5/rGODLsZ9/dJ3jbzrW8/aK1M8q465ljPLZ/mFYL+CemrfYfP2e4guw2xTsvWUdTjZO3XtDF534xzMfvepZaS4Q/vu5cdg3EeGXvQTrr3dR57NgsijdfvIn1PiuX7Kjnf3zzWbZ/9mHedX4Df7DDaCwnwzE+d18PLS47b9remV6Ws1wsu+Brre8E7gTYuXPnopq5sTGjhTatYfMFb2pqIhqNMjU1RSSe4NtP9jEZA1vtIW5/TXfeY83lr55rPxPT4uruzn/8XLTW6W5+5rFDsQTHR4OsaYvidBpPdDAY5Pjx43i9Rhc7HA4zOTmJz+ejr68v/YKb18I8vtaa93xzFzH/OH59kBpluB6OJ+t539WbOKtjpkWfr575zr0Qwe/v78dms9HS0pL2k05OTqYFv6enJ+t40WiU0UAUuzN/dkOzzHAsgWuWpfcAmrwORqdC9PT04PV6SSQ1yYz6hqMxXjk5wTmdMyMlIpEIPT09tLa2pns2/nCcGuf0JK+mpiYGBwdpdls4v83Bj587gb1uPx94zZnEYjFOjhs9gr++4QwmbI3c86vnGQ9EuOXfn+LTVzVw+SZDDOx2+wwrFGBwcJDJyUkePTDKj/ZMYidBi8UQqJdPTnL8/lf4X28+B4/dSs+gMTZwXmcdNptOX/euri4avQ6uPaOVh/cMciLp42Ov60yfQ6bg17hsJJOaqXCcOx7dx3jCyWdfv5ELu1vyXl/zXrpsxrGiiSRHRwOct64Nj90YR2j02fnMm87ipVf2sX9gikgkgtVqnbXRHZgI8Zl795JAkcCCU8HbLuwCZjcAmr2GnD2wbwQHCWpdNny+Br706EG+98wxvnpjF/Uuo7wTY0EePzDMNdtauHpbC5+5dy9djR7ee/kGnjwRgmiI15zZwua1bUZ2zZMn+Y93X8CnfvAUzx+L8+mHj1PvsfO6jS28fWdHOiVFXV0dExMTXNzl5WOv3crnH+7hFy/14tYhfveCLh7eM0gkkeQvX7+t7GIPK0Dwl4pMwckUfDCsbLfbzdTUFI/uGyIYS9JZ5+YHzx7n2o0+Op1zh2XF4/FZ89DkE/xIJJL2dU9NTVFbWztv/TNfuFPjITqsdjyxOJ9/6AB9o0Fuf/A4X/uTq7h0Y1Pav55Zp/7+fnw+X9oNYpZvHldrzanxMCcm4+xodHHJphYO9E9Q77bzo0NxPvDtJ3nwY6+Zc2KNeZx8fxfi2jLr3dIyLRyzJbTSWrP3xCifvvtlbC43d32klaacbnpfXx/RaDRrBaS8lp/XwWQwBNQTCAT47tPHeKJnmLdduok9fcM83x9gKFnLzRd28b/fci4Om2VGfSYmJvB6vSilmArHs9bPNS3VwcFB/uRVG7nziSP8+2N7aGSK9Y1uvvnbo9gsig3NXjZt7GRHQ5RoPMn//s0E332ql0u6G9Eadp8cZ2QiyOXWeuqTSV4civLCoVPcdL4hKD/ZH+TyLa18/i1n8avn99HicxKKJvi7+/fx7d8e5fd2ruWlExOs8TlZ3+RJC3EoFEr7/G88t4OjIwF8qp4/unIj46NDWb0pID0w+/DeQXYfn+L/vuMibpzFjZJJasyUYDTBqbEQrzuzHovFkjZGBgcHOaO9luePjXOk7xgNvlq6ugwRzx0POpEaZP/A1d2sa/TirqmlwWslFAqhtc7bc3ZZNQkUCs3f3HgmG5q8bNy4kd3HJ/nT7zzHVx47yCdv2EpSa77y6CFqXXZuOr+DWpedO96+HbThT79i+1YGBgaIx+M0NDSk6+a2Km67biO/7PXTH3XysddtxaoTTExMpI1Ns16nTp3i/Vdv5G071/Kpbz/Cz18e4KotLdy93881W1tp82WHt1a8S0cp9X3g1UCzUuoE8Gmt9ddKVV7mgNbU1BRNTU3pi6iU4iuPH+Zw3wmODAfY2d3Mey5Zy8cfOsUXHt7P316/lsFAkExjPPMBNK3mrPISSb792z4CCcU1OxU3p6wPIGuUv7+/H6/XO69rxxTo4akIn753Dy6nk1MhCw0qxBlttTzdH+POB3eRvHwdfUMTRBNJLt+cbXHlcy/F4/G0P7xnyE8UK7f/znZqLDHeeI7ht75oS4QvPfgyzx4Z4ootM33Zs5WhtWYsGMVmmR4jmJqaYnJycsaYwnxkXu8Xjo/zrd8eZTycwIomEIzy7m88w9svWse7Lp32/ZoNXjSeyFpcO3McYHR0lEa3lYNj043jCyeMyKvvPnUUBwm2Ndfgjrv58XMnuHprC2/a3jHjBTTdM0fHYzx/bJwNzV6amprSjQAY931tawMffd0Z/MMDe/nnx4zkegHt4J2XrMOiVDo6x2GzcNM2L/9yNMnQVJjH9g1x//5x3CrGl56d5K2brTx8aAo3MUYDUVrrvfRPxbnjHZtprHVxbtd0b+SG89p46JVBdh0dI4aFN162HaVUliVsRput7Wjly3+8Ho/Hg1IKczg826VjCP6DrwywqbWdm7Z3zLhf+RpWeypTad9IgHhSc2a7j2TSTyQSobe3l2QyyVVbW/jNoVG++tghrtq2huvrW2iucaavi3nfhiaNd2hray11HjttbY1YLBZCoRAOh2OGlR+PxwkEAiSwYEGzLhWddeTIES7Zto13X7aBHz2+i6//ppcda+sZDUT54Bt2UOsyjuPLSBNts9loa2tjZGQkK7Q1EAiQTCZ5+2WbM4w4G16vd4bgm+6/NY2NvPbMNew9Nckn7n6Z07qed166DlieRIYlE3yt9S2lOnY+MqNHRkZGcLvdOBwOwrEEX/zvHn743CmaLYbV8J4rN+OxxPnDc7184Zcn+dD3nyeOhe+vXYc7GaS+vn5WH/mIP8Kx0SCDkxGePDJKHAv3975IPJHk5gu78EfiJFO/bW9vp7+/n4MHD9LetY6vP3mcs9p9vO7stqy6T0xMpEMv9/ZPktSwoclDdCzBOo+F267fxgN7T3P3s0f4nz+cjo2eCMW4PuNYZj2DkQTBWJw6txEH/c0Hn2LPyXGODAfY0NREV6OX06enA6g2N9qwWBQ//+1LhMba+cW+frxOGx9av5HU+8BYMMbDewbY0hVmYr+fbWtqOX+Nnb+9bx8ToRjf+GAbG52udFSTOVAIxsOfmVk0Hs/OtxIIBNLiHYkn+OZv+6hz2bnxvHbO6axn/3CI7748yd/f+wJv3dE5Y0ZiOBpLL6KdiRnG2GQJsitoHD8YSzAQSHDLjg4sVitttQ4uXN9AfWMzV37xafb1T/Km7R15J8Alk0nu2j3IqaSPm8/dQnNz84znw2az0ejzcvsbzuChPQPsOjrGe153IRevq2V4eJjh4eH0vs0O43ef/JkRxvfas9dz05k+vviMn6cO93LFpi421Fm5d3cfz50M8cdXnsNlm5pm1O2tO7q4fFMz//jgATY01/Dx1xtjWA6Hg5aWFqxWKwMDAzQ0NKTrbJLp0nG73YRCoazeyzsuWV/w5K/AuHFuP0utiXtxdyM1llr6+/vTdd7UUsNNV57Pd361j72nDvLXjw7xd79zNjsbs6O/BifC2K0Kn9uWPhe3283GjRuzXF8mJ06cIJFIcNmmJqaCYSw5dT6zvRYF/PbQKL89NEoSxTXnbyR0ejDLQAPDZeR0OtMu0/T8hlSjmbuASqYxl3lvxsfHaWxspKtxeu7Cx167lQ3NNYyOrjLBLzeZgg/gD4XZ2zfO/U/1cf+hMJtaa/nIZRuIJZK0N3iZmJjgwvUN1KrpGaTf/eUr3HxuI8lkMu2vBTg05CcUS/BM72mezJg6v63Nx0dfu5Vb7znJ7Xe/zJ1PHOHISIB/+d3NbPIZD8beU5P86uAw+8cPs/d0EpvFwjfecyE7Ory43W4SiUQ6KgYMwa/3OPn49Vvx+XycHhvD6XRy0Vovdz9r7LNzQwPHTwd5dN8gm1trODIcwOu00dbeQTCW4G/ueSU9+aN7TT29g9Nhjbe/44yswTIwJszs3NjKrw4O8quDIzhtFiKJJI8c/W/edpaXff1TvJhKuvXg3iFOJX2AokEFqVFGOTd9+VfYrYpubwyLUvzBa128dadhjef2jsbHx7PcUZnx0i8cH2c4BO+/eh3b2gwram1zLa1eG194aIhneke55ozsXkg0nsDhMLrI5uDqyZMn01ZjrU0TjkS554VTJHSSJIZ7ZfvaBrTW2O12IqEAW5pcHOif5HQgipWZsdovn5zgN0en+PBrz+JD121Jf2f6orXW6QFFh83COy7fwjtfZaWtrS1tAWbSnjFrdXNrDR+4diuhqTG++rttnD7dyJo1a5iYnOL0lB+r08tfv/FMIH8gQJvPxeffdh5NTU1Z6Q8aG41FT7xe74z7bmK6dLxeLz6fj4ng9P14846uvL8xyby3joy87htbvHTUuwE3g4ODWUJ42xvO4p0723jw2f3c25vgb+95ga21MbxOO+evrefP161jaMJPU42x/GJTU1M6R705NpXbCJnP059dtQHIFt7Tp0/T4UpgwWgkLtzQgNflpLXWRcLTRSwWS4+55es9KKXS99fj8cz4PvN+mNfD5XIRDodJJBLpvD9djR4+eO2WrAlt5WZVCX5m3PF//PIw33imnzbLFG+5YAt/86Zz04sWmw++1aL4wKs3EYwmeKV/iodfPsm6GtjanuBkQLOnt5/DQ34OD+efsXdhdxM2C3z193fw8R+9yMjoCM1WC788MMT6C9fw7m/uYs/hE3S4E3TUu/j9a9v49ishPv69J/nole2c11WX5cP+z6eO8dzRMa4720h6NTY2hgJqampoiUT48HVb6Grx0eBU7O4b419+cZj/88D+dH3+/ZkhWu0xxkNxY4KFglA4xJvP7+DFExNoNDec25bVfQZobm7m8+/dyqN7TnG0t5ed3Y2cGg/xjWcGuSsjXnjHunrO66zjugu28MypCF/66a+JYuWj12zgyFiU0YkAu48F0Rr+549fYG2Dm63NzqzGE0hPpDoxFiQ6keSh53vZvraeY6NBfnlwiCafLy325rXZ1OzBZlV8/YkeLuiqJR4Jpb+PxJJ4aqbFM/P8HA4HNS4btSrCf71oWJ4bW5s4o62WZDKJ1WqltraW0dFRzqyN8GjPaa7/217a17Tw99d3YLUoTgfj/KpniMcPDNG9Zg23XpUdraKUwmKxkEgksNls6eerrq4u3fXP6wKxWrh6Wwsbmjy8aksLdV4noSkj+MA8pt1m5T2Xd9PY2DinpW2xWNi8efOs+8wm9ub1NeteV1dHnWeQD123mc3tTfg8M8MbTczFUUwyG5o/zbhGNpstyyBTSuHzOLliczPXbK/lZ7vd/PeLvRw/HeT46SDPD/2agcFxLu42Gqumpuxw0Llob2+fMXdmeHgYh9ZctKGBq7e2cEa7D5fLeF6sVitWq5XNmzenP+fD7FHU19fP+C5T8M3r7/V6CYfD6YbkjrefT/e6tQA0NDQQi8Wy5rpUvA+/nJhJo5xOJy6Xi7GxMd641cv+o0mOjyneekFX1k3JXP3qgvUNAHQ2eHiyd4w7n5i2+JWCrgYPbzi3jZGpCKFYgluv2sSRkQCP7B3gVdvaQUdptQb5yhvbCEZb+M+n+nixd4C7rXF+cyjIp268kJt3tDE2MkQ4HOaiM7v5i+/8lq88doj1TR6uPaMVn9vO00dO89QRQwivz3H5+Hw+pqameM2FW9MLMe9YV88F6xoIxeLc9pZLeeTZ/dy/d4TRQJSdG1t5/5Vrqa2tTYvf9ee0pc4p27dbW1ubFpPXnNPJAbux/6aWGv7PTXUMTgQ5ORbirA4fdqsFu91O1D/ORU12vvh759EzaeH8Vgs71k03XKFYkj+/60V++PhuNrXWsKWzmWcOnuTiDY0EIgnGglGePjLKyyenH/jn+gwLuK3OyZ+94WxstmTaWkomkzhsFv7g0vV86dcDvOWOh/j9C1porXXx+IEhjp0Osr0tvzD5fD7a64zr2lHv4pptrdxwyRmEJ8fSg38+n4/R0VGuP7uN8eAxwjErLw+OcccjU2xqqeG+/RNY4yHWNnj47Dt35k0gZrfb06Lp9XpxOBxZXf/ZwnczxyRyxdpisaS35QpRZ2dnVlSXaYUWi1IqXbfMcMfzuurp7p49TNoUqMzemcdh5T2Xb+DczjrqPNk+8dweuNkARQNTvHV7K5etdfHi8Qn84RjPHh3jnLUN3HbzVdS584dg5mP9+vXpeQq5s9OVUvzp1ZvSn3N7SfOF/prkm7uTWb/W1lY8Ho8xO3l0ND22uP3MLWnDx2q10t7eTjAYLFk69NmoeMFPJBLpXDN1dXXU1dWlfHIh/uqGMwBY216XZeHke4C6mz18+o3b6JtIMjg6RnOtk3dddwH9p07O2PecDh/ndPhY09rA4OAgfr8fpRR1XheXdDey6+gY9708yC0Xn8X/uNIYCa71rOPQoUMkg2P845vP4NeHRrjr2WN84zdHU3WCa89o4ZaL1+H1etPTxWtra3E4HOnwTtM1oJTi/a82rKhN7U3os9Zw3ZmtjASTnL2pi3g0QlNTE5FIhEgkkpWPJ/PhbmhoyLoemb2kRCJBd3szF53bnM402t7ezsDAANFolDq3nXecsylrUFsphcdh5cw2L08dGU01YoaV88BL064rgDq3nZ0bGtix1ojmaKn3sr6ljjVr1nDq1Kn03AOzPldubsZtt/LAK0N867fGMSe1kzp3Lb970fq899bpdHL9Jeew88xN+MeGAGiscTMc8hONRrFYLDgcDnw+H+uBj7/+DLTW/ONDPRwYmOLAgJ+NXW28/5LNdDbXsb41/2Q9n89HOBxOi2aunzdX8DLxeDwz5giAIUrmtlxByhWepcjplNsLmCvQINPvnXWPtjTP2Nc895aWFurqjMHmTKMrHA7T1lBLV0sDgUCAG7d3sG7duoKXGnS73dTV1aWt9jVr1mC327NcJ93d3cYM41CI0dHRohtHMwgh3+8yr5PVaqWuri7LpbRhw4YZvVww9KrY9NeLpeIF32q10t3djd/vT88MNUOpzO6m1WrNuiler5fGxkai0WhW939js5eLtjXhcGzFarXi8XiYaxVYu92O0+kkEolQW1tLR0cHiaRmXVM/LfW1fPpNZ6f3NUXA7/djtSiu3trCVVua2ds/xVQ4xo519bS1NFNbW0sgECAYDKKUoqMjO0Ii84EzrTqr1ZpOVLW5o5GGuul4erfbjd1uzxL8zBc796VuampiaGgo/bm+vj7rYXW73XR3dzMyMkIsFku7MHItlT951Ub2TDrY4LPwSu9JHt8/zPBUhHdfew6XbGnHPzqIy2ZNJzzbsGFDep4BkL4OpuVs1u1C4OwOH5++Zw/heIKvvutKtm/M7hHlu0edLhcHJ0bSbhyHw5EWfDAaMpvNxunTp1FK8b5Xb6R3OECrz8UVO87Ksrbz0dDQkLbs82GGBeejs7MTi8UyY8p+5r0pxaL2ueQKfiGi6Ha7jbkNKfeOx+OZ4aNuampibGwsy7iwWq2sWbMm/VzW1tbS1NSUtnoLEXuzocmdsKmUorGxMd0AhMNhHA4HDocjyzAphrlm5ee7NxaLhebmZhwOR9ZznUlzczNut5sTJ04QCoVmGAmloOIFHww/rTk4BcbDY7Va0zkxMid4gHEzWlpaGBkZwe/3p6MTzH3zpRTIh1IqLfimxeJxu/jUjWdRU1Mzo+vf2NiI3+/H6XTS2NjI8PAwZ3f48Hg81NXVUVNTg8ViSVtE+fx6+br9YFiJExMTeR/Mubqvud81NDTgdrvp6+ujsbEx6yHMFLPMaA+73U44HM5KY1HvcfDe87cSDAbpcCe47ow19E+EuOisbnw+HwejE+l9W1tbZ7wUdXV1OJ1OQqFQ2pr0er2Mjo7islv58rsvxz81xZa12f5d89zMkMnM42Zay/mEubm5mfr6eo4cOYLPZWf72no2bNiQZY3OxWxiD0bD6fP5OHToUHpfh8OB3+9P3wOv10tHR0faB51p4eftlXZ3G0m7Ts7shRZK5nFz6z9XI9PR0UE0Gk1HsmSSK/j19fV5fd+Zv02/P0WIXnd396w9G6VU+viZ5ZjnW44V4AoZezCv8cjISFFjFQtlVQh+PjJFbTbLxfzf5XKlBT93385OYzai6atsa2tjaGgonWfELMe8cU6nc9a0rG63Oyvtg8/nSzcWmS/XbBZB7nllnsOaNWtobW2d1dqYjbwTWFwu1q9fn1WPjRs3znoc0yVRU1OTDv9raGhIf1dfX8/4+DhdDZ50fTdv3szhw4dJJBJ5xcCsR+b8CpfLlY6WaGttwdE1M9bf6XSm3WGzWYkWiwWv1whNzXRNKKWw2+1Z/vGlsqxzx066u7vzunEyxSnf85WJ2WgsBo/HMyOGPLPOs2G322dtCJVSBVnome+aaY0XgznguhAqZcnPpaYqBH++m+tyuWhoaGBsbGzGQ29azEopGhoa0pEXgUAAp3M6X0nm6HyukMxFPnGf6yWuqamhra2NeDw7X3mxg3Yej4dgMDiroOW+gHNZuZkWnMfjmZHrZM2aNUxNTaXz/Jj1XbduHZFIZM5651pn5kSY2erT0NBAMBjM20sz0wWb7rrGxsa81z+zl7TUrpSurq50g5TvnlksFurr65mYmMBqtaZ7P3MJqNvtXpBgwrRFXchs8ELZunVrQfvN1bsoFeb9LLTXVi7miqJa0nLKUsoyUMiL2tDQkA7Lq62txeVyzdqlzHyILRZL+gVpaGggHo+nB6PcbjcWi2VR3TMzFcRsfsO6urp0yuCFhnN1dnZmpXleKuZ7kTLvSyEWqsVioaOjI/07c//Z6m2329mwYUPe79auXUsoNJ3pMDPFw2ws9fXxer153SCZmL01s+xMd2U+FpN00GKxsGnTprKMEeSjs7OzbGIHRmPe0dExp09+Iaxdu3ZBvQ3z/S1XA1RVgr9+/fqsaAnTmjIp1HefW05mal2lFFu2bJnjF4Ux30u82PTMZnRKuViM7zTT+mxvb19wHYpxgZgD0cslhOV0OZRTcHNZauEthKXszZgsdMDVFPxCI5IWy6oV/Hy4XK4Fd31XGjU1NdTU1BQsYA6HY9nEK5PF1mGhPttiWb9+/awJ8wRhqfB6vbS1tS3I2FwIq1rwu7q6ltV6KSUWi6WoBGWFpmkuNZUyWJY5Y7ba6OzsXPK1moXZMd3B5WBVP9Hz+UqF8lHOcDhhcSyHm0UoD8vfxxeqgpXgThKEamdVW/jCyqGzs5PJyckVFw4nCNWEmF1CWbDb7WWZSSgIwuyI4AuCIFQJIviCIAhVggi+IAhClVBSwVdKvV4pdUApdUgpdXspyxIEQRDmpmSCr5SyAv8MvAE4C7hFKXVWqcoTBEEQ5qaUFv7FwCGt9RGtdRS4C/idEpYnCIIgzEEpBb8TOJ7x+URqmyAIgrAMlFLw882hn5HLVyl1q1Jql1Jq1/DwcAmrIwiCUN2UcqbtCWBtxucu4FTuTlrrO4E7AZRSw0qpvgWW1wyMzLvX6kLOuTqQc64OFnrO6wvdUS10AY15D6yUDegBrgNOAs8Cv6+13lOi8nZprXeW4tgrFTnn6kDOuTooxzmXzMLXWseVUh8EHgKswNdLJfaCIAjC/JQ0eZrW+gHggVKWIQiCIBTGapppe+dyV2AZkHOuDuScq4OSn3PJfPiCIAjCymI1WfiCIAjCHFS84K/WfD1Kqa8rpYaUUq9kbGtUSj2ilDqY+r8htV0ppb6cugYvKaUuWL6aLxyl1Fql1ONKqX1KqT1KqQ+ntq/a81ZKuZRSzyilXkyd82dT27uVUk+nzvkHSilHarsz9flQ6vsNy1n/xaCUsiqlnldK3Zf6vKrPWSl1VCn1slLqBaXUrtS2sj7bFS34qzxfzzeB1+dsu5zoWH0AAAUKSURBVB14VGu9BXg09RmM89+S+ncr8K9lquNSEwc+prU+E7gU+LPU/VzN5x0BrtVabwfOB16vlLoU+Afgn1LnPAb8UWr/PwLGtNabgX9K7VepfBjYl/G5Gs75Gq31+Rnhl+V9trXWFfsPuAx4KOPzJ4BPLHe9lvD8NgCvZHw+ALSn/m4HDqT+/jfglnz7VfI/4B7gtdVy3oAH2A1cgjEBx5bann7OMcKcL0v9bUvtp5a77gs41y4MgbsWuA9jZv5qP+ejQHPOtrI+2xVt4VN9+XrWaK37AVL/t6a2r7rrkOq27wCeZpWfd8q18QIwBDwCHAbGtdbx1C6Z55U+59T3E0Alrh35ReDjQDL1uYnVf84aeFgp9ZxS6tbUtrI+25W+iHlB+XqqgFV1HZRSNcBPgI9orSeVynd6xq55tlXceWutE8D5Sql64KfAmfl2S/1f8eeslLoRGNJaP6eUerW5Oc+uq+acU1yhtT6llGoFHlFK7Z9j35Kcc6Vb+AXl61lFDCql2gFS/w+ltq+a66CUsmOI/Xe11nenNq/68wbQWo8Dv8AYv6hPpSeB7PNKn3Pq+zrgdHlrumiuAG5SSh3FSJt+LYbFv5rPGa31qdT/QxgN+8WU+dmudMF/FtiSGt13AO8A7l3mOpWSe4F3p/5+N4aP29z+h6mR/UuBCbObWEkow5T/GrBPa31Hxler9ryVUi0pyx6llBt4DcZA5uPAzandcs/ZvBY3A4/plJO3UtBaf0Jr3aW13oDxzj6mtX4nq/iclVJepVSt+TfwOuAVyv1sL/dAxhIMhNyAkaTtMPDXy12fJTyv7wP9QAyjtf8jDL/lo8DB1P+NqX0VRrTSYeBlYOdy13+B53wlRrf1JeCF1L8bVvN5A+cBz6fO+RXgU6ntG4FngEPAjwBnarsr9flQ6vuNy30Oizz/VwP3rfZzTp3bi6l/e0ytKvezLTNtBUEQqoRKd+kIgiAIBSKCLwiCUCWI4AuCIFQJIviCIAhVggi+IAhClSCCL6xalFKJVGZC89+c2VSVUu9TSv3hEpR7VCnVvNjjCMJSI2GZwqpFKeXXWtcsQ7lHMeKmR8pdtiDMhVj4QtWRssD/IZWH/hml1ObU9s8opW5L/f0hpdTeVC7yu1LbGpVSP0tte0opdV5qe5NS6uFUbvd/IyMPilLqD1JlvKCU+rdUSm9BWBZE8IXVjDvHpfP2jO8mtdYXA1/FyOOSy+3ADq31ecD7Uts+Czyf2vZXwLdT2z8N/FprvQNjSvw6AKXUmcDbMZJmnQ8kgHcu7SkKQuFUerZMQZiLUEpo8/H9jP//Kc/3LwHfVUr9DPhZatuVwO8CaK0fS1n2dcBVwFtT2+9XSo2l9r8OuBB4NpXx0810cixBKDsi+EK1omf52+SNGEJ+E/BJpdTZzJ2yNt8xFPAtrfUnFlNRQVgqxKUjVCtvz/j/ycwvlFIWYK3W+nGMRTrqgRrgCVIumVQe9xGt9WTO9jcADalDPQrcnMp/bo4BrC/hOQnCnIiFL6xm3KmVpEwe1FqboZlOpdTTGEbPLTm/swLfSblrFMY6q+NKqc8A31BKvQQEmU5r+1ng+0qp3cAvgWMAWuu9Sqm/wVjlyIKR+fTPgL6lPlFBKAQJyxSqDgmbFKoVcekIgiBUCWLhC4IgVAli4QuCIFQJIviCIAhVggi+IAhClSCCLwiCUCWI4AuCIFQJIviCIAhVwv8HV4fNsUXPojUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'D losses')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 1\n",
    "test_max_steps = 20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
    "\n",
    "# # # Create the env after closing it.\n",
    "# env = gym.make('CartPole-v0')\n",
    "# # env = gym.make('Acrobot-v1')\n",
    "env.reset()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore/load the trained model \n",
    "    #saver.restore(sess, 'checkpoints/QGAN-cartpole.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # iterations\n",
    "    for ep in range(test_episodes):\n",
    "        \n",
    "        # number of env/rob steps\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            \n",
    "            # Rendering the env graphics\n",
    "            env.render()\n",
    "            \n",
    "            # Get action from DQAN\n",
    "            feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "            actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # The task is done or not;\n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the env\n",
    "# WARNING: If you close, you can NOT restart again!!!!!!\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this to Deep Convolutional QAN\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# QGAN: (Q-Net) + GAN (G-Net and D-Net)\n",
    "\n",
    "More specifically, we'll use Q-GAN to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command 'pip install -e gym/[all]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "rewards, states, actions, dones = [], [], [], []\n",
    "for _ in range(10):\n",
    "    #env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    states.append(state)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    dones.append(done)\n",
    "    #     print('state, action, reward, done, info')\n",
    "    #     print(state, action, reward, done, info)\n",
    "    if done:\n",
    "    #         print('state, action, reward, done, info')\n",
    "    #         print(state, action, reward, done, info)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        dones.append(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(10,) (10, 4) (10,) (10,)\n",
      "float64 float64 int64 bool\n",
      "actions: 1 0\n",
      "rewards min and max: 1.0 1.0\n",
      "state size: (10, 4) action size: 2\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print('actions:', np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print('rewards min and max:', np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print('state size:', np.array(states).shape, \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    # Current states given\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    \n",
    "    # Next states given\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    \n",
    "    # Current actions given\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # TargetQs/values\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    \n",
    "    # returning the given data to the model\n",
    "    return states, next_states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Q: Qfunction/Encoder/Classifier\n",
    "# def qfunction(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "#     with tf.variable_scope('qfunction', reuse=reuse):        \n",
    "#         # First fully connected layer\n",
    "#         h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "#         bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "#         nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "#         # Second fully connected layer\n",
    "#         h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "#         bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "#         nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "#         # Output layer\n",
    "#         logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "#         #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "#         # return actions logits\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: Generator/Decoder: actions can be given actions, generated actions\n",
    "def generator(states, actions, state_size, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # Fuse/merge states and actions together\n",
    "        x_fused = tf.concat(axis=1, values=[states, actions])\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=x_fused, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        #logits = tf.layers.dense(inputs=nl2, units=state_size)        \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "        \n",
    "        # Split states and actions together\n",
    "        next_state_logits, actions_logit = tf.split(axis=1, num_or_size_splits=[state_size, action_size], value=nl2) \n",
    "        # states sigmoid/regression/continuous and actions softmax/classification/discrete\n",
    "        \n",
    "        # return next_states_logits\n",
    "        return next_state_logits, actions_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D: Descriminator/Reward function\n",
    "def discriminator(next_states, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=next_states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)   \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return reward logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states,  actions, next_states, targetQs, # model input data \n",
    "               state_size, action_size, hidden_size): # model init\n",
    "    # GAN: Generate next states\n",
    "    next_states_logits, actions_logits = generator(states=states, actions=actions, \n",
    "                                   action_size=action_size, state_size=state_size, hidden_size=hidden_size)\n",
    "    # DQN: Q-learning - Bellman equations: loss (targetQ - Q)^2\n",
    "    #actions_logits = qfunction(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_real = tf.one_hot(indices=actions, depth=action_size)\n",
    "    Qs = tf.reduce_sum(tf.multiply(actions_logits, actions_real), axis=1)\n",
    "    g_loss = tf.reduce_mean(tf.square(targetQs - Qs))\n",
    "    \n",
    "    # GAN: Discriminate between fake and real\n",
    "    d_logits_fake = discriminator(next_states=next_states_logits, hidden_size=hidden_size, reuse=False)\n",
    "    d_logits_real = discriminator(next_states=next_states, hidden_size=hidden_size, reuse=True)\n",
    "\n",
    "    # GAN: Adverserial training - G-learning\n",
    "    g_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "    g_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.zeros_like(d_logits_real)))\n",
    "    g_loss += g_loss_real + g_loss_fake\n",
    "    \n",
    "    # GAN: Adverserial training - D-learning\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # Rewards fake/real\n",
    "    rewards_fake = tf.sigmoid(d_logits_fake)\n",
    "    rewards_real = tf.sigmoid(d_logits_real)\n",
    "\n",
    "    return actions_logits, q_loss, g_loss, d_loss, rewards_fake, rewards_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(q_loss, g_loss, d_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param q_loss: Qfunction/Value loss Tensor for next action prediction\n",
    "    :param g_loss: Generator/Decoder loss Tensor for next state prediction\n",
    "    :param d_loss: Discriminator/Reward loss Tensor for current reward function\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    q_vars = [var for var in t_vars if var.name.startswith('qfunction')] # Q: action At/at\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')] # G: next state St/st\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        q_opt = tf.train.AdamOptimizer(learning_rate).minimize(q_loss, var_list=q_vars)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return q_opt, g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGAN:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.next_states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.q_loss, self.g_loss, self.d_loss, self.rewards_fake, self.rewards_real = model_loss(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, next_states=self.next_states, actions=self.actions, targetQs=self.targetQs) # model input data\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.q_opt, self.g_opt, self.d_opt = model_opt(q_loss=self.q_loss, g_loss=self.g_loss, d_loss=self.d_loss, \n",
    "                                                       learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size: 4 action size: 2\n"
     ]
    }
   ],
   "source": [
    "print('state size:', np.array(states).shape[1], \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 250           # max number of episodes to learn from\n",
    "max_steps = 2000000000000000   # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000           # memory capacity\n",
    "batch_size = 200               # experience mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = QGAN(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 0 Total reward: 14.0 Average reward fake: 0.5146830081939697 Average reward real: 0.5908793807029724 Training q_loss: 0.3496 Training g_loss: 1.5795 Training d_loss: 1.2742 Explore P: 0.9986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 1 Total reward: 21.0 Average reward fake: 0.3195183277130127 Average reward real: 0.5851050019264221 Training q_loss: 0.7967 Training g_loss: 2.3430 Training d_loss: 1.0126 Explore P: 0.9965\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 2 Total reward: 23.0 Average reward fake: 0.6939302086830139 Average reward real: 0.6864286065101624 Training q_loss: 4.4988 Training g_loss: 2.4247 Training d_loss: 2.3269 Explore P: 0.9943\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 3 Total reward: 40.0 Average reward fake: 0.051248300820589066 Average reward real: 0.41477248072624207 Training q_loss: 53.7983 Training g_loss: 3.9453 Training d_loss: 1.3250 Explore P: 0.9903\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 4 Total reward: 37.0 Average reward fake: 0.009075271897017956 Average reward real: 0.4236867129802704 Training q_loss: 102.9494 Training g_loss: 5.3038 Training d_loss: 1.4472 Explore P: 0.9867\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 5 Total reward: 14.0 Average reward fake: 0.006930219940841198 Average reward real: 0.4560316503047943 Training q_loss: 46.6387 Training g_loss: 5.5120 Training d_loss: 1.0879 Explore P: 0.9854\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 6 Total reward: 11.0 Average reward fake: 0.005663597956299782 Average reward real: 0.495911568403244 Training q_loss: 25.2385 Training g_loss: 5.8359 Training d_loss: 0.8557 Explore P: 0.9843\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 7 Total reward: 17.0 Average reward fake: 0.032850589603185654 Average reward real: 0.5592232346534729 Training q_loss: 7.7090 Training g_loss: 4.4192 Training d_loss: 0.7091 Explore P: 0.9826\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 8 Total reward: 11.0 Average reward fake: 0.029399966821074486 Average reward real: 0.6079035401344299 Training q_loss: 2.7359 Training g_loss: 4.8041 Training d_loss: 0.5846 Explore P: 0.9816\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 9 Total reward: 42.0 Average reward fake: 0.7067052721977234 Average reward real: 0.6994755268096924 Training q_loss: 2.6809 Training g_loss: 1.5921 Training d_loss: 1.6272 Explore P: 0.9775\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 10 Total reward: 9.0 Average reward fake: 0.653033435344696 Average reward real: 0.6295206546783447 Training q_loss: 4.4960 Training g_loss: 1.4679 Training d_loss: 1.5678 Explore P: 0.9766\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 11 Total reward: 13.0 Average reward fake: 0.6265142560005188 Average reward real: 0.5719261765480042 Training q_loss: 5.8686 Training g_loss: 1.3471 Training d_loss: 1.5996 Explore P: 0.9754\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 12 Total reward: 40.0 Average reward fake: 0.5561009049415588 Average reward real: 0.494981050491333 Training q_loss: 8.1038 Training g_loss: 1.2830 Training d_loss: 1.5388 Explore P: 0.9715\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 13 Total reward: 33.0 Average reward fake: 0.5327715873718262 Average reward real: 0.5030627250671387 Training q_loss: 6.2632 Training g_loss: 1.3356 Training d_loss: 1.4616 Explore P: 0.9683\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 14 Total reward: 28.0 Average reward fake: 0.5241833329200745 Average reward real: 0.49872902035713196 Training q_loss: 7.3449 Training g_loss: 1.3424 Training d_loss: 1.4497 Explore P: 0.9657\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 15 Total reward: 22.0 Average reward fake: 0.5159814357757568 Average reward real: 0.5066978335380554 Training q_loss: 10.6580 Training g_loss: 1.3703 Training d_loss: 1.4080 Explore P: 0.9636\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 16 Total reward: 23.0 Average reward fake: 0.4950701892375946 Average reward real: 0.4990864098072052 Training q_loss: 6.5106 Training g_loss: 1.3952 Training d_loss: 1.3832 Explore P: 0.9614\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 17 Total reward: 19.0 Average reward fake: 0.5349422693252563 Average reward real: 0.5029582381248474 Training q_loss: 7.9465 Training g_loss: 1.3281 Training d_loss: 1.4606 Explore P: 0.9596\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 18 Total reward: 43.0 Average reward fake: 0.5055608153343201 Average reward real: 0.5051793456077576 Training q_loss: 15.8982 Training g_loss: 1.3867 Training d_loss: 1.3889 Explore P: 0.9555\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 19 Total reward: 12.0 Average reward fake: 0.5056262016296387 Average reward real: 0.5052337050437927 Training q_loss: 13.6244 Training g_loss: 1.3872 Training d_loss: 1.3911 Explore P: 0.9544\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 20 Total reward: 28.0 Average reward fake: 0.5047410726547241 Average reward real: 0.48459750413894653 Training q_loss: 14.4122 Training g_loss: 1.3473 Training d_loss: 1.4414 Explore P: 0.9517\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 21 Total reward: 27.0 Average reward fake: 0.5034059286117554 Average reward real: 0.49748459458351135 Training q_loss: 21.0522 Training g_loss: 1.3751 Training d_loss: 1.4001 Explore P: 0.9492\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 22 Total reward: 17.0 Average reward fake: 0.5137003064155579 Average reward real: 0.5013752579689026 Training q_loss: 50.4785 Training g_loss: 1.3615 Training d_loss: 1.4265 Explore P: 0.9476\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 23 Total reward: 18.0 Average reward fake: 0.4960657060146332 Average reward real: 0.492096871137619 Training q_loss: 19.0413 Training g_loss: 1.3769 Training d_loss: 1.4086 Explore P: 0.9459\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 24 Total reward: 14.0 Average reward fake: 0.5066484808921814 Average reward real: 0.49603408575057983 Training q_loss: 19.4808 Training g_loss: 1.3667 Training d_loss: 1.4096 Explore P: 0.9446\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 25 Total reward: 15.0 Average reward fake: 0.5011744499206543 Average reward real: 0.49497756361961365 Training q_loss: 44.8162 Training g_loss: 1.3750 Training d_loss: 1.3996 Explore P: 0.9432\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 26 Total reward: 14.0 Average reward fake: 0.4962945580482483 Average reward real: 0.494762122631073 Training q_loss: 31.0397 Training g_loss: 1.3838 Training d_loss: 1.3897 Explore P: 0.9419\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 27 Total reward: 13.0 Average reward fake: 0.5020052194595337 Average reward real: 0.4971773624420166 Training q_loss: 78.8064 Training g_loss: 1.3804 Training d_loss: 1.4141 Explore P: 0.9407\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 28 Total reward: 51.0 Average reward fake: 0.5096885561943054 Average reward real: 0.4997689127922058 Training q_loss: 137.5586 Training g_loss: 1.3685 Training d_loss: 1.4047 Explore P: 0.9359\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 29 Total reward: 26.0 Average reward fake: 0.5095169544219971 Average reward real: 0.4970993101596832 Training q_loss: 45.2338 Training g_loss: 1.3639 Training d_loss: 1.4233 Explore P: 0.9335\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 30 Total reward: 20.0 Average reward fake: 0.5045146942138672 Average reward real: 0.4959184527397156 Training q_loss: 62.9274 Training g_loss: 1.3702 Training d_loss: 1.4051 Explore P: 0.9317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 31 Total reward: 24.0 Average reward fake: 0.49049896001815796 Average reward real: 0.5005533695220947 Training q_loss: 85.4710 Training g_loss: 1.4697 Training d_loss: 1.3638 Explore P: 0.9295\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 32 Total reward: 10.0 Average reward fake: 0.4999751150608063 Average reward real: 0.5026857256889343 Training q_loss: 84.6335 Training g_loss: 1.3930 Training d_loss: 1.4152 Explore P: 0.9286\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 33 Total reward: 14.0 Average reward fake: 0.4929905831813812 Average reward real: 0.49610427021980286 Training q_loss: 96.6058 Training g_loss: 1.3927 Training d_loss: 1.3812 Explore P: 0.9273\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 34 Total reward: 16.0 Average reward fake: 0.4981211721897125 Average reward real: 0.49965083599090576 Training q_loss: 109.0341 Training g_loss: 1.3884 Training d_loss: 1.3873 Explore P: 0.9258\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 35 Total reward: 13.0 Average reward fake: 0.49418962001800537 Average reward real: 0.5015111565589905 Training q_loss: 116.7142 Training g_loss: 1.4215 Training d_loss: 1.3766 Explore P: 0.9246\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 36 Total reward: 51.0 Average reward fake: 0.49377524852752686 Average reward real: 0.5022579431533813 Training q_loss: 117.8358 Training g_loss: 1.4016 Training d_loss: 1.3762 Explore P: 0.9200\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 37 Total reward: 13.0 Average reward fake: 0.4712837338447571 Average reward real: 0.5006058216094971 Training q_loss: 277.8805 Training g_loss: 1.4505 Training d_loss: 1.3686 Explore P: 0.9188\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 38 Total reward: 23.0 Average reward fake: 0.4800238311290741 Average reward real: 0.504118025302887 Training q_loss: 77.4575 Training g_loss: 1.5950 Training d_loss: 1.3520 Explore P: 0.9167\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 39 Total reward: 19.0 Average reward fake: 0.5021971464157104 Average reward real: 0.5067258477210999 Training q_loss: 136.7951 Training g_loss: 1.3981 Training d_loss: 1.3893 Explore P: 0.9150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 40 Total reward: 38.0 Average reward fake: 0.5073023438453674 Average reward real: 0.5056098699569702 Training q_loss: 123.2425 Training g_loss: 1.3847 Training d_loss: 1.3835 Explore P: 0.9115\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 41 Total reward: 29.0 Average reward fake: 0.4986971616744995 Average reward real: 0.5176441073417664 Training q_loss: 258.0519 Training g_loss: 1.4224 Training d_loss: 1.3272 Explore P: 0.9089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 42 Total reward: 28.0 Average reward fake: 0.5064377784729004 Average reward real: 0.5134178996086121 Training q_loss: 267.8463 Training g_loss: 1.4043 Training d_loss: 1.1993 Explore P: 0.9064\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 43 Total reward: 29.0 Average reward fake: 0.46014735102653503 Average reward real: 0.5296528339385986 Training q_loss: 154.0554 Training g_loss: 1.5388 Training d_loss: 1.3237 Explore P: 0.9038\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 44 Total reward: 33.0 Average reward fake: 0.35072001814842224 Average reward real: 0.5450270175933838 Training q_loss: 491.1057 Training g_loss: 1.8446 Training d_loss: 1.2611 Explore P: 0.9009\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 45 Total reward: 29.0 Average reward fake: 0.246749609708786 Average reward real: 0.5675600171089172 Training q_loss: 526.9448 Training g_loss: 2.3418 Training d_loss: 0.7571 Explore P: 0.8983\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 46 Total reward: 16.0 Average reward fake: 0.35242173075675964 Average reward real: 0.6497968435287476 Training q_loss: 346.5304 Training g_loss: 2.1710 Training d_loss: 0.8098 Explore P: 0.8969\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 47 Total reward: 23.0 Average reward fake: 0.29096561670303345 Average reward real: 0.638033926486969 Training q_loss: 661.7241 Training g_loss: 2.3400 Training d_loss: 0.7055 Explore P: 0.8948\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 48 Total reward: 46.0 Average reward fake: 0.13827085494995117 Average reward real: 0.8072196245193481 Training q_loss: 704.8333 Training g_loss: 4.4214 Training d_loss: 0.4472 Explore P: 0.8908\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 49 Total reward: 25.0 Average reward fake: 0.4127940237522125 Average reward real: 0.5821813941001892 Training q_loss: 967.9486 Training g_loss: 1.8083 Training d_loss: 0.7079 Explore P: 0.8886\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 50 Total reward: 13.0 Average reward fake: 0.021018320694565773 Average reward real: 0.7281336784362793 Training q_loss: 1191.2271 Training g_loss: 6.7544 Training d_loss: 0.3640 Explore P: 0.8874\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 51 Total reward: 35.0 Average reward fake: 0.16096191108226776 Average reward real: 0.7765307426452637 Training q_loss: 774.1387 Training g_loss: 3.9102 Training d_loss: 0.8089 Explore P: 0.8844\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 52 Total reward: 54.0 Average reward fake: 0.27283990383148193 Average reward real: 0.8185631632804871 Training q_loss: 2659.7764 Training g_loss: 3.3128 Training d_loss: 0.4203 Explore P: 0.8797\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 53 Total reward: 84.0 Average reward fake: 0.04091043397784233 Average reward real: 0.9012472629547119 Training q_loss: 1705.4631 Training g_loss: 7.9415 Training d_loss: 0.2278 Explore P: 0.8724\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 54 Total reward: 12.0 Average reward fake: 0.11777340620756149 Average reward real: 0.8981620073318481 Training q_loss: 1811.3545 Training g_loss: 5.2155 Training d_loss: 0.1334 Explore P: 0.8714\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 55 Total reward: 10.0 Average reward fake: 0.009465519338846207 Average reward real: 0.9191814661026001 Training q_loss: 3361.4900 Training g_loss: 11.1409 Training d_loss: 0.1020 Explore P: 0.8705\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 56 Total reward: 12.0 Average reward fake: 0.007336590439081192 Average reward real: 0.9200959205627441 Training q_loss: 2798.8875 Training g_loss: 15.4480 Training d_loss: 0.4531 Explore P: 0.8695\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 57 Total reward: 17.0 Average reward fake: 0.007622026838362217 Average reward real: 0.9264573454856873 Training q_loss: 1880.3816 Training g_loss: 16.4689 Training d_loss: 0.1038 Explore P: 0.8680\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 58 Total reward: 42.0 Average reward fake: 0.023324737325310707 Average reward real: 0.8778407573699951 Training q_loss: 3679.1328 Training g_loss: 8.5991 Training d_loss: 0.2082 Explore P: 0.8644\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 59 Total reward: 60.0 Average reward fake: 0.0014757808530703187 Average reward real: 0.9554550647735596 Training q_loss: 10403.8252 Training g_loss: 39.4729 Training d_loss: 0.0667 Explore P: 0.8593\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 60 Total reward: 48.0 Average reward fake: 0.07884127646684647 Average reward real: 0.9648280143737793 Training q_loss: 4563.6646 Training g_loss: 8.4832 Training d_loss: 0.0522 Explore P: 0.8552\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 61 Total reward: 48.0 Average reward fake: 0.06805215030908585 Average reward real: 0.9710804224014282 Training q_loss: 7728.9219 Training g_loss: 10.7434 Training d_loss: 0.0518 Explore P: 0.8512\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 62 Total reward: 10.0 Average reward fake: 0.08379989862442017 Average reward real: 0.9709862470626831 Training q_loss: 13336.8223 Training g_loss: 9.1115 Training d_loss: 0.0609 Explore P: 0.8503\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 63 Total reward: 20.0 Average reward fake: 0.006416928023099899 Average reward real: 0.9733777642250061 Training q_loss: 5945.3726 Training g_loss: 27.2161 Training d_loss: 0.0449 Explore P: 0.8487\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 64 Total reward: 15.0 Average reward fake: 0.01678277924656868 Average reward real: 0.9764022827148438 Training q_loss: 14799.9854 Training g_loss: 17.6105 Training d_loss: 0.0316 Explore P: 0.8474\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 65 Total reward: 18.0 Average reward fake: 0.05494144931435585 Average reward real: 0.9743340015411377 Training q_loss: 26199.9102 Training g_loss: 10.1719 Training d_loss: 0.0334 Explore P: 0.8459\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 66 Total reward: 18.0 Average reward fake: 0.02070050686597824 Average reward real: 0.9674278497695923 Training q_loss: 20688.7676 Training g_loss: 13.2135 Training d_loss: 0.1045 Explore P: 0.8444\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 67 Total reward: 11.0 Average reward fake: 0.02798791415989399 Average reward real: 0.9613146185874939 Training q_loss: 8350.1992 Training g_loss: 15.0100 Training d_loss: 0.0736 Explore P: 0.8435\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 68 Total reward: 11.0 Average reward fake: 0.026165984570980072 Average reward real: 0.967348039150238 Training q_loss: 11508.7109 Training g_loss: 15.3700 Training d_loss: 0.0933 Explore P: 0.8426\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 69 Total reward: 37.0 Average reward fake: 0.017244571819901466 Average reward real: 0.9786222577095032 Training q_loss: 13303.9717 Training g_loss: 14.5344 Training d_loss: 0.0768 Explore P: 0.8395\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 70 Total reward: 34.0 Average reward fake: 0.054800134152173996 Average reward real: 0.9658633470535278 Training q_loss: 17555.3418 Training g_loss: 9.0355 Training d_loss: 0.0385 Explore P: 0.8367\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 71 Total reward: 39.0 Average reward fake: 0.0029147977475076914 Average reward real: 0.9813252091407776 Training q_loss: 18452.7090 Training g_loss: 19.0300 Training d_loss: 1.8755 Explore P: 0.8335\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 72 Total reward: 13.0 Average reward fake: 0.0003032199165318161 Average reward real: 0.9677597284317017 Training q_loss: 35569.9570 Training g_loss: 22.7670 Training d_loss: 0.0373 Explore P: 0.8324\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 73 Total reward: 80.0 Average reward fake: 0.0007798071019351482 Average reward real: 0.9837782382965088 Training q_loss: 56275.8438 Training g_loss: 77.0538 Training d_loss: 0.0192 Explore P: 0.8258\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 74 Total reward: 49.0 Average reward fake: 0.020234031602740288 Average reward real: 0.9889042377471924 Training q_loss: 101081.3125 Training g_loss: 14.9343 Training d_loss: 0.0119 Explore P: 0.8218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 75 Total reward: 18.0 Average reward fake: 0.006269318517297506 Average reward real: 0.990196704864502 Training q_loss: 102933.2578 Training g_loss: 46.0886 Training d_loss: 0.0114 Explore P: 0.8204\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 76 Total reward: 45.0 Average reward fake: 4.032056676805951e-05 Average reward real: 0.9916897416114807 Training q_loss: 64724.9492 Training g_loss: 47.2562 Training d_loss: 0.0087 Explore P: 0.8167\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 77 Total reward: 10.0 Average reward fake: 0.012054414488375187 Average reward real: 0.9943166971206665 Training q_loss: 136191.5625 Training g_loss: 29.8431 Training d_loss: 0.0137 Explore P: 0.8159\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 78 Total reward: 45.0 Average reward fake: 0.008143539540469646 Average reward real: 0.9949765205383301 Training q_loss: 250461.5938 Training g_loss: 41.5980 Training d_loss: 0.0379 Explore P: 0.8123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 79 Total reward: 20.0 Average reward fake: 2.4479007709743428e-09 Average reward real: 0.9974604845046997 Training q_loss: 147418.2188 Training g_loss: 73.8543 Training d_loss: 0.0025 Explore P: 0.8107\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 80 Total reward: 10.0 Average reward fake: 0.004897697828710079 Average reward real: 0.9956262111663818 Training q_loss: 87900.5625 Training g_loss: 50.2812 Training d_loss: 0.0049 Explore P: 0.8099\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 81 Total reward: 47.0 Average reward fake: 8.239686394517776e-06 Average reward real: 0.9962877035140991 Training q_loss: 394734.7500 Training g_loss: 45.1179 Training d_loss: 0.0154 Explore P: 0.8062\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 82 Total reward: 19.0 Average reward fake: 1.0359923097343071e-13 Average reward real: 0.9949687123298645 Training q_loss: 174329.6406 Training g_loss: 107.2979 Training d_loss: 0.0051 Explore P: 0.8047\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 83 Total reward: 44.0 Average reward fake: 4.0299441025126725e-05 Average reward real: 0.9937989711761475 Training q_loss: 217255.8594 Training g_loss: 26.0284 Training d_loss: 0.0073 Explore P: 0.8012\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 84 Total reward: 13.0 Average reward fake: 8.766796781856101e-06 Average reward real: 0.9921154975891113 Training q_loss: 280990.6250 Training g_loss: 41.2022 Training d_loss: 0.0082 Explore P: 0.8001\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 85 Total reward: 20.0 Average reward fake: 5.570373673435824e-07 Average reward real: 0.9951678514480591 Training q_loss: 261748.7969 Training g_loss: 53.1159 Training d_loss: 0.0290 Explore P: 0.7986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 86 Total reward: 23.0 Average reward fake: 8.391783694605692e-07 Average reward real: 0.9945095777511597 Training q_loss: 180754.0000 Training g_loss: 61.9260 Training d_loss: 0.0056 Explore P: 0.7967\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 87 Total reward: 116.0 Average reward fake: 1.8480252037988976e-05 Average reward real: 0.9979856610298157 Training q_loss: 1265918.5000 Training g_loss: 79.9860 Training d_loss: 0.0020 Explore P: 0.7877\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 88 Total reward: 84.0 Average reward fake: 3.270633486263108e-10 Average reward real: 0.9982637166976929 Training q_loss: 704549.2500 Training g_loss: 100.1609 Training d_loss: 0.0017 Explore P: 0.7812\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 89 Total reward: 13.0 Average reward fake: 9.470000339462104e-10 Average reward real: 0.9988479614257812 Training q_loss: 1210852.0000 Training g_loss: 124.3457 Training d_loss: 0.0012 Explore P: 0.7802\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 90 Total reward: 35.0 Average reward fake: 3.2505176935510027e-12 Average reward real: 0.9984729886054993 Training q_loss: 1092123.7500 Training g_loss: 104.1842 Training d_loss: 0.0015 Explore P: 0.7775\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 91 Total reward: 23.0 Average reward fake: 1.0169830202170019e-19 Average reward real: 0.9984042644500732 Training q_loss: 690849.7500 Training g_loss: 143.9700 Training d_loss: 0.0016 Explore P: 0.7757\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 92 Total reward: 29.0 Average reward fake: 8.594616734475995e-16 Average reward real: 0.9988481998443604 Training q_loss: 1742746.5000 Training g_loss: 132.8675 Training d_loss: 0.0012 Explore P: 0.7735\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 93 Total reward: 16.0 Average reward fake: 9.719756249859657e-12 Average reward real: 0.9987898468971252 Training q_loss: 1875219.2500 Training g_loss: 138.4331 Training d_loss: 0.0012 Explore P: 0.7723\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 94 Total reward: 57.0 Average reward fake: 4.873413574604661e-18 Average reward real: 0.9949676394462585 Training q_loss: 1795252.3750 Training g_loss: 186.4124 Training d_loss: 0.0066 Explore P: 0.7679\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 95 Total reward: 24.0 Average reward fake: 8.75835515223855e-11 Average reward real: 0.9992547631263733 Training q_loss: 1591614.3750 Training g_loss: 87.4154 Training d_loss: 0.0007 Explore P: 0.7661\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 96 Total reward: 25.0 Average reward fake: 6.401627561380963e-10 Average reward real: 0.9993106722831726 Training q_loss: 2636569.2500 Training g_loss: 102.2949 Training d_loss: 0.0007 Explore P: 0.7642\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 97 Total reward: 75.0 Average reward fake: 3.2305706906358967e-16 Average reward real: 0.9991466403007507 Training q_loss: 2013887.2500 Training g_loss: 93.1033 Training d_loss: 0.0009 Explore P: 0.7586\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 98 Total reward: 24.0 Average reward fake: 1.6525305568393378e-08 Average reward real: 0.9994340538978577 Training q_loss: 4052445.5000 Training g_loss: 63.7573 Training d_loss: 0.0006 Explore P: 0.7568\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 99 Total reward: 21.0 Average reward fake: 7.72918784530674e-10 Average reward real: 0.9993988871574402 Training q_loss: 8462903.0000 Training g_loss: 49.2159 Training d_loss: 0.0006 Explore P: 0.7552\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 100 Total reward: 74.0 Average reward fake: 1.8216053394425752e-14 Average reward real: 0.9988967180252075 Training q_loss: 1864877.7500 Training g_loss: 85.1749 Training d_loss: 0.0011 Explore P: 0.7497\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 101 Total reward: 38.0 Average reward fake: 1.763781280137408e-27 Average reward real: 0.99934983253479 Training q_loss: 1626292.3750 Training g_loss: 174.6692 Training d_loss: 0.0007 Explore P: 0.7469\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 102 Total reward: 40.0 Average reward fake: 1.0118453147025478e-14 Average reward real: 0.9993586540222168 Training q_loss: 1888324.1250 Training g_loss: 119.9420 Training d_loss: 0.0006 Explore P: 0.7440\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 103 Total reward: 15.0 Average reward fake: 6.736303475918248e-06 Average reward real: 0.9994021654129028 Training q_loss: 6221486.0000 Training g_loss: 67.1640 Training d_loss: 0.0006 Explore P: 0.7429\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 104 Total reward: 36.0 Average reward fake: 6.511147870869038e-11 Average reward real: 0.9997116923332214 Training q_loss: 2834965.0000 Training g_loss: 254.9983 Training d_loss: 0.0003 Explore P: 0.7403\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 105 Total reward: 31.0 Average reward fake: 1.515715886135638e-10 Average reward real: 0.9996637105941772 Training q_loss: 13582931.0000 Training g_loss: 127.3865 Training d_loss: 0.0003 Explore P: 0.7380\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 106 Total reward: 14.0 Average reward fake: 3.789278546023839e-15 Average reward real: 0.9996209144592285 Training q_loss: 6018824.5000 Training g_loss: 124.9707 Training d_loss: 0.0004 Explore P: 0.7370\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 107 Total reward: 30.0 Average reward fake: 2.950079784984092e-28 Average reward real: 0.9996166825294495 Training q_loss: 5675798.5000 Training g_loss: 407.8166 Training d_loss: 0.0004 Explore P: 0.7348\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 108 Total reward: 16.0 Average reward fake: 4.188161861588824e-13 Average reward real: 0.9996649026870728 Training q_loss: 7378450.5000 Training g_loss: 137.8495 Training d_loss: 0.0003 Explore P: 0.7336\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 109 Total reward: 29.0 Average reward fake: 3.246409585599963e-09 Average reward real: 0.9996150732040405 Training q_loss: 15751448.0000 Training g_loss: 163.2143 Training d_loss: 0.0004 Explore P: 0.7316\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 110 Total reward: 18.0 Average reward fake: 1.0759793056536182e-10 Average reward real: 0.9996755719184875 Training q_loss: 5805881.5000 Training g_loss: 49.5818 Training d_loss: 0.0003 Explore P: 0.7303\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 111 Total reward: 29.0 Average reward fake: 1.9171776509729445e-23 Average reward real: 0.9997519850730896 Training q_loss: 15327095.0000 Training g_loss: 133.0549 Training d_loss: 0.0002 Explore P: 0.7282\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 112 Total reward: 32.0 Average reward fake: 4.2795199988177046e-05 Average reward real: 0.9996722340583801 Training q_loss: 20339906.0000 Training g_loss: 67.9394 Training d_loss: 0.0003 Explore P: 0.7259\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 113 Total reward: 57.0 Average reward fake: 6.804230361012742e-05 Average reward real: 0.9997296929359436 Training q_loss: 19364058.0000 Training g_loss: 160.2677 Training d_loss: 0.0003 Explore P: 0.7218\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 114 Total reward: 114.0 Average reward fake: 3.3570279245924365e-30 Average reward real: 0.9996604919433594 Training q_loss: 13736351.0000 Training g_loss: 191.2688 Training d_loss: 0.0003 Explore P: 0.7137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 115 Total reward: 64.0 Average reward fake: 2.970677424314432e-16 Average reward real: 0.9995481371879578 Training q_loss: 40382672.0000 Training g_loss: 201.0075 Training d_loss: 0.0005 Explore P: 0.7092\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 116 Total reward: 19.0 Average reward fake: 3.0633139766842864e-16 Average reward real: 0.9996523261070251 Training q_loss: 35220784.0000 Training g_loss: 156.8259 Training d_loss: 0.0003 Explore P: 0.7079\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 117 Total reward: 10.0 Average reward fake: 6.897440789094961e-14 Average reward real: 0.9994364976882935 Training q_loss: 53095224.0000 Training g_loss: 135.2301 Training d_loss: 0.0006 Explore P: 0.7072\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 118 Total reward: 38.0 Average reward fake: 1.8898835006504419e-16 Average reward real: 0.9996869564056396 Training q_loss: 19920318.0000 Training g_loss: 149.4192 Training d_loss: 0.0003 Explore P: 0.7046\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 119 Total reward: 79.0 Average reward fake: 1.828104068124503e-08 Average reward real: 0.9997801780700684 Training q_loss: 42949256.0000 Training g_loss: 109.5132 Training d_loss: 0.0002 Explore P: 0.6991\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 120 Total reward: 34.0 Average reward fake: 9.39184687038172e-36 Average reward real: 0.9998733997344971 Training q_loss: 19723134.0000 Training g_loss: 293.5258 Training d_loss: 0.0001 Explore P: 0.6968\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 121 Total reward: 27.0 Average reward fake: 1.1528543296254503e-33 Average reward real: 0.9998895525932312 Training q_loss: 27442438.0000 Training g_loss: 262.0219 Training d_loss: 0.0001 Explore P: 0.6949\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 122 Total reward: 47.0 Average reward fake: 1.1240733241032296e-21 Average reward real: 0.9998141527175903 Training q_loss: 35338204.0000 Training g_loss: 202.3794 Training d_loss: 0.0002 Explore P: 0.6917\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 123 Total reward: 17.0 Average reward fake: 2.6087662952272518e-22 Average reward real: 0.9996906518936157 Training q_loss: 71426616.0000 Training g_loss: 362.7899 Training d_loss: 0.0003 Explore P: 0.6906\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 124 Total reward: 63.0 Average reward fake: 9.260507761579518e-34 Average reward real: 0.9996746778488159 Training q_loss: 34732428.0000 Training g_loss: 233.7706 Training d_loss: 0.0003 Explore P: 0.6863\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 125 Total reward: 27.0 Average reward fake: 1.5432929237911852e-27 Average reward real: 0.9998866319656372 Training q_loss: 66191984.0000 Training g_loss: 254.1495 Training d_loss: 0.0001 Explore P: 0.6845\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 126 Total reward: 8.0 Average reward fake: 0.0 Average reward real: 0.9999040365219116 Training q_loss: 55048520.0000 Training g_loss: 219.8208 Training d_loss: 0.0001 Explore P: 0.6839\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 127 Total reward: 16.0 Average reward fake: 5.417242828636954e-36 Average reward real: 0.9999048113822937 Training q_loss: 147958832.0000 Training g_loss: 283.6722 Training d_loss: 0.0001 Explore P: 0.6828\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 128 Total reward: 106.0 Average reward fake: 2.5728599027309242e-23 Average reward real: 0.9998530745506287 Training q_loss: 141113728.0000 Training g_loss: 240.2210 Training d_loss: 0.0001 Explore P: 0.6757\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 129 Total reward: 25.0 Average reward fake: 7.081736369930121e-21 Average reward real: 0.9999313354492188 Training q_loss: 114144296.0000 Training g_loss: 347.7455 Training d_loss: 0.0001 Explore P: 0.6741\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 130 Total reward: 82.0 Average reward fake: 6.52461008940515e-14 Average reward real: 0.9999063014984131 Training q_loss: 126092688.0000 Training g_loss: 107.5068 Training d_loss: 0.0001 Explore P: 0.6687\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 131 Total reward: 95.0 Average reward fake: 4.0879704677788953e-13 Average reward real: 0.99994295835495 Training q_loss: 63794088.0000 Training g_loss: 105.5120 Training d_loss: 0.0001 Explore P: 0.6624\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 132 Total reward: 45.0 Average reward fake: 4.9245089243580954e-39 Average reward real: 0.9998566508293152 Training q_loss: 94147872.0000 Training g_loss: 220.6049 Training d_loss: 0.0001 Explore P: 0.6595\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 133 Total reward: 125.0 Average reward fake: 1.5377179343811675e-26 Average reward real: 0.9999507069587708 Training q_loss: 284362560.0000 Training g_loss: 239.9252 Training d_loss: 0.0000 Explore P: 0.6514\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 134 Total reward: 127.0 Average reward fake: 7.563874078186927e-06 Average reward real: 0.9999563097953796 Training q_loss: 257448464.0000 Training g_loss: 260.9779 Training d_loss: 0.0000 Explore P: 0.6433\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 135 Total reward: 14.0 Average reward fake: 2.0411453561201718e-39 Average reward real: 0.9999458193778992 Training q_loss: 100306312.0000 Training g_loss: 136.6585 Training d_loss: 0.0001 Explore P: 0.6425\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 136 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9997379779815674 Training q_loss: 524495776.0000 Training g_loss: 443.5394 Training d_loss: 0.0003 Explore P: 0.6300\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 137 Total reward: 199.0 Average reward fake: 1.350061976613963e-25 Average reward real: 0.9999809265136719 Training q_loss: 181030080.0000 Training g_loss: 303.8258 Training d_loss: 0.0000 Explore P: 0.6178\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 138 Total reward: 18.0 Average reward fake: 3.5680188514795803e-32 Average reward real: 0.9999182224273682 Training q_loss: 161906224.0000 Training g_loss: 286.9932 Training d_loss: 0.0001 Explore P: 0.6167\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 139 Total reward: 32.0 Average reward fake: 2.06194053750253e-21 Average reward real: 0.9999563694000244 Training q_loss: 670878336.0000 Training g_loss: 184.4673 Training d_loss: 0.0000 Explore P: 0.6147\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 140 Total reward: 120.0 Average reward fake: 8.59459642155217e-27 Average reward real: 0.9999457597732544 Training q_loss: 394304896.0000 Training g_loss: 169.4719 Training d_loss: 0.0001 Explore P: 0.6075\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 141 Total reward: 77.0 Average reward fake: 0.0 Average reward real: 0.999973475933075 Training q_loss: 481856512.0000 Training g_loss: 280.8673 Training d_loss: 0.0000 Explore P: 0.6029\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 142 Total reward: 146.0 Average reward fake: 0.0 Average reward real: 0.998816728591919 Training q_loss: 665803520.0000 Training g_loss: 337.6574 Training d_loss: 0.0013 Explore P: 0.5944\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 143 Total reward: 29.0 Average reward fake: 2.3029911463848285e-38 Average reward real: 0.9999841451644897 Training q_loss: 319013184.0000 Training g_loss: 266.5995 Training d_loss: 0.0000 Explore P: 0.5927\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 144 Total reward: 32.0 Average reward fake: 5.21889931093731e-39 Average reward real: 0.999776303768158 Training q_loss: 601593664.0000 Training g_loss: 190.0414 Training d_loss: 0.0002 Explore P: 0.5908\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 145 Total reward: 160.0 Average reward fake: 0.0 Average reward real: 0.9999639987945557 Training q_loss: 240726880.0000 Training g_loss: 287.4946 Training d_loss: 0.0000 Explore P: 0.5816\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 146 Total reward: 59.0 Average reward fake: 3.996139183773636e-32 Average reward real: 0.9999984502792358 Training q_loss: 1275391616.0000 Training g_loss: 174.2562 Training d_loss: 0.0000 Explore P: 0.5782\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 147 Total reward: 125.0 Average reward fake: 0.0 Average reward real: 0.9998666644096375 Training q_loss: 1089197568.0000 Training g_loss: 306.0638 Training d_loss: 0.0001 Explore P: 0.5712\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 148 Total reward: 35.0 Average reward fake: 0.0 Average reward real: 0.999885618686676 Training q_loss: 940199104.0000 Training g_loss: 275.1008 Training d_loss: 0.0001 Explore P: 0.5692\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 149 Total reward: 47.0 Average reward fake: 0.0 Average reward real: 0.999885082244873 Training q_loss: 2010020224.0000 Training g_loss: 230.1484 Training d_loss: 0.0001 Explore P: 0.5666\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 150 Total reward: 36.0 Average reward fake: 3.038518675340193e-16 Average reward real: 0.9999673366546631 Training q_loss: 1363533184.0000 Training g_loss: 314.8126 Training d_loss: 0.0000 Explore P: 0.5646\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 151 Total reward: 141.0 Average reward fake: 0.0 Average reward real: 0.999998927116394 Training q_loss: 1946880512.0000 Training g_loss: 218.7113 Training d_loss: 0.0000 Explore P: 0.5568\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 152 Total reward: 95.0 Average reward fake: 2.043152827138806e-31 Average reward real: 0.9999983310699463 Training q_loss: 1549590528.0000 Training g_loss: 149.5244 Training d_loss: 0.0000 Explore P: 0.5516\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 153 Total reward: 14.0 Average reward fake: 6.743086692273769e-33 Average reward real: 0.9999969005584717 Training q_loss: 475318592.0000 Training g_loss: 257.6935 Training d_loss: 0.0000 Explore P: 0.5509\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 154 Total reward: 18.0 Average reward fake: 9.919412262881979e-15 Average reward real: 0.9999651312828064 Training q_loss: 1065955072.0000 Training g_loss: 301.4401 Training d_loss: 0.0000 Explore P: 0.5499\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 155 Total reward: 16.0 Average reward fake: 0.0 Average reward real: 0.9998905062675476 Training q_loss: 596625024.0000 Training g_loss: 216.8209 Training d_loss: 0.0001 Explore P: 0.5490\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 156 Total reward: 22.0 Average reward fake: 3.868268079475835e-35 Average reward real: 0.9999017119407654 Training q_loss: 2318681088.0000 Training g_loss: 290.7412 Training d_loss: 0.0001 Explore P: 0.5479\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 157 Total reward: 116.0 Average reward fake: 0.0 Average reward real: 0.9999241828918457 Training q_loss: 4123889152.0000 Training g_loss: 312.3728 Training d_loss: 0.0001 Explore P: 0.5417\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 158 Total reward: 199.0 Average reward fake: 1.9769606542597775e-21 Average reward real: 0.9999790787696838 Training q_loss: 1888273664.0000 Training g_loss: 182.2452 Training d_loss: 0.0000 Explore P: 0.5312\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 159 Total reward: 164.0 Average reward fake: 0.0 Average reward real: 0.9986541271209717 Training q_loss: 2007569920.0000 Training g_loss: 337.6091 Training d_loss: 0.0015 Explore P: 0.5227\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 160 Total reward: 159.0 Average reward fake: 0.0 Average reward real: 0.9998704791069031 Training q_loss: 1963463680.0000 Training g_loss: 228.9424 Training d_loss: 0.0001 Explore P: 0.5146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 161 Total reward: 164.0 Average reward fake: 2.8361831559522e-22 Average reward real: 0.99993497133255 Training q_loss: 2408870912.0000 Training g_loss: 192.9028 Training d_loss: 0.0001 Explore P: 0.5064\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 162 Total reward: 34.0 Average reward fake: 0.0 Average reward real: 0.99994957447052 Training q_loss: 3037595904.0000 Training g_loss: 295.5449 Training d_loss: 0.0001 Explore P: 0.5047\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 163 Total reward: 101.0 Average reward fake: 6.70904290049725e-39 Average reward real: 0.9999988079071045 Training q_loss: 2055972480.0000 Training g_loss: 229.9926 Training d_loss: 0.0000 Explore P: 0.4998\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 164 Total reward: 44.0 Average reward fake: 1.1925255227751563e-10 Average reward real: 0.9999992251396179 Training q_loss: 2535929344.0000 Training g_loss: 204.0904 Training d_loss: 0.0000 Explore P: 0.4976\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 165 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999441504478455 Training q_loss: 2079907200.0000 Training g_loss: 328.3344 Training d_loss: 0.0001 Explore P: 0.4880\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 166 Total reward: 103.0 Average reward fake: 1.2679679200075844e-33 Average reward real: 0.9999936819076538 Training q_loss: 17935046656.0000 Training g_loss: 316.3382 Training d_loss: 0.0000 Explore P: 0.4831\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 167 Total reward: 151.0 Average reward fake: 0.0 Average reward real: 0.9999978542327881 Training q_loss: 5876508672.0000 Training g_loss: 266.4240 Training d_loss: 0.0000 Explore P: 0.4760\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 168 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999997615814209 Training q_loss: 1231535744.0000 Training g_loss: 201.0860 Training d_loss: 0.0000 Explore P: 0.4668\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 169 Total reward: 199.0 Average reward fake: 2.600989420433657e-23 Average reward real: 0.9999962449073792 Training q_loss: 2700059136.0000 Training g_loss: 124.0559 Training d_loss: 0.0000 Explore P: 0.4578\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 170 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.999948263168335 Training q_loss: 5656356352.0000 Training g_loss: 207.1120 Training d_loss: 0.0001 Explore P: 0.4490\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 171 Total reward: 199.0 Average reward fake: 7.361384910258328e-23 Average reward real: 0.9998833537101746 Training q_loss: 3299231744.0000 Training g_loss: 143.4678 Training d_loss: 0.0001 Explore P: 0.4404\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 172 Total reward: 168.0 Average reward fake: 2.3106266337411532e-33 Average reward real: 0.9999901652336121 Training q_loss: 4911343104.0000 Training g_loss: 212.8866 Training d_loss: 0.0000 Explore P: 0.4332\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 173 Total reward: 34.0 Average reward fake: 8.77532099890968e-33 Average reward real: 0.9999947547912598 Training q_loss: 3424759040.0000 Training g_loss: 193.0170 Training d_loss: 0.0000 Explore P: 0.4317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 174 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999977946281433 Training q_loss: 2312870912.0000 Training g_loss: 191.5141 Training d_loss: 0.0000 Explore P: 0.4234\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 175 Total reward: 199.0 Average reward fake: 1.945645304041939e-27 Average reward real: 0.9999812245368958 Training q_loss: 16971388928.0000 Training g_loss: 131.9213 Training d_loss: 0.0000 Explore P: 0.4153\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 176 Total reward: 199.0 Average reward fake: 1.2259278865203134e-18 Average reward real: 0.9999578595161438 Training q_loss: 9330903040.0000 Training g_loss: 135.0638 Training d_loss: 0.0000 Explore P: 0.4073\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 177 Total reward: 199.0 Average reward fake: 2.4557059628486477e-34 Average reward real: 0.9999687075614929 Training q_loss: 5521676288.0000 Training g_loss: 138.7221 Training d_loss: 0.0000 Explore P: 0.3995\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 178 Total reward: 177.0 Average reward fake: 4.4143567628118616e-24 Average reward real: 0.99997878074646 Training q_loss: 1830546176.0000 Training g_loss: 162.2709 Training d_loss: 0.0000 Explore P: 0.3926\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 179 Total reward: 141.0 Average reward fake: 1.4128809680923153e-31 Average reward real: 0.9999912977218628 Training q_loss: 3323078912.0000 Training g_loss: 209.8453 Training d_loss: 0.0000 Explore P: 0.3873\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 180 Total reward: 180.0 Average reward fake: 5.866756865533824e-38 Average reward real: 0.9999637007713318 Training q_loss: 5424395776.0000 Training g_loss: 173.0301 Training d_loss: 0.0000 Explore P: 0.3806\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 181 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999485015869141 Training q_loss: 2593233408.0000 Training g_loss: 283.7033 Training d_loss: 0.0001 Explore P: 0.3733\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 182 Total reward: 177.0 Average reward fake: 1.948111810756714e-12 Average reward real: 0.9999828934669495 Training q_loss: 2216773120.0000 Training g_loss: 104.2248 Training d_loss: 0.0000 Explore P: 0.3669\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 183 Total reward: 199.0 Average reward fake: 1.2854374311364862e-17 Average reward real: 0.9999842643737793 Training q_loss: 3594660096.0000 Training g_loss: 144.5324 Training d_loss: 0.0000 Explore P: 0.3599\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 184 Total reward: 199.0 Average reward fake: 5.274066843652583e-24 Average reward real: 0.9998676776885986 Training q_loss: 3880089088.0000 Training g_loss: 151.9528 Training d_loss: 0.0001 Explore P: 0.3530\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 185 Total reward: 199.0 Average reward fake: 9.801402044483734e-17 Average reward real: 0.9999243021011353 Training q_loss: 2042132224.0000 Training g_loss: 162.9714 Training d_loss: 0.0001 Explore P: 0.3462\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 186 Total reward: 199.0 Average reward fake: 2.013228373646904e-25 Average reward real: 0.9999087452888489 Training q_loss: 8312664064.0000 Training g_loss: 165.8824 Training d_loss: 0.0001 Explore P: 0.3396\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 187 Total reward: 199.0 Average reward fake: 1.4094844180689847e-09 Average reward real: 0.9997820258140564 Training q_loss: 13524643840.0000 Training g_loss: 168.8416 Training d_loss: 0.0002 Explore P: 0.3331\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 188 Total reward: 199.0 Average reward fake: 1.3196719108113375e-12 Average reward real: 0.9998303055763245 Training q_loss: 33389387776.0000 Training g_loss: 129.8562 Training d_loss: 0.0002 Explore P: 0.3267\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 189 Total reward: 199.0 Average reward fake: 2.6687836385264063e-09 Average reward real: 0.9996864199638367 Training q_loss: 3281197824.0000 Training g_loss: 120.8214 Training d_loss: 0.0003 Explore P: 0.3205\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 190 Total reward: 179.0 Average reward fake: 3.920323894143439e-25 Average reward real: 0.9994511604309082 Training q_loss: 2075814144.0000 Training g_loss: 161.7016 Training d_loss: 0.0006 Explore P: 0.3150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 191 Total reward: 199.0 Average reward fake: 0.002447711070999503 Average reward real: 0.9988572597503662 Training q_loss: 2747614720.0000 Training g_loss: 112.0578 Training d_loss: 0.0019 Explore P: 0.3090\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 192 Total reward: 199.0 Average reward fake: 1.8887703974335886e-21 Average reward real: 0.9995623826980591 Training q_loss: 1593582336.0000 Training g_loss: 194.5820 Training d_loss: 0.0004 Explore P: 0.3031\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 193 Total reward: 19.0 Average reward fake: 2.103899760186323e-06 Average reward real: 0.9996035099029541 Training q_loss: 1573676800.0000 Training g_loss: 113.5807 Training d_loss: 0.0004 Explore P: 0.3025\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 194 Total reward: 199.0 Average reward fake: 4.966263179196659e-24 Average reward real: 0.9997711181640625 Training q_loss: 1979469440.0000 Training g_loss: 134.1068 Training d_loss: 0.0002 Explore P: 0.2967\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 195 Total reward: 199.0 Average reward fake: 6.606594438185454e-11 Average reward real: 0.999653160572052 Training q_loss: 1278218112.0000 Training g_loss: 122.3755 Training d_loss: 0.0003 Explore P: 0.2911\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 196 Total reward: 199.0 Average reward fake: 4.3314841491337575e-07 Average reward real: 0.9993710517883301 Training q_loss: 8921715712.0000 Training g_loss: 101.1486 Training d_loss: 0.0006 Explore P: 0.2856\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 197 Total reward: 199.0 Average reward fake: 6.25465168939014e-16 Average reward real: 0.9994919300079346 Training q_loss: 16368346112.0000 Training g_loss: 149.2156 Training d_loss: 0.0005 Explore P: 0.2801\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 198 Total reward: 199.0 Average reward fake: 0.0035266191698610783 Average reward real: 0.9991562366485596 Training q_loss: 3099858944.0000 Training g_loss: 110.8752 Training d_loss: 0.0008 Explore P: 0.2748\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 199 Total reward: 199.0 Average reward fake: 0.0019012625562027097 Average reward real: 0.9989681839942932 Training q_loss: 1574520064.0000 Training g_loss: 103.4691 Training d_loss: 0.0010 Explore P: 0.2696\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 200 Total reward: 199.0 Average reward fake: 4.3506680924565444e-08 Average reward real: 0.9994029998779297 Training q_loss: 1317731328.0000 Training g_loss: 126.0384 Training d_loss: 0.0006 Explore P: 0.2645\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 201 Total reward: 199.0 Average reward fake: 2.1607442590720893e-07 Average reward real: 0.999532163143158 Training q_loss: 1261504128.0000 Training g_loss: 102.1256 Training d_loss: 0.0005 Explore P: 0.2595\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 202 Total reward: 199.0 Average reward fake: 9.167330861981939e-15 Average reward real: 0.9956106543540955 Training q_loss: 1015344192.0000 Training g_loss: 184.3084 Training d_loss: 0.0046 Explore P: 0.2545\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 203 Total reward: 199.0 Average reward fake: 0.0034192397724837065 Average reward real: 0.997500479221344 Training q_loss: 1664269184.0000 Training g_loss: 121.1413 Training d_loss: 0.0119 Explore P: 0.2497\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 204 Total reward: 199.0 Average reward fake: 2.0633230679578674e-09 Average reward real: 0.9970167279243469 Training q_loss: 1194923648.0000 Training g_loss: 95.5578 Training d_loss: 0.0271 Explore P: 0.2450\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 205 Total reward: 199.0 Average reward fake: 7.504007157876913e-07 Average reward real: 0.9982646703720093 Training q_loss: 2746420480.0000 Training g_loss: 169.6052 Training d_loss: 0.0202 Explore P: 0.2404\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 206 Total reward: 199.0 Average reward fake: 0.0060952454805374146 Average reward real: 0.9971591830253601 Training q_loss: 704576448.0000 Training g_loss: 41.4492 Training d_loss: 0.0116 Explore P: 0.2358\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 207 Total reward: 199.0 Average reward fake: 0.0538351908326149 Average reward real: 0.9918544292449951 Training q_loss: 555649280.0000 Training g_loss: 31.4865 Training d_loss: 0.0126 Explore P: 0.2314\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 208 Total reward: 199.0 Average reward fake: 3.6552418869462144e-09 Average reward real: 0.994260847568512 Training q_loss: 1366068224.0000 Training g_loss: 65.2814 Training d_loss: 0.0476 Explore P: 0.2270\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 209 Total reward: 199.0 Average reward fake: 6.230125748629689e-09 Average reward real: 0.9811285138130188 Training q_loss: 3633383424.0000 Training g_loss: 81.3629 Training d_loss: 0.0209 Explore P: 0.2227\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 210 Total reward: 199.0 Average reward fake: 0.003382535185664892 Average reward real: 0.9953368902206421 Training q_loss: 558953216.0000 Training g_loss: 49.3748 Training d_loss: 0.0109 Explore P: 0.2186\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 211 Total reward: 199.0 Average reward fake: 0.006110051646828651 Average reward real: 0.9884265065193176 Training q_loss: 628494976.0000 Training g_loss: 53.5521 Training d_loss: 0.0369 Explore P: 0.2144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 212 Total reward: 199.0 Average reward fake: 0.016352158039808273 Average reward real: 0.9937781691551208 Training q_loss: 3168504064.0000 Training g_loss: 44.2168 Training d_loss: 0.0999 Explore P: 0.2104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 213 Total reward: 199.0 Average reward fake: 0.011274440214037895 Average reward real: 0.994303286075592 Training q_loss: 2605687808.0000 Training g_loss: 44.3430 Training d_loss: 0.0509 Explore P: 0.2065\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 214 Total reward: 199.0 Average reward fake: 0.021673979237675667 Average reward real: 0.9809839725494385 Training q_loss: 2629401088.0000 Training g_loss: 27.2756 Training d_loss: 0.1114 Explore P: 0.2026\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 215 Total reward: 199.0 Average reward fake: 0.001488580135628581 Average reward real: 0.9842227101325989 Training q_loss: 1636945408.0000 Training g_loss: 75.4107 Training d_loss: 0.0184 Explore P: 0.1988\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 216 Total reward: 199.0 Average reward fake: 0.016698945313692093 Average reward real: 0.8756103515625 Training q_loss: 311387488.0000 Training g_loss: 31.5614 Training d_loss: 0.2629 Explore P: 0.1951\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 217 Total reward: 199.0 Average reward fake: 0.024235649034380913 Average reward real: 0.9191095232963562 Training q_loss: 423254944.0000 Training g_loss: 24.2109 Training d_loss: 0.1579 Explore P: 0.1914\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 218 Total reward: 199.0 Average reward fake: 0.07160686701536179 Average reward real: 0.8735725283622742 Training q_loss: 205170912.0000 Training g_loss: 13.8768 Training d_loss: 0.2114 Explore P: 0.1879\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 219 Total reward: 199.0 Average reward fake: 0.03136453032493591 Average reward real: 0.9752333760261536 Training q_loss: 209257152.0000 Training g_loss: 18.0962 Training d_loss: 0.1157 Explore P: 0.1844\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 220 Total reward: 199.0 Average reward fake: 0.05162680521607399 Average reward real: 0.9265389442443848 Training q_loss: 360116192.0000 Training g_loss: 16.7543 Training d_loss: 0.1493 Explore P: 0.1809\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 221 Total reward: 199.0 Average reward fake: 0.025847630575299263 Average reward real: 0.9614072442054749 Training q_loss: 403848288.0000 Training g_loss: 22.3184 Training d_loss: 0.0930 Explore P: 0.1776\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 222 Total reward: 199.0 Average reward fake: 0.008351307362318039 Average reward real: 0.906270444393158 Training q_loss: 253649200.0000 Training g_loss: 20.1114 Training d_loss: 0.1513 Explore P: 0.1743\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 223 Total reward: 199.0 Average reward fake: 0.20552010834217072 Average reward real: 0.8597468733787537 Training q_loss: 271336704.0000 Training g_loss: 15.4153 Training d_loss: 0.2442 Explore P: 0.1710\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 224 Total reward: 199.0 Average reward fake: 0.08661872148513794 Average reward real: 0.9714048504829407 Training q_loss: 125897704.0000 Training g_loss: 16.3757 Training d_loss: 0.0769 Explore P: 0.1678\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 225 Total reward: 199.0 Average reward fake: 0.01813027821481228 Average reward real: 0.9234583973884583 Training q_loss: 296735712.0000 Training g_loss: 29.5375 Training d_loss: 0.2569 Explore P: 0.1647\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 226 Total reward: 199.0 Average reward fake: 0.05685622617602348 Average reward real: 0.9074496626853943 Training q_loss: 306765728.0000 Training g_loss: 15.4901 Training d_loss: 0.1684 Explore P: 0.1617\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 227 Total reward: 199.0 Average reward fake: 0.051800232380628586 Average reward real: 0.855592668056488 Training q_loss: 142705200.0000 Training g_loss: 15.1725 Training d_loss: 0.2206 Explore P: 0.1587\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 228 Total reward: 199.0 Average reward fake: 0.04901926964521408 Average reward real: 0.862261950969696 Training q_loss: 98554248.0000 Training g_loss: 10.4959 Training d_loss: 0.3837 Explore P: 0.1558\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 229 Total reward: 199.0 Average reward fake: 0.045092009007930756 Average reward real: 0.9262087941169739 Training q_loss: 135952368.0000 Training g_loss: 14.1337 Training d_loss: 0.2392 Explore P: 0.1529\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 230 Total reward: 199.0 Average reward fake: 0.09239589422941208 Average reward real: 0.9134914875030518 Training q_loss: 413948512.0000 Training g_loss: 7.2775 Training d_loss: 2.0371 Explore P: 0.1501\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 231 Total reward: 199.0 Average reward fake: 0.11398975551128387 Average reward real: 0.7715557813644409 Training q_loss: 139726272.0000 Training g_loss: 5.8544 Training d_loss: 0.3818 Explore P: 0.1473\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 232 Total reward: 195.0 Average reward fake: 0.21166324615478516 Average reward real: 0.7595522999763489 Training q_loss: 507056032.0000 Training g_loss: 5.8159 Training d_loss: 0.9949 Explore P: 0.1447\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 233 Total reward: 199.0 Average reward fake: 0.03639957681298256 Average reward real: 0.8239108324050903 Training q_loss: 109192184.0000 Training g_loss: 11.8954 Training d_loss: 0.3218 Explore P: 0.1420\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 234 Total reward: 199.0 Average reward fake: 0.5505281686782837 Average reward real: 0.7611711025238037 Training q_loss: 98143480.0000 Training g_loss: 5.0222 Training d_loss: 1.1136 Explore P: 0.1394\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 235 Total reward: 183.0 Average reward fake: 0.4521714150905609 Average reward real: 0.6050685048103333 Training q_loss: 76861024.0000 Training g_loss: 2.8178 Training d_loss: 1.3836 Explore P: 0.1371\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 236 Total reward: 105.0 Average reward fake: 0.44715049862861633 Average reward real: 0.6507612466812134 Training q_loss: 64229340.0000 Training g_loss: 6.4434 Training d_loss: 1.5815 Explore P: 0.1357\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 237 Total reward: 39.0 Average reward fake: 0.3930507004261017 Average reward real: 0.6096497774124146 Training q_loss: 78261448.0000 Training g_loss: 3.9155 Training d_loss: 0.8271 Explore P: 0.1352\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 238 Total reward: 199.0 Average reward fake: 0.31717386841773987 Average reward real: 0.6043360233306885 Training q_loss: 119417504.0000 Training g_loss: 5.1234 Training d_loss: 0.8242 Explore P: 0.1328\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 239 Total reward: 23.0 Average reward fake: 0.4125453233718872 Average reward real: 0.7036064267158508 Training q_loss: 170361328.0000 Training g_loss: 4.6398 Training d_loss: 1.1858 Explore P: 0.1325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 240 Total reward: 199.0 Average reward fake: 0.3791171610355377 Average reward real: 0.6117085814476013 Training q_loss: 51376312.0000 Training g_loss: 3.1922 Training d_loss: 1.0135 Explore P: 0.1301\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 241 Total reward: 199.0 Average reward fake: 0.5082843899726868 Average reward real: 0.606219470500946 Training q_loss: 101399808.0000 Training g_loss: 3.1207 Training d_loss: 1.0855 Explore P: 0.1277\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 242 Total reward: 199.0 Average reward fake: 0.3163765072822571 Average reward real: 0.5176199674606323 Training q_loss: 73184232.0000 Training g_loss: 2.5444 Training d_loss: 0.9735 Explore P: 0.1254\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 243 Total reward: 36.0 Average reward fake: 0.45824041962623596 Average reward real: 0.6445060968399048 Training q_loss: 35249092.0000 Training g_loss: 2.6371 Training d_loss: 1.2804 Explore P: 0.1250\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 244 Total reward: 193.0 Average reward fake: 0.3124462068080902 Average reward real: 0.7003869414329529 Training q_loss: 252755536.0000 Training g_loss: 3.9757 Training d_loss: 1.1409 Explore P: 0.1228\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 245 Total reward: 99.0 Average reward fake: 0.49431487917900085 Average reward real: 0.5907792448997498 Training q_loss: 35844192.0000 Training g_loss: 2.7614 Training d_loss: 1.0811 Explore P: 0.1217\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 246 Total reward: 199.0 Average reward fake: 0.3919501006603241 Average reward real: 0.6009688973426819 Training q_loss: 68716288.0000 Training g_loss: 6.4298 Training d_loss: 0.8428 Explore P: 0.1195\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 247 Total reward: 77.0 Average reward fake: 0.3928157389163971 Average reward real: 0.6929073929786682 Training q_loss: 73538584.0000 Training g_loss: 3.2758 Training d_loss: 0.8648 Explore P: 0.1186\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 248 Total reward: 159.0 Average reward fake: 0.12933391332626343 Average reward real: 0.7650378346443176 Training q_loss: 50084476.0000 Training g_loss: 6.1547 Training d_loss: 0.4424 Explore P: 0.1169\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 249 Total reward: 199.0 Average reward fake: 0.04604436829686165 Average reward real: 0.8536424040794373 Training q_loss: 24013578.0000 Training g_loss: 10.1513 Training d_loss: 0.3354 Explore P: 0.1148\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards and losses list for plotting\n",
    "rewards_list, rewards_fake_list, rewards_real_list = [], [], []\n",
    "q_loss_list, g_loss_list, d_loss_list = [], [], [] \n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #     # Restore/load the trained model \n",
    "    #     #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #     saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        \n",
    "        # Env/agent steps/batches/minibatches\n",
    "        total_reward, rewards_fake_mean, rewards_real_mean = 0, 0, 0\n",
    "        q_loss, g_loss, d_loss = 0, 0, 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from model\n",
    "                feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "                actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "                action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Episode/epoch training is done/failed!\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Average reward fake: {}'.format(rewards_fake_mean),\n",
    "                      'Average reward real: {}'.format(rewards_real_mean),\n",
    "                      'Training q_loss: {:.4f}'.format(q_loss),\n",
    "                      'Training g_loss: {:.4f}'.format(g_loss),\n",
    "                      'Training d_loss: {:.4f}'.format(d_loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                \n",
    "                # total rewards and losses for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                rewards_fake_list.append((ep, rewards_fake_mean))\n",
    "                rewards_real_list.append((ep, rewards_real_mean))\n",
    "                q_loss_list.append((ep, q_loss))\n",
    "                g_loss_list.append((ep, g_loss))\n",
    "                d_loss_list.append((ep, d_loss))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            #rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            #             # Train the model\n",
    "            #             feed_dict = {model.states: states, model.next_states: next_states}\n",
    "            #             next_actions_logits, rewards_fake, rewards_real = sess.run([model.actions_logits, \n",
    "            #                                                                         model.rewards_fake, model.rewards_real], \n",
    "            #                                                                        feed_dict)\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions}\n",
    "            rewards_fake, rewards_real = sess.run([model.rewards_fake, model.rewards_real], feed_dict)\n",
    "            feed_dict={model.states: next_states}\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "\n",
    "            # Mean/average fake and real rewards or rewarded generated/given actions\n",
    "            rewards_fake_mean = np.mean(rewards_fake.reshape(-1))\n",
    "            rewards_real_mean = np.mean(rewards_real.reshape(-1))\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            next_actions_logits[episode_ends] = (0, 0) # NOTE: action size\n",
    "\n",
    "            # Bellman equation: Qt = Rt + max(Qt+1)\n",
    "            targetQs = rewards_fake.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "\n",
    "            # Updating the model\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions,\n",
    "                         model.targetQs: targetQs}\n",
    "            q_loss, _ = sess.run([model.q_loss, model.q_opt], feed_dict)\n",
    "            g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict)\n",
    "            d_loss, _ = sess.run([model.d_loss, model.d_opt], feed_dict)\n",
    "            \n",
    "    # Save the trained model\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Q losses')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYHHd95/H3t7un59Yx0uiwbsuywfchbAgseE1sbCexCdhgcpmE4CXgBcLCLmQ3XNl9nrAbQkIgBBMTDAGbBIhRwJiYIxgCPmQjy5Zl2bKtYzSyZzSjua8+vvtHd7VqerpnekZTM+qZz+t55lF3dXXVr6ZH9envr6p+Ze6OiIgIQGy+GyAiIqcOhYKIiBQoFEREpEChICIiBQoFEREpUCiIiEhBVYaCmX3RzDrM7IkK5n21mT1qZmkzu6HotZvN7Jn8z83RtVhEpDpUZSgAXwKurnDeQ8Bbga+FJ5pZC/AR4DLgUuAjZrZ89pooIlJ9qjIU3P1+oDs8zcy2mtm9ZvaImf3UzF6Sn/eAu+8GskWLeR1wn7t3u/tx4D4qDxoRkQUpMd8NmEW3Ae9w92fM7DLgb4ErJpl/HXA49LwtP01EZNFaEKFgZk3ArwD/bGbB5Nqp3lZimsb8EJFFbUGEArlusB53v3Aa72kDLg89Xw/8+yy2SUSk6lTlMYVi7t4HPG9mNwJYzgVTvO37wFVmtjx/gPmq/DQRkUWrKkPBzO4EfgGcZWZtZvY24LeBt5nZY8Ae4Pr8vC8zszbgRuDzZrYHwN27gT8DHs7/fDw/TURk0TINnS0iIoGqrBRERCQaVXegeeXKlb558+b5boaISFV55JFHjrl761TzVV0obN68mZ07d853M0REqoqZHaxkPnUfiYhIgUJBREQKFAoiIlKgUBARkQKFgoiIFCgURESkQKEgIiIFCgURmVWpVIrBwcH5bobMkEJBRGZVb28v7e3t890MmSGFgojMKndHA21WL4WCiMwqBUJ1iywUzKzOzB4ys8fMbI+ZfazEPG81s04z25X/+cOo2iMic0fBUL2iHBBvFLjC3QfMrAb4mZl9z90fKJrv6+5+a4TtEBGRCkVWKXjOQP5pTf5HXx9EFglVC9Up0mMKZhY3s11AB3Cfuz9YYrY3mtluM/uGmW0os5xbzGynme3s7OyMsskicpIUBtUt0lBw94y7XwisBy41s3OLZvlXYLO7nw/8ALijzHJuc/ft7r69tXXKe0SIiMgMzcnZR+7eA/w7cHXR9C53H80//QJwyVy0R0Sip4qhOkV59lGrmS3LP64HfhV4qmietaGn1wF7o2qPiMwNhUF1i/Lso7XAHWYWJxc+/+Tu3zGzjwM73X0H8G4zuw5IA93AWyNsj4iITCGyUHD33cBFJaZ/OPT4Q8CHomqDiMwfVQzVSVc0i8isUhhUN4WCiIgUKBREJBKqGKqTQkFERAoUCiIyq1QhVDeFgohEQuFQnRQKIiJSoFAQkVmlCqG6KRREJBIKh+qkUBARkQKFgojMKlUI1U2hICIiBQoFEYmEKobqpFAQEZEChYKIzCpVCNVNoSAikVA4VCeFgoiIFCgURGRWqUKobpGFgpnVmdlDZvaYme0xs4+VmKfWzL5uZvvN7EEz2xxVe0RkbikcqlOUlcIocIW7XwBcCFxtZi8vmudtwHF3PwP4FPCJCNsjIiJTiCwUPGcg/7Qm/1P81eF64I78428ArzUzi6pNIiIyuUiPKZhZ3Mx2AR3Afe7+YNEs64DDAO6eBnqBFSWWc4uZ7TSznZ2dnVE2WUROUtBtpO6j6hRpKLh7xt0vBNYDl5rZuUWzlKoKJvwluftt7r7d3be3trZG0VQREWGOzj5y9x7g34Gri15qAzYAmFkCWAp0z0WbRERkoijPPmo1s2X5x/XArwJPFc22A7g5//gG4EeumlOkqqn7qLolIlz2WuAOM4uTC59/cvfvmNnHgZ3uvgO4HfiKme0nVyHcFGF7RERkCpGFgrvvBi4qMf3DoccjwI1RtUFERKZHVzSLyKxS91F1UyiIiEiBQkFERAoUCiISCXUfVSeFgojMKoVBdVMoiIhIgUJBRCKhiqE6KRREZFYpDKqbQkFERAoUCiISCVUM1UmhICKzSmFQ3RQKIiJSoFAQEZEChYKIRELdSNVJoSAis0phUN0UCiISCYVDdVIoiIhIgUJBRGaVKoTqplAQEZGCyELBzDaY2Y/NbK+Z7TGz95SY53Iz6zWzXfmfD5dalohUH1UM1SkR4bLTwH9z90fNrBl4xMzuc/cni+b7qbv/eoTtEJE5pDCobpFVCu5+1N0fzT/uB/YC66Jan4icWhQO1WlOjimY2WbgIuDBEi+/wsweM7Pvmdk5Zd5/i5ntNLOdnZ2dEbZURE6GgqD6RR4KZtYEfBN4r7v3Fb38KLDJ3S8A/ga4u9Qy3P02d9/u7ttbW1ujbbCIyCIWaSiYWQ25QPiqu3+r+HV373P3gfzje4AaM1sZZZtERKS8KM8+MuB2YK+7/2WZedbk58PMLs23pyuqNonI3FFXUnWK8uyjVwK/CzxuZrvy0/4E2Ajg7n8H3AD8kZmlgWHgJtdfkkjV0n/f6hdZKLj7zwCbYp7PAJ+Jqg0iIjI9uqJZRCKhqqE6KRREZNYoCKqfQkFERAoUCiISCVUN1UmhICIiBQoFEZk1qg6qn0JBRCKhgKhOCgURqZi709nZSSqVmu+mSEQUCiJSsUwmQ3d3N4ODgyVfV3VQ/RQKIjJtlez8FRDVSaEgIhXTjn7hUyiIyLSVCweFRvVTKIhIxaaz01dAVKdphYKZxcxsSVSNERGR+TVlKJjZ18xsiZk1Ak8C+8zsA9E3TURONcG3f1UBC1cllcLZ+Xsrvx64h9xNcn430laJSFUKh4WCozpVEgo1+Xstvx74trunAH3aIouYdvgLVyWh8HngANAI3G9mm4C+KBslIqcmhcHCN2UouPun3X2du1/rOQeB/zzV+8xsg5n92Mz2mtkeM3tPiXnMzD5tZvvNbLeZXTzD7RCROVTJKakKkOpUyYHm1WZ2u5l9L//8bODmCpadBv6bu78UeDnwrvx7w64BtuV/bgE+N53Gi8jc0o5+4auk++hLwPeB0/LPnwbeO9Wb3P2ouz+af9wP7AXWFc12PfDlfAXyALDMzNZW2HYREZlllYTCSnf/JyAL4O5pIDOdlZjZZuAi4MGil9YBh0PP25gYHJjZLWa208x2dnZ2TmfVIjKLpjolVd1H1a+SUBg0sxXkzzgys5cDvZWuwMyagG8C782f2jru5RJvmfCX5O63uft2d9/e2tpa6apFRGSaEhXM8z5gB7DVzP4DaAVuqGTh+VNZvwl81d2/VWKWNmBD6Pl6oL2SZYvI3NPFawvflKHg7o+a2WuAs8h9s9+Xv1ZhUmZmwO3AXnf/yzKz7QBuNbO7gMuAXnc/WnHrRURkVlVy9tGNQL277yF3AdvXKzx19JXkrny+wsx25X+uNbN3mNk78vPcAzwH7Ae+ALxzRlshInNKxxQWrkq6j/7U3f/ZzF4FvA74C3Knjl422Zvc/WeUPmYQnseBd1XYVhGZZ9rRL3yVHGgOzjT6NeBz7v5tIBldk0Sk2pmZAqRKVRIKR8zs88CbgHvMrLbC94nIAjOdU1KlOlWyc38TuYvXrnb3HqAF0NDZIlJW7jyT2ZXNZkmlpjzHRU5SJaGwFviuuz9jZpcDNwIPRdoqETklVXpKahSh0NPTw6FDh2Z9uTJeJaHwTSBjZmeQO8V0C/C1SFslIlUpyrOPMpkMmcy0BlOQGagkFLL5oS3eAPyVu/8xuepBRBap+agU3L3wI9GpJBRSZvYW4PeA7+Sn1UTXJBE5VWmHvPBVEgq/D7wC+D/u/ryZbQH+MdpmiUg1i+KUVA2xMTcqucnOk8D7gcfN7Fygzd3/PPKWicgpp9JTUqPqPpps3TI7pryiOX/G0R3kbslpwAYzu9nd74+2aSIiEykUolXJMBefBK5y930AZnYmcCdwSZQNE5FTz3ROSVX3UXWq5JhCTRAIAO7+NDrQLCIlzMUOW6EQrUoqhZ1mdjvwlfzz3wYeia5JInKqm89KQaJVSSj8EbmRTN9N7pjC/cDfRtkoETk1VbpjjnJAPIVDtCq5yc4o8Jf5HxGReaFjCnOjbCiY2eOUuF9ywN3Pj6RFInLKms9TUovXIdGYrFL49TlrhYgsKDr7qHqVDQV3PziXDRGRU9+psGNWKEQrspvlmNkXzazDzJ4o8/rlZtYbun/zh6Nqi4jMjbm4olmiVcnZRzP1JeAzwJcnmeen7q5uKpEqU8kOWmcfVadKhrloAM7IP92XPxtpSu5+v5ltnnnTRORUM51TUqNat0IhWmW7j8ysxsz+CmgD/oHc+EfPmdkH869fNAvrf4WZPWZm3zOzc2ZheSIyj06m+6i/v7+im+goFKI12TGFTwJNwCZ3v8TdLwJeCpxuZp8DvnWS6340v+wLgL8B7i43o5ndYmY7zWxnZ2fnSa5WRGZqOt/Wp7PzzmQytLe309/fPyvrlpmbLBSuBd7u7oVPyd37yF3hfBPwlpNZsbv3uftA/vE9QI2ZrSwz723uvt3dt7e2tp7MakVkDky3Ushms8D8HquQnMlCIeslfvvungE63f2Bk1mxma2x/F+OmV2ab0vXySxTRKI1nVFSZyIIh8nWLdGa7EDzk2b2e+4+7uwhM/sdYO9UCzazO4HLgZVm1gZ8hPzoqu7+d8ANwB+ZWRoYBm4qFUIiUj3C/4Wn8985qm4pmb7JQuFdwLfM7A/IjYrqwMuAeuA3p1qwu0/aveTunyF3yqqIVImoKoXphIFCIVqTXdF8BLjMzK4AziE3Qur33P2Hc9U4EVlcJus+CigUolXJKKk/An40B20RkSoXPiV1truPVCnMjciGuRCRhSfq7iMdU5h/CgURicx0d+CVVAoSLYWCiFQsqvspqFI4dSgURGTe6ZjCqUOhICIVq2SHbGYzvnhNlcL8UyiIyLRVumOe7nyqFOafQkFEZqTUznmmO2yFwqlDoSAiFZtu99FsVgrTaYPMnEJBRGYkip2zTkmdfwoFEanYVDvmqLqPZjrQnkyfQkFEZtVMzj5S99GpQ6EgIhWb7jf22byieabLlOlRKIjIrCkOja8+cJDO/tGK36fuo/mnUBCRGZls52xmPHdskI9/50n+5ZdtJecZGRlhZGRk3LKmGwrt7e08/fTT0267lKdQEJGKVXpKKsCuwz0AtPeMFF5Lp9Ps37+f0dFROjs76ezsnPbyw/r7+3F3VQ+zSKEgIjMy1cVruVBw2o4PF6aNjY2RyWQYGxsjm80Wbqpzst1HqVRqRtsgEykURKRilX4jP3x8mKM9I5hBe8+JUAiHgLtPCIVK1hF+PRbL7cLGxsYq2wCZUmShYGZfNLMOM3uizOtmZp82s/1mttvMLo6qLSIyt771aBuxmHH5tlaOTBIKlQ6VUS40ampqAIXCbIqyUvgScPUkr18DbMv/3AJ8LsK2iMgsqOQbff9omrt/2c5lm1u4eFMLvcMpBkbTwMlXCsW3+QyOXygUZk9koeDu9wPdk8xyPfBlz3kAWGZma6Nqj4hEz935ydOdjKQyXHPeGtYsrQXgaL5aCIfA8cFRugdGC8/Dyyi1XDjRXVQ8XaEwexLzuO51wOHQ87b8tKPFM5rZLeSqCTZu3DgnjROR0oJv6+W+0Xf0jbC8Mclpy+ppiNcB0NYzzLbVzYVQyGaz/N97n6Krf4T3xVu4ZNWJnf1UlUKwjPC8CoXZM58HmktdB1/yr8Hdb3P37e6+vbW1NeJmiUg57j7lEBa9w2mWNyRz8/d3UkuqcLA52KE/caSXtuPDxOPG+/9517QqhfDrwfIymQyZTOYktkwC81kptAEbQs/XA+3z1BYRqVA4FILjAvF4vPC8fyTN8oZchbC0voaGeJafP9vFWaub6e0+zrcf2s/R0QT1NTFee9Yq/m7XIMNjmXHLnGzdxQEyVeUi0zOfobADuNXM7gIuA3rdfULXkYicOop3yP39/bz44ots3bq10N/fP5LitJZ6AGJmrFtez3d3H+W7u4+ywgZpSWbpGEtw3UtaWNaYxBikfyRFbYl1FK83fJ+GIAxisRiZTEahMEsiCwUzuxO4HFhpZm3AR4AaAHf/O+Ae4FpgPzAE/H5UbRGR2ROuFEZHR8lms2QymUIo9I6kOXdJI2eeeSbPPPMMf3HD+YzGGznQNcjzBw9z+dYljMXqqPdRdrf1YjgDoylqcz1Ok+7cg3WEQyEejysUZlFkoeDub5nidQfeFdX6RWR2jIyMYGbU1tYWvplDbsecTqcLjwHSmSyDo2laGpOFIbRXNCZpbV3GBRuWcaglw/DwMKuX1NPXl6IhGcfIdTmtSMbGLSusVKUQ/ITbIydPVzSLyKQ6Ozvp6OgoPA9XCkEoBAd8+0ZSOLkgCOYNny0UPvsIoLE2gQEDIyeGqZjqmEIwTzBf+HiGnDyFgohM4O50dHSQyWQK3UOB8I65uFLoHc7t3Fsac0cIyp0tFPwbVArBxW3hZRW3J1heuWkKhdmhUBCRCUZGRjh+/DjDw8MTrjwOVwrBQHSFSmEoCIUKK4VkghgwOJKqaOdeqlJQKMwuhYKITBDeeYdHM4UTO+bwwd3iSmFFUy4UpqoU6pMxYparFCbbuRcfUwhGWQ3WUe59Mn0KBRGZIOgummyMovBw1eFjCjC+UggHR/A4mN/MaKqNMzCaHlcFlBMEQFtbG729vYCOKcw2hYKITBD+Rl88ommw8w6OJ8DESiG4ojncfVSqGwlgSV1iyu6jYFoiceKEySCUVCnMLoWCiEwQrgyKAyIIhXClEOyQ+4ZTNNUmiMdy84S7j8qHQnzK7qNAfX0927Ztw8wK1YxCYXYpFERkguIhruFEl1KpUCh0Hw2nWFJfU5herlIIa65NMDSNYwqxWIxYLFaoVMyMgdG0QmGWKBREZILwQHPF08LdR50DKb76wEH2Hs3177/QN8LS+mThPaUqheLhr5tr4wxWeEwhsPeFfoZGciOj3v3YUf7467v4yb6OKd4llVAoiMgEpb7dF1cKmUyGe5/s4Ef7OnnnPz7Cx//1SZ4/NsArTl9ReE+pSiE4MBxoro0zOJYuXAE9VaWwu62H/33PPn649wUA7tvbgTt87F+f4EdPvTgr27+YKRREZIIgAEpVCgF355GDPZy7bhnnrVvCF//jeZqTMa4898S9ssI7+XKh0Fgbp284xX+9cxePHDw+ZaVw50OHceD5Y4MMpzI8crCXV56xgo3LG/iDL+3k2r/+KR/dsYeOvpEZb/9iplAQkQkq6T461D3MsaEUl52+gg9cdSYrG5P82jmrWNJYX3hPqe6jcCgEp6RCbif/Dz8/wLGB3M681D0WhsYy7Nh1hKwbzx8b5Mn2Psayzqu2tfLZ37qId792G63NtfzjAwd5w+d+ruMMMzCfQ2eLyCmqku6jXYd7ALh403JWNdfyk/e/mrZDB6ipGX+gufhah3AoxONxmvJDXdQmYoykM3zwG7tZtfpFHj14nG/f+krWL28AcsHwiXufYnAsw+VbV7L7+Rf4yb5OmuuTbG1tJJmI8b4rzwTg73/6HP/7u3s5NjBGa3MtUjlVCiKLTGdnJ8PDw5POU6pSCIdCOuP87JlOzl23jKUNtWSzWcxzr4dDITioHL4qOhwKsVisMP0NF6/nj688k+GxND975hgDo2n+z3f3ArlAuP+ZY/zTzjbeeflWrrtoHQBPHu3jhkvWk4jHx1UFW1Y2AnD4+NB0fz2LnioFkUUkk8nQ3d0N5M75L2eq7qOHD3RzfCjF21+7odBFFJyiWlwpwInrHYJTSgPxeJz/tG0lwyOjvOGyjaRGR7jtd1exbOUqvvKLg3zyvqe594EnOPu0Jfx8/zHOWrOcD7zuLA4eyd2PKx4z/uBVpzN0rH1cKGxoyVUXh7uHuHjj8pn/whYhVQoii0jxAHblhIe5CE/LuvPn33uKrz14iNOW1XHp6SsKZxilUinMbNxVx8WVQiwWGzegXiwWoy4R45pz15BMxInFYiRisKwhydtffTorG5Pc/cjzvHi8n2ePDXLV2WswM5rra9m2uonXnNnKacsaxh3QHhoaYkW+x+hwtyqF6VKlILKIVBIK5e53nM1m6egf5b69HbxiXSNv2r6eeDxeuJAslUqRSCTG7fSLK4XiaxTi8ThjY2OFK6XD3Ul1NXF+/5UbuesHO7n7l0fA4bVnrwJyYfLfX3dWYXnhUDh27BgAK5tqOdw9eTeZTKRKQWQRCUJhsrNySgVGMKxE90DugrFfP28t65c3FK4tCCqFcNdR8L5gfUEohHfk4bOTikMB4M3b19Ncl+D+pztZ0Zjk7LVLAAoVR6lQCIbj2NBSr2MKMxBpKJjZ1Wa2z8z2m9kHS7z+VjPrNLNd+Z8/jLI9IotdJZVC8VlGkPtGn81m6R4cw4GW0NDY4WMKxaEwWfdROFBKVQoAjTUxPnbdOfzWZRu5+Vc2F5YXDoPg3/BorNlslo0tDRzKdx91d3cXRlWVyUXWfWRmceCzwJVAG/Cwme1w9yeLZv26u98aVTtE5IRKQiF8llAwvlDwuGtwDMwKo6AGO/ngDm1TVQrxeHzcjrw4BIqfZ7NZltTXcMVLVo1b7mShELx/w/IGvrP7KKlMlu7u7sL9H5YtW1bx72sxirJSuBTY7+7PufsYcBdwfYTrE5EpTKf7qPh6glylMEpLY7IwCmrxjn26lULxhWzBegLhs5+CecLLnar7KJN1DncNFpYTnHkl5UUZCuuAw6Hnbflpxd5oZrvN7BtmtqHUgszsFjPbaWY7Ozs7o2iryIIXPm20kkohfBZRIpHA3ekeHGP1kvFXLIe7mcLvgdLHFCYLhaArqtTFc8XdWeFpxRfJZbNZLtnUghn888MHCu+Z6qwriTYUrMS04q8n/wpsdvfzgR8Ad5RakLvf5u7b3X17a2vrLDdTZHFIp9OFvvtKu48CweNcKNQVpocPHEP5SqGSUAjPX+o6iVLzlQqFYH1bWxu59ry1fP3BAwyMpkkmkwqFCkQZCm1A+Jv/eqA9PIO7d7n7aP7pF4BLImyPyKIWVAnJZHLS7qNgRxx86w923u5O1+AYa5aeqBSCg8WBcpVCpd1HxaFQrlIoFwrh+d2d9752G6lUijt+foAnXxxi79FejYc0hShD4WFgm5ltMbMkcBOwIzyDma0NPb0O2Bthe0QWteCg8VTfmItDIRaLkSXGoe5h0hlnTZlKofgaBRg/zHYwf/GB5vC8lVYK4WUE/xZfX5HNZtm2upl3vmYLvzzUwwe+tYfP/fuzZZcpOZGdfeTuaTO7Ffg+EAe+6O57zOzjwE533wG828yuA9JAN/DWqNojstgVVwq9vb309fWxYcP4Q3mZTKZwURrkdrgf/+5T7HrqOQBWL60DTtwfOdgxF3cdBa/DiUCabvdRuUohCJCpKgWA11+whvTIIHu6nT37D3Gwa4Ctq3UGUjmRXtHs7vcA9xRN+3Do8YeAD0XZBhHJSafTxOPxwo54cHCQoaEhRkdHqa09MZJoJpMhkUjw9IsDNGadxw/1cO+THZy7NEnXwBhbVjZhoz3jri2AiV1HgeL7KReHQrBDn06lAEwIruJQCB6n02muv3gjvzKa4L37D/HY4R6FwiQ0zIXIAhXsaAPpdJpEIjHh2/vQ0NC4UEin0+xu7+d/7HiWKzfXsPfFIc5Y3cqfvW41A6NpNq9s5MiR3LDZU1UKwTzlQiH8+nSOKQC0trYW1jlVKNTW1rJ1aRM1CePxwz28YXuFv8RFSMNciCxAmUyGZ599loGBgcK0dDpNTU1NYecadCcNDQ1NeO8P9nZgBr881ANmfO53t1MTjxUuWguEDzRPVimU6z6C8aeXBqEwODhIW1sb6XR6wnhJgebmZurq6grvLT6mEDwOrrRO1iTYvKKRPe095X9xokpBZCEaGxsjk8kwMjJCU1MTkNs51tXVjasUjg+NcaS3i9bVuVFKAXoGR/j588d586WnszYxxNnrV7J5ZRP7unLLDoIg+AnCIFxthAWD3sHkoRC8DtDf31/YqdfW1jI6OjqhUggrVykEVzEHFdKWFY1846leUpksNXF9Jy5FoSCyAAU74VQqVdhZBscKBsfSZLLOXQ8d4of7jhHD6f3OIW56+VZ+ZesKvvrjZxjLGK+/aD11o8dpaGgouY5gJ51MJjn99NPLdh8FO3WorFIIX50MuQokeH855Q40BxVKEApbVzWReqKfPe19XLhBxxVKUSiILCCDg4MMDAwUdrjpdJqOjg76+/sBGM0ar//bn9MaG6BvOMVrzl7HWSuS7OoyvvDT57j9/v1sSQ7ygasv4CVrl3LgwPEJZ/gEFcJkF62FhSuIqSqFYJ7wAebw9RLllKsUikNh26omzJyHnu/igvVLCwffy3VRLUYKBZEFpL+/n97eXpLJXN9/KpUik8kUdrI/fOoYx4fTbGmJs21VE++56hx6jnfzG5e18q6rkrx4vJ+60W7OOn3jhHGGwgPkhadPpTgUAqUqhWCe4MCzu08aOMXLCodJuFIIdvxL6mvY1FLPQ893c8U6Y8cvD7F8STO/f5Wumw0oFEQWkODgcdB9FN6JA3xzVzvbVjfzsWvWYmbU1SaJx+OkUinOWN3C2kajra1vwumekPu2HSyvuFKYTBBQ4bGNwsstXk/wvKmpif7+/nFnGJVTKhTCVUP4wroL1y/hu/u6+KuhF3nscC+xRA03vuYCmmq1OwSdfSSyoAShACcGsXN3mpubOdyXZteRAW7cvmHct/SamprCsYfwN+ty3TzhezVXoqampuTyJqsUAJYvX86qVasKB8onEx5OI9zO4Oyl8E15zlu3hMGRMXa39fKfX7KKVDrNjl3tky1+UVE0iiwAbW1tLFmyZFwoNDQ00NfXB8CyZcu4/TuHWNFYyw3bN9J+6Hkgt0NOJpMMDw9z6NAhRkZGAEreZ7mxsZHBwcEJw1ZXIplMjmtbfX19oVspqASKl5tMJqmvry9Mq7RSCKqRIOSKt2X7xuVccWYfV21ew8u2ruaZF/v56x/s4xfPdXH1OWu45tw1xGJ+ebjAAAAO2klEQVSVBd5CpEpBpMplMhkGBwfp6sqdM9rc3Aww7hv29/d28Yvnurj1ijNoqjvRRx+LxQqVQhAIwfTibp3ly5ezefNm6uvrp9V9BLB06VKWLFlSeL5x48bC84aGBjZu3FjoZorFYuOuvA6mTaY4FIKRYIMhO8LzNdXG+eSN53PeuqXU1dVx3QWnsaIxyQPPdfGurz3KJ+59quLtWohUKYhUueD4QfDv8uXLaW1tLewM73vqGH/xix4u2riM37ps47gb4wTdR+W0tLSMC5fg2/3KlSsrOgAcWLp0adnXzKxQEQTrDAcITK9SqKmpKVQLwdXM4eWEz0qqra3l4k3LecNrNpOoSfIn33qc2376HFeevZrtm1sq3r6FRJWCSJULd8tArjsmuHL5Z892cccDbVx73hrufPvLqU2M778Ph0J9fT2bNm1i/fr1hWW1traO22EHlixZUnL6bKirq5twHKHSSiGbzRZOmQ12/sXdR0EFYWaF6iSTyRCPGX/6G2dz2tJ6PvztPYt2iG2FgkiVC4dCMMhcR/8Iv/43P+NTP32BMzeu5lNvvpC6mvHdMcG372QymetWaWqirq6OxsbG+diMSSUSiQnXM4SFQyHYtuC+0aVCIbg+IXgtqByaahO878ozefJoH9/f80KEW3TqUiiIVLmxsbHCTrOmpoahsQxv+9JOnusc5MNvfBn/8PZXFyqEQNBvD7kd7qZNm1i+fPl8NL8ia9asYc2aNWVfL74BTywWK4Rl8bGJ8LGG4LXwqayvv2gdp7c28qn7niGbXXzVgkJBpMqlUimSyWSuHz5Rx+/c/iB72nv5m7dcxJu2byCZmPjfvPheBrW1tRWfYjofig88FysOBTMrhEJxpRA+KymYNxwK8Zjx3l89k30v9vOdx49GsDWnNh1oFqkCw8PDtLe3c9ppp03oy0+lUjQ2NtK8bAX/5e8fYM+RPv72ty/hV89eXXZ5zc3Np3QITFepG/AEwgfEg0oBTgRh8ZXaAP9pYwMXr4T/d+9eeodTnL9uKeetW7ooTlVVpSByCgj6v8sZHBwknU5z9OjRwimovb29hf7xhw/28qbP/4LHDvfw6bdcxNXnlu9qgdwZPqdyd9F0JZNJli5dSn19PY2NjYWQqK2tLRxMhonHFCBXhRTfzKe3t4ebX7aK5Ggvf3r341z/2f/gPV/ftSi6k1QpiMwzd+fgwYM0NDRM6DcPgmJ4eLgwzMThw4cZGxsjm81y6Fg/d+88zJ2P97OyZRl/fdPUgbAQxWKxcb+7np7cPROCazYC4RFYg26lRCIxLhQymQyjo6NcsKmVz76pmcSSVfzL4x189sfPsmVlI++78syoN2deKRRE5ll/fz+pVIqBgYHClbjHjx8nHo/T1dVFIpFgZGSE5/vggUMDtLcfoX/M6R4YZWg0RZoYb7jsbD563XkkdI8A4MQZWcWhED4uEa4UBgcHefbZZ1m7dm0hIFpbWzly5AjLklnef9VZdPSN8ukfPkN9dphVdVleds5WNqxo5sgLnYyNjXD6po1ztHXRijQUzOxq4K+BOPD37v7nRa/XAl8GLgG6gDe7+4Eo2yRyqunp6Skc7BwaGuJYVzfPHe2i7fgwbT0j9A2Psr9jgCeOx6GmnpesWkpLSy2b1hnbljqXnnsG521YOd+bcUpZs2YNQ0ND47qOIHd9hbszOjpaOPU2OP6QyWRob2+ntraWWCxGQ0MDdXV1DA4OsnLlSj72Gy+l44V2vvaTJwDov/dZhqyOVfSSjBsXnrWFN758G+uW1VNbE6M2EaexNk5tIj7h1qinMovqAg0ziwNPA1cCbcDDwFvc/cnQPO8Eznf3d5jZTcBvuvubJ1vu9u3bfefOnZG0WeRkBOP5BxdQjY6lSDtk3OgfHKavf5ChkRFGs5DyOENpp7e3l+O9fTz6Yoahvh5GM1l6B8fozNQx6nGIxdnWMEprY5zXv/pirjl/3bjrDeTkjY2NMTw8TH19PW1tbaRSKZqamli3bh1dXV0cO3aMJUuWMDAwwFg6Q3emjtTYKPsOd9KTilHHGN3DGX7+7DHaR5JkMTLEqLU0daRpbazhtOYY8Zok6Xg9TXVJNi2robGhjvq6OuqTSWqTMepqEtQnE9QlYtTVxEnGoLbGqE/WkIwZDXU11NXEZxwuZvaIu095d+ooK4VLgf3u/ly+QXcB1wNPhua5Hvho/vE3gM+YmXkESTU4OEhHR0dF8z7W1stXfnFg3LSTaVKpd1a6vFKzeaklVjap4nXMtC3uUPwnW3L7S69hppMq/32exHuL32w4WQwnt82x/AzuTjrrZIoOSjqQIUacbOF35ECv17FqRQtnL19CraVoeekmXrppLS9Zs4StrU1kUqMMDQ2xYsWKytop05JMJgsVxZYtW8ZVGM3NzXR1dTE4OEhzczMtLS0kk0lGR0dZl7/Gb/ny5TQ3N3PgUBuPt3UzPJZhLJ0llckylIaO/jFeGMySHhsl5j0c6U6za9/EO8k5kMUwcn9bpf4fXXvJGfzJGy+L7HcB0YbCOuBw6HkbULw1hXncPW1mvcAK4Fh4JjO7BbgFcgNpzUQsFit7D9lizQ31rF+xZOILJQK6ZGaXSPJS85UK/NLzVfjNoOTyKmiLlVlvhSspbl7u+dRtrnT7K96uk/i9l13thJmt6LHnYsEMLAZmmMVIJoxkooZkzKmJQ11tXW5k0GSChpoYdXFoqDGWNjWwtCHJisZk4aKq4i4PEvWRDSkh45nZuCu6k8kkZ5xxxoRhNmpra9m4cSOJRKJwyutLzjyDzRtHcHdSqRSJRGLC1eEjIyNks1lqkrX0DY3QNzDE8FiKkbEMI6k0o2MpxjLOWMZJZY3RdJbRdJrRtDMyluKCTa2R/w6iDIVS//WKv5JVMg/ufhtwG+S6j2bSmPr6yv9jnXYavPaSs2ayGpEZm+oCLZkf5cZdKt6fFA/sV0pdXV3h8YoljaxYcuoNKRLlqQptwIbQ8/VA8Z0sCvOYWQJYCnRH2CYREZlElKHwMLDNzLaYWRK4CdhRNM8O4Ob84xuAH0VxPEFERCoTWfdR/hjBrcD3yZ2S+kV332NmHwd2uvsO4HbgK2a2n1yFcFNU7RERkalFep2Cu98D3FM07cOhxyPAjVG2QUREKqfLH0VEpEChICIiBQoFEREpUCiIiEhBZGMfRcXMOoGDM3z7Soqull4kFuN2a5sXB21z5Ta5+5SXRFddKJwMM9tZyYBQC81i3G5t8+KgbZ596j4SEZEChYKIiBQstlC4bb4bME8W43ZrmxcHbfMsW1THFEREZHKLrVIQEZFJKBRERKRg0YSCmV1tZvvMbL+ZfXC+2xMVMztgZo+b2S4z25mf1mJm95nZM/l/l893O0+GmX3RzDrM7InQtJLbaDmfzn/uu83s4vlr+cyV2eaPmtmR/Ge9y8yuDb32ofw27zOz181Pq0+OmW0wsx+b2V4z22Nm78lPX7Cf9STbPHeftbsv+B9yQ3c/C5wOJIHHgLPnu10RbesBYGXRtP8LfDD/+IPAJ+a7nSe5ja8GLgaemGobgWuB75G7y9/LgQfnu/2zuM0fBd5fYt6z83/jtcCW/N9+fL63YQbbvBa4OP+4GXg6v20L9rOeZJvn7LNeLJXCpcB+d3/O3ceAu4Dr57lNc+l64I784zuA189jW06au9/PxDv0ldvG64Eve84DwDIzWzs3LZ09Zba5nOuBu9x91N2fB/aT+z9QVdz9qLs/mn/cD+wld1/3BftZT7LN5cz6Z71YQmEdcDj0vI3Jf9HVzIF/M7NHzOyW/LTV7n4Ucn90wKp5a110ym3jQv/sb813lXwx1C244LbZzDYDFwEPskg+66Jthjn6rBdLKFiJaQv1XNxXuvvFwDXAu8zs1fPdoHm2kD/7zwFbgQuBo8An89MX1DabWRPwTeC97t432awlplXldpfY5jn7rBdLKLQBG0LP1wPt89SWSLl7e/7fDuBfyJWSLwZldP7fjvlrYWTKbeOC/ezd/UV3z7h7FvgCJ7oNFsw2m1kNuZ3jV939W/nJC/qzLrXNc/lZL5ZQeBjYZmZbzCxJ7l7QO+a5TbPOzBrNrDl4DFwFPEFuW2/Oz3Yz8O35aWGkym3jDuD38memvBzoDboeql1Rf/lvkvusIbfNN5lZrZltAbYBD811+06WmRm5+7jvdfe/DL20YD/rcts8p5/1fB9tn8Oj+teSO5L/LPA/57s9EW3j6eTORHgM2BNsJ7AC+CHwTP7flvlu60lu553kSugUuW9Kbyu3jeTK68/mP/fHge3z3f5Z3Oav5Ldpd37nsDY0///Mb/M+4Jr5bv8Mt/lV5LpCdgO78j/XLuTPepJtnrPPWsNciIhIwWLpPhIRkQooFEREpEChICIiBQoFEREpUCiIiEiBQkEWPTPLhEaf3DXVKLpm9g4z+71ZWO8BM1t5sssRmU06JVUWPTMbcPemeVjvAXLn0h+b63WLlKNKQaSM/Df5T5jZQ/mfM/LTP2pm788/freZPZkfqOyu/LQWM7s7P+0BMzs/P32Fmf2bmf3SzD5PaNwaM/ud/Dp2mdnnzSw+D5ssolAQAeqLuo/eHHqtz90vBT4D/FWJ934QuMjdzwfekZ/2MeCX+Wl/Anw5P/0jwM/c/SJyV6VuBDCzlwJvJjeY4YVABvjt2d1Ekcok5rsBIqeA4fzOuJQ7Q/9+qsTru4GvmtndwN35aa8C3gjg7j/KVwhLyd0o5w356d81s+P5+V8LXAI8nBv6hnoW5qCFUgUUCiKT8zKPA79Gbmd/HfCnZnYOkw9nXGoZBtzh7h86mYaKzAZ1H4lM7s2hf38RfsHMYsAGd/8x8N+BZUATcD/57h8zuxw45rkx8cPTrwGCG6X8ELjBzFblX2sxs00RbpNIWaoURPLHFELP73X34LTUWjN7kNwXqLcUvS8O/GO+a8iAT7l7j5l9FPgHM9sNDHFimOePAXea2aPAT4BDAO7+pJn9L3J3zIuRGwn1XcDB2d5QkanolFSRMnTKqCxG6j4SEZECVQoiIlKgSkFERAoUCiIiUqBQEBGRAoWCiIgUKBRERKTg/wPdM2R/X+EumAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(q_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Q losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'G losses')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'D losses')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 1\n",
    "test_max_steps = 20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
    "\n",
    "# # # Create the env after closing it.\n",
    "# env = gym.make('CartPole-v0')\n",
    "# # env = gym.make('Acrobot-v1')\n",
    "env.reset()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore/load the trained model \n",
    "    #saver.restore(sess, 'checkpoints/QGAN-cartpole.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # iterations\n",
    "    for ep in range(test_episodes):\n",
    "        \n",
    "        # number of env/rob steps\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            \n",
    "            # Rendering the env graphics\n",
    "            env.render()\n",
    "            \n",
    "            # Get action from DQAN\n",
    "            feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "            actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # The task is done or not;\n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the env\n",
    "# WARNING: If you close, you can NOT restart again!!!!!!\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this to Deep Convolutional QAN\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

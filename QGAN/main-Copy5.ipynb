{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# QGAN: (Q-Net) + GAN (G-Net and D-Net)\n",
    "\n",
    "More specifically, we'll use Q-GAN to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command 'pip install -e gym/[all]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "rewards, states, actions, dones = [], [], [], []\n",
    "for _ in range(10):\n",
    "    #env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    states.append(state)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    dones.append(done)\n",
    "    #     print('state, action, reward, done, info')\n",
    "    #     print(state, action, reward, done, info)\n",
    "    if done:\n",
    "    #         print('state, action, reward, done, info')\n",
    "    #         print(state, action, reward, done, info)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        dones.append(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(10,) (10, 4) (10,) (10,)\n",
      "float64 float64 int64 bool\n",
      "actions: 1 0\n",
      "rewards min and max: 1.0 1.0\n",
      "state size: (10, 4) action size: 2\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print('actions:', np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print('rewards min and max:', np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print('state size:', np.array(states).shape, \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    # Current states given\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    \n",
    "    # Next states given\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    \n",
    "    # Current actions given\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # TargetQs/values\n",
    "    targetQs_fake = tf.placeholder(tf.float32, [None], name='targetQs_fake')\n",
    "    targetQs_real = tf.placeholder(tf.float32, [None], name='targetQs_real')\n",
    "    \n",
    "    # returning the given data to the model\n",
    "    return states, next_states, actions, targetQs_fake, targetQs_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: Generator/Encoder-Decoder/Predictor/Qfunction: given states, generate/predict the action and next state\n",
    "def generator(states, state_size, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        # states sigmoid/regression/continuous and actions softmax/classification/discrete\n",
    "        # Split states and actions together\n",
    "        logits = tf.layers.dense(inputs=nl2, units=(state_size + action_size))        \n",
    "        next_states_logits, actions_logit = tf.split(axis=1, num_or_size_splits=[state_size, action_size], \n",
    "                                                     value=logits)\n",
    "        #predictions = tf.sigmoid(next_states_logits)\n",
    "        #predictions = tf.nn.softmax(actions_logit)\n",
    "\n",
    "        \n",
    "        # return next_states_logits\n",
    "        return next_states_logits, actions_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D: Descriminator/Reward function\n",
    "def discriminator(states, actions, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Fuse/merge states and actions together\n",
    "        x_fused = tf.concat(axis=1, values=[states, actions])\n",
    "\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=x_fused, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)   \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return rewards logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(states, actions, next_states,\n",
    "                 state_size, action_size, hidden_size):\n",
    "    # GAN: Generate next states and current actions\n",
    "    next_states_logits, actions_logits = generator(states=states, \n",
    "                                                   action_size=action_size, state_size=state_size, \n",
    "                                                   hidden_size=hidden_size)\n",
    "    \n",
    "    # Qs for the next states fake or real\n",
    "    actions_real = tf.one_hot(depth=action_size, indices=actions)\n",
    "    nextQs_logits_real = discriminator(states=next_states, actions=actions_real, hidden_size=hidden_size, \n",
    "                                       reuse=False)\n",
    "    nextQs_logits_fake = discriminator(states=next_states_logits, actions=actions_logits, hidden_size=hidden_size, \n",
    "                                       reuse=True)\n",
    "    \n",
    "    # nextQs will be used outside\n",
    "    return actions_logits, actions_real, nextQs_logits_fake, nextQs_logits_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(actions_logits, actions_real, targetQs_fake, targetQs_real):\n",
    "    \n",
    "    Qs = tf.reduce_sum(tf.multiply(actions_logits, actions_real), axis=1)\n",
    "    g_loss = tf.reduce_mean(tf.square(targetQs_fake - Qs))\n",
    "    d_loss = tf.reduce_mean(tf.square(targetQs_real - Qs))\n",
    "\n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(g_loss, d_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param g_loss: Generator/Decoder loss Tensor for next state and action prediction\n",
    "    :param d_loss: Discriminator/Reward loss Tensor for current reward function\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')] # G: next state St/st\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGAN:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.next_states, self.actions, self.targetQs_fake, self.targetQs_real = model_input(\n",
    "            state_size=state_size)\n",
    "\n",
    "        # Output of the Model: forwad pass\n",
    "        self.actions_logits, self.actions_real, self.nextQs_logits_fake, self.nextQs_logits_real = model_output(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, # init data\n",
    "            states=self.states, next_states=self.next_states, actions=self.actions) # model data\n",
    "        \n",
    "        # Loss of the Model: calculating the loss and forwad pass\n",
    "        self.g_loss, self.d_loss = model_loss(\n",
    "            actions_logits=self.actions_logits, actions_real=self.actions_real, \n",
    "            targetQs_fake=self.nextQs_logits_fake, targetQs_real=self.nextQs_logits_real)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.g_opt, self.d_opt = model_opt(g_loss=self.g_loss, d_loss=self.d_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size: 4 action size: 2\n"
     ]
    }
   ],
   "source": [
    "print('state size:', np.array(states).shape[1], \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 500           # max number of episodes to learn from\n",
    "max_steps = 2000000000000000   # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000           # memory capacity\n",
    "batch_size = 200               # experience mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = QGAN(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 0 Total reward: 3.0 Average reward fake: 0.504061758518219 Average reward real: 0.5252454280853271 Training g_loss: 1.7741 Training d_loss: 1.3504 Explore P: 0.9997\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 1 Total reward: 12.0 Average reward fake: 0.4812980890274048 Average reward real: 0.5627188682556152 Training g_loss: 1.9413 Training d_loss: 1.2453 Explore P: 0.9985\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 2 Total reward: 23.0 Average reward fake: 0.4685312509536743 Average reward real: 0.5662208795547485 Training g_loss: 2.3828 Training d_loss: 1.2540 Explore P: 0.9962\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 3 Total reward: 15.0 Average reward fake: 0.3868376910686493 Average reward real: 0.6295425891876221 Training g_loss: 3.6239 Training d_loss: 1.0458 Explore P: 0.9948\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 4 Total reward: 48.0 Average reward fake: 0.6685190796852112 Average reward real: 0.49578848481178284 Training g_loss: 27.0233 Training d_loss: 3.0866 Explore P: 0.9901\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 5 Total reward: 26.0 Average reward fake: 0.01365354098379612 Average reward real: 0.3951922357082367 Training g_loss: 93.5688 Training d_loss: 2.1987 Explore P: 0.9875\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 6 Total reward: 14.0 Average reward fake: 0.02521245740354061 Average reward real: 0.5205363631248474 Training g_loss: 116.1811 Training d_loss: 1.4135 Explore P: 0.9861\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 7 Total reward: 26.0 Average reward fake: 0.03718596696853638 Average reward real: 0.43212956190109253 Training g_loss: 102.5440 Training d_loss: 1.2167 Explore P: 0.9836\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 8 Total reward: 11.0 Average reward fake: 0.0002922253916040063 Average reward real: 0.4553977847099304 Training g_loss: 61.6270 Training d_loss: 0.9120 Explore P: 0.9825\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 9 Total reward: 8.0 Average reward fake: 0.004883956164121628 Average reward real: 0.5348474383354187 Training g_loss: 30.4152 Training d_loss: 0.7258 Explore P: 0.9818\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 10 Total reward: 39.0 Average reward fake: 0.08359217643737793 Average reward real: 0.8026750087738037 Training g_loss: 9.0729 Training d_loss: 0.3746 Explore P: 0.9780\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 11 Total reward: 12.0 Average reward fake: 0.08860515803098679 Average reward real: 0.8439040184020996 Training g_loss: 11.0278 Training d_loss: 0.3429 Explore P: 0.9768\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 12 Total reward: 42.0 Average reward fake: 0.15176717936992645 Average reward real: 0.8609466552734375 Training g_loss: 8.0976 Training d_loss: 0.3719 Explore P: 0.9728\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 13 Total reward: 42.0 Average reward fake: 0.3436955511569977 Average reward real: 0.5560380816459656 Training g_loss: 7.9886 Training d_loss: 1.0793 Explore P: 0.9687\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 14 Total reward: 12.0 Average reward fake: 0.3895758390426636 Average reward real: 0.5945045948028564 Training g_loss: 7.5770 Training d_loss: 1.1094 Explore P: 0.9676\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 15 Total reward: 13.0 Average reward fake: 0.5817186832427979 Average reward real: 0.5903586745262146 Training g_loss: 5.6361 Training d_loss: 1.4888 Explore P: 0.9663\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 16 Total reward: 30.0 Average reward fake: 0.45452040433883667 Average reward real: 0.5397266149520874 Training g_loss: 11.7780 Training d_loss: 1.2801 Explore P: 0.9635\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 17 Total reward: 37.0 Average reward fake: 0.4762563705444336 Average reward real: 0.5170009732246399 Training g_loss: 22.3179 Training d_loss: 1.3252 Explore P: 0.9599\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 18 Total reward: 26.0 Average reward fake: 0.3724256753921509 Average reward real: 0.5691462755203247 Training g_loss: 19.0486 Training d_loss: 1.0893 Explore P: 0.9575\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 19 Total reward: 13.0 Average reward fake: 0.5332356095314026 Average reward real: 0.5703130960464478 Training g_loss: 20.1927 Training d_loss: 1.4702 Explore P: 0.9562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 20 Total reward: 24.0 Average reward fake: 0.26189717650413513 Average reward real: 0.4078224301338196 Training g_loss: 22.7320 Training d_loss: 1.2314 Explore P: 0.9540\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 21 Total reward: 15.0 Average reward fake: 0.5358521342277527 Average reward real: 0.546656608581543 Training g_loss: 23.6698 Training d_loss: 1.4693 Explore P: 0.9526\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 22 Total reward: 77.0 Average reward fake: 0.36848151683807373 Average reward real: 0.43699324131011963 Training g_loss: 26.3139 Training d_loss: 1.3591 Explore P: 0.9453\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 23 Total reward: 16.0 Average reward fake: 0.5288803577423096 Average reward real: 0.4466257095336914 Training g_loss: 24.8070 Training d_loss: 1.6056 Explore P: 0.9438\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 24 Total reward: 17.0 Average reward fake: 0.525999128818512 Average reward real: 0.500170111656189 Training g_loss: 37.3111 Training d_loss: 1.4746 Explore P: 0.9423\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 25 Total reward: 12.0 Average reward fake: 0.5479472875595093 Average reward real: 0.49709051847457886 Training g_loss: 14.0931 Training d_loss: 1.5263 Explore P: 0.9411\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 26 Total reward: 16.0 Average reward fake: 0.4905170500278473 Average reward real: 0.46737658977508545 Training g_loss: 64.0630 Training d_loss: 1.4487 Explore P: 0.9396\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 27 Total reward: 26.0 Average reward fake: 0.4837898910045624 Average reward real: 0.4778634011745453 Training g_loss: 49.4698 Training d_loss: 1.4159 Explore P: 0.9372\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 28 Total reward: 52.0 Average reward fake: 0.5403423309326172 Average reward real: 0.5315186381340027 Training g_loss: 34.4244 Training d_loss: 1.4553 Explore P: 0.9324\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 29 Total reward: 27.0 Average reward fake: 0.4174688756465912 Average reward real: 0.4919908940792084 Training g_loss: 57.1698 Training d_loss: 1.2881 Explore P: 0.9299\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 30 Total reward: 15.0 Average reward fake: 0.5502118468284607 Average reward real: 0.514289915561676 Training g_loss: 66.1335 Training d_loss: 1.5170 Explore P: 0.9286\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 31 Total reward: 13.0 Average reward fake: 0.5006026029586792 Average reward real: 0.5211977958679199 Training g_loss: 107.2795 Training d_loss: 1.3510 Explore P: 0.9274\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 32 Total reward: 11.0 Average reward fake: 0.28301963210105896 Average reward real: 0.5480234026908875 Training g_loss: 69.7066 Training d_loss: 0.9561 Explore P: 0.9264\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 33 Total reward: 15.0 Average reward fake: 0.6555505394935608 Average reward real: 0.6026477813720703 Training g_loss: 47.5850 Training d_loss: 1.7053 Explore P: 0.9250\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 34 Total reward: 21.0 Average reward fake: 0.4590432643890381 Average reward real: 0.4955310821533203 Training g_loss: 109.2402 Training d_loss: 1.4048 Explore P: 0.9231\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 35 Total reward: 54.0 Average reward fake: 0.48201462626457214 Average reward real: 0.4858335256576538 Training g_loss: 139.9272 Training d_loss: 1.3957 Explore P: 0.9181\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 36 Total reward: 18.0 Average reward fake: 0.48213499784469604 Average reward real: 0.4894375503063202 Training g_loss: 65.1564 Training d_loss: 1.3863 Explore P: 0.9165\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 37 Total reward: 19.0 Average reward fake: 0.470470666885376 Average reward real: 0.4965950846672058 Training g_loss: 78.7146 Training d_loss: 1.3490 Explore P: 0.9148\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 38 Total reward: 35.0 Average reward fake: 0.4510174095630646 Average reward real: 0.5052659511566162 Training g_loss: 78.1488 Training d_loss: 1.2940 Explore P: 0.9116\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 39 Total reward: 46.0 Average reward fake: 0.4785788655281067 Average reward real: 0.5606582164764404 Training g_loss: 256.0280 Training d_loss: 1.3130 Explore P: 0.9075\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 40 Total reward: 32.0 Average reward fake: 0.49342432618141174 Average reward real: 0.5104497671127319 Training g_loss: 318.3946 Training d_loss: 1.3595 Explore P: 0.9046\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 41 Total reward: 21.0 Average reward fake: 0.4884427785873413 Average reward real: 0.5085241198539734 Training g_loss: 240.5292 Training d_loss: 1.3718 Explore P: 0.9027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 42 Total reward: 15.0 Average reward fake: 0.4787311851978302 Average reward real: 0.49123242497444153 Training g_loss: 264.5322 Training d_loss: 1.3863 Explore P: 0.9014\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 43 Total reward: 23.0 Average reward fake: 0.4729706645011902 Average reward real: 0.5155314803123474 Training g_loss: 192.8075 Training d_loss: 1.3335 Explore P: 0.8994\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 44 Total reward: 23.0 Average reward fake: 0.4508747160434723 Average reward real: 0.5050244927406311 Training g_loss: 439.1976 Training d_loss: 1.3103 Explore P: 0.8973\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 45 Total reward: 20.0 Average reward fake: 0.46722930669784546 Average reward real: 0.5219018459320068 Training g_loss: 215.2168 Training d_loss: 1.2953 Explore P: 0.8955\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 46 Total reward: 21.0 Average reward fake: 0.49251723289489746 Average reward real: 0.525226354598999 Training g_loss: 446.2751 Training d_loss: 1.3400 Explore P: 0.8937\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 47 Total reward: 12.0 Average reward fake: 0.4431089162826538 Average reward real: 0.5151326656341553 Training g_loss: 443.9510 Training d_loss: 1.2758 Explore P: 0.8926\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 48 Total reward: 31.0 Average reward fake: 0.42943432927131653 Average reward real: 0.5357552170753479 Training g_loss: 596.1973 Training d_loss: 1.2006 Explore P: 0.8899\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 49 Total reward: 26.0 Average reward fake: 0.4870976209640503 Average reward real: 0.543613076210022 Training g_loss: 601.8022 Training d_loss: 1.3222 Explore P: 0.8876\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 50 Total reward: 13.0 Average reward fake: 0.3677676320075989 Average reward real: 0.5551080107688904 Training g_loss: 320.2636 Training d_loss: 1.0896 Explore P: 0.8865\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 51 Total reward: 39.0 Average reward fake: 0.4128710925579071 Average reward real: 0.535453200340271 Training g_loss: 637.1757 Training d_loss: 1.1917 Explore P: 0.8831\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 52 Total reward: 17.0 Average reward fake: 0.43257826566696167 Average reward real: 0.5736687183380127 Training g_loss: 1496.3032 Training d_loss: 1.1197 Explore P: 0.8816\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 53 Total reward: 15.0 Average reward fake: 0.40135669708251953 Average reward real: 0.5916107892990112 Training g_loss: 883.1275 Training d_loss: 1.1589 Explore P: 0.8803\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 54 Total reward: 28.0 Average reward fake: 0.44744551181793213 Average reward real: 0.5734261274337769 Training g_loss: 1052.2697 Training d_loss: 1.3353 Explore P: 0.8778\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 55 Total reward: 57.0 Average reward fake: 0.40321236848831177 Average reward real: 0.6196316480636597 Training g_loss: 810.2519 Training d_loss: 1.1118 Explore P: 0.8729\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 56 Total reward: 85.0 Average reward fake: 0.38917046785354614 Average reward real: 0.650041401386261 Training g_loss: 1014.7664 Training d_loss: 0.8905 Explore P: 0.8656\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 57 Total reward: 16.0 Average reward fake: 0.42805400490760803 Average reward real: 0.6304123401641846 Training g_loss: 2029.4990 Training d_loss: 1.1260 Explore P: 0.8642\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 58 Total reward: 38.0 Average reward fake: 0.223784938454628 Average reward real: 0.579774022102356 Training g_loss: 686.2084 Training d_loss: 1.2175 Explore P: 0.8610\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 59 Total reward: 47.0 Average reward fake: 0.15840622782707214 Average reward real: 0.6194111704826355 Training g_loss: 1144.1310 Training d_loss: 1.0791 Explore P: 0.8570\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 60 Total reward: 115.0 Average reward fake: 0.13825401663780212 Average reward real: 0.7490057349205017 Training g_loss: 3407.9824 Training d_loss: 1.0970 Explore P: 0.8473\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 61 Total reward: 13.0 Average reward fake: 0.3818540871143341 Average reward real: 0.6424179077148438 Training g_loss: 5102.3589 Training d_loss: 1.1267 Explore P: 0.8462\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 62 Total reward: 10.0 Average reward fake: 0.024180546402931213 Average reward real: 0.654051661491394 Training g_loss: 3944.3628 Training d_loss: 0.6531 Explore P: 0.8454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 63 Total reward: 13.0 Average reward fake: 0.0989733338356018 Average reward real: 0.8402130603790283 Training g_loss: 2097.5920 Training d_loss: 0.8705 Explore P: 0.8443\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 64 Total reward: 36.0 Average reward fake: 0.08056974411010742 Average reward real: 0.8079794049263 Training g_loss: 4823.6377 Training d_loss: 0.5158 Explore P: 0.8413\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 65 Total reward: 31.0 Average reward fake: 0.1285448521375656 Average reward real: 0.7093982696533203 Training g_loss: 2381.7666 Training d_loss: 0.8100 Explore P: 0.8387\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 66 Total reward: 12.0 Average reward fake: 0.29827091097831726 Average reward real: 0.7395097613334656 Training g_loss: 4318.7827 Training d_loss: 0.6083 Explore P: 0.8377\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 67 Total reward: 51.0 Average reward fake: 0.1753610074520111 Average reward real: 0.885009229183197 Training g_loss: 13010.5713 Training d_loss: 0.3047 Explore P: 0.8335\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 68 Total reward: 62.0 Average reward fake: 0.47463104128837585 Average reward real: 0.9327029585838318 Training g_loss: 31530.3652 Training d_loss: 0.0945 Explore P: 0.8284\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 69 Total reward: 48.0 Average reward fake: 0.11251530051231384 Average reward real: 0.956066906452179 Training g_loss: 31891.0469 Training d_loss: 0.6523 Explore P: 0.8245\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 70 Total reward: 88.0 Average reward fake: 0.12499523162841797 Average reward real: 0.8977815508842468 Training g_loss: 89086.7422 Training d_loss: 0.2667 Explore P: 0.8174\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 71 Total reward: 56.0 Average reward fake: 0.08138539642095566 Average reward real: 0.8236067295074463 Training g_loss: 17309.6113 Training d_loss: 0.3154 Explore P: 0.8129\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 72 Total reward: 11.0 Average reward fake: 0.13699883222579956 Average reward real: 0.8544048070907593 Training g_loss: 37032.3008 Training d_loss: 0.3298 Explore P: 0.8120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 73 Total reward: 14.0 Average reward fake: 0.25095948576927185 Average reward real: 0.841197669506073 Training g_loss: 39619.4414 Training d_loss: 0.7272 Explore P: 0.8109\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 74 Total reward: 39.0 Average reward fake: 0.17786858975887299 Average reward real: 0.802310049533844 Training g_loss: 11896.8262 Training d_loss: 0.3442 Explore P: 0.8078\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 75 Total reward: 44.0 Average reward fake: 0.08724509924650192 Average reward real: 0.9213242530822754 Training g_loss: 41410.9805 Training d_loss: 0.1763 Explore P: 0.8043\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 76 Total reward: 34.0 Average reward fake: 0.020815158262848854 Average reward real: 0.91666579246521 Training g_loss: 48573.2812 Training d_loss: 0.1924 Explore P: 0.8016\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 77 Total reward: 15.0 Average reward fake: 0.0009400920826010406 Average reward real: 0.8958086967468262 Training g_loss: 42144.1211 Training d_loss: 0.1682 Explore P: 0.8004\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 78 Total reward: 38.0 Average reward fake: 0.018426787108182907 Average reward real: 0.9094674587249756 Training g_loss: 88003.0156 Training d_loss: 0.1683 Explore P: 0.7974\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 79 Total reward: 20.0 Average reward fake: 0.0013031340204179287 Average reward real: 0.9637172222137451 Training g_loss: 22494.7363 Training d_loss: 0.0524 Explore P: 0.7958\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 80 Total reward: 24.0 Average reward fake: 0.0014441227540373802 Average reward real: 0.9525816440582275 Training g_loss: 49961.5625 Training d_loss: 0.1487 Explore P: 0.7939\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 81 Total reward: 17.0 Average reward fake: 0.020431730896234512 Average reward real: 0.9668442010879517 Training g_loss: 32683.1133 Training d_loss: 0.0580 Explore P: 0.7926\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 82 Total reward: 25.0 Average reward fake: 0.001214224612340331 Average reward real: 0.9629731774330139 Training g_loss: 32266.7969 Training d_loss: 0.0697 Explore P: 0.7906\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 83 Total reward: 26.0 Average reward fake: 0.15768380463123322 Average reward real: 0.9461300373077393 Training g_loss: 34962.3477 Training d_loss: 0.0782 Explore P: 0.7886\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 84 Total reward: 56.0 Average reward fake: 0.05909958854317665 Average reward real: 0.9472090005874634 Training g_loss: 58799.1250 Training d_loss: 0.0861 Explore P: 0.7843\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 85 Total reward: 9.0 Average reward fake: 0.005000193137675524 Average reward real: 0.9320400357246399 Training g_loss: 133691.1406 Training d_loss: 0.1469 Explore P: 0.7836\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 86 Total reward: 41.0 Average reward fake: 0.08793432265520096 Average reward real: 0.9382601976394653 Training g_loss: 76778.0625 Training d_loss: 0.0964 Explore P: 0.7804\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 87 Total reward: 17.0 Average reward fake: 0.006216907873749733 Average reward real: 0.9593214392662048 Training g_loss: 62878.8398 Training d_loss: 0.0578 Explore P: 0.7791\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 88 Total reward: 34.0 Average reward fake: 0.04744037613272667 Average reward real: 0.960777759552002 Training g_loss: 195124.4688 Training d_loss: 0.0727 Explore P: 0.7765\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 89 Total reward: 42.0 Average reward fake: 0.018203776329755783 Average reward real: 0.9809749126434326 Training g_loss: 211750.6562 Training d_loss: 0.0890 Explore P: 0.7733\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 90 Total reward: 16.0 Average reward fake: 0.002162755001336336 Average reward real: 0.9827850461006165 Training g_loss: 127433.5391 Training d_loss: 0.0401 Explore P: 0.7720\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 91 Total reward: 11.0 Average reward fake: 7.253631029158214e-11 Average reward real: 0.9808183312416077 Training g_loss: 74690.0000 Training d_loss: 0.0220 Explore P: 0.7712\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 92 Total reward: 46.0 Average reward fake: 9.317056282043268e-08 Average reward real: 0.9913197159767151 Training g_loss: 234127.5938 Training d_loss: 0.0099 Explore P: 0.7677\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 93 Total reward: 117.0 Average reward fake: 2.5552653326599284e-08 Average reward real: 0.9774410128593445 Training g_loss: 409606.1875 Training d_loss: 0.0308 Explore P: 0.7589\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 94 Total reward: 114.0 Average reward fake: 6.008436912452453e-07 Average reward real: 0.9838052988052368 Training g_loss: 368188.2188 Training d_loss: 0.0285 Explore P: 0.7504\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 95 Total reward: 87.0 Average reward fake: 0.001745155779644847 Average reward real: 0.9962727427482605 Training g_loss: 516839.0000 Training d_loss: 0.0040 Explore P: 0.7440\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 96 Total reward: 33.0 Average reward fake: 0.0023065838031470776 Average reward real: 0.9931968450546265 Training g_loss: 1082040.1250 Training d_loss: 0.0109 Explore P: 0.7416\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 97 Total reward: 26.0 Average reward fake: 0.0016562759410589933 Average reward real: 0.9906208515167236 Training g_loss: 1574404.2500 Training d_loss: 0.0105 Explore P: 0.7397\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 98 Total reward: 39.0 Average reward fake: 0.005041096359491348 Average reward real: 0.9959797859191895 Training g_loss: 1009873.8750 Training d_loss: 0.0043 Explore P: 0.7368\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 99 Total reward: 17.0 Average reward fake: 0.005200936924666166 Average reward real: 0.9938279986381531 Training g_loss: 513322.1250 Training d_loss: 0.0281 Explore P: 0.7356\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 100 Total reward: 14.0 Average reward fake: 0.01742076314985752 Average reward real: 0.990021824836731 Training g_loss: 1166122.3750 Training d_loss: 0.0609 Explore P: 0.7346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 101 Total reward: 16.0 Average reward fake: 0.004105728585273027 Average reward real: 0.9893536567687988 Training g_loss: 1557873.2500 Training d_loss: 0.1286 Explore P: 0.7334\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 102 Total reward: 11.0 Average reward fake: 0.00040971313137561083 Average reward real: 0.9914528131484985 Training g_loss: 2921134.2500 Training d_loss: 0.0099 Explore P: 0.7326\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 103 Total reward: 30.0 Average reward fake: 0.054308243095874786 Average reward real: 0.9906358122825623 Training g_loss: 1720545.5000 Training d_loss: 0.1233 Explore P: 0.7305\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 104 Total reward: 124.0 Average reward fake: 0.001992449164390564 Average reward real: 0.9956082105636597 Training g_loss: 1604685.8750 Training d_loss: 0.0116 Explore P: 0.7216\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 105 Total reward: 121.0 Average reward fake: 0.0008435257477685809 Average reward real: 0.9959084987640381 Training g_loss: 6115315.0000 Training d_loss: 0.0043 Explore P: 0.7130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 106 Total reward: 56.0 Average reward fake: 1.2862001241842336e-08 Average reward real: 0.9966404438018799 Training g_loss: 6465285.5000 Training d_loss: 0.0036 Explore P: 0.7091\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 107 Total reward: 73.0 Average reward fake: 0.00045575416879728436 Average reward real: 0.9952825903892517 Training g_loss: 6814072.0000 Training d_loss: 0.0125 Explore P: 0.7040\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 108 Total reward: 34.0 Average reward fake: 2.0487883375608362e-05 Average reward real: 0.9954555034637451 Training g_loss: 2867371.0000 Training d_loss: 0.0050 Explore P: 0.7017\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 109 Total reward: 25.0 Average reward fake: 0.0007637230446562171 Average reward real: 0.9984461069107056 Training g_loss: 13111703.0000 Training d_loss: 0.0016 Explore P: 0.6999\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 110 Total reward: 124.0 Average reward fake: 0.00594525458291173 Average reward real: 0.9933872818946838 Training g_loss: 9444747.0000 Training d_loss: 0.0311 Explore P: 0.6914\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 111 Total reward: 77.0 Average reward fake: 1.7644239418776285e-39 Average reward real: 0.9993705749511719 Training g_loss: 10791794.0000 Training d_loss: 0.0006 Explore P: 0.6862\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 112 Total reward: 51.0 Average reward fake: 7.397378709583791e-09 Average reward real: 0.9995880126953125 Training g_loss: 8674350.0000 Training d_loss: 0.0004 Explore P: 0.6828\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 113 Total reward: 53.0 Average reward fake: 2.7540971348112564e-14 Average reward real: 0.9965226650238037 Training g_loss: 11298014.0000 Training d_loss: 0.0039 Explore P: 0.6792\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 114 Total reward: 75.0 Average reward fake: 0.00870137196034193 Average reward real: 0.9980179667472839 Training g_loss: 25276762.0000 Training d_loss: 0.0023 Explore P: 0.6742\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 115 Total reward: 21.0 Average reward fake: 0.006963949650526047 Average reward real: 0.9987967610359192 Training g_loss: 11656956.0000 Training d_loss: 0.0012 Explore P: 0.6728\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 116 Total reward: 105.0 Average reward fake: 4.4989278181962856e-17 Average reward real: 0.9982473254203796 Training g_loss: 25493242.0000 Training d_loss: 0.0018 Explore P: 0.6659\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 117 Total reward: 147.0 Average reward fake: 4.6779884788983664e-14 Average reward real: 0.9935847520828247 Training g_loss: 46606552.0000 Training d_loss: 0.0164 Explore P: 0.6563\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 118 Total reward: 26.0 Average reward fake: 5.6457757580119505e-08 Average reward real: 0.9993117451667786 Training g_loss: 15814212.0000 Training d_loss: 0.0007 Explore P: 0.6546\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 119 Total reward: 45.0 Average reward fake: 9.118036541622132e-05 Average reward real: 0.9950351119041443 Training g_loss: 32145484.0000 Training d_loss: 0.0111 Explore P: 0.6518\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 120 Total reward: 79.0 Average reward fake: 7.896937736254621e-28 Average reward real: 0.9988864064216614 Training g_loss: 38796364.0000 Training d_loss: 0.0012 Explore P: 0.6467\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 121 Total reward: 120.0 Average reward fake: 5.281586279437533e-10 Average reward real: 0.9992257952690125 Training g_loss: 22048344.0000 Training d_loss: 0.0008 Explore P: 0.6391\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 122 Total reward: 79.0 Average reward fake: 1.319818680445273e-16 Average reward real: 0.9998322129249573 Training g_loss: 57104128.0000 Training d_loss: 0.0002 Explore P: 0.6342\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 123 Total reward: 14.0 Average reward fake: 4.382188988310935e-14 Average reward real: 0.9995579719543457 Training g_loss: 51435224.0000 Training d_loss: 0.0004 Explore P: 0.6333\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 124 Total reward: 48.0 Average reward fake: 5.437312324829691e-07 Average reward real: 0.9968188405036926 Training g_loss: 48671300.0000 Training d_loss: 0.0035 Explore P: 0.6303\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 125 Total reward: 152.0 Average reward fake: 2.260291703316462e-20 Average reward real: 0.9995169639587402 Training g_loss: 71977096.0000 Training d_loss: 0.0005 Explore P: 0.6209\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 126 Total reward: 137.0 Average reward fake: 6.576804806071152e-21 Average reward real: 0.9998161196708679 Training g_loss: 104199848.0000 Training d_loss: 0.0002 Explore P: 0.6126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 127 Total reward: 44.0 Average reward fake: 6.010515767221838e-22 Average reward real: 0.9998295307159424 Training g_loss: 181903888.0000 Training d_loss: 0.0002 Explore P: 0.6100\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 128 Total reward: 57.0 Average reward fake: 4.9877207078271466e-30 Average reward real: 0.999752938747406 Training g_loss: 74023928.0000 Training d_loss: 0.0002 Explore P: 0.6066\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 129 Total reward: 21.0 Average reward fake: 7.45700301507668e-09 Average reward real: 0.9997046589851379 Training g_loss: 127173496.0000 Training d_loss: 0.0003 Explore P: 0.6053\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 130 Total reward: 40.0 Average reward fake: 2.7025517587518187e-17 Average reward real: 0.9996283054351807 Training g_loss: 35503796.0000 Training d_loss: 0.0004 Explore P: 0.6029\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 131 Total reward: 73.0 Average reward fake: 3.2557323337296777e-16 Average reward real: 0.9996354579925537 Training g_loss: 218014736.0000 Training d_loss: 0.0004 Explore P: 0.5986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 132 Total reward: 162.0 Average reward fake: 1.532741375803086e-15 Average reward real: 0.9998795390129089 Training g_loss: 212555072.0000 Training d_loss: 0.0001 Explore P: 0.5892\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 133 Total reward: 74.0 Average reward fake: 2.748705019642372e-20 Average reward real: 0.9997348189353943 Training g_loss: 199993264.0000 Training d_loss: 0.0003 Explore P: 0.5849\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 134 Total reward: 41.0 Average reward fake: 4.097921275317967e-13 Average reward real: 0.999905526638031 Training g_loss: 442547168.0000 Training d_loss: 0.0001 Explore P: 0.5826\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 135 Total reward: 78.0 Average reward fake: 6.337522243844668e-39 Average reward real: 0.9999220371246338 Training g_loss: 509170688.0000 Training d_loss: 0.0001 Explore P: 0.5781\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 136 Total reward: 37.0 Average reward fake: 2.238818255243312e-33 Average reward real: 0.9999321103096008 Training g_loss: 291761248.0000 Training d_loss: 0.0001 Explore P: 0.5760\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 137 Total reward: 31.0 Average reward fake: 0.0 Average reward real: 0.9999373555183411 Training g_loss: 140740400.0000 Training d_loss: 0.0001 Explore P: 0.5743\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 138 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999731183052063 Training g_loss: 412632320.0000 Training d_loss: 0.0000 Explore P: 0.5631\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 139 Total reward: 27.0 Average reward fake: 7.659097734227372e-22 Average reward real: 0.9999547004699707 Training g_loss: 283048384.0000 Training d_loss: 0.0000 Explore P: 0.5616\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 140 Total reward: 134.0 Average reward fake: 4.7170452644628035e-20 Average reward real: 0.9999558925628662 Training g_loss: 619718656.0000 Training d_loss: 0.0000 Explore P: 0.5543\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 141 Total reward: 154.0 Average reward fake: 0.0 Average reward real: 0.99991774559021 Training g_loss: 587310976.0000 Training d_loss: 0.0001 Explore P: 0.5460\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 142 Total reward: 199.0 Average reward fake: 6.621653724366561e-40 Average reward real: 0.9999825954437256 Training g_loss: 1522415232.0000 Training d_loss: 0.0000 Explore P: 0.5354\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 143 Total reward: 81.0 Average reward fake: 0.0 Average reward real: 0.9999784827232361 Training g_loss: 217800208.0000 Training d_loss: 0.0000 Explore P: 0.5312\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 144 Total reward: 191.0 Average reward fake: 1.4958970609734618e-35 Average reward real: 0.9999092221260071 Training g_loss: 278834368.0000 Training d_loss: 0.0001 Explore P: 0.5213\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 145 Total reward: 172.0 Average reward fake: 5.012059391488554e-21 Average reward real: 0.9999709129333496 Training g_loss: 2182050560.0000 Training d_loss: 0.0000 Explore P: 0.5126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 146 Total reward: 78.0 Average reward fake: 2.2599426330979646e-18 Average reward real: 0.9999605417251587 Training g_loss: 2843885568.0000 Training d_loss: 0.0000 Explore P: 0.5087\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 147 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999552965164185 Training g_loss: 1175180672.0000 Training d_loss: 0.0000 Explore P: 0.4989\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 148 Total reward: 199.0 Average reward fake: 1.009809932337319e-36 Average reward real: 0.9999462962150574 Training g_loss: 1259223552.0000 Training d_loss: 0.0001 Explore P: 0.4892\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 149 Total reward: 184.0 Average reward fake: 6.045371649427901e-24 Average reward real: 0.999992847442627 Training g_loss: 1847822080.0000 Training d_loss: 0.0000 Explore P: 0.4805\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 150 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999856352806091 Training g_loss: 1357165312.0000 Training d_loss: 0.0000 Explore P: 0.4712\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 151 Total reward: 50.0 Average reward fake: 0.0 Average reward real: 0.9999929070472717 Training g_loss: 2329537280.0000 Training d_loss: 0.0000 Explore P: 0.4689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 152 Total reward: 199.0 Average reward fake: 6.0366886757161e-36 Average reward real: 0.9999925494194031 Training g_loss: 2333085696.0000 Training d_loss: 0.0000 Explore P: 0.4599\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 153 Total reward: 67.0 Average reward fake: 1.348842200439265e-25 Average reward real: 0.999989926815033 Training g_loss: 1597162496.0000 Training d_loss: 0.0000 Explore P: 0.4569\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 154 Total reward: 180.0 Average reward fake: 1.583980503141548e-35 Average reward real: 0.9999929666519165 Training g_loss: 1137490304.0000 Training d_loss: 0.0000 Explore P: 0.4489\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 155 Total reward: 52.0 Average reward fake: 0.0 Average reward real: 0.9999945163726807 Training g_loss: 2910752768.0000 Training d_loss: 0.0000 Explore P: 0.4466\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 156 Total reward: 199.0 Average reward fake: 3.663934323198981e-21 Average reward real: 0.9999818205833435 Training g_loss: 1230904448.0000 Training d_loss: 0.0000 Explore P: 0.4380\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 157 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999879598617554 Training g_loss: 3620379136.0000 Training d_loss: 0.0000 Explore P: 0.4296\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 158 Total reward: 199.0 Average reward fake: 2.032988458756705e-22 Average reward real: 0.9999948143959045 Training g_loss: 1464123648.0000 Training d_loss: 0.0000 Explore P: 0.4213\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 159 Total reward: 11.0 Average reward fake: 0.0 Average reward real: 0.999996542930603 Training g_loss: 2764561408.0000 Training d_loss: 0.0000 Explore P: 0.4209\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 160 Total reward: 199.0 Average reward fake: 1.415831035915469e-25 Average reward real: 0.9999971985816956 Training g_loss: 2859377920.0000 Training d_loss: 0.0000 Explore P: 0.4128\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 161 Total reward: 199.0 Average reward fake: 2.9284925458142564e-34 Average reward real: 0.9999949932098389 Training g_loss: 1703763328.0000 Training d_loss: 0.0000 Explore P: 0.4048\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 162 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999963641166687 Training g_loss: 780186112.0000 Training d_loss: 0.0000 Explore P: 0.3971\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 163 Total reward: 23.0 Average reward fake: 0.0 Average reward real: 0.9999951124191284 Training g_loss: 5083217408.0000 Training d_loss: 0.0000 Explore P: 0.3962\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 164 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999958872795105 Training g_loss: 1024118848.0000 Training d_loss: 0.0000 Explore P: 0.3886\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 165 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999983310699463 Training g_loss: 1115178112.0000 Training d_loss: 0.0000 Explore P: 0.3811\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 166 Total reward: 199.0 Average reward fake: 6.605234595788848e-23 Average reward real: 0.9999980926513672 Training g_loss: 1134157312.0000 Training d_loss: 0.0000 Explore P: 0.3738\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 167 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999986290931702 Training g_loss: 1385457152.0000 Training d_loss: 0.0000 Explore P: 0.3666\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 168 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.999998927116394 Training g_loss: 3596570624.0000 Training d_loss: 0.0000 Explore P: 0.3596\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 169 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999992847442627 Training g_loss: 3315786752.0000 Training d_loss: 0.0000 Explore P: 0.3527\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 170 Total reward: 125.0 Average reward fake: 0.0 Average reward real: 0.9999992251396179 Training g_loss: 2817038848.0000 Training d_loss: 0.0000 Explore P: 0.3485\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 171 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999986886978149 Training g_loss: 719708224.0000 Training d_loss: 0.0000 Explore P: 0.3418\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 172 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999992847442627 Training g_loss: 2141359616.0000 Training d_loss: 0.0000 Explore P: 0.3353\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 173 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999986290931702 Training g_loss: 394433056.0000 Training d_loss: 0.0000 Explore P: 0.3288\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 174 Total reward: 199.0 Average reward fake: 1.1505434638192986e-17 Average reward real: 0.9999401569366455 Training g_loss: 2431164928.0000 Training d_loss: 0.0001 Explore P: 0.3226\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 175 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999978542327881 Training g_loss: 2933393408.0000 Training d_loss: 0.0000 Explore P: 0.3164\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 176 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999896883964539 Training g_loss: 2608679168.0000 Training d_loss: 0.0000 Explore P: 0.3104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 177 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999974966049194 Training g_loss: 2449985280.0000 Training d_loss: 0.0000 Explore P: 0.3044\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 178 Total reward: 199.0 Average reward fake: 4.952479884272076e-36 Average reward real: 0.9999600052833557 Training g_loss: 3986933760.0000 Training d_loss: 0.0000 Explore P: 0.2986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 179 Total reward: 199.0 Average reward fake: 1.1653226377852376e-18 Average reward real: 0.9999890327453613 Training g_loss: 420851168.0000 Training d_loss: 0.0000 Explore P: 0.2930\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 180 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999952912330627 Training g_loss: 3034621440.0000 Training d_loss: 0.0000 Explore P: 0.2874\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 181 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999969601631165 Training g_loss: 259881392.0000 Training d_loss: 0.0000 Explore P: 0.2819\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 182 Total reward: 199.0 Average reward fake: 3.1765994112849445e-20 Average reward real: 0.9999994039535522 Training g_loss: 504859104.0000 Training d_loss: 0.0000 Explore P: 0.2766\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 183 Total reward: 199.0 Average reward fake: 8.425989282987711e-17 Average reward real: 0.9999988675117493 Training g_loss: 1162818560.0000 Training d_loss: 0.0000 Explore P: 0.2713\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 184 Total reward: 199.0 Average reward fake: 1.462348536470735e-23 Average reward real: 0.9999996423721313 Training g_loss: 728578496.0000 Training d_loss: 0.0000 Explore P: 0.2662\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 185 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999996423721313 Training g_loss: 575361728.0000 Training d_loss: 0.0000 Explore P: 0.2611\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 186 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999994039535522 Training g_loss: 1125154688.0000 Training d_loss: 0.0000 Explore P: 0.2562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 187 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999983906745911 Training g_loss: 1040579584.0000 Training d_loss: 0.0000 Explore P: 0.2513\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 188 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999996423721313 Training g_loss: 307805088.0000 Training d_loss: 0.0000 Explore P: 0.2466\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 189 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999998211860657 Training g_loss: 163742448.0000 Training d_loss: 0.0000 Explore P: 0.2419\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 190 Total reward: 199.0 Average reward fake: 1.519642985556596e-30 Average reward real: 0.9999995231628418 Training g_loss: 190805808.0000 Training d_loss: 0.0000 Explore P: 0.2373\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 191 Total reward: 199.0 Average reward fake: 9.101689769975044e-25 Average reward real: 0.9999998211860657 Training g_loss: 170098496.0000 Training d_loss: 0.0000 Explore P: 0.2329\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 192 Total reward: 199.0 Average reward fake: 3.1940191848249635e-36 Average reward real: 0.9999999403953552 Training g_loss: 234289248.0000 Training d_loss: 0.0000 Explore P: 0.2285\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 193 Total reward: 199.0 Average reward fake: 1.1289291039599912e-25 Average reward real: 0.9999998211860657 Training g_loss: 140711936.0000 Training d_loss: 0.0000 Explore P: 0.2242\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 194 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999999403953552 Training g_loss: 101462912.0000 Training d_loss: 0.0000 Explore P: 0.2199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 195 Total reward: 199.0 Average reward fake: 9.437962516424425e-29 Average reward real: 0.9999999403953552 Training g_loss: 91192424.0000 Training d_loss: 0.0000 Explore P: 0.2158\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 196 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999998211860657 Training g_loss: 481255424.0000 Training d_loss: 0.0000 Explore P: 0.2117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 197 Total reward: 199.0 Average reward fake: 9.916989523246115e-20 Average reward real: 0.9999998211860657 Training g_loss: 281797856.0000 Training d_loss: 0.0000 Explore P: 0.2078\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 198 Total reward: 199.0 Average reward fake: 2.5395619965081514e-39 Average reward real: 1.0 Training g_loss: 263604816.0000 Training d_loss: 0.0000 Explore P: 0.2039\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 199 Total reward: 199.0 Average reward fake: 1.3303275005845019e-15 Average reward real: 0.9999999403953552 Training g_loss: 287456608.0000 Training d_loss: 0.0000 Explore P: 0.2001\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 200 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999702572822571 Training g_loss: 401182016.0000 Training d_loss: 0.0000 Explore P: 0.1963\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 201 Total reward: 199.0 Average reward fake: 9.085178463603519e-41 Average reward real: 0.9997498393058777 Training g_loss: 105525856.0000 Training d_loss: 0.0003 Explore P: 0.1926\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 202 Total reward: 199.0 Average reward fake: 8.971636196210282e-31 Average reward real: 0.9999721050262451 Training g_loss: 176793520.0000 Training d_loss: 0.0000 Explore P: 0.1890\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 203 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999901652336121 Training g_loss: 84261944.0000 Training d_loss: 0.0000 Explore P: 0.1855\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 204 Total reward: 199.0 Average reward fake: 4.820884626182075e-34 Average reward real: 0.999982476234436 Training g_loss: 185430336.0000 Training d_loss: 0.0000 Explore P: 0.1821\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 205 Total reward: 199.0 Average reward fake: 2.302619428462549e-09 Average reward real: 0.9999861717224121 Training g_loss: 52759896.0000 Training d_loss: 0.0000 Explore P: 0.1787\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 206 Total reward: 199.0 Average reward fake: 3.83435857098548e-21 Average reward real: 0.999966561794281 Training g_loss: 27856574.0000 Training d_loss: 0.0000 Explore P: 0.1753\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 207 Total reward: 199.0 Average reward fake: 1.8744951608713062e-13 Average reward real: 0.9999485611915588 Training g_loss: 28381862.0000 Training d_loss: 0.0001 Explore P: 0.1721\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 208 Total reward: 199.0 Average reward fake: 8.59185279658837e-36 Average reward real: 0.9997732639312744 Training g_loss: 93928464.0000 Training d_loss: 0.0002 Explore P: 0.1689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 209 Total reward: 199.0 Average reward fake: 0.004964096006006002 Average reward real: 0.9997439384460449 Training g_loss: 23466478.0000 Training d_loss: 0.0003 Explore P: 0.1658\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 210 Total reward: 199.0 Average reward fake: 1.4926009317406397e-09 Average reward real: 0.9999558925628662 Training g_loss: 70048728.0000 Training d_loss: 0.0000 Explore P: 0.1627\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 211 Total reward: 199.0 Average reward fake: 6.228859206203197e-07 Average reward real: 0.9999229311943054 Training g_loss: 195542688.0000 Training d_loss: 0.0001 Explore P: 0.1597\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 212 Total reward: 199.0 Average reward fake: 4.807564346620552e-10 Average reward real: 0.9999090433120728 Training g_loss: 52421840.0000 Training d_loss: 0.0001 Explore P: 0.1567\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 213 Total reward: 199.0 Average reward fake: 1.0467209043962811e-10 Average reward real: 0.999919593334198 Training g_loss: 82290448.0000 Training d_loss: 0.0001 Explore P: 0.1538\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 214 Total reward: 199.0 Average reward fake: 1.5394949547800017e-17 Average reward real: 0.9999130964279175 Training g_loss: 51987076.0000 Training d_loss: 0.0001 Explore P: 0.1510\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 215 Total reward: 199.0 Average reward fake: 3.4163353391828094e-18 Average reward real: 0.9997047185897827 Training g_loss: 46222224.0000 Training d_loss: 0.0003 Explore P: 0.1482\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 216 Total reward: 199.0 Average reward fake: 2.492139055281653e-18 Average reward real: 0.999951958656311 Training g_loss: 13562581.0000 Training d_loss: 0.0000 Explore P: 0.1455\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 217 Total reward: 199.0 Average reward fake: 3.223974421559154e-16 Average reward real: 0.9999931454658508 Training g_loss: 43672400.0000 Training d_loss: 0.0000 Explore P: 0.1428\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 218 Total reward: 199.0 Average reward fake: 1.1737990734450838e-23 Average reward real: 0.9999673366546631 Training g_loss: 14095735.0000 Training d_loss: 0.0000 Explore P: 0.1402\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 219 Total reward: 70.0 Average reward fake: 0.0 Average reward real: 0.9999704957008362 Training g_loss: 16999490.0000 Training d_loss: 0.0000 Explore P: 0.1393\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 220 Total reward: 199.0 Average reward fake: 3.236130932539029e-16 Average reward real: 0.999919056892395 Training g_loss: 19520432.0000 Training d_loss: 0.0001 Explore P: 0.1368\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 221 Total reward: 199.0 Average reward fake: 2.6317035935606924e-21 Average reward real: 0.999916672706604 Training g_loss: 12836011.0000 Training d_loss: 0.0001 Explore P: 0.1343\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 222 Total reward: 146.0 Average reward fake: 2.7882871063711333e-21 Average reward real: 0.9999826550483704 Training g_loss: 65354936.0000 Training d_loss: 0.0000 Explore P: 0.1325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 223 Total reward: 77.0 Average reward fake: 8.319244598764541e-12 Average reward real: 0.9999909996986389 Training g_loss: 65393504.0000 Training d_loss: 0.0000 Explore P: 0.1315\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 224 Total reward: 199.0 Average reward fake: 1.4814450111089172e-08 Average reward real: 0.9999191164970398 Training g_loss: 16966074.0000 Training d_loss: 0.0001 Explore P: 0.1291\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 225 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9984408617019653 Training g_loss: 9972847.0000 Training d_loss: 0.0018 Explore P: 0.1268\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 226 Total reward: 199.0 Average reward fake: 2.8839073056702302e-12 Average reward real: 0.9997904300689697 Training g_loss: 18642524.0000 Training d_loss: 0.0002 Explore P: 0.1245\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 227 Total reward: 199.0 Average reward fake: 1.1612817374384576e-08 Average reward real: 0.9999536275863647 Training g_loss: 12043522.0000 Training d_loss: 0.0000 Explore P: 0.1222\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 228 Total reward: 165.0 Average reward fake: 0.0 Average reward real: 0.9999658465385437 Training g_loss: 42666804.0000 Training d_loss: 0.0000 Explore P: 0.1204\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 229 Total reward: 199.0 Average reward fake: 6.693586469901349e-27 Average reward real: 0.9999732375144958 Training g_loss: 13340942.0000 Training d_loss: 0.0000 Explore P: 0.1182\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 230 Total reward: 199.0 Average reward fake: 1.9747974956685344e-12 Average reward real: 0.9999760985374451 Training g_loss: 7250265.0000 Training d_loss: 0.0000 Explore P: 0.1161\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 231 Total reward: 199.0 Average reward fake: 2.25337593029451e-09 Average reward real: 0.9997378587722778 Training g_loss: 18084064.0000 Training d_loss: 0.0003 Explore P: 0.1140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 232 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.999833881855011 Training g_loss: 6143265.0000 Training d_loss: 0.0002 Explore P: 0.1119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 233 Total reward: 199.0 Average reward fake: 1.9074521333095618e-05 Average reward real: 0.9997378587722778 Training g_loss: 2979592.7500 Training d_loss: 0.0118 Explore P: 0.1099\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 234 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999672770500183 Training g_loss: 15926300.0000 Training d_loss: 0.0000 Explore P: 0.1080\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 235 Total reward: 199.0 Average reward fake: 0.008014010265469551 Average reward real: 0.9980528354644775 Training g_loss: 12474051.0000 Training d_loss: 0.0020 Explore P: 0.1060\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 236 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9999263286590576 Training g_loss: 16635388.0000 Training d_loss: 0.0001 Explore P: 0.1041\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 237 Total reward: 199.0 Average reward fake: 3.4523224123200746e-12 Average reward real: 0.9933763146400452 Training g_loss: 11615698.0000 Training d_loss: 0.0149 Explore P: 0.1023\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 238 Total reward: 199.0 Average reward fake: 3.647762071437861e-40 Average reward real: 0.9998708963394165 Training g_loss: 10690324.0000 Training d_loss: 0.0001 Explore P: 0.1005\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 239 Total reward: 199.0 Average reward fake: 1.4880382967202366e-22 Average reward real: 0.9998782277107239 Training g_loss: 7998961.5000 Training d_loss: 0.0001 Explore P: 0.0987\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 240 Total reward: 199.0 Average reward fake: 0.0043287682346999645 Average reward real: 0.9977006316184998 Training g_loss: 6881019.0000 Training d_loss: 0.0024 Explore P: 0.0969\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 241 Total reward: 199.0 Average reward fake: 0.009358515031635761 Average reward real: 0.9994127154350281 Training g_loss: 2646939.7500 Training d_loss: 0.0006 Explore P: 0.0952\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 242 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9987742900848389 Training g_loss: 2392227.0000 Training d_loss: 0.0013 Explore P: 0.0935\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 243 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9992936849594116 Training g_loss: 2217506.2500 Training d_loss: 0.0007 Explore P: 0.0919\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 244 Total reward: 97.0 Average reward fake: 3.995792801860963e-15 Average reward real: 0.9994833469390869 Training g_loss: 15447320.0000 Training d_loss: 0.0005 Explore P: 0.0911\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 245 Total reward: 199.0 Average reward fake: 8.222433530283028e-23 Average reward real: 0.9999458193778992 Training g_loss: 15672811.0000 Training d_loss: 0.0001 Explore P: 0.0895\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 246 Total reward: 199.0 Average reward fake: 2.654518792277738e-11 Average reward real: 0.9876434206962585 Training g_loss: 21712140.0000 Training d_loss: 0.0171 Explore P: 0.0879\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 247 Total reward: 140.0 Average reward fake: 3.408518606251576e-11 Average reward real: 0.9956371188163757 Training g_loss: 3733689.7500 Training d_loss: 0.0054 Explore P: 0.0869\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 248 Total reward: 199.0 Average reward fake: 8.499279838952711e-13 Average reward real: 0.9997544884681702 Training g_loss: 2823684.0000 Training d_loss: 0.0002 Explore P: 0.0853\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 249 Total reward: 153.0 Average reward fake: 4.866217410986638e-15 Average reward real: 0.9996928572654724 Training g_loss: 2127669.0000 Training d_loss: 0.0254 Explore P: 0.0842\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 250 Total reward: 199.0 Average reward fake: 4.084490137756802e-05 Average reward real: 0.99969482421875 Training g_loss: 3171079.0000 Training d_loss: 0.0003 Explore P: 0.0827\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 251 Total reward: 199.0 Average reward fake: 3.094691966347675e-29 Average reward real: 0.9995046257972717 Training g_loss: 4009230.0000 Training d_loss: 0.0005 Explore P: 0.0813\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 252 Total reward: 121.0 Average reward fake: 0.0 Average reward real: 0.9997801184654236 Training g_loss: 7905595.5000 Training d_loss: 0.0002 Explore P: 0.0805\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 253 Total reward: 199.0 Average reward fake: 1.2626553279229246e-14 Average reward real: 0.999000072479248 Training g_loss: 24274474.0000 Training d_loss: 0.0248 Explore P: 0.0791\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 254 Total reward: 199.0 Average reward fake: 1.8835775108527741e-06 Average reward real: 0.9977104663848877 Training g_loss: 2982885.0000 Training d_loss: 0.0024 Explore P: 0.0777\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 255 Total reward: 144.0 Average reward fake: 2.4160429008242324e-34 Average reward real: 0.9988477826118469 Training g_loss: 3291712.2500 Training d_loss: 0.0012 Explore P: 0.0767\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 256 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9993719458580017 Training g_loss: 25706240.0000 Training d_loss: 0.0006 Explore P: 0.0754\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 257 Total reward: 199.0 Average reward fake: 2.359556917155847e-16 Average reward real: 0.9998716115951538 Training g_loss: 2806683.7500 Training d_loss: 0.0003 Explore P: 0.0741\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 258 Total reward: 199.0 Average reward fake: 1.8810651454259641e-06 Average reward real: 0.9960446953773499 Training g_loss: 2357200.2500 Training d_loss: 0.0270 Explore P: 0.0729\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 259 Total reward: 159.0 Average reward fake: 0.0 Average reward real: 0.9996864199638367 Training g_loss: 11844377.0000 Training d_loss: 0.0003 Explore P: 0.0719\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 260 Total reward: 174.0 Average reward fake: 1.0736138930987527e-21 Average reward real: 0.9977465867996216 Training g_loss: 1743647.6250 Training d_loss: 0.0025 Explore P: 0.0708\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 261 Total reward: 173.0 Average reward fake: 1.748969896339872e-30 Average reward real: 0.9994956851005554 Training g_loss: 13694484.0000 Training d_loss: 0.0005 Explore P: 0.0698\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 262 Total reward: 199.0 Average reward fake: 7.0435168114668656e-12 Average reward real: 0.9992445111274719 Training g_loss: 13218783.0000 Training d_loss: 0.1169 Explore P: 0.0686\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 263 Total reward: 189.0 Average reward fake: 0.0 Average reward real: 0.9997610449790955 Training g_loss: 3959602.7500 Training d_loss: 0.0002 Explore P: 0.0675\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 264 Total reward: 175.0 Average reward fake: 2.1189396632766124e-21 Average reward real: 0.9996236562728882 Training g_loss: 10081559.0000 Training d_loss: 0.0004 Explore P: 0.0665\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 265 Total reward: 199.0 Average reward fake: 2.5505535624819804e-28 Average reward real: 0.9995932579040527 Training g_loss: 938236.7500 Training d_loss: 0.0004 Explore P: 0.0654\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 266 Total reward: 199.0 Average reward fake: 9.065402089448787e-23 Average reward real: 0.9997348189353943 Training g_loss: 2395159.5000 Training d_loss: 0.0003 Explore P: 0.0643\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 267 Total reward: 199.0 Average reward fake: 2.8314540294887084e-22 Average reward real: 0.9995168447494507 Training g_loss: 9899878.0000 Training d_loss: 0.0005 Explore P: 0.0632\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 268 Total reward: 157.0 Average reward fake: 1.0493307577832869e-14 Average reward real: 0.9995215535163879 Training g_loss: 16180167.0000 Training d_loss: 0.0005 Explore P: 0.0624\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 269 Total reward: 199.0 Average reward fake: 0.0006379082333296537 Average reward real: 0.9998992681503296 Training g_loss: 710101.9375 Training d_loss: 0.0001 Explore P: 0.0614\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 270 Total reward: 199.0 Average reward fake: 1.5690894041638032e-24 Average reward real: 0.9998789429664612 Training g_loss: 6143979.5000 Training d_loss: 0.0001 Explore P: 0.0603\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 271 Total reward: 199.0 Average reward fake: 3.29162692188585e-32 Average reward real: 0.999864935874939 Training g_loss: 3869640.5000 Training d_loss: 0.0001 Explore P: 0.0594\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 272 Total reward: 199.0 Average reward fake: 3.271597576182117e-11 Average reward real: 0.999845027923584 Training g_loss: 6557003.5000 Training d_loss: 0.0002 Explore P: 0.0584\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 273 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9991073608398438 Training g_loss: 1806575.8750 Training d_loss: 0.0009 Explore P: 0.0574\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 274 Total reward: 61.0 Average reward fake: 3.754914246201224e-07 Average reward real: 0.9971771240234375 Training g_loss: 991702.4375 Training d_loss: 0.0064 Explore P: 0.0571\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 275 Total reward: 38.0 Average reward fake: 3.087537379542482e-06 Average reward real: 0.9992515444755554 Training g_loss: 15977742.0000 Training d_loss: 0.0008 Explore P: 0.0570\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 276 Total reward: 197.0 Average reward fake: 1.1558557162061334e-05 Average reward real: 0.998309314250946 Training g_loss: 2006881.6250 Training d_loss: 0.0932 Explore P: 0.0560\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 277 Total reward: 199.0 Average reward fake: 9.197712643072009e-06 Average reward real: 0.9978798031806946 Training g_loss: 5239437.5000 Training d_loss: 0.0091 Explore P: 0.0551\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 278 Total reward: 134.0 Average reward fake: 0.003794389311224222 Average reward real: 0.9956822395324707 Training g_loss: 5162242.5000 Training d_loss: 0.0273 Explore P: 0.0545\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 279 Total reward: 96.0 Average reward fake: 4.0184348395740175e-15 Average reward real: 0.9990026950836182 Training g_loss: 11303583.0000 Training d_loss: 0.0404 Explore P: 0.0541\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 280 Total reward: 199.0 Average reward fake: 5.156485372026509e-07 Average reward real: 0.9941795468330383 Training g_loss: 8297125.0000 Training d_loss: 0.0154 Explore P: 0.0532\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 281 Total reward: 57.0 Average reward fake: 0.0001711083168629557 Average reward real: 0.9953939914703369 Training g_loss: 784352.3125 Training d_loss: 0.0072 Explore P: 0.0530\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 282 Total reward: 199.0 Average reward fake: 1.3427831836674702e-30 Average reward real: 0.9997117519378662 Training g_loss: 6967573.0000 Training d_loss: 0.0003 Explore P: 0.0521\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 283 Total reward: 199.0 Average reward fake: 5.940429218753707e-06 Average reward real: 0.9980127215385437 Training g_loss: 751338.1875 Training d_loss: 0.0159 Explore P: 0.0513\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 284 Total reward: 199.0 Average reward fake: 7.908249166632686e-09 Average reward real: 0.997138500213623 Training g_loss: 4930405.5000 Training d_loss: 0.0379 Explore P: 0.0505\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 285 Total reward: 199.0 Average reward fake: 7.022398613130976e-13 Average reward real: 0.997983992099762 Training g_loss: 1635825.0000 Training d_loss: 0.0100 Explore P: 0.0497\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 286 Total reward: 199.0 Average reward fake: 1.3136928674984863e-21 Average reward real: 0.998386561870575 Training g_loss: 1236935.1250 Training d_loss: 0.0017 Explore P: 0.0489\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 287 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9986746311187744 Training g_loss: 1855811.1250 Training d_loss: 0.0016 Explore P: 0.0482\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 288 Total reward: 188.0 Average reward fake: 7.805610796874599e-40 Average reward real: 0.9959190487861633 Training g_loss: 4975393.0000 Training d_loss: 0.0343 Explore P: 0.0474\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 289 Total reward: 199.0 Average reward fake: 0.006727499887347221 Average reward real: 0.9992062449455261 Training g_loss: 2993472.0000 Training d_loss: 0.0008 Explore P: 0.0467\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 290 Total reward: 199.0 Average reward fake: 1.3623646752825708e-13 Average reward real: 0.9939248561859131 Training g_loss: 809679.1875 Training d_loss: 0.0067 Explore P: 0.0460\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 291 Total reward: 199.0 Average reward fake: 5.2859893699808384e-27 Average reward real: 0.9985218644142151 Training g_loss: 3617255.5000 Training d_loss: 0.0015 Explore P: 0.0453\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 292 Total reward: 174.0 Average reward fake: 0.0 Average reward real: 0.9986027479171753 Training g_loss: 480395.4375 Training d_loss: 0.0014 Explore P: 0.0447\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 293 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9991021156311035 Training g_loss: 1575725.0000 Training d_loss: 0.0009 Explore P: 0.0440\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 294 Total reward: 189.0 Average reward fake: 6.485138328571338e-07 Average reward real: 0.9876596927642822 Training g_loss: 613133.5625 Training d_loss: 0.0799 Explore P: 0.0433\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 295 Total reward: 199.0 Average reward fake: 2.2583002904762867e-13 Average reward real: 0.994875967502594 Training g_loss: 505877.0625 Training d_loss: 0.0059 Explore P: 0.0427\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 296 Total reward: 199.0 Average reward fake: 0.01188679225742817 Average reward real: 0.9979493618011475 Training g_loss: 414750.0938 Training d_loss: 0.0021 Explore P: 0.0420\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 297 Total reward: 199.0 Average reward fake: 2.8438577628180415e-23 Average reward real: 0.9939441084861755 Training g_loss: 1868732.3750 Training d_loss: 0.0081 Explore P: 0.0414\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 298 Total reward: 199.0 Average reward fake: 2.856335705610745e-15 Average reward real: 0.9976322650909424 Training g_loss: 1835602.0000 Training d_loss: 0.0024 Explore P: 0.0408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 299 Total reward: 199.0 Average reward fake: 5.5340078700053285e-19 Average reward real: 0.999197244644165 Training g_loss: 1112352.0000 Training d_loss: 0.0008 Explore P: 0.0402\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 300 Total reward: 199.0 Average reward fake: 5.003691350147221e-10 Average reward real: 0.9975907802581787 Training g_loss: 2767180.7500 Training d_loss: 0.0026 Explore P: 0.0396\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 301 Total reward: 199.0 Average reward fake: 8.931682975686639e-13 Average reward real: 0.9927191734313965 Training g_loss: 407315.0625 Training d_loss: 0.0077 Explore P: 0.0390\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 302 Total reward: 199.0 Average reward fake: 0.005027326755225658 Average reward real: 0.9990934729576111 Training g_loss: 312704.7812 Training d_loss: 0.0009 Explore P: 0.0384\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 303 Total reward: 199.0 Average reward fake: 3.3900253129104385e-06 Average reward real: 0.9987030029296875 Training g_loss: 413266.9062 Training d_loss: 0.0013 Explore P: 0.0379\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 304 Total reward: 199.0 Average reward fake: 2.4852188289514743e-06 Average reward real: 0.9944294691085815 Training g_loss: 1621433.3750 Training d_loss: 0.0208 Explore P: 0.0373\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 305 Total reward: 162.0 Average reward fake: 0.0 Average reward real: 0.9985635280609131 Training g_loss: 363533.5938 Training d_loss: 0.0015 Explore P: 0.0369\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 306 Total reward: 199.0 Average reward fake: 0.018242761492729187 Average reward real: 0.9978063702583313 Training g_loss: 267569.1250 Training d_loss: 0.0023 Explore P: 0.0364\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 307 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.998427152633667 Training g_loss: 2132877.7500 Training d_loss: 0.0017 Explore P: 0.0358\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 308 Total reward: 199.0 Average reward fake: 0.00931681040674448 Average reward real: 0.9990125894546509 Training g_loss: 288700.7188 Training d_loss: 0.0170 Explore P: 0.0353\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 309 Total reward: 199.0 Average reward fake: 0.0057537127286195755 Average reward real: 0.9976660013198853 Training g_loss: 318854.8438 Training d_loss: 0.0024 Explore P: 0.0348\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 310 Total reward: 199.0 Average reward fake: 1.3989150635677737e-22 Average reward real: 0.9980195760726929 Training g_loss: 1081538.8750 Training d_loss: 0.0020 Explore P: 0.0343\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 311 Total reward: 199.0 Average reward fake: 2.7232834355688495e-40 Average reward real: 0.9994229078292847 Training g_loss: 325778.8125 Training d_loss: 0.0006 Explore P: 0.0339\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 312 Total reward: 199.0 Average reward fake: 1.890046746666485e-06 Average reward real: 0.9987634420394897 Training g_loss: 702688.5000 Training d_loss: 0.0012 Explore P: 0.0334\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 313 Total reward: 86.0 Average reward fake: 1.0599725634187237e-17 Average reward real: 0.9990702271461487 Training g_loss: 550474.3750 Training d_loss: 0.0241 Explore P: 0.0332\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 314 Total reward: 194.0 Average reward fake: 0.009803556837141514 Average reward real: 0.9947288036346436 Training g_loss: 1269023.5000 Training d_loss: 0.1157 Explore P: 0.0327\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 315 Total reward: 199.0 Average reward fake: 7.18702267477056e-06 Average reward real: 0.9977720379829407 Training g_loss: 3317530.0000 Training d_loss: 0.0022 Explore P: 0.0323\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 316 Total reward: 30.0 Average reward fake: 0.00030498101841658354 Average reward real: 0.9958418011665344 Training g_loss: 471315.6250 Training d_loss: 0.0045 Explore P: 0.0322\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 317 Total reward: 103.0 Average reward fake: 3.800796483099944e-11 Average reward real: 0.9943893551826477 Training g_loss: 219941.2188 Training d_loss: 0.0560 Explore P: 0.0320\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 318 Total reward: 199.0 Average reward fake: 8.048463482731838e-20 Average reward real: 0.9993737936019897 Training g_loss: 697260.3750 Training d_loss: 0.0235 Explore P: 0.0316\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 319 Total reward: 199.0 Average reward fake: 0.013803798705339432 Average reward real: 0.9945088028907776 Training g_loss: 464343.6562 Training d_loss: 0.0913 Explore P: 0.0311\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 320 Total reward: 173.0 Average reward fake: 8.795093435765011e-07 Average reward real: 0.9987977743148804 Training g_loss: 331055.9375 Training d_loss: 0.0012 Explore P: 0.0308\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 321 Total reward: 124.0 Average reward fake: 1.5706589481687852e-20 Average reward real: 0.9907389283180237 Training g_loss: 294217.7500 Training d_loss: 0.0119 Explore P: 0.0305\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 322 Total reward: 158.0 Average reward fake: 1.3842152347462332e-39 Average reward real: 0.9986498355865479 Training g_loss: 338285.4062 Training d_loss: 0.0014 Explore P: 0.0302\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 323 Total reward: 199.0 Average reward fake: 1.8705078509591642e-22 Average reward real: 0.9949593544006348 Training g_loss: 834004.0625 Training d_loss: 0.0052 Explore P: 0.0298\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 324 Total reward: 199.0 Average reward fake: 1.0590892337861905e-16 Average reward real: 0.9996898770332336 Training g_loss: 169910.7656 Training d_loss: 0.0003 Explore P: 0.0294\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 325 Total reward: 195.0 Average reward fake: 0.06342337280511856 Average reward real: 0.9903634786605835 Training g_loss: 419427.5312 Training d_loss: 0.0189 Explore P: 0.0290\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 326 Total reward: 95.0 Average reward fake: 0.0 Average reward real: 0.9983599781990051 Training g_loss: 198815.0156 Training d_loss: 0.0017 Explore P: 0.0289\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 327 Total reward: 172.0 Average reward fake: 0.03011101298034191 Average reward real: 0.9968713521957397 Training g_loss: 1145963.2500 Training d_loss: 0.0032 Explore P: 0.0285\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 328 Total reward: 110.0 Average reward fake: 9.838696968245131e-09 Average reward real: 0.9996165633201599 Training g_loss: 195815.4219 Training d_loss: 0.0004 Explore P: 0.0283\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 329 Total reward: 133.0 Average reward fake: 0.0010343283647671342 Average reward real: 0.9997218251228333 Training g_loss: 931281.8125 Training d_loss: 0.0003 Explore P: 0.0281\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 330 Total reward: 158.0 Average reward fake: 4.69986360940311e-08 Average reward real: 0.992982029914856 Training g_loss: 1371602.1250 Training d_loss: 0.0078 Explore P: 0.0278\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 331 Total reward: 101.0 Average reward fake: 1.5592231329555627e-28 Average reward real: 0.9992976188659668 Training g_loss: 169196.2656 Training d_loss: 0.0007 Explore P: 0.0276\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 332 Total reward: 106.0 Average reward fake: 1.5535362464164158e-16 Average reward real: 0.9945555329322815 Training g_loss: 958858.6250 Training d_loss: 0.0176 Explore P: 0.0274\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 333 Total reward: 105.0 Average reward fake: 0.0 Average reward real: 0.9972814917564392 Training g_loss: 1039425.7500 Training d_loss: 0.0028 Explore P: 0.0273\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 334 Total reward: 133.0 Average reward fake: 4.781045388878985e-38 Average reward real: 0.999673068523407 Training g_loss: 279141.0000 Training d_loss: 0.0003 Explore P: 0.0270\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 335 Total reward: 135.0 Average reward fake: 1.2472843591293525e-10 Average reward real: 0.9997857809066772 Training g_loss: 551498.8125 Training d_loss: 0.0002 Explore P: 0.0268\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 336 Total reward: 107.0 Average reward fake: 0.06277012079954147 Average reward real: 0.9983817934989929 Training g_loss: 1496741.3750 Training d_loss: 0.0392 Explore P: 0.0266\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 337 Total reward: 105.0 Average reward fake: 0.0 Average reward real: 0.9995723962783813 Training g_loss: 909849.6250 Training d_loss: 0.0004 Explore P: 0.0265\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 338 Total reward: 115.0 Average reward fake: 0.0 Average reward real: 0.9995476007461548 Training g_loss: 649820.9375 Training d_loss: 0.0005 Explore P: 0.0263\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 339 Total reward: 112.0 Average reward fake: 7.211515562414533e-26 Average reward real: 0.9996793270111084 Training g_loss: 177351.6094 Training d_loss: 0.0003 Explore P: 0.0261\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 340 Total reward: 107.0 Average reward fake: 9.841345234259734e-33 Average reward real: 0.9993938207626343 Training g_loss: 196723.6250 Training d_loss: 0.0006 Explore P: 0.0259\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 341 Total reward: 124.0 Average reward fake: 0.0 Average reward real: 0.9996839165687561 Training g_loss: 192482.3125 Training d_loss: 0.0003 Explore P: 0.0257\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 342 Total reward: 21.0 Average reward fake: 0.0 Average reward real: 0.9997305274009705 Training g_loss: 331423.5938 Training d_loss: 0.0003 Explore P: 0.0257\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 343 Total reward: 13.0 Average reward fake: 0.0 Average reward real: 0.9993737936019897 Training g_loss: 10528414.0000 Training d_loss: 0.0006 Explore P: 0.0257\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 344 Total reward: 181.0 Average reward fake: 0.0 Average reward real: 0.9998090863227844 Training g_loss: 589198.6250 Training d_loss: 0.0002 Explore P: 0.0254\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 345 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9985321760177612 Training g_loss: 3771008.7500 Training d_loss: 0.0015 Explore P: 0.0251\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 346 Total reward: 149.0 Average reward fake: 0.0 Average reward real: 0.9997357726097107 Training g_loss: 264369.4688 Training d_loss: 0.0003 Explore P: 0.0249\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 347 Total reward: 143.0 Average reward fake: 3.0007267016237543e-14 Average reward real: 0.9993191361427307 Training g_loss: 339376.5312 Training d_loss: 0.0007 Explore P: 0.0246\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 348 Total reward: 131.0 Average reward fake: 0.0 Average reward real: 0.999504804611206 Training g_loss: 811872.2500 Training d_loss: 0.0005 Explore P: 0.0245\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 349 Total reward: 153.0 Average reward fake: 0.0 Average reward real: 0.9998204112052917 Training g_loss: 289930.1875 Training d_loss: 0.0002 Explore P: 0.0242\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 350 Total reward: 155.0 Average reward fake: 0.0 Average reward real: 0.9997929930686951 Training g_loss: 369494.7188 Training d_loss: 0.0002 Explore P: 0.0240\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 351 Total reward: 144.0 Average reward fake: 6.25194197720817e-24 Average reward real: 0.9985293745994568 Training g_loss: 511809.7812 Training d_loss: 0.0015 Explore P: 0.0238\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 352 Total reward: 145.0 Average reward fake: 0.0 Average reward real: 0.9996568560600281 Training g_loss: 702655.6250 Training d_loss: 0.0003 Explore P: 0.0236\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 353 Total reward: 140.0 Average reward fake: 0.0 Average reward real: 0.9998024106025696 Training g_loss: 1269195.5000 Training d_loss: 0.0002 Explore P: 0.0234\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 354 Total reward: 138.0 Average reward fake: 1.53879657807404e-35 Average reward real: 0.9994688630104065 Training g_loss: 497986.3438 Training d_loss: 0.0005 Explore P: 0.0232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 355 Total reward: 152.0 Average reward fake: 0.0 Average reward real: 0.9997552633285522 Training g_loss: 206131.1719 Training d_loss: 0.0002 Explore P: 0.0230\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 356 Total reward: 136.0 Average reward fake: 0.0 Average reward real: 0.999695360660553 Training g_loss: 627977.0625 Training d_loss: 0.0038 Explore P: 0.0229\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 357 Total reward: 161.0 Average reward fake: 0.0 Average reward real: 0.9998599290847778 Training g_loss: 157400.7656 Training d_loss: 0.0001 Explore P: 0.0227\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 358 Total reward: 199.0 Average reward fake: 7.542282673966838e-06 Average reward real: 0.9982234239578247 Training g_loss: 219047.1875 Training d_loss: 0.0018 Explore P: 0.0224\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 359 Total reward: 134.0 Average reward fake: 4.750460812242589e-24 Average reward real: 0.998683750629425 Training g_loss: 334938.2812 Training d_loss: 0.0119 Explore P: 0.0222\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 360 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9992308020591736 Training g_loss: 410389.0938 Training d_loss: 0.0008 Explore P: 0.0220\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 361 Total reward: 199.0 Average reward fake: 1.776645176829102e-20 Average reward real: 0.998791515827179 Training g_loss: 226701.5781 Training d_loss: 0.0012 Explore P: 0.0218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 362 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9997461438179016 Training g_loss: 492638.0000 Training d_loss: 0.0003 Explore P: 0.0215\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 363 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9997764825820923 Training g_loss: 111582.9297 Training d_loss: 0.0002 Explore P: 0.0213\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 364 Total reward: 199.0 Average reward fake: 8.746566191557222e-36 Average reward real: 0.9998484253883362 Training g_loss: 145638.7656 Training d_loss: 0.0002 Explore P: 0.0211\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 365 Total reward: 199.0 Average reward fake: 8.07109309941545e-11 Average reward real: 0.999793291091919 Training g_loss: 190385.4062 Training d_loss: 0.0002 Explore P: 0.0209\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 366 Total reward: 199.0 Average reward fake: 3.0867208095086696e-11 Average reward real: 0.9914237856864929 Training g_loss: 269047.6562 Training d_loss: 0.0098 Explore P: 0.0207\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 367 Total reward: 199.0 Average reward fake: 2.3138438387526605e-10 Average reward real: 0.9951484203338623 Training g_loss: 134917.1250 Training d_loss: 0.0068 Explore P: 0.0204\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 368 Total reward: 130.0 Average reward fake: 0.0 Average reward real: 0.9982867240905762 Training g_loss: 1459088.6250 Training d_loss: 0.0017 Explore P: 0.0203\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 369 Total reward: 199.0 Average reward fake: 0.049697838723659515 Average reward real: 0.9995476603507996 Training g_loss: 496725.3750 Training d_loss: 0.0005 Explore P: 0.0201\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 370 Total reward: 199.0 Average reward fake: 0.00012113131379010156 Average reward real: 0.9995918869972229 Training g_loss: 517495.6562 Training d_loss: 0.0004 Explore P: 0.0199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 371 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9990759491920471 Training g_loss: 363797.7500 Training d_loss: 0.0009 Explore P: 0.0197\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 372 Total reward: 46.0 Average reward fake: 3.001403203781067e-20 Average reward real: 0.9994789361953735 Training g_loss: 1414321.1250 Training d_loss: 0.0005 Explore P: 0.0197\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 373 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9987651109695435 Training g_loss: 632166.6875 Training d_loss: 0.0013 Explore P: 0.0195\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 374 Total reward: 64.0 Average reward fake: 8.986566288072053e-39 Average reward real: 0.9995718598365784 Training g_loss: 303407.0000 Training d_loss: 0.0004 Explore P: 0.0194\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 375 Total reward: 49.0 Average reward fake: 0.0 Average reward real: 0.9997335076332092 Training g_loss: 2456784.2500 Training d_loss: 0.0003 Explore P: 0.0194\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 376 Total reward: 41.0 Average reward fake: 0.004973918199539185 Average reward real: 0.9994635581970215 Training g_loss: 247000.5000 Training d_loss: 0.0005 Explore P: 0.0193\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 377 Total reward: 66.0 Average reward fake: 0.0 Average reward real: 0.9991979002952576 Training g_loss: 302367.8125 Training d_loss: 0.0008 Explore P: 0.0193\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 378 Total reward: 111.0 Average reward fake: 0.0 Average reward real: 0.9993308782577515 Training g_loss: 157447.2500 Training d_loss: 0.0007 Explore P: 0.0192\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 379 Total reward: 116.0 Average reward fake: 0.0 Average reward real: 0.9997256398200989 Training g_loss: 169382.0312 Training d_loss: 0.0003 Explore P: 0.0191\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 380 Total reward: 110.0 Average reward fake: 1.4644301049582253e-10 Average reward real: 0.9998685717582703 Training g_loss: 203613.6406 Training d_loss: 0.0001 Explore P: 0.0190\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 381 Total reward: 37.0 Average reward fake: 0.009730569086968899 Average reward real: 0.9997515678405762 Training g_loss: 878540.1875 Training d_loss: 0.0002 Explore P: 0.0189\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 382 Total reward: 55.0 Average reward fake: 0.0 Average reward real: 0.9998482465744019 Training g_loss: 153689.3594 Training d_loss: 0.0002 Explore P: 0.0189\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 383 Total reward: 91.0 Average reward fake: 0.027504688128829002 Average reward real: 0.9986364841461182 Training g_loss: 281256.8750 Training d_loss: 0.0014 Explore P: 0.0188\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 384 Total reward: 101.0 Average reward fake: 0.004995647817850113 Average reward real: 0.999744713306427 Training g_loss: 184137.2656 Training d_loss: 0.0003 Explore P: 0.0187\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 385 Total reward: 122.0 Average reward fake: 0.03049803338944912 Average reward real: 0.9992378354072571 Training g_loss: 347585.3125 Training d_loss: 0.0008 Explore P: 0.0186\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 386 Total reward: 102.0 Average reward fake: 0.0 Average reward real: 0.9997928142547607 Training g_loss: 74908.4922 Training d_loss: 0.0002 Explore P: 0.0185\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 387 Total reward: 93.0 Average reward fake: 0.009995883330702782 Average reward real: 0.9984670877456665 Training g_loss: 559948.4375 Training d_loss: 0.0016 Explore P: 0.0184\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 388 Total reward: 42.0 Average reward fake: 0.0 Average reward real: 0.9985049366950989 Training g_loss: 110196.1094 Training d_loss: 0.0016 Explore P: 0.0184\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 389 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.999284029006958 Training g_loss: 126916.1250 Training d_loss: 0.0007 Explore P: 0.0182\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 390 Total reward: 108.0 Average reward fake: 0.0 Average reward real: 0.9912147521972656 Training g_loss: 473081.2188 Training d_loss: 0.0127 Explore P: 0.0182\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 391 Total reward: 15.0 Average reward fake: 0.0 Average reward real: 0.9973556995391846 Training g_loss: 4057744.2500 Training d_loss: 0.0027 Explore P: 0.0181\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 392 Total reward: 11.0 Average reward fake: 0.0 Average reward real: 0.9981220364570618 Training g_loss: 1844674.0000 Training d_loss: 0.0019 Explore P: 0.0181\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 393 Total reward: 118.0 Average reward fake: 0.0 Average reward real: 0.9995100498199463 Training g_loss: 702862.3125 Training d_loss: 0.0005 Explore P: 0.0180\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 394 Total reward: 199.0 Average reward fake: 1.202590246987564e-16 Average reward real: 0.9993617534637451 Training g_loss: 4035382.2500 Training d_loss: 0.0006 Explore P: 0.0179\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 395 Total reward: 162.0 Average reward fake: 0.0 Average reward real: 0.9989423155784607 Training g_loss: 580956.1875 Training d_loss: 0.0011 Explore P: 0.0178\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 396 Total reward: 166.0 Average reward fake: 0.0 Average reward real: 0.999809741973877 Training g_loss: 1491114.0000 Training d_loss: 0.0002 Explore P: 0.0176\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 397 Total reward: 158.0 Average reward fake: 0.0 Average reward real: 0.9994680881500244 Training g_loss: 209397.8750 Training d_loss: 0.0042 Explore P: 0.0175\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 398 Total reward: 161.0 Average reward fake: 8.97691078113347e-37 Average reward real: 0.9993959665298462 Training g_loss: 283817.3438 Training d_loss: 0.0006 Explore P: 0.0174\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 399 Total reward: 182.0 Average reward fake: 0.0 Average reward real: 0.9991002082824707 Training g_loss: 79245.5469 Training d_loss: 0.0009 Explore P: 0.0173\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 400 Total reward: 199.0 Average reward fake: 0.0014521974371746182 Average reward real: 0.995220959186554 Training g_loss: 394026.9688 Training d_loss: 0.0056 Explore P: 0.0171\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 401 Total reward: 199.0 Average reward fake: 1.0709981927587648e-31 Average reward real: 0.9989731311798096 Training g_loss: 621771.5000 Training d_loss: 0.0010 Explore P: 0.0170\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 402 Total reward: 138.0 Average reward fake: 1.5176617282829642e-38 Average reward real: 0.9995259046554565 Training g_loss: 206795.7500 Training d_loss: 0.0005 Explore P: 0.0169\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 403 Total reward: 124.0 Average reward fake: 0.0 Average reward real: 0.9995153546333313 Training g_loss: 121544.5234 Training d_loss: 0.0005 Explore P: 0.0168\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 404 Total reward: 121.0 Average reward fake: 2.0187890404203337e-39 Average reward real: 0.9996891617774963 Training g_loss: 140726.0781 Training d_loss: 0.0248 Explore P: 0.0167\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 405 Total reward: 144.0 Average reward fake: 4.561694170772753e-29 Average reward real: 0.997834324836731 Training g_loss: 85462.9453 Training d_loss: 0.0105 Explore P: 0.0166\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 406 Total reward: 199.0 Average reward fake: 1.7534280694064819e-09 Average reward real: 0.9984623193740845 Training g_loss: 348065.1562 Training d_loss: 0.3093 Explore P: 0.0165\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 407 Total reward: 76.0 Average reward fake: 3.864512231618085e-25 Average reward real: 0.9987123608589172 Training g_loss: 140193.0312 Training d_loss: 0.0013 Explore P: 0.0164\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 408 Total reward: 14.0 Average reward fake: 0.0 Average reward real: 0.9988647699356079 Training g_loss: 149233.5000 Training d_loss: 0.0011 Explore P: 0.0164\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 409 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9992656707763672 Training g_loss: 138011.1094 Training d_loss: 0.0007 Explore P: 0.0163\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 410 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9994509816169739 Training g_loss: 78087.4844 Training d_loss: 0.0006 Explore P: 0.0162\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 411 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9994804263114929 Training g_loss: 574535.1250 Training d_loss: 0.0005 Explore P: 0.0161\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 412 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9992239475250244 Training g_loss: 68345.3906 Training d_loss: 0.0008 Explore P: 0.0159\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 413 Total reward: 199.0 Average reward fake: 1.3395264541871046e-27 Average reward real: 0.9945109486579895 Training g_loss: 251130.2031 Training d_loss: 0.0070 Explore P: 0.0158\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 414 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.998569130897522 Training g_loss: 274718.0312 Training d_loss: 0.0015 Explore P: 0.0157\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 415 Total reward: 199.0 Average reward fake: 2.650214303654558e-13 Average reward real: 0.997151255607605 Training g_loss: 164771.9688 Training d_loss: 0.0029 Explore P: 0.0156\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 416 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9991334676742554 Training g_loss: 86611.3750 Training d_loss: 0.0009 Explore P: 0.0155\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 417 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9991947412490845 Training g_loss: 93218.7891 Training d_loss: 0.0008 Explore P: 0.0154\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 418 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9984330534934998 Training g_loss: 483220.7812 Training d_loss: 0.0016 Explore P: 0.0153\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 419 Total reward: 199.0 Average reward fake: 2.9834922387130013e-16 Average reward real: 0.9990790486335754 Training g_loss: 290679.5000 Training d_loss: 0.0009 Explore P: 0.0152\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 420 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9989495873451233 Training g_loss: 80561.4844 Training d_loss: 0.0011 Explore P: 0.0151\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 421 Total reward: 199.0 Average reward fake: 7.134461056044707e-21 Average reward real: 0.9976553916931152 Training g_loss: 385474.0000 Training d_loss: 0.0024 Explore P: 0.0150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 422 Total reward: 163.0 Average reward fake: 1.1886894383426365e-22 Average reward real: 0.9995220899581909 Training g_loss: 365214.2812 Training d_loss: 0.0005 Explore P: 0.0149\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 423 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9993305802345276 Training g_loss: 76671.1016 Training d_loss: 0.0007 Explore P: 0.0148\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 424 Total reward: 199.0 Average reward fake: 3.5070732984365804e-09 Average reward real: 0.999418318271637 Training g_loss: 168591.5625 Training d_loss: 0.0006 Explore P: 0.0147\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 425 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.998778223991394 Training g_loss: 482604.1562 Training d_loss: 0.0012 Explore P: 0.0146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 426 Total reward: 127.0 Average reward fake: 0.0 Average reward real: 0.9996721148490906 Training g_loss: 719940.5000 Training d_loss: 0.0003 Explore P: 0.0145\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 427 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9944368004798889 Training g_loss: 78394.6875 Training d_loss: 0.0137 Explore P: 0.0144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 428 Total reward: 128.0 Average reward fake: 1.409128953456414e-18 Average reward real: 0.9983588457107544 Training g_loss: 134756.2500 Training d_loss: 0.0017 Explore P: 0.0144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 429 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.999570906162262 Training g_loss: 161712.9062 Training d_loss: 0.0004 Explore P: 0.0143\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 430 Total reward: 122.0 Average reward fake: 3.2574377411026356e-28 Average reward real: 0.9996433258056641 Training g_loss: 63965.2500 Training d_loss: 0.0004 Explore P: 0.0143\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 431 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.998771607875824 Training g_loss: 97435.9766 Training d_loss: 0.0012 Explore P: 0.0142\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 432 Total reward: 152.0 Average reward fake: 8.66904951376863e-34 Average reward real: 0.9982335567474365 Training g_loss: 75998.5312 Training d_loss: 0.0018 Explore P: 0.0141\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 433 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9994299411773682 Training g_loss: 7471832.5000 Training d_loss: 0.0006 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 434 Total reward: 8.0 Average reward fake: 0.0 Average reward real: 0.9996397495269775 Training g_loss: 16276955.0000 Training d_loss: 0.0004 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 435 Total reward: 8.0 Average reward fake: 0.0 Average reward real: 0.9995732307434082 Training g_loss: 61902484.0000 Training d_loss: 0.0004 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 436 Total reward: 176.0 Average reward fake: 0.0 Average reward real: 0.9997727274894714 Training g_loss: 5949086.0000 Training d_loss: 0.0002 Explore P: 0.0139\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 437 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9992872476577759 Training g_loss: 1833635.0000 Training d_loss: 0.0335 Explore P: 0.0139\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 438 Total reward: 189.0 Average reward fake: 0.0 Average reward real: 0.9985272288322449 Training g_loss: 317476.9688 Training d_loss: 0.0015 Explore P: 0.0138\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 439 Total reward: 182.0 Average reward fake: 4.120189076792652e-26 Average reward real: 0.9990596175193787 Training g_loss: 254315.5469 Training d_loss: 0.0009 Explore P: 0.0137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 440 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9981866478919983 Training g_loss: 116222.4766 Training d_loss: 0.0019 Explore P: 0.0137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 441 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9976017475128174 Training g_loss: 117676.3984 Training d_loss: 0.0024 Explore P: 0.0136\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 442 Total reward: 199.0 Average reward fake: 1.3254880699975491e-11 Average reward real: 0.9966192841529846 Training g_loss: 145415.1875 Training d_loss: 0.0034 Explore P: 0.0135\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 443 Total reward: 113.0 Average reward fake: 0.0 Average reward real: 0.9972506761550903 Training g_loss: 349276.5938 Training d_loss: 0.0028 Explore P: 0.0135\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 444 Total reward: 91.0 Average reward fake: 0.0 Average reward real: 0.998464822769165 Training g_loss: 601018.6250 Training d_loss: 0.0015 Explore P: 0.0134\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 445 Total reward: 107.0 Average reward fake: 0.0 Average reward real: 0.9993915557861328 Training g_loss: 295463.3750 Training d_loss: 0.0006 Explore P: 0.0134\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 446 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9989999532699585 Training g_loss: 71772.0781 Training d_loss: 0.0010 Explore P: 0.0133\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 447 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.999366044998169 Training g_loss: 148671.5625 Training d_loss: 0.0006 Explore P: 0.0133\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 448 Total reward: 98.0 Average reward fake: 0.0 Average reward real: 0.9995647668838501 Training g_loss: 8889044.0000 Training d_loss: 0.0004 Explore P: 0.0132\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 449 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9995891451835632 Training g_loss: 247324.9375 Training d_loss: 0.0004 Explore P: 0.0132\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 450 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9987281560897827 Training g_loss: 222231.5312 Training d_loss: 0.0013 Explore P: 0.0131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 451 Total reward: 199.0 Average reward fake: 0.01880924217402935 Average reward real: 0.9988689422607422 Training g_loss: 93393.8125 Training d_loss: 0.0011 Explore P: 0.0131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 452 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9982931017875671 Training g_loss: 348335.9688 Training d_loss: 0.0018 Explore P: 0.0130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 453 Total reward: 114.0 Average reward fake: 0.0 Average reward real: 0.9995903968811035 Training g_loss: 359202.7188 Training d_loss: 0.0004 Explore P: 0.0130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 454 Total reward: 199.0 Average reward fake: 3.2071707453396016e-35 Average reward real: 0.9935969710350037 Training g_loss: 457332.8125 Training d_loss: 0.0073 Explore P: 0.0129\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 455 Total reward: 159.0 Average reward fake: 1.8178582012091937e-13 Average reward real: 0.9979400038719177 Training g_loss: 684578.5000 Training d_loss: 0.0403 Explore P: 0.0129\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 456 Total reward: 183.0 Average reward fake: 6.477481300020318e-37 Average reward real: 0.9938008189201355 Training g_loss: 120859.2578 Training d_loss: 0.0067 Explore P: 0.0128\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 457 Total reward: 199.0 Average reward fake: 2.09631447666064e-37 Average reward real: 0.9932266473770142 Training g_loss: 3784393.0000 Training d_loss: 0.0073 Explore P: 0.0127\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 458 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9991033673286438 Training g_loss: 167460.2969 Training d_loss: 0.0009 Explore P: 0.0127\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 459 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.985664963722229 Training g_loss: 46362.0234 Training d_loss: 0.0156 Explore P: 0.0126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 460 Total reward: 108.0 Average reward fake: 2.9978929061424964e-11 Average reward real: 0.9979780316352844 Training g_loss: 53136.7383 Training d_loss: 0.0020 Explore P: 0.0126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 461 Total reward: 199.0 Average reward fake: 3.3214380658849214e-36 Average reward real: 0.9984841346740723 Training g_loss: 49665.6367 Training d_loss: 0.0015 Explore P: 0.0126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 462 Total reward: 105.0 Average reward fake: 0.0 Average reward real: 0.9991135597229004 Training g_loss: 306833.0000 Training d_loss: 0.2752 Explore P: 0.0125\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 463 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9989315867424011 Training g_loss: 51006.6250 Training d_loss: 0.0011 Explore P: 0.0125\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 464 Total reward: 103.0 Average reward fake: 0.0 Average reward real: 0.9988758563995361 Training g_loss: 447783.1875 Training d_loss: 0.0011 Explore P: 0.0125\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 465 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9978030323982239 Training g_loss: 60511.8594 Training d_loss: 0.0022 Explore P: 0.0124\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 466 Total reward: 101.0 Average reward fake: 0.0 Average reward real: 0.9902106523513794 Training g_loss: 42059.4648 Training d_loss: 0.0114 Explore P: 0.0124\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 467 Total reward: 116.0 Average reward fake: 0.0 Average reward real: 0.9992722868919373 Training g_loss: 29667.2969 Training d_loss: 0.0007 Explore P: 0.0124\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 468 Total reward: 104.0 Average reward fake: 1.799665375380101e-29 Average reward real: 0.9997192621231079 Training g_loss: 72456.7344 Training d_loss: 0.0003 Explore P: 0.0123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 469 Total reward: 99.0 Average reward fake: 0.00466429628431797 Average reward real: 0.9983218908309937 Training g_loss: 131248.1875 Training d_loss: 0.0017 Explore P: 0.0123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 470 Total reward: 111.0 Average reward fake: 0.0037028726655989885 Average reward real: 0.9907721877098083 Training g_loss: 121128.9062 Training d_loss: 0.0233 Explore P: 0.0123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 471 Total reward: 133.0 Average reward fake: 0.0 Average reward real: 0.9982600212097168 Training g_loss: 112975.4609 Training d_loss: 0.0018 Explore P: 0.0123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 472 Total reward: 98.0 Average reward fake: 0.0 Average reward real: 0.998495876789093 Training g_loss: 355739.2812 Training d_loss: 0.0015 Explore P: 0.0122\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 473 Total reward: 107.0 Average reward fake: 0.0 Average reward real: 0.9992015361785889 Training g_loss: 124256.0938 Training d_loss: 0.0008 Explore P: 0.0122\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 474 Total reward: 105.0 Average reward fake: 1.4514747104564364e-32 Average reward real: 0.9973666667938232 Training g_loss: 40904.4844 Training d_loss: 0.0027 Explore P: 0.0122\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 475 Total reward: 141.0 Average reward fake: 6.007333445916733e-38 Average reward real: 0.9985124468803406 Training g_loss: 282474.7500 Training d_loss: 0.0015 Explore P: 0.0122\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 476 Total reward: 96.0 Average reward fake: 0.0 Average reward real: 0.9993559122085571 Training g_loss: 504765.4688 Training d_loss: 0.0006 Explore P: 0.0121\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 477 Total reward: 199.0 Average reward fake: 3.593580766292348e-09 Average reward real: 0.9886114597320557 Training g_loss: 174317.9219 Training d_loss: 0.0715 Explore P: 0.0121\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 478 Total reward: 140.0 Average reward fake: 0.0 Average reward real: 0.993751049041748 Training g_loss: 82962.2266 Training d_loss: 0.0076 Explore P: 0.0121\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 479 Total reward: 114.0 Average reward fake: 0.0 Average reward real: 0.999134361743927 Training g_loss: 114605.2266 Training d_loss: 0.0009 Explore P: 0.0120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 480 Total reward: 112.0 Average reward fake: 0.0 Average reward real: 0.9993213415145874 Training g_loss: 131753.2969 Training d_loss: 0.0007 Explore P: 0.0120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 481 Total reward: 105.0 Average reward fake: 0.0 Average reward real: 0.9988113641738892 Training g_loss: 106918.9609 Training d_loss: 0.0012 Explore P: 0.0120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 482 Total reward: 100.0 Average reward fake: 0.0 Average reward real: 0.9980673789978027 Training g_loss: 54265.9883 Training d_loss: 0.0860 Explore P: 0.0120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 483 Total reward: 109.0 Average reward fake: 0.0 Average reward real: 0.9971328973770142 Training g_loss: 705776.8125 Training d_loss: 0.0031 Explore P: 0.0120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 484 Total reward: 117.0 Average reward fake: 0.0032579272519797087 Average reward real: 0.9971060156822205 Training g_loss: 70596.2031 Training d_loss: 0.0029 Explore P: 0.0119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 485 Total reward: 98.0 Average reward fake: 0.0 Average reward real: 0.9991675615310669 Training g_loss: 50183.8125 Training d_loss: 0.0008 Explore P: 0.0119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 486 Total reward: 118.0 Average reward fake: 1.9783046728560905e-13 Average reward real: 0.9987832903862 Training g_loss: 69583.3516 Training d_loss: 0.0012 Explore P: 0.0119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 487 Total reward: 124.0 Average reward fake: 0.0 Average reward real: 0.9991841316223145 Training g_loss: 36631.1367 Training d_loss: 0.0008 Explore P: 0.0119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 488 Total reward: 120.0 Average reward fake: 0.0 Average reward real: 0.9979846477508545 Training g_loss: 40580.8125 Training d_loss: 0.0020 Explore P: 0.0118\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 489 Total reward: 114.0 Average reward fake: 2.8519507310209146e-20 Average reward real: 0.9987863302230835 Training g_loss: 140855.2656 Training d_loss: 0.0012 Explore P: 0.0118\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 490 Total reward: 199.0 Average reward fake: 3.671553078926637e-14 Average reward real: 0.9975640773773193 Training g_loss: 135060.2812 Training d_loss: 0.0025 Explore P: 0.0118\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 491 Total reward: 145.0 Average reward fake: 0.0008251448743976653 Average reward real: 0.9978492259979248 Training g_loss: 40457.7188 Training d_loss: 0.0535 Explore P: 0.0118\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 492 Total reward: 105.0 Average reward fake: 1.734946509396228e-21 Average reward real: 0.9901478290557861 Training g_loss: 306006.9375 Training d_loss: 0.0128 Explore P: 0.0117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 493 Total reward: 199.0 Average reward fake: 0.0 Average reward real: 0.9985133409500122 Training g_loss: 435019.7188 Training d_loss: 0.0015 Explore P: 0.0117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 494 Total reward: 119.0 Average reward fake: 0.0 Average reward real: 0.9977642297744751 Training g_loss: 70875.5391 Training d_loss: 0.0023 Explore P: 0.0117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 495 Total reward: 122.0 Average reward fake: 0.0 Average reward real: 0.9993293881416321 Training g_loss: 127877.2578 Training d_loss: 0.0007 Explore P: 0.0117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 496 Total reward: 188.0 Average reward fake: 1.0056441901440394e-08 Average reward real: 0.9988048076629639 Training g_loss: 72180.6641 Training d_loss: 0.0012 Explore P: 0.0116\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 497 Total reward: 180.0 Average reward fake: 0.0 Average reward real: 0.9983378052711487 Training g_loss: 73270.1328 Training d_loss: 0.0017 Explore P: 0.0116\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 498 Total reward: 71.0 Average reward fake: 0.0 Average reward real: 0.9992666840553284 Training g_loss: 80009.9453 Training d_loss: 0.0007 Explore P: 0.0116\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 499 Total reward: 69.0 Average reward fake: 0.06186161935329437 Average reward real: 0.9989184737205505 Training g_loss: 140391.6250 Training d_loss: 0.0011 Explore P: 0.0116\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards and losses list for plotting\n",
    "rewards_list = []\n",
    "g_loss_list, d_loss_list = [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #     # Restore/load the trained model \n",
    "    #     #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #     saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        \n",
    "        # Env/agent steps/batches/minibatches\n",
    "        total_reward = 0\n",
    "        g_loss, d_loss = 0, 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from model\n",
    "                feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "                actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "                action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Episode/epoch training is done/failed!\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training g_loss: {:.4f}'.format(g_loss),\n",
    "                      'Training d_loss: {:.4f}'.format(d_loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                \n",
    "                # total rewards and losses for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                g_loss_list.append((ep, g_loss))\n",
    "                d_loss_list.append((ep, d_loss))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Next action logits using next states for calculating maxQ\n",
    "            #feed_dict={model.states: next_states}\n",
    "            #next_actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            feed_dict = {model.states: states, \n",
    "                         model.actions: actions,\n",
    "                         model.next_states: next_states} \n",
    "            nextQs_logits_fake, nextQs_logits_real = sess.run([model.nextQs_logits_fake, model.nextQs_logits_real], \n",
    "                                                              feed_dict)\n",
    "\n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == tf.zeros(states[0].shape)).all(axis=1)\n",
    "            #next_actions_logits[episode_ends] = (0, 0) # NOTE: action size\n",
    "            nextQs_logits_fake[episode_ends] = 0 # NOTE: size is always one\n",
    "            nextQs_logits_real[episode_ends] = 0 # NOTE: size is always one\n",
    "\n",
    "            # Bellman equation: Qt = Rt + max(Qt+1)\n",
    "            #targetQs = rewards + (gamma * np.max(next_actions_logits, axis=1))\n",
    "            targetQs_fake = rewards + (gamma * nextQs_logits_fake)\n",
    "            targetQs_real = rewards + (gamma * nextQs_logits_real)\n",
    "            #targetQs = rewards_fake.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "            #targetQs = rewards_real.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "            #targetQs = np.ones_like(rewards) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "\n",
    "            # Updating the model\n",
    "            feed_dict = {model.states: states, \n",
    "                         model.actions: actions,\n",
    "                         model.next_states: next_states, \n",
    "                         model.targetQs_fake: targetQs_fake,\n",
    "                         model.targetQs_real: targetQs_real}\n",
    "            g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict)\n",
    "            d_loss, _ = sess.run([model.d_loss, model.d_opt], feed_dict)\n",
    "            \n",
    "    # Save the trained model\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'G losses')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'D losses')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 1\n",
    "test_max_steps = 20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
    "\n",
    "# # # Create the env after closing it.\n",
    "# env = gym.make('CartPole-v0')\n",
    "# # env = gym.make('Acrobot-v1')\n",
    "env.reset()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore/load the trained model \n",
    "    #saver.restore(sess, 'checkpoints/QGAN-cartpole.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # iterations\n",
    "    for ep in range(test_episodes):\n",
    "        \n",
    "        # number of env/rob steps\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            \n",
    "            # Rendering the env graphics\n",
    "            env.render()\n",
    "            \n",
    "            # Get action from DQAN\n",
    "            feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "            actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # The task is done or not;\n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the env\n",
    "# WARNING: If you close, you can NOT restart again!!!!!!\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this to Deep Convolutional QAN\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

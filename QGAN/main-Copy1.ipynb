{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# QGAN: (Q-Net) + GAN (G-Net and D-Net)\n",
    "\n",
    "More specifically, we'll use Q-GAN to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command 'pip install -e gym/[all]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Create the Cart-Pole game environment\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Pendulum-v0')\n",
    "# env = gym.make('Blackjack-v0')\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# env = gym.make('AirRaid-ram-v0')\n",
    "# env = gym.make('AirRaid-v0')\n",
    "# env = gym.make('BipedalWalker-v2')\n",
    "# env = gym.make('Copy-v0')\n",
    "# env = gym.make('CarRacing-v0')\n",
    "# env = gym.make('Ant-v2') #mujoco\n",
    "# env = gym.make('FetchPickAndPlace-v1') # mujoco required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "rewards, states, actions, dones = [], [], [], []\n",
    "for _ in range(10):\n",
    "    #env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    states.append(state)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    dones.append(done)\n",
    "    #     print('state, action, reward, done, info')\n",
    "    #     print(state, action, reward, done, info)\n",
    "    if done:\n",
    "    #         print('state, action, reward, done, info')\n",
    "    #         print(state, action, reward, done, info)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        dones.append(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(10,) (10, 4) (10,) (10,)\n",
      "float64 float64 int64 bool\n",
      "actions: 1 0\n",
      "rewards min and max: 1.0 1.0\n",
      "state size: (10, 4) action size: 2\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print('actions:', np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print('rewards min and max:', np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print('state size:', np.array(states).shape, \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    # Current states given\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    \n",
    "    # Next states given\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    \n",
    "    # Current actions given\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # TargetQs/values\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    \n",
    "    # returning the given data to the model\n",
    "    return states, next_states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Qfunction/Encoder/Classifier\n",
    "def qfunction(states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('qfunction', reuse=reuse):        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits: Sqeezed/compressed/represented states into actions size\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: Generator/Decoder: actions can be given actions, generated actions\n",
    "def generator(states, actions, state_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # Fuse compressed states (actions fake) with actions (actions real)\n",
    "        x_fused = tf.concat(axis=1, values=[states, actions]) # NxD: axis1=N, and axis2=D\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=x_fused, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=state_size)        \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return next_states_logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D: Descriminator/Reward function\n",
    "def discriminator(states, actions, next_states, action_size, hidden_size, reuse=False, alpha=0.1, training=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=next_states, units=hidden_size)\n",
    "        bn1 = tf.layers.batch_normalization(h1, training=training)        \n",
    "        nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=action_size)\n",
    "        bn2 = tf.layers.batch_normalization(h2, training=training)        \n",
    "        nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "        # Fused compressed states, actions, and compressed next_states (all three in action size)\n",
    "        #h3 = tf.layers.dense(inputs=nl2, units=action_size)\n",
    "        h3_fused = tf.concat(axis=1, values=[states, actions, nl2])\n",
    "        bn3 = tf.layers.batch_normalization(h3_fused, training=training)        \n",
    "        nl3 = tf.maximum(alpha * bn3, bn3)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl3, units=1)   \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return reward logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, actions, next_states, targetQs, # model_input\n",
    "               state_size, action_size, hidden_size): # model_init\n",
    "    # DQN: Q-learning - Bellman equations: loss (targetQ - Q)^2\n",
    "    actions_logits = qfunction(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_real = tf.one_hot(indices=actions, depth=action_size)\n",
    "    Qs = tf.reduce_sum(tf.multiply(actions_logits, actions_real), axis=1)\n",
    "    q_loss = tf.reduce_mean(tf.square(targetQs - Qs))\n",
    "\n",
    "    # GAN: Generate next states\n",
    "    actions_fake = tf.nn.softmax(actions_logits)\n",
    "    next_states_logits = generator(states=actions_fake, actions=actions_real, \n",
    "                                   state_size=state_size, hidden_size=hidden_size)\n",
    "    \n",
    "    # GAN: Discriminate between fake and real\n",
    "    next_states_fake = tf.sigmoid(x=next_states_logits)\n",
    "    d_logits_fake = discriminator(states=actions_fake, actions=actions_real, action_size=action_size,\n",
    "                                  next_states=next_states_fake, hidden_size=hidden_size, reuse=False)\n",
    "    next_states_real = tf.sigmoid(x=next_states) \n",
    "    d_logits_real = discriminator(states=actions_fake, actions=actions_real, action_size=action_size,\n",
    "                                  next_states=next_states_real, hidden_size=hidden_size, reuse=True)    \n",
    "\n",
    "    # GAN: Adverserial training - G-learning -  Relavistic GAN\n",
    "    g_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "    g_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.zeros_like(d_logits_real)))\n",
    "    g_loss = g_loss_real + g_loss_fake\n",
    "    \n",
    "    # VAE: Variational AE reconstruction/prediction loss\n",
    "    loss_reconst = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=next_states_logits, labels=next_states_real))\n",
    "    q_loss += g_loss + loss_reconst \n",
    "    g_loss += loss_reconst\n",
    "    \n",
    "    # GAN: Adverserial training - D-learning-  Standard GAN\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # Rewards fake/real\n",
    "    rewards_fake = tf.sigmoid(d_logits_fake)\n",
    "    rewards_real = tf.sigmoid(d_logits_real)\n",
    "\n",
    "    return actions_logits, q_loss, g_loss, d_loss, rewards_fake, rewards_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(q_loss, g_loss, d_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param q_loss: Qfunction/Value loss Tensor for next action prediction\n",
    "    :param g_loss: Generator/Decoder loss Tensor for next state prediction\n",
    "    :param d_loss: Discriminator/Reward loss Tensor for current reward function\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    q_vars = [var for var in t_vars if var.name.startswith('qfunction')] # Q: action At/at\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')] # G: next state St/st\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        q_opt = tf.train.AdamOptimizer(learning_rate).minimize(q_loss, var_list=q_vars)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return q_opt, g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGAN:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.next_states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.q_loss, self.g_loss, self.d_loss, self.rewards_fake, self.rewards_real = model_loss(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, # model init parameters\n",
    "            states=self.states, next_states=self.next_states, actions=self.actions, targetQs=self.targetQs) # model input data\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.q_opt, self.g_opt, self.d_opt = model_opt(q_loss=self.q_loss, g_loss=self.g_loss, d_loss=self.d_loss, \n",
    "                                                       learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size: 4 action size: 2\n"
     ]
    }
   ],
   "source": [
    "print('state size:', np.array(states).shape[1], \n",
    "      'action size: {}'.format((np.max(np.array(actions)) - np.min(np.array(actions)))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 2000000000000000   # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "state_size = 4                 # number of units for the input state/observation -- simulation\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer -- simulation\n",
    "action_size = 2                # number of units for the output actions -- simulation\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000           # memory capacity\n",
    "batch_size = 200               # experience mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = QGAN(state_size=state_size, action_size=action_size, hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 0 Total reward: 33.0 Average reward fake: 0.19600506126880646 Average reward real: 0.1960034817457199 Training q_loss: 2.6797 Training g_loss: 2.5373 Training d_loss: 1.8479 Explore P: 0.9967\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 1 Total reward: 41.0 Average reward fake: 0.24042381346225739 Average reward real: 0.24041762948036194 Training q_loss: 4.5685 Training g_loss: 2.3783 Training d_loss: 1.7004 Explore P: 0.9927\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 2 Total reward: 14.0 Average reward fake: 0.25487691164016724 Average reward real: 0.25488054752349854 Training q_loss: 6.5446 Training g_loss: 2.3374 Training d_loss: 1.6611 Explore P: 0.9913\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 3 Total reward: 27.0 Average reward fake: 0.2840881645679474 Average reward real: 0.28413480520248413 Training q_loss: 9.3247 Training g_loss: 2.2767 Training d_loss: 1.5926 Explore P: 0.9887\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 4 Total reward: 22.0 Average reward fake: 0.3076390027999878 Average reward real: 0.3076241612434387 Training q_loss: 4.7606 Training g_loss: 2.2276 Training d_loss: 1.5465 Explore P: 0.9865\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 5 Total reward: 26.0 Average reward fake: 0.3352756202220917 Average reward real: 0.3351287543773651 Training q_loss: 5.2320 Training g_loss: 2.1802 Training d_loss: 1.5017 Explore P: 0.9840\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 6 Total reward: 13.0 Average reward fake: 0.34919998049736023 Average reward real: 0.3489571511745453 Training q_loss: 6.9617 Training g_loss: 2.1596 Training d_loss: 1.4824 Explore P: 0.9827\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 7 Total reward: 13.0 Average reward fake: 0.36367806792259216 Average reward real: 0.3631771206855774 Training q_loss: 7.5959 Training g_loss: 2.1462 Training d_loss: 1.4649 Explore P: 0.9815\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 8 Total reward: 28.0 Average reward fake: 0.394459992647171 Average reward real: 0.39346274733543396 Training q_loss: 6.5974 Training g_loss: 2.1130 Training d_loss: 1.4350 Explore P: 0.9787\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 9 Total reward: 45.0 Average reward fake: 0.44512131810188293 Average reward real: 0.4417616128921509 Training q_loss: 10.9911 Training g_loss: 2.0823 Training d_loss: 1.4060 Explore P: 0.9744\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 10 Total reward: 30.0 Average reward fake: 0.4735363721847534 Average reward real: 0.4697447121143341 Training q_loss: 13.5838 Training g_loss: 2.0700 Training d_loss: 1.3977 Explore P: 0.9715\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 11 Total reward: 23.0 Average reward fake: 0.48642870783805847 Average reward real: 0.48078155517578125 Training q_loss: 2.5871 Training g_loss: 2.0713 Training d_loss: 1.3987 Explore P: 0.9693\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 12 Total reward: 16.0 Average reward fake: 0.4889974296092987 Average reward real: 0.484275221824646 Training q_loss: 8.4431 Training g_loss: 2.0678 Training d_loss: 1.3973 Explore P: 0.9678\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 13 Total reward: 47.0 Average reward fake: 0.49063530564308167 Average reward real: 0.4868054986000061 Training q_loss: 3.4191 Training g_loss: 2.0716 Training d_loss: 1.3946 Explore P: 0.9633\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 14 Total reward: 19.0 Average reward fake: 0.4907713830471039 Average reward real: 0.4882092773914337 Training q_loss: 8.8934 Training g_loss: 2.0820 Training d_loss: 1.3908 Explore P: 0.9615\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 15 Total reward: 12.0 Average reward fake: 0.4924851357936859 Average reward real: 0.48842671513557434 Training q_loss: 6.2844 Training g_loss: 2.0728 Training d_loss: 1.3947 Explore P: 0.9603\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 16 Total reward: 15.0 Average reward fake: 0.4938274323940277 Average reward real: 0.4897274672985077 Training q_loss: 15.8140 Training g_loss: 2.0744 Training d_loss: 1.3946 Explore P: 0.9589\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 17 Total reward: 16.0 Average reward fake: 0.4940636157989502 Average reward real: 0.4898220896720886 Training q_loss: 3.2570 Training g_loss: 2.0731 Training d_loss: 1.3950 Explore P: 0.9574\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 18 Total reward: 21.0 Average reward fake: 0.4932197630405426 Average reward real: 0.4900200366973877 Training q_loss: 5.6823 Training g_loss: 2.0741 Training d_loss: 1.3930 Explore P: 0.9554\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 19 Total reward: 19.0 Average reward fake: 0.49408936500549316 Average reward real: 0.49090680480003357 Training q_loss: 6.3894 Training g_loss: 2.0761 Training d_loss: 1.3932 Explore P: 0.9536\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 20 Total reward: 39.0 Average reward fake: 0.49399352073669434 Average reward real: 0.49157726764678955 Training q_loss: 7.3672 Training g_loss: 2.0749 Training d_loss: 1.3914 Explore P: 0.9499\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 21 Total reward: 11.0 Average reward fake: 0.49395951628685 Average reward real: 0.4920523762702942 Training q_loss: 16.3409 Training g_loss: 2.0756 Training d_loss: 1.3904 Explore P: 0.9489\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 22 Total reward: 10.0 Average reward fake: 0.49436190724372864 Average reward real: 0.4915718138217926 Training q_loss: 9.5808 Training g_loss: 2.0729 Training d_loss: 1.3922 Explore P: 0.9480\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 23 Total reward: 22.0 Average reward fake: 0.4949415624141693 Average reward real: 0.49277472496032715 Training q_loss: 9.4793 Training g_loss: 2.0744 Training d_loss: 1.3908 Explore P: 0.9459\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 24 Total reward: 14.0 Average reward fake: 0.4950315058231354 Average reward real: 0.49310654401779175 Training q_loss: 7.3082 Training g_loss: 2.0752 Training d_loss: 1.3903 Explore P: 0.9446\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 25 Total reward: 16.0 Average reward fake: 0.49539700150489807 Average reward real: 0.4934948682785034 Training q_loss: 7.3157 Training g_loss: 2.0744 Training d_loss: 1.3902 Explore P: 0.9431\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 26 Total reward: 18.0 Average reward fake: 0.4956896901130676 Average reward real: 0.49392417073249817 Training q_loss: 8.2933 Training g_loss: 2.0718 Training d_loss: 1.3900 Explore P: 0.9414\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 27 Total reward: 18.0 Average reward fake: 0.4956466555595398 Average reward real: 0.4939665198326111 Training q_loss: 4.2470 Training g_loss: 2.0731 Training d_loss: 1.3897 Explore P: 0.9397\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 28 Total reward: 20.0 Average reward fake: 0.49574506282806396 Average reward real: 0.4942895472049713 Training q_loss: 8.7132 Training g_loss: 2.0714 Training d_loss: 1.3892 Explore P: 0.9379\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 29 Total reward: 16.0 Average reward fake: 0.4960569143295288 Average reward real: 0.4943714439868927 Training q_loss: 8.7140 Training g_loss: 2.0715 Training d_loss: 1.3897 Explore P: 0.9364\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 30 Total reward: 16.0 Average reward fake: 0.4964415729045868 Average reward real: 0.494974821805954 Training q_loss: 3.1066 Training g_loss: 2.0741 Training d_loss: 1.3893 Explore P: 0.9349\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 31 Total reward: 21.0 Average reward fake: 0.49633026123046875 Average reward real: 0.49526557326316833 Training q_loss: 4.0705 Training g_loss: 2.0705 Training d_loss: 1.3886 Explore P: 0.9330\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 32 Total reward: 17.0 Average reward fake: 0.49644336104393005 Average reward real: 0.49559229612350464 Training q_loss: 8.0338 Training g_loss: 2.0779 Training d_loss: 1.3879 Explore P: 0.9314\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 33 Total reward: 17.0 Average reward fake: 0.49705561995506287 Average reward real: 0.49608710408210754 Training q_loss: 8.2243 Training g_loss: 2.0740 Training d_loss: 1.3881 Explore P: 0.9298\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 34 Total reward: 18.0 Average reward fake: 0.49701789021492004 Average reward real: 0.49615341424942017 Training q_loss: 6.1003 Training g_loss: 2.0766 Training d_loss: 1.3880 Explore P: 0.9282\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 35 Total reward: 15.0 Average reward fake: 0.497030109167099 Average reward real: 0.4964621663093567 Training q_loss: 5.1660 Training g_loss: 2.0755 Training d_loss: 1.3875 Explore P: 0.9268\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 36 Total reward: 34.0 Average reward fake: 0.4975719451904297 Average reward real: 0.49670931696891785 Training q_loss: 3.4359 Training g_loss: 2.0799 Training d_loss: 1.3879 Explore P: 0.9237\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 37 Total reward: 22.0 Average reward fake: 0.49752968549728394 Average reward real: 0.49707698822021484 Training q_loss: 3.1785 Training g_loss: 2.0728 Training d_loss: 1.3873 Explore P: 0.9217\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 38 Total reward: 23.0 Average reward fake: 0.4978182315826416 Average reward real: 0.49735862016677856 Training q_loss: 4.2631 Training g_loss: 2.0720 Training d_loss: 1.3872 Explore P: 0.9196\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 39 Total reward: 17.0 Average reward fake: 0.49765339493751526 Average reward real: 0.49735748767852783 Training q_loss: 5.2735 Training g_loss: 2.0753 Training d_loss: 1.3869 Explore P: 0.9181\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 40 Total reward: 17.0 Average reward fake: 0.49774226546287537 Average reward real: 0.49769484996795654 Training q_loss: 4.6492 Training g_loss: 2.0742 Training d_loss: 1.3864 Explore P: 0.9165\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 41 Total reward: 16.0 Average reward fake: 0.49848517775535583 Average reward real: 0.4981187582015991 Training q_loss: 3.7322 Training g_loss: 2.0765 Training d_loss: 1.3870 Explore P: 0.9151\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 42 Total reward: 20.0 Average reward fake: 0.4985503852367401 Average reward real: 0.49857980012893677 Training q_loss: 3.8423 Training g_loss: 2.0770 Training d_loss: 1.3863 Explore P: 0.9133\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 43 Total reward: 13.0 Average reward fake: 0.4988298714160919 Average reward real: 0.4985438585281372 Training q_loss: 3.4110 Training g_loss: 2.0707 Training d_loss: 1.3869 Explore P: 0.9121\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 44 Total reward: 26.0 Average reward fake: 0.49818989634513855 Average reward real: 0.4981478750705719 Training q_loss: 4.4008 Training g_loss: 2.0749 Training d_loss: 1.3864 Explore P: 0.9097\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 45 Total reward: 12.0 Average reward fake: 0.498309850692749 Average reward real: 0.49865829944610596 Training q_loss: 4.5941 Training g_loss: 2.0732 Training d_loss: 1.3858 Explore P: 0.9087\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 46 Total reward: 25.0 Average reward fake: 0.4987887442111969 Average reward real: 0.4988235831260681 Training q_loss: 3.0473 Training g_loss: 2.0717 Training d_loss: 1.3863 Explore P: 0.9064\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 47 Total reward: 12.0 Average reward fake: 0.4989415109157562 Average reward real: 0.49893224239349365 Training q_loss: 2.9987 Training g_loss: 2.0690 Training d_loss: 1.3864 Explore P: 0.9053\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 48 Total reward: 9.0 Average reward fake: 0.4985668957233429 Average reward real: 0.49882981181144714 Training q_loss: 3.9884 Training g_loss: 2.0752 Training d_loss: 1.3857 Explore P: 0.9045\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 49 Total reward: 20.0 Average reward fake: 0.49908608198165894 Average reward real: 0.4997040629386902 Training q_loss: 5.3445 Training g_loss: 2.0734 Training d_loss: 1.3851 Explore P: 0.9027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 50 Total reward: 24.0 Average reward fake: 0.49942007660865784 Average reward real: 0.4999349117279053 Training q_loss: 4.1626 Training g_loss: 2.0784 Training d_loss: 1.3854 Explore P: 0.9006\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 51 Total reward: 15.0 Average reward fake: 0.4993339478969574 Average reward real: 0.5001152753829956 Training q_loss: 2.6650 Training g_loss: 2.0765 Training d_loss: 1.3848 Explore P: 0.8993\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 52 Total reward: 11.0 Average reward fake: 0.49974656105041504 Average reward real: 0.5002255439758301 Training q_loss: 3.7451 Training g_loss: 2.0783 Training d_loss: 1.3852 Explore P: 0.8983\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 53 Total reward: 12.0 Average reward fake: 0.5002912282943726 Average reward real: 0.5006381869316101 Training q_loss: 4.4230 Training g_loss: 2.0762 Training d_loss: 1.3856 Explore P: 0.8972\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 54 Total reward: 18.0 Average reward fake: 0.49961864948272705 Average reward real: 0.5000739097595215 Training q_loss: 3.2002 Training g_loss: 2.0698 Training d_loss: 1.3856 Explore P: 0.8956\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 55 Total reward: 23.0 Average reward fake: 0.49852049350738525 Average reward real: 0.49938011169433594 Training q_loss: 3.4996 Training g_loss: 2.0834 Training d_loss: 1.3845 Explore P: 0.8936\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 56 Total reward: 31.0 Average reward fake: 0.500118613243103 Average reward real: 0.5008803009986877 Training q_loss: 4.3249 Training g_loss: 2.0823 Training d_loss: 1.3848 Explore P: 0.8909\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 57 Total reward: 23.0 Average reward fake: 0.4998432993888855 Average reward real: 0.5009036064147949 Training q_loss: 2.9567 Training g_loss: 2.0786 Training d_loss: 1.3842 Explore P: 0.8888\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 58 Total reward: 22.0 Average reward fake: 0.4992714822292328 Average reward real: 0.5008264780044556 Training q_loss: 2.9208 Training g_loss: 2.0783 Training d_loss: 1.3833 Explore P: 0.8869\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 59 Total reward: 39.0 Average reward fake: 0.5005773901939392 Average reward real: 0.5020171999931335 Training q_loss: 3.4078 Training g_loss: 2.0798 Training d_loss: 1.3836 Explore P: 0.8835\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 60 Total reward: 24.0 Average reward fake: 0.4992341697216034 Average reward real: 0.5011430978775024 Training q_loss: 3.2321 Training g_loss: 2.0803 Training d_loss: 1.3824 Explore P: 0.8814\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 61 Total reward: 14.0 Average reward fake: 0.4997430443763733 Average reward real: 0.5009739995002747 Training q_loss: 2.5062 Training g_loss: 2.0813 Training d_loss: 1.3839 Explore P: 0.8802\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 62 Total reward: 16.0 Average reward fake: 0.5005978345870972 Average reward real: 0.502236545085907 Training q_loss: 3.7075 Training g_loss: 2.0794 Training d_loss: 1.3832 Explore P: 0.8788\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 63 Total reward: 15.0 Average reward fake: 0.5003342032432556 Average reward real: 0.5015580654144287 Training q_loss: 3.3910 Training g_loss: 2.0816 Training d_loss: 1.3839 Explore P: 0.8775\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 64 Total reward: 13.0 Average reward fake: 0.5003393292427063 Average reward real: 0.5024174451828003 Training q_loss: 2.6886 Training g_loss: 2.0803 Training d_loss: 1.3824 Explore P: 0.8764\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 65 Total reward: 14.0 Average reward fake: 0.5004714727401733 Average reward real: 0.5027637481689453 Training q_loss: 3.5571 Training g_loss: 2.0816 Training d_loss: 1.3819 Explore P: 0.8752\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 66 Total reward: 11.0 Average reward fake: 0.5016863942146301 Average reward real: 0.5035369992256165 Training q_loss: 3.1673 Training g_loss: 2.0804 Training d_loss: 1.3829 Explore P: 0.8742\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 67 Total reward: 22.0 Average reward fake: 0.5019176006317139 Average reward real: 0.503365695476532 Training q_loss: 3.7027 Training g_loss: 2.0837 Training d_loss: 1.3834 Explore P: 0.8723\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 68 Total reward: 17.0 Average reward fake: 0.4991650879383087 Average reward real: 0.5012366771697998 Training q_loss: 2.7946 Training g_loss: 2.0806 Training d_loss: 1.3822 Explore P: 0.8708\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 69 Total reward: 13.0 Average reward fake: 0.4988137185573578 Average reward real: 0.49972784519195557 Training q_loss: 3.8863 Training g_loss: 2.0763 Training d_loss: 1.3849 Explore P: 0.8697\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 70 Total reward: 9.0 Average reward fake: 0.5002654790878296 Average reward real: 0.5005820393562317 Training q_loss: 4.3321 Training g_loss: 2.0734 Training d_loss: 1.3859 Explore P: 0.8689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 71 Total reward: 21.0 Average reward fake: 0.49883323907852173 Average reward real: 0.500308096408844 Training q_loss: 2.8112 Training g_loss: 2.0740 Training d_loss: 1.3830 Explore P: 0.8671\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 72 Total reward: 14.0 Average reward fake: 0.49890005588531494 Average reward real: 0.4994364082813263 Training q_loss: 3.9117 Training g_loss: 2.0704 Training d_loss: 1.3849 Explore P: 0.8659\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 73 Total reward: 12.0 Average reward fake: 0.4993114769458771 Average reward real: 0.5001617670059204 Training q_loss: 4.0138 Training g_loss: 2.0841 Training d_loss: 1.3847 Explore P: 0.8649\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 74 Total reward: 14.0 Average reward fake: 0.49966201186180115 Average reward real: 0.500548243522644 Training q_loss: 2.6956 Training g_loss: 2.0709 Training d_loss: 1.3845 Explore P: 0.8637\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 75 Total reward: 85.0 Average reward fake: 0.4995020925998688 Average reward real: 0.5006340146064758 Training q_loss: 3.4800 Training g_loss: 2.0674 Training d_loss: 1.3841 Explore P: 0.8565\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 76 Total reward: 25.0 Average reward fake: 0.49997222423553467 Average reward real: 0.5003560781478882 Training q_loss: 2.5370 Training g_loss: 2.0717 Training d_loss: 1.3855 Explore P: 0.8544\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 77 Total reward: 16.0 Average reward fake: 0.5006899237632751 Average reward real: 0.5008353590965271 Training q_loss: 3.0603 Training g_loss: 2.0695 Training d_loss: 1.3863 Explore P: 0.8530\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 78 Total reward: 18.0 Average reward fake: 0.4993274211883545 Average reward real: 0.4990188479423523 Training q_loss: 3.8539 Training g_loss: 2.0671 Training d_loss: 1.3875 Explore P: 0.8515\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 79 Total reward: 10.0 Average reward fake: 0.4991152584552765 Average reward real: 0.4987637400627136 Training q_loss: 3.6819 Training g_loss: 2.0713 Training d_loss: 1.3872 Explore P: 0.8507\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 80 Total reward: 39.0 Average reward fake: 0.5003494024276733 Average reward real: 0.4999288320541382 Training q_loss: 4.0923 Training g_loss: 2.0673 Training d_loss: 1.3871 Explore P: 0.8474\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 81 Total reward: 29.0 Average reward fake: 0.4994867742061615 Average reward real: 0.4995828866958618 Training q_loss: 3.2399 Training g_loss: 2.0709 Training d_loss: 1.3862 Explore P: 0.8450\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 82 Total reward: 13.0 Average reward fake: 0.5004252791404724 Average reward real: 0.5000788569450378 Training q_loss: 3.5394 Training g_loss: 2.0662 Training d_loss: 1.3873 Explore P: 0.8439\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 83 Total reward: 25.0 Average reward fake: 0.49892494082450867 Average reward real: 0.4987453818321228 Training q_loss: 2.5647 Training g_loss: 2.0700 Training d_loss: 1.3871 Explore P: 0.8418\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 84 Total reward: 19.0 Average reward fake: 0.500186026096344 Average reward real: 0.5005537867546082 Training q_loss: 3.7531 Training g_loss: 2.0628 Training d_loss: 1.3856 Explore P: 0.8402\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 85 Total reward: 24.0 Average reward fake: 0.4996268153190613 Average reward real: 0.5000849366188049 Training q_loss: 3.1565 Training g_loss: 2.0774 Training d_loss: 1.3849 Explore P: 0.8382\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 86 Total reward: 25.0 Average reward fake: 0.5012443661689758 Average reward real: 0.499898761510849 Training q_loss: 3.6387 Training g_loss: 2.0678 Training d_loss: 1.3882 Explore P: 0.8362\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 87 Total reward: 45.0 Average reward fake: 0.5002928376197815 Average reward real: 0.5005179047584534 Training q_loss: 2.9470 Training g_loss: 2.0621 Training d_loss: 1.3860 Explore P: 0.8325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 88 Total reward: 24.0 Average reward fake: 0.49915534257888794 Average reward real: 0.49867674708366394 Training q_loss: 2.8419 Training g_loss: 2.0620 Training d_loss: 1.3871 Explore P: 0.8305\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 89 Total reward: 10.0 Average reward fake: 0.4990953803062439 Average reward real: 0.49870413541793823 Training q_loss: 3.4857 Training g_loss: 2.0686 Training d_loss: 1.3872 Explore P: 0.8297\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 90 Total reward: 58.0 Average reward fake: 0.4999520480632782 Average reward real: 0.500231146812439 Training q_loss: 2.6979 Training g_loss: 2.0719 Training d_loss: 1.3854 Explore P: 0.8249\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 91 Total reward: 17.0 Average reward fake: 0.5004006028175354 Average reward real: 0.5009170174598694 Training q_loss: 2.6928 Training g_loss: 2.0675 Training d_loss: 1.3853 Explore P: 0.8235\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 92 Total reward: 22.0 Average reward fake: 0.4997202157974243 Average reward real: 0.4991941750049591 Training q_loss: 4.6467 Training g_loss: 2.0631 Training d_loss: 1.3874 Explore P: 0.8218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 93 Total reward: 20.0 Average reward fake: 0.4994674026966095 Average reward real: 0.4996006488800049 Training q_loss: 2.9229 Training g_loss: 2.0643 Training d_loss: 1.3861 Explore P: 0.8201\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 94 Total reward: 56.0 Average reward fake: 0.49896126985549927 Average reward real: 0.4993942379951477 Training q_loss: 4.6402 Training g_loss: 2.0659 Training d_loss: 1.3854 Explore P: 0.8156\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 95 Total reward: 13.0 Average reward fake: 0.49993765354156494 Average reward real: 0.5001478791236877 Training q_loss: 3.6454 Training g_loss: 2.0687 Training d_loss: 1.3859 Explore P: 0.8146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 96 Total reward: 78.0 Average reward fake: 0.500977098941803 Average reward real: 0.5014190077781677 Training q_loss: 3.0719 Training g_loss: 2.0663 Training d_loss: 1.3859 Explore P: 0.8083\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 97 Total reward: 20.0 Average reward fake: 0.49941346049308777 Average reward real: 0.4990832507610321 Training q_loss: 3.6089 Training g_loss: 2.0666 Training d_loss: 1.3869 Explore P: 0.8067\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 98 Total reward: 55.0 Average reward fake: 0.5002642869949341 Average reward real: 0.5012457370758057 Training q_loss: 4.5042 Training g_loss: 2.0694 Training d_loss: 1.3844 Explore P: 0.8024\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 99 Total reward: 63.0 Average reward fake: 0.5004953145980835 Average reward real: 0.5004808902740479 Training q_loss: 2.9060 Training g_loss: 2.0684 Training d_loss: 1.3865 Explore P: 0.7974\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 100 Total reward: 67.0 Average reward fake: 0.4997349679470062 Average reward real: 0.5002719163894653 Training q_loss: 2.4481 Training g_loss: 2.0817 Training d_loss: 1.3853 Explore P: 0.7921\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 101 Total reward: 11.0 Average reward fake: 0.5008094906806946 Average reward real: 0.5008547902107239 Training q_loss: 6.0016 Training g_loss: 2.0650 Training d_loss: 1.3862 Explore P: 0.7913\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 102 Total reward: 20.0 Average reward fake: 0.49863457679748535 Average reward real: 0.4988045394420624 Training q_loss: 3.0639 Training g_loss: 2.0688 Training d_loss: 1.3858 Explore P: 0.7897\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 103 Total reward: 93.0 Average reward fake: 0.5003818273544312 Average reward real: 0.5009841322898865 Training q_loss: 3.3420 Training g_loss: 2.0658 Training d_loss: 1.3851 Explore P: 0.7825\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 104 Total reward: 17.0 Average reward fake: 0.5002573132514954 Average reward real: 0.501407265663147 Training q_loss: 3.3075 Training g_loss: 2.0674 Training d_loss: 1.3841 Explore P: 0.7812\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 105 Total reward: 30.0 Average reward fake: 0.5020244717597961 Average reward real: 0.5007359981536865 Training q_loss: 3.0467 Training g_loss: 2.0635 Training d_loss: 1.3892 Explore P: 0.7789\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 106 Total reward: 48.0 Average reward fake: 0.5005859136581421 Average reward real: 0.5014011263847351 Training q_loss: 3.0315 Training g_loss: 2.0690 Training d_loss: 1.3850 Explore P: 0.7752\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 107 Total reward: 54.0 Average reward fake: 0.4996299743652344 Average reward real: 0.4997760057449341 Training q_loss: 4.9213 Training g_loss: 2.0710 Training d_loss: 1.3859 Explore P: 0.7711\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 108 Total reward: 45.0 Average reward fake: 0.49984070658683777 Average reward real: 0.500505805015564 Training q_loss: 2.8126 Training g_loss: 2.0674 Training d_loss: 1.3851 Explore P: 0.7676\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 109 Total reward: 38.0 Average reward fake: 0.5011844635009766 Average reward real: 0.5002656579017639 Training q_loss: 3.4376 Training g_loss: 2.0686 Training d_loss: 1.3879 Explore P: 0.7648\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 110 Total reward: 29.0 Average reward fake: 0.5003601312637329 Average reward real: 0.5002802014350891 Training q_loss: 2.1581 Training g_loss: 2.0655 Training d_loss: 1.3866 Explore P: 0.7626\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 111 Total reward: 26.0 Average reward fake: 0.4993584454059601 Average reward real: 0.4993157684803009 Training q_loss: 4.2934 Training g_loss: 2.0714 Training d_loss: 1.3869 Explore P: 0.7606\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 112 Total reward: 38.0 Average reward fake: 0.49998748302459717 Average reward real: 0.5002425909042358 Training q_loss: 3.7783 Training g_loss: 2.0665 Training d_loss: 1.3859 Explore P: 0.7578\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 113 Total reward: 43.0 Average reward fake: 0.5010541677474976 Average reward real: 0.5016839504241943 Training q_loss: 3.4996 Training g_loss: 2.0718 Training d_loss: 1.3851 Explore P: 0.7546\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 114 Total reward: 118.0 Average reward fake: 0.5009661316871643 Average reward real: 0.500367283821106 Training q_loss: 3.0356 Training g_loss: 2.0661 Training d_loss: 1.3876 Explore P: 0.7458\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 115 Total reward: 11.0 Average reward fake: 0.49916571378707886 Average reward real: 0.49931061267852783 Training q_loss: 2.8025 Training g_loss: 2.0700 Training d_loss: 1.3858 Explore P: 0.7450\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 116 Total reward: 17.0 Average reward fake: 0.5005367398262024 Average reward real: 0.5004507303237915 Training q_loss: 32.2110 Training g_loss: 2.0987 Training d_loss: 1.3895 Explore P: 0.7438\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 117 Total reward: 31.0 Average reward fake: 0.5000736117362976 Average reward real: 0.5032782554626465 Training q_loss: 3.1685 Training g_loss: 2.0854 Training d_loss: 1.3800 Explore P: 0.7415\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 118 Total reward: 29.0 Average reward fake: 0.49971243739128113 Average reward real: 0.5048757791519165 Training q_loss: 2.7239 Training g_loss: 2.0869 Training d_loss: 1.3775 Explore P: 0.7394\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 119 Total reward: 22.0 Average reward fake: 0.49442845582962036 Average reward real: 0.49706023931503296 Training q_loss: 2.9352 Training g_loss: 2.0910 Training d_loss: 1.3809 Explore P: 0.7378\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 120 Total reward: 24.0 Average reward fake: 0.5051302313804626 Average reward real: 0.4952329993247986 Training q_loss: 2.3501 Training g_loss: 2.0777 Training d_loss: 1.4061 Explore P: 0.7360\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 121 Total reward: 111.0 Average reward fake: 0.4915795922279358 Average reward real: 0.4920404553413391 Training q_loss: 4.5253 Training g_loss: 2.0813 Training d_loss: 1.3857 Explore P: 0.7280\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 122 Total reward: 25.0 Average reward fake: 0.5068159103393555 Average reward real: 0.5009469389915466 Training q_loss: 2.6969 Training g_loss: 2.0758 Training d_loss: 1.3975 Explore P: 0.7262\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 123 Total reward: 20.0 Average reward fake: 0.49676713347435 Average reward real: 0.49758780002593994 Training q_loss: 2.6607 Training g_loss: 2.0752 Training d_loss: 1.3860 Explore P: 0.7248\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 124 Total reward: 23.0 Average reward fake: 0.5005117654800415 Average reward real: 0.498540461063385 Training q_loss: 8.2064 Training g_loss: 2.0718 Training d_loss: 1.3900 Explore P: 0.7232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 125 Total reward: 12.0 Average reward fake: 0.49939072132110596 Average reward real: 0.4980923533439636 Training q_loss: 3.0412 Training g_loss: 2.0648 Training d_loss: 1.3889 Explore P: 0.7223\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 126 Total reward: 49.0 Average reward fake: 0.5007169842720032 Average reward real: 0.49972695112228394 Training q_loss: 3.2358 Training g_loss: 2.0662 Training d_loss: 1.3885 Explore P: 0.7188\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 127 Total reward: 40.0 Average reward fake: 0.5002354383468628 Average reward real: 0.5003368258476257 Training q_loss: 2.7586 Training g_loss: 2.0714 Training d_loss: 1.3861 Explore P: 0.7160\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 128 Total reward: 23.0 Average reward fake: 0.4984844923019409 Average reward real: 0.5000820755958557 Training q_loss: 6.2130 Training g_loss: 2.0781 Training d_loss: 1.3831 Explore P: 0.7144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 129 Total reward: 17.0 Average reward fake: 0.4996595084667206 Average reward real: 0.5014057755470276 Training q_loss: 3.0895 Training g_loss: 2.0712 Training d_loss: 1.3836 Explore P: 0.7132\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 130 Total reward: 38.0 Average reward fake: 0.4998948276042938 Average reward real: 0.49945586919784546 Training q_loss: 2.1322 Training g_loss: 2.0686 Training d_loss: 1.3870 Explore P: 0.7105\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 131 Total reward: 25.0 Average reward fake: 0.5003202557563782 Average reward real: 0.5003702044487 Training q_loss: 2.9024 Training g_loss: 2.0738 Training d_loss: 1.3864 Explore P: 0.7088\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 132 Total reward: 18.0 Average reward fake: 0.5005142092704773 Average reward real: 0.49950242042541504 Training q_loss: 2.5987 Training g_loss: 2.0693 Training d_loss: 1.3883 Explore P: 0.7075\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 133 Total reward: 25.0 Average reward fake: 0.49919453263282776 Average reward real: 0.5000010132789612 Training q_loss: 2.4799 Training g_loss: 2.0791 Training d_loss: 1.3843 Explore P: 0.7058\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 134 Total reward: 27.0 Average reward fake: 0.49943941831588745 Average reward real: 0.5006727576255798 Training q_loss: 2.9203 Training g_loss: 2.0719 Training d_loss: 1.3841 Explore P: 0.7039\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 135 Total reward: 33.0 Average reward fake: 0.5003920197486877 Average reward real: 0.5001635551452637 Training q_loss: 2.1346 Training g_loss: 2.0658 Training d_loss: 1.3871 Explore P: 0.7016\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 136 Total reward: 9.0 Average reward fake: 0.4999168813228607 Average reward real: 0.4999014139175415 Training q_loss: 3.8005 Training g_loss: 2.0663 Training d_loss: 1.3863 Explore P: 0.7010\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 137 Total reward: 84.0 Average reward fake: 0.4998325705528259 Average reward real: 0.5000383853912354 Training q_loss: 2.7054 Training g_loss: 2.0721 Training d_loss: 1.3861 Explore P: 0.6952\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 138 Total reward: 62.0 Average reward fake: 0.49945706129074097 Average reward real: 0.500033438205719 Training q_loss: 2.5994 Training g_loss: 2.0739 Training d_loss: 1.3851 Explore P: 0.6910\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 139 Total reward: 19.0 Average reward fake: 0.4996790289878845 Average reward real: 0.5000208616256714 Training q_loss: 2.4610 Training g_loss: 2.0752 Training d_loss: 1.3857 Explore P: 0.6897\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 140 Total reward: 26.0 Average reward fake: 0.5002864003181458 Average reward real: 0.5006552338600159 Training q_loss: 2.8991 Training g_loss: 2.0664 Training d_loss: 1.3856 Explore P: 0.6879\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 141 Total reward: 56.0 Average reward fake: 0.49977314472198486 Average reward real: 0.49930164217948914 Training q_loss: 2.8012 Training g_loss: 2.0665 Training d_loss: 1.3869 Explore P: 0.6841\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 142 Total reward: 32.0 Average reward fake: 0.5003142356872559 Average reward real: 0.5001880526542664 Training q_loss: 2.4131 Training g_loss: 2.0699 Training d_loss: 1.3862 Explore P: 0.6820\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 143 Total reward: 21.0 Average reward fake: 0.4994245767593384 Average reward real: 0.5000096559524536 Training q_loss: 2.7427 Training g_loss: 2.0733 Training d_loss: 1.3851 Explore P: 0.6806\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 144 Total reward: 45.0 Average reward fake: 0.4999772012233734 Average reward real: 0.49999818205833435 Training q_loss: 3.7705 Training g_loss: 2.0687 Training d_loss: 1.3863 Explore P: 0.6775\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 145 Total reward: 65.0 Average reward fake: 0.49979567527770996 Average reward real: 0.5000259280204773 Training q_loss: 3.3523 Training g_loss: 2.0709 Training d_loss: 1.3860 Explore P: 0.6732\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 146 Total reward: 19.0 Average reward fake: 0.4995763301849365 Average reward real: 0.49991142749786377 Training q_loss: 2.7634 Training g_loss: 2.0726 Training d_loss: 1.3855 Explore P: 0.6720\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 147 Total reward: 27.0 Average reward fake: 0.49995726346969604 Average reward real: 0.5006876587867737 Training q_loss: 2.1865 Training g_loss: 2.0696 Training d_loss: 1.3848 Explore P: 0.6702\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 148 Total reward: 67.0 Average reward fake: 0.500904381275177 Average reward real: 0.5002879500389099 Training q_loss: 2.5417 Training g_loss: 2.0664 Training d_loss: 1.3875 Explore P: 0.6658\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 149 Total reward: 24.0 Average reward fake: 0.49954330921173096 Average reward real: 0.49985426664352417 Training q_loss: 2.6366 Training g_loss: 2.0692 Training d_loss: 1.3856 Explore P: 0.6642\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 150 Total reward: 61.0 Average reward fake: 0.5001686215400696 Average reward real: 0.5004653930664062 Training q_loss: 2.7465 Training g_loss: 2.0698 Training d_loss: 1.3857 Explore P: 0.6602\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 151 Total reward: 22.0 Average reward fake: 0.4993062913417816 Average reward real: 0.4999021589756012 Training q_loss: 3.1986 Training g_loss: 2.0767 Training d_loss: 1.3853 Explore P: 0.6588\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 152 Total reward: 35.0 Average reward fake: 0.4995249807834625 Average reward real: 0.49992796778678894 Training q_loss: 2.4069 Training g_loss: 2.0671 Training d_loss: 1.3854 Explore P: 0.6565\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 153 Total reward: 84.0 Average reward fake: 0.49877429008483887 Average reward real: 0.49958565831184387 Training q_loss: 2.6198 Training g_loss: 2.0733 Training d_loss: 1.3847 Explore P: 0.6511\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 154 Total reward: 21.0 Average reward fake: 0.5013852715492249 Average reward real: 0.5008108019828796 Training q_loss: 3.7379 Training g_loss: 2.0645 Training d_loss: 1.3875 Explore P: 0.6498\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 155 Total reward: 9.0 Average reward fake: 0.5001065135002136 Average reward real: 0.5005975961685181 Training q_loss: 3.6341 Training g_loss: 2.0673 Training d_loss: 1.3850 Explore P: 0.6492\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 156 Total reward: 49.0 Average reward fake: 0.500210702419281 Average reward real: 0.5002026557922363 Training q_loss: 3.2367 Training g_loss: 2.0708 Training d_loss: 1.3865 Explore P: 0.6461\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 157 Total reward: 25.0 Average reward fake: 0.4995642900466919 Average reward real: 0.5000413656234741 Training q_loss: 5.8362 Training g_loss: 2.0703 Training d_loss: 1.3856 Explore P: 0.6445\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 158 Total reward: 27.0 Average reward fake: 0.5003978610038757 Average reward real: 0.5000922679901123 Training q_loss: 2.6620 Training g_loss: 2.0651 Training d_loss: 1.3869 Explore P: 0.6428\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 159 Total reward: 19.0 Average reward fake: 0.4995391070842743 Average reward real: 0.49996814131736755 Training q_loss: 2.0996 Training g_loss: 2.0743 Training d_loss: 1.3854 Explore P: 0.6416\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 160 Total reward: 26.0 Average reward fake: 0.49997657537460327 Average reward real: 0.500030517578125 Training q_loss: 2.1573 Training g_loss: 2.0695 Training d_loss: 1.3860 Explore P: 0.6399\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 161 Total reward: 32.0 Average reward fake: 0.5002392530441284 Average reward real: 0.5001225471496582 Training q_loss: 2.7488 Training g_loss: 2.0655 Training d_loss: 1.3866 Explore P: 0.6379\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 162 Total reward: 38.0 Average reward fake: 0.5000689625740051 Average reward real: 0.5002164244651794 Training q_loss: 2.3616 Training g_loss: 2.0685 Training d_loss: 1.3858 Explore P: 0.6355\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 163 Total reward: 15.0 Average reward fake: 0.4993981122970581 Average reward real: 0.4996839463710785 Training q_loss: 2.4063 Training g_loss: 2.0745 Training d_loss: 1.3857 Explore P: 0.6346\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 164 Total reward: 38.0 Average reward fake: 0.4992261528968811 Average reward real: 0.49957534670829773 Training q_loss: 2.6285 Training g_loss: 2.0657 Training d_loss: 1.3859 Explore P: 0.6322\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 165 Total reward: 53.0 Average reward fake: 0.4996293783187866 Average reward real: 0.49985983967781067 Training q_loss: 2.2676 Training g_loss: 2.0697 Training d_loss: 1.3859 Explore P: 0.6289\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 166 Total reward: 17.0 Average reward fake: 0.49993225932121277 Average reward real: 0.5002530813217163 Training q_loss: 3.0575 Training g_loss: 2.0679 Training d_loss: 1.3856 Explore P: 0.6279\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 167 Total reward: 67.0 Average reward fake: 0.49997496604919434 Average reward real: 0.5003606677055359 Training q_loss: 2.5334 Training g_loss: 2.0654 Training d_loss: 1.3856 Explore P: 0.6238\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 168 Total reward: 25.0 Average reward fake: 0.5000167489051819 Average reward real: 0.5001690983772278 Training q_loss: 2.5888 Training g_loss: 2.0646 Training d_loss: 1.3863 Explore P: 0.6222\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 169 Total reward: 99.0 Average reward fake: 0.5008943676948547 Average reward real: 0.5008940696716309 Training q_loss: 2.7309 Training g_loss: 2.0656 Training d_loss: 1.3863 Explore P: 0.6162\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 170 Total reward: 36.0 Average reward fake: 0.5005906224250793 Average reward real: 0.5006272792816162 Training q_loss: 2.3441 Training g_loss: 2.0703 Training d_loss: 1.3861 Explore P: 0.6140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 171 Total reward: 24.0 Average reward fake: 0.5001130104064941 Average reward real: 0.5003331899642944 Training q_loss: 4.4700 Training g_loss: 2.0662 Training d_loss: 1.3858 Explore P: 0.6126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 172 Total reward: 70.0 Average reward fake: 0.499428391456604 Average reward real: 0.4998559057712555 Training q_loss: 2.7214 Training g_loss: 2.0701 Training d_loss: 1.3858 Explore P: 0.6084\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 173 Total reward: 33.0 Average reward fake: 0.49963846802711487 Average reward real: 0.5001111030578613 Training q_loss: 2.4788 Training g_loss: 2.0747 Training d_loss: 1.3853 Explore P: 0.6064\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 174 Total reward: 15.0 Average reward fake: 0.5002071857452393 Average reward real: 0.5003319382667542 Training q_loss: 2.6474 Training g_loss: 2.0710 Training d_loss: 1.3858 Explore P: 0.6055\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 175 Total reward: 25.0 Average reward fake: 0.49986398220062256 Average reward real: 0.5003755688667297 Training q_loss: 2.4826 Training g_loss: 2.0682 Training d_loss: 1.3848 Explore P: 0.6040\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 176 Total reward: 60.0 Average reward fake: 0.5000132918357849 Average reward real: 0.5001237988471985 Training q_loss: 2.7313 Training g_loss: 2.0688 Training d_loss: 1.3860 Explore P: 0.6005\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 177 Total reward: 41.0 Average reward fake: 0.5015407204627991 Average reward real: 0.5010619163513184 Training q_loss: 3.1460 Training g_loss: 2.0704 Training d_loss: 1.3861 Explore P: 0.5980\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 178 Total reward: 69.0 Average reward fake: 0.49984437227249146 Average reward real: 0.5001938939094543 Training q_loss: 2.2313 Training g_loss: 2.0706 Training d_loss: 1.3863 Explore P: 0.5940\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 179 Total reward: 94.0 Average reward fake: 0.5004856586456299 Average reward real: 0.5004656314849854 Training q_loss: 2.2952 Training g_loss: 2.0746 Training d_loss: 1.3865 Explore P: 0.5885\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 180 Total reward: 29.0 Average reward fake: 0.49905452132225037 Average reward real: 0.4996771216392517 Training q_loss: 3.2576 Training g_loss: 2.0700 Training d_loss: 1.3850 Explore P: 0.5869\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 181 Total reward: 63.0 Average reward fake: 0.49993079900741577 Average reward real: 0.5004268884658813 Training q_loss: 2.4576 Training g_loss: 2.0703 Training d_loss: 1.3854 Explore P: 0.5832\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 182 Total reward: 19.0 Average reward fake: 0.4998767375946045 Average reward real: 0.5001113414764404 Training q_loss: 2.6328 Training g_loss: 2.0717 Training d_loss: 1.3863 Explore P: 0.5822\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 183 Total reward: 82.0 Average reward fake: 0.49973922967910767 Average reward real: 0.5000253915786743 Training q_loss: 2.3126 Training g_loss: 2.0683 Training d_loss: 1.3858 Explore P: 0.5775\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 184 Total reward: 27.0 Average reward fake: 0.5003901720046997 Average reward real: 0.4995577335357666 Training q_loss: 2.1440 Training g_loss: 2.0654 Training d_loss: 1.3878 Explore P: 0.5759\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 185 Total reward: 40.0 Average reward fake: 0.4999585449695587 Average reward real: 0.5003758072853088 Training q_loss: 2.5240 Training g_loss: 2.0654 Training d_loss: 1.3852 Explore P: 0.5737\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 186 Total reward: 84.0 Average reward fake: 0.49960067868232727 Average reward real: 0.49992233514785767 Training q_loss: 2.4007 Training g_loss: 2.0707 Training d_loss: 1.3859 Explore P: 0.5690\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 187 Total reward: 27.0 Average reward fake: 0.49977052211761475 Average reward real: 0.4998348355293274 Training q_loss: 3.3353 Training g_loss: 2.0736 Training d_loss: 1.3862 Explore P: 0.5675\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 188 Total reward: 20.0 Average reward fake: 0.4995855391025543 Average reward real: 0.5000132918357849 Training q_loss: 2.2001 Training g_loss: 2.0783 Training d_loss: 1.3854 Explore P: 0.5664\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 189 Total reward: 17.0 Average reward fake: 0.5005627274513245 Average reward real: 0.5005170702934265 Training q_loss: 2.4082 Training g_loss: 2.0685 Training d_loss: 1.3864 Explore P: 0.5654\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 190 Total reward: 37.0 Average reward fake: 0.5000229477882385 Average reward real: 0.5004432201385498 Training q_loss: 2.1851 Training g_loss: 2.0693 Training d_loss: 1.3855 Explore P: 0.5634\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 191 Total reward: 111.0 Average reward fake: 0.4990224540233612 Average reward real: 0.4995037913322449 Training q_loss: 2.7583 Training g_loss: 2.0709 Training d_loss: 1.3856 Explore P: 0.5572\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 192 Total reward: 71.0 Average reward fake: 0.49953514337539673 Average reward real: 0.5000253915786743 Training q_loss: 2.5614 Training g_loss: 2.0757 Training d_loss: 1.3851 Explore P: 0.5534\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 193 Total reward: 27.0 Average reward fake: 0.4998175799846649 Average reward real: 0.5005064606666565 Training q_loss: 2.6203 Training g_loss: 2.0746 Training d_loss: 1.3857 Explore P: 0.5519\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 194 Total reward: 31.0 Average reward fake: 0.4988800287246704 Average reward real: 0.4994302988052368 Training q_loss: 2.7648 Training g_loss: 2.0764 Training d_loss: 1.3852 Explore P: 0.5502\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 195 Total reward: 18.0 Average reward fake: 0.49998390674591064 Average reward real: 0.5009081363677979 Training q_loss: 2.2396 Training g_loss: 2.0674 Training d_loss: 1.3846 Explore P: 0.5493\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 196 Total reward: 13.0 Average reward fake: 0.4998563826084137 Average reward real: 0.4998912811279297 Training q_loss: 2.5877 Training g_loss: 2.0689 Training d_loss: 1.3861 Explore P: 0.5486\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 197 Total reward: 83.0 Average reward fake: 0.5001484155654907 Average reward real: 0.49998557567596436 Training q_loss: 2.3797 Training g_loss: 2.0689 Training d_loss: 1.3865 Explore P: 0.5441\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 198 Total reward: 25.0 Average reward fake: 0.49984559416770935 Average reward real: 0.500148355960846 Training q_loss: 2.4211 Training g_loss: 2.0776 Training d_loss: 1.3858 Explore P: 0.5428\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 199 Total reward: 16.0 Average reward fake: 0.5016286969184875 Average reward real: 0.5006728768348694 Training q_loss: 2.9879 Training g_loss: 2.0652 Training d_loss: 1.3885 Explore P: 0.5419\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 200 Total reward: 82.0 Average reward fake: 0.4999806582927704 Average reward real: 0.49980881810188293 Training q_loss: 2.1462 Training g_loss: 2.0758 Training d_loss: 1.3867 Explore P: 0.5376\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 201 Total reward: 34.0 Average reward fake: 0.4990684390068054 Average reward real: 0.4992956519126892 Training q_loss: 2.3045 Training g_loss: 2.0731 Training d_loss: 1.3858 Explore P: 0.5358\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 202 Total reward: 119.0 Average reward fake: 0.5001376867294312 Average reward real: 0.500340461730957 Training q_loss: 2.7987 Training g_loss: 2.0658 Training d_loss: 1.3860 Explore P: 0.5296\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 203 Total reward: 36.0 Average reward fake: 0.5009267330169678 Average reward real: 0.5006518363952637 Training q_loss: 2.4820 Training g_loss: 2.0706 Training d_loss: 1.3870 Explore P: 0.5277\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 204 Total reward: 24.0 Average reward fake: 0.4999762773513794 Average reward real: 0.5000319480895996 Training q_loss: 2.3291 Training g_loss: 2.0779 Training d_loss: 1.3859 Explore P: 0.5265\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 205 Total reward: 16.0 Average reward fake: 0.4991080164909363 Average reward real: 0.49940812587738037 Training q_loss: 2.2447 Training g_loss: 2.0737 Training d_loss: 1.3856 Explore P: 0.5256\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 206 Total reward: 46.0 Average reward fake: 0.5005841255187988 Average reward real: 0.5006567239761353 Training q_loss: 3.3355 Training g_loss: 2.0715 Training d_loss: 1.3863 Explore P: 0.5233\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 207 Total reward: 13.0 Average reward fake: 0.5009104013442993 Average reward real: 0.5003104209899902 Training q_loss: 2.1682 Training g_loss: 2.0776 Training d_loss: 1.3873 Explore P: 0.5226\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 208 Total reward: 30.0 Average reward fake: 0.5002678036689758 Average reward real: 0.5015771389007568 Training q_loss: 2.4005 Training g_loss: 2.0723 Training d_loss: 1.3840 Explore P: 0.5211\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 209 Total reward: 44.0 Average reward fake: 0.5007959604263306 Average reward real: 0.5013903379440308 Training q_loss: 2.4386 Training g_loss: 2.0739 Training d_loss: 1.3851 Explore P: 0.5188\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 210 Total reward: 51.0 Average reward fake: 0.499370276927948 Average reward real: 0.5002878904342651 Training q_loss: 2.2912 Training g_loss: 2.0693 Training d_loss: 1.3846 Explore P: 0.5162\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 211 Total reward: 65.0 Average reward fake: 0.4995749592781067 Average reward real: 0.4996279180049896 Training q_loss: 3.8118 Training g_loss: 2.0753 Training d_loss: 1.3861 Explore P: 0.5130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 212 Total reward: 53.0 Average reward fake: 0.5007564425468445 Average reward real: 0.5002335906028748 Training q_loss: 2.1982 Training g_loss: 2.0674 Training d_loss: 1.3885 Explore P: 0.5103\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 213 Total reward: 47.0 Average reward fake: 0.4995720684528351 Average reward real: 0.49991241097450256 Training q_loss: 2.5332 Training g_loss: 2.0718 Training d_loss: 1.3857 Explore P: 0.5080\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 214 Total reward: 20.0 Average reward fake: 0.4991725981235504 Average reward real: 0.4996625483036041 Training q_loss: 2.3121 Training g_loss: 2.0685 Training d_loss: 1.3854 Explore P: 0.5070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 215 Total reward: 17.0 Average reward fake: 0.4997364282608032 Average reward real: 0.5004411935806274 Training q_loss: 2.4471 Training g_loss: 2.0703 Training d_loss: 1.3851 Explore P: 0.5061\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 216 Total reward: 26.0 Average reward fake: 0.5001437664031982 Average reward real: 0.4999019503593445 Training q_loss: 2.3841 Training g_loss: 2.0756 Training d_loss: 1.3866 Explore P: 0.5048\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 217 Total reward: 27.0 Average reward fake: 0.49978867173194885 Average reward real: 0.5008056163787842 Training q_loss: 2.2778 Training g_loss: 2.0722 Training d_loss: 1.3846 Explore P: 0.5035\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 218 Total reward: 17.0 Average reward fake: 0.4992998242378235 Average reward real: 0.49957385659217834 Training q_loss: 2.3176 Training g_loss: 2.0703 Training d_loss: 1.3860 Explore P: 0.5027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 219 Total reward: 53.0 Average reward fake: 0.4995235204696655 Average reward real: 0.49908748269081116 Training q_loss: 2.4432 Training g_loss: 2.0724 Training d_loss: 1.3871 Explore P: 0.5000\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 220 Total reward: 27.0 Average reward fake: 0.5005916357040405 Average reward real: 0.5005130171775818 Training q_loss: 2.6037 Training g_loss: 2.0698 Training d_loss: 1.3866 Explore P: 0.4987\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 221 Total reward: 42.0 Average reward fake: 0.4996046721935272 Average reward real: 0.5016207098960876 Training q_loss: 2.2123 Training g_loss: 2.0784 Training d_loss: 1.3824 Explore P: 0.4967\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 222 Total reward: 81.0 Average reward fake: 0.49983206391334534 Average reward real: 0.5010141134262085 Training q_loss: 2.2392 Training g_loss: 2.0714 Training d_loss: 1.3857 Explore P: 0.4928\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 223 Total reward: 104.0 Average reward fake: 0.4997166395187378 Average reward real: 0.5001599788665771 Training q_loss: 2.2569 Training g_loss: 2.0727 Training d_loss: 1.3854 Explore P: 0.4878\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 224 Total reward: 18.0 Average reward fake: 0.49939224123954773 Average reward real: 0.5005190372467041 Training q_loss: 2.4872 Training g_loss: 2.0716 Training d_loss: 1.3842 Explore P: 0.4869\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 225 Total reward: 50.0 Average reward fake: 0.49967440962791443 Average reward real: 0.49968352913856506 Training q_loss: 2.3606 Training g_loss: 2.0698 Training d_loss: 1.3861 Explore P: 0.4845\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 226 Total reward: 20.0 Average reward fake: 0.4998621344566345 Average reward real: 0.5004688501358032 Training q_loss: 2.3163 Training g_loss: 2.0751 Training d_loss: 1.3851 Explore P: 0.4836\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 227 Total reward: 23.0 Average reward fake: 0.4992634654045105 Average reward real: 0.5000036954879761 Training q_loss: 2.2184 Training g_loss: 2.0758 Training d_loss: 1.3850 Explore P: 0.4825\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 228 Total reward: 81.0 Average reward fake: 0.5018157958984375 Average reward real: 0.49963676929473877 Training q_loss: 2.1217 Training g_loss: 2.0726 Training d_loss: 1.3913 Explore P: 0.4787\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 229 Total reward: 24.0 Average reward fake: 0.49910610914230347 Average reward real: 0.4986521005630493 Training q_loss: 2.1615 Training g_loss: 2.0731 Training d_loss: 1.3859 Explore P: 0.4775\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 230 Total reward: 142.0 Average reward fake: 0.5000513195991516 Average reward real: 0.5010879039764404 Training q_loss: 2.7476 Training g_loss: 2.0733 Training d_loss: 1.3845 Explore P: 0.4710\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 231 Total reward: 9.0 Average reward fake: 0.5002407431602478 Average reward real: 0.5005209445953369 Training q_loss: 3.4696 Training g_loss: 2.0706 Training d_loss: 1.3860 Explore P: 0.4705\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 232 Total reward: 28.0 Average reward fake: 0.49997633695602417 Average reward real: 0.5006880164146423 Training q_loss: 2.2351 Training g_loss: 2.0749 Training d_loss: 1.3855 Explore P: 0.4693\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 233 Total reward: 20.0 Average reward fake: 0.5010603070259094 Average reward real: 0.49879664182662964 Training q_loss: 2.7436 Training g_loss: 2.0752 Training d_loss: 1.3908 Explore P: 0.4683\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 234 Total reward: 47.0 Average reward fake: 0.4995681047439575 Average reward real: 0.5003975033760071 Training q_loss: 2.4706 Training g_loss: 2.0716 Training d_loss: 1.3848 Explore P: 0.4662\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 235 Total reward: 75.0 Average reward fake: 0.4996340870857239 Average reward real: 0.5015184283256531 Training q_loss: 2.6406 Training g_loss: 2.0765 Training d_loss: 1.3826 Explore P: 0.4628\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 236 Total reward: 14.0 Average reward fake: 0.49966827034950256 Average reward real: 0.5011757016181946 Training q_loss: 2.5401 Training g_loss: 2.0734 Training d_loss: 1.3833 Explore P: 0.4621\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 237 Total reward: 47.0 Average reward fake: 0.5015558004379272 Average reward real: 0.5014041662216187 Training q_loss: 2.6903 Training g_loss: 2.0834 Training d_loss: 1.3873 Explore P: 0.4600\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 238 Total reward: 25.0 Average reward fake: 0.49920254945755005 Average reward real: 0.4997312128543854 Training q_loss: 2.6724 Training g_loss: 2.0740 Training d_loss: 1.3855 Explore P: 0.4589\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 239 Total reward: 15.0 Average reward fake: 0.4994295835494995 Average reward real: 0.4999527633190155 Training q_loss: 2.4110 Training g_loss: 2.0767 Training d_loss: 1.3853 Explore P: 0.4582\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 240 Total reward: 82.0 Average reward fake: 0.49981072545051575 Average reward real: 0.5007098913192749 Training q_loss: 2.5109 Training g_loss: 2.0754 Training d_loss: 1.3845 Explore P: 0.4546\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 241 Total reward: 51.0 Average reward fake: 0.500479519367218 Average reward real: 0.5002803206443787 Training q_loss: 2.3335 Training g_loss: 2.0672 Training d_loss: 1.3866 Explore P: 0.4523\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 242 Total reward: 25.0 Average reward fake: 0.4998162090778351 Average reward real: 0.5007034540176392 Training q_loss: 2.4587 Training g_loss: 2.0761 Training d_loss: 1.3848 Explore P: 0.4512\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 243 Total reward: 32.0 Average reward fake: 0.5001571178436279 Average reward real: 0.49952566623687744 Training q_loss: 2.1209 Training g_loss: 2.0739 Training d_loss: 1.3876 Explore P: 0.4498\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 244 Total reward: 72.0 Average reward fake: 0.499327689409256 Average reward real: 0.5004236698150635 Training q_loss: 2.7627 Training g_loss: 2.0729 Training d_loss: 1.3843 Explore P: 0.4466\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 245 Total reward: 38.0 Average reward fake: 0.49953845143318176 Average reward real: 0.5006900429725647 Training q_loss: 2.6343 Training g_loss: 2.0835 Training d_loss: 1.3841 Explore P: 0.4450\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 246 Total reward: 15.0 Average reward fake: 0.500478208065033 Average reward real: 0.5008987188339233 Training q_loss: 2.6140 Training g_loss: 2.0716 Training d_loss: 1.3855 Explore P: 0.4443\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 247 Total reward: 17.0 Average reward fake: 0.49929144978523254 Average reward real: 0.5001531839370728 Training q_loss: 2.4195 Training g_loss: 2.0734 Training d_loss: 1.3847 Explore P: 0.4436\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 248 Total reward: 64.0 Average reward fake: 0.4993728995323181 Average reward real: 0.49962103366851807 Training q_loss: 2.4045 Training g_loss: 2.0776 Training d_loss: 1.3860 Explore P: 0.4408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 249 Total reward: 55.0 Average reward fake: 0.49993008375167847 Average reward real: 0.4997026026248932 Training q_loss: 2.5595 Training g_loss: 2.0690 Training d_loss: 1.3866 Explore P: 0.4385\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 250 Total reward: 43.0 Average reward fake: 0.4997401535511017 Average reward real: 0.49991554021835327 Training q_loss: 2.7977 Training g_loss: 2.0725 Training d_loss: 1.3860 Explore P: 0.4366\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 251 Total reward: 30.0 Average reward fake: 0.5000575184822083 Average reward real: 0.4999508261680603 Training q_loss: 2.4476 Training g_loss: 2.0699 Training d_loss: 1.3865 Explore P: 0.4353\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 252 Total reward: 35.0 Average reward fake: 0.499418169260025 Average reward real: 0.5005521178245544 Training q_loss: 2.9287 Training g_loss: 2.0716 Training d_loss: 1.3843 Explore P: 0.4339\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 253 Total reward: 59.0 Average reward fake: 0.4996771216392517 Average reward real: 0.4993983507156372 Training q_loss: 2.9747 Training g_loss: 2.0798 Training d_loss: 1.3869 Explore P: 0.4314\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 254 Total reward: 35.0 Average reward fake: 0.5012040734291077 Average reward real: 0.5007290840148926 Training q_loss: 2.4865 Training g_loss: 2.0736 Training d_loss: 1.3869 Explore P: 0.4299\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 255 Total reward: 81.0 Average reward fake: 0.5006187558174133 Average reward real: 0.500103771686554 Training q_loss: 2.3693 Training g_loss: 2.0716 Training d_loss: 1.3873 Explore P: 0.4265\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 256 Total reward: 32.0 Average reward fake: 0.5011336803436279 Average reward real: 0.5005390048027039 Training q_loss: 2.4836 Training g_loss: 2.0705 Training d_loss: 1.3875 Explore P: 0.4252\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 257 Total reward: 35.0 Average reward fake: 0.4996976852416992 Average reward real: 0.4998358190059662 Training q_loss: 2.3693 Training g_loss: 2.0826 Training d_loss: 1.3863 Explore P: 0.4237\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 258 Total reward: 36.0 Average reward fake: 0.5005586743354797 Average reward real: 0.5010452270507812 Training q_loss: 2.4359 Training g_loss: 2.0669 Training d_loss: 1.3857 Explore P: 0.4222\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 259 Total reward: 70.0 Average reward fake: 0.5002074241638184 Average reward real: 0.5003253221511841 Training q_loss: 2.4002 Training g_loss: 2.0715 Training d_loss: 1.3863 Explore P: 0.4194\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 260 Total reward: 17.0 Average reward fake: 0.49947836995124817 Average reward real: 0.4994101822376251 Training q_loss: 2.3701 Training g_loss: 2.0798 Training d_loss: 1.3865 Explore P: 0.4187\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 261 Total reward: 52.0 Average reward fake: 0.5000243186950684 Average reward real: 0.5002808570861816 Training q_loss: 2.3472 Training g_loss: 2.0779 Training d_loss: 1.3859 Explore P: 0.4165\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 262 Total reward: 40.0 Average reward fake: 0.49949783086776733 Average reward real: 0.499144971370697 Training q_loss: 2.5511 Training g_loss: 2.0718 Training d_loss: 1.3872 Explore P: 0.4149\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 263 Total reward: 22.0 Average reward fake: 0.4998619556427002 Average reward real: 0.5001556873321533 Training q_loss: 2.7271 Training g_loss: 2.0692 Training d_loss: 1.3857 Explore P: 0.4140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 264 Total reward: 38.0 Average reward fake: 0.5008611083030701 Average reward real: 0.5016490817070007 Training q_loss: 2.7268 Training g_loss: 2.0725 Training d_loss: 1.3849 Explore P: 0.4125\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 265 Total reward: 14.0 Average reward fake: 0.5003381967544556 Average reward real: 0.5009585022926331 Training q_loss: 2.2056 Training g_loss: 2.0703 Training d_loss: 1.3856 Explore P: 0.4119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 266 Total reward: 74.0 Average reward fake: 0.5003417730331421 Average reward real: 0.4998839497566223 Training q_loss: 4.5241 Training g_loss: 2.0728 Training d_loss: 1.3870 Explore P: 0.4090\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 267 Total reward: 47.0 Average reward fake: 0.4999200403690338 Average reward real: 0.49968841671943665 Training q_loss: 2.6612 Training g_loss: 2.0711 Training d_loss: 1.3866 Explore P: 0.4071\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 268 Total reward: 15.0 Average reward fake: 0.5000876784324646 Average reward real: 0.5002564191818237 Training q_loss: 2.7409 Training g_loss: 2.0754 Training d_loss: 1.3864 Explore P: 0.4065\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 269 Total reward: 43.0 Average reward fake: 0.5003917813301086 Average reward real: 0.5000944137573242 Training q_loss: 2.5330 Training g_loss: 2.0750 Training d_loss: 1.3870 Explore P: 0.4048\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 270 Total reward: 62.0 Average reward fake: 0.5000565052032471 Average reward real: 0.5001171231269836 Training q_loss: 2.7290 Training g_loss: 2.0704 Training d_loss: 1.3865 Explore P: 0.4024\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 271 Total reward: 33.0 Average reward fake: 0.49977028369903564 Average reward real: 0.500592827796936 Training q_loss: 2.5680 Training g_loss: 2.0712 Training d_loss: 1.3847 Explore P: 0.4011\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 272 Total reward: 35.0 Average reward fake: 0.49923065304756165 Average reward real: 0.499923437833786 Training q_loss: 2.1671 Training g_loss: 2.0743 Training d_loss: 1.3848 Explore P: 0.3997\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 273 Total reward: 47.0 Average reward fake: 0.4999690353870392 Average reward real: 0.5001264214515686 Training q_loss: 2.8515 Training g_loss: 2.0732 Training d_loss: 1.3861 Explore P: 0.3979\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 274 Total reward: 25.0 Average reward fake: 0.5001780986785889 Average reward real: 0.5006970763206482 Training q_loss: 2.3781 Training g_loss: 2.0684 Training d_loss: 1.3854 Explore P: 0.3969\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 275 Total reward: 87.0 Average reward fake: 0.4991665780544281 Average reward real: 0.4994798004627228 Training q_loss: 2.6271 Training g_loss: 2.0709 Training d_loss: 1.3858 Explore P: 0.3936\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 276 Total reward: 44.0 Average reward fake: 0.4991869330406189 Average reward real: 0.4998537302017212 Training q_loss: 2.1741 Training g_loss: 2.0759 Training d_loss: 1.3850 Explore P: 0.3919\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 277 Total reward: 67.0 Average reward fake: 0.5009555816650391 Average reward real: 0.5006891489028931 Training q_loss: 2.1097 Training g_loss: 2.0697 Training d_loss: 1.3859 Explore P: 0.3893\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 278 Total reward: 35.0 Average reward fake: 0.5001368522644043 Average reward real: 0.5004146695137024 Training q_loss: 2.4805 Training g_loss: 2.0778 Training d_loss: 1.3856 Explore P: 0.3880\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 279 Total reward: 52.0 Average reward fake: 0.5003251433372498 Average reward real: 0.5014774203300476 Training q_loss: 2.3656 Training g_loss: 2.0688 Training d_loss: 1.3841 Explore P: 0.3860\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 280 Total reward: 37.0 Average reward fake: 0.49953651428222656 Average reward real: 0.4999455213546753 Training q_loss: 2.3363 Training g_loss: 2.0751 Training d_loss: 1.3854 Explore P: 0.3847\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 281 Total reward: 42.0 Average reward fake: 0.49943068623542786 Average reward real: 0.5005871653556824 Training q_loss: 2.2068 Training g_loss: 2.0772 Training d_loss: 1.3841 Explore P: 0.3831\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 282 Total reward: 39.0 Average reward fake: 0.4994269609451294 Average reward real: 0.5004704594612122 Training q_loss: 2.5845 Training g_loss: 2.0732 Training d_loss: 1.3842 Explore P: 0.3816\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 283 Total reward: 75.0 Average reward fake: 0.5010700821876526 Average reward real: 0.49995627999305725 Training q_loss: 3.0405 Training g_loss: 2.0688 Training d_loss: 1.3884 Explore P: 0.3789\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 284 Total reward: 25.0 Average reward fake: 0.5002539753913879 Average reward real: 0.500465452671051 Training q_loss: 2.1872 Training g_loss: 2.0759 Training d_loss: 1.3857 Explore P: 0.3779\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 285 Total reward: 92.0 Average reward fake: 0.5000251531600952 Average reward real: 0.4993082284927368 Training q_loss: 3.7069 Training g_loss: 2.0749 Training d_loss: 1.3874 Explore P: 0.3746\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 286 Total reward: 79.0 Average reward fake: 0.5005672574043274 Average reward real: 0.5002075433731079 Training q_loss: 2.1225 Training g_loss: 2.0731 Training d_loss: 1.3869 Explore P: 0.3717\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 287 Total reward: 45.0 Average reward fake: 0.5005282163619995 Average reward real: 0.5000454187393188 Training q_loss: 2.3281 Training g_loss: 2.0730 Training d_loss: 1.3876 Explore P: 0.3701\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 288 Total reward: 35.0 Average reward fake: 0.5000792145729065 Average reward real: 0.500617504119873 Training q_loss: 2.1535 Training g_loss: 2.0696 Training d_loss: 1.3855 Explore P: 0.3688\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 289 Total reward: 46.0 Average reward fake: 0.5016435384750366 Average reward real: 0.49987098574638367 Training q_loss: 2.4137 Training g_loss: 2.0741 Training d_loss: 1.3897 Explore P: 0.3672\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 290 Total reward: 38.0 Average reward fake: 0.49967536330223083 Average reward real: 0.49977073073387146 Training q_loss: 2.1630 Training g_loss: 2.0734 Training d_loss: 1.3860 Explore P: 0.3658\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 291 Total reward: 28.0 Average reward fake: 0.4987632632255554 Average reward real: 0.499394029378891 Training q_loss: 4.2146 Training g_loss: 2.0756 Training d_loss: 1.3850 Explore P: 0.3648\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 292 Total reward: 233.0 Average reward fake: 0.4990045130252838 Average reward real: 0.4997168779373169 Training q_loss: 2.5406 Training g_loss: 2.0730 Training d_loss: 1.3849 Explore P: 0.3566\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 293 Total reward: 71.0 Average reward fake: 0.49982112646102905 Average reward real: 0.5004372596740723 Training q_loss: 2.4330 Training g_loss: 2.0786 Training d_loss: 1.3852 Explore P: 0.3542\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 294 Total reward: 99.0 Average reward fake: 0.49950966238975525 Average reward real: 0.500864565372467 Training q_loss: 3.0718 Training g_loss: 2.0730 Training d_loss: 1.3839 Explore P: 0.3508\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 295 Total reward: 15.0 Average reward fake: 0.498747855424881 Average reward real: 0.5004410743713379 Training q_loss: 2.1868 Training g_loss: 2.0785 Training d_loss: 1.3831 Explore P: 0.3503\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 296 Total reward: 45.0 Average reward fake: 0.5011948347091675 Average reward real: 0.500805675983429 Training q_loss: 2.2873 Training g_loss: 2.0731 Training d_loss: 1.3877 Explore P: 0.3488\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 297 Total reward: 31.0 Average reward fake: 0.4991806745529175 Average reward real: 0.4990242123603821 Training q_loss: 2.1785 Training g_loss: 2.0761 Training d_loss: 1.3865 Explore P: 0.3477\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 298 Total reward: 156.0 Average reward fake: 0.49925410747528076 Average reward real: 0.4995758831501007 Training q_loss: 2.2965 Training g_loss: 2.0728 Training d_loss: 1.3855 Explore P: 0.3425\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 299 Total reward: 30.0 Average reward fake: 0.49972304701805115 Average reward real: 0.49987584352493286 Training q_loss: 2.1235 Training g_loss: 2.0715 Training d_loss: 1.3861 Explore P: 0.3415\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 300 Total reward: 80.0 Average reward fake: 0.4999594986438751 Average reward real: 0.5000718832015991 Training q_loss: 2.1964 Training g_loss: 2.0738 Training d_loss: 1.3860 Explore P: 0.3389\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 301 Total reward: 10.0 Average reward fake: 0.5002045631408691 Average reward real: 0.5004885792732239 Training q_loss: 2.8281 Training g_loss: 2.0702 Training d_loss: 1.3859 Explore P: 0.3385\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 302 Total reward: 50.0 Average reward fake: 0.4995439648628235 Average reward real: 0.4995887279510498 Training q_loss: 2.1580 Training g_loss: 2.0761 Training d_loss: 1.3862 Explore P: 0.3369\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 303 Total reward: 42.0 Average reward fake: 0.5000325441360474 Average reward real: 0.4996833801269531 Training q_loss: 2.2384 Training g_loss: 2.0708 Training d_loss: 1.3874 Explore P: 0.3355\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 304 Total reward: 85.0 Average reward fake: 0.4997805655002594 Average reward real: 0.5001817941665649 Training q_loss: 2.5403 Training g_loss: 2.0731 Training d_loss: 1.3855 Explore P: 0.3328\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 305 Total reward: 55.0 Average reward fake: 0.4994070827960968 Average reward real: 0.4994088113307953 Training q_loss: 2.5284 Training g_loss: 2.0710 Training d_loss: 1.3864 Explore P: 0.3310\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 306 Total reward: 52.0 Average reward fake: 0.4999815821647644 Average reward real: 0.5001220703125 Training q_loss: 2.4007 Training g_loss: 2.0715 Training d_loss: 1.3861 Explore P: 0.3293\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 307 Total reward: 59.0 Average reward fake: 0.5004639625549316 Average reward real: 0.5006632208824158 Training q_loss: 2.3806 Training g_loss: 2.0712 Training d_loss: 1.3859 Explore P: 0.3274\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 308 Total reward: 27.0 Average reward fake: 0.49990615248680115 Average reward real: 0.4998483955860138 Training q_loss: 2.4921 Training g_loss: 2.0752 Training d_loss: 1.3868 Explore P: 0.3266\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 309 Total reward: 43.0 Average reward fake: 0.49936801195144653 Average reward real: 0.49997836351394653 Training q_loss: 2.5440 Training g_loss: 2.0731 Training d_loss: 1.3850 Explore P: 0.3252\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 310 Total reward: 37.0 Average reward fake: 0.5002442002296448 Average reward real: 0.5001828670501709 Training q_loss: 2.3460 Training g_loss: 2.0738 Training d_loss: 1.3862 Explore P: 0.3241\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 311 Total reward: 71.0 Average reward fake: 0.5002520084381104 Average reward real: 0.5003309845924377 Training q_loss: 2.1232 Training g_loss: 2.0736 Training d_loss: 1.3863 Explore P: 0.3218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 312 Total reward: 83.0 Average reward fake: 0.5002763867378235 Average reward real: 0.5002103447914124 Training q_loss: 2.4545 Training g_loss: 2.0722 Training d_loss: 1.3864 Explore P: 0.3193\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 313 Total reward: 36.0 Average reward fake: 0.5000215768814087 Average reward real: 0.5003024339675903 Training q_loss: 2.4064 Training g_loss: 2.0742 Training d_loss: 1.3859 Explore P: 0.3182\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 314 Total reward: 22.0 Average reward fake: 0.4995253086090088 Average reward real: 0.4998934864997864 Training q_loss: 3.1054 Training g_loss: 2.0741 Training d_loss: 1.3858 Explore P: 0.3175\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 315 Total reward: 111.0 Average reward fake: 0.5005439519882202 Average reward real: 0.5009795427322388 Training q_loss: 2.2382 Training g_loss: 2.0689 Training d_loss: 1.3857 Explore P: 0.3141\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 316 Total reward: 33.0 Average reward fake: 0.49989449977874756 Average reward real: 0.5003616213798523 Training q_loss: 2.2151 Training g_loss: 2.0731 Training d_loss: 1.3855 Explore P: 0.3131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 317 Total reward: 104.0 Average reward fake: 0.49950554966926575 Average reward real: 0.4995182752609253 Training q_loss: 2.4503 Training g_loss: 2.0732 Training d_loss: 1.3859 Explore P: 0.3099\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 318 Total reward: 45.0 Average reward fake: 0.4995213449001312 Average reward real: 0.4999522268772125 Training q_loss: 2.3092 Training g_loss: 2.0725 Training d_loss: 1.3855 Explore P: 0.3086\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 319 Total reward: 39.0 Average reward fake: 0.5001348257064819 Average reward real: 0.5003942847251892 Training q_loss: 2.3445 Training g_loss: 2.0696 Training d_loss: 1.3857 Explore P: 0.3074\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 320 Total reward: 47.0 Average reward fake: 0.4999591112136841 Average reward real: 0.49998924136161804 Training q_loss: 2.4438 Training g_loss: 2.0752 Training d_loss: 1.3862 Explore P: 0.3060\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 321 Total reward: 57.0 Average reward fake: 0.4997572600841522 Average reward real: 0.499984472990036 Training q_loss: 2.3726 Training g_loss: 2.0742 Training d_loss: 1.3858 Explore P: 0.3044\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 322 Total reward: 55.0 Average reward fake: 0.49994561076164246 Average reward real: 0.5001740455627441 Training q_loss: 2.4477 Training g_loss: 2.0757 Training d_loss: 1.3861 Explore P: 0.3027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 323 Total reward: 52.0 Average reward fake: 0.5000019073486328 Average reward real: 0.5011432766914368 Training q_loss: 2.7570 Training g_loss: 2.0727 Training d_loss: 1.3851 Explore P: 0.3012\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 324 Total reward: 79.0 Average reward fake: 0.49934622645378113 Average reward real: 0.49981391429901123 Training q_loss: 2.3989 Training g_loss: 2.0713 Training d_loss: 1.3855 Explore P: 0.2989\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 325 Total reward: 56.0 Average reward fake: 0.5000889301300049 Average reward real: 0.5004568696022034 Training q_loss: 2.1083 Training g_loss: 2.0705 Training d_loss: 1.3857 Explore P: 0.2973\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 326 Total reward: 77.0 Average reward fake: 0.4993615746498108 Average reward real: 0.4995589554309845 Training q_loss: 2.6085 Training g_loss: 2.0760 Training d_loss: 1.3856 Explore P: 0.2951\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 327 Total reward: 67.0 Average reward fake: 0.4997178018093109 Average reward real: 0.5003752708435059 Training q_loss: 2.1339 Training g_loss: 2.0726 Training d_loss: 1.3850 Explore P: 0.2932\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 328 Total reward: 38.0 Average reward fake: 0.49949410557746887 Average reward real: 0.5001599788665771 Training q_loss: 2.1513 Training g_loss: 2.0717 Training d_loss: 1.3850 Explore P: 0.2921\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 329 Total reward: 64.0 Average reward fake: 0.5001997351646423 Average reward real: 0.4997953772544861 Training q_loss: 3.7294 Training g_loss: 2.0747 Training d_loss: 1.3866 Explore P: 0.2903\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 330 Total reward: 31.0 Average reward fake: 0.500308632850647 Average reward real: 0.49989548325538635 Training q_loss: 2.4337 Training g_loss: 2.0703 Training d_loss: 1.3872 Explore P: 0.2895\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 331 Total reward: 23.0 Average reward fake: 0.5001056790351868 Average reward real: 0.5006455183029175 Training q_loss: 2.8077 Training g_loss: 2.0717 Training d_loss: 1.3851 Explore P: 0.2888\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 332 Total reward: 71.0 Average reward fake: 0.49868229031562805 Average reward real: 0.49903392791748047 Training q_loss: 2.6027 Training g_loss: 2.0765 Training d_loss: 1.3854 Explore P: 0.2869\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 333 Total reward: 39.0 Average reward fake: 0.49935516715049744 Average reward real: 0.5000285506248474 Training q_loss: 2.2402 Training g_loss: 2.0745 Training d_loss: 1.3850 Explore P: 0.2858\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 334 Total reward: 51.0 Average reward fake: 0.500449538230896 Average reward real: 0.5003750920295715 Training q_loss: 2.0797 Training g_loss: 2.0705 Training d_loss: 1.3866 Explore P: 0.2844\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 335 Total reward: 56.0 Average reward fake: 0.5000166893005371 Average reward real: 0.4995880126953125 Training q_loss: 2.9190 Training g_loss: 2.0744 Training d_loss: 1.3873 Explore P: 0.2828\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 336 Total reward: 92.0 Average reward fake: 0.5001827478408813 Average reward real: 0.5001654028892517 Training q_loss: 2.1426 Training g_loss: 2.0708 Training d_loss: 1.3863 Explore P: 0.2803\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 337 Total reward: 94.0 Average reward fake: 0.4999714195728302 Average reward real: 0.4999338388442993 Training q_loss: 2.7252 Training g_loss: 2.0760 Training d_loss: 1.3866 Explore P: 0.2778\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 338 Total reward: 47.0 Average reward fake: 0.499275803565979 Average reward real: 0.5002886056900024 Training q_loss: 2.3591 Training g_loss: 2.0725 Training d_loss: 1.3843 Explore P: 0.2766\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 339 Total reward: 51.0 Average reward fake: 0.49931734800338745 Average reward real: 0.500329315662384 Training q_loss: 2.1821 Training g_loss: 2.0722 Training d_loss: 1.3844 Explore P: 0.2752\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 340 Total reward: 54.0 Average reward fake: 0.499927818775177 Average reward real: 0.5010961294174194 Training q_loss: 2.3641 Training g_loss: 2.0721 Training d_loss: 1.3843 Explore P: 0.2738\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 341 Total reward: 89.0 Average reward fake: 0.5006200671195984 Average reward real: 0.49992436170578003 Training q_loss: 2.0823 Training g_loss: 2.0711 Training d_loss: 1.3877 Explore P: 0.2714\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 342 Total reward: 78.0 Average reward fake: 0.4994482398033142 Average reward real: 0.5001895427703857 Training q_loss: 2.3606 Training g_loss: 2.0714 Training d_loss: 1.3853 Explore P: 0.2694\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 343 Total reward: 79.0 Average reward fake: 0.49982959032058716 Average reward real: 0.4999006688594818 Training q_loss: 2.1486 Training g_loss: 2.0749 Training d_loss: 1.3861 Explore P: 0.2674\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 344 Total reward: 26.0 Average reward fake: 0.49957138299942017 Average reward real: 0.4999176859855652 Training q_loss: 2.1640 Training g_loss: 2.0717 Training d_loss: 1.3857 Explore P: 0.2667\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 345 Total reward: 25.0 Average reward fake: 0.49962469935417175 Average reward real: 0.5000426173210144 Training q_loss: 2.3000 Training g_loss: 2.0704 Training d_loss: 1.3853 Explore P: 0.2661\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 346 Total reward: 53.0 Average reward fake: 0.49950793385505676 Average reward real: 0.4996408224105835 Training q_loss: 2.1288 Training g_loss: 2.0715 Training d_loss: 1.3855 Explore P: 0.2647\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 347 Total reward: 32.0 Average reward fake: 0.49985969066619873 Average reward real: 0.5002177953720093 Training q_loss: 2.3965 Training g_loss: 2.0739 Training d_loss: 1.3856 Explore P: 0.2639\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 348 Total reward: 20.0 Average reward fake: 0.4995178282260895 Average reward real: 0.5000252723693848 Training q_loss: 2.2183 Training g_loss: 2.0748 Training d_loss: 1.3852 Explore P: 0.2634\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 349 Total reward: 75.0 Average reward fake: 0.49938929080963135 Average reward real: 0.500494658946991 Training q_loss: 2.2899 Training g_loss: 2.0760 Training d_loss: 1.3842 Explore P: 0.2615\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 350 Total reward: 51.0 Average reward fake: 0.499492883682251 Average reward real: 0.5000115633010864 Training q_loss: 2.3119 Training g_loss: 2.0743 Training d_loss: 1.3853 Explore P: 0.2602\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 351 Total reward: 71.0 Average reward fake: 0.49970269203186035 Average reward real: 0.500082790851593 Training q_loss: 2.3979 Training g_loss: 2.0725 Training d_loss: 1.3861 Explore P: 0.2584\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 352 Total reward: 136.0 Average reward fake: 0.49996626377105713 Average reward real: 0.49988266825675964 Training q_loss: 2.5249 Training g_loss: 2.0716 Training d_loss: 1.3866 Explore P: 0.2551\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 353 Total reward: 49.0 Average reward fake: 0.49976104497909546 Average reward real: 0.5001779794692993 Training q_loss: 2.3138 Training g_loss: 2.0720 Training d_loss: 1.3855 Explore P: 0.2539\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 354 Total reward: 40.0 Average reward fake: 0.4995632469654083 Average reward real: 0.5002004504203796 Training q_loss: 2.2271 Training g_loss: 2.0760 Training d_loss: 1.3851 Explore P: 0.2529\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 355 Total reward: 38.0 Average reward fake: 0.5006305575370789 Average reward real: 0.5009401440620422 Training q_loss: 2.3085 Training g_loss: 2.0713 Training d_loss: 1.3859 Explore P: 0.2520\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 356 Total reward: 83.0 Average reward fake: 0.49926406145095825 Average reward real: 0.4993348717689514 Training q_loss: 2.3420 Training g_loss: 2.0733 Training d_loss: 1.3863 Explore P: 0.2500\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 357 Total reward: 39.0 Average reward fake: 0.4995787441730499 Average reward real: 0.500128448009491 Training q_loss: 2.3530 Training g_loss: 2.0710 Training d_loss: 1.3858 Explore P: 0.2491\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 358 Total reward: 60.0 Average reward fake: 0.49986526370048523 Average reward real: 0.4995954930782318 Training q_loss: 2.5122 Training g_loss: 2.0779 Training d_loss: 1.3866 Explore P: 0.2476\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 359 Total reward: 68.0 Average reward fake: 0.4993795156478882 Average reward real: 0.49918419122695923 Training q_loss: 2.2172 Training g_loss: 2.0720 Training d_loss: 1.3870 Explore P: 0.2460\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 360 Total reward: 117.0 Average reward fake: 0.5002278685569763 Average reward real: 0.4998873174190521 Training q_loss: 2.4978 Training g_loss: 2.0746 Training d_loss: 1.3871 Explore P: 0.2433\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 361 Total reward: 55.0 Average reward fake: 0.5002219080924988 Average reward real: 0.4999633729457855 Training q_loss: 2.2594 Training g_loss: 2.0743 Training d_loss: 1.3869 Explore P: 0.2420\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 362 Total reward: 134.0 Average reward fake: 0.500144362449646 Average reward real: 0.49969282746315 Training q_loss: 5.4410 Training g_loss: 2.0783 Training d_loss: 1.3875 Explore P: 0.2389\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 363 Total reward: 56.0 Average reward fake: 0.4994814395904541 Average reward real: 0.500192403793335 Training q_loss: 2.3049 Training g_loss: 2.0721 Training d_loss: 1.3850 Explore P: 0.2376\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 364 Total reward: 81.0 Average reward fake: 0.49913322925567627 Average reward real: 0.4991409182548523 Training q_loss: 2.6881 Training g_loss: 2.0736 Training d_loss: 1.3863 Explore P: 0.2358\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 365 Total reward: 79.0 Average reward fake: 0.49950942397117615 Average reward real: 0.5002180337905884 Training q_loss: 2.2534 Training g_loss: 2.0735 Training d_loss: 1.3850 Explore P: 0.2340\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 366 Total reward: 58.0 Average reward fake: 0.4997001886367798 Average reward real: 0.49993622303009033 Training q_loss: 2.2398 Training g_loss: 2.0702 Training d_loss: 1.3859 Explore P: 0.2327\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 367 Total reward: 68.0 Average reward fake: 0.4997771382331848 Average reward real: 0.4997261166572571 Training q_loss: 2.1406 Training g_loss: 2.0735 Training d_loss: 1.3864 Explore P: 0.2312\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 368 Total reward: 33.0 Average reward fake: 0.4995878338813782 Average reward real: 0.4993726313114166 Training q_loss: 2.1730 Training g_loss: 2.0700 Training d_loss: 1.3868 Explore P: 0.2305\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 369 Total reward: 28.0 Average reward fake: 0.4999045431613922 Average reward real: 0.5000360012054443 Training q_loss: 2.1593 Training g_loss: 2.0752 Training d_loss: 1.3863 Explore P: 0.2299\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 370 Total reward: 64.0 Average reward fake: 0.49959731101989746 Average reward real: 0.49962425231933594 Training q_loss: 2.2511 Training g_loss: 2.0726 Training d_loss: 1.3863 Explore P: 0.2285\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 371 Total reward: 60.0 Average reward fake: 0.49926894903182983 Average reward real: 0.4997083246707916 Training q_loss: 2.1646 Training g_loss: 2.0736 Training d_loss: 1.3855 Explore P: 0.2272\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 372 Total reward: 39.0 Average reward fake: 0.4998215436935425 Average reward real: 0.5001367926597595 Training q_loss: 2.1995 Training g_loss: 2.0770 Training d_loss: 1.3861 Explore P: 0.2263\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 373 Total reward: 40.0 Average reward fake: 0.5005081295967102 Average reward real: 0.5006141066551208 Training q_loss: 2.4052 Training g_loss: 2.0759 Training d_loss: 1.3861 Explore P: 0.2254\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 374 Total reward: 30.0 Average reward fake: 0.5002133250236511 Average reward real: 0.5007356405258179 Training q_loss: 2.1567 Training g_loss: 2.0775 Training d_loss: 1.3853 Explore P: 0.2248\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 375 Total reward: 64.0 Average reward fake: 0.49939846992492676 Average reward real: 0.49973374605178833 Training q_loss: 2.1899 Training g_loss: 2.0749 Training d_loss: 1.3858 Explore P: 0.2234\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 376 Total reward: 64.0 Average reward fake: 0.4999896287918091 Average reward real: 0.5002959370613098 Training q_loss: 2.2709 Training g_loss: 2.0815 Training d_loss: 1.3857 Explore P: 0.2221\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 377 Total reward: 61.0 Average reward fake: 0.4999539852142334 Average reward real: 0.5000823736190796 Training q_loss: 2.2674 Training g_loss: 2.0771 Training d_loss: 1.3860 Explore P: 0.2208\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 378 Total reward: 41.0 Average reward fake: 0.49941879510879517 Average reward real: 0.49970367550849915 Training q_loss: 2.2643 Training g_loss: 2.0756 Training d_loss: 1.3858 Explore P: 0.2199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 379 Total reward: 33.0 Average reward fake: 0.5003087520599365 Average reward real: 0.5004180669784546 Training q_loss: 2.2047 Training g_loss: 2.0732 Training d_loss: 1.3860 Explore P: 0.2192\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 380 Total reward: 86.0 Average reward fake: 0.49945682287216187 Average reward real: 0.5000021457672119 Training q_loss: 2.4753 Training g_loss: 2.0705 Training d_loss: 1.3852 Explore P: 0.2174\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 381 Total reward: 44.0 Average reward fake: 0.4997023046016693 Average reward real: 0.5001022219657898 Training q_loss: 2.2422 Training g_loss: 2.0822 Training d_loss: 1.3855 Explore P: 0.2165\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 382 Total reward: 57.0 Average reward fake: 0.5010908246040344 Average reward real: 0.5010631680488586 Training q_loss: 2.5553 Training g_loss: 2.0705 Training d_loss: 1.3866 Explore P: 0.2153\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 383 Total reward: 56.0 Average reward fake: 0.49945494532585144 Average reward real: 0.4989680349826813 Training q_loss: 2.5302 Training g_loss: 2.0748 Training d_loss: 1.3872 Explore P: 0.2142\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 384 Total reward: 42.0 Average reward fake: 0.4996418058872223 Average reward real: 0.5005406141281128 Training q_loss: 2.5726 Training g_loss: 2.0726 Training d_loss: 1.3847 Explore P: 0.2133\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 385 Total reward: 28.0 Average reward fake: 0.49956876039505005 Average reward real: 0.49947142601013184 Training q_loss: 2.1805 Training g_loss: 2.0711 Training d_loss: 1.3864 Explore P: 0.2128\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 386 Total reward: 108.0 Average reward fake: 0.5002638101577759 Average reward real: 0.5001487731933594 Training q_loss: 2.2261 Training g_loss: 2.0728 Training d_loss: 1.3867 Explore P: 0.2106\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 387 Total reward: 37.0 Average reward fake: 0.49943551421165466 Average reward real: 0.4992940127849579 Training q_loss: 2.5165 Training g_loss: 2.0760 Training d_loss: 1.3866 Explore P: 0.2099\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 388 Total reward: 78.0 Average reward fake: 0.5004512071609497 Average reward real: 0.5003098249435425 Training q_loss: 2.1816 Training g_loss: 2.0730 Training d_loss: 1.3866 Explore P: 0.2083\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 389 Total reward: 40.0 Average reward fake: 0.4995515048503876 Average reward real: 0.4998281002044678 Training q_loss: 2.1977 Training g_loss: 2.0760 Training d_loss: 1.3859 Explore P: 0.2075\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 390 Total reward: 88.0 Average reward fake: 0.4998131990432739 Average reward real: 0.5002665519714355 Training q_loss: 2.3562 Training g_loss: 2.0723 Training d_loss: 1.3858 Explore P: 0.2058\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 391 Total reward: 40.0 Average reward fake: 0.5010473728179932 Average reward real: 0.49953675270080566 Training q_loss: 7.9485 Training g_loss: 2.0757 Training d_loss: 1.3912 Explore P: 0.2050\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 392 Total reward: 64.0 Average reward fake: 0.5000414848327637 Average reward real: 0.5001943707466125 Training q_loss: 2.1112 Training g_loss: 2.0711 Training d_loss: 1.3862 Explore P: 0.2038\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 393 Total reward: 43.0 Average reward fake: 0.499857097864151 Average reward real: 0.4999273717403412 Training q_loss: 2.2632 Training g_loss: 2.0741 Training d_loss: 1.3863 Explore P: 0.2029\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 394 Total reward: 32.0 Average reward fake: 0.5004364252090454 Average reward real: 0.5006994605064392 Training q_loss: 2.3853 Training g_loss: 2.0728 Training d_loss: 1.3860 Explore P: 0.2023\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 395 Total reward: 153.0 Average reward fake: 0.4993346333503723 Average reward real: 0.49947068095207214 Training q_loss: 2.2465 Training g_loss: 2.0754 Training d_loss: 1.3860 Explore P: 0.1994\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 396 Total reward: 42.0 Average reward fake: 0.49952632188796997 Average reward real: 0.5004186034202576 Training q_loss: 2.4364 Training g_loss: 2.0753 Training d_loss: 1.3845 Explore P: 0.1986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 397 Total reward: 45.0 Average reward fake: 0.5001897215843201 Average reward real: 0.5000836253166199 Training q_loss: 2.2101 Training g_loss: 2.0796 Training d_loss: 1.3867 Explore P: 0.1977\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 398 Total reward: 35.0 Average reward fake: 0.49953940510749817 Average reward real: 0.4999617636203766 Training q_loss: 2.0875 Training g_loss: 2.0741 Training d_loss: 1.3855 Explore P: 0.1971\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 399 Total reward: 55.0 Average reward fake: 0.5005289316177368 Average reward real: 0.5001444816589355 Training q_loss: 2.1366 Training g_loss: 2.0801 Training d_loss: 1.3869 Explore P: 0.1961\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 400 Total reward: 61.0 Average reward fake: 0.500302791595459 Average reward real: 0.5000285506248474 Training q_loss: 3.4096 Training g_loss: 2.0750 Training d_loss: 1.3871 Explore P: 0.1949\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 401 Total reward: 33.0 Average reward fake: 0.49967941641807556 Average reward real: 0.49941936135292053 Training q_loss: 2.2566 Training g_loss: 2.0774 Training d_loss: 1.3871 Explore P: 0.1943\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 402 Total reward: 53.0 Average reward fake: 0.5002267360687256 Average reward real: 0.5004522204399109 Training q_loss: 2.2868 Training g_loss: 2.0715 Training d_loss: 1.3860 Explore P: 0.1934\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 403 Total reward: 53.0 Average reward fake: 0.5005459189414978 Average reward real: 0.5006788372993469 Training q_loss: 2.2648 Training g_loss: 2.0756 Training d_loss: 1.3860 Explore P: 0.1924\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 404 Total reward: 71.0 Average reward fake: 0.5018770098686218 Average reward real: 0.5019290447235107 Training q_loss: 2.1248 Training g_loss: 2.0714 Training d_loss: 1.3861 Explore P: 0.1911\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 405 Total reward: 42.0 Average reward fake: 0.49937015771865845 Average reward real: 0.4998929500579834 Training q_loss: 2.3143 Training g_loss: 2.0772 Training d_loss: 1.3852 Explore P: 0.1903\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 406 Total reward: 39.0 Average reward fake: 0.4994319677352905 Average reward real: 0.49965691566467285 Training q_loss: 3.5731 Training g_loss: 2.0730 Training d_loss: 1.3859 Explore P: 0.1896\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 407 Total reward: 85.0 Average reward fake: 0.5003560781478882 Average reward real: 0.5009357929229736 Training q_loss: 2.4092 Training g_loss: 2.0759 Training d_loss: 1.3852 Explore P: 0.1881\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 408 Total reward: 52.0 Average reward fake: 0.4991137683391571 Average reward real: 0.4995873272418976 Training q_loss: 2.2701 Training g_loss: 2.0755 Training d_loss: 1.3856 Explore P: 0.1872\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 409 Total reward: 25.0 Average reward fake: 0.49921339750289917 Average reward real: 0.500196635723114 Training q_loss: 2.1248 Training g_loss: 2.0717 Training d_loss: 1.3843 Explore P: 0.1867\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 410 Total reward: 103.0 Average reward fake: 0.5000021457672119 Average reward real: 0.5005764365196228 Training q_loss: 2.1612 Training g_loss: 2.0753 Training d_loss: 1.3854 Explore P: 0.1849\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 411 Total reward: 31.0 Average reward fake: 0.5000985860824585 Average reward real: 0.4997546374797821 Training q_loss: 2.1861 Training g_loss: 2.0757 Training d_loss: 1.3872 Explore P: 0.1844\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 412 Total reward: 59.0 Average reward fake: 0.4996676743030548 Average reward real: 0.49947723746299744 Training q_loss: 2.1408 Training g_loss: 2.0734 Training d_loss: 1.3867 Explore P: 0.1834\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 413 Total reward: 156.0 Average reward fake: 0.49974703788757324 Average reward real: 0.4984811544418335 Training q_loss: 3.1678 Training g_loss: 2.0756 Training d_loss: 1.3896 Explore P: 0.1807\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 414 Total reward: 115.0 Average reward fake: 0.5002220869064331 Average reward real: 0.49967291951179504 Training q_loss: 2.5738 Training g_loss: 2.0753 Training d_loss: 1.3871 Explore P: 0.1787\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 415 Total reward: 32.0 Average reward fake: 0.500785768032074 Average reward real: 0.500339150428772 Training q_loss: 2.3674 Training g_loss: 2.0758 Training d_loss: 1.3873 Explore P: 0.1782\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 416 Total reward: 39.0 Average reward fake: 0.4994925260543823 Average reward real: 0.4998822808265686 Training q_loss: 2.1977 Training g_loss: 2.0736 Training d_loss: 1.3855 Explore P: 0.1775\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 417 Total reward: 41.0 Average reward fake: 0.49983224272727966 Average reward real: 0.5004615783691406 Training q_loss: 2.1690 Training g_loss: 2.0772 Training d_loss: 1.3851 Explore P: 0.1769\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 418 Total reward: 38.0 Average reward fake: 0.5012962818145752 Average reward real: 0.5008678436279297 Training q_loss: 2.1079 Training g_loss: 2.0713 Training d_loss: 1.3891 Explore P: 0.1762\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 419 Total reward: 52.0 Average reward fake: 0.4992581307888031 Average reward real: 0.49953505396842957 Training q_loss: 2.1005 Training g_loss: 2.0762 Training d_loss: 1.3857 Explore P: 0.1754\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 420 Total reward: 59.0 Average reward fake: 0.5024498105049133 Average reward real: 0.49860817193984985 Training q_loss: 2.1135 Training g_loss: 2.0730 Training d_loss: 1.3965 Explore P: 0.1744\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 421 Total reward: 47.0 Average reward fake: 0.5003515481948853 Average reward real: 0.4995138645172119 Training q_loss: 2.1876 Training g_loss: 2.0721 Training d_loss: 1.3881 Explore P: 0.1736\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 422 Total reward: 38.0 Average reward fake: 0.4998321235179901 Average reward real: 0.5000588893890381 Training q_loss: 2.1787 Training g_loss: 2.0740 Training d_loss: 1.3859 Explore P: 0.1730\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 423 Total reward: 21.0 Average reward fake: 0.49950602650642395 Average reward real: 0.5000964999198914 Training q_loss: 2.2481 Training g_loss: 2.0734 Training d_loss: 1.3852 Explore P: 0.1727\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 424 Total reward: 33.0 Average reward fake: 0.4997135400772095 Average reward real: 0.49991467595100403 Training q_loss: 2.7696 Training g_loss: 2.0770 Training d_loss: 1.3860 Explore P: 0.1721\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 425 Total reward: 74.0 Average reward fake: 0.4998442828655243 Average reward real: 0.5004451870918274 Training q_loss: 2.1090 Training g_loss: 2.0735 Training d_loss: 1.3851 Explore P: 0.1709\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 426 Total reward: 125.0 Average reward fake: 0.49948281049728394 Average reward real: 0.49961337447166443 Training q_loss: 2.1952 Training g_loss: 2.0751 Training d_loss: 1.3859 Explore P: 0.1689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 427 Total reward: 71.0 Average reward fake: 0.5001052618026733 Average reward real: 0.5007454752922058 Training q_loss: 2.5851 Training g_loss: 2.0729 Training d_loss: 1.3850 Explore P: 0.1678\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 428 Total reward: 33.0 Average reward fake: 0.49966609477996826 Average reward real: 0.5006940364837646 Training q_loss: 2.2104 Training g_loss: 2.0771 Training d_loss: 1.3846 Explore P: 0.1673\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 429 Total reward: 126.0 Average reward fake: 0.4998339116573334 Average reward real: 0.5003292560577393 Training q_loss: 2.1199 Training g_loss: 2.0733 Training d_loss: 1.3853 Explore P: 0.1653\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 430 Total reward: 73.0 Average reward fake: 0.49928343296051025 Average reward real: 0.5008267164230347 Training q_loss: 2.1810 Training g_loss: 2.0785 Training d_loss: 1.3833 Explore P: 0.1642\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 431 Total reward: 50.0 Average reward fake: 0.49929794669151306 Average reward real: 0.49934110045433044 Training q_loss: 2.2041 Training g_loss: 2.0732 Training d_loss: 1.3863 Explore P: 0.1634\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 432 Total reward: 78.0 Average reward fake: 0.49998241662979126 Average reward real: 0.5005093216896057 Training q_loss: 2.4047 Training g_loss: 2.0723 Training d_loss: 1.3854 Explore P: 0.1622\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 433 Total reward: 45.0 Average reward fake: 0.5039350390434265 Average reward real: 0.49584734439849854 Training q_loss: 2.2098 Training g_loss: 2.0895 Training d_loss: 1.4011 Explore P: 0.1615\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 434 Total reward: 48.0 Average reward fake: 0.49931931495666504 Average reward real: 0.4986538589000702 Training q_loss: 2.1576 Training g_loss: 2.0786 Training d_loss: 1.3876 Explore P: 0.1608\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 435 Total reward: 46.0 Average reward fake: 0.4999314248561859 Average reward real: 0.5000205039978027 Training q_loss: 2.3428 Training g_loss: 2.0714 Training d_loss: 1.3862 Explore P: 0.1601\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 436 Total reward: 61.0 Average reward fake: 0.4993884563446045 Average reward real: 0.4995216429233551 Training q_loss: 2.2432 Training g_loss: 2.0767 Training d_loss: 1.3860 Explore P: 0.1592\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 437 Total reward: 60.0 Average reward fake: 0.49964526295661926 Average reward real: 0.4998844265937805 Training q_loss: 2.2356 Training g_loss: 2.0736 Training d_loss: 1.3858 Explore P: 0.1583\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 438 Total reward: 99.0 Average reward fake: 0.49958938360214233 Average reward real: 0.5000059008598328 Training q_loss: 2.1745 Training g_loss: 2.0780 Training d_loss: 1.3855 Explore P: 0.1568\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 439 Total reward: 54.0 Average reward fake: 0.4998452365398407 Average reward real: 0.5005283355712891 Training q_loss: 2.1223 Training g_loss: 2.0742 Training d_loss: 1.3850 Explore P: 0.1561\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 440 Total reward: 31.0 Average reward fake: 0.49948838353157043 Average reward real: 0.49983108043670654 Training q_loss: 2.1712 Training g_loss: 2.0723 Training d_loss: 1.3856 Explore P: 0.1556\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 441 Total reward: 34.0 Average reward fake: 0.4993729293346405 Average reward real: 0.5001296997070312 Training q_loss: 2.8595 Training g_loss: 2.0752 Training d_loss: 1.3851 Explore P: 0.1551\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 442 Total reward: 135.0 Average reward fake: 0.5022627711296082 Average reward real: 0.4997212886810303 Training q_loss: 2.4152 Training g_loss: 2.0775 Training d_loss: 1.3931 Explore P: 0.1532\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 443 Total reward: 89.0 Average reward fake: 0.499532014131546 Average reward real: 0.4998633563518524 Training q_loss: 2.2573 Training g_loss: 2.0769 Training d_loss: 1.3856 Explore P: 0.1519\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 444 Total reward: 41.0 Average reward fake: 0.49956443905830383 Average reward real: 0.5002131462097168 Training q_loss: 2.1323 Training g_loss: 2.0765 Training d_loss: 1.3851 Explore P: 0.1513\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 445 Total reward: 127.0 Average reward fake: 0.5002171993255615 Average reward real: 0.5003743171691895 Training q_loss: 2.3600 Training g_loss: 2.0748 Training d_loss: 1.3862 Explore P: 0.1495\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 446 Total reward: 146.0 Average reward fake: 0.4994259774684906 Average reward real: 0.5000557899475098 Training q_loss: 3.3683 Training g_loss: 2.0757 Training d_loss: 1.3847 Explore P: 0.1475\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 447 Total reward: 52.0 Average reward fake: 0.5001567602157593 Average reward real: 0.5006522536277771 Training q_loss: 3.3113 Training g_loss: 2.0777 Training d_loss: 1.3851 Explore P: 0.1468\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 448 Total reward: 36.0 Average reward fake: 0.4996168613433838 Average reward real: 0.5004485249519348 Training q_loss: 2.5313 Training g_loss: 2.0747 Training d_loss: 1.3858 Explore P: 0.1463\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 449 Total reward: 46.0 Average reward fake: 0.4991651773452759 Average reward real: 0.499704509973526 Training q_loss: 2.3205 Training g_loss: 2.0746 Training d_loss: 1.3852 Explore P: 0.1457\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 450 Total reward: 68.0 Average reward fake: 0.49969467520713806 Average reward real: 0.49957436323165894 Training q_loss: 2.0813 Training g_loss: 2.0713 Training d_loss: 1.3878 Explore P: 0.1448\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 451 Total reward: 54.0 Average reward fake: 0.5002782940864563 Average reward real: 0.5004926323890686 Training q_loss: 2.3033 Training g_loss: 2.0747 Training d_loss: 1.3858 Explore P: 0.1440\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 452 Total reward: 56.0 Average reward fake: 0.49978768825531006 Average reward real: 0.5008766651153564 Training q_loss: 2.0833 Training g_loss: 2.0722 Training d_loss: 1.3844 Explore P: 0.1433\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 453 Total reward: 47.0 Average reward fake: 0.49999532103538513 Average reward real: 0.499031662940979 Training q_loss: 2.1075 Training g_loss: 2.0757 Training d_loss: 1.3884 Explore P: 0.1427\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 454 Total reward: 45.0 Average reward fake: 0.4998618960380554 Average reward real: 0.49897438287734985 Training q_loss: 4.2174 Training g_loss: 2.0756 Training d_loss: 1.3892 Explore P: 0.1421\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 455 Total reward: 62.0 Average reward fake: 0.5008209347724915 Average reward real: 0.5002185106277466 Training q_loss: 2.2045 Training g_loss: 2.0745 Training d_loss: 1.3878 Explore P: 0.1413\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 456 Total reward: 79.0 Average reward fake: 0.5005900263786316 Average reward real: 0.4999776780605316 Training q_loss: 2.2558 Training g_loss: 2.0787 Training d_loss: 1.3873 Explore P: 0.1402\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 457 Total reward: 54.0 Average reward fake: 0.500478982925415 Average reward real: 0.5001905560493469 Training q_loss: 2.1965 Training g_loss: 2.0729 Training d_loss: 1.3874 Explore P: 0.1395\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 458 Total reward: 42.0 Average reward fake: 0.49948588013648987 Average reward real: 0.499757319688797 Training q_loss: 2.0899 Training g_loss: 2.0751 Training d_loss: 1.3859 Explore P: 0.1390\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 459 Total reward: 123.0 Average reward fake: 0.49946334958076477 Average reward real: 0.5000762939453125 Training q_loss: 2.1206 Training g_loss: 2.0717 Training d_loss: 1.3852 Explore P: 0.1374\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 460 Total reward: 83.0 Average reward fake: 0.5003013610839844 Average reward real: 0.49995067715644836 Training q_loss: 2.6972 Training g_loss: 2.0746 Training d_loss: 1.3872 Explore P: 0.1363\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 461 Total reward: 41.0 Average reward fake: 0.4998517334461212 Average reward real: 0.5002912878990173 Training q_loss: 2.2791 Training g_loss: 2.0733 Training d_loss: 1.3853 Explore P: 0.1358\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 462 Total reward: 34.0 Average reward fake: 0.4997137784957886 Average reward real: 0.4996677339076996 Training q_loss: 2.1597 Training g_loss: 2.0726 Training d_loss: 1.3862 Explore P: 0.1354\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 463 Total reward: 28.0 Average reward fake: 0.4997122883796692 Average reward real: 0.49955323338508606 Training q_loss: 2.8872 Training g_loss: 2.0735 Training d_loss: 1.3868 Explore P: 0.1350\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 464 Total reward: 32.0 Average reward fake: 0.4998025596141815 Average reward real: 0.4997907280921936 Training q_loss: 2.0902 Training g_loss: 2.0727 Training d_loss: 1.3863 Explore P: 0.1346\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 465 Total reward: 62.0 Average reward fake: 0.5002545118331909 Average reward real: 0.5006905198097229 Training q_loss: 2.3899 Training g_loss: 2.0749 Training d_loss: 1.3854 Explore P: 0.1339\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 466 Total reward: 64.0 Average reward fake: 0.5010920763015747 Average reward real: 0.4994344413280487 Training q_loss: 2.1201 Training g_loss: 2.0697 Training d_loss: 1.3916 Explore P: 0.1331\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 467 Total reward: 59.0 Average reward fake: 0.5004622936248779 Average reward real: 0.49982360005378723 Training q_loss: 2.0785 Training g_loss: 2.0736 Training d_loss: 1.3874 Explore P: 0.1324\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 468 Total reward: 110.0 Average reward fake: 0.4998478591442108 Average reward real: 0.49952206015586853 Training q_loss: 2.4080 Training g_loss: 2.0742 Training d_loss: 1.3869 Explore P: 0.1310\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 469 Total reward: 59.0 Average reward fake: 0.4996660649776459 Average reward real: 0.5002375245094299 Training q_loss: 2.3744 Training g_loss: 2.0722 Training d_loss: 1.3850 Explore P: 0.1303\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 470 Total reward: 114.0 Average reward fake: 0.5000796318054199 Average reward real: 0.5004951357841492 Training q_loss: 2.4876 Training g_loss: 2.0749 Training d_loss: 1.3855 Explore P: 0.1290\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 471 Total reward: 50.0 Average reward fake: 0.49994131922721863 Average reward real: 0.4996775686740875 Training q_loss: 2.2699 Training g_loss: 2.0724 Training d_loss: 1.3869 Explore P: 0.1284\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 472 Total reward: 24.0 Average reward fake: 0.4998917281627655 Average reward real: 0.500535786151886 Training q_loss: 2.1188 Training g_loss: 2.0768 Training d_loss: 1.3850 Explore P: 0.1281\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 473 Total reward: 63.0 Average reward fake: 0.5002966523170471 Average reward real: 0.49980467557907104 Training q_loss: 2.1106 Training g_loss: 2.0774 Training d_loss: 1.3872 Explore P: 0.1273\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 474 Total reward: 31.0 Average reward fake: 0.5003556609153748 Average reward real: 0.5008633732795715 Training q_loss: 2.1483 Training g_loss: 2.0728 Training d_loss: 1.3853 Explore P: 0.1270\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 475 Total reward: 34.0 Average reward fake: 0.5003008246421814 Average reward real: 0.49988678097724915 Training q_loss: 2.4836 Training g_loss: 2.0830 Training d_loss: 1.3873 Explore P: 0.1266\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 476 Total reward: 30.0 Average reward fake: 0.4992404878139496 Average reward real: 0.49901139736175537 Training q_loss: 2.1982 Training g_loss: 2.0762 Training d_loss: 1.3868 Explore P: 0.1262\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 477 Total reward: 38.0 Average reward fake: 0.5011526346206665 Average reward real: 0.4996873438358307 Training q_loss: 2.3993 Training g_loss: 2.0807 Training d_loss: 1.3895 Explore P: 0.1258\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 478 Total reward: 49.0 Average reward fake: 0.5008234977722168 Average reward real: 0.5014354586601257 Training q_loss: 2.1910 Training g_loss: 2.0779 Training d_loss: 1.3852 Explore P: 0.1252\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 479 Total reward: 51.0 Average reward fake: 0.49955612421035767 Average reward real: 0.4993033707141876 Training q_loss: 2.4243 Training g_loss: 2.0721 Training d_loss: 1.3869 Explore P: 0.1246\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 480 Total reward: 102.0 Average reward fake: 0.49993813037872314 Average reward real: 0.5004224181175232 Training q_loss: 2.1886 Training g_loss: 2.0748 Training d_loss: 1.3855 Explore P: 0.1235\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 481 Total reward: 25.0 Average reward fake: 0.4991445243358612 Average reward real: 0.49975916743278503 Training q_loss: 2.3848 Training g_loss: 2.0736 Training d_loss: 1.3851 Explore P: 0.1232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 482 Total reward: 74.0 Average reward fake: 0.49945494532585144 Average reward real: 0.4998156428337097 Training q_loss: 2.6926 Training g_loss: 2.0768 Training d_loss: 1.3861 Explore P: 0.1223\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 483 Total reward: 40.0 Average reward fake: 0.49996334314346313 Average reward real: 0.5002923011779785 Training q_loss: 2.4664 Training g_loss: 2.0740 Training d_loss: 1.3859 Explore P: 0.1219\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 484 Total reward: 50.0 Average reward fake: 0.5005518198013306 Average reward real: 0.5007138252258301 Training q_loss: 2.4108 Training g_loss: 2.0789 Training d_loss: 1.3862 Explore P: 0.1213\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 485 Total reward: 45.0 Average reward fake: 0.5000334978103638 Average reward real: 0.5005548596382141 Training q_loss: 2.0871 Training g_loss: 2.0723 Training d_loss: 1.3853 Explore P: 0.1208\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 486 Total reward: 74.0 Average reward fake: 0.49994713068008423 Average reward real: 0.5001679062843323 Training q_loss: 2.3049 Training g_loss: 2.0787 Training d_loss: 1.3860 Explore P: 0.1200\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 487 Total reward: 53.0 Average reward fake: 0.5005502104759216 Average reward real: 0.4999127984046936 Training q_loss: 2.1263 Training g_loss: 2.0722 Training d_loss: 1.3877 Explore P: 0.1194\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 488 Total reward: 52.0 Average reward fake: 0.49950018525123596 Average reward real: 0.498951256275177 Training q_loss: 2.1435 Training g_loss: 2.0739 Training d_loss: 1.3873 Explore P: 0.1189\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 489 Total reward: 45.0 Average reward fake: 0.49934035539627075 Average reward real: 0.49970781803131104 Training q_loss: 2.0887 Training g_loss: 2.0758 Training d_loss: 1.3856 Explore P: 0.1184\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 490 Total reward: 58.0 Average reward fake: 0.4997446537017822 Average reward real: 0.4998086988925934 Training q_loss: 2.6488 Training g_loss: 2.0768 Training d_loss: 1.3862 Explore P: 0.1178\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 491 Total reward: 57.0 Average reward fake: 0.5002467036247253 Average reward real: 0.5000231862068176 Training q_loss: 2.0797 Training g_loss: 2.0752 Training d_loss: 1.3872 Explore P: 0.1171\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 492 Total reward: 91.0 Average reward fake: 0.5001246929168701 Average reward real: 0.5003364682197571 Training q_loss: 2.5160 Training g_loss: 2.0734 Training d_loss: 1.3857 Explore P: 0.1162\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 493 Total reward: 100.0 Average reward fake: 0.4998808801174164 Average reward real: 0.4996388256549835 Training q_loss: 2.1889 Training g_loss: 2.0730 Training d_loss: 1.3869 Explore P: 0.1151\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 494 Total reward: 74.0 Average reward fake: 0.49950310587882996 Average reward real: 0.4999300241470337 Training q_loss: 2.2134 Training g_loss: 2.0758 Training d_loss: 1.3858 Explore P: 0.1143\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 495 Total reward: 20.0 Average reward fake: 0.4997999668121338 Average reward real: 0.4990885555744171 Training q_loss: 2.2188 Training g_loss: 2.0787 Training d_loss: 1.3877 Explore P: 0.1141\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 496 Total reward: 36.0 Average reward fake: 0.5007129907608032 Average reward real: 0.5003629326820374 Training q_loss: 2.5555 Training g_loss: 2.0845 Training d_loss: 1.3872 Explore P: 0.1138\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 497 Total reward: 37.0 Average reward fake: 0.4989110231399536 Average reward real: 0.4977913796901703 Training q_loss: 2.1995 Training g_loss: 2.0787 Training d_loss: 1.3892 Explore P: 0.1134\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 498 Total reward: 34.0 Average reward fake: 0.5004713535308838 Average reward real: 0.5009227991104126 Training q_loss: 8.7026 Training g_loss: 2.0755 Training d_loss: 1.3864 Explore P: 0.1130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 499 Total reward: 75.0 Average reward fake: 0.4994969069957733 Average reward real: 0.5002872347831726 Training q_loss: 2.4741 Training g_loss: 2.0764 Training d_loss: 1.3850 Explore P: 0.1123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 500 Total reward: 30.0 Average reward fake: 0.49960365891456604 Average reward real: 0.5003818273544312 Training q_loss: 2.3050 Training g_loss: 2.0821 Training d_loss: 1.3846 Explore P: 0.1120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 501 Total reward: 78.0 Average reward fake: 0.5006721019744873 Average reward real: 0.5009249448776245 Training q_loss: 2.1050 Training g_loss: 2.0767 Training d_loss: 1.3860 Explore P: 0.1112\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 502 Total reward: 61.0 Average reward fake: 0.5000608563423157 Average reward real: 0.49981698393821716 Training q_loss: 2.1577 Training g_loss: 2.0773 Training d_loss: 1.3874 Explore P: 0.1105\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 503 Total reward: 163.0 Average reward fake: 0.5000913143157959 Average reward real: 0.5006254315376282 Training q_loss: 2.1279 Training g_loss: 2.0767 Training d_loss: 1.3853 Explore P: 0.1089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 504 Total reward: 120.0 Average reward fake: 0.49878188967704773 Average reward real: 0.4992680251598358 Training q_loss: 2.1378 Training g_loss: 2.0768 Training d_loss: 1.3850 Explore P: 0.1077\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 505 Total reward: 68.0 Average reward fake: 0.5004435181617737 Average reward real: 0.4996912479400635 Training q_loss: 2.1385 Training g_loss: 2.0767 Training d_loss: 1.3880 Explore P: 0.1071\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 506 Total reward: 38.0 Average reward fake: 0.500329852104187 Average reward real: 0.5000694990158081 Training q_loss: 2.2122 Training g_loss: 2.0707 Training d_loss: 1.3874 Explore P: 0.1067\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 507 Total reward: 80.0 Average reward fake: 0.4995439946651459 Average reward real: 0.49981799721717834 Training q_loss: 2.3357 Training g_loss: 2.0770 Training d_loss: 1.3853 Explore P: 0.1059\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 508 Total reward: 73.0 Average reward fake: 0.49966415762901306 Average reward real: 0.5001752972602844 Training q_loss: 2.1988 Training g_loss: 2.0784 Training d_loss: 1.3853 Explore P: 0.1052\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 509 Total reward: 44.0 Average reward fake: 0.49970778822898865 Average reward real: 0.5003756880760193 Training q_loss: 2.0961 Training g_loss: 2.0773 Training d_loss: 1.3854 Explore P: 0.1048\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 510 Total reward: 42.0 Average reward fake: 0.49941474199295044 Average reward real: 0.5006073117256165 Training q_loss: 2.1413 Training g_loss: 2.0783 Training d_loss: 1.3837 Explore P: 0.1044\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 511 Total reward: 138.0 Average reward fake: 0.5029590725898743 Average reward real: 0.5016744136810303 Training q_loss: 2.1122 Training g_loss: 2.0876 Training d_loss: 1.3885 Explore P: 0.1031\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 512 Total reward: 48.0 Average reward fake: 0.5001146793365479 Average reward real: 0.4989798069000244 Training q_loss: 2.5031 Training g_loss: 2.0741 Training d_loss: 1.3884 Explore P: 0.1027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 513 Total reward: 99.0 Average reward fake: 0.4994231164455414 Average reward real: 0.49924910068511963 Training q_loss: 2.1895 Training g_loss: 2.0787 Training d_loss: 1.3865 Explore P: 0.1018\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 514 Total reward: 64.0 Average reward fake: 0.4992993474006653 Average reward real: 0.49973824620246887 Training q_loss: 2.0806 Training g_loss: 2.0730 Training d_loss: 1.3853 Explore P: 0.1012\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 515 Total reward: 34.0 Average reward fake: 0.4999448359012604 Average reward real: 0.5005558133125305 Training q_loss: 2.2125 Training g_loss: 2.0758 Training d_loss: 1.3852 Explore P: 0.1009\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 516 Total reward: 51.0 Average reward fake: 0.5005237460136414 Average reward real: 0.49953705072402954 Training q_loss: 2.1693 Training g_loss: 2.0743 Training d_loss: 1.3886 Explore P: 0.1004\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 517 Total reward: 70.0 Average reward fake: 0.4997127652168274 Average reward real: 0.5001553297042847 Training q_loss: 2.0873 Training g_loss: 2.0759 Training d_loss: 1.3854 Explore P: 0.0998\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 518 Total reward: 73.0 Average reward fake: 0.49947166442871094 Average reward real: 0.49983569979667664 Training q_loss: 2.0917 Training g_loss: 2.0759 Training d_loss: 1.3859 Explore P: 0.0991\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 519 Total reward: 74.0 Average reward fake: 0.500061571598053 Average reward real: 0.5002283453941345 Training q_loss: 2.3168 Training g_loss: 2.0743 Training d_loss: 1.3861 Explore P: 0.0985\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 520 Total reward: 31.0 Average reward fake: 0.4996061623096466 Average reward real: 0.49969208240509033 Training q_loss: 2.2051 Training g_loss: 2.0820 Training d_loss: 1.3861 Explore P: 0.0982\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 521 Total reward: 128.0 Average reward fake: 0.5006646513938904 Average reward real: 0.5001764297485352 Training q_loss: 2.8936 Training g_loss: 2.0768 Training d_loss: 1.3875 Explore P: 0.0971\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 522 Total reward: 69.0 Average reward fake: 0.4999573528766632 Average reward real: 0.5008038282394409 Training q_loss: 2.1009 Training g_loss: 2.0799 Training d_loss: 1.3847 Explore P: 0.0965\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 523 Total reward: 45.0 Average reward fake: 0.4995056092739105 Average reward real: 0.500494122505188 Training q_loss: 2.1342 Training g_loss: 2.0753 Training d_loss: 1.3845 Explore P: 0.0961\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 524 Total reward: 84.0 Average reward fake: 0.4988398849964142 Average reward real: 0.4994942545890808 Training q_loss: 2.1137 Training g_loss: 2.0760 Training d_loss: 1.3850 Explore P: 0.0954\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 525 Total reward: 85.0 Average reward fake: 0.4998122453689575 Average reward real: 0.5004456639289856 Training q_loss: 2.1882 Training g_loss: 2.0763 Training d_loss: 1.3850 Explore P: 0.0946\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 526 Total reward: 61.0 Average reward fake: 0.49975937604904175 Average reward real: 0.4998897612094879 Training q_loss: 2.1701 Training g_loss: 2.0747 Training d_loss: 1.3860 Explore P: 0.0941\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 527 Total reward: 41.0 Average reward fake: 0.5000748634338379 Average reward real: 0.4992488920688629 Training q_loss: 2.6732 Training g_loss: 2.0763 Training d_loss: 1.3883 Explore P: 0.0938\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 528 Total reward: 46.0 Average reward fake: 0.5004940629005432 Average reward real: 0.5006568431854248 Training q_loss: 2.1949 Training g_loss: 2.0741 Training d_loss: 1.3861 Explore P: 0.0934\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 529 Total reward: 151.0 Average reward fake: 0.5003204941749573 Average reward real: 0.5005272626876831 Training q_loss: 2.1160 Training g_loss: 2.0753 Training d_loss: 1.3860 Explore P: 0.0922\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 530 Total reward: 41.0 Average reward fake: 0.49966421723365784 Average reward real: 0.5001930594444275 Training q_loss: 2.3139 Training g_loss: 2.0779 Training d_loss: 1.3854 Explore P: 0.0918\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 531 Total reward: 110.0 Average reward fake: 0.49991557002067566 Average reward real: 0.5003297924995422 Training q_loss: 2.0985 Training g_loss: 2.0770 Training d_loss: 1.3855 Explore P: 0.0909\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 532 Total reward: 22.0 Average reward fake: 0.4993192255496979 Average reward real: 0.49975812435150146 Training q_loss: 2.4288 Training g_loss: 2.0772 Training d_loss: 1.3856 Explore P: 0.0907\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 533 Total reward: 48.0 Average reward fake: 0.4999738931655884 Average reward real: 0.5008577108383179 Training q_loss: 2.1436 Training g_loss: 2.0765 Training d_loss: 1.3846 Explore P: 0.0904\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 534 Total reward: 106.0 Average reward fake: 0.5016838312149048 Average reward real: 0.5006812810897827 Training q_loss: 2.0908 Training g_loss: 2.0745 Training d_loss: 1.3886 Explore P: 0.0895\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 535 Total reward: 48.0 Average reward fake: 0.4993821382522583 Average reward real: 0.499405175447464 Training q_loss: 2.1188 Training g_loss: 2.0771 Training d_loss: 1.3863 Explore P: 0.0891\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 536 Total reward: 125.0 Average reward fake: 0.5006626844406128 Average reward real: 0.5017744302749634 Training q_loss: 2.1013 Training g_loss: 2.0776 Training d_loss: 1.3841 Explore P: 0.0881\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 537 Total reward: 47.0 Average reward fake: 0.5000819563865662 Average reward real: 0.5008207559585571 Training q_loss: 2.1429 Training g_loss: 2.0748 Training d_loss: 1.3849 Explore P: 0.0878\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 538 Total reward: 81.0 Average reward fake: 0.5002899765968323 Average reward real: 0.5011303424835205 Training q_loss: 2.0835 Training g_loss: 2.0743 Training d_loss: 1.3847 Explore P: 0.0872\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 539 Total reward: 47.0 Average reward fake: 0.4994329810142517 Average reward real: 0.5003818273544312 Training q_loss: 2.3455 Training g_loss: 2.0740 Training d_loss: 1.3846 Explore P: 0.0868\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 540 Total reward: 39.0 Average reward fake: 0.4997860789299011 Average reward real: 0.5002073049545288 Training q_loss: 2.1557 Training g_loss: 2.0815 Training d_loss: 1.3858 Explore P: 0.0865\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 541 Total reward: 63.0 Average reward fake: 0.4991791844367981 Average reward real: 0.49941176176071167 Training q_loss: 2.1677 Training g_loss: 2.0737 Training d_loss: 1.3860 Explore P: 0.0860\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 542 Total reward: 34.0 Average reward fake: 0.5002799034118652 Average reward real: 0.5002225041389465 Training q_loss: 2.0837 Training g_loss: 2.0741 Training d_loss: 1.3868 Explore P: 0.0858\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 543 Total reward: 40.0 Average reward fake: 0.49970167875289917 Average reward real: 0.498098224401474 Training q_loss: 2.2125 Training g_loss: 2.0712 Training d_loss: 1.3898 Explore P: 0.0855\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 544 Total reward: 75.0 Average reward fake: 0.5000602602958679 Average reward real: 0.49993380904197693 Training q_loss: 2.0912 Training g_loss: 2.0760 Training d_loss: 1.3866 Explore P: 0.0849\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 545 Total reward: 40.0 Average reward fake: 0.499939888715744 Average reward real: 0.5002815127372742 Training q_loss: 2.3183 Training g_loss: 2.0739 Training d_loss: 1.3858 Explore P: 0.0846\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 546 Total reward: 82.0 Average reward fake: 0.49900999665260315 Average reward real: 0.49958714842796326 Training q_loss: 2.1186 Training g_loss: 2.0741 Training d_loss: 1.3852 Explore P: 0.0840\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 547 Total reward: 28.0 Average reward fake: 0.4999516010284424 Average reward real: 0.5000274777412415 Training q_loss: 2.2166 Training g_loss: 2.0812 Training d_loss: 1.3860 Explore P: 0.0838\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 548 Total reward: 40.0 Average reward fake: 0.4996693730354309 Average reward real: 0.5001623630523682 Training q_loss: 2.1449 Training g_loss: 2.0774 Training d_loss: 1.3854 Explore P: 0.0835\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 549 Total reward: 69.0 Average reward fake: 0.4996733069419861 Average reward real: 0.500510036945343 Training q_loss: 2.1492 Training g_loss: 2.0792 Training d_loss: 1.3850 Explore P: 0.0830\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 550 Total reward: 186.0 Average reward fake: 0.49981430172920227 Average reward real: 0.5004217028617859 Training q_loss: 2.8824 Training g_loss: 2.0786 Training d_loss: 1.3852 Explore P: 0.0816\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 551 Total reward: 51.0 Average reward fake: 0.49967944622039795 Average reward real: 0.5004346966743469 Training q_loss: 2.0897 Training g_loss: 2.0764 Training d_loss: 1.3847 Explore P: 0.0813\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 552 Total reward: 181.0 Average reward fake: 0.4997195303440094 Average reward real: 0.5000038146972656 Training q_loss: 2.2260 Training g_loss: 2.0737 Training d_loss: 1.3855 Explore P: 0.0800\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 553 Total reward: 26.0 Average reward fake: 0.49999159574508667 Average reward real: 0.4998953342437744 Training q_loss: 2.1289 Training g_loss: 2.0859 Training d_loss: 1.3860 Explore P: 0.0798\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 554 Total reward: 51.0 Average reward fake: 0.500387966632843 Average reward real: 0.5000291466712952 Training q_loss: 2.1756 Training g_loss: 2.0758 Training d_loss: 1.3869 Explore P: 0.0794\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 555 Total reward: 53.0 Average reward fake: 0.499324768781662 Average reward real: 0.4994877278804779 Training q_loss: 2.1190 Training g_loss: 2.0773 Training d_loss: 1.3875 Explore P: 0.0791\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 556 Total reward: 72.0 Average reward fake: 0.5005387663841248 Average reward real: 0.4993526041507721 Training q_loss: 2.1110 Training g_loss: 2.0732 Training d_loss: 1.3886 Explore P: 0.0786\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 557 Total reward: 50.0 Average reward fake: 0.49951115250587463 Average reward real: 0.4994145333766937 Training q_loss: 2.2165 Training g_loss: 2.0756 Training d_loss: 1.3868 Explore P: 0.0782\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 558 Total reward: 38.0 Average reward fake: 0.49967455863952637 Average reward real: 0.4999544620513916 Training q_loss: 2.0936 Training g_loss: 2.0733 Training d_loss: 1.3861 Explore P: 0.0780\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 559 Total reward: 60.0 Average reward fake: 0.4997502267360687 Average reward real: 0.49988463521003723 Training q_loss: 2.1011 Training g_loss: 2.0750 Training d_loss: 1.3860 Explore P: 0.0776\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 560 Total reward: 71.0 Average reward fake: 0.4999009668827057 Average reward real: 0.5003593564033508 Training q_loss: 2.1574 Training g_loss: 2.0739 Training d_loss: 1.3854 Explore P: 0.0771\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 561 Total reward: 67.0 Average reward fake: 0.49937546253204346 Average reward real: 0.49938270449638367 Training q_loss: 2.1853 Training g_loss: 2.0799 Training d_loss: 1.3863 Explore P: 0.0767\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 562 Total reward: 85.0 Average reward fake: 0.5002485513687134 Average reward real: 0.4994845688343048 Training q_loss: 2.1223 Training g_loss: 2.0774 Training d_loss: 1.3884 Explore P: 0.0761\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 563 Total reward: 93.0 Average reward fake: 0.5001164078712463 Average reward real: 0.5001245141029358 Training q_loss: 2.3865 Training g_loss: 2.0742 Training d_loss: 1.3864 Explore P: 0.0755\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 564 Total reward: 80.0 Average reward fake: 0.499317467212677 Average reward real: 0.5003899335861206 Training q_loss: 2.1788 Training g_loss: 2.0769 Training d_loss: 1.3842 Explore P: 0.0750\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 565 Total reward: 121.0 Average reward fake: 0.500018298625946 Average reward real: 0.5008969902992249 Training q_loss: 2.1346 Training g_loss: 2.0755 Training d_loss: 1.3846 Explore P: 0.0742\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 566 Total reward: 64.0 Average reward fake: 0.5000602602958679 Average reward real: 0.5002993941307068 Training q_loss: 2.0809 Training g_loss: 2.0725 Training d_loss: 1.3860 Explore P: 0.0738\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 567 Total reward: 172.0 Average reward fake: 0.5000335574150085 Average reward real: 0.5007905960083008 Training q_loss: 2.1544 Training g_loss: 2.0789 Training d_loss: 1.3851 Explore P: 0.0727\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 568 Total reward: 60.0 Average reward fake: 0.4976018965244293 Average reward real: 0.49961596727371216 Training q_loss: 2.8026 Training g_loss: 2.0801 Training d_loss: 1.3826 Explore P: 0.0723\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 569 Total reward: 46.0 Average reward fake: 0.5010179877281189 Average reward real: 0.4992971122264862 Training q_loss: 2.1651 Training g_loss: 2.0761 Training d_loss: 1.3898 Explore P: 0.0720\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 570 Total reward: 46.0 Average reward fake: 0.500300407409668 Average reward real: 0.4999208152294159 Training q_loss: 2.1553 Training g_loss: 2.0734 Training d_loss: 1.3871 Explore P: 0.0717\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 571 Total reward: 53.0 Average reward fake: 0.49931347370147705 Average reward real: 0.4998314380645752 Training q_loss: 2.1147 Training g_loss: 2.0726 Training d_loss: 1.3854 Explore P: 0.0714\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 572 Total reward: 68.0 Average reward fake: 0.4999494254589081 Average reward real: 0.4993553161621094 Training q_loss: 2.9263 Training g_loss: 2.0748 Training d_loss: 1.3877 Explore P: 0.0710\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 573 Total reward: 48.0 Average reward fake: 0.49956488609313965 Average reward real: 0.5000960230827332 Training q_loss: 2.3288 Training g_loss: 2.0788 Training d_loss: 1.3853 Explore P: 0.0707\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 574 Total reward: 83.0 Average reward fake: 0.4988653063774109 Average reward real: 0.49986639618873596 Training q_loss: 2.1071 Training g_loss: 2.0781 Training d_loss: 1.3844 Explore P: 0.0702\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 575 Total reward: 58.0 Average reward fake: 0.49950793385505676 Average reward real: 0.4993855953216553 Training q_loss: 2.1036 Training g_loss: 2.0806 Training d_loss: 1.3871 Explore P: 0.0698\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 576 Total reward: 73.0 Average reward fake: 0.49964362382888794 Average reward real: 0.4998303949832916 Training q_loss: 2.2107 Training g_loss: 2.0755 Training d_loss: 1.3857 Explore P: 0.0694\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 577 Total reward: 39.0 Average reward fake: 0.49951258301734924 Average reward real: 0.5002121925354004 Training q_loss: 2.1419 Training g_loss: 2.0758 Training d_loss: 1.3853 Explore P: 0.0692\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 578 Total reward: 31.0 Average reward fake: 0.4993198812007904 Average reward real: 0.5013659000396729 Training q_loss: 2.1263 Training g_loss: 2.0804 Training d_loss: 1.3822 Explore P: 0.0690\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 579 Total reward: 58.0 Average reward fake: 0.5008196830749512 Average reward real: 0.4978487491607666 Training q_loss: 2.0908 Training g_loss: 2.0772 Training d_loss: 1.3946 Explore P: 0.0687\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 580 Total reward: 54.0 Average reward fake: 0.49950945377349854 Average reward real: 0.4993983507156372 Training q_loss: 2.5124 Training g_loss: 2.0742 Training d_loss: 1.3866 Explore P: 0.0683\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 581 Total reward: 26.0 Average reward fake: 0.4991912543773651 Average reward real: 0.4998457431793213 Training q_loss: 2.1077 Training g_loss: 2.0777 Training d_loss: 1.3851 Explore P: 0.0682\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 582 Total reward: 91.0 Average reward fake: 0.49980995059013367 Average reward real: 0.4998074471950531 Training q_loss: 2.1062 Training g_loss: 2.0736 Training d_loss: 1.3864 Explore P: 0.0677\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 583 Total reward: 71.0 Average reward fake: 0.4999867379665375 Average reward real: 0.4999977946281433 Training q_loss: 2.1948 Training g_loss: 2.0742 Training d_loss: 1.3860 Explore P: 0.0673\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 584 Total reward: 65.0 Average reward fake: 0.5007894039154053 Average reward real: 0.5006486773490906 Training q_loss: 2.1532 Training g_loss: 2.0728 Training d_loss: 1.3869 Explore P: 0.0669\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 585 Total reward: 61.0 Average reward fake: 0.4999713897705078 Average reward real: 0.4986366927623749 Training q_loss: 2.2131 Training g_loss: 2.0771 Training d_loss: 1.3890 Explore P: 0.0665\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 586 Total reward: 10.0 Average reward fake: 0.4997427463531494 Average reward real: 0.49979037046432495 Training q_loss: 2.1618 Training g_loss: 2.0760 Training d_loss: 1.3864 Explore P: 0.0665\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 587 Total reward: 51.0 Average reward fake: 0.5004016757011414 Average reward real: 0.5003318786621094 Training q_loss: 2.0830 Training g_loss: 2.0726 Training d_loss: 1.3869 Explore P: 0.0662\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 588 Total reward: 50.0 Average reward fake: 0.49957334995269775 Average reward real: 0.5002370476722717 Training q_loss: 3.3295 Training g_loss: 2.0778 Training d_loss: 1.3852 Explore P: 0.0659\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 589 Total reward: 41.0 Average reward fake: 0.499032586812973 Average reward real: 0.4990249574184418 Training q_loss: 2.1385 Training g_loss: 2.0767 Training d_loss: 1.3862 Explore P: 0.0657\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 590 Total reward: 91.0 Average reward fake: 0.5015037059783936 Average reward real: 0.4987766146659851 Training q_loss: 2.0844 Training g_loss: 2.0709 Training d_loss: 1.3918 Explore P: 0.0652\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 591 Total reward: 61.0 Average reward fake: 0.5007088780403137 Average reward real: 0.4985300898551941 Training q_loss: 2.0794 Training g_loss: 2.0727 Training d_loss: 1.3904 Explore P: 0.0648\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 592 Total reward: 58.0 Average reward fake: 0.4999971091747284 Average reward real: 0.49964267015457153 Training q_loss: 2.0824 Training g_loss: 2.0724 Training d_loss: 1.3873 Explore P: 0.0645\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 593 Total reward: 51.0 Average reward fake: 0.4990599751472473 Average reward real: 0.4993405044078827 Training q_loss: 2.1972 Training g_loss: 2.0783 Training d_loss: 1.3857 Explore P: 0.0643\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 594 Total reward: 54.0 Average reward fake: 0.500641405582428 Average reward real: 0.5005761981010437 Training q_loss: 2.1112 Training g_loss: 2.0771 Training d_loss: 1.3866 Explore P: 0.0640\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 595 Total reward: 78.0 Average reward fake: 0.4996158480644226 Average reward real: 0.5000383257865906 Training q_loss: 2.1085 Training g_loss: 2.0753 Training d_loss: 1.3853 Explore P: 0.0635\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 596 Total reward: 51.0 Average reward fake: 0.49944359064102173 Average reward real: 0.499441921710968 Training q_loss: 2.0919 Training g_loss: 2.0754 Training d_loss: 1.3864 Explore P: 0.0633\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 597 Total reward: 40.0 Average reward fake: 0.5000365972518921 Average reward real: 0.4987221956253052 Training q_loss: 2.1678 Training g_loss: 2.0727 Training d_loss: 1.3893 Explore P: 0.0631\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 598 Total reward: 20.0 Average reward fake: 0.5011664628982544 Average reward real: 0.49960392713546753 Training q_loss: 2.0874 Training g_loss: 2.0753 Training d_loss: 1.3897 Explore P: 0.0629\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 599 Total reward: 78.0 Average reward fake: 0.4998525381088257 Average reward real: 0.4995375871658325 Training q_loss: 2.1151 Training g_loss: 2.0767 Training d_loss: 1.3868 Explore P: 0.0625\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 600 Total reward: 57.0 Average reward fake: 0.5003398656845093 Average reward real: 0.5001487731933594 Training q_loss: 2.2800 Training g_loss: 2.0767 Training d_loss: 1.3868 Explore P: 0.0622\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 601 Total reward: 21.0 Average reward fake: 0.49974656105041504 Average reward real: 0.499557763338089 Training q_loss: 2.1393 Training g_loss: 2.0820 Training d_loss: 1.3864 Explore P: 0.0621\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 602 Total reward: 77.0 Average reward fake: 0.4998439848423004 Average reward real: 0.5002415180206299 Training q_loss: 2.1758 Training g_loss: 2.0748 Training d_loss: 1.3852 Explore P: 0.0617\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 603 Total reward: 43.0 Average reward fake: 0.49963387846946716 Average reward real: 0.5001484751701355 Training q_loss: 2.2609 Training g_loss: 2.0817 Training d_loss: 1.3858 Explore P: 0.0615\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 604 Total reward: 45.0 Average reward fake: 0.4992924928665161 Average reward real: 0.499957799911499 Training q_loss: 2.3546 Training g_loss: 2.0737 Training d_loss: 1.3851 Explore P: 0.0613\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 605 Total reward: 40.0 Average reward fake: 0.5006368160247803 Average reward real: 0.5012470483779907 Training q_loss: 2.0958 Training g_loss: 2.0759 Training d_loss: 1.3852 Explore P: 0.0611\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 606 Total reward: 72.0 Average reward fake: 0.49976277351379395 Average reward real: 0.5013703107833862 Training q_loss: 2.0891 Training g_loss: 2.0760 Training d_loss: 1.3832 Explore P: 0.0607\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 607 Total reward: 47.0 Average reward fake: 0.5017897486686707 Average reward real: 0.5008901953697205 Training q_loss: 2.1240 Training g_loss: 2.0755 Training d_loss: 1.3879 Explore P: 0.0605\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 608 Total reward: 42.0 Average reward fake: 0.5000102519989014 Average reward real: 0.4991905987262726 Training q_loss: 2.1000 Training g_loss: 2.0746 Training d_loss: 1.3885 Explore P: 0.0603\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 609 Total reward: 32.0 Average reward fake: 0.4989347755908966 Average reward real: 0.5001310706138611 Training q_loss: 2.0842 Training g_loss: 2.0763 Training d_loss: 1.3844 Explore P: 0.0601\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 610 Total reward: 55.0 Average reward fake: 0.5000449419021606 Average reward real: 0.5002326369285583 Training q_loss: 2.1195 Training g_loss: 2.0762 Training d_loss: 1.3859 Explore P: 0.0598\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 611 Total reward: 41.0 Average reward fake: 0.5007370710372925 Average reward real: 0.5010542869567871 Training q_loss: 2.1322 Training g_loss: 2.0747 Training d_loss: 1.3856 Explore P: 0.0596\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 612 Total reward: 95.0 Average reward fake: 0.49914419651031494 Average reward real: 0.4996492862701416 Training q_loss: 2.1169 Training g_loss: 2.0762 Training d_loss: 1.3852 Explore P: 0.0591\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 613 Total reward: 135.0 Average reward fake: 0.4995696246623993 Average reward real: 0.5008541345596313 Training q_loss: 2.1206 Training g_loss: 2.0791 Training d_loss: 1.3839 Explore P: 0.0585\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 614 Total reward: 63.0 Average reward fake: 0.49969083070755005 Average reward real: 0.5016176104545593 Training q_loss: 2.1224 Training g_loss: 2.0776 Training d_loss: 1.3836 Explore P: 0.0582\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 615 Total reward: 35.0 Average reward fake: 0.5019382834434509 Average reward real: 0.5009692907333374 Training q_loss: 2.3805 Training g_loss: 2.0779 Training d_loss: 1.3882 Explore P: 0.0580\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 616 Total reward: 69.0 Average reward fake: 0.49924322962760925 Average reward real: 0.5001917481422424 Training q_loss: 2.0933 Training g_loss: 2.0803 Training d_loss: 1.3843 Explore P: 0.0577\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 617 Total reward: 110.0 Average reward fake: 0.5003225207328796 Average reward real: 0.5003880262374878 Training q_loss: 2.1651 Training g_loss: 2.0768 Training d_loss: 1.3861 Explore P: 0.0572\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 618 Total reward: 25.0 Average reward fake: 0.5002418756484985 Average reward real: 0.5005879998207092 Training q_loss: 2.3192 Training g_loss: 2.0740 Training d_loss: 1.3858 Explore P: 0.0570\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 619 Total reward: 64.0 Average reward fake: 0.49910426139831543 Average reward real: 0.4999648332595825 Training q_loss: 2.1006 Training g_loss: 2.0781 Training d_loss: 1.3845 Explore P: 0.0567\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 620 Total reward: 56.0 Average reward fake: 0.49961552023887634 Average reward real: 0.5002368092536926 Training q_loss: 2.1590 Training g_loss: 2.0758 Training d_loss: 1.3854 Explore P: 0.0565\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 621 Total reward: 71.0 Average reward fake: 0.5020725727081299 Average reward real: 0.4986097812652588 Training q_loss: 2.1184 Training g_loss: 2.0736 Training d_loss: 1.3933 Explore P: 0.0562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 622 Total reward: 39.0 Average reward fake: 0.49947434663772583 Average reward real: 0.49960601329803467 Training q_loss: 2.6758 Training g_loss: 2.0748 Training d_loss: 1.3860 Explore P: 0.0560\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 623 Total reward: 16.0 Average reward fake: 0.4999676048755646 Average reward real: 0.5007637143135071 Training q_loss: 3.5251 Training g_loss: 2.0769 Training d_loss: 1.3850 Explore P: 0.0559\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 624 Total reward: 88.0 Average reward fake: 0.4995851218700409 Average reward real: 0.4995481073856354 Training q_loss: 2.1469 Training g_loss: 2.0730 Training d_loss: 1.3865 Explore P: 0.0555\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 625 Total reward: 21.0 Average reward fake: 0.5007144808769226 Average reward real: 0.5001506209373474 Training q_loss: 3.3859 Training g_loss: 2.0754 Training d_loss: 1.3874 Explore P: 0.0554\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 626 Total reward: 57.0 Average reward fake: 0.5002790093421936 Average reward real: 0.5004050731658936 Training q_loss: 2.1421 Training g_loss: 2.0746 Training d_loss: 1.3862 Explore P: 0.0551\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 627 Total reward: 96.0 Average reward fake: 0.5001181960105896 Average reward real: 0.5002385973930359 Training q_loss: 2.0758 Training g_loss: 2.0734 Training d_loss: 1.3861 Explore P: 0.0547\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 628 Total reward: 134.0 Average reward fake: 0.5000659823417664 Average reward real: 0.5003188848495483 Training q_loss: 2.1685 Training g_loss: 2.0849 Training d_loss: 1.3865 Explore P: 0.0541\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 629 Total reward: 49.0 Average reward fake: 0.5004338622093201 Average reward real: 0.5015177130699158 Training q_loss: 2.1162 Training g_loss: 2.0773 Training d_loss: 1.3845 Explore P: 0.0539\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 630 Total reward: 104.0 Average reward fake: 0.5003199577331543 Average reward real: 0.5004310607910156 Training q_loss: 2.1004 Training g_loss: 2.0733 Training d_loss: 1.3858 Explore P: 0.0534\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 631 Total reward: 81.0 Average reward fake: 0.4996844530105591 Average reward real: 0.5000166893005371 Training q_loss: 2.2974 Training g_loss: 2.0758 Training d_loss: 1.3856 Explore P: 0.0531\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 632 Total reward: 47.0 Average reward fake: 0.4996781051158905 Average reward real: 0.5004934668540955 Training q_loss: 2.3193 Training g_loss: 2.0770 Training d_loss: 1.3846 Explore P: 0.0529\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 633 Total reward: 74.0 Average reward fake: 0.5002334117889404 Average reward real: 0.49966371059417725 Training q_loss: 2.0875 Training g_loss: 2.0734 Training d_loss: 1.3870 Explore P: 0.0526\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 634 Total reward: 73.0 Average reward fake: 0.5000931024551392 Average reward real: 0.5001263618469238 Training q_loss: 2.1122 Training g_loss: 2.0763 Training d_loss: 1.3859 Explore P: 0.0523\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 635 Total reward: 44.0 Average reward fake: 0.49858415126800537 Average reward real: 0.4993807077407837 Training q_loss: 2.2285 Training g_loss: 2.0787 Training d_loss: 1.3849 Explore P: 0.0521\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 636 Total reward: 63.0 Average reward fake: 0.4991351068019867 Average reward real: 0.49931809306144714 Training q_loss: 2.2390 Training g_loss: 2.0864 Training d_loss: 1.3860 Explore P: 0.0518\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 637 Total reward: 61.0 Average reward fake: 0.4992819130420685 Average reward real: 0.5000259280204773 Training q_loss: 2.2153 Training g_loss: 2.0827 Training d_loss: 1.3848 Explore P: 0.0516\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 638 Total reward: 31.0 Average reward fake: 0.49981924891471863 Average reward real: 0.5011651515960693 Training q_loss: 2.3193 Training g_loss: 2.0776 Training d_loss: 1.3837 Explore P: 0.0514\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 639 Total reward: 29.0 Average reward fake: 0.4986301362514496 Average reward real: 0.4991602301597595 Training q_loss: 2.0874 Training g_loss: 2.0749 Training d_loss: 1.3859 Explore P: 0.0513\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 640 Total reward: 40.0 Average reward fake: 0.4958340525627136 Average reward real: 0.4979110062122345 Training q_loss: 2.1336 Training g_loss: 2.0780 Training d_loss: 1.3849 Explore P: 0.0512\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 641 Total reward: 32.0 Average reward fake: 0.503254771232605 Average reward real: 0.5001931190490723 Training q_loss: 2.0866 Training g_loss: 2.0784 Training d_loss: 1.3918 Explore P: 0.0510\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 642 Total reward: 87.0 Average reward fake: 0.4996931552886963 Average reward real: 0.5001687407493591 Training q_loss: 2.5291 Training g_loss: 2.0754 Training d_loss: 1.3854 Explore P: 0.0507\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 643 Total reward: 62.0 Average reward fake: 0.499321848154068 Average reward real: 0.4994792938232422 Training q_loss: 2.1583 Training g_loss: 2.0736 Training d_loss: 1.3870 Explore P: 0.0504\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 644 Total reward: 96.0 Average reward fake: 0.499481201171875 Average reward real: 0.49977073073387146 Training q_loss: 2.0870 Training g_loss: 2.0756 Training d_loss: 1.3858 Explore P: 0.0500\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 645 Total reward: 28.0 Average reward fake: 0.4998328387737274 Average reward real: 0.5006207227706909 Training q_loss: 2.0886 Training g_loss: 2.0722 Training d_loss: 1.3849 Explore P: 0.0499\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 646 Total reward: 46.0 Average reward fake: 0.4994155764579773 Average reward real: 0.5003489851951599 Training q_loss: 2.1295 Training g_loss: 2.0767 Training d_loss: 1.3844 Explore P: 0.0497\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 647 Total reward: 41.0 Average reward fake: 0.5002464056015015 Average reward real: 0.5000284910202026 Training q_loss: 2.1489 Training g_loss: 2.0746 Training d_loss: 1.3872 Explore P: 0.0496\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 648 Total reward: 32.0 Average reward fake: 0.5002643465995789 Average reward real: 0.5011757016181946 Training q_loss: 2.1030 Training g_loss: 2.0768 Training d_loss: 1.3855 Explore P: 0.0494\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 649 Total reward: 41.0 Average reward fake: 0.49964970350265503 Average reward real: 0.5002472400665283 Training q_loss: 2.1043 Training g_loss: 2.0751 Training d_loss: 1.3853 Explore P: 0.0493\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 650 Total reward: 26.0 Average reward fake: 0.5006045699119568 Average reward real: 0.5007084608078003 Training q_loss: 2.1361 Training g_loss: 2.0749 Training d_loss: 1.3866 Explore P: 0.0492\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 651 Total reward: 50.0 Average reward fake: 0.4995935559272766 Average reward real: 0.49977490305900574 Training q_loss: 2.0848 Training g_loss: 2.0751 Training d_loss: 1.3860 Explore P: 0.0490\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 652 Total reward: 57.0 Average reward fake: 0.4999130964279175 Average reward real: 0.5001966953277588 Training q_loss: 2.1520 Training g_loss: 2.0771 Training d_loss: 1.3859 Explore P: 0.0488\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 653 Total reward: 52.0 Average reward fake: 0.5001457333564758 Average reward real: 0.500507116317749 Training q_loss: 4.2307 Training g_loss: 2.0777 Training d_loss: 1.3854 Explore P: 0.0486\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 654 Total reward: 44.0 Average reward fake: 0.49990516901016235 Average reward real: 0.49877628684043884 Training q_loss: 2.0966 Training g_loss: 2.0771 Training d_loss: 1.3889 Explore P: 0.0484\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 655 Total reward: 40.0 Average reward fake: 0.5013223886489868 Average reward real: 0.4997299909591675 Training q_loss: 2.0761 Training g_loss: 2.0729 Training d_loss: 1.3897 Explore P: 0.0482\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 656 Total reward: 62.0 Average reward fake: 0.49999940395355225 Average reward real: 0.5001861453056335 Training q_loss: 2.1833 Training g_loss: 2.0776 Training d_loss: 1.3860 Explore P: 0.0480\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 657 Total reward: 95.0 Average reward fake: 0.49869978427886963 Average reward real: 0.49889498949050903 Training q_loss: 2.1080 Training g_loss: 2.0743 Training d_loss: 1.3866 Explore P: 0.0476\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 658 Total reward: 73.0 Average reward fake: 0.4993961751461029 Average reward real: 0.49987852573394775 Training q_loss: 2.0925 Training g_loss: 2.0761 Training d_loss: 1.3854 Explore P: 0.0474\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 659 Total reward: 36.0 Average reward fake: 0.49961167573928833 Average reward real: 0.49982619285583496 Training q_loss: 2.1432 Training g_loss: 2.0782 Training d_loss: 1.3858 Explore P: 0.0472\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 660 Total reward: 52.0 Average reward fake: 0.49948006868362427 Average reward real: 0.5005283355712891 Training q_loss: 2.2382 Training g_loss: 2.0749 Training d_loss: 1.3842 Explore P: 0.0470\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 661 Total reward: 73.0 Average reward fake: 0.49999549984931946 Average reward real: 0.5009865760803223 Training q_loss: 2.2552 Training g_loss: 2.0773 Training d_loss: 1.3842 Explore P: 0.0468\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 662 Total reward: 128.0 Average reward fake: 0.5008634924888611 Average reward real: 0.4973163604736328 Training q_loss: 2.0921 Training g_loss: 2.0716 Training d_loss: 1.3937 Explore P: 0.0463\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 663 Total reward: 73.0 Average reward fake: 0.502983033657074 Average reward real: 0.49790680408477783 Training q_loss: 2.0887 Training g_loss: 2.0818 Training d_loss: 1.3960 Explore P: 0.0460\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 664 Total reward: 60.0 Average reward fake: 0.5001947283744812 Average reward real: 0.49912330508232117 Training q_loss: 2.1282 Training g_loss: 2.0756 Training d_loss: 1.3885 Explore P: 0.0458\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 665 Total reward: 146.0 Average reward fake: 0.5001288056373596 Average reward real: 0.50022292137146 Training q_loss: 2.0767 Training g_loss: 2.0744 Training d_loss: 1.3861 Explore P: 0.0453\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 666 Total reward: 82.0 Average reward fake: 0.499825119972229 Average reward real: 0.5002127289772034 Training q_loss: 2.0852 Training g_loss: 2.0726 Training d_loss: 1.3856 Explore P: 0.0450\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 667 Total reward: 55.0 Average reward fake: 0.5006139278411865 Average reward real: 0.500409722328186 Training q_loss: 2.1040 Training g_loss: 2.0766 Training d_loss: 1.3865 Explore P: 0.0448\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 668 Total reward: 26.0 Average reward fake: 0.4992785155773163 Average reward real: 0.49996304512023926 Training q_loss: 2.1531 Training g_loss: 2.0744 Training d_loss: 1.3849 Explore P: 0.0447\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 669 Total reward: 44.0 Average reward fake: 0.5000746250152588 Average reward real: 0.5003401637077332 Training q_loss: 2.1608 Training g_loss: 2.0740 Training d_loss: 1.3856 Explore P: 0.0446\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 670 Total reward: 34.0 Average reward fake: 0.500572681427002 Average reward real: 0.5007357597351074 Training q_loss: 2.1924 Training g_loss: 2.0749 Training d_loss: 1.3859 Explore P: 0.0445\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 671 Total reward: 90.0 Average reward fake: 0.4991263449192047 Average reward real: 0.49982020258903503 Training q_loss: 2.0918 Training g_loss: 2.0760 Training d_loss: 1.3848 Explore P: 0.0442\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 672 Total reward: 35.0 Average reward fake: 0.49972230195999146 Average reward real: 0.5000425577163696 Training q_loss: 2.0967 Training g_loss: 2.0792 Training d_loss: 1.3857 Explore P: 0.0440\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 673 Total reward: 64.0 Average reward fake: 0.4991720914840698 Average reward real: 0.49942338466644287 Training q_loss: 2.1107 Training g_loss: 2.0755 Training d_loss: 1.3860 Explore P: 0.0438\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 674 Total reward: 40.0 Average reward fake: 0.4997175633907318 Average reward real: 0.5008701086044312 Training q_loss: 2.1197 Training g_loss: 2.0733 Training d_loss: 1.3842 Explore P: 0.0437\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 675 Total reward: 90.0 Average reward fake: 0.4995449483394623 Average reward real: 0.4998229146003723 Training q_loss: 2.1021 Training g_loss: 2.0743 Training d_loss: 1.3859 Explore P: 0.0434\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 676 Total reward: 161.0 Average reward fake: 0.5000319480895996 Average reward real: 0.5000836849212646 Training q_loss: 2.0828 Training g_loss: 2.0749 Training d_loss: 1.3863 Explore P: 0.0429\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 677 Total reward: 32.0 Average reward fake: 0.5002950429916382 Average reward real: 0.4996695816516876 Training q_loss: 2.2816 Training g_loss: 2.0750 Training d_loss: 1.3876 Explore P: 0.0427\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 678 Total reward: 39.0 Average reward fake: 0.5001252889633179 Average reward real: 0.5002605319023132 Training q_loss: 2.1238 Training g_loss: 2.0747 Training d_loss: 1.3864 Explore P: 0.0426\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 679 Total reward: 64.0 Average reward fake: 0.500037670135498 Average reward real: 0.5005365610122681 Training q_loss: 2.0815 Training g_loss: 2.0764 Training d_loss: 1.3854 Explore P: 0.0424\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 680 Total reward: 79.0 Average reward fake: 0.49907389283180237 Average reward real: 0.5000789761543274 Training q_loss: 2.1017 Training g_loss: 2.0808 Training d_loss: 1.3856 Explore P: 0.0422\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 681 Total reward: 55.0 Average reward fake: 0.49960213899612427 Average reward real: 0.4985849857330322 Training q_loss: 2.0982 Training g_loss: 2.0738 Training d_loss: 1.3884 Explore P: 0.0420\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 682 Total reward: 40.0 Average reward fake: 0.5011492371559143 Average reward real: 0.5009480714797974 Training q_loss: 2.1011 Training g_loss: 2.0826 Training d_loss: 1.3870 Explore P: 0.0419\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 683 Total reward: 40.0 Average reward fake: 0.5002573132514954 Average reward real: 0.49987372756004333 Training q_loss: 2.0833 Training g_loss: 2.0740 Training d_loss: 1.3870 Explore P: 0.0417\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 684 Total reward: 66.0 Average reward fake: 0.5000197887420654 Average reward real: 0.4987504482269287 Training q_loss: 2.1047 Training g_loss: 2.0765 Training d_loss: 1.3894 Explore P: 0.0415\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 685 Total reward: 32.0 Average reward fake: 0.500572919845581 Average reward real: 0.5006704926490784 Training q_loss: 2.1425 Training g_loss: 2.0794 Training d_loss: 1.3861 Explore P: 0.0414\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 686 Total reward: 119.0 Average reward fake: 0.4991798400878906 Average reward real: 0.5000621676445007 Training q_loss: 2.0917 Training g_loss: 2.0754 Training d_loss: 1.3846 Explore P: 0.0410\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 687 Total reward: 49.0 Average reward fake: 0.5001086592674255 Average reward real: 0.5004767775535583 Training q_loss: 2.0942 Training g_loss: 2.0762 Training d_loss: 1.3857 Explore P: 0.0409\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 688 Total reward: 67.0 Average reward fake: 0.49973639845848083 Average reward real: 0.5007621645927429 Training q_loss: 2.0903 Training g_loss: 2.0798 Training d_loss: 1.3843 Explore P: 0.0407\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 689 Total reward: 38.0 Average reward fake: 0.49997633695602417 Average reward real: 0.500152587890625 Training q_loss: 2.1528 Training g_loss: 2.0748 Training d_loss: 1.3860 Explore P: 0.0406\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 690 Total reward: 91.0 Average reward fake: 0.5005823373794556 Average reward real: 0.499759703874588 Training q_loss: 2.1100 Training g_loss: 2.0745 Training d_loss: 1.3881 Explore P: 0.0403\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards and losses list for plotting\n",
    "rewards_list, rewards_fake_list, rewards_real_list = [], [], []\n",
    "q_loss_list, g_loss_list, d_loss_list = [], [], [] \n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #     # Restore/load the trained model \n",
    "    #     #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #     saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        \n",
    "        # Env/agent steps/batches/minibatches\n",
    "        total_reward, rewards_fake_mean, rewards_real_mean = 0, 0, 0\n",
    "        q_loss, g_loss, d_loss = 0, 0, 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from model\n",
    "                feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "                actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "                action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Episode/epoch training is done/failed!\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Average reward fake: {}'.format(rewards_fake_mean),\n",
    "                      'Average reward real: {}'.format(rewards_real_mean),\n",
    "                      'Training q_loss: {:.4f}'.format(q_loss),\n",
    "                      'Training g_loss: {:.4f}'.format(g_loss),\n",
    "                      'Training d_loss: {:.4f}'.format(d_loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                \n",
    "                # total rewards and losses for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                rewards_fake_list.append((ep, rewards_fake_mean))\n",
    "                rewards_real_list.append((ep, rewards_real_mean))\n",
    "                q_loss_list.append((ep, q_loss))\n",
    "                g_loss_list.append((ep, g_loss))\n",
    "                d_loss_list.append((ep, d_loss))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            #rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Calculating real current reward and next action\n",
    "            feed_dict = {model.states: states, model.actions: actions, model.next_states: next_states}\n",
    "            next_actions_logits, rewards_fake, rewards_real = sess.run([model.actions_logits, \n",
    "                                                                        model.rewards_fake, model.rewards_real], \n",
    "                                                                       feed_dict)\n",
    "            #             feed_dict={model.states: next_states}\n",
    "            #             next_actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "\n",
    "            # Mean/average fake and real rewards or rewarded generated/given actions\n",
    "            rewards_fake_mean = np.mean(rewards_fake.reshape(-1))\n",
    "            rewards_real_mean = np.mean(rewards_real.reshape(-1))\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            next_actions_logits[episode_ends] = (0, 0) # NOTE: action size\n",
    "\n",
    "            # Bellman equation: Qt = Rt + max(Qt+1)\n",
    "            #targetQs = rewards_fake.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "            targetQs = rewards_real.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "\n",
    "            # Updating/training/optimizing the model\n",
    "            feed_dict = {model.states: states, model.actions: actions, model.next_states: next_states,\n",
    "                         model.targetQs: targetQs}\n",
    "            q_loss, _ = sess.run([model.q_loss, model.q_opt], feed_dict)\n",
    "            g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict)\n",
    "            d_loss, _ = sess.run([model.d_loss, model.d_opt], feed_dict)\n",
    "            \n",
    "    # Save the trained model\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_fake_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Fake rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_real_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Real rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(q_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Q losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 1\n",
    "test_max_steps = 20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
    "\n",
    "# # # Create the env after closing it.\n",
    "# env = gym.make('CartPole-v0')\n",
    "# # env = gym.make('Acrobot-v1')\n",
    "env.reset()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore/load the trained model \n",
    "    #saver.restore(sess, 'checkpoints/QGAN-cartpole.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # iterations\n",
    "    for ep in range(test_episodes):\n",
    "        \n",
    "        # number of env/rob steps\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            \n",
    "            # Rendering the env graphics\n",
    "            env.render()\n",
    "            \n",
    "            # Get action from DQAN\n",
    "            feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "            actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # The task is done or not;\n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the env\n",
    "# WARNING: If you close, you can NOT restart again!!!!!!\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this to Deep Convolutional QAN\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

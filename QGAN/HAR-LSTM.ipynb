{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAR classification \n",
    "# Author: Burak Himmetoglu\n",
    "# 8/15/2017\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_data(data_path, split = \"train\"):\n",
    "\t\"\"\" Read data \"\"\"\n",
    "\n",
    "\t# Fixed params\n",
    "\tn_class = 6\n",
    "\tn_steps = 128\n",
    "\n",
    "\t# Paths\n",
    "\tpath_ = os.path.join(data_path, split)\n",
    "\tpath_signals = os.path.join(path_, \"Inertial_Signals\")\n",
    "\n",
    "\t# Read labels and one-hot encode\n",
    "\tlabel_path = os.path.join(path_, \"y_\" + split + \".txt\")\n",
    "\tlabels = pd.read_csv(label_path, header = None)\n",
    "\n",
    "\t# Read time-series data\n",
    "\tchannel_files = os.listdir(path_signals)\n",
    "\tchannel_files.sort()\n",
    "\tn_channels = len(channel_files)\n",
    "\tposix = len(split) + 5\n",
    "\n",
    "\t# Initiate array\n",
    "\tlist_of_channels = []\n",
    "\tX = np.zeros((len(labels), n_steps, n_channels))\n",
    "\ti_ch = 0\n",
    "\tfor fil_ch in channel_files:\n",
    "\t\tchannel_name = fil_ch[:-posix]\n",
    "\t\tdat_ = pd.read_csv(os.path.join(path_signals,fil_ch), delim_whitespace = True, header = None)\n",
    "\t\tX[:,:,i_ch] = dat_.as_matrix()\n",
    "\n",
    "\t\t# Record names\n",
    "\t\tlist_of_channels.append(channel_name)\n",
    "\n",
    "\t\t# iterate\n",
    "\t\ti_ch += 1\n",
    "\n",
    "\t# Return \n",
    "\treturn X, labels[0].values, list_of_channels\n",
    "\n",
    "# def standardize(train, test):\n",
    "# \t\"\"\" Standardize data \"\"\"\n",
    "\n",
    "# \t# Standardize train and test\n",
    "# \tX_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n",
    "# \tX_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n",
    "\n",
    "# \treturn X_train, X_test\n",
    "\n",
    "# def one_hot(labels, n_class = 6):\n",
    "# \t\"\"\" One-hot encoding \"\"\"\n",
    "# \texpansion = np.eye(n_class)\n",
    "# \ty = expansion[:, labels-1].T\n",
    "# \tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "# \treturn y\n",
    "\n",
    "def get_batches(X, y, batch_size = 100):\n",
    "\t\"\"\" Return a generator for batches \"\"\"\n",
    "\tn_batches = len(X) // batch_size\n",
    "\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "\t# Loop over batches and yield\n",
    "\tfor b in range(0, len(X), batch_size):\n",
    "\t\tyield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/ipykernel_launcher.py:37: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain, list_ch_train = read_data(data_path=\"/home/arasdar/datasets/har-data/\", split=\"train\") # train\n",
    "Xtest, Ytest, list_ch_test = read_data(data_path=\"/home/arasdar/datasets/har-data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize\n",
    "# X_train, X_test = standardize(X_train, X_test)\n",
    "# print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, stratify = Ytrain, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5514, 128, 9) float64\n",
      "(1838, 128, 9) float64\n",
      "(2947, 128, 9) float64\n",
      "(5514,) int64\n",
      "(1838,) int64\n",
      "(2947,) int64\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape, Xtrain.dtype)\n",
    "print(Xvalid.shape, Xvalid.dtype)\n",
    "print(Xtest.shape, Xtest.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype)\n",
    "print(Yvalid.shape, Yvalid.dtype)\n",
    "print(Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tr = one_hot(lab_tr)\n",
    "# y_vld = one_hot(lab_vld)\n",
    "# y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 1        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "# with graph.as_default():\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "indices_ = tf.placeholder(tf.int32, [None], name = 'indices')\n",
    "#     keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "#     learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 9)\n",
      "(128, ?, 9)\n",
      "(?, 9)\n",
      "128 (?, 9)\n"
     ]
    }
   ],
   "source": [
    "# with graph.as_default():\n",
    "# Construct the LSTM inputs and LSTM cells\n",
    "print(inputs_.shape)\n",
    "lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "print(lstm_in.shape)\n",
    "lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "print(lstm_in.shape)\n",
    "\n",
    "# Open up the tensor into a list of seq_len pieces\n",
    "lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "print(len(lstm_in), lstm_in[0].shape)\n",
    "\n",
    "# Add LSTM layers\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "#     drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([lstm] * lstm_layers)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with graph.as_default():\n",
    "# with tf.variable_scope('RNN', reuse=True):\n",
    "outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32, initial_state = initial_state)\n",
    "\n",
    "# We only need the last output tensor to pass into a classifier\n",
    "logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "labels = tf.one_hot(depth=n_classes, indices=indices_)\n",
    "\n",
    "# Loss/cost using labels and logits\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "\n",
    "# Accuracy using logits and labels\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "# Optimize using loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost) # No grad clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 (600, 27)\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs), outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"logits/BiasAdd:0\", shape=(600, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Train loss: 1.439217448234558 Train acc: 0.1461111158132553\n",
      "Epoch: 0/1000 Valid loss: 1.4121150970458984 Valid acc: 0.1505555510520935\n",
      "Epoch: 1/1000 Train loss: 1.3941774368286133 Train acc: 0.19925925135612488\n",
      "Epoch: 1/1000 Valid loss: 1.3711084127426147 Valid acc: 0.25333333015441895\n",
      "Epoch: 2/1000 Train loss: 1.3531736135482788 Train acc: 0.2812963128089905\n",
      "Epoch: 2/1000 Valid loss: 1.3281340599060059 Valid acc: 0.30444446206092834\n",
      "Epoch: 3/1000 Train loss: 1.3050353527069092 Train acc: 0.3361111283302307\n",
      "Epoch: 3/1000 Valid loss: 1.2717067003250122 Valid acc: 0.3611111342906952\n",
      "Epoch: 4/1000 Train loss: 1.2444381713867188 Train acc: 0.3409259021282196\n",
      "Epoch: 4/1000 Valid loss: 1.2054648399353027 Valid acc: 0.3188888728618622\n",
      "Epoch: 5/1000 Train loss: 1.191493272781372 Train acc: 0.3248148262500763\n",
      "Epoch: 5/1000 Valid loss: 1.1501469612121582 Valid acc: 0.35500001907348633\n",
      "Epoch: 6/1000 Train loss: 1.1383728981018066 Train acc: 0.3714815080165863\n",
      "Epoch: 6/1000 Valid loss: 1.1008435487747192 Valid acc: 0.38277778029441833\n",
      "Epoch: 7/1000 Train loss: 1.0869498252868652 Train acc: 0.3866666555404663\n",
      "Epoch: 7/1000 Valid loss: 1.0611251592636108 Valid acc: 0.39666667580604553\n",
      "Epoch: 8/1000 Train loss: 1.0335397720336914 Train acc: 0.4103703796863556\n",
      "Epoch: 8/1000 Valid loss: 1.0015106201171875 Valid acc: 0.42666664719581604\n",
      "Epoch: 9/1000 Train loss: 0.9759945273399353 Train acc: 0.44111111760139465\n",
      "Epoch: 9/1000 Valid loss: 0.9394819140434265 Valid acc: 0.4577777683734894\n",
      "Epoch: 10/1000 Train loss: 0.9407131671905518 Train acc: 0.4568518400192261\n",
      "Epoch: 10/1000 Valid loss: 0.9117367267608643 Valid acc: 0.448888897895813\n",
      "Epoch: 11/1000 Train loss: 0.8850787281990051 Train acc: 0.47074073553085327\n",
      "Epoch: 11/1000 Valid loss: 0.8599420189857483 Valid acc: 0.4888888895511627\n",
      "Epoch: 12/1000 Train loss: 0.852165699005127 Train acc: 0.4814814329147339\n",
      "Epoch: 12/1000 Valid loss: 0.8381139636039734 Valid acc: 0.5049999952316284\n",
      "Epoch: 13/1000 Train loss: 0.8176630735397339 Train acc: 0.5140740871429443\n",
      "Epoch: 13/1000 Valid loss: 0.8066802024841309 Valid acc: 0.5294444561004639\n",
      "Epoch: 14/1000 Train loss: 0.7858066558837891 Train acc: 0.5290740728378296\n",
      "Epoch: 14/1000 Valid loss: 0.7693861126899719 Valid acc: 0.5416666865348816\n",
      "Epoch: 15/1000 Train loss: 0.7555534839630127 Train acc: 0.5538888573646545\n",
      "Epoch: 15/1000 Valid loss: 0.7537477016448975 Valid acc: 0.5450000166893005\n",
      "Epoch: 16/1000 Train loss: 0.7458203434944153 Train acc: 0.5537036657333374\n",
      "Epoch: 16/1000 Valid loss: 0.7356789708137512 Valid acc: 0.5588889122009277\n",
      "Epoch: 17/1000 Train loss: 0.7218276262283325 Train acc: 0.5627777576446533\n",
      "Epoch: 17/1000 Valid loss: 0.7254769802093506 Valid acc: 0.5638888478279114\n",
      "Epoch: 18/1000 Train loss: 0.7462777495384216 Train acc: 0.5351852178573608\n",
      "Epoch: 18/1000 Valid loss: 0.7635164260864258 Valid acc: 0.5244444012641907\n",
      "Epoch: 19/1000 Train loss: 0.9831074476242065 Train acc: 0.4224074184894562\n",
      "Epoch: 19/1000 Valid loss: 1.0560795068740845 Valid acc: 0.38722220063209534\n",
      "Epoch: 20/1000 Train loss: 0.9713218212127686 Train acc: 0.4131481647491455\n",
      "Epoch: 20/1000 Valid loss: 0.9734167456626892 Valid acc: 0.40833333134651184\n",
      "Epoch: 21/1000 Train loss: 0.8973851799964905 Train acc: 0.4444444477558136\n",
      "Epoch: 21/1000 Valid loss: 0.8662047982215881 Valid acc: 0.43611112236976624\n",
      "Epoch: 22/1000 Train loss: 0.8702836632728577 Train acc: 0.44240739941596985\n",
      "Epoch: 22/1000 Valid loss: 0.8329775333404541 Valid acc: 0.46388888359069824\n",
      "Epoch: 23/1000 Train loss: 0.8113837242126465 Train acc: 0.47962963581085205\n",
      "Epoch: 23/1000 Valid loss: 0.8073520660400391 Valid acc: 0.47333332896232605\n",
      "Epoch: 24/1000 Train loss: 0.7897903323173523 Train acc: 0.48000001907348633\n",
      "Epoch: 24/1000 Valid loss: 0.7869073748588562 Valid acc: 0.46611109375953674\n",
      "Epoch: 25/1000 Train loss: 0.7726831436157227 Train acc: 0.48537036776542664\n",
      "Epoch: 25/1000 Valid loss: 0.7709372043609619 Valid acc: 0.48777779936790466\n",
      "Epoch: 26/1000 Train loss: 0.762340784072876 Train acc: 0.5051851272583008\n",
      "Epoch: 26/1000 Valid loss: 0.7628268599510193 Valid acc: 0.4950000047683716\n",
      "Epoch: 27/1000 Train loss: 0.752081573009491 Train acc: 0.5079629421234131\n",
      "Epoch: 27/1000 Valid loss: 0.7553601861000061 Valid acc: 0.4933333396911621\n",
      "Epoch: 28/1000 Train loss: 0.7419586181640625 Train acc: 0.5153703689575195\n",
      "Epoch: 28/1000 Valid loss: 0.7510571479797363 Valid acc: 0.49888888001441956\n",
      "Epoch: 29/1000 Train loss: 0.7365360856056213 Train acc: 0.5201852321624756\n",
      "Epoch: 29/1000 Valid loss: 0.7395003437995911 Valid acc: 0.504444420337677\n",
      "Epoch: 30/1000 Train loss: 0.7267300486564636 Train acc: 0.5246296525001526\n",
      "Epoch: 30/1000 Valid loss: 0.7320963740348816 Valid acc: 0.5038889050483704\n",
      "Epoch: 31/1000 Train loss: 0.7152900099754333 Train acc: 0.5325925350189209\n",
      "Epoch: 31/1000 Valid loss: 0.7255713939666748 Valid acc: 0.5244444012641907\n",
      "Epoch: 32/1000 Train loss: 0.70718914270401 Train acc: 0.5377777814865112\n",
      "Epoch: 32/1000 Valid loss: 0.715287983417511 Valid acc: 0.5361111164093018\n",
      "Epoch: 33/1000 Train loss: 0.6974865198135376 Train acc: 0.5514814853668213\n",
      "Epoch: 33/1000 Valid loss: 0.707089900970459 Valid acc: 0.5461111068725586\n",
      "Epoch: 34/1000 Train loss: 0.6885955929756165 Train acc: 0.5605555772781372\n",
      "Epoch: 34/1000 Valid loss: 0.699308454990387 Valid acc: 0.5577778220176697\n",
      "Epoch: 35/1000 Train loss: 0.6806566119194031 Train acc: 0.5699999928474426\n",
      "Epoch: 35/1000 Valid loss: 0.6918603777885437 Valid acc: 0.5616666674613953\n",
      "Epoch: 36/1000 Train loss: 0.6738021373748779 Train acc: 0.5707407593727112\n",
      "Epoch: 36/1000 Valid loss: 0.6832926869392395 Valid acc: 0.5638888478279114\n",
      "Epoch: 37/1000 Train loss: 0.6634619832038879 Train acc: 0.5766666531562805\n",
      "Epoch: 37/1000 Valid loss: 0.6751449704170227 Valid acc: 0.5727777481079102\n",
      "Epoch: 38/1000 Train loss: 0.6528189778327942 Train acc: 0.5881481766700745\n",
      "Epoch: 38/1000 Valid loss: 0.665012776851654 Valid acc: 0.5799999833106995\n",
      "Epoch: 39/1000 Train loss: 0.6442078948020935 Train acc: 0.5959259867668152\n",
      "Epoch: 39/1000 Valid loss: 0.6558248400688171 Valid acc: 0.5844444632530212\n",
      "Epoch: 40/1000 Train loss: 0.6352526545524597 Train acc: 0.5994445085525513\n",
      "Epoch: 40/1000 Valid loss: 0.6494258046150208 Valid acc: 0.5777778029441833\n",
      "Epoch: 41/1000 Train loss: 0.6252932548522949 Train acc: 0.6024073958396912\n",
      "Epoch: 41/1000 Valid loss: 0.6293396353721619 Valid acc: 0.5972222685813904\n",
      "Epoch: 42/1000 Train loss: 0.6119515299797058 Train acc: 0.6087037324905396\n",
      "Epoch: 42/1000 Valid loss: 0.6376191973686218 Valid acc: 0.5933333039283752\n",
      "Epoch: 43/1000 Train loss: 0.6092466711997986 Train acc: 0.609259307384491\n",
      "Epoch: 43/1000 Valid loss: 0.6094472408294678 Valid acc: 0.6050000190734863\n",
      "Epoch: 44/1000 Train loss: 0.5945833921432495 Train acc: 0.6122222542762756\n",
      "Epoch: 44/1000 Valid loss: 0.6112724542617798 Valid acc: 0.5861111283302307\n",
      "Epoch: 45/1000 Train loss: 0.5974707007408142 Train acc: 0.5983333587646484\n",
      "Epoch: 45/1000 Valid loss: 0.6094375252723694 Valid acc: 0.587222158908844\n",
      "Epoch: 46/1000 Train loss: 0.5901401042938232 Train acc: 0.6107407212257385\n",
      "Epoch: 46/1000 Valid loss: 0.604360818862915 Valid acc: 0.5999999642372131\n",
      "Epoch: 47/1000 Train loss: 0.5807134509086609 Train acc: 0.6150000095367432\n",
      "Epoch: 47/1000 Valid loss: 0.5856380462646484 Valid acc: 0.6155555844306946\n",
      "Epoch: 48/1000 Train loss: 0.5694105625152588 Train acc: 0.6209259629249573\n",
      "Epoch: 48/1000 Valid loss: 0.5808818936347961 Valid acc: 0.6094444394111633\n",
      "Epoch: 49/1000 Train loss: 0.5604363083839417 Train acc: 0.6224073767662048\n",
      "Epoch: 49/1000 Valid loss: 0.5846365094184875 Valid acc: 0.597777783870697\n",
      "Epoch: 50/1000 Train loss: 0.5654491782188416 Train acc: 0.6114814281463623\n",
      "Epoch: 50/1000 Valid loss: 0.5782787799835205 Valid acc: 0.6016666889190674\n",
      "Epoch: 51/1000 Train loss: 0.5553894639015198 Train acc: 0.6211110949516296\n",
      "Epoch: 51/1000 Valid loss: 0.5699287056922913 Valid acc: 0.6061111092567444\n",
      "Epoch: 52/1000 Train loss: 0.5540308356285095 Train acc: 0.6188889145851135\n",
      "Epoch: 52/1000 Valid loss: 0.5600228309631348 Valid acc: 0.6127777695655823\n",
      "Epoch: 53/1000 Train loss: 0.548015832901001 Train acc: 0.6251851916313171\n",
      "Epoch: 53/1000 Valid loss: 0.5474540591239929 Valid acc: 0.6194444298744202\n",
      "Epoch: 54/1000 Train loss: 0.5393568873405457 Train acc: 0.6294444799423218\n",
      "Epoch: 54/1000 Valid loss: 0.5567045211791992 Valid acc: 0.6322222352027893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/1000 Train loss: 0.5331711173057556 Train acc: 0.6379629969596863\n",
      "Epoch: 55/1000 Valid loss: 0.5382387042045593 Valid acc: 0.620555579662323\n",
      "Epoch: 56/1000 Train loss: 0.5319458842277527 Train acc: 0.6281481981277466\n",
      "Epoch: 56/1000 Valid loss: 0.5405706763267517 Valid acc: 0.6333333253860474\n",
      "Epoch: 57/1000 Train loss: 0.5184677243232727 Train acc: 0.6370370388031006\n",
      "Epoch: 57/1000 Valid loss: 0.536198079586029 Valid acc: 0.6377777457237244\n",
      "Epoch: 58/1000 Train loss: 0.5206047892570496 Train acc: 0.6320370435714722\n",
      "Epoch: 58/1000 Valid loss: 0.5214328765869141 Valid acc: 0.6383333206176758\n",
      "Epoch: 59/1000 Train loss: 0.5073747038841248 Train acc: 0.6412963271141052\n",
      "Epoch: 59/1000 Valid loss: 0.5114033818244934 Valid acc: 0.6277777552604675\n",
      "Epoch: 60/1000 Train loss: 0.49829113483428955 Train acc: 0.6348148584365845\n",
      "Epoch: 60/1000 Valid loss: 0.5188214182853699 Valid acc: 0.6194444298744202\n",
      "Epoch: 61/1000 Train loss: 0.49408209323883057 Train acc: 0.6355555057525635\n",
      "Epoch: 61/1000 Valid loss: 0.5017619729042053 Valid acc: 0.6311110854148865\n",
      "Epoch: 62/1000 Train loss: 0.48726946115493774 Train acc: 0.6483333110809326\n",
      "Epoch: 62/1000 Valid loss: 0.49507203698158264 Valid acc: 0.6466667056083679\n",
      "Epoch: 63/1000 Train loss: 0.479952335357666 Train acc: 0.6498148441314697\n",
      "Epoch: 63/1000 Valid loss: 0.4847158193588257 Valid acc: 0.6433333158493042\n",
      "Epoch: 64/1000 Train loss: 0.47520849108695984 Train acc: 0.6512963175773621\n",
      "Epoch: 64/1000 Valid loss: 0.4871000051498413 Valid acc: 0.64000004529953\n",
      "Epoch: 65/1000 Train loss: 0.4724689722061157 Train acc: 0.6551851630210876\n",
      "Epoch: 65/1000 Valid loss: 0.4926368296146393 Valid acc: 0.6405555605888367\n",
      "Epoch: 66/1000 Train loss: 0.48021644353866577 Train acc: 0.6492592692375183\n",
      "Epoch: 66/1000 Valid loss: 0.48891106247901917 Valid acc: 0.6366666555404663\n",
      "Epoch: 67/1000 Train loss: 0.5020989775657654 Train acc: 0.6349999904632568\n",
      "Epoch: 67/1000 Valid loss: 0.5678407549858093 Valid acc: 0.5988888740539551\n",
      "Epoch: 68/1000 Train loss: 0.5220115184783936 Train acc: 0.6320369839668274\n",
      "Epoch: 68/1000 Valid loss: 0.5020056366920471 Valid acc: 0.6355555653572083\n",
      "Epoch: 69/1000 Train loss: 0.5016712546348572 Train acc: 0.6377778053283691\n",
      "Epoch: 69/1000 Valid loss: 0.5120479464530945 Valid acc: 0.621666669845581\n",
      "Epoch: 70/1000 Train loss: 0.4982237219810486 Train acc: 0.6331481337547302\n",
      "Epoch: 70/1000 Valid loss: 0.4970199167728424 Valid acc: 0.6322222352027893\n",
      "Epoch: 71/1000 Train loss: 0.48381173610687256 Train acc: 0.6309258937835693\n",
      "Epoch: 71/1000 Valid loss: 0.494060754776001 Valid acc: 0.6211110949516296\n",
      "Epoch: 72/1000 Train loss: 0.46907296776771545 Train acc: 0.6461111307144165\n",
      "Epoch: 72/1000 Valid loss: 0.4792293310165405 Valid acc: 0.6405555605888367\n",
      "Epoch: 73/1000 Train loss: 0.46142420172691345 Train acc: 0.6533333659172058\n",
      "Epoch: 73/1000 Valid loss: 0.4754696786403656 Valid acc: 0.6455555558204651\n",
      "Epoch: 74/1000 Train loss: 0.4545861780643463 Train acc: 0.6572222113609314\n",
      "Epoch: 74/1000 Valid loss: 0.4559776782989502 Valid acc: 0.6566666960716248\n",
      "Epoch: 75/1000 Train loss: 0.4456208050251007 Train acc: 0.6618518233299255\n",
      "Epoch: 75/1000 Valid loss: 0.4627216160297394 Valid acc: 0.6427778005599976\n",
      "Epoch: 76/1000 Train loss: 0.4435842037200928 Train acc: 0.6631481647491455\n",
      "Epoch: 76/1000 Valid loss: 0.4517761766910553 Valid acc: 0.6516666412353516\n",
      "Epoch: 77/1000 Train loss: 0.4359866678714752 Train acc: 0.6625926494598389\n",
      "Epoch: 77/1000 Valid loss: 0.4560154378414154 Valid acc: 0.6500000357627869\n",
      "Epoch: 78/1000 Train loss: 0.44001758098602295 Train acc: 0.6616666316986084\n",
      "Epoch: 78/1000 Valid loss: 0.4474398195743561 Valid acc: 0.6544444561004639\n",
      "Epoch: 79/1000 Train loss: 0.42964059114456177 Train acc: 0.6694444417953491\n",
      "Epoch: 79/1000 Valid loss: 0.44376954436302185 Valid acc: 0.6566666960716248\n",
      "Epoch: 80/1000 Train loss: 0.42548394203186035 Train acc: 0.6653703451156616\n",
      "Epoch: 80/1000 Valid loss: 0.44696807861328125 Valid acc: 0.6544443964958191\n",
      "Epoch: 81/1000 Train loss: 0.42430126667022705 Train acc: 0.6712962985038757\n",
      "Epoch: 81/1000 Valid loss: 0.44159626960754395 Valid acc: 0.6644444465637207\n",
      "Epoch: 82/1000 Train loss: 0.4210675358772278 Train acc: 0.6733333468437195\n",
      "Epoch: 82/1000 Valid loss: 0.43143853545188904 Valid acc: 0.6694445013999939\n",
      "Epoch: 83/1000 Train loss: 0.42152664065361023 Train acc: 0.6724073886871338\n",
      "Epoch: 83/1000 Valid loss: 0.43513116240501404 Valid acc: 0.6688888669013977\n",
      "Epoch: 84/1000 Train loss: 0.4088619649410248 Train acc: 0.6796296238899231\n",
      "Epoch: 84/1000 Valid loss: 0.42935243248939514 Valid acc: 0.666111171245575\n",
      "Epoch: 85/1000 Train loss: 0.41068506240844727 Train acc: 0.6742592453956604\n",
      "Epoch: 85/1000 Valid loss: 0.4307168424129486 Valid acc: 0.6633333563804626\n",
      "Epoch: 86/1000 Train loss: 0.4073474407196045 Train acc: 0.6772222518920898\n",
      "Epoch: 86/1000 Valid loss: 0.43404221534729004 Valid acc: 0.6577777862548828\n",
      "Epoch: 87/1000 Train loss: 0.4126027822494507 Train acc: 0.6725925803184509\n",
      "Epoch: 87/1000 Valid loss: 0.4413067102432251 Valid acc: 0.6483333110809326\n",
      "Epoch: 88/1000 Train loss: 0.42165571451187134 Train acc: 0.6727778315544128\n",
      "Epoch: 88/1000 Valid loss: 0.43626511096954346 Valid acc: 0.6711111068725586\n",
      "Epoch: 89/1000 Train loss: 0.4550643563270569 Train acc: 0.6503703594207764\n",
      "Epoch: 89/1000 Valid loss: 0.47963473200798035 Valid acc: 0.6266666650772095\n",
      "Epoch: 90/1000 Train loss: 0.4449126422405243 Train acc: 0.6579630374908447\n",
      "Epoch: 90/1000 Valid loss: 0.448280930519104 Valid acc: 0.6544444561004639\n",
      "Epoch: 91/1000 Train loss: 0.444050669670105 Train acc: 0.6644444465637207\n",
      "Epoch: 91/1000 Valid loss: 0.44150540232658386 Valid acc: 0.6588888764381409\n",
      "Epoch: 92/1000 Train loss: 0.4518929123878479 Train acc: 0.6533333659172058\n",
      "Epoch: 92/1000 Valid loss: 0.45158910751342773 Valid acc: 0.6544444561004639\n",
      "Epoch: 93/1000 Train loss: 0.4264853298664093 Train acc: 0.6690740585327148\n",
      "Epoch: 93/1000 Valid loss: 0.41906294226646423 Valid acc: 0.6677777767181396\n",
      "Epoch: 94/1000 Train loss: 0.40574467182159424 Train acc: 0.6712963581085205\n",
      "Epoch: 94/1000 Valid loss: 0.42166101932525635 Valid acc: 0.6738889217376709\n",
      "Epoch: 95/1000 Train loss: 0.41289156675338745 Train acc: 0.6762962937355042\n",
      "Epoch: 95/1000 Valid loss: 0.43360140919685364 Valid acc: 0.6555555462837219\n",
      "Epoch: 96/1000 Train loss: 0.454753041267395 Train acc: 0.661481499671936\n",
      "Epoch: 96/1000 Valid loss: 0.4702613353729248 Valid acc: 0.6577777862548828\n",
      "Epoch: 97/1000 Train loss: 0.46975237131118774 Train acc: 0.669259250164032\n",
      "Epoch: 97/1000 Valid loss: 0.4787029027938843 Valid acc: 0.6505555510520935\n",
      "Epoch: 98/1000 Train loss: 0.45120537281036377 Train acc: 0.6607407331466675\n",
      "Epoch: 98/1000 Valid loss: 0.4486054480075836 Valid acc: 0.67166668176651\n",
      "Epoch: 99/1000 Train loss: 0.42145445942878723 Train acc: 0.6751851439476013\n",
      "Epoch: 99/1000 Valid loss: 0.42971527576446533 Valid acc: 0.6616666913032532\n",
      "Epoch: 100/1000 Train loss: 0.41043350100517273 Train acc: 0.6770370006561279\n",
      "Epoch: 100/1000 Valid loss: 0.41224193572998047 Valid acc: 0.6772222518920898\n",
      "Epoch: 101/1000 Train loss: 0.4169951379299164 Train acc: 0.6840741634368896\n",
      "Epoch: 101/1000 Valid loss: 0.433638334274292 Valid acc: 0.6583333611488342\n",
      "Epoch: 102/1000 Train loss: 0.42934998869895935 Train acc: 0.6766666173934937\n",
      "Epoch: 102/1000 Valid loss: 0.45976611971855164 Valid acc: 0.6594443917274475\n",
      "Epoch: 103/1000 Train loss: 0.47851625084877014 Train acc: 0.655925989151001\n",
      "Epoch: 103/1000 Valid loss: 0.465663880109787 Valid acc: 0.6633333563804626\n",
      "Epoch: 104/1000 Train loss: 0.4360869228839874 Train acc: 0.6742593050003052\n",
      "Epoch: 104/1000 Valid loss: 0.4119966924190521 Valid acc: 0.6783333420753479\n",
      "Epoch: 105/1000 Train loss: 0.4066704213619232 Train acc: 0.6968518495559692\n",
      "Epoch: 105/1000 Valid loss: 0.4073012173175812 Valid acc: 0.6805555820465088\n",
      "Epoch: 106/1000 Train loss: 0.3887818157672882 Train acc: 0.7037037014961243\n",
      "Epoch: 106/1000 Valid loss: 0.3789069652557373 Valid acc: 0.6966666579246521\n",
      "Epoch: 107/1000 Train loss: 0.395053505897522 Train acc: 0.6940740942955017\n",
      "Epoch: 107/1000 Valid loss: 0.4162255823612213 Valid acc: 0.6766666769981384\n",
      "Epoch: 108/1000 Train loss: 0.3849393427371979 Train acc: 0.6953704357147217\n",
      "Epoch: 108/1000 Valid loss: 0.4049718379974365 Valid acc: 0.6744444370269775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109/1000 Train loss: 0.428823858499527 Train acc: 0.6794444918632507\n",
      "Epoch: 109/1000 Valid loss: 0.4246574640274048 Valid acc: 0.6644444465637207\n",
      "Epoch: 110/1000 Train loss: 0.4099773168563843 Train acc: 0.6835185289382935\n",
      "Epoch: 110/1000 Valid loss: 0.41836681962013245 Valid acc: 0.662777841091156\n",
      "Epoch: 111/1000 Train loss: 0.40657010674476624 Train acc: 0.6774073839187622\n",
      "Epoch: 111/1000 Valid loss: 0.41456320881843567 Valid acc: 0.6827778220176697\n",
      "Epoch: 112/1000 Train loss: 0.3896823823451996 Train acc: 0.7042592167854309\n",
      "Epoch: 112/1000 Valid loss: 0.3801058232784271 Valid acc: 0.6944444179534912\n",
      "Epoch: 113/1000 Train loss: 0.3911307752132416 Train acc: 0.6899999976158142\n",
      "Epoch: 113/1000 Valid loss: 0.3841873109340668 Valid acc: 0.708888828754425\n",
      "Epoch: 114/1000 Train loss: 0.38506701588630676 Train acc: 0.7000000476837158\n",
      "Epoch: 114/1000 Valid loss: 0.4211454391479492 Valid acc: 0.6566666960716248\n",
      "Epoch: 115/1000 Train loss: 0.36878976225852966 Train acc: 0.7016666531562805\n",
      "Epoch: 115/1000 Valid loss: 0.38023364543914795 Valid acc: 0.7066666483879089\n",
      "Epoch: 116/1000 Train loss: 0.3697178363800049 Train acc: 0.7037036418914795\n",
      "Epoch: 116/1000 Valid loss: 0.39781057834625244 Valid acc: 0.6727778315544128\n",
      "Epoch: 117/1000 Train loss: 0.37320709228515625 Train acc: 0.7000000476837158\n",
      "Epoch: 117/1000 Valid loss: 0.36893925070762634 Valid acc: 0.7011110782623291\n",
      "Epoch: 118/1000 Train loss: 0.34574970602989197 Train acc: 0.7129629254341125\n",
      "Epoch: 118/1000 Valid loss: 0.34795403480529785 Valid acc: 0.7011110782623291\n",
      "Epoch: 119/1000 Train loss: 0.33883070945739746 Train acc: 0.7185185551643372\n",
      "Epoch: 119/1000 Valid loss: 0.35250458121299744 Valid acc: 0.7072222232818604\n",
      "Epoch: 120/1000 Train loss: 0.3430953621864319 Train acc: 0.7170369625091553\n",
      "Epoch: 120/1000 Valid loss: 0.35996389389038086 Valid acc: 0.7055554986000061\n",
      "Epoch: 121/1000 Train loss: 0.36521291732788086 Train acc: 0.7055554986000061\n",
      "Epoch: 121/1000 Valid loss: 0.3769371509552002 Valid acc: 0.6933333277702332\n",
      "Epoch: 122/1000 Train loss: 0.37606990337371826 Train acc: 0.70203697681427\n",
      "Epoch: 122/1000 Valid loss: 0.3588753938674927 Valid acc: 0.7138888835906982\n",
      "Epoch: 123/1000 Train loss: 0.3449571430683136 Train acc: 0.7196296453475952\n",
      "Epoch: 123/1000 Valid loss: 0.3310014307498932 Valid acc: 0.7277777791023254\n",
      "Epoch: 124/1000 Train loss: 0.3273508846759796 Train acc: 0.729629635810852\n",
      "Epoch: 124/1000 Valid loss: 0.3232289254665375 Valid acc: 0.7155556082725525\n",
      "Epoch: 125/1000 Train loss: 0.3191567659378052 Train acc: 0.7298148274421692\n",
      "Epoch: 125/1000 Valid loss: 0.32348111271858215 Valid acc: 0.712222158908844\n",
      "Epoch: 126/1000 Train loss: 0.3164559304714203 Train acc: 0.7301852107048035\n",
      "Epoch: 126/1000 Valid loss: 0.315862774848938 Valid acc: 0.7266666889190674\n",
      "Epoch: 127/1000 Train loss: 0.29912102222442627 Train acc: 0.7403703927993774\n",
      "Epoch: 127/1000 Valid loss: 0.31565698981285095 Valid acc: 0.7188888192176819\n",
      "Epoch: 128/1000 Train loss: 0.30116379261016846 Train acc: 0.7370370030403137\n",
      "Epoch: 128/1000 Valid loss: 0.3106478452682495 Valid acc: 0.7216666340827942\n",
      "Epoch: 129/1000 Train loss: 0.30028036236763 Train acc: 0.7385185360908508\n",
      "Epoch: 129/1000 Valid loss: 0.3179890811443329 Valid acc: 0.7177777886390686\n",
      "Epoch: 130/1000 Train loss: 0.3123072385787964 Train acc: 0.7322222590446472\n",
      "Epoch: 130/1000 Valid loss: 0.31713587045669556 Valid acc: 0.7294445037841797\n",
      "Epoch: 131/1000 Train loss: 0.30723047256469727 Train acc: 0.7301851511001587\n",
      "Epoch: 131/1000 Valid loss: 0.309349000453949 Valid acc: 0.7244444489479065\n",
      "Epoch: 132/1000 Train loss: 0.319133460521698 Train acc: 0.7235185503959656\n",
      "Epoch: 132/1000 Valid loss: 0.3138114809989929 Valid acc: 0.7233333587646484\n",
      "Epoch: 133/1000 Train loss: 0.30098289251327515 Train acc: 0.7351852059364319\n",
      "Epoch: 133/1000 Valid loss: 0.3012273609638214 Valid acc: 0.7277777791023254\n",
      "Epoch: 134/1000 Train loss: 0.29022088646888733 Train acc: 0.7388889193534851\n",
      "Epoch: 134/1000 Valid loss: 0.291890025138855 Valid acc: 0.7316667437553406\n",
      "Epoch: 135/1000 Train loss: 0.282396137714386 Train acc: 0.742222249507904\n",
      "Epoch: 135/1000 Valid loss: 0.31262293457984924 Valid acc: 0.7133333086967468\n",
      "Epoch: 136/1000 Train loss: 0.2957441210746765 Train acc: 0.7324073910713196\n",
      "Epoch: 136/1000 Valid loss: 0.28659144043922424 Valid acc: 0.7338889241218567\n",
      "Epoch: 137/1000 Train loss: 0.2783728241920471 Train acc: 0.7392592430114746\n",
      "Epoch: 137/1000 Valid loss: 0.28381237387657166 Valid acc: 0.7283332943916321\n",
      "Epoch: 138/1000 Train loss: 0.26955175399780273 Train acc: 0.7422221899032593\n",
      "Epoch: 138/1000 Valid loss: 0.27268490195274353 Valid acc: 0.7383334040641785\n",
      "Epoch: 139/1000 Train loss: 0.276668906211853 Train acc: 0.7403703331947327\n",
      "Epoch: 139/1000 Valid loss: 0.31003057956695557 Valid acc: 0.7216666340827942\n",
      "Epoch: 140/1000 Train loss: 0.2997252643108368 Train acc: 0.7361111044883728\n",
      "Epoch: 140/1000 Valid loss: 0.30217882990837097 Valid acc: 0.730555534362793\n",
      "Epoch: 141/1000 Train loss: 0.2996567189693451 Train acc: 0.73499995470047\n",
      "Epoch: 141/1000 Valid loss: 0.28666505217552185 Valid acc: 0.7366666793823242\n",
      "Epoch: 142/1000 Train loss: 0.2850531339645386 Train acc: 0.7344444394111633\n",
      "Epoch: 142/1000 Valid loss: 0.2953411638736725 Valid acc: 0.7211111187934875\n",
      "Epoch: 143/1000 Train loss: 0.27560076117515564 Train acc: 0.7383334040641785\n",
      "Epoch: 143/1000 Valid loss: 0.27893102169036865 Valid acc: 0.7272222638130188\n",
      "Epoch: 144/1000 Train loss: 0.26507750153541565 Train acc: 0.7448147535324097\n",
      "Epoch: 144/1000 Valid loss: 0.2895260155200958 Valid acc: 0.7255555987358093\n",
      "Epoch: 145/1000 Train loss: 0.26617833971977234 Train acc: 0.7405555844306946\n",
      "Epoch: 145/1000 Valid loss: 0.28256702423095703 Valid acc: 0.7266666889190674\n",
      "Epoch: 146/1000 Train loss: 0.2783617675304413 Train acc: 0.7362963557243347\n",
      "Epoch: 146/1000 Valid loss: 0.27444303035736084 Valid acc: 0.7311111092567444\n",
      "Epoch: 147/1000 Train loss: 0.2632550001144409 Train acc: 0.738518476486206\n",
      "Epoch: 147/1000 Valid loss: 0.2714187800884247 Valid acc: 0.7294445037841797\n",
      "Epoch: 148/1000 Train loss: 0.25344371795654297 Train acc: 0.744259238243103\n",
      "Epoch: 148/1000 Valid loss: 0.2698286175727844 Valid acc: 0.7355555891990662\n",
      "Epoch: 149/1000 Train loss: 0.2568570375442505 Train acc: 0.7425925731658936\n",
      "Epoch: 149/1000 Valid loss: 0.28706368803977966 Valid acc: 0.7172222137451172\n",
      "Epoch: 150/1000 Train loss: 0.26209205389022827 Train acc: 0.73499995470047\n",
      "Epoch: 150/1000 Valid loss: 0.2794558107852936 Valid acc: 0.7194444537162781\n",
      "Epoch: 151/1000 Train loss: 0.2492634654045105 Train acc: 0.7425925731658936\n",
      "Epoch: 151/1000 Valid loss: 0.2662203013896942 Valid acc: 0.7283332943916321\n",
      "Epoch: 152/1000 Train loss: 0.2452189177274704 Train acc: 0.7429630160331726\n",
      "Epoch: 152/1000 Valid loss: 0.2708548605442047 Valid acc: 0.7300000190734863\n",
      "Epoch: 153/1000 Train loss: 0.2544320225715637 Train acc: 0.7427778244018555\n",
      "Epoch: 153/1000 Valid loss: 0.2523702085018158 Valid acc: 0.7338889241218567\n",
      "Epoch: 154/1000 Train loss: 0.24812190234661102 Train acc: 0.7405555248260498\n",
      "Epoch: 154/1000 Valid loss: 0.28167054057121277 Valid acc: 0.7094444632530212\n",
      "Epoch: 155/1000 Train loss: 0.24756741523742676 Train acc: 0.7379629611968994\n",
      "Epoch: 155/1000 Valid loss: 0.25839248299598694 Valid acc: 0.7266666889190674\n",
      "Epoch: 156/1000 Train loss: 0.23861530423164368 Train acc: 0.7470370531082153\n",
      "Epoch: 156/1000 Valid loss: 0.2620122730731964 Valid acc: 0.7272222638130188\n",
      "Epoch: 157/1000 Train loss: 0.23967044055461884 Train acc: 0.7464814782142639\n",
      "Epoch: 157/1000 Valid loss: 0.267107218503952 Valid acc: 0.7266666889190674\n",
      "Epoch: 158/1000 Train loss: 0.24128000438213348 Train acc: 0.7437037229537964\n",
      "Epoch: 158/1000 Valid loss: 0.2498631626367569 Valid acc: 0.7366666793823242\n",
      "Epoch: 159/1000 Train loss: 0.23407000303268433 Train acc: 0.7483332753181458\n",
      "Epoch: 159/1000 Valid loss: 0.24697095155715942 Valid acc: 0.7388889193534851\n",
      "Epoch: 160/1000 Train loss: 0.24474528431892395 Train acc: 0.7437037229537964\n",
      "Epoch: 160/1000 Valid loss: 0.2963196933269501 Valid acc: 0.7188888192176819\n",
      "Epoch: 161/1000 Train loss: 0.3557713031768799 Train acc: 0.7229629755020142\n",
      "Epoch: 161/1000 Valid loss: 0.3333546221256256 Valid acc: 0.7183333039283752\n",
      "Epoch: 162/1000 Train loss: 0.26921358704566956 Train acc: 0.7372222542762756\n",
      "Epoch: 162/1000 Valid loss: 0.31610986590385437 Valid acc: 0.707777738571167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163/1000 Train loss: 0.30120792984962463 Train acc: 0.7222222089767456\n",
      "Epoch: 163/1000 Valid loss: 0.30210360884666443 Valid acc: 0.7172222137451172\n",
      "Epoch: 164/1000 Train loss: 0.29721754789352417 Train acc: 0.7220370173454285\n",
      "Epoch: 164/1000 Valid loss: 0.30955013632774353 Valid acc: 0.7166666984558105\n",
      "Epoch: 165/1000 Train loss: 0.29151424765586853 Train acc: 0.729629635810852\n",
      "Epoch: 165/1000 Valid loss: 0.3152804970741272 Valid acc: 0.7194444537162781\n",
      "Epoch: 166/1000 Train loss: 0.324637234210968 Train acc: 0.7209258675575256\n",
      "Epoch: 166/1000 Valid loss: 0.34714579582214355 Valid acc: 0.726111114025116\n",
      "Epoch: 167/1000 Train loss: 0.3126879036426544 Train acc: 0.7214815020561218\n",
      "Epoch: 167/1000 Valid loss: 0.2922121286392212 Valid acc: 0.7211111187934875\n",
      "Epoch: 168/1000 Train loss: 0.2866678535938263 Train acc: 0.730555534362793\n",
      "Epoch: 168/1000 Valid loss: 0.28572750091552734 Valid acc: 0.7205556035041809\n",
      "Epoch: 169/1000 Train loss: 0.2762206792831421 Train acc: 0.7268518805503845\n",
      "Epoch: 169/1000 Valid loss: 0.2835295498371124 Valid acc: 0.7238888740539551\n",
      "Epoch: 170/1000 Train loss: 0.2612965404987335 Train acc: 0.7329629063606262\n",
      "Epoch: 170/1000 Valid loss: 0.2646300494670868 Valid acc: 0.7233333587646484\n",
      "Epoch: 171/1000 Train loss: 0.2524850070476532 Train acc: 0.7392592430114746\n",
      "Epoch: 171/1000 Valid loss: 0.27104613184928894 Valid acc: 0.7177777290344238\n",
      "Epoch: 172/1000 Train loss: 0.24629300832748413 Train acc: 0.7416666746139526\n",
      "Epoch: 172/1000 Valid loss: 0.25768229365348816 Valid acc: 0.7277777791023254\n",
      "Epoch: 173/1000 Train loss: 0.23839057981967926 Train acc: 0.7448147535324097\n",
      "Epoch: 173/1000 Valid loss: 0.2517601251602173 Valid acc: 0.7344444394111633\n",
      "Epoch: 174/1000 Train loss: 0.23750567436218262 Train acc: 0.7446296215057373\n",
      "Epoch: 174/1000 Valid loss: 0.25712165236473083 Valid acc: 0.7238888740539551\n",
      "Epoch: 175/1000 Train loss: 0.23673908412456512 Train acc: 0.7470370531082153\n",
      "Epoch: 175/1000 Valid loss: 0.25122174620628357 Valid acc: 0.7344444394111633\n",
      "Epoch: 176/1000 Train loss: 0.2373773753643036 Train acc: 0.7451851963996887\n",
      "Epoch: 176/1000 Valid loss: 0.2616693675518036 Valid acc: 0.7233333587646484\n",
      "Epoch: 177/1000 Train loss: 0.23743125796318054 Train acc: 0.7425925731658936\n",
      "Epoch: 177/1000 Valid loss: 0.25495222210884094 Valid acc: 0.7333333492279053\n",
      "Epoch: 178/1000 Train loss: 0.22856725752353668 Train acc: 0.7464815378189087\n",
      "Epoch: 178/1000 Valid loss: 0.24591390788555145 Valid acc: 0.7427778244018555\n",
      "Epoch: 179/1000 Train loss: 0.22626344859600067 Train acc: 0.7512962818145752\n",
      "Epoch: 179/1000 Valid loss: 0.24344508349895477 Valid acc: 0.7383334040641785\n",
      "Epoch: 180/1000 Train loss: 0.2264767736196518 Train acc: 0.7483332753181458\n",
      "Epoch: 180/1000 Valid loss: 0.25144675374031067 Valid acc: 0.7255555987358093\n",
      "Epoch: 181/1000 Train loss: 0.22675006091594696 Train acc: 0.7481482028961182\n",
      "Epoch: 181/1000 Valid loss: 0.2293299436569214 Valid acc: 0.7416666150093079\n",
      "Epoch: 182/1000 Train loss: 0.22090782225131989 Train acc: 0.7492592334747314\n",
      "Epoch: 182/1000 Valid loss: 0.23298628628253937 Valid acc: 0.7450000643730164\n",
      "Epoch: 183/1000 Train loss: 0.21541659533977509 Train acc: 0.7516666650772095\n",
      "Epoch: 183/1000 Valid loss: 0.23235255479812622 Valid acc: 0.7411110997200012\n",
      "Epoch: 184/1000 Train loss: 0.2177017331123352 Train acc: 0.7512962818145752\n",
      "Epoch: 184/1000 Valid loss: 0.2400027960538864 Valid acc: 0.7355555891990662\n",
      "Epoch: 185/1000 Train loss: 0.21532347798347473 Train acc: 0.7512962818145752\n",
      "Epoch: 185/1000 Valid loss: 0.2350478321313858 Valid acc: 0.7366666793823242\n",
      "Epoch: 186/1000 Train loss: 0.21583214402198792 Train acc: 0.7518518567085266\n",
      "Epoch: 186/1000 Valid loss: 0.22925083339214325 Valid acc: 0.7438888549804688\n",
      "Epoch: 187/1000 Train loss: 0.2200707197189331 Train acc: 0.7485184669494629\n",
      "Epoch: 187/1000 Valid loss: 0.25162193179130554 Valid acc: 0.7211111187934875\n",
      "Epoch: 188/1000 Train loss: 0.22256644070148468 Train acc: 0.7461111545562744\n",
      "Epoch: 188/1000 Valid loss: 0.23211848735809326 Valid acc: 0.7394444346427917\n",
      "Epoch: 189/1000 Train loss: 0.21241621673107147 Train acc: 0.7498148083686829\n",
      "Epoch: 189/1000 Valid loss: 0.23339517414569855 Valid acc: 0.7461110949516296\n",
      "Epoch: 190/1000 Train loss: 0.20947614312171936 Train acc: 0.7546296119689941\n",
      "Epoch: 190/1000 Valid loss: 0.23314963281154633 Valid acc: 0.7372221946716309\n",
      "Epoch: 191/1000 Train loss: 0.2160021811723709 Train acc: 0.7511110901832581\n",
      "Epoch: 191/1000 Valid loss: 0.2395002394914627 Valid acc: 0.7377777695655823\n",
      "Epoch: 192/1000 Train loss: 0.25059032440185547 Train acc: 0.7322221994400024\n",
      "Epoch: 192/1000 Valid loss: 0.25973621010780334 Valid acc: 0.7316667437553406\n",
      "Epoch: 193/1000 Train loss: 0.24071913957595825 Train acc: 0.7401852011680603\n",
      "Epoch: 193/1000 Valid loss: 0.2506251931190491 Valid acc: 0.727222204208374\n",
      "Epoch: 194/1000 Train loss: 0.2492082118988037 Train acc: 0.729629635810852\n",
      "Epoch: 194/1000 Valid loss: 0.30110710859298706 Valid acc: 0.7083333134651184\n",
      "Epoch: 195/1000 Train loss: 0.25560709834098816 Train acc: 0.727222204208374\n",
      "Epoch: 195/1000 Valid loss: 0.2746415138244629 Valid acc: 0.7149999737739563\n",
      "Epoch: 196/1000 Train loss: 0.24921303987503052 Train acc: 0.730370283126831\n",
      "Epoch: 196/1000 Valid loss: 0.2672621011734009 Valid acc: 0.7361111640930176\n",
      "Epoch: 197/1000 Train loss: 0.23900935053825378 Train acc: 0.7448147535324097\n",
      "Epoch: 197/1000 Valid loss: 0.24121592938899994 Valid acc: 0.730555534362793\n",
      "Epoch: 198/1000 Train loss: 0.22956760227680206 Train acc: 0.7392593026161194\n",
      "Epoch: 198/1000 Valid loss: 0.25096771121025085 Valid acc: 0.7277777791023254\n",
      "Epoch: 199/1000 Train loss: 0.22983519732952118 Train acc: 0.7398148775100708\n",
      "Epoch: 199/1000 Valid loss: 0.2311200350522995 Valid acc: 0.7327777743339539\n",
      "Epoch: 200/1000 Train loss: 0.22394458949565887 Train acc: 0.7411110401153564\n",
      "Epoch: 200/1000 Valid loss: 0.24071337282657623 Valid acc: 0.7294445037841797\n",
      "Epoch: 201/1000 Train loss: 0.23607853055000305 Train acc: 0.7344443798065186\n",
      "Epoch: 201/1000 Valid loss: 0.24863581359386444 Valid acc: 0.7322222590446472\n",
      "Epoch: 202/1000 Train loss: 0.24038903415203094 Train acc: 0.7414814829826355\n",
      "Epoch: 202/1000 Valid loss: 0.23825602233409882 Valid acc: 0.742222249507904\n",
      "Epoch: 203/1000 Train loss: 0.22423246502876282 Train acc: 0.7409259080886841\n",
      "Epoch: 203/1000 Valid loss: 0.23259393870830536 Valid acc: 0.7316667437553406\n",
      "Epoch: 204/1000 Train loss: 0.22341717779636383 Train acc: 0.7481482028961182\n",
      "Epoch: 204/1000 Valid loss: 0.23622624576091766 Valid acc: 0.7394444346427917\n",
      "Epoch: 205/1000 Train loss: 0.2170059084892273 Train acc: 0.7409259676933289\n",
      "Epoch: 205/1000 Valid loss: 0.2177082896232605 Valid acc: 0.7450000643730164\n",
      "Epoch: 206/1000 Train loss: 0.21427328884601593 Train acc: 0.7494444251060486\n",
      "Epoch: 206/1000 Valid loss: 0.22652506828308105 Valid acc: 0.7311111092567444\n",
      "Epoch: 207/1000 Train loss: 0.21027439832687378 Train acc: 0.7433333396911621\n",
      "Epoch: 207/1000 Valid loss: 0.22960682213306427 Valid acc: 0.7361111640930176\n",
      "Epoch: 208/1000 Train loss: 0.21032698452472687 Train acc: 0.7492592930793762\n",
      "Epoch: 208/1000 Valid loss: 0.2224666029214859 Valid acc: 0.7366666793823242\n",
      "Epoch: 209/1000 Train loss: 0.20596012473106384 Train acc: 0.7488888502120972\n",
      "Epoch: 209/1000 Valid loss: 0.22073541581630707 Valid acc: 0.7472222447395325\n",
      "Epoch: 210/1000 Train loss: 0.20478636026382446 Train acc: 0.7524073719978333\n",
      "Epoch: 210/1000 Valid loss: 0.2230989933013916 Valid acc: 0.7416666150093079\n",
      "Epoch: 211/1000 Train loss: 0.2254694551229477 Train acc: 0.7401852011680603\n",
      "Epoch: 211/1000 Valid loss: 0.2342180609703064 Valid acc: 0.730555534362793\n",
      "Epoch: 212/1000 Train loss: 0.23292367160320282 Train acc: 0.7368519306182861\n",
      "Epoch: 212/1000 Valid loss: 0.25815045833587646 Valid acc: 0.7322222590446472\n",
      "Epoch: 213/1000 Train loss: 0.2319512963294983 Train acc: 0.7437037229537964\n",
      "Epoch: 213/1000 Valid loss: 0.22263014316558838 Valid acc: 0.7327777743339539\n",
      "Epoch: 214/1000 Train loss: 0.21297556161880493 Train acc: 0.7438888549804688\n",
      "Epoch: 214/1000 Valid loss: 0.22604866325855255 Valid acc: 0.7488889098167419\n",
      "Epoch: 215/1000 Train loss: 0.22634370625019073 Train acc: 0.7420370578765869\n",
      "Epoch: 215/1000 Valid loss: 0.2252776026725769 Valid acc: 0.7272222638130188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 216/1000 Train loss: 0.20826596021652222 Train acc: 0.7474074363708496\n",
      "Epoch: 216/1000 Valid loss: 0.20724010467529297 Valid acc: 0.7522222399711609\n",
      "Epoch: 217/1000 Train loss: 0.19963914155960083 Train acc: 0.7551851868629456\n",
      "Epoch: 217/1000 Valid loss: 0.20715992152690887 Valid acc: 0.742222249507904\n",
      "Epoch: 218/1000 Train loss: 0.19782716035842896 Train acc: 0.7527778148651123\n",
      "Epoch: 218/1000 Valid loss: 0.21448923647403717 Valid acc: 0.7511110901832581\n",
      "Epoch: 219/1000 Train loss: 0.1976996511220932 Train acc: 0.7537037134170532\n",
      "Epoch: 219/1000 Valid loss: 0.20469433069229126 Valid acc: 0.7516667246818542\n",
      "Epoch: 220/1000 Train loss: 0.19498318433761597 Train acc: 0.7555555105209351\n",
      "Epoch: 220/1000 Valid loss: 0.2071903944015503 Valid acc: 0.7450000643730164\n",
      "Epoch: 221/1000 Train loss: 0.19583790004253387 Train acc: 0.7529630064964294\n",
      "Epoch: 221/1000 Valid loss: 0.20646969974040985 Valid acc: 0.7511110901832581\n",
      "Epoch: 222/1000 Train loss: 0.21817567944526672 Train acc: 0.7414814829826355\n",
      "Epoch: 222/1000 Valid loss: 0.2453204244375229 Valid acc: 0.7300000190734863\n",
      "Epoch: 223/1000 Train loss: 0.22971943020820618 Train acc: 0.7429629564285278\n",
      "Epoch: 223/1000 Valid loss: 0.22900275886058807 Valid acc: 0.7338889241218567\n",
      "Epoch: 224/1000 Train loss: 0.22663214802742004 Train acc: 0.737407386302948\n",
      "Epoch: 224/1000 Valid loss: 0.22380459308624268 Valid acc: 0.745555579662323\n",
      "Epoch: 225/1000 Train loss: 0.20811568200588226 Train acc: 0.7524073719978333\n",
      "Epoch: 225/1000 Valid loss: 0.21704304218292236 Valid acc: 0.7366666793823242\n",
      "Epoch: 226/1000 Train loss: 0.21053928136825562 Train acc: 0.7490741014480591\n",
      "Epoch: 226/1000 Valid loss: 0.22951388359069824 Valid acc: 0.7472222447395325\n",
      "Epoch: 227/1000 Train loss: 0.2194211632013321 Train acc: 0.7503703832626343\n",
      "Epoch: 227/1000 Valid loss: 0.23328404128551483 Valid acc: 0.7433333396911621\n",
      "Epoch: 228/1000 Train loss: 0.21208450198173523 Train acc: 0.7524073719978333\n",
      "Epoch: 228/1000 Valid loss: 0.21931637823581696 Valid acc: 0.7505555152893066\n",
      "Epoch: 229/1000 Train loss: 0.2053796499967575 Train acc: 0.7553703784942627\n",
      "Epoch: 229/1000 Valid loss: 0.2113129049539566 Valid acc: 0.7522222399711609\n",
      "Epoch: 230/1000 Train loss: 0.1952633261680603 Train acc: 0.7551851868629456\n",
      "Epoch: 230/1000 Valid loss: 0.21101613342761993 Valid acc: 0.7511110901832581\n",
      "Epoch: 231/1000 Train loss: 0.1928521990776062 Train acc: 0.7583333253860474\n",
      "Epoch: 231/1000 Valid loss: 0.2078874707221985 Valid acc: 0.7488889098167419\n",
      "Epoch: 232/1000 Train loss: 0.18980301916599274 Train acc: 0.7570370435714722\n",
      "Epoch: 232/1000 Valid loss: 0.20638996362686157 Valid acc: 0.7516667246818542\n",
      "Epoch: 233/1000 Train loss: 0.19243910908699036 Train acc: 0.7546296119689941\n",
      "Epoch: 233/1000 Valid loss: 0.20916415750980377 Valid acc: 0.745555579662323\n",
      "Epoch: 234/1000 Train loss: 0.1908460110425949 Train acc: 0.7553703784942627\n",
      "Epoch: 234/1000 Valid loss: 0.209720179438591 Valid acc: 0.7488889098167419\n",
      "Epoch: 235/1000 Train loss: 0.1895281970500946 Train acc: 0.7564814686775208\n",
      "Epoch: 235/1000 Valid loss: 0.20827604830265045 Valid acc: 0.7438888549804688\n",
      "Epoch: 236/1000 Train loss: 0.1892097443342209 Train acc: 0.7546296119689941\n",
      "Epoch: 236/1000 Valid loss: 0.21186377108097076 Valid acc: 0.7427778244018555\n",
      "Epoch: 237/1000 Train loss: 0.1890525072813034 Train acc: 0.7553703784942627\n",
      "Epoch: 237/1000 Valid loss: 0.20478105545043945 Valid acc: 0.7505555152893066\n",
      "Epoch: 238/1000 Train loss: 0.18512634932994843 Train acc: 0.7574074268341064\n",
      "Epoch: 238/1000 Valid loss: 0.20154732465744019 Valid acc: 0.7516667246818542\n",
      "Epoch: 239/1000 Train loss: 0.20365510880947113 Train acc: 0.7494444251060486\n",
      "Epoch: 239/1000 Valid loss: 0.2559765577316284 Valid acc: 0.7200000286102295\n",
      "Epoch: 240/1000 Train loss: 0.21017341315746307 Train acc: 0.738518476486206\n",
      "Epoch: 240/1000 Valid loss: 0.20140592753887177 Valid acc: 0.7427778244018555\n",
      "Epoch: 241/1000 Train loss: 0.18997223675251007 Train acc: 0.7535185217857361\n",
      "Epoch: 241/1000 Valid loss: 0.20542685687541962 Valid acc: 0.75\n",
      "Epoch: 242/1000 Train loss: 0.19633013010025024 Train acc: 0.7549999952316284\n",
      "Epoch: 242/1000 Valid loss: 0.2185034304857254 Valid acc: 0.7400000095367432\n",
      "Epoch: 243/1000 Train loss: 0.199050173163414 Train acc: 0.7537037134170532\n",
      "Epoch: 243/1000 Valid loss: 0.20825666189193726 Valid acc: 0.753333330154419\n",
      "Epoch: 244/1000 Train loss: 0.19577959179878235 Train acc: 0.7572222352027893\n",
      "Epoch: 244/1000 Valid loss: 0.21216535568237305 Valid acc: 0.7411110997200012\n",
      "Epoch: 245/1000 Train loss: 0.19261415302753448 Train acc: 0.7549999952316284\n",
      "Epoch: 245/1000 Valid loss: 0.20423687994480133 Valid acc: 0.7505555152893066\n",
      "Epoch: 246/1000 Train loss: 0.19232147932052612 Train acc: 0.7562962770462036\n",
      "Epoch: 246/1000 Valid loss: 0.20829133689403534 Valid acc: 0.7488889098167419\n",
      "Epoch: 247/1000 Train loss: 0.19759275019168854 Train acc: 0.7514814734458923\n",
      "Epoch: 247/1000 Valid loss: 0.20694558322429657 Valid acc: 0.7477777600288391\n",
      "Epoch: 248/1000 Train loss: 0.1908237338066101 Train acc: 0.753333330154419\n",
      "Epoch: 248/1000 Valid loss: 0.20179544389247894 Valid acc: 0.7438888549804688\n",
      "Epoch: 249/1000 Train loss: 0.1816917508840561 Train acc: 0.754444420337677\n",
      "Epoch: 249/1000 Valid loss: 0.2004805952310562 Valid acc: 0.7488889098167419\n",
      "Epoch: 250/1000 Train loss: 0.18849951028823853 Train acc: 0.7540740370750427\n",
      "Epoch: 250/1000 Valid loss: 0.19897085428237915 Valid acc: 0.7522222399711609\n",
      "Epoch: 251/1000 Train loss: 0.1803564727306366 Train acc: 0.7574074268341064\n",
      "Epoch: 251/1000 Valid loss: 0.19631671905517578 Valid acc: 0.7516667246818542\n",
      "Epoch: 252/1000 Train loss: 0.17967291176319122 Train acc: 0.757777750492096\n",
      "Epoch: 252/1000 Valid loss: 0.19065909087657928 Valid acc: 0.7538889050483704\n",
      "Epoch: 253/1000 Train loss: 0.17622850835323334 Train acc: 0.7570370435714722\n",
      "Epoch: 253/1000 Valid loss: 0.19475364685058594 Valid acc: 0.7505555152893066\n",
      "Epoch: 254/1000 Train loss: 0.17575614154338837 Train acc: 0.7566666603088379\n",
      "Epoch: 254/1000 Valid loss: 0.18754921853542328 Valid acc: 0.753333330154419\n",
      "Epoch: 255/1000 Train loss: 0.17706650495529175 Train acc: 0.7559259533882141\n",
      "Epoch: 255/1000 Valid loss: 0.19008906185626984 Valid acc: 0.7505555152893066\n",
      "Epoch: 256/1000 Train loss: 0.17397649586200714 Train acc: 0.7577778100967407\n",
      "Epoch: 256/1000 Valid loss: 0.1884695440530777 Valid acc: 0.7505555152893066\n",
      "Epoch: 257/1000 Train loss: 0.170630544424057 Train acc: 0.7599999904632568\n",
      "Epoch: 257/1000 Valid loss: 0.18984569609165192 Valid acc: 0.7494444847106934\n",
      "Epoch: 258/1000 Train loss: 0.1733788698911667 Train acc: 0.7590740323066711\n",
      "Epoch: 258/1000 Valid loss: 0.19221095740795135 Valid acc: 0.7472222447395325\n",
      "Epoch: 259/1000 Train loss: 0.35699012875556946 Train acc: 0.6896296739578247\n",
      "Epoch: 259/1000 Valid loss: 0.41354915499687195 Valid acc: 0.6650000214576721\n",
      "Epoch: 260/1000 Train loss: 0.375432550907135 Train acc: 0.6777778267860413\n",
      "Epoch: 260/1000 Valid loss: 0.37491336464881897 Valid acc: 0.667222261428833\n",
      "Epoch: 261/1000 Train loss: 0.34882816672325134 Train acc: 0.6831481456756592\n",
      "Epoch: 261/1000 Valid loss: 0.3365921974182129 Valid acc: 0.6844444274902344\n",
      "Epoch: 262/1000 Train loss: 0.3094552755355835 Train acc: 0.6966666579246521\n",
      "Epoch: 262/1000 Valid loss: 0.32206177711486816 Valid acc: 0.6905555725097656\n",
      "Epoch: 263/1000 Train loss: 0.28743529319763184 Train acc: 0.7088888883590698\n",
      "Epoch: 263/1000 Valid loss: 0.29735496640205383 Valid acc: 0.7027778029441833\n",
      "Epoch: 264/1000 Train loss: 0.2701236605644226 Train acc: 0.7237036824226379\n",
      "Epoch: 264/1000 Valid loss: 0.3353308141231537 Valid acc: 0.6972222328186035\n",
      "Epoch: 265/1000 Train loss: 0.331731379032135 Train acc: 0.7009259462356567\n",
      "Epoch: 265/1000 Valid loss: 0.28652656078338623 Valid acc: 0.7149999737739563\n",
      "Epoch: 266/1000 Train loss: 0.24453197419643402 Train acc: 0.7344444394111633\n",
      "Epoch: 266/1000 Valid loss: 0.2636716663837433 Valid acc: 0.7138888835906982\n",
      "Epoch: 267/1000 Train loss: 0.22419969737529755 Train acc: 0.7420370578765869\n",
      "Epoch: 267/1000 Valid loss: 0.2276260405778885 Valid acc: 0.7438888549804688\n",
      "Epoch: 268/1000 Train loss: 0.2163669317960739 Train acc: 0.7420370578765869\n",
      "Epoch: 268/1000 Valid loss: 0.22898423671722412 Valid acc: 0.73499995470047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 269/1000 Train loss: 0.21292699873447418 Train acc: 0.7464814782142639\n",
      "Epoch: 269/1000 Valid loss: 0.21697567403316498 Valid acc: 0.746666669845581\n",
      "Epoch: 270/1000 Train loss: 0.2250206172466278 Train acc: 0.745185136795044\n",
      "Epoch: 270/1000 Valid loss: 0.21996231377124786 Valid acc: 0.7450000643730164\n",
      "Epoch: 271/1000 Train loss: 0.20616605877876282 Train acc: 0.7518518567085266\n",
      "Epoch: 271/1000 Valid loss: 0.20858478546142578 Valid acc: 0.7461110949516296\n",
      "Epoch: 272/1000 Train loss: 0.19782087206840515 Train acc: 0.7546296715736389\n",
      "Epoch: 272/1000 Valid loss: 0.2010239213705063 Valid acc: 0.7433333396911621\n",
      "Epoch: 273/1000 Train loss: 0.1991795003414154 Train acc: 0.7490741014480591\n",
      "Epoch: 273/1000 Valid loss: 0.20371027290821075 Valid acc: 0.7472222447395325\n",
      "Epoch: 274/1000 Train loss: 0.19324201345443726 Train acc: 0.7529629468917847\n",
      "Epoch: 274/1000 Valid loss: 0.1987677812576294 Valid acc: 0.7511110901832581\n",
      "Epoch: 275/1000 Train loss: 0.1874217689037323 Train acc: 0.7538888454437256\n",
      "Epoch: 275/1000 Valid loss: 0.2238403558731079 Valid acc: 0.7322222590446472\n",
      "Epoch: 276/1000 Train loss: 0.2238803505897522 Train acc: 0.7409259080886841\n",
      "Epoch: 276/1000 Valid loss: 0.21360264718532562 Valid acc: 0.7488889098167419\n",
      "Epoch: 277/1000 Train loss: 0.20108947157859802 Train acc: 0.7537037134170532\n",
      "Epoch: 277/1000 Valid loss: 0.21363534033298492 Valid acc: 0.746666669845581\n",
      "Epoch: 278/1000 Train loss: 0.199380025267601 Train acc: 0.7514814734458923\n",
      "Epoch: 278/1000 Valid loss: 0.194480761885643 Valid acc: 0.753333330154419\n",
      "Epoch: 279/1000 Train loss: 0.18391864001750946 Train acc: 0.755740761756897\n",
      "Epoch: 279/1000 Valid loss: 0.18807880580425262 Valid acc: 0.7516667246818542\n",
      "Epoch: 280/1000 Train loss: 0.1793210804462433 Train acc: 0.7559258937835693\n",
      "Epoch: 280/1000 Valid loss: 0.1907031536102295 Valid acc: 0.7555555701255798\n",
      "Epoch: 281/1000 Train loss: 0.18092936277389526 Train acc: 0.7572222352027893\n",
      "Epoch: 281/1000 Valid loss: 0.19617129862308502 Valid acc: 0.7394444346427917\n",
      "Epoch: 282/1000 Train loss: 0.17990165948867798 Train acc: 0.7546296119689941\n",
      "Epoch: 282/1000 Valid loss: 0.1867547482252121 Valid acc: 0.753333330154419\n",
      "Epoch: 283/1000 Train loss: 0.17388516664505005 Train acc: 0.7588889002799988\n",
      "Epoch: 283/1000 Valid loss: 0.18960417807102203 Valid acc: 0.7522222399711609\n",
      "Epoch: 284/1000 Train loss: 0.17071299254894257 Train acc: 0.7605555653572083\n",
      "Epoch: 284/1000 Valid loss: 0.1885116547346115 Valid acc: 0.753333330154419\n",
      "Epoch: 285/1000 Train loss: 0.17178042232990265 Train acc: 0.7562962770462036\n",
      "Epoch: 285/1000 Valid loss: 0.18316684663295746 Valid acc: 0.753333330154419\n",
      "Epoch: 286/1000 Train loss: 0.1692648082971573 Train acc: 0.7612963318824768\n",
      "Epoch: 286/1000 Valid loss: 0.18828392028808594 Valid acc: 0.75\n",
      "Epoch: 287/1000 Train loss: 0.17163550853729248 Train acc: 0.7592592239379883\n",
      "Epoch: 287/1000 Valid loss: 0.18617039918899536 Valid acc: 0.7527777552604675\n",
      "Epoch: 288/1000 Train loss: 0.17413559556007385 Train acc: 0.7570370435714722\n",
      "Epoch: 288/1000 Valid loss: 0.1845703125 Valid acc: 0.746666669845581\n",
      "Epoch: 289/1000 Train loss: 0.1743733435869217 Train acc: 0.7585185170173645\n",
      "Epoch: 289/1000 Valid loss: 0.18570087850093842 Valid acc: 0.7522222399711609\n",
      "Epoch: 290/1000 Train loss: 0.1777825951576233 Train acc: 0.7566666603088379\n",
      "Epoch: 290/1000 Valid loss: 0.1856696456670761 Valid acc: 0.7511110901832581\n",
      "Epoch: 291/1000 Train loss: 0.17750853300094604 Train acc: 0.7561110854148865\n",
      "Epoch: 291/1000 Valid loss: 0.19175930321216583 Valid acc: 0.7461110949516296\n",
      "Epoch: 292/1000 Train loss: 0.17682938277721405 Train acc: 0.7572222352027893\n",
      "Epoch: 292/1000 Valid loss: 0.20007748901844025 Valid acc: 0.7416666150093079\n",
      "Epoch: 293/1000 Train loss: 0.1731249839067459 Train acc: 0.7585184574127197\n",
      "Epoch: 293/1000 Valid loss: 0.18291807174682617 Valid acc: 0.754444420337677\n",
      "Epoch: 294/1000 Train loss: 0.17147456109523773 Train acc: 0.760185182094574\n",
      "Epoch: 294/1000 Valid loss: 0.19271916151046753 Valid acc: 0.7411110997200012\n",
      "Epoch: 295/1000 Train loss: 0.17857572436332703 Train acc: 0.755740761756897\n",
      "Epoch: 295/1000 Valid loss: 1.0619081258773804 Valid acc: 0.5138888955116272\n",
      "Epoch: 296/1000 Train loss: 1.0728715658187866 Train acc: 0.41296297311782837\n",
      "Epoch: 296/1000 Valid loss: 1.0884037017822266 Valid acc: 0.36444446444511414\n",
      "Epoch: 297/1000 Train loss: 1.2641112804412842 Train acc: 0.24666666984558105\n",
      "Epoch: 297/1000 Valid loss: 1.2204004526138306 Valid acc: 0.2661111056804657\n",
      "Epoch: 298/1000 Train loss: 1.2976744174957275 Train acc: 0.23185184597969055\n",
      "Epoch: 298/1000 Valid loss: 1.2415028810501099 Valid acc: 0.253888875246048\n",
      "Epoch: 299/1000 Train loss: 1.2973003387451172 Train acc: 0.2101851850748062\n",
      "Epoch: 299/1000 Valid loss: 1.2444037199020386 Valid acc: 0.24388889968395233\n",
      "Epoch: 300/1000 Train loss: 1.2922804355621338 Train acc: 0.2503703534603119\n",
      "Epoch: 300/1000 Valid loss: 1.2457714080810547 Valid acc: 0.24166665971279144\n",
      "Epoch: 301/1000 Train loss: 1.2907215356826782 Train acc: 0.19648148119449615\n",
      "Epoch: 301/1000 Valid loss: 1.233608365058899 Valid acc: 0.23277777433395386\n",
      "Epoch: 302/1000 Train loss: 1.2863740921020508 Train acc: 0.1944444626569748\n",
      "Epoch: 302/1000 Valid loss: 1.228452205657959 Valid acc: 0.2338888794183731\n",
      "Epoch: 303/1000 Train loss: 1.2827566862106323 Train acc: 0.19814816117286682\n",
      "Epoch: 303/1000 Valid loss: 1.2261383533477783 Valid acc: 0.24555553495883942\n",
      "Epoch: 304/1000 Train loss: 1.279739499092102 Train acc: 0.22388887405395508\n",
      "Epoch: 304/1000 Valid loss: 1.224401593208313 Valid acc: 0.2738889157772064\n",
      "Epoch: 305/1000 Train loss: 1.2781221866607666 Train acc: 0.24111111462116241\n",
      "Epoch: 305/1000 Valid loss: 1.2183181047439575 Valid acc: 0.28333333134651184\n",
      "Epoch: 306/1000 Train loss: 1.2812575101852417 Train acc: 0.2544444799423218\n",
      "Epoch: 306/1000 Valid loss: 1.6094266176223755 Valid acc: 0.3266666829586029\n",
      "Epoch: 307/1000 Train loss: 1.508406162261963 Train acc: 0.2548148036003113\n",
      "Epoch: 307/1000 Valid loss: 1.9924923181533813 Valid acc: 0.2705555856227875\n",
      "Epoch: 308/1000 Train loss: 1.6708874702453613 Train acc: 0.2307407259941101\n",
      "Epoch: 308/1000 Valid loss: 1.9963735342025757 Valid acc: 0.24888886511325836\n",
      "Epoch: 309/1000 Train loss: 1.671766757965088 Train acc: 0.22407406568527222\n",
      "Epoch: 309/1000 Valid loss: 1.816815972328186 Valid acc: 0.2527777850627899\n",
      "Epoch: 310/1000 Train loss: 1.562317967414856 Train acc: 0.22925925254821777\n",
      "Epoch: 310/1000 Valid loss: 1.623608946800232 Valid acc: 0.26333335041999817\n",
      "Epoch: 311/1000 Train loss: 1.4524157047271729 Train acc: 0.23722222447395325\n",
      "Epoch: 311/1000 Valid loss: 1.4363741874694824 Valid acc: 0.277222216129303\n",
      "Epoch: 312/1000 Train loss: 1.3524717092514038 Train acc: 0.2424073964357376\n",
      "Epoch: 312/1000 Valid loss: 1.291176676750183 Valid acc: 0.28777778148651123\n",
      "Epoch: 313/1000 Train loss: 1.2857102155685425 Train acc: 0.24722221493721008\n",
      "Epoch: 313/1000 Valid loss: 1.2217425107955933 Valid acc: 0.2966666519641876\n",
      "Epoch: 314/1000 Train loss: 1.2564219236373901 Train acc: 0.2518518269062042\n",
      "Epoch: 314/1000 Valid loss: 1.1881217956542969 Valid acc: 0.3099999725818634\n",
      "Epoch: 315/1000 Train loss: 1.239217758178711 Train acc: 0.2598147988319397\n",
      "Epoch: 315/1000 Valid loss: 1.1628473997116089 Valid acc: 0.31833335757255554\n",
      "Epoch: 316/1000 Train loss: 1.2241911888122559 Train acc: 0.2696295976638794\n",
      "Epoch: 316/1000 Valid loss: 1.1410011053085327 Valid acc: 0.32111111283302307\n",
      "Epoch: 317/1000 Train loss: 1.2099710702896118 Train acc: 0.27814817428588867\n",
      "Epoch: 317/1000 Valid loss: 1.1244559288024902 Valid acc: 0.3288888931274414\n",
      "Epoch: 318/1000 Train loss: 1.196096420288086 Train acc: 0.2868518531322479\n",
      "Epoch: 318/1000 Valid loss: 1.1078886985778809 Valid acc: 0.3305555582046509\n",
      "Epoch: 319/1000 Train loss: 1.1815416812896729 Train acc: 0.2944444417953491\n",
      "Epoch: 319/1000 Valid loss: 1.089524745941162 Valid acc: 0.33722221851348877\n",
      "Epoch: 320/1000 Train loss: 1.166672945022583 Train acc: 0.30129629373550415\n",
      "Epoch: 320/1000 Valid loss: 1.0736101865768433 Valid acc: 0.3450000286102295\n",
      "Epoch: 321/1000 Train loss: 1.1556860208511353 Train acc: 0.301111102104187\n",
      "Epoch: 321/1000 Valid loss: 1.0594478845596313 Valid acc: 0.352222204208374\n",
      "Epoch: 322/1000 Train loss: 1.1457277536392212 Train acc: 0.3055555522441864\n",
      "Epoch: 322/1000 Valid loss: 1.0455355644226074 Valid acc: 0.3655555546283722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 323/1000 Train loss: 1.1336055994033813 Train acc: 0.31888890266418457\n",
      "Epoch: 323/1000 Valid loss: 1.0364800691604614 Valid acc: 0.37555554509162903\n",
      "Epoch: 324/1000 Train loss: 1.129337191581726 Train acc: 0.3318518400192261\n",
      "Epoch: 324/1000 Valid loss: 1.022961974143982 Valid acc: 0.3838888704776764\n",
      "Epoch: 325/1000 Train loss: 1.113398790359497 Train acc: 0.3431481122970581\n",
      "Epoch: 325/1000 Valid loss: 1.0060656070709229 Valid acc: 0.4011111259460449\n",
      "Epoch: 326/1000 Train loss: 1.0932228565216064 Train acc: 0.3583333492279053\n",
      "Epoch: 326/1000 Valid loss: 0.988635241985321 Valid acc: 0.41555556654930115\n",
      "Epoch: 327/1000 Train loss: 1.0755470991134644 Train acc: 0.36888885498046875\n",
      "Epoch: 327/1000 Valid loss: 0.9711413383483887 Valid acc: 0.4238888919353485\n",
      "Epoch: 328/1000 Train loss: 1.0616800785064697 Train acc: 0.37518519163131714\n",
      "Epoch: 328/1000 Valid loss: 0.9581975936889648 Valid acc: 0.4372222125530243\n",
      "Epoch: 329/1000 Train loss: 1.0470157861709595 Train acc: 0.39462965726852417\n",
      "Epoch: 329/1000 Valid loss: 0.9602212905883789 Valid acc: 0.4472222328186035\n",
      "Epoch: 330/1000 Train loss: 1.0949498414993286 Train acc: 0.3722222149372101\n",
      "Epoch: 330/1000 Valid loss: 0.9698260426521301 Valid acc: 0.44777777791023254\n",
      "Epoch: 331/1000 Train loss: 1.0861916542053223 Train acc: 0.3875925838947296\n",
      "Epoch: 331/1000 Valid loss: 0.9528825879096985 Valid acc: 0.44333335757255554\n",
      "Epoch: 332/1000 Train loss: 1.0744211673736572 Train acc: 0.385185182094574\n",
      "Epoch: 332/1000 Valid loss: 0.9406641125679016 Valid acc: 0.4444444477558136\n",
      "Epoch: 333/1000 Train loss: 1.0649278163909912 Train acc: 0.3894444704055786\n",
      "Epoch: 333/1000 Valid loss: 0.925504207611084 Valid acc: 0.4533333480358124\n",
      "Epoch: 334/1000 Train loss: 1.0541588068008423 Train acc: 0.39277777075767517\n",
      "Epoch: 334/1000 Valid loss: 0.9125307202339172 Valid acc: 0.4566666781902313\n",
      "Epoch: 335/1000 Train loss: 1.0436204671859741 Train acc: 0.4024074077606201\n",
      "Epoch: 335/1000 Valid loss: 0.9015828967094421 Valid acc: 0.47833332419395447\n",
      "Epoch: 336/1000 Train loss: 1.0330734252929688 Train acc: 0.41277778148651123\n",
      "Epoch: 336/1000 Valid loss: 0.8905553221702576 Valid acc: 0.48944446444511414\n",
      "Epoch: 337/1000 Train loss: 1.0246825218200684 Train acc: 0.4150000214576721\n",
      "Epoch: 337/1000 Valid loss: 0.8784860968589783 Valid acc: 0.49166667461395264\n",
      "Epoch: 338/1000 Train loss: 1.0147534608840942 Train acc: 0.41907408833503723\n",
      "Epoch: 338/1000 Valid loss: 0.867397129535675 Valid acc: 0.49000000953674316\n",
      "Epoch: 339/1000 Train loss: 1.0059216022491455 Train acc: 0.4225925803184509\n",
      "Epoch: 339/1000 Valid loss: 0.8583834767341614 Valid acc: 0.49166667461395264\n",
      "Epoch: 340/1000 Train loss: 0.9976240992546082 Train acc: 0.42444443702697754\n",
      "Epoch: 340/1000 Valid loss: 0.8483808636665344 Valid acc: 0.4911111295223236\n",
      "Epoch: 341/1000 Train loss: 0.9907482862472534 Train acc: 0.4257407486438751\n",
      "Epoch: 341/1000 Valid loss: 0.8389377593994141 Valid acc: 0.49388888478279114\n",
      "Epoch: 342/1000 Train loss: 0.9843130111694336 Train acc: 0.426111102104187\n",
      "Epoch: 342/1000 Valid loss: 0.8329080939292908 Valid acc: 0.49666666984558105\n",
      "Epoch: 343/1000 Train loss: 0.9786889553070068 Train acc: 0.42777779698371887\n",
      "Epoch: 343/1000 Valid loss: 0.8240432143211365 Valid acc: 0.5\n",
      "Epoch: 344/1000 Train loss: 0.9728926420211792 Train acc: 0.42907407879829407\n",
      "Epoch: 344/1000 Valid loss: 0.8167255520820618 Valid acc: 0.5027777552604675\n",
      "Epoch: 345/1000 Train loss: 0.9671037197113037 Train acc: 0.43074074387550354\n",
      "Epoch: 345/1000 Valid loss: 0.8110468983650208 Valid acc: 0.5061110854148865\n",
      "Epoch: 346/1000 Train loss: 0.9616458415985107 Train acc: 0.4327777624130249\n",
      "Epoch: 346/1000 Valid loss: 0.8051413893699646 Valid acc: 0.5038889050483704\n",
      "Epoch: 347/1000 Train loss: 0.9563369750976562 Train acc: 0.4340740740299225\n",
      "Epoch: 347/1000 Valid loss: 0.799025297164917 Valid acc: 0.5072222352027893\n",
      "Epoch: 348/1000 Train loss: 0.950581431388855 Train acc: 0.4355555474758148\n",
      "Epoch: 348/1000 Valid loss: 0.7936050891876221 Valid acc: 0.5038889050483704\n",
      "Epoch: 349/1000 Train loss: 0.9444055557250977 Train acc: 0.4350000321865082\n",
      "Epoch: 349/1000 Valid loss: 0.7883098721504211 Valid acc: 0.5061110854148865\n",
      "Epoch: 350/1000 Train loss: 0.9390286207199097 Train acc: 0.4362963140010834\n",
      "Epoch: 350/1000 Valid loss: 0.7828531265258789 Valid acc: 0.5094444155693054\n",
      "Epoch: 351/1000 Train loss: 0.9326133728027344 Train acc: 0.4359259307384491\n",
      "Epoch: 351/1000 Valid loss: 0.7760927081108093 Valid acc: 0.5105555653572083\n",
      "Epoch: 352/1000 Train loss: 0.9273643493652344 Train acc: 0.4359259009361267\n",
      "Epoch: 352/1000 Valid loss: 0.7759418487548828 Valid acc: 0.5111111402511597\n",
      "Epoch: 353/1000 Train loss: 0.9240273237228394 Train acc: 0.4359259307384491\n",
      "Epoch: 353/1000 Valid loss: 0.7725642323493958 Valid acc: 0.5072222352027893\n",
      "Epoch: 354/1000 Train loss: 0.9185212254524231 Train acc: 0.43425923585891724\n",
      "Epoch: 354/1000 Valid loss: 0.7672340273857117 Valid acc: 0.5088889002799988\n",
      "Epoch: 355/1000 Train loss: 0.9115055799484253 Train acc: 0.4387036859989166\n",
      "Epoch: 355/1000 Valid loss: 0.7646676898002625 Valid acc: 0.5111110806465149\n",
      "Epoch: 356/1000 Train loss: 0.9053137302398682 Train acc: 0.4399999976158142\n",
      "Epoch: 356/1000 Valid loss: 0.7594544291496277 Valid acc: 0.5027778148651123\n",
      "Epoch: 357/1000 Train loss: 0.897720217704773 Train acc: 0.4416666626930237\n",
      "Epoch: 357/1000 Valid loss: 0.7546671032905579 Valid acc: 0.5055555701255798\n",
      "Epoch: 358/1000 Train loss: 0.8913230895996094 Train acc: 0.44203701615333557\n",
      "Epoch: 358/1000 Valid loss: 0.7529376149177551 Valid acc: 0.5033333897590637\n",
      "Epoch: 359/1000 Train loss: 0.8850374817848206 Train acc: 0.4409259259700775\n",
      "Epoch: 359/1000 Valid loss: 0.7444680333137512 Valid acc: 0.5061111450195312\n",
      "Epoch: 360/1000 Train loss: 0.8750900626182556 Train acc: 0.4431481659412384\n",
      "Epoch: 360/1000 Valid loss: 0.7400394082069397 Valid acc: 0.5099999904632568\n",
      "Epoch: 361/1000 Train loss: 0.8686662316322327 Train acc: 0.4453704059123993\n",
      "Epoch: 361/1000 Valid loss: 0.7329761981964111 Valid acc: 0.5011110901832581\n",
      "Epoch: 362/1000 Train loss: 0.8601203560829163 Train acc: 0.4462963342666626\n",
      "Epoch: 362/1000 Valid loss: 0.72499680519104 Valid acc: 0.51500004529953\n",
      "Epoch: 363/1000 Train loss: 0.8525631427764893 Train acc: 0.4525925815105438\n",
      "Epoch: 363/1000 Valid loss: 0.7195529937744141 Valid acc: 0.5100000500679016\n",
      "Epoch: 364/1000 Train loss: 0.8458983898162842 Train acc: 0.4546296298503876\n",
      "Epoch: 364/1000 Valid loss: 0.7152395844459534 Valid acc: 0.5222222208976746\n",
      "Epoch: 365/1000 Train loss: 0.8405764102935791 Train acc: 0.4564814567565918\n",
      "Epoch: 365/1000 Valid loss: 0.7104403972625732 Valid acc: 0.5349999666213989\n",
      "Epoch: 366/1000 Train loss: 0.8347210884094238 Train acc: 0.46129629015922546\n",
      "Epoch: 366/1000 Valid loss: 0.7075119614601135 Valid acc: 0.5266666412353516\n",
      "Epoch: 367/1000 Train loss: 0.832061231136322 Train acc: 0.46444442868232727\n",
      "Epoch: 367/1000 Valid loss: 0.7041716575622559 Valid acc: 0.5400000214576721\n",
      "Epoch: 368/1000 Train loss: 0.8268086314201355 Train acc: 0.4705555737018585\n",
      "Epoch: 368/1000 Valid loss: 0.7015328407287598 Valid acc: 0.54666668176651\n",
      "Epoch: 369/1000 Train loss: 0.8233116865158081 Train acc: 0.47907406091690063\n",
      "Epoch: 369/1000 Valid loss: 0.6983878016471863 Valid acc: 0.5594444274902344\n",
      "Epoch: 370/1000 Train loss: 0.8189847469329834 Train acc: 0.48499998450279236\n",
      "Epoch: 370/1000 Valid loss: 0.6956291198730469 Valid acc: 0.5594444870948792\n",
      "Epoch: 371/1000 Train loss: 0.8154220581054688 Train acc: 0.4899999797344208\n",
      "Epoch: 371/1000 Valid loss: 0.6921388506889343 Valid acc: 0.5666666626930237\n",
      "Epoch: 372/1000 Train loss: 0.8123204112052917 Train acc: 0.4920370280742645\n",
      "Epoch: 372/1000 Valid loss: 0.6869921684265137 Valid acc: 0.5722221732139587\n",
      "Epoch: 373/1000 Train loss: 0.8071945309638977 Train acc: 0.494259238243103\n",
      "Epoch: 373/1000 Valid loss: 0.6836313605308533 Valid acc: 0.5677778124809265\n",
      "Epoch: 374/1000 Train loss: 0.8043128252029419 Train acc: 0.49129629135131836\n",
      "Epoch: 374/1000 Valid loss: 0.6807820796966553 Valid acc: 0.5683333277702332\n",
      "Epoch: 375/1000 Train loss: 0.8009548783302307 Train acc: 0.49259254336357117\n",
      "Epoch: 375/1000 Valid loss: 0.6783125996589661 Valid acc: 0.5611110925674438\n",
      "Epoch: 376/1000 Train loss: 0.7993810772895813 Train acc: 0.48314815759658813\n",
      "Epoch: 376/1000 Valid loss: 0.6749923229217529 Valid acc: 0.5633333325386047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 377/1000 Train loss: 0.7953236699104309 Train acc: 0.48759257793426514\n",
      "Epoch: 377/1000 Valid loss: 0.6740068793296814 Valid acc: 0.5550000071525574\n",
      "Epoch: 378/1000 Train loss: 0.7945846319198608 Train acc: 0.47870370745658875\n",
      "Epoch: 378/1000 Valid loss: 0.6699879765510559 Valid acc: 0.5538888573646545\n",
      "Epoch: 379/1000 Train loss: 0.7900533676147461 Train acc: 0.48277774453163147\n",
      "Epoch: 379/1000 Valid loss: 0.6701188683509827 Valid acc: 0.5483333468437195\n",
      "Epoch: 380/1000 Train loss: 0.7898905277252197 Train acc: 0.47611114382743835\n",
      "Epoch: 380/1000 Valid loss: 0.6669893264770508 Valid acc: 0.5488888621330261\n",
      "Epoch: 381/1000 Train loss: 0.7855724692344666 Train acc: 0.4788888692855835\n",
      "Epoch: 381/1000 Valid loss: 0.6643224358558655 Valid acc: 0.5444445013999939\n",
      "Epoch: 382/1000 Train loss: 0.7850549817085266 Train acc: 0.47462961077690125\n",
      "Epoch: 382/1000 Valid loss: 0.6640737652778625 Valid acc: 0.545555591583252\n",
      "Epoch: 383/1000 Train loss: 0.7816681265830994 Train acc: 0.4788888692855835\n",
      "Epoch: 383/1000 Valid loss: 0.6641598343849182 Valid acc: 0.5444444417953491\n",
      "Epoch: 384/1000 Train loss: 0.7813966870307922 Train acc: 0.4740740954875946\n",
      "Epoch: 384/1000 Valid loss: 0.6602082848548889 Valid acc: 0.545555591583252\n",
      "Epoch: 385/1000 Train loss: 0.7780148386955261 Train acc: 0.48055559396743774\n",
      "Epoch: 385/1000 Valid loss: 0.658951461315155 Valid acc: 0.54666668176651\n",
      "Epoch: 386/1000 Train loss: 0.7767037153244019 Train acc: 0.47703707218170166\n",
      "Epoch: 386/1000 Valid loss: 0.6556036472320557 Valid acc: 0.5483333468437195\n",
      "Epoch: 387/1000 Train loss: 0.7737685441970825 Train acc: 0.48055553436279297\n",
      "Epoch: 387/1000 Valid loss: 0.6530930995941162 Valid acc: 0.5488888621330261\n",
      "Epoch: 388/1000 Train loss: 0.7724771499633789 Train acc: 0.47833335399627686\n",
      "Epoch: 388/1000 Valid loss: 0.6527190804481506 Valid acc: 0.5511111617088318\n",
      "Epoch: 389/1000 Train loss: 0.770928680896759 Train acc: 0.48222219944000244\n",
      "Epoch: 389/1000 Valid loss: 0.6490470767021179 Valid acc: 0.5566666722297668\n",
      "Epoch: 390/1000 Train loss: 0.7713241577148438 Train acc: 0.48000001907348633\n",
      "Epoch: 390/1000 Valid loss: 0.6448590755462646 Valid acc: 0.5550000071525574\n",
      "Epoch: 391/1000 Train loss: 0.7684080004692078 Train acc: 0.48407405614852905\n",
      "Epoch: 391/1000 Valid loss: 0.6467804908752441 Valid acc: 0.5561110973358154\n",
      "Epoch: 392/1000 Train loss: 0.7692922353744507 Train acc: 0.47999995946884155\n",
      "Epoch: 392/1000 Valid loss: 0.6419922709465027 Valid acc: 0.5566666722297668\n",
      "Epoch: 393/1000 Train loss: 0.7681753039360046 Train acc: 0.48092591762542725\n",
      "Epoch: 393/1000 Valid loss: 0.6411333084106445 Valid acc: 0.5550000071525574\n",
      "Epoch: 394/1000 Train loss: 0.7639738917350769 Train acc: 0.4794444441795349\n",
      "Epoch: 394/1000 Valid loss: 0.6324060559272766 Valid acc: 0.5583333373069763\n",
      "Epoch: 395/1000 Train loss: 0.7564899921417236 Train acc: 0.48462963104248047\n",
      "Epoch: 395/1000 Valid loss: 0.6309362053871155 Valid acc: 0.5577778220176697\n",
      "Epoch: 396/1000 Train loss: 0.7553592920303345 Train acc: 0.48314815759658813\n",
      "Epoch: 396/1000 Valid loss: 0.6284207701683044 Valid acc: 0.5605555772781372\n",
      "Epoch: 397/1000 Train loss: 0.7537171244621277 Train acc: 0.4896296262741089\n",
      "Epoch: 397/1000 Valid loss: 0.6250764727592468 Valid acc: 0.5627778172492981\n",
      "Epoch: 398/1000 Train loss: 0.7539064884185791 Train acc: 0.48888885974884033\n",
      "Epoch: 398/1000 Valid loss: 0.6269877552986145 Valid acc: 0.5672222375869751\n",
      "Epoch: 399/1000 Train loss: 0.7542511820793152 Train acc: 0.4909259080886841\n",
      "Epoch: 399/1000 Valid loss: 0.6279249787330627 Valid acc: 0.569444477558136\n",
      "Epoch: 400/1000 Train loss: 0.7550628185272217 Train acc: 0.4888888895511627\n",
      "Epoch: 400/1000 Valid loss: 0.6271535754203796 Valid acc: 0.5649999976158142\n",
      "Epoch: 401/1000 Train loss: 0.7541133165359497 Train acc: 0.4887036681175232\n",
      "Epoch: 401/1000 Valid loss: 0.625119149684906 Valid acc: 0.5616666674613953\n",
      "Epoch: 402/1000 Train loss: 0.7530454397201538 Train acc: 0.48592594265937805\n",
      "Epoch: 402/1000 Valid loss: 0.6243169903755188 Valid acc: 0.5605555772781372\n",
      "Epoch: 403/1000 Train loss: 0.7514517307281494 Train acc: 0.4883333444595337\n",
      "Epoch: 403/1000 Valid loss: 0.6223941445350647 Valid acc: 0.5616666674613953\n",
      "Epoch: 404/1000 Train loss: 0.7500593066215515 Train acc: 0.48722225427627563\n",
      "Epoch: 404/1000 Valid loss: 0.6202864050865173 Valid acc: 0.5600000023841858\n",
      "Epoch: 405/1000 Train loss: 0.7483950853347778 Train acc: 0.489814817905426\n",
      "Epoch: 405/1000 Valid loss: 0.6182394027709961 Valid acc: 0.5644444823265076\n",
      "Epoch: 406/1000 Train loss: 0.7465447187423706 Train acc: 0.49037039279937744\n",
      "Epoch: 406/1000 Valid loss: 0.6163080334663391 Valid acc: 0.5655555725097656\n",
      "Epoch: 407/1000 Train loss: 0.7452142834663391 Train acc: 0.49222224950790405\n",
      "Epoch: 407/1000 Valid loss: 0.614010751247406 Valid acc: 0.5683333277702332\n",
      "Epoch: 408/1000 Train loss: 0.7438371181488037 Train acc: 0.4924074411392212\n",
      "Epoch: 408/1000 Valid loss: 0.6129401922225952 Valid acc: 0.5672221779823303\n",
      "Epoch: 409/1000 Train loss: 0.7423308491706848 Train acc: 0.4931481182575226\n",
      "Epoch: 409/1000 Valid loss: 0.6112200617790222 Valid acc: 0.5649999976158142\n",
      "Epoch: 410/1000 Train loss: 0.7411315441131592 Train acc: 0.4922221899032593\n",
      "Epoch: 410/1000 Valid loss: 0.609663724899292 Valid acc: 0.5666666626930237\n",
      "Epoch: 411/1000 Train loss: 0.7397274374961853 Train acc: 0.4935184717178345\n",
      "Epoch: 411/1000 Valid loss: 0.6083385348320007 Valid acc: 0.5649999976158142\n",
      "Epoch: 412/1000 Train loss: 0.7385901808738708 Train acc: 0.4924074411392212\n",
      "Epoch: 412/1000 Valid loss: 0.606776237487793 Valid acc: 0.5672222375869751\n",
      "Epoch: 413/1000 Train loss: 0.7373063564300537 Train acc: 0.4918518662452698\n",
      "Epoch: 413/1000 Valid loss: 0.6047253608703613 Valid acc: 0.5688889026641846\n",
      "Epoch: 414/1000 Train loss: 0.7362609505653381 Train acc: 0.49092593789100647\n",
      "Epoch: 414/1000 Valid loss: 0.6033219695091248 Valid acc: 0.5677777528762817\n",
      "Epoch: 415/1000 Train loss: 0.7350669503211975 Train acc: 0.49166664481163025\n",
      "Epoch: 415/1000 Valid loss: 0.6019337773323059 Valid acc: 0.5699999928474426\n",
      "Epoch: 416/1000 Train loss: 0.7340709567070007 Train acc: 0.49037033319473267\n",
      "Epoch: 416/1000 Valid loss: 0.6005639433860779 Valid acc: 0.5699999928474426\n",
      "Epoch: 417/1000 Train loss: 0.7329731583595276 Train acc: 0.49074071645736694\n",
      "Epoch: 417/1000 Valid loss: 0.5994421243667603 Valid acc: 0.5711110830307007\n",
      "Epoch: 418/1000 Train loss: 0.7320011258125305 Train acc: 0.489814817905426\n",
      "Epoch: 418/1000 Valid loss: 0.5984565615653992 Valid acc: 0.570555567741394\n",
      "Epoch: 419/1000 Train loss: 0.7314063310623169 Train acc: 0.48944446444511414\n",
      "Epoch: 419/1000 Valid loss: 0.5980982780456543 Valid acc: 0.5711111426353455\n",
      "Epoch: 420/1000 Train loss: 0.730463981628418 Train acc: 0.489814817905426\n",
      "Epoch: 420/1000 Valid loss: 0.5963789820671082 Valid acc: 0.5699999928474426\n",
      "Epoch: 421/1000 Train loss: 0.729537308216095 Train acc: 0.49037039279937744\n",
      "Epoch: 421/1000 Valid loss: 0.5945014357566833 Valid acc: 0.5694444179534912\n",
      "Epoch: 422/1000 Train loss: 0.7285802364349365 Train acc: 0.48944440484046936\n",
      "Epoch: 422/1000 Valid loss: 0.5949594378471375 Valid acc: 0.5722222328186035\n",
      "Epoch: 423/1000 Train loss: 0.7277616858482361 Train acc: 0.489814817905426\n",
      "Epoch: 423/1000 Valid loss: 0.592749297618866 Valid acc: 0.570555567741394\n",
      "Epoch: 424/1000 Train loss: 0.7268239855766296 Train acc: 0.4892592430114746\n",
      "Epoch: 424/1000 Valid loss: 0.5931816101074219 Valid acc: 0.5722222328186035\n",
      "Epoch: 425/1000 Train loss: 0.7260122895240784 Train acc: 0.49037039279937744\n",
      "Epoch: 425/1000 Valid loss: 0.5920420289039612 Valid acc: 0.5711111426353455\n",
      "Epoch: 426/1000 Train loss: 0.7251436114311218 Train acc: 0.48907408118247986\n",
      "Epoch: 426/1000 Valid loss: 0.592678964138031 Valid acc: 0.5711110830307007\n",
      "Epoch: 427/1000 Train loss: 0.724290132522583 Train acc: 0.49037033319473267\n",
      "Epoch: 427/1000 Valid loss: 0.5899550318717957 Valid acc: 0.5722222328186035\n",
      "Epoch: 428/1000 Train loss: 0.7234480381011963 Train acc: 0.4905555546283722\n",
      "Epoch: 428/1000 Valid loss: 0.5904959440231323 Valid acc: 0.5711111426353455\n",
      "Epoch: 429/1000 Train loss: 0.722541868686676 Train acc: 0.4905555546283722\n",
      "Epoch: 429/1000 Valid loss: 0.5896026492118835 Valid acc: 0.5705555081367493\n",
      "Epoch: 430/1000 Train loss: 0.7217341661453247 Train acc: 0.4899999797344208\n",
      "Epoch: 430/1000 Valid loss: 0.5885170102119446 Valid acc: 0.5716666579246521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 431/1000 Train loss: 0.7208846211433411 Train acc: 0.4914814531803131\n",
      "Epoch: 431/1000 Valid loss: 0.5875482559204102 Valid acc: 0.5716666579246521\n",
      "Epoch: 432/1000 Train loss: 0.7200897336006165 Train acc: 0.4905555546283722\n",
      "Epoch: 432/1000 Valid loss: 0.5877103209495544 Valid acc: 0.573888897895813\n",
      "Epoch: 433/1000 Train loss: 0.7192955613136292 Train acc: 0.49111106991767883\n",
      "Epoch: 433/1000 Valid loss: 0.586671769618988 Valid acc: 0.5716666579246521\n",
      "Epoch: 434/1000 Train loss: 0.7185659408569336 Train acc: 0.4905555546283722\n",
      "Epoch: 434/1000 Valid loss: 0.586219072341919 Valid acc: 0.5733333230018616\n",
      "Epoch: 435/1000 Train loss: 0.7176691889762878 Train acc: 0.49129629135131836\n",
      "Epoch: 435/1000 Valid loss: 0.5847830772399902 Valid acc: 0.5733333230018616\n",
      "Epoch: 436/1000 Train loss: 0.7169529795646667 Train acc: 0.49074071645736694\n",
      "Epoch: 436/1000 Valid loss: 0.58393794298172 Valid acc: 0.5722222328186035\n",
      "Epoch: 437/1000 Train loss: 0.7160841822624207 Train acc: 0.49166664481163025\n",
      "Epoch: 437/1000 Valid loss: 0.5828133225440979 Valid acc: 0.5722221732139587\n",
      "Epoch: 438/1000 Train loss: 0.7153603434562683 Train acc: 0.4920370280742645\n",
      "Epoch: 438/1000 Valid loss: 0.5811083316802979 Valid acc: 0.5727777481079102\n",
      "Epoch: 439/1000 Train loss: 0.7145265936851501 Train acc: 0.49259260296821594\n",
      "Epoch: 439/1000 Valid loss: 0.5790751576423645 Valid acc: 0.5733333230018616\n",
      "Epoch: 440/1000 Train loss: 0.7138493657112122 Train acc: 0.49259260296821594\n",
      "Epoch: 440/1000 Valid loss: 0.5786607265472412 Valid acc: 0.5738888382911682\n",
      "Epoch: 441/1000 Train loss: 0.7129530906677246 Train acc: 0.4933333396911621\n",
      "Epoch: 441/1000 Valid loss: 0.5787414908409119 Valid acc: 0.5733333230018616\n",
      "Epoch: 442/1000 Train loss: 0.7123683094978333 Train acc: 0.49351850152015686\n",
      "Epoch: 442/1000 Valid loss: 0.5758881568908691 Valid acc: 0.5744444131851196\n",
      "Epoch: 443/1000 Train loss: 0.7115394473075867 Train acc: 0.4940740764141083\n",
      "Epoch: 443/1000 Valid loss: 0.5776191353797913 Valid acc: 0.5733333230018616\n",
      "Epoch: 444/1000 Train loss: 0.7115269303321838 Train acc: 0.4920370280742645\n",
      "Epoch: 444/1000 Valid loss: 0.5732574462890625 Valid acc: 0.5761110782623291\n",
      "Epoch: 445/1000 Train loss: 0.7103608250617981 Train acc: 0.4924073815345764\n",
      "Epoch: 445/1000 Valid loss: 0.571445882320404 Valid acc: 0.5766666531562805\n",
      "Epoch: 446/1000 Train loss: 0.710181474685669 Train acc: 0.49129629135131836\n",
      "Epoch: 446/1000 Valid loss: 0.5725945830345154 Valid acc: 0.574999988079071\n",
      "Epoch: 447/1000 Train loss: 0.7097300291061401 Train acc: 0.49166667461395264\n",
      "Epoch: 447/1000 Valid loss: 0.5712717175483704 Valid acc: 0.573888897895813\n",
      "Epoch: 448/1000 Train loss: 0.7084604501724243 Train acc: 0.49222224950790405\n",
      "Epoch: 448/1000 Valid loss: 0.5694885849952698 Valid acc: 0.5772222280502319\n",
      "Epoch: 449/1000 Train loss: 0.7075013518333435 Train acc: 0.4914814531803131\n",
      "Epoch: 449/1000 Valid loss: 0.5674128532409668 Valid acc: 0.5777777433395386\n",
      "Epoch: 450/1000 Train loss: 0.7067061066627502 Train acc: 0.4924074411392212\n",
      "Epoch: 450/1000 Valid loss: 0.5678529739379883 Valid acc: 0.5788888335227966\n",
      "Epoch: 451/1000 Train loss: 0.705784261226654 Train acc: 0.49259260296821594\n",
      "Epoch: 451/1000 Valid loss: 0.5622713565826416 Valid acc: 0.5816666483879089\n",
      "Epoch: 452/1000 Train loss: 0.7046182155609131 Train acc: 0.4924073815345764\n",
      "Epoch: 452/1000 Valid loss: 0.5603797435760498 Valid acc: 0.582777738571167\n",
      "Epoch: 453/1000 Train loss: 0.704666256904602 Train acc: 0.4933333396911621\n",
      "Epoch: 453/1000 Valid loss: 0.5609584450721741 Valid acc: 0.5811110734939575\n",
      "Epoch: 454/1000 Train loss: 0.7032064199447632 Train acc: 0.4937037229537964\n",
      "Epoch: 454/1000 Valid loss: 0.5582833886146545 Valid acc: 0.5833333134651184\n",
      "Epoch: 455/1000 Train loss: 0.702219545841217 Train acc: 0.49351850152015686\n",
      "Epoch: 455/1000 Valid loss: 0.5575653910636902 Valid acc: 0.5838889479637146\n",
      "Epoch: 456/1000 Train loss: 0.70148766040802 Train acc: 0.493703693151474\n",
      "Epoch: 456/1000 Valid loss: 0.555881917476654 Valid acc: 0.5833333134651184\n",
      "Epoch: 457/1000 Train loss: 0.7019359469413757 Train acc: 0.49351850152015686\n",
      "Epoch: 457/1000 Valid loss: 0.5550853610038757 Valid acc: 0.5844444632530212\n",
      "Epoch: 458/1000 Train loss: 0.700531542301178 Train acc: 0.4946295917034149\n",
      "Epoch: 458/1000 Valid loss: 0.556839644908905 Valid acc: 0.5850000381469727\n",
      "Epoch: 459/1000 Train loss: 0.6996743679046631 Train acc: 0.4959259033203125\n",
      "Epoch: 459/1000 Valid loss: 0.5560266375541687 Valid acc: 0.5849999785423279\n",
      "Epoch: 460/1000 Train loss: 0.6986498832702637 Train acc: 0.49611106514930725\n",
      "Epoch: 460/1000 Valid loss: 0.5555715560913086 Valid acc: 0.5838889479637146\n",
      "Epoch: 461/1000 Train loss: 0.697902262210846 Train acc: 0.49611106514930725\n",
      "Epoch: 461/1000 Valid loss: 0.5513966679573059 Valid acc: 0.5850000381469727\n",
      "Epoch: 462/1000 Train loss: 0.6981911063194275 Train acc: 0.49518516659736633\n",
      "Epoch: 462/1000 Valid loss: 0.5519700646400452 Valid acc: 0.5838889479637146\n",
      "Epoch: 463/1000 Train loss: 0.6969559192657471 Train acc: 0.4953703284263611\n",
      "Epoch: 463/1000 Valid loss: 0.5515106320381165 Valid acc: 0.5866666436195374\n",
      "Epoch: 464/1000 Train loss: 0.696546733379364 Train acc: 0.4955555498600006\n",
      "Epoch: 464/1000 Valid loss: 0.5489883422851562 Valid acc: 0.5883333683013916\n",
      "Epoch: 465/1000 Train loss: 0.6957471370697021 Train acc: 0.49481481313705444\n",
      "Epoch: 465/1000 Valid loss: 0.5462656617164612 Valid acc: 0.5888888835906982\n",
      "Epoch: 466/1000 Train loss: 0.6940467953681946 Train acc: 0.4964814782142639\n",
      "Epoch: 466/1000 Valid loss: 0.5489307045936584 Valid acc: 0.5855555534362793\n",
      "Epoch: 467/1000 Train loss: 0.6937367916107178 Train acc: 0.4968518018722534\n",
      "Epoch: 467/1000 Valid loss: 0.5452304482460022 Valid acc: 0.5877777934074402\n",
      "Epoch: 468/1000 Train loss: 0.6921731233596802 Train acc: 0.4972222149372101\n",
      "Epoch: 468/1000 Valid loss: 0.5466788411140442 Valid acc: 0.5883333683013916\n",
      "Epoch: 469/1000 Train loss: 0.6913320422172546 Train acc: 0.496111124753952\n",
      "Epoch: 469/1000 Valid loss: 0.5435771346092224 Valid acc: 0.5905556082725525\n",
      "Epoch: 470/1000 Train loss: 0.6902949213981628 Train acc: 0.49703705310821533\n",
      "Epoch: 470/1000 Valid loss: 0.5447325706481934 Valid acc: 0.5927777886390686\n",
      "Epoch: 471/1000 Train loss: 0.6898651719093323 Train acc: 0.4968518018722534\n",
      "Epoch: 471/1000 Valid loss: 0.5446142554283142 Valid acc: 0.5938889384269714\n",
      "Epoch: 472/1000 Train loss: 0.6889472603797913 Train acc: 0.49796295166015625\n",
      "Epoch: 472/1000 Valid loss: 0.544655442237854 Valid acc: 0.5922222137451172\n",
      "Epoch: 473/1000 Train loss: 0.6888803243637085 Train acc: 0.49796295166015625\n",
      "Epoch: 473/1000 Valid loss: 0.5476400256156921 Valid acc: 0.5933333039283752\n",
      "Epoch: 474/1000 Train loss: 0.6879549026489258 Train acc: 0.4981481730937958\n",
      "Epoch: 474/1000 Valid loss: 0.5452989935874939 Valid acc: 0.5938889384269714\n",
      "Epoch: 475/1000 Train loss: 0.687163770198822 Train acc: 0.4987036883831024\n",
      "Epoch: 475/1000 Valid loss: 0.5464169383049011 Valid acc: 0.5938889384269714\n",
      "Epoch: 476/1000 Train loss: 0.6864039897918701 Train acc: 0.4990741014480591\n",
      "Epoch: 476/1000 Valid loss: 0.5452271103858948 Valid acc: 0.5950000286102295\n",
      "Epoch: 477/1000 Train loss: 0.685600757598877 Train acc: 0.4987037479877472\n",
      "Epoch: 477/1000 Valid loss: 0.5434341430664062 Valid acc: 0.5944444537162781\n",
      "Epoch: 478/1000 Train loss: 0.6848357319831848 Train acc: 0.49925926327705383\n",
      "Epoch: 478/1000 Valid loss: 0.5442865490913391 Valid acc: 0.5955555438995361\n",
      "Epoch: 479/1000 Train loss: 0.6841945648193359 Train acc: 0.4996296167373657\n",
      "Epoch: 479/1000 Valid loss: 0.5385286808013916 Valid acc: 0.5983333587646484\n",
      "Epoch: 480/1000 Train loss: 0.6834256649017334 Train acc: 0.5\n",
      "Epoch: 480/1000 Valid loss: 0.5407991409301758 Valid acc: 0.5961111187934875\n",
      "Epoch: 481/1000 Train loss: 0.6828823089599609 Train acc: 0.4994444251060486\n",
      "Epoch: 481/1000 Valid loss: 0.5406021475791931 Valid acc: 0.5983333587646484\n",
      "Epoch: 482/1000 Train loss: 0.682242214679718 Train acc: 0.5005555748939514\n",
      "Epoch: 482/1000 Valid loss: 0.5392497181892395 Valid acc: 0.5983333587646484\n",
      "Epoch: 483/1000 Train loss: 0.6821928024291992 Train acc: 0.49796295166015625\n",
      "Epoch: 483/1000 Valid loss: 0.5372050404548645 Valid acc: 0.5994444489479065\n",
      "Epoch: 484/1000 Train loss: 0.6807702779769897 Train acc: 0.5016666650772095\n",
      "Epoch: 484/1000 Valid loss: 0.5391244888305664 Valid acc: 0.5927777886390686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 485/1000 Train loss: 0.6815128326416016 Train acc: 0.4987036883831024\n",
      "Epoch: 485/1000 Valid loss: 0.5355488657951355 Valid acc: 0.6016666889190674\n",
      "Epoch: 486/1000 Train loss: 0.6798474788665771 Train acc: 0.5025925636291504\n",
      "Epoch: 486/1000 Valid loss: 0.5519639849662781 Valid acc: 0.5916666388511658\n",
      "Epoch: 487/1000 Train loss: 0.6899694204330444 Train acc: 0.4977777898311615\n",
      "Epoch: 487/1000 Valid loss: 0.5455074310302734 Valid acc: 0.5955555438995361\n",
      "Epoch: 488/1000 Train loss: 0.6867789030075073 Train acc: 0.5014815330505371\n",
      "Epoch: 488/1000 Valid loss: 0.5433763861656189 Valid acc: 0.5994444489479065\n",
      "Epoch: 489/1000 Train loss: 0.6839325428009033 Train acc: 0.504444420337677\n",
      "Epoch: 489/1000 Valid loss: 0.5435495972633362 Valid acc: 0.5938888192176819\n",
      "Epoch: 490/1000 Train loss: 0.6835095882415771 Train acc: 0.5012962818145752\n",
      "Epoch: 490/1000 Valid loss: 0.5342867374420166 Valid acc: 0.6022222638130188\n",
      "Epoch: 491/1000 Train loss: 0.6802146434783936 Train acc: 0.5046296715736389\n",
      "Epoch: 491/1000 Valid loss: 0.5293229222297668 Valid acc: 0.6033332943916321\n",
      "Epoch: 492/1000 Train loss: 0.678902268409729 Train acc: 0.5031481981277466\n",
      "Epoch: 492/1000 Valid loss: 0.5309357047080994 Valid acc: 0.6072222590446472\n",
      "Epoch: 493/1000 Train loss: 0.6775643825531006 Train acc: 0.5064814686775208\n",
      "Epoch: 493/1000 Valid loss: 0.5271908640861511 Valid acc: 0.6033332943916321\n",
      "Epoch: 494/1000 Train loss: 0.6776899695396423 Train acc: 0.5009258985519409\n",
      "Epoch: 494/1000 Valid loss: 0.5293765068054199 Valid acc: 0.6044444441795349\n",
      "Epoch: 495/1000 Train loss: 0.676068902015686 Train acc: 0.5072222352027893\n",
      "Epoch: 495/1000 Valid loss: 0.5259869694709778 Valid acc: 0.6033332943916321\n",
      "Epoch: 496/1000 Train loss: 0.6779024600982666 Train acc: 0.4996296465396881\n",
      "Epoch: 496/1000 Valid loss: 0.531455934047699 Valid acc: 0.5994444489479065\n",
      "Epoch: 497/1000 Train loss: 0.6756835579872131 Train acc: 0.5074074268341064\n",
      "Epoch: 497/1000 Valid loss: 0.5326910614967346 Valid acc: 0.6005555987358093\n",
      "Epoch: 498/1000 Train loss: 0.678289532661438 Train acc: 0.5009258985519409\n",
      "Epoch: 498/1000 Valid loss: 0.5297961235046387 Valid acc: 0.6016666889190674\n",
      "Epoch: 499/1000 Train loss: 0.6754211187362671 Train acc: 0.5077778100967407\n",
      "Epoch: 499/1000 Valid loss: 0.5232409238815308 Valid acc: 0.6050000190734863\n",
      "Epoch: 500/1000 Train loss: 0.6750178337097168 Train acc: 0.5012962818145752\n",
      "Epoch: 500/1000 Valid loss: 0.5231534838676453 Valid acc: 0.6088889241218567\n",
      "Epoch: 501/1000 Train loss: 0.6730446219444275 Train acc: 0.5107407569885254\n",
      "Epoch: 501/1000 Valid loss: 0.5216783285140991 Valid acc: 0.6055555939674377\n",
      "Epoch: 502/1000 Train loss: 0.6742599010467529 Train acc: 0.5018518567085266\n",
      "Epoch: 502/1000 Valid loss: 0.5232787132263184 Valid acc: 0.6027777791023254\n",
      "Epoch: 503/1000 Train loss: 0.6718767285346985 Train acc: 0.5114814639091492\n",
      "Epoch: 503/1000 Valid loss: 0.5219475626945496 Valid acc: 0.6033334136009216\n",
      "Epoch: 504/1000 Train loss: 0.6745322346687317 Train acc: 0.5\n",
      "Epoch: 504/1000 Valid loss: 0.5256596207618713 Valid acc: 0.5972222685813904\n",
      "Epoch: 505/1000 Train loss: 0.6723689436912537 Train acc: 0.5096296072006226\n",
      "Epoch: 505/1000 Valid loss: 0.5228139758110046 Valid acc: 0.602222204208374\n",
      "Epoch: 506/1000 Train loss: 0.6738215684890747 Train acc: 0.5009258985519409\n",
      "Epoch: 506/1000 Valid loss: 0.5161440968513489 Valid acc: 0.605555534362793\n",
      "Epoch: 507/1000 Train loss: 0.6693887114524841 Train acc: 0.513333261013031\n",
      "Epoch: 507/1000 Valid loss: 0.5143871903419495 Valid acc: 0.6122222542762756\n",
      "Epoch: 508/1000 Train loss: 0.6706733107566833 Train acc: 0.5020370483398438\n",
      "Epoch: 508/1000 Valid loss: 0.5160463452339172 Valid acc: 0.602222204208374\n",
      "Epoch: 509/1000 Train loss: 0.6686437129974365 Train acc: 0.512592613697052\n",
      "Epoch: 509/1000 Valid loss: 0.5142199993133545 Valid acc: 0.6116666793823242\n",
      "Epoch: 510/1000 Train loss: 0.6691577434539795 Train acc: 0.5029629468917847\n",
      "Epoch: 510/1000 Valid loss: 0.5137694478034973 Valid acc: 0.6083333492279053\n",
      "Epoch: 511/1000 Train loss: 0.6676466464996338 Train acc: 0.5148148536682129\n",
      "Epoch: 511/1000 Valid loss: 0.5128108859062195 Valid acc: 0.6111111044883728\n",
      "Epoch: 512/1000 Train loss: 0.669623613357544 Train acc: 0.5018518567085266\n",
      "Epoch: 512/1000 Valid loss: 0.5112507343292236 Valid acc: 0.6122221946716309\n",
      "Epoch: 513/1000 Train loss: 0.666083812713623 Train acc: 0.5131481289863586\n",
      "Epoch: 513/1000 Valid loss: 0.511399507522583 Valid acc: 0.6111111640930176\n",
      "Epoch: 514/1000 Train loss: 0.6669968366622925 Train acc: 0.5042592883110046\n",
      "Epoch: 514/1000 Valid loss: 0.5089038014411926 Valid acc: 0.6116666793823242\n",
      "Epoch: 515/1000 Train loss: 0.6646612882614136 Train acc: 0.5127778053283691\n",
      "Epoch: 515/1000 Valid loss: 0.507975161075592 Valid acc: 0.6127777695655823\n",
      "Epoch: 516/1000 Train loss: 0.6670119166374207 Train acc: 0.5027778148651123\n",
      "Epoch: 516/1000 Valid loss: 0.5064088106155396 Valid acc: 0.6061111092567444\n",
      "Epoch: 517/1000 Train loss: 0.6639230847358704 Train acc: 0.5131481289863586\n",
      "Epoch: 517/1000 Valid loss: 0.5046699047088623 Valid acc: 0.6161110997200012\n",
      "Epoch: 518/1000 Train loss: 0.6642413139343262 Train acc: 0.5053703784942627\n",
      "Epoch: 518/1000 Valid loss: 0.5126045346260071 Valid acc: 0.605555534362793\n",
      "Epoch: 519/1000 Train loss: 0.6642398834228516 Train acc: 0.5131481289863586\n",
      "Epoch: 519/1000 Valid loss: 0.5117030143737793 Valid acc: 0.6072222590446472\n",
      "Epoch: 520/1000 Train loss: 0.666106641292572 Train acc: 0.5042592883110046\n",
      "Epoch: 520/1000 Valid loss: 0.5132614374160767 Valid acc: 0.601111114025116\n",
      "Epoch: 521/1000 Train loss: 0.6633952856063843 Train acc: 0.5120370388031006\n",
      "Epoch: 521/1000 Valid loss: 0.5020278692245483 Valid acc: 0.6188889145851135\n",
      "Epoch: 522/1000 Train loss: 0.6613149642944336 Train acc: 0.5075925588607788\n",
      "Epoch: 522/1000 Valid loss: 0.499438613653183 Valid acc: 0.6161110997200012\n",
      "Epoch: 523/1000 Train loss: 0.6592832803726196 Train acc: 0.5144444704055786\n",
      "Epoch: 523/1000 Valid loss: 0.5097122192382812 Valid acc: 0.6105555891990662\n",
      "Epoch: 524/1000 Train loss: 0.6635575294494629 Train acc: 0.5051851868629456\n",
      "Epoch: 524/1000 Valid loss: 0.514826238155365 Valid acc: 0.5966666340827942\n",
      "Epoch: 525/1000 Train loss: 0.6623088717460632 Train acc: 0.5124074220657349\n",
      "Epoch: 525/1000 Valid loss: 0.4994896948337555 Valid acc: 0.6222221851348877\n",
      "Epoch: 526/1000 Train loss: 0.6585356593132019 Train acc: 0.5099999904632568\n",
      "Epoch: 526/1000 Valid loss: 0.5040690302848816 Valid acc: 0.617222249507904\n",
      "Epoch: 527/1000 Train loss: 0.6611301898956299 Train acc: 0.5164815187454224\n",
      "Epoch: 527/1000 Valid loss: 0.4956156313419342 Valid acc: 0.6233332753181458\n",
      "Epoch: 528/1000 Train loss: 0.6602565050125122 Train acc: 0.5085185170173645\n",
      "Epoch: 528/1000 Valid loss: 0.4991025924682617 Valid acc: 0.6133332848548889\n",
      "Epoch: 529/1000 Train loss: 0.6567735075950623 Train acc: 0.5164814591407776\n",
      "Epoch: 529/1000 Valid loss: 0.4927575886249542 Valid acc: 0.620555579662323\n",
      "Epoch: 530/1000 Train loss: 0.6548444032669067 Train acc: 0.5137037038803101\n",
      "Epoch: 530/1000 Valid loss: 0.4870699644088745 Valid acc: 0.6244444847106934\n",
      "Epoch: 531/1000 Train loss: 0.6530044078826904 Train acc: 0.5183333158493042\n",
      "Epoch: 531/1000 Valid loss: 0.48783746361732483 Valid acc: 0.625\n",
      "Epoch: 532/1000 Train loss: 0.6533539295196533 Train acc: 0.5155555605888367\n",
      "Epoch: 532/1000 Valid loss: 0.4846789538860321 Valid acc: 0.6272222399711609\n",
      "Epoch: 533/1000 Train loss: 0.6527133584022522 Train acc: 0.517037034034729\n",
      "Epoch: 533/1000 Valid loss: 0.4900003969669342 Valid acc: 0.6222221851348877\n",
      "Epoch: 534/1000 Train loss: 0.6545615196228027 Train acc: 0.5131481289863586\n",
      "Epoch: 534/1000 Valid loss: 0.48835238814353943 Valid acc: 0.6161110997200012\n",
      "Epoch: 535/1000 Train loss: 0.6524817943572998 Train acc: 0.5172222256660461\n",
      "Epoch: 535/1000 Valid loss: 0.4991241693496704 Valid acc: 0.6150000095367432\n",
      "Epoch: 536/1000 Train loss: 0.6553621888160706 Train acc: 0.5131481289863586\n",
      "Epoch: 536/1000 Valid loss: 0.5007193088531494 Valid acc: 0.6105555891990662\n",
      "Epoch: 537/1000 Train loss: 0.6533834934234619 Train acc: 0.5172221660614014\n",
      "Epoch: 537/1000 Valid loss: 0.48583129048347473 Valid acc: 0.6238889098167419\n",
      "Epoch: 538/1000 Train loss: 0.6511433720588684 Train acc: 0.5155555605888367\n",
      "Epoch: 538/1000 Valid loss: 0.4845668375492096 Valid acc: 0.6238889098167419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 539/1000 Train loss: 0.651494562625885 Train acc: 0.5190740823745728\n",
      "Epoch: 539/1000 Valid loss: 0.4897121489048004 Valid acc: 0.6322221755981445\n",
      "Epoch: 540/1000 Train loss: 0.6561161279678345 Train acc: 0.5125925540924072\n",
      "Epoch: 540/1000 Valid loss: 0.4946676790714264 Valid acc: 0.6138889193534851\n",
      "Epoch: 541/1000 Train loss: 0.6550871133804321 Train acc: 0.5181481838226318\n",
      "Epoch: 541/1000 Valid loss: 0.49000048637390137 Valid acc: 0.6255555152893066\n",
      "Epoch: 542/1000 Train loss: 0.6542200446128845 Train acc: 0.5124073624610901\n",
      "Epoch: 542/1000 Valid loss: 0.4933806359767914 Valid acc: 0.6150000095367432\n",
      "Epoch: 543/1000 Train loss: 0.6552783846855164 Train acc: 0.5162962675094604\n",
      "Epoch: 543/1000 Valid loss: 0.4900777041912079 Valid acc: 0.6311111450195312\n",
      "Epoch: 544/1000 Train loss: 0.6516011357307434 Train acc: 0.5151851773262024\n",
      "Epoch: 544/1000 Valid loss: 0.4796799123287201 Valid acc: 0.6300000548362732\n",
      "Epoch: 545/1000 Train loss: 0.6472436785697937 Train acc: 0.5222222208976746\n",
      "Epoch: 545/1000 Valid loss: 0.4748823940753937 Valid acc: 0.6361110806465149\n",
      "Epoch: 546/1000 Train loss: 0.6481513381004333 Train acc: 0.5144444704055786\n",
      "Epoch: 546/1000 Valid loss: 0.48509320616722107 Valid acc: 0.6222222447395325\n",
      "Epoch: 547/1000 Train loss: 0.6480627059936523 Train acc: 0.5231481790542603\n",
      "Epoch: 547/1000 Valid loss: 0.47053226828575134 Valid acc: 0.6372222304344177\n",
      "Epoch: 548/1000 Train loss: 0.6469916105270386 Train acc: 0.5162962675094604\n",
      "Epoch: 548/1000 Valid loss: 0.4800114631652832 Valid acc: 0.6244444847106934\n",
      "Epoch: 549/1000 Train loss: 0.6468979716300964 Train acc: 0.5235185027122498\n",
      "Epoch: 549/1000 Valid loss: 0.4699982702732086 Valid acc: 0.64000004529953\n",
      "Epoch: 550/1000 Train loss: 0.6442204713821411 Train acc: 0.5177777409553528\n",
      "Epoch: 550/1000 Valid loss: 0.47465237975120544 Valid acc: 0.6322222352027893\n",
      "Epoch: 551/1000 Train loss: 0.6421402096748352 Train acc: 0.5248148441314697\n",
      "Epoch: 551/1000 Valid loss: 0.4667872190475464 Valid acc: 0.6399999260902405\n",
      "Epoch: 552/1000 Train loss: 0.6412460803985596 Train acc: 0.5201852321624756\n",
      "Epoch: 552/1000 Valid loss: 0.4621065557003021 Valid acc: 0.6388888955116272\n",
      "Epoch: 553/1000 Train loss: 0.6388094425201416 Train acc: 0.5242593288421631\n",
      "Epoch: 553/1000 Valid loss: 0.4589065611362457 Valid acc: 0.6461110711097717\n",
      "Epoch: 554/1000 Train loss: 0.6366487145423889 Train acc: 0.5237037539482117\n",
      "Epoch: 554/1000 Valid loss: 0.45470961928367615 Valid acc: 0.6527777314186096\n",
      "Epoch: 555/1000 Train loss: 0.635500431060791 Train acc: 0.5253703594207764\n",
      "Epoch: 555/1000 Valid loss: 0.46029019355773926 Valid acc: 0.6411110758781433\n",
      "Epoch: 556/1000 Train loss: 0.6346244215965271 Train acc: 0.5255554914474487\n",
      "Epoch: 556/1000 Valid loss: 0.45259785652160645 Valid acc: 0.652222216129303\n",
      "Epoch: 557/1000 Train loss: 0.6339353322982788 Train acc: 0.5262963175773621\n",
      "Epoch: 557/1000 Valid loss: 0.45719265937805176 Valid acc: 0.644444465637207\n",
      "Epoch: 558/1000 Train loss: 0.6339051723480225 Train acc: 0.5257407426834106\n",
      "Epoch: 558/1000 Valid loss: 0.4495548903942108 Valid acc: 0.6466665863990784\n",
      "Epoch: 559/1000 Train loss: 0.6333754658699036 Train acc: 0.5253703594207764\n",
      "Epoch: 559/1000 Valid loss: 0.446012407541275 Valid acc: 0.6511110663414001\n",
      "Epoch: 560/1000 Train loss: 0.6294450759887695 Train acc: 0.5275925993919373\n",
      "Epoch: 560/1000 Valid loss: 0.4448992908000946 Valid acc: 0.652222216129303\n",
      "Epoch: 561/1000 Train loss: 0.6290799975395203 Train acc: 0.5274074077606201\n",
      "Epoch: 561/1000 Valid loss: 0.4512968957424164 Valid acc: 0.6433332562446594\n",
      "Epoch: 562/1000 Train loss: 0.6293959021568298 Train acc: 0.5255556106567383\n",
      "Epoch: 562/1000 Valid loss: 0.4398278295993805 Valid acc: 0.652222216129303\n",
      "Epoch: 563/1000 Train loss: 0.6281916499137878 Train acc: 0.5246296525001526\n",
      "Epoch: 563/1000 Valid loss: 0.44916772842407227 Valid acc: 0.6422221660614014\n",
      "Epoch: 564/1000 Train loss: 0.6298368573188782 Train acc: 0.5248148441314697\n",
      "Epoch: 564/1000 Valid loss: 0.4474106729030609 Valid acc: 0.6483333110809326\n",
      "Epoch: 565/1000 Train loss: 0.6292417049407959 Train acc: 0.5238888263702393\n",
      "Epoch: 565/1000 Valid loss: 0.45430824160575867 Valid acc: 0.644444465637207\n",
      "Epoch: 566/1000 Train loss: 0.6312662363052368 Train acc: 0.5266667008399963\n",
      "Epoch: 566/1000 Valid loss: 0.4489487111568451 Valid acc: 0.643333375453949\n",
      "Epoch: 567/1000 Train loss: 0.6303007006645203 Train acc: 0.522777795791626\n",
      "Epoch: 567/1000 Valid loss: 0.4494664669036865 Valid acc: 0.6405555605888367\n",
      "Epoch: 568/1000 Train loss: 0.626481294631958 Train acc: 0.5268518328666687\n",
      "Epoch: 568/1000 Valid loss: 0.4311796724796295 Valid acc: 0.6538888812065125\n",
      "Epoch: 569/1000 Train loss: 0.624374508857727 Train acc: 0.5274074077606201\n",
      "Epoch: 569/1000 Valid loss: 0.4386909008026123 Valid acc: 0.6449999809265137\n",
      "Epoch: 570/1000 Train loss: 0.6217647790908813 Train acc: 0.5275925397872925\n",
      "Epoch: 570/1000 Valid loss: 0.4262286126613617 Valid acc: 0.6549999713897705\n",
      "Epoch: 571/1000 Train loss: 0.619279682636261 Train acc: 0.5301852226257324\n",
      "Epoch: 571/1000 Valid loss: 0.4240274727344513 Valid acc: 0.6555555462837219\n",
      "Epoch: 572/1000 Train loss: 0.6161302924156189 Train acc: 0.5338889360427856\n",
      "Epoch: 572/1000 Valid loss: 0.4247969686985016 Valid acc: 0.6555555462837219\n",
      "Epoch: 573/1000 Train loss: 0.6151559948921204 Train acc: 0.5320370197296143\n",
      "Epoch: 573/1000 Valid loss: 0.42354413866996765 Valid acc: 0.6555555462837219\n",
      "Epoch: 574/1000 Train loss: 0.6144182682037354 Train acc: 0.5327777862548828\n",
      "Epoch: 574/1000 Valid loss: 0.41730332374572754 Valid acc: 0.6566666960716248\n",
      "Epoch: 575/1000 Train loss: 0.6141676902770996 Train acc: 0.5311111211776733\n",
      "Epoch: 575/1000 Valid loss: 0.4168587923049927 Valid acc: 0.6572222113609314\n",
      "Epoch: 576/1000 Train loss: 0.6136557459831238 Train acc: 0.5325925946235657\n",
      "Epoch: 576/1000 Valid loss: 0.4217405319213867 Valid acc: 0.6566666960716248\n",
      "Epoch: 577/1000 Train loss: 0.6146799921989441 Train acc: 0.5298148393630981\n",
      "Epoch: 577/1000 Valid loss: 0.43114206194877625 Valid acc: 0.648888885974884\n",
      "Epoch: 578/1000 Train loss: 0.6167965531349182 Train acc: 0.5314815044403076\n",
      "Epoch: 578/1000 Valid loss: 0.4274921417236328 Valid acc: 0.6538888812065125\n",
      "Epoch: 579/1000 Train loss: 0.6142706274986267 Train acc: 0.5311110615730286\n",
      "Epoch: 579/1000 Valid loss: 0.4238196313381195 Valid acc: 0.6527777314186096\n",
      "Epoch: 580/1000 Train loss: 0.6115039587020874 Train acc: 0.534074068069458\n",
      "Epoch: 580/1000 Valid loss: 0.41803669929504395 Valid acc: 0.6561110615730286\n",
      "Epoch: 581/1000 Train loss: 0.6116029620170593 Train acc: 0.5307407379150391\n",
      "Epoch: 581/1000 Valid loss: 0.42990633845329285 Valid acc: 0.6427777409553528\n",
      "Epoch: 582/1000 Train loss: 0.6157243251800537 Train acc: 0.527222216129303\n",
      "Epoch: 582/1000 Valid loss: 0.4380422532558441 Valid acc: 0.6461110711097717\n",
      "Epoch: 583/1000 Train loss: 0.62265944480896 Train acc: 0.527222216129303\n",
      "Epoch: 583/1000 Valid loss: 0.4144425392150879 Valid acc: 0.6533333659172058\n",
      "Epoch: 584/1000 Train loss: 0.6203354597091675 Train acc: 0.5209258794784546\n",
      "Epoch: 584/1000 Valid loss: 0.5677267909049988 Valid acc: 0.5999999642372131\n",
      "Epoch: 585/1000 Train loss: 0.7004625201225281 Train acc: 0.4977777898311615\n",
      "Epoch: 585/1000 Valid loss: 0.569532036781311 Valid acc: 0.5916666388511658\n",
      "Epoch: 586/1000 Train loss: 0.6896548867225647 Train acc: 0.49833330512046814\n",
      "Epoch: 586/1000 Valid loss: 0.5132066607475281 Valid acc: 0.6183333396911621\n",
      "Epoch: 587/1000 Train loss: 0.6578644514083862 Train acc: 0.5200000405311584\n",
      "Epoch: 587/1000 Valid loss: 0.47596415877342224 Valid acc: 0.6394444108009338\n",
      "Epoch: 588/1000 Train loss: 0.6442894339561462 Train acc: 0.5170370936393738\n",
      "Epoch: 588/1000 Valid loss: 0.48616185784339905 Valid acc: 0.6122222542762756\n",
      "Epoch: 589/1000 Train loss: 0.6462891101837158 Train acc: 0.515740692615509\n",
      "Epoch: 589/1000 Valid loss: 0.46128448843955994 Valid acc: 0.6383333206176758\n",
      "Epoch: 590/1000 Train loss: 0.6447784304618835 Train acc: 0.5185185670852661\n",
      "Epoch: 590/1000 Valid loss: 0.455313116312027 Valid acc: 0.64000004529953\n",
      "Epoch: 591/1000 Train loss: 0.6363723278045654 Train acc: 0.5207407474517822\n",
      "Epoch: 591/1000 Valid loss: 0.4475717544555664 Valid acc: 0.6427777409553528\n",
      "Epoch: 592/1000 Train loss: 0.627830982208252 Train acc: 0.5262963175773621\n",
      "Epoch: 592/1000 Valid loss: 0.44754672050476074 Valid acc: 0.6422221660614014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 593/1000 Train loss: 0.6266059875488281 Train acc: 0.5255555510520935\n",
      "Epoch: 593/1000 Valid loss: 0.4307337999343872 Valid acc: 0.6505555510520935\n",
      "Epoch: 594/1000 Train loss: 0.6213807463645935 Train acc: 0.5288888812065125\n",
      "Epoch: 594/1000 Valid loss: 0.4276951849460602 Valid acc: 0.6566666960716248\n",
      "Epoch: 595/1000 Train loss: 0.6191907525062561 Train acc: 0.5296295881271362\n",
      "Epoch: 595/1000 Valid loss: 0.42487093806266785 Valid acc: 0.6622222065925598\n",
      "Epoch: 596/1000 Train loss: 0.6199426054954529 Train acc: 0.5305555462837219\n",
      "Epoch: 596/1000 Valid loss: 0.42595699429512024 Valid acc: 0.6577777862548828\n",
      "Epoch: 597/1000 Train loss: 0.6154909729957581 Train acc: 0.5311111211776733\n",
      "Epoch: 597/1000 Valid loss: 0.4213719069957733 Valid acc: 0.6600000262260437\n",
      "Epoch: 598/1000 Train loss: 0.6132333278656006 Train acc: 0.5324074029922485\n",
      "Epoch: 598/1000 Valid loss: 0.4172758162021637 Valid acc: 0.6605556011199951\n",
      "Epoch: 599/1000 Train loss: 0.6111084222793579 Train acc: 0.5331481695175171\n",
      "Epoch: 599/1000 Valid loss: 0.4170307219028473 Valid acc: 0.6577777862548828\n",
      "Epoch: 600/1000 Train loss: 0.6090546250343323 Train acc: 0.5337036848068237\n",
      "Epoch: 600/1000 Valid loss: 0.41672566533088684 Valid acc: 0.6561110615730286\n",
      "Epoch: 601/1000 Train loss: 0.6084128618240356 Train acc: 0.5335185527801514\n",
      "Epoch: 601/1000 Valid loss: 0.41371116042137146 Valid acc: 0.6572222113609314\n",
      "Epoch: 602/1000 Train loss: 0.6063113808631897 Train acc: 0.5355555415153503\n",
      "Epoch: 602/1000 Valid loss: 0.41199907660484314 Valid acc: 0.6600000262260437\n",
      "Epoch: 603/1000 Train loss: 0.6058111786842346 Train acc: 0.5362963080406189\n",
      "Epoch: 603/1000 Valid loss: 0.41041162610054016 Valid acc: 0.6600000262260437\n",
      "Epoch: 604/1000 Train loss: 0.6044762134552002 Train acc: 0.5377777814865112\n",
      "Epoch: 604/1000 Valid loss: 0.4070242643356323 Valid acc: 0.6633333563804626\n",
      "Epoch: 605/1000 Train loss: 0.6027128100395203 Train acc: 0.5403703451156616\n",
      "Epoch: 605/1000 Valid loss: 0.40712419152259827 Valid acc: 0.6644444465637207\n",
      "Epoch: 606/1000 Train loss: 0.6008192896842957 Train acc: 0.542222261428833\n",
      "Epoch: 606/1000 Valid loss: 0.40394195914268494 Valid acc: 0.6688888669013977\n",
      "Epoch: 607/1000 Train loss: 0.5978832244873047 Train acc: 0.544259250164032\n",
      "Epoch: 607/1000 Valid loss: 0.4015056788921356 Valid acc: 0.6688888669013977\n",
      "Epoch: 608/1000 Train loss: 0.596782386302948 Train acc: 0.5464814901351929\n",
      "Epoch: 608/1000 Valid loss: 0.40542352199554443 Valid acc: 0.667222261428833\n",
      "Epoch: 609/1000 Train loss: 0.597744882106781 Train acc: 0.5431481599807739\n",
      "Epoch: 609/1000 Valid loss: 0.4001823961734772 Valid acc: 0.6666666865348816\n",
      "Epoch: 610/1000 Train loss: 0.5987355709075928 Train acc: 0.5392592549324036\n",
      "Epoch: 610/1000 Valid loss: 0.4044400751590729 Valid acc: 0.6644444465637207\n",
      "Epoch: 611/1000 Train loss: 0.5982100963592529 Train acc: 0.5412963032722473\n",
      "Epoch: 611/1000 Valid loss: 0.4028205871582031 Valid acc: 0.6633333563804626\n",
      "Epoch: 612/1000 Train loss: 0.5958711504936218 Train acc: 0.5440740585327148\n",
      "Epoch: 612/1000 Valid loss: 0.4095257818698883 Valid acc: 0.6666666865348816\n",
      "Epoch: 613/1000 Train loss: 0.5999863147735596 Train acc: 0.5433332920074463\n",
      "Epoch: 613/1000 Valid loss: 0.40459153056144714 Valid acc: 0.6533333659172058\n",
      "Epoch: 614/1000 Train loss: 0.6004473567008972 Train acc: 0.5327777862548828\n",
      "Epoch: 614/1000 Valid loss: 0.3982444107532501 Valid acc: 0.6688888669013977\n",
      "Epoch: 615/1000 Train loss: 0.5986785292625427 Train acc: 0.5362962484359741\n",
      "Epoch: 615/1000 Valid loss: 0.39703360199928284 Valid acc: 0.666111171245575\n",
      "Epoch: 616/1000 Train loss: 0.59727543592453 Train acc: 0.5379629135131836\n",
      "Epoch: 616/1000 Valid loss: 0.40210679173469543 Valid acc: 0.6666666865348816\n",
      "Epoch: 617/1000 Train loss: 0.6003595590591431 Train acc: 0.5361111164093018\n",
      "Epoch: 617/1000 Valid loss: 0.3956408202648163 Valid acc: 0.6638889312744141\n",
      "Epoch: 618/1000 Train loss: 0.5968434810638428 Train acc: 0.5368518829345703\n",
      "Epoch: 618/1000 Valid loss: 0.392501562833786 Valid acc: 0.6683333516120911\n",
      "Epoch: 619/1000 Train loss: 0.5948506593704224 Train acc: 0.5385185480117798\n",
      "Epoch: 619/1000 Valid loss: 0.38920101523399353 Valid acc: 0.6688888669013977\n",
      "Epoch: 620/1000 Train loss: 0.5926192998886108 Train acc: 0.5390741229057312\n",
      "Epoch: 620/1000 Valid loss: 0.3863711357116699 Valid acc: 0.6705555319786072\n",
      "Epoch: 621/1000 Train loss: 0.5913100838661194 Train acc: 0.539814829826355\n",
      "Epoch: 621/1000 Valid loss: 0.38620105385780334 Valid acc: 0.6711111068725586\n",
      "Epoch: 622/1000 Train loss: 0.5904228687286377 Train acc: 0.540925920009613\n",
      "Epoch: 622/1000 Valid loss: 0.3860461711883545 Valid acc: 0.67166668176651\n",
      "Epoch: 623/1000 Train loss: 0.5894121527671814 Train acc: 0.540925920009613\n",
      "Epoch: 623/1000 Valid loss: 0.3851613998413086 Valid acc: 0.6700000166893005\n",
      "Epoch: 624/1000 Train loss: 0.5888699293136597 Train acc: 0.542962908744812\n",
      "Epoch: 624/1000 Valid loss: 0.3836909830570221 Valid acc: 0.6733333468437195\n",
      "Epoch: 625/1000 Train loss: 0.5867006182670593 Train acc: 0.5442593097686768\n",
      "Epoch: 625/1000 Valid loss: 0.38266682624816895 Valid acc: 0.6722221970558167\n",
      "Epoch: 626/1000 Train loss: 0.5867993831634521 Train acc: 0.5449999570846558\n",
      "Epoch: 626/1000 Valid loss: 0.38364148139953613 Valid acc: 0.67166668176651\n",
      "Epoch: 627/1000 Train loss: 0.5869324207305908 Train acc: 0.5446296334266663\n",
      "Epoch: 627/1000 Valid loss: 0.38374194502830505 Valid acc: 0.6655555367469788\n",
      "Epoch: 628/1000 Train loss: 0.5845224261283875 Train acc: 0.5444444417953491\n",
      "Epoch: 628/1000 Valid loss: 0.3819443881511688 Valid acc: 0.670555591583252\n",
      "Epoch: 629/1000 Train loss: 0.5860673785209656 Train acc: 0.5440740585327148\n",
      "Epoch: 629/1000 Valid loss: 0.37796318531036377 Valid acc: 0.6761110424995422\n",
      "Epoch: 630/1000 Train loss: 0.5830584168434143 Train acc: 0.5490740537643433\n",
      "Epoch: 630/1000 Valid loss: 0.37803614139556885 Valid acc: 0.6738889217376709\n",
      "Epoch: 631/1000 Train loss: 0.5828899145126343 Train acc: 0.5522222518920898\n",
      "Epoch: 631/1000 Valid loss: 0.3770996034145355 Valid acc: 0.6722223162651062\n",
      "Epoch: 632/1000 Train loss: 0.58121657371521 Train acc: 0.5475925803184509\n",
      "Epoch: 632/1000 Valid loss: 0.37361279129981995 Valid acc: 0.675000011920929\n",
      "Epoch: 633/1000 Train loss: 0.58102947473526 Train acc: 0.5459259152412415\n",
      "Epoch: 633/1000 Valid loss: 0.375173956155777 Valid acc: 0.6761111617088318\n",
      "Epoch: 634/1000 Train loss: 0.5793181657791138 Train acc: 0.5477778315544128\n",
      "Epoch: 634/1000 Valid loss: 0.36520734429359436 Valid acc: 0.6794444918632507\n",
      "Epoch: 635/1000 Train loss: 0.5763458013534546 Train acc: 0.5522221922874451\n",
      "Epoch: 635/1000 Valid loss: 0.35984519124031067 Valid acc: 0.6833333373069763\n",
      "Epoch: 636/1000 Train loss: 0.5740424394607544 Train acc: 0.5642592906951904\n",
      "Epoch: 636/1000 Valid loss: 0.3600553572177887 Valid acc: 0.6700000166893005\n",
      "Epoch: 637/1000 Train loss: 0.572914183139801 Train acc: 0.5561110973358154\n",
      "Epoch: 637/1000 Valid loss: 0.36049672961235046 Valid acc: 0.6766666769981384\n",
      "Epoch: 638/1000 Train loss: 0.5755870938301086 Train acc: 0.5516666769981384\n",
      "Epoch: 638/1000 Valid loss: 0.3628634214401245 Valid acc: 0.6688888669013977\n",
      "Epoch: 639/1000 Train loss: 0.5752053260803223 Train acc: 0.5512962937355042\n",
      "Epoch: 639/1000 Valid loss: 0.3591063320636749 Valid acc: 0.6811111569404602\n",
      "Epoch: 640/1000 Train loss: 0.5721375942230225 Train acc: 0.5562962889671326\n",
      "Epoch: 640/1000 Valid loss: 0.3622385561466217 Valid acc: 0.675000011920929\n",
      "Epoch: 641/1000 Train loss: 0.574298620223999 Train acc: 0.5548148155212402\n",
      "Epoch: 641/1000 Valid loss: 0.3565002381801605 Valid acc: 0.6783332824707031\n",
      "Epoch: 642/1000 Train loss: 0.5740118622779846 Train acc: 0.5509259104728699\n",
      "Epoch: 642/1000 Valid loss: 0.3645056486129761 Valid acc: 0.6633333563804626\n",
      "Epoch: 643/1000 Train loss: 0.5763754844665527 Train acc: 0.5477777719497681\n",
      "Epoch: 643/1000 Valid loss: 0.3541114628314972 Valid acc: 0.6794444918632507\n",
      "Epoch: 644/1000 Train loss: 0.571527898311615 Train acc: 0.5548148155212402\n",
      "Epoch: 644/1000 Valid loss: 0.35238921642303467 Valid acc: 0.6805555820465088\n",
      "Epoch: 645/1000 Train loss: 0.5705487728118896 Train acc: 0.5572222471237183\n",
      "Epoch: 645/1000 Valid loss: 0.35512006282806396 Valid acc: 0.6755555272102356\n",
      "Epoch: 646/1000 Train loss: 0.5692752599716187 Train acc: 0.5562962889671326\n",
      "Epoch: 646/1000 Valid loss: 0.35587576031684875 Valid acc: 0.6788888573646545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 647/1000 Train loss: 0.5692867636680603 Train acc: 0.5555555820465088\n",
      "Epoch: 647/1000 Valid loss: 0.3556157648563385 Valid acc: 0.6766667366027832\n",
      "Epoch: 648/1000 Train loss: 0.5644025802612305 Train acc: 0.5562962293624878\n",
      "Epoch: 648/1000 Valid loss: 0.353325217962265 Valid acc: 0.6788888573646545\n",
      "Epoch: 649/1000 Train loss: 0.5548644065856934 Train acc: 0.5677778124809265\n",
      "Epoch: 649/1000 Valid loss: 0.3564217984676361 Valid acc: 0.6700000166893005\n",
      "Epoch: 650/1000 Train loss: 0.5572366714477539 Train acc: 0.5638888478279114\n",
      "Epoch: 650/1000 Valid loss: 0.3581978380680084 Valid acc: 0.6738888621330261\n",
      "Epoch: 651/1000 Train loss: 0.5696380138397217 Train acc: 0.5555555820465088\n",
      "Epoch: 651/1000 Valid loss: 0.3746929466724396 Valid acc: 0.6627777814865112\n",
      "Epoch: 652/1000 Train loss: 0.5090468525886536 Train acc: 0.5968518853187561\n",
      "Epoch: 652/1000 Valid loss: 0.36805638670921326 Valid acc: 0.67166668176651\n",
      "Epoch: 653/1000 Train loss: 0.4995803236961365 Train acc: 0.6087037920951843\n",
      "Epoch: 653/1000 Valid loss: 0.3503030836582184 Valid acc: 0.6766667366027832\n",
      "Epoch: 654/1000 Train loss: 0.4835187494754791 Train acc: 0.6153704524040222\n",
      "Epoch: 654/1000 Valid loss: 0.3360111713409424 Valid acc: 0.6938889026641846\n",
      "Epoch: 655/1000 Train loss: 0.4594379663467407 Train acc: 0.6320370435714722\n",
      "Epoch: 655/1000 Valid loss: 0.3303438723087311 Valid acc: 0.6944444179534912\n",
      "Epoch: 656/1000 Train loss: 0.4262942671775818 Train acc: 0.6538889408111572\n",
      "Epoch: 656/1000 Valid loss: 0.3119637668132782 Valid acc: 0.707777738571167\n",
      "Epoch: 657/1000 Train loss: 0.34274980425834656 Train acc: 0.6972222328186035\n",
      "Epoch: 657/1000 Valid loss: 0.2740040719509125 Valid acc: 0.7255555987358093\n",
      "Epoch: 658/1000 Train loss: 0.31517863273620605 Train acc: 0.7094444632530212\n",
      "Epoch: 658/1000 Valid loss: 0.31820979714393616 Valid acc: 0.6966666579246521\n",
      "Epoch: 659/1000 Train loss: 0.47717660665512085 Train acc: 0.6214814782142639\n",
      "Epoch: 659/1000 Valid loss: 0.3485790193080902 Valid acc: 0.6822221875190735\n",
      "Epoch: 660/1000 Train loss: 0.518204927444458 Train acc: 0.6001851558685303\n",
      "Epoch: 660/1000 Valid loss: 0.3264443576335907 Valid acc: 0.6933333277702332\n",
      "Epoch: 661/1000 Train loss: 0.35358816385269165 Train acc: 0.692037045955658\n",
      "Epoch: 661/1000 Valid loss: 0.27555063366889954 Valid acc: 0.7127777934074402\n",
      "Epoch: 662/1000 Train loss: 0.32862651348114014 Train acc: 0.6996296644210815\n",
      "Epoch: 662/1000 Valid loss: 0.2757631838321686 Valid acc: 0.7216666340827942\n",
      "Epoch: 663/1000 Train loss: 0.3158622980117798 Train acc: 0.7138888835906982\n",
      "Epoch: 663/1000 Valid loss: 0.26977670192718506 Valid acc: 0.7255555987358093\n",
      "Epoch: 664/1000 Train loss: 0.3132956326007843 Train acc: 0.7170370817184448\n",
      "Epoch: 664/1000 Valid loss: 0.26791128516197205 Valid acc: 0.7183333039283752\n",
      "Epoch: 665/1000 Train loss: 0.31311723589897156 Train acc: 0.7066667079925537\n",
      "Epoch: 665/1000 Valid loss: 0.26559388637542725 Valid acc: 0.731666624546051\n",
      "Epoch: 666/1000 Train loss: 0.30794665217399597 Train acc: 0.7124073505401611\n",
      "Epoch: 666/1000 Valid loss: 0.26346686482429504 Valid acc: 0.7333333492279053\n",
      "Epoch: 667/1000 Train loss: 0.3033030331134796 Train acc: 0.7188888788223267\n",
      "Epoch: 667/1000 Valid loss: 0.26675912737846375 Valid acc: 0.746666669845581\n",
      "Epoch: 668/1000 Train loss: 0.3066507577896118 Train acc: 0.7277777791023254\n",
      "Epoch: 668/1000 Valid loss: 0.2621002197265625 Valid acc: 0.726111114025116\n",
      "Epoch: 669/1000 Train loss: 0.30259189009666443 Train acc: 0.711481511592865\n",
      "Epoch: 669/1000 Valid loss: 0.2631465494632721 Valid acc: 0.7255555987358093\n",
      "Epoch: 670/1000 Train loss: 0.29630157351493835 Train acc: 0.7164814472198486\n",
      "Epoch: 670/1000 Valid loss: 0.26259350776672363 Valid acc: 0.727222204208374\n",
      "Epoch: 671/1000 Train loss: 0.301162987947464 Train acc: 0.7161111235618591\n",
      "Epoch: 671/1000 Valid loss: 0.26872801780700684 Valid acc: 0.7144444584846497\n",
      "Epoch: 672/1000 Train loss: 0.29464876651763916 Train acc: 0.7127777934074402\n",
      "Epoch: 672/1000 Valid loss: 0.2599974572658539 Valid acc: 0.7194444537162781\n",
      "Epoch: 673/1000 Train loss: 0.3138395845890045 Train acc: 0.7040740847587585\n",
      "Epoch: 673/1000 Valid loss: 0.26035889983177185 Valid acc: 0.7266666889190674\n",
      "Epoch: 674/1000 Train loss: 0.2915377914905548 Train acc: 0.7161110639572144\n",
      "Epoch: 674/1000 Valid loss: 0.25312766432762146 Valid acc: 0.7288889288902283\n",
      "Epoch: 675/1000 Train loss: 0.28721508383750916 Train acc: 0.7200000286102295\n",
      "Epoch: 675/1000 Valid loss: 0.25038206577301025 Valid acc: 0.7333333492279053\n",
      "Epoch: 676/1000 Train loss: 0.28398534655570984 Train acc: 0.7194444537162781\n",
      "Epoch: 676/1000 Valid loss: 0.24932861328125 Valid acc: 0.7333333492279053\n",
      "Epoch: 677/1000 Train loss: 0.322154700756073 Train acc: 0.7024074196815491\n",
      "Epoch: 677/1000 Valid loss: 0.29482367634773254 Valid acc: 0.7099999785423279\n",
      "Epoch: 678/1000 Train loss: 0.37544307112693787 Train acc: 0.6718518733978271\n",
      "Epoch: 678/1000 Valid loss: 0.2681612968444824 Valid acc: 0.712222158908844\n",
      "Epoch: 679/1000 Train loss: 0.2930848300457001 Train acc: 0.7222222089767456\n",
      "Epoch: 679/1000 Valid loss: 0.2605566382408142 Valid acc: 0.7483332753181458\n",
      "Epoch: 680/1000 Train loss: 0.2906879782676697 Train acc: 0.7301852107048035\n",
      "Epoch: 680/1000 Valid loss: 0.24792341887950897 Valid acc: 0.727222204208374\n",
      "Epoch: 681/1000 Train loss: 0.2614065408706665 Train acc: 0.734259307384491\n",
      "Epoch: 681/1000 Valid loss: 0.22129280865192413 Valid acc: 0.7472222447395325\n",
      "Epoch: 682/1000 Train loss: 0.23767434060573578 Train acc: 0.7424073815345764\n",
      "Epoch: 682/1000 Valid loss: 0.21258115768432617 Valid acc: 0.7527777552604675\n",
      "Epoch: 683/1000 Train loss: 0.21932107210159302 Train acc: 0.746666669845581\n",
      "Epoch: 683/1000 Valid loss: 0.21283133327960968 Valid acc: 0.7388889193534851\n",
      "Epoch: 684/1000 Train loss: 0.21350935101509094 Train acc: 0.7522222995758057\n",
      "Epoch: 684/1000 Valid loss: 0.22862088680267334 Valid acc: 0.7438888549804688\n",
      "Epoch: 685/1000 Train loss: 0.29166361689567566 Train acc: 0.7251851558685303\n",
      "Epoch: 685/1000 Valid loss: 0.22751764953136444 Valid acc: 0.7461110949516296\n",
      "Epoch: 686/1000 Train loss: 0.22495198249816895 Train acc: 0.7490741014480591\n",
      "Epoch: 686/1000 Valid loss: 0.21610617637634277 Valid acc: 0.746666669845581\n",
      "Epoch: 687/1000 Train loss: 0.21129100024700165 Train acc: 0.7511111497879028\n",
      "Epoch: 687/1000 Valid loss: 0.20508049428462982 Valid acc: 0.7522222399711609\n",
      "Epoch: 688/1000 Train loss: 0.20148412883281708 Train acc: 0.7564814686775208\n",
      "Epoch: 688/1000 Valid loss: 0.20330099761486053 Valid acc: 0.7516667246818542\n",
      "Epoch: 689/1000 Train loss: 0.21245890855789185 Train acc: 0.7516666650772095\n",
      "Epoch: 689/1000 Valid loss: 0.21538640558719635 Valid acc: 0.7483332753181458\n",
      "Epoch: 690/1000 Train loss: 0.21887046098709106 Train acc: 0.7470370531082153\n",
      "Epoch: 690/1000 Valid loss: 0.22514121234416962 Valid acc: 0.7316667437553406\n",
      "Epoch: 691/1000 Train loss: 0.21659359335899353 Train acc: 0.7457406520843506\n",
      "Epoch: 691/1000 Valid loss: 0.21074582636356354 Valid acc: 0.7461110949516296\n",
      "Epoch: 692/1000 Train loss: 0.20839767158031464 Train acc: 0.7505555748939514\n",
      "Epoch: 692/1000 Valid loss: 0.20368152856826782 Valid acc: 0.7561111450195312\n",
      "Epoch: 693/1000 Train loss: 0.2075456976890564 Train acc: 0.7535185217857361\n",
      "Epoch: 693/1000 Valid loss: 0.21054048836231232 Valid acc: 0.7505555152893066\n",
      "Epoch: 694/1000 Train loss: 0.21422980725765228 Train acc: 0.745555579662323\n",
      "Epoch: 694/1000 Valid loss: 0.2266102284193039 Valid acc: 0.7316667437553406\n",
      "Epoch: 695/1000 Train loss: 0.2208063304424286 Train acc: 0.7459259629249573\n",
      "Epoch: 695/1000 Valid loss: 0.21151788532733917 Valid acc: 0.7505555152893066\n",
      "Epoch: 696/1000 Train loss: 0.22285911440849304 Train acc: 0.7490741014480591\n",
      "Epoch: 696/1000 Valid loss: 0.21182197332382202 Valid acc: 0.7522222399711609\n",
      "Epoch: 697/1000 Train loss: 0.21282976865768433 Train acc: 0.753148078918457\n",
      "Epoch: 697/1000 Valid loss: 0.2043553739786148 Valid acc: 0.754444420337677\n",
      "Epoch: 698/1000 Train loss: 0.21588259935379028 Train acc: 0.7518517971038818\n",
      "Epoch: 698/1000 Valid loss: 0.20892786979675293 Valid acc: 0.754444420337677\n",
      "Epoch: 699/1000 Train loss: 0.21965807676315308 Train acc: 0.7518517971038818\n",
      "Epoch: 699/1000 Valid loss: 0.20078325271606445 Valid acc: 0.7566666603088379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700/1000 Train loss: 0.211237832903862 Train acc: 0.7549999952316284\n",
      "Epoch: 700/1000 Valid loss: 0.20707309246063232 Valid acc: 0.75\n",
      "Epoch: 701/1000 Train loss: 0.212612122297287 Train acc: 0.7448147535324097\n",
      "Epoch: 701/1000 Valid loss: 0.2149425595998764 Valid acc: 0.742222249507904\n",
      "Epoch: 702/1000 Train loss: 0.2079842984676361 Train acc: 0.7540740966796875\n",
      "Epoch: 702/1000 Valid loss: 0.202168807387352 Valid acc: 0.7549999356269836\n",
      "Epoch: 703/1000 Train loss: 0.21270082890987396 Train acc: 0.745185136795044\n",
      "Epoch: 703/1000 Valid loss: 0.20651914179325104 Valid acc: 0.7394444346427917\n",
      "Epoch: 704/1000 Train loss: 0.20117676258087158 Train acc: 0.753333330154419\n",
      "Epoch: 704/1000 Valid loss: 0.1989242285490036 Valid acc: 0.7522222399711609\n",
      "Epoch: 705/1000 Train loss: 0.19692747294902802 Train acc: 0.7546296119689941\n",
      "Epoch: 705/1000 Valid loss: 0.1930071860551834 Valid acc: 0.757777750492096\n",
      "Epoch: 706/1000 Train loss: 0.18624360859394073 Train acc: 0.7579629421234131\n",
      "Epoch: 706/1000 Valid loss: 0.1881973296403885 Valid acc: 0.7583333849906921\n",
      "Epoch: 707/1000 Train loss: 0.19231121242046356 Train acc: 0.7490741014480591\n",
      "Epoch: 707/1000 Valid loss: 0.18828816711902618 Valid acc: 0.7538889050483704\n",
      "Epoch: 708/1000 Train loss: 0.19358132779598236 Train acc: 0.7570369839668274\n",
      "Epoch: 708/1000 Valid loss: 0.1990666538476944 Valid acc: 0.7549999356269836\n",
      "Epoch: 709/1000 Train loss: 0.2055668979883194 Train acc: 0.7537037134170532\n",
      "Epoch: 709/1000 Valid loss: 0.20205409824848175 Valid acc: 0.7549999356269836\n",
      "Epoch: 710/1000 Train loss: 0.22085006535053253 Train acc: 0.7490740418434143\n",
      "Epoch: 710/1000 Valid loss: 0.2243005782365799 Valid acc: 0.7472222447395325\n",
      "Epoch: 711/1000 Train loss: 0.2243325114250183 Train acc: 0.746666669845581\n",
      "Epoch: 711/1000 Valid loss: 0.19964106380939484 Valid acc: 0.7522222399711609\n",
      "Epoch: 712/1000 Train loss: 0.21520625054836273 Train acc: 0.7535185217857361\n",
      "Epoch: 712/1000 Valid loss: 0.21349585056304932 Valid acc: 0.7483332753181458\n",
      "Epoch: 713/1000 Train loss: 0.22213265299797058 Train acc: 0.7483333349227905\n",
      "Epoch: 713/1000 Valid loss: 0.18847353756427765 Valid acc: 0.7572221755981445\n",
      "Epoch: 714/1000 Train loss: 0.1850621998310089 Train acc: 0.7570370435714722\n",
      "Epoch: 714/1000 Valid loss: 0.1822224110364914 Valid acc: 0.7583333849906921\n",
      "Epoch: 715/1000 Train loss: 0.1831158846616745 Train acc: 0.7583333253860474\n",
      "Epoch: 715/1000 Valid loss: 0.18424995243549347 Valid acc: 0.7566666603088379\n",
      "Epoch: 716/1000 Train loss: 0.18089500069618225 Train acc: 0.7581481337547302\n",
      "Epoch: 716/1000 Valid loss: 0.18406327068805695 Valid acc: 0.7566666603088379\n",
      "Epoch: 717/1000 Train loss: 0.18115992844104767 Train acc: 0.7583333849906921\n",
      "Epoch: 717/1000 Valid loss: 0.18701235949993134 Valid acc: 0.7555555701255798\n",
      "Epoch: 718/1000 Train loss: 0.18641667068004608 Train acc: 0.7553703784942627\n",
      "Epoch: 718/1000 Valid loss: 0.19404418766498566 Valid acc: 0.7505555152893066\n",
      "Epoch: 719/1000 Train loss: 0.19072018563747406 Train acc: 0.7559258937835693\n",
      "Epoch: 719/1000 Valid loss: 0.19020569324493408 Valid acc: 0.7561111450195312\n",
      "Epoch: 720/1000 Train loss: 0.1927012950181961 Train acc: 0.7518517971038818\n",
      "Epoch: 720/1000 Valid loss: 0.18881885707378387 Valid acc: 0.7549999356269836\n",
      "Epoch: 721/1000 Train loss: 0.18791423738002777 Train acc: 0.7588889002799988\n",
      "Epoch: 721/1000 Valid loss: 0.18698231875896454 Valid acc: 0.7572221755981445\n",
      "Epoch: 722/1000 Train loss: 0.18890202045440674 Train acc: 0.7555555701255798\n",
      "Epoch: 722/1000 Valid loss: 0.1878783255815506 Valid acc: 0.7561111450195312\n",
      "Epoch: 723/1000 Train loss: 0.18802334368228912 Train acc: 0.7581481337547302\n",
      "Epoch: 723/1000 Valid loss: 0.18392209708690643 Valid acc: 0.7572221755981445\n",
      "Epoch: 724/1000 Train loss: 0.18519125878810883 Train acc: 0.760185182094574\n",
      "Epoch: 724/1000 Valid loss: 0.18215598165988922 Valid acc: 0.7588889002799988\n",
      "Epoch: 725/1000 Train loss: 0.20000775158405304 Train acc: 0.7551851868629456\n",
      "Epoch: 725/1000 Valid loss: 0.19110094010829926 Valid acc: 0.7555555701255798\n",
      "Epoch: 726/1000 Train loss: 0.1965922862291336 Train acc: 0.7564814686775208\n",
      "Epoch: 726/1000 Valid loss: 0.18905185163021088 Valid acc: 0.7583333849906921\n",
      "Epoch: 727/1000 Train loss: 0.19860826432704926 Train acc: 0.7514814734458923\n",
      "Epoch: 727/1000 Valid loss: 0.1912994533777237 Valid acc: 0.7572221755981445\n",
      "Epoch: 728/1000 Train loss: 0.20408593118190765 Train acc: 0.7557407021522522\n",
      "Epoch: 728/1000 Valid loss: 0.20483197271823883 Valid acc: 0.7516667246818542\n",
      "Epoch: 729/1000 Train loss: 0.20744898915290833 Train acc: 0.7559258937835693\n",
      "Epoch: 729/1000 Valid loss: 0.18573157489299774 Valid acc: 0.757777750492096\n",
      "Epoch: 730/1000 Train loss: 0.18440325558185577 Train acc: 0.7581481337547302\n",
      "Epoch: 730/1000 Valid loss: 0.17751716077327728 Valid acc: 0.7599999904632568\n",
      "Epoch: 731/1000 Train loss: 0.1715543121099472 Train acc: 0.7616665959358215\n",
      "Epoch: 731/1000 Valid loss: 0.17481523752212524 Valid acc: 0.7594444155693054\n",
      "Epoch: 732/1000 Train loss: 0.17060145735740662 Train acc: 0.761296272277832\n",
      "Epoch: 732/1000 Valid loss: 0.1767568588256836 Valid acc: 0.7594444155693054\n",
      "Epoch: 733/1000 Train loss: 0.17382657527923584 Train acc: 0.7574074268341064\n",
      "Epoch: 733/1000 Valid loss: 0.17711837589740753 Valid acc: 0.7611110806465149\n",
      "Epoch: 734/1000 Train loss: 0.17674221098423004 Train acc: 0.7592592835426331\n",
      "Epoch: 734/1000 Valid loss: 0.17814438045024872 Valid acc: 0.7594444155693054\n",
      "Epoch: 735/1000 Train loss: 0.18059797585010529 Train acc: 0.7594444751739502\n",
      "Epoch: 735/1000 Valid loss: 0.1784706860780716 Valid acc: 0.7572221755981445\n",
      "Epoch: 736/1000 Train loss: 0.18072248995304108 Train acc: 0.7596296072006226\n",
      "Epoch: 736/1000 Valid loss: 0.17804448306560516 Valid acc: 0.7588889002799988\n",
      "Epoch: 737/1000 Train loss: 0.17761051654815674 Train acc: 0.7605555057525635\n",
      "Epoch: 737/1000 Valid loss: 0.17549137771129608 Valid acc: 0.7583333849906921\n",
      "Epoch: 738/1000 Train loss: 0.1800554394721985 Train acc: 0.7609259486198425\n",
      "Epoch: 738/1000 Valid loss: 0.18217264115810394 Valid acc: 0.7566666603088379\n",
      "Epoch: 739/1000 Train loss: 0.1818239986896515 Train acc: 0.7574074268341064\n",
      "Epoch: 739/1000 Valid loss: 0.1778000146150589 Valid acc: 0.7588889002799988\n",
      "Epoch: 740/1000 Train loss: 0.1775798350572586 Train acc: 0.7592592835426331\n",
      "Epoch: 740/1000 Valid loss: 0.17541056871414185 Valid acc: 0.7594444155693054\n",
      "Epoch: 741/1000 Train loss: 0.166044682264328 Train acc: 0.7629629373550415\n",
      "Epoch: 741/1000 Valid loss: 0.1736549288034439 Valid acc: 0.7594444155693054\n",
      "Epoch: 742/1000 Train loss: 0.16637259721755981 Train acc: 0.7585185170173645\n",
      "Epoch: 742/1000 Valid loss: 0.1682133674621582 Valid acc: 0.7605555653572083\n",
      "Epoch: 743/1000 Train loss: 0.1677151918411255 Train acc: 0.7587037086486816\n",
      "Epoch: 743/1000 Valid loss: 0.17008864879608154 Valid acc: 0.7566666603088379\n",
      "Epoch: 744/1000 Train loss: 0.16947637498378754 Train acc: 0.7629629969596863\n",
      "Epoch: 744/1000 Valid loss: 0.16979794204235077 Valid acc: 0.7572221755981445\n",
      "Epoch: 745/1000 Train loss: 0.16635353863239288 Train acc: 0.7624074220657349\n",
      "Epoch: 745/1000 Valid loss: 0.16761839389801025 Valid acc: 0.7599999904632568\n",
      "Epoch: 746/1000 Train loss: 0.16545607149600983 Train acc: 0.7631481289863586\n",
      "Epoch: 746/1000 Valid loss: 0.1669936329126358 Valid acc: 0.7594444155693054\n",
      "Epoch: 747/1000 Train loss: 0.16679826378822327 Train acc: 0.7637036442756653\n",
      "Epoch: 747/1000 Valid loss: 0.16689814627170563 Valid acc: 0.7583333849906921\n",
      "Epoch: 748/1000 Train loss: 0.16701872646808624 Train acc: 0.7605555057525635\n",
      "Epoch: 748/1000 Valid loss: 0.1680973321199417 Valid acc: 0.7599999904632568\n",
      "Epoch: 749/1000 Train loss: 0.1677071899175644 Train acc: 0.7618518471717834\n",
      "Epoch: 749/1000 Valid loss: 0.172010138630867 Valid acc: 0.7588889002799988\n",
      "Epoch: 750/1000 Train loss: 0.16778308153152466 Train acc: 0.7642592191696167\n",
      "Epoch: 750/1000 Valid loss: 0.17689169943332672 Valid acc: 0.7594444155693054\n",
      "Epoch: 751/1000 Train loss: 0.16572658717632294 Train acc: 0.7642592787742615\n",
      "Epoch: 751/1000 Valid loss: 0.17037121951580048 Valid acc: 0.7599999904632568\n",
      "Epoch: 752/1000 Train loss: 0.16733498871326447 Train acc: 0.7620370388031006\n",
      "Epoch: 752/1000 Valid loss: 0.16836707293987274 Valid acc: 0.7605555653572083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 753/1000 Train loss: 0.16589045524597168 Train acc: 0.7629629969596863\n",
      "Epoch: 753/1000 Valid loss: 0.17287921905517578 Valid acc: 0.7594444155693054\n",
      "Epoch: 754/1000 Train loss: 0.17074531316757202 Train acc: 0.7624074220657349\n",
      "Epoch: 754/1000 Valid loss: 0.1735808104276657 Valid acc: 0.7583333849906921\n",
      "Epoch: 755/1000 Train loss: 0.17110970616340637 Train acc: 0.762592613697052\n",
      "Epoch: 755/1000 Valid loss: 0.16656307876110077 Valid acc: 0.7622222304344177\n",
      "Epoch: 756/1000 Train loss: 0.16071659326553345 Train acc: 0.761296272277832\n",
      "Epoch: 756/1000 Valid loss: 0.16156870126724243 Valid acc: 0.7605555653572083\n",
      "Epoch: 757/1000 Train loss: 0.15558625757694244 Train acc: 0.7648147940635681\n",
      "Epoch: 757/1000 Valid loss: 0.1618305742740631 Valid acc: 0.7605555653572083\n",
      "Epoch: 758/1000 Train loss: 0.15907156467437744 Train acc: 0.7618518471717834\n",
      "Epoch: 758/1000 Valid loss: 0.16063253581523895 Valid acc: 0.7616665959358215\n",
      "Epoch: 759/1000 Train loss: 0.15697436034679413 Train acc: 0.765740692615509\n",
      "Epoch: 759/1000 Valid loss: 0.15926973521709442 Valid acc: 0.7599999904632568\n",
      "Epoch: 760/1000 Train loss: 0.1575910747051239 Train acc: 0.7655555605888367\n",
      "Epoch: 760/1000 Valid loss: 0.1624523401260376 Valid acc: 0.7616665959358215\n",
      "Epoch: 761/1000 Train loss: 0.1633400171995163 Train acc: 0.7618519067764282\n",
      "Epoch: 761/1000 Valid loss: 0.1708592027425766 Valid acc: 0.7599999904632568\n",
      "Epoch: 762/1000 Train loss: 0.16988588869571686 Train acc: 0.7574074268341064\n",
      "Epoch: 762/1000 Valid loss: 0.16378776729106903 Valid acc: 0.7611110806465149\n",
      "Epoch: 763/1000 Train loss: 0.1707058697938919 Train acc: 0.7590740323066711\n",
      "Epoch: 763/1000 Valid loss: 0.1899290531873703 Valid acc: 0.7505555152893066\n",
      "Epoch: 764/1000 Train loss: 0.1666984111070633 Train acc: 0.761296272277832\n",
      "Epoch: 764/1000 Valid loss: 0.16360484063625336 Valid acc: 0.7611110806465149\n",
      "Epoch: 765/1000 Train loss: 0.16337956488132477 Train acc: 0.7581480741500854\n",
      "Epoch: 765/1000 Valid loss: 0.15733803808689117 Valid acc: 0.7616665959358215\n",
      "Epoch: 766/1000 Train loss: 0.16029757261276245 Train acc: 0.7583333253860474\n",
      "Epoch: 766/1000 Valid loss: 0.16263447701931 Valid acc: 0.753333330154419\n",
      "Epoch: 767/1000 Train loss: 0.15501536428928375 Train acc: 0.7640740871429443\n",
      "Epoch: 767/1000 Valid loss: 0.16095298528671265 Valid acc: 0.7627778053283691\n",
      "Epoch: 768/1000 Train loss: 0.15348128974437714 Train acc: 0.765925943851471\n",
      "Epoch: 768/1000 Valid loss: 0.15991102159023285 Valid acc: 0.7588889002799988\n",
      "Epoch: 769/1000 Train loss: 0.15609516203403473 Train acc: 0.7618518471717834\n",
      "Epoch: 769/1000 Valid loss: 0.1595194786787033 Valid acc: 0.7611110806465149\n",
      "Epoch: 770/1000 Train loss: 0.15376229584217072 Train acc: 0.764629602432251\n",
      "Epoch: 770/1000 Valid loss: 0.15605150163173676 Valid acc: 0.7633333206176758\n",
      "Epoch: 771/1000 Train loss: 0.15146584808826447 Train acc: 0.765740692615509\n",
      "Epoch: 771/1000 Valid loss: 0.15974460542201996 Valid acc: 0.7616665959358215\n",
      "Epoch: 772/1000 Train loss: 0.15687546133995056 Train acc: 0.7579629421234131\n",
      "Epoch: 772/1000 Valid loss: 0.15620554983615875 Valid acc: 0.7633333206176758\n",
      "Epoch: 773/1000 Train loss: 0.1519489884376526 Train acc: 0.7642592191696167\n",
      "Epoch: 773/1000 Valid loss: 0.15830682218074799 Valid acc: 0.7622222304344177\n",
      "Epoch: 774/1000 Train loss: 0.150838702917099 Train acc: 0.7653703689575195\n",
      "Epoch: 774/1000 Valid loss: 0.16336800158023834 Valid acc: 0.7588889002799988\n",
      "Epoch: 775/1000 Train loss: 0.15213239192962646 Train acc: 0.761481523513794\n",
      "Epoch: 775/1000 Valid loss: 0.15466554462909698 Valid acc: 0.7611110806465149\n",
      "Epoch: 776/1000 Train loss: 0.15064473450183868 Train acc: 0.76500004529953\n",
      "Epoch: 776/1000 Valid loss: 0.15541978180408478 Valid acc: 0.7622222304344177\n",
      "Epoch: 777/1000 Train loss: 0.14865006506443024 Train acc: 0.7668519020080566\n",
      "Epoch: 777/1000 Valid loss: 0.16023428738117218 Valid acc: 0.7588889002799988\n",
      "Epoch: 778/1000 Train loss: 0.15121613442897797 Train acc: 0.7629629373550415\n",
      "Epoch: 778/1000 Valid loss: 0.1540812999010086 Valid acc: 0.7622222304344177\n",
      "Epoch: 779/1000 Train loss: 0.14933747053146362 Train acc: 0.7644444704055786\n",
      "Epoch: 779/1000 Valid loss: 0.15566691756248474 Valid acc: 0.7605555653572083\n",
      "Epoch: 780/1000 Train loss: 0.14810989797115326 Train acc: 0.7668518424034119\n",
      "Epoch: 780/1000 Valid loss: 0.15687842667102814 Valid acc: 0.7605555653572083\n",
      "Epoch: 781/1000 Train loss: 0.1473463475704193 Train acc: 0.7657407522201538\n",
      "Epoch: 781/1000 Valid loss: 0.15268361568450928 Valid acc: 0.7633333206176758\n",
      "Epoch: 782/1000 Train loss: 0.1503829061985016 Train acc: 0.7648147940635681\n",
      "Epoch: 782/1000 Valid loss: 0.15930317342281342 Valid acc: 0.7622222304344177\n",
      "Epoch: 783/1000 Train loss: 0.15076801180839539 Train acc: 0.765925943851471\n",
      "Epoch: 783/1000 Valid loss: 0.16713951528072357 Valid acc: 0.7588889002799988\n",
      "Epoch: 784/1000 Train loss: 0.1541653722524643 Train acc: 0.7599999904632568\n",
      "Epoch: 784/1000 Valid loss: 0.16037416458129883 Valid acc: 0.754444420337677\n",
      "Epoch: 785/1000 Train loss: 0.1556466817855835 Train acc: 0.7572221755981445\n",
      "Epoch: 785/1000 Valid loss: 0.15708212554454803 Valid acc: 0.757777750492096\n",
      "Epoch: 786/1000 Train loss: 0.15116389095783234 Train acc: 0.7653703689575195\n",
      "Epoch: 786/1000 Valid loss: 0.1584954708814621 Valid acc: 0.7611110806465149\n",
      "Epoch: 787/1000 Train loss: 0.15025371313095093 Train acc: 0.7648147940635681\n",
      "Epoch: 787/1000 Valid loss: 0.15351653099060059 Valid acc: 0.7616665959358215\n",
      "Epoch: 788/1000 Train loss: 0.14606806635856628 Train acc: 0.7675926685333252\n",
      "Epoch: 788/1000 Valid loss: 0.154424250125885 Valid acc: 0.7622222304344177\n",
      "Epoch: 789/1000 Train loss: 0.1492292881011963 Train acc: 0.7648147940635681\n",
      "Epoch: 789/1000 Valid loss: 0.14975707232952118 Valid acc: 0.7627778053283691\n",
      "Epoch: 790/1000 Train loss: 0.14433258771896362 Train acc: 0.7664814591407776\n",
      "Epoch: 790/1000 Valid loss: 0.15022720396518707 Valid acc: 0.7622222304344177\n",
      "Epoch: 791/1000 Train loss: 0.1437734067440033 Train acc: 0.7657407522201538\n",
      "Epoch: 791/1000 Valid loss: 0.15007437765598297 Valid acc: 0.7622222304344177\n",
      "Epoch: 792/1000 Train loss: 0.1422480046749115 Train acc: 0.7668518424034119\n",
      "Epoch: 792/1000 Valid loss: 0.15236131846904755 Valid acc: 0.7622222304344177\n",
      "Epoch: 793/1000 Train loss: 0.14268584549427032 Train acc: 0.7679629325866699\n",
      "Epoch: 793/1000 Valid loss: 0.15265467762947083 Valid acc: 0.7627778053283691\n",
      "Epoch: 794/1000 Train loss: 0.1435934454202652 Train acc: 0.767037034034729\n",
      "Epoch: 794/1000 Valid loss: 0.15611931681632996 Valid acc: 0.7583333849906921\n",
      "Epoch: 795/1000 Train loss: 0.14792901277542114 Train acc: 0.7640740871429443\n",
      "Epoch: 795/1000 Valid loss: 0.1546168476343155 Valid acc: 0.7555555701255798\n",
      "Epoch: 796/1000 Train loss: 0.14593106508255005 Train acc: 0.7627777457237244\n",
      "Epoch: 796/1000 Valid loss: 0.15609751641750336 Valid acc: 0.7566666603088379\n",
      "Epoch: 797/1000 Train loss: 0.14318326115608215 Train acc: 0.7666666507720947\n",
      "Epoch: 797/1000 Valid loss: 0.1562720686197281 Valid acc: 0.7622222304344177\n",
      "Epoch: 798/1000 Train loss: 0.14253245294094086 Train acc: 0.7672221660614014\n",
      "Epoch: 798/1000 Valid loss: 0.15462879836559296 Valid acc: 0.7627778053283691\n",
      "Epoch: 799/1000 Train loss: 0.18726962804794312 Train acc: 0.756481409072876\n",
      "Epoch: 799/1000 Valid loss: 0.5743200182914734 Valid acc: 0.6722221970558167\n",
      "Epoch: 800/1000 Train loss: 0.6444157958030701 Train acc: 0.6538888812065125\n",
      "Epoch: 800/1000 Valid loss: 0.3596367835998535 Valid acc: 0.7127777934074402\n",
      "Epoch: 801/1000 Train loss: 0.39553162455558777 Train acc: 0.7022221684455872\n",
      "Epoch: 801/1000 Valid loss: 0.3857487142086029 Valid acc: 0.7111110687255859\n",
      "Epoch: 802/1000 Train loss: 0.41022124886512756 Train acc: 0.7001851201057434\n",
      "Epoch: 802/1000 Valid loss: 0.4195619523525238 Valid acc: 0.6716666221618652\n",
      "Epoch: 803/1000 Train loss: 0.4251203238964081 Train acc: 0.6575925350189209\n",
      "Epoch: 803/1000 Valid loss: 0.4019516408443451 Valid acc: 0.6594444513320923\n",
      "Epoch: 804/1000 Train loss: 0.3872876763343811 Train acc: 0.6501851677894592\n",
      "Epoch: 804/1000 Valid loss: 0.3709094524383545 Valid acc: 0.6511110663414001\n",
      "Epoch: 805/1000 Train loss: 0.4607176184654236 Train acc: 0.6279629468917847\n",
      "Epoch: 805/1000 Valid loss: 0.41335687041282654 Valid acc: 0.6349999904632568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 806/1000 Train loss: 0.4896481931209564 Train acc: 0.613703727722168\n",
      "Epoch: 806/1000 Valid loss: 0.3725484311580658 Valid acc: 0.6538888812065125\n",
      "Epoch: 807/1000 Train loss: 0.5032153129577637 Train acc: 0.6135185360908508\n",
      "Epoch: 807/1000 Valid loss: 0.40095949172973633 Valid acc: 0.6505555510520935\n",
      "Epoch: 808/1000 Train loss: 0.521941065788269 Train acc: 0.601111114025116\n",
      "Epoch: 808/1000 Valid loss: 0.4042418897151947 Valid acc: 0.6388888955116272\n",
      "Epoch: 809/1000 Train loss: 0.5086212158203125 Train acc: 0.604259192943573\n",
      "Epoch: 809/1000 Valid loss: 0.374026894569397 Valid acc: 0.6572222113609314\n",
      "Epoch: 810/1000 Train loss: 0.48952925205230713 Train acc: 0.6174074411392212\n",
      "Epoch: 810/1000 Valid loss: 0.35815557837486267 Valid acc: 0.6688888669013977\n",
      "Epoch: 811/1000 Train loss: 0.4172666072845459 Train acc: 0.6520370841026306\n",
      "Epoch: 811/1000 Valid loss: 0.32767125964164734 Valid acc: 0.6833333373069763\n",
      "Epoch: 812/1000 Train loss: 0.36286771297454834 Train acc: 0.6718518733978271\n",
      "Epoch: 812/1000 Valid loss: 0.3056579530239105 Valid acc: 0.6916666626930237\n",
      "Epoch: 813/1000 Train loss: 0.33269229531288147 Train acc: 0.688703715801239\n",
      "Epoch: 813/1000 Valid loss: 0.29894208908081055 Valid acc: 0.7033333778381348\n",
      "Epoch: 814/1000 Train loss: 0.32002460956573486 Train acc: 0.6988889575004578\n",
      "Epoch: 814/1000 Valid loss: 0.2924330234527588 Valid acc: 0.7022221684455872\n",
      "Epoch: 815/1000 Train loss: 0.31074562668800354 Train acc: 0.7027777433395386\n",
      "Epoch: 815/1000 Valid loss: 0.28495287895202637 Valid acc: 0.7161111235618591\n",
      "Epoch: 816/1000 Train loss: 0.31752336025238037 Train acc: 0.7137037515640259\n",
      "Epoch: 816/1000 Valid loss: 0.28963136672973633 Valid acc: 0.7166666984558105\n",
      "Epoch: 817/1000 Train loss: 0.3099851906299591 Train acc: 0.7122222185134888\n",
      "Epoch: 817/1000 Valid loss: 0.2723415195941925 Valid acc: 0.7183333039283752\n",
      "Epoch: 818/1000 Train loss: 0.2888125479221344 Train acc: 0.707037091255188\n",
      "Epoch: 818/1000 Valid loss: 0.25598734617233276 Valid acc: 0.7166666388511658\n",
      "Epoch: 819/1000 Train loss: 0.2933013439178467 Train acc: 0.7118518352508545\n",
      "Epoch: 819/1000 Valid loss: 0.26442673802375793 Valid acc: 0.722777783870697\n",
      "Epoch: 820/1000 Train loss: 0.290378212928772 Train acc: 0.7150000333786011\n",
      "Epoch: 820/1000 Valid loss: 0.25935354828834534 Valid acc: 0.7149999737739563\n",
      "Epoch: 821/1000 Train loss: 0.27429816126823425 Train acc: 0.7122222185134888\n",
      "Epoch: 821/1000 Valid loss: 0.2550508975982666 Valid acc: 0.7061111330986023\n",
      "Epoch: 822/1000 Train loss: 0.28171125054359436 Train acc: 0.699999988079071\n",
      "Epoch: 822/1000 Valid loss: 0.25378474593162537 Valid acc: 0.7083333134651184\n",
      "Epoch: 823/1000 Train loss: 0.2760829031467438 Train acc: 0.7042592167854309\n",
      "Epoch: 823/1000 Valid loss: 0.2468550205230713 Valid acc: 0.7188888192176819\n",
      "Epoch: 824/1000 Train loss: 0.26821109652519226 Train acc: 0.7138888835906982\n",
      "Epoch: 824/1000 Valid loss: 0.2337377667427063 Valid acc: 0.7238888740539551\n",
      "Epoch: 825/1000 Train loss: 0.2634871304035187 Train acc: 0.7174074649810791\n",
      "Epoch: 825/1000 Valid loss: 0.2314084768295288 Valid acc: 0.7238888740539551\n",
      "Epoch: 826/1000 Train loss: 0.2613328993320465 Train acc: 0.714629590511322\n",
      "Epoch: 826/1000 Valid loss: 0.23437778651714325 Valid acc: 0.7205555438995361\n",
      "Epoch: 827/1000 Train loss: 0.26145225763320923 Train acc: 0.7166666388511658\n",
      "Epoch: 827/1000 Valid loss: 0.25141122937202454 Valid acc: 0.7216666340827942\n",
      "Epoch: 828/1000 Train loss: 0.2732955515384674 Train acc: 0.7187036871910095\n",
      "Epoch: 828/1000 Valid loss: 0.24600045382976532 Valid acc: 0.7233332991600037\n",
      "Epoch: 829/1000 Train loss: 0.27259892225265503 Train acc: 0.7155555486679077\n",
      "Epoch: 829/1000 Valid loss: 0.24588638544082642 Valid acc: 0.7149999737739563\n",
      "Epoch: 830/1000 Train loss: 0.2645215690135956 Train acc: 0.7133333683013916\n",
      "Epoch: 830/1000 Valid loss: 0.22911816835403442 Valid acc: 0.7166666984558105\n",
      "Epoch: 831/1000 Train loss: 0.26324042677879333 Train acc: 0.7111111283302307\n",
      "Epoch: 831/1000 Valid loss: 0.2516744136810303 Valid acc: 0.7027778029441833\n",
      "Epoch: 832/1000 Train loss: 0.2721019387245178 Train acc: 0.7001851797103882\n",
      "Epoch: 832/1000 Valid loss: 0.24759197235107422 Valid acc: 0.7161111235618591\n",
      "Epoch: 833/1000 Train loss: 0.26961421966552734 Train acc: 0.7085185050964355\n",
      "Epoch: 833/1000 Valid loss: 0.2416217178106308 Valid acc: 0.7144444584846497\n",
      "Epoch: 834/1000 Train loss: 0.26376405358314514 Train acc: 0.7098147869110107\n",
      "Epoch: 834/1000 Valid loss: 0.23782461881637573 Valid acc: 0.7144443988800049\n",
      "Epoch: 835/1000 Train loss: 0.27154287695884705 Train acc: 0.708148181438446\n",
      "Epoch: 835/1000 Valid loss: 0.23859572410583496 Valid acc: 0.7166666984558105\n",
      "Epoch: 836/1000 Train loss: 0.2777080535888672 Train acc: 0.7055555582046509\n",
      "Epoch: 836/1000 Valid loss: 0.2327471822500229 Valid acc: 0.7172222137451172\n",
      "Epoch: 837/1000 Train loss: 0.2648831009864807 Train acc: 0.7118518352508545\n",
      "Epoch: 837/1000 Valid loss: 0.2285260409116745 Valid acc: 0.7249999642372131\n",
      "Epoch: 838/1000 Train loss: 0.262606680393219 Train acc: 0.7172222137451172\n",
      "Epoch: 838/1000 Valid loss: 0.22653190791606903 Valid acc: 0.7222222685813904\n",
      "Epoch: 839/1000 Train loss: 0.2670515179634094 Train acc: 0.7140741348266602\n",
      "Epoch: 839/1000 Valid loss: 0.24041561782360077 Valid acc: 0.7177777290344238\n",
      "Epoch: 840/1000 Train loss: 0.2706342339515686 Train acc: 0.7161111235618591\n",
      "Epoch: 840/1000 Valid loss: 0.25766733288764954 Valid acc: 0.7233333587646484\n",
      "Epoch: 841/1000 Train loss: 0.2940555810928345 Train acc: 0.7064815163612366\n",
      "Epoch: 841/1000 Valid loss: 0.25689932703971863 Valid acc: 0.7100000381469727\n",
      "Epoch: 842/1000 Train loss: 0.3177763819694519 Train acc: 0.6905555725097656\n",
      "Epoch: 842/1000 Valid loss: 0.2597220242023468 Valid acc: 0.7116666436195374\n",
      "Epoch: 843/1000 Train loss: 0.2884708642959595 Train acc: 0.7037036418914795\n",
      "Epoch: 843/1000 Valid loss: 0.24217207729816437 Valid acc: 0.7211111187934875\n",
      "Epoch: 844/1000 Train loss: 0.2697478234767914 Train acc: 0.7135184407234192\n",
      "Epoch: 844/1000 Valid loss: 0.22615723311901093 Valid acc: 0.7177777290344238\n",
      "Epoch: 845/1000 Train loss: 0.2609844505786896 Train acc: 0.7131481766700745\n",
      "Epoch: 845/1000 Valid loss: 0.22147595882415771 Valid acc: 0.7222222685813904\n",
      "Epoch: 846/1000 Train loss: 0.25423961877822876 Train acc: 0.7153703570365906\n",
      "Epoch: 846/1000 Valid loss: 0.22058890759944916 Valid acc: 0.722777783870697\n",
      "Epoch: 847/1000 Train loss: 0.25726574659347534 Train acc: 0.7140740752220154\n",
      "Epoch: 847/1000 Valid loss: 0.21822039783000946 Valid acc: 0.7188888192176819\n",
      "Epoch: 848/1000 Train loss: 0.2526416480541229 Train acc: 0.7174074649810791\n",
      "Epoch: 848/1000 Valid loss: 0.22133110463619232 Valid acc: 0.7255555987358093\n",
      "Epoch: 849/1000 Train loss: 0.24226967990398407 Train acc: 0.7207407355308533\n",
      "Epoch: 849/1000 Valid loss: 0.2175309658050537 Valid acc: 0.7238888740539551\n",
      "Epoch: 850/1000 Train loss: 0.1938495635986328 Train acc: 0.743148148059845\n",
      "Epoch: 850/1000 Valid loss: 0.17407917976379395 Valid acc: 0.745555579662323\n",
      "Epoch: 851/1000 Train loss: 0.17695710062980652 Train acc: 0.7518518567085266\n",
      "Epoch: 851/1000 Valid loss: 0.1783704310655594 Valid acc: 0.742222249507904\n",
      "Epoch: 852/1000 Train loss: 0.22799403965473175 Train acc: 0.7316666841506958\n",
      "Epoch: 852/1000 Valid loss: 0.2742851972579956 Valid acc: 0.707777738571167\n",
      "Epoch: 853/1000 Train loss: 0.3061660826206207 Train acc: 0.7025926113128662\n",
      "Epoch: 853/1000 Valid loss: 0.2461996078491211 Valid acc: 0.7216666340827942\n",
      "Epoch: 854/1000 Train loss: 0.3300515413284302 Train acc: 0.7020370364189148\n",
      "Epoch: 854/1000 Valid loss: 0.3450484275817871 Valid acc: 0.6938889026641846\n",
      "Epoch: 855/1000 Train loss: 0.5575526356697083 Train acc: 0.614814817905426\n",
      "Epoch: 855/1000 Valid loss: 0.39680981636047363 Valid acc: 0.6733333468437195\n",
      "Epoch: 856/1000 Train loss: 0.644327700138092 Train acc: 0.5692592859268188\n",
      "Epoch: 856/1000 Valid loss: 0.38522568345069885 Valid acc: 0.6649999618530273\n",
      "Epoch: 857/1000 Train loss: 0.6308972835540771 Train acc: 0.5562963485717773\n",
      "Epoch: 857/1000 Valid loss: 0.36706557869911194 Valid acc: 0.6616666316986084\n",
      "Epoch: 858/1000 Train loss: 0.6425778865814209 Train acc: 0.5562962889671326\n",
      "Epoch: 858/1000 Valid loss: 0.3648078739643097 Valid acc: 0.6738888621330261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 859/1000 Train loss: 0.607643187046051 Train acc: 0.570555567741394\n",
      "Epoch: 859/1000 Valid loss: 0.3577791154384613 Valid acc: 0.6700000166893005\n",
      "Epoch: 860/1000 Train loss: 0.5372017621994019 Train acc: 0.5948148369789124\n",
      "Epoch: 860/1000 Valid loss: 0.3066484034061432 Valid acc: 0.694444477558136\n",
      "Epoch: 861/1000 Train loss: 0.34916117787361145 Train acc: 0.6837036609649658\n",
      "Epoch: 861/1000 Valid loss: 0.26862862706184387 Valid acc: 0.708888828754425\n",
      "Epoch: 862/1000 Train loss: 0.32407715916633606 Train acc: 0.6935184597969055\n",
      "Epoch: 862/1000 Valid loss: 0.25875720381736755 Valid acc: 0.7099999785423279\n",
      "Epoch: 863/1000 Train loss: 0.32756394147872925 Train acc: 0.6874074339866638\n",
      "Epoch: 863/1000 Valid loss: 0.2722291052341461 Valid acc: 0.7088889479637146\n",
      "Epoch: 864/1000 Train loss: 0.3243650197982788 Train acc: 0.6879629492759705\n",
      "Epoch: 864/1000 Valid loss: 0.25012871623039246 Valid acc: 0.7122222781181335\n",
      "Epoch: 865/1000 Train loss: 0.2901071310043335 Train acc: 0.7022222280502319\n",
      "Epoch: 865/1000 Valid loss: 0.23722590506076813 Valid acc: 0.7200000286102295\n",
      "Epoch: 866/1000 Train loss: 0.27682748436927795 Train acc: 0.7079629898071289\n",
      "Epoch: 866/1000 Valid loss: 0.226466104388237 Valid acc: 0.7211110591888428\n",
      "Epoch: 867/1000 Train loss: 0.27356722950935364 Train acc: 0.7087036967277527\n",
      "Epoch: 867/1000 Valid loss: 0.22301208972930908 Valid acc: 0.7222222685813904\n",
      "Epoch: 868/1000 Train loss: 0.2666894495487213 Train acc: 0.712592601776123\n",
      "Epoch: 868/1000 Valid loss: 0.22365696728229523 Valid acc: 0.7238888740539551\n",
      "Epoch: 869/1000 Train loss: 0.26435744762420654 Train acc: 0.7114814519882202\n",
      "Epoch: 869/1000 Valid loss: 0.2199995517730713 Valid acc: 0.7216666340827942\n",
      "Epoch: 870/1000 Train loss: 0.26707541942596436 Train acc: 0.7088888883590698\n",
      "Epoch: 870/1000 Valid loss: 0.22091273963451385 Valid acc: 0.7211110591888428\n",
      "Epoch: 871/1000 Train loss: 0.2646836042404175 Train acc: 0.7109259366989136\n",
      "Epoch: 871/1000 Valid loss: 0.2190995216369629 Valid acc: 0.7205555438995361\n",
      "Epoch: 872/1000 Train loss: 0.26532799005508423 Train acc: 0.7098147869110107\n",
      "Epoch: 872/1000 Valid loss: 0.2186547964811325 Valid acc: 0.7200000286102295\n",
      "Epoch: 873/1000 Train loss: 0.26157495379447937 Train acc: 0.7127777934074402\n",
      "Epoch: 873/1000 Valid loss: 0.21641850471496582 Valid acc: 0.7233333587646484\n",
      "Epoch: 874/1000 Train loss: 0.2586568593978882 Train acc: 0.7135184407234192\n",
      "Epoch: 874/1000 Valid loss: 0.21466092765331268 Valid acc: 0.7222222685813904\n",
      "Epoch: 875/1000 Train loss: 0.2528127133846283 Train acc: 0.7153703570365906\n",
      "Epoch: 875/1000 Valid loss: 0.21150772273540497 Valid acc: 0.7244444489479065\n",
      "Epoch: 876/1000 Train loss: 0.2539862394332886 Train acc: 0.7148147821426392\n",
      "Epoch: 876/1000 Valid loss: 0.21720926463603973 Valid acc: 0.7222221493721008\n",
      "Epoch: 877/1000 Train loss: 0.26920944452285767 Train acc: 0.7066666483879089\n",
      "Epoch: 877/1000 Valid loss: 0.22889156639575958 Valid acc: 0.7149999737739563\n",
      "Epoch: 878/1000 Train loss: 0.260701060295105 Train acc: 0.7111111283302307\n",
      "Epoch: 878/1000 Valid loss: 0.21216554939746857 Valid acc: 0.7249999642372131\n",
      "Epoch: 879/1000 Train loss: 0.2422526478767395 Train acc: 0.7188888788223267\n",
      "Epoch: 879/1000 Valid loss: 0.21527647972106934 Valid acc: 0.7249999642372131\n",
      "Epoch: 880/1000 Train loss: 0.2405347228050232 Train acc: 0.7200000286102295\n",
      "Epoch: 880/1000 Valid loss: 0.21065987646579742 Valid acc: 0.7244444489479065\n",
      "Epoch: 881/1000 Train loss: 0.23989656567573547 Train acc: 0.719074010848999\n",
      "Epoch: 881/1000 Valid loss: 0.20812998712062836 Valid acc: 0.7244443893432617\n",
      "Epoch: 882/1000 Train loss: 0.2382906824350357 Train acc: 0.7199999690055847\n",
      "Epoch: 882/1000 Valid loss: 0.20920167863368988 Valid acc: 0.726111114025116\n",
      "Epoch: 883/1000 Train loss: 0.23820172250270844 Train acc: 0.7196296453475952\n",
      "Epoch: 883/1000 Valid loss: 0.21054072678089142 Valid acc: 0.722777783870697\n",
      "Epoch: 884/1000 Train loss: 0.23774297535419464 Train acc: 0.7192592620849609\n",
      "Epoch: 884/1000 Valid loss: 0.21089839935302734 Valid acc: 0.7255555987358093\n",
      "Epoch: 885/1000 Train loss: 0.23711834847927094 Train acc: 0.7192592620849609\n",
      "Epoch: 885/1000 Valid loss: 0.20689530670642853 Valid acc: 0.7222221493721008\n",
      "Epoch: 886/1000 Train loss: 0.239325150847435 Train acc: 0.7188889384269714\n",
      "Epoch: 886/1000 Valid loss: 0.20528900623321533 Valid acc: 0.7277777791023254\n",
      "Epoch: 887/1000 Train loss: 0.23818212747573853 Train acc: 0.7212963104248047\n",
      "Epoch: 887/1000 Valid loss: 0.20501263439655304 Valid acc: 0.7288889288902283\n",
      "Epoch: 888/1000 Train loss: 0.2370162010192871 Train acc: 0.7209259867668152\n",
      "Epoch: 888/1000 Valid loss: 0.20408116281032562 Valid acc: 0.7311111092567444\n",
      "Epoch: 889/1000 Train loss: 0.23678486049175262 Train acc: 0.7216666340827942\n",
      "Epoch: 889/1000 Valid loss: 0.20529763400554657 Valid acc: 0.7288889288902283\n",
      "Epoch: 890/1000 Train loss: 0.23637087643146515 Train acc: 0.7222222089767456\n",
      "Epoch: 890/1000 Valid loss: 0.20386378467082977 Valid acc: 0.7327777743339539\n",
      "Epoch: 891/1000 Train loss: 0.23521624505519867 Train acc: 0.7242592573165894\n",
      "Epoch: 891/1000 Valid loss: 0.20867282152175903 Valid acc: 0.7294444441795349\n",
      "Epoch: 892/1000 Train loss: 0.24292922019958496 Train acc: 0.7188888788223267\n",
      "Epoch: 892/1000 Valid loss: 0.24224670231342316 Valid acc: 0.722777783870697\n",
      "Epoch: 893/1000 Train loss: 0.26474159955978394 Train acc: 0.7279629707336426\n",
      "Epoch: 893/1000 Valid loss: 0.2250930517911911 Valid acc: 0.7438888549804688\n",
      "Epoch: 894/1000 Train loss: 0.24761363863945007 Train acc: 0.7481482028961182\n",
      "Epoch: 894/1000 Valid loss: 0.20805753767490387 Valid acc: 0.7416666150093079\n",
      "Epoch: 895/1000 Train loss: 0.24076366424560547 Train acc: 0.7438889145851135\n",
      "Epoch: 895/1000 Valid loss: 0.20514976978302002 Valid acc: 0.7372221946716309\n",
      "Epoch: 896/1000 Train loss: 0.23457013070583344 Train acc: 0.7364814281463623\n",
      "Epoch: 896/1000 Valid loss: 0.20514261722564697 Valid acc: 0.7327777743339539\n",
      "Epoch: 897/1000 Train loss: 0.23231808841228485 Train acc: 0.7307407855987549\n",
      "Epoch: 897/1000 Valid loss: 0.20394444465637207 Valid acc: 0.7266666889190674\n",
      "Epoch: 898/1000 Train loss: 0.23673921823501587 Train acc: 0.7257406711578369\n",
      "Epoch: 898/1000 Valid loss: 0.2086430788040161 Valid acc: 0.7249999642372131\n",
      "Epoch: 899/1000 Train loss: 0.23616372048854828 Train acc: 0.7224074006080627\n",
      "Epoch: 899/1000 Valid loss: 0.20960797369480133 Valid acc: 0.7266666889190674\n",
      "Epoch: 900/1000 Train loss: 0.23758186399936676 Train acc: 0.7222222089767456\n",
      "Epoch: 900/1000 Valid loss: 0.21124960482120514 Valid acc: 0.731666624546051\n",
      "Epoch: 901/1000 Train loss: 0.23848533630371094 Train acc: 0.7237036824226379\n",
      "Epoch: 901/1000 Valid loss: 0.21259646117687225 Valid acc: 0.727222204208374\n",
      "Epoch: 902/1000 Train loss: 0.23397085070610046 Train acc: 0.7244445085525513\n",
      "Epoch: 902/1000 Valid loss: 0.20231132209300995 Valid acc: 0.7366666793823242\n",
      "Epoch: 903/1000 Train loss: 0.23049429059028625 Train acc: 0.7270370125770569\n",
      "Epoch: 903/1000 Valid loss: 0.2030794769525528 Valid acc: 0.7344444394111633\n",
      "Epoch: 904/1000 Train loss: 0.23063400387763977 Train acc: 0.7268518209457397\n",
      "Epoch: 904/1000 Valid loss: 0.20725993812084198 Valid acc: 0.7394444346427917\n",
      "Epoch: 905/1000 Train loss: 0.22901058197021484 Train acc: 0.7281481623649597\n",
      "Epoch: 905/1000 Valid loss: 0.20120370388031006 Valid acc: 0.7372221946716309\n",
      "Epoch: 906/1000 Train loss: 0.22863012552261353 Train acc: 0.7270370721817017\n",
      "Epoch: 906/1000 Valid loss: 0.20164866745471954 Valid acc: 0.7361111044883728\n",
      "Epoch: 907/1000 Train loss: 0.22842830419540405 Train acc: 0.7277777194976807\n",
      "Epoch: 907/1000 Valid loss: 0.2039089947938919 Valid acc: 0.73499995470047\n",
      "Epoch: 908/1000 Train loss: 0.22724570333957672 Train acc: 0.727222204208374\n",
      "Epoch: 908/1000 Valid loss: 0.20068101584911346 Valid acc: 0.7322222590446472\n",
      "Epoch: 909/1000 Train loss: 0.22740711271762848 Train acc: 0.7262962460517883\n",
      "Epoch: 909/1000 Valid loss: 0.19738002121448517 Valid acc: 0.7372221946716309\n",
      "Epoch: 910/1000 Train loss: 0.2277112603187561 Train acc: 0.7268518805503845\n",
      "Epoch: 910/1000 Valid loss: 0.2017107456922531 Valid acc: 0.7311111092567444\n",
      "Epoch: 911/1000 Train loss: 0.22966411709785461 Train acc: 0.7229629755020142\n",
      "Epoch: 911/1000 Valid loss: 0.2006831169128418 Valid acc: 0.73499995470047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 912/1000 Train loss: 0.22725582122802734 Train acc: 0.7262963056564331\n",
      "Epoch: 912/1000 Valid loss: 0.19909392297267914 Valid acc: 0.730555534362793\n",
      "Epoch: 913/1000 Train loss: 0.22625930607318878 Train acc: 0.7246296405792236\n",
      "Epoch: 913/1000 Valid loss: 0.20102627575397491 Valid acc: 0.731666624546051\n",
      "Epoch: 914/1000 Train loss: 0.2267981320619583 Train acc: 0.7268518805503845\n",
      "Epoch: 914/1000 Valid loss: 0.19979526102542877 Valid acc: 0.7377777695655823\n",
      "Epoch: 915/1000 Train loss: 0.2260264754295349 Train acc: 0.7244444489479065\n",
      "Epoch: 915/1000 Valid loss: 0.19982945919036865 Valid acc: 0.7238888740539551\n",
      "Epoch: 916/1000 Train loss: 0.22645919024944305 Train acc: 0.7238889336585999\n",
      "Epoch: 916/1000 Valid loss: 0.20061051845550537 Valid acc: 0.7372221946716309\n",
      "Epoch: 917/1000 Train loss: 0.22497953474521637 Train acc: 0.7268518805503845\n",
      "Epoch: 917/1000 Valid loss: 0.2010573148727417 Valid acc: 0.7288889288902283\n",
      "Epoch: 918/1000 Train loss: 0.2251555621623993 Train acc: 0.7259259223937988\n",
      "Epoch: 918/1000 Valid loss: 0.20166511833667755 Valid acc: 0.7327777743339539\n",
      "Epoch: 919/1000 Train loss: 0.2250107079744339 Train acc: 0.7259259223937988\n",
      "Epoch: 919/1000 Valid loss: 0.1992630511522293 Valid acc: 0.7366666793823242\n",
      "Epoch: 920/1000 Train loss: 0.22470147907733917 Train acc: 0.7277777791023254\n",
      "Epoch: 920/1000 Valid loss: 0.20110519230365753 Valid acc: 0.731666624546051\n",
      "Epoch: 921/1000 Train loss: 0.22432512044906616 Train acc: 0.7261111736297607\n",
      "Epoch: 921/1000 Valid loss: 0.20155425369739532 Valid acc: 0.7322222590446472\n",
      "Epoch: 922/1000 Train loss: 0.22522933781147003 Train acc: 0.7253703474998474\n",
      "Epoch: 922/1000 Valid loss: 0.20114846527576447 Valid acc: 0.7344444394111633\n",
      "Epoch: 923/1000 Train loss: 0.22556202113628387 Train acc: 0.7287037372589111\n",
      "Epoch: 923/1000 Valid loss: 0.196843221783638 Valid acc: 0.7366666793823242\n",
      "Epoch: 924/1000 Train loss: 0.22522391378879547 Train acc: 0.7251851558685303\n",
      "Epoch: 924/1000 Valid loss: 0.20082242786884308 Valid acc: 0.7238888740539551\n",
      "Epoch: 925/1000 Train loss: 0.22488301992416382 Train acc: 0.7248148322105408\n",
      "Epoch: 925/1000 Valid loss: 0.1994336098432541 Valid acc: 0.7361111044883728\n",
      "Epoch: 926/1000 Train loss: 0.2234857827425003 Train acc: 0.7266666889190674\n",
      "Epoch: 926/1000 Valid loss: 0.2009574919939041 Valid acc: 0.7283332943916321\n",
      "Epoch: 927/1000 Train loss: 0.22387398779392242 Train acc: 0.726111114025116\n",
      "Epoch: 927/1000 Valid loss: 0.20249266922473907 Valid acc: 0.7355555891990662\n",
      "Epoch: 928/1000 Train loss: 0.2236732691526413 Train acc: 0.726111114025116\n",
      "Epoch: 928/1000 Valid loss: 0.20005814731121063 Valid acc: 0.7327777743339539\n",
      "Epoch: 929/1000 Train loss: 0.2234017550945282 Train acc: 0.7301852107048035\n",
      "Epoch: 929/1000 Valid loss: 0.19812969863414764 Valid acc: 0.7450000643730164\n",
      "Epoch: 930/1000 Train loss: 0.22105975449085236 Train acc: 0.7505555748939514\n",
      "Epoch: 930/1000 Valid loss: 0.19515816867351532 Valid acc: 0.7555555701255798\n",
      "Epoch: 931/1000 Train loss: 0.22111356258392334 Train acc: 0.754444420337677\n",
      "Epoch: 931/1000 Valid loss: 0.19310426712036133 Valid acc: 0.7566666603088379\n",
      "Epoch: 932/1000 Train loss: 0.22216655313968658 Train acc: 0.7481481432914734\n",
      "Epoch: 932/1000 Valid loss: 0.1974082738161087 Valid acc: 0.7383334040641785\n",
      "Epoch: 933/1000 Train loss: 0.23003584146499634 Train acc: 0.7300000190734863\n",
      "Epoch: 933/1000 Valid loss: 0.20518849790096283 Valid acc: 0.73499995470047\n",
      "Epoch: 934/1000 Train loss: 0.2335788458585739 Train acc: 0.7264814376831055\n",
      "Epoch: 934/1000 Valid loss: 0.20589663088321686 Valid acc: 0.7355555891990662\n",
      "Epoch: 935/1000 Train loss: 0.23308870196342468 Train acc: 0.727222204208374\n",
      "Epoch: 935/1000 Valid loss: 0.20530086755752563 Valid acc: 0.7377777695655823\n",
      "Epoch: 936/1000 Train loss: 0.22771303355693817 Train acc: 0.7292592525482178\n",
      "Epoch: 936/1000 Valid loss: 0.20283858478069305 Valid acc: 0.7394444346427917\n",
      "Epoch: 937/1000 Train loss: 0.22595936059951782 Train acc: 0.7301852107048035\n",
      "Epoch: 937/1000 Valid loss: 0.2011318951845169 Valid acc: 0.7405555248260498\n",
      "Epoch: 938/1000 Train loss: 0.22506608068943024 Train acc: 0.7290740609169006\n",
      "Epoch: 938/1000 Valid loss: 0.20225213468074799 Valid acc: 0.7388889193534851\n",
      "Epoch: 939/1000 Train loss: 0.2254195213317871 Train acc: 0.7438889145851135\n",
      "Epoch: 939/1000 Valid loss: 0.19807958602905273 Valid acc: 0.7511110901832581\n",
      "Epoch: 940/1000 Train loss: 0.22397677600383759 Train acc: 0.7511111497879028\n",
      "Epoch: 940/1000 Valid loss: 0.19707955420017242 Valid acc: 0.7516667246818542\n",
      "Epoch: 941/1000 Train loss: 0.22408658266067505 Train acc: 0.752036988735199\n",
      "Epoch: 941/1000 Valid loss: 0.19515590369701385 Valid acc: 0.7483332753181458\n",
      "Epoch: 942/1000 Train loss: 0.2229626476764679 Train acc: 0.7468518018722534\n",
      "Epoch: 942/1000 Valid loss: 0.192657932639122 Valid acc: 0.7488889098167419\n",
      "Epoch: 943/1000 Train loss: 0.22495728731155396 Train acc: 0.7409259080886841\n",
      "Epoch: 943/1000 Valid loss: 0.19562770426273346 Valid acc: 0.7427778244018555\n",
      "Epoch: 944/1000 Train loss: 0.2327500432729721 Train acc: 0.7396296262741089\n",
      "Epoch: 944/1000 Valid loss: 0.1985033005475998 Valid acc: 0.7483332753181458\n",
      "Epoch: 945/1000 Train loss: 0.22410529851913452 Train acc: 0.7427778244018555\n",
      "Epoch: 945/1000 Valid loss: 0.19222302734851837 Valid acc: 0.7505555152893066\n",
      "Epoch: 946/1000 Train loss: 0.20382873713970184 Train acc: 0.7575926184654236\n",
      "Epoch: 946/1000 Valid loss: 0.1712978035211563 Valid acc: 0.7599999904632568\n",
      "Epoch: 947/1000 Train loss: 0.17405425012111664 Train acc: 0.7599999904632568\n",
      "Epoch: 947/1000 Valid loss: 0.16164596378803253 Valid acc: 0.7555555701255798\n",
      "Epoch: 948/1000 Train loss: 0.1672348976135254 Train acc: 0.7627778053283691\n",
      "Epoch: 948/1000 Valid loss: 0.15993016958236694 Valid acc: 0.7572221755981445\n",
      "Epoch: 949/1000 Train loss: 0.17125767469406128 Train acc: 0.7609259486198425\n",
      "Epoch: 949/1000 Valid loss: 0.16250069439411163 Valid acc: 0.7588889002799988\n",
      "Epoch: 950/1000 Train loss: 0.1696271002292633 Train acc: 0.7633333802223206\n",
      "Epoch: 950/1000 Valid loss: 0.1588250994682312 Valid acc: 0.7538889050483704\n",
      "Epoch: 951/1000 Train loss: 0.16968603432178497 Train acc: 0.7618519067764282\n",
      "Epoch: 951/1000 Valid loss: 0.15934066474437714 Valid acc: 0.7611110806465149\n",
      "Epoch: 952/1000 Train loss: 0.16875086724758148 Train acc: 0.762222170829773\n",
      "Epoch: 952/1000 Valid loss: 0.16032297909259796 Valid acc: 0.75\n",
      "Epoch: 953/1000 Train loss: 0.16710242629051208 Train acc: 0.7611110210418701\n",
      "Epoch: 953/1000 Valid loss: 0.16036848723888397 Valid acc: 0.7599999904632568\n",
      "Epoch: 954/1000 Train loss: 0.17543096840381622 Train acc: 0.7598148584365845\n",
      "Epoch: 954/1000 Valid loss: 0.16492784023284912 Valid acc: 0.7561111450195312\n",
      "Epoch: 955/1000 Train loss: 0.1720801293849945 Train acc: 0.7616665959358215\n",
      "Epoch: 955/1000 Valid loss: 0.1627693921327591 Valid acc: 0.7527777552604675\n",
      "Epoch: 956/1000 Train loss: 0.1693219095468521 Train acc: 0.7592592239379883\n",
      "Epoch: 956/1000 Valid loss: 0.16076068580150604 Valid acc: 0.7549999356269836\n",
      "Epoch: 957/1000 Train loss: 0.16834399104118347 Train acc: 0.7620370388031006\n",
      "Epoch: 957/1000 Valid loss: 0.15870389342308044 Valid acc: 0.7566666603088379\n",
      "Epoch: 958/1000 Train loss: 0.16646337509155273 Train acc: 0.7640740871429443\n",
      "Epoch: 958/1000 Valid loss: 0.15918020904064178 Valid acc: 0.7594444155693054\n",
      "Epoch: 959/1000 Train loss: 0.16574621200561523 Train acc: 0.764629602432251\n",
      "Epoch: 959/1000 Valid loss: 0.1618460863828659 Valid acc: 0.7472222447395325\n",
      "Epoch: 960/1000 Train loss: 0.16428957879543304 Train acc: 0.7609259486198425\n",
      "Epoch: 960/1000 Valid loss: 0.15735583007335663 Valid acc: 0.7594444155693054\n",
      "Epoch: 961/1000 Train loss: 0.1626242995262146 Train acc: 0.7651851177215576\n",
      "Epoch: 961/1000 Valid loss: 0.1567971557378769 Valid acc: 0.7594444155693054\n",
      "Epoch: 962/1000 Train loss: 0.1621359884738922 Train acc: 0.7633333206176758\n",
      "Epoch: 962/1000 Valid loss: 0.15545855462551117 Valid acc: 0.7599999904632568\n",
      "Epoch: 963/1000 Train loss: 0.16172939538955688 Train acc: 0.7642592787742615\n",
      "Epoch: 963/1000 Valid loss: 0.1567704677581787 Valid acc: 0.753333330154419\n",
      "Epoch: 964/1000 Train loss: 0.1614239364862442 Train acc: 0.7631481289863586\n",
      "Epoch: 964/1000 Valid loss: 0.1551162451505661 Valid acc: 0.7599999904632568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 965/1000 Train loss: 0.16067558526992798 Train acc: 0.7651851773262024\n",
      "Epoch: 965/1000 Valid loss: 0.15644027292728424 Valid acc: 0.7572221755981445\n",
      "Epoch: 966/1000 Train loss: 0.16048887372016907 Train acc: 0.764629602432251\n",
      "Epoch: 966/1000 Valid loss: 0.15615308284759521 Valid acc: 0.7566666603088379\n",
      "Epoch: 967/1000 Train loss: 0.15939487516880035 Train acc: 0.764629602432251\n",
      "Epoch: 967/1000 Valid loss: 0.15661810338497162 Valid acc: 0.7561111450195312\n",
      "Epoch: 968/1000 Train loss: 0.1589042991399765 Train acc: 0.7644444704055786\n",
      "Epoch: 968/1000 Valid loss: 0.1565864086151123 Valid acc: 0.7599999904632568\n",
      "Epoch: 969/1000 Train loss: 0.1602926105260849 Train acc: 0.765740692615509\n",
      "Epoch: 969/1000 Valid loss: 0.1607852727174759 Valid acc: 0.757777750492096\n",
      "Epoch: 970/1000 Train loss: 0.16128191351890564 Train acc: 0.7653703689575195\n",
      "Epoch: 970/1000 Valid loss: 0.16101345419883728 Valid acc: 0.7583333849906921\n",
      "Epoch: 971/1000 Train loss: 0.163651242852211 Train acc: 0.7631481289863586\n",
      "Epoch: 971/1000 Valid loss: 0.1568896621465683 Valid acc: 0.7572221755981445\n",
      "Epoch: 972/1000 Train loss: 0.1615559160709381 Train acc: 0.7624074220657349\n",
      "Epoch: 972/1000 Valid loss: 0.15746207535266876 Valid acc: 0.7599999904632568\n",
      "Epoch: 973/1000 Train loss: 0.16391444206237793 Train acc: 0.7649999856948853\n",
      "Epoch: 973/1000 Valid loss: 0.15828709304332733 Valid acc: 0.7444444298744202\n",
      "Epoch: 974/1000 Train loss: 0.16212892532348633 Train acc: 0.7577778100967407\n",
      "Epoch: 974/1000 Valid loss: 0.15539605915546417 Valid acc: 0.7527777552604675\n",
      "Epoch: 975/1000 Train loss: 0.1609729379415512 Train acc: 0.7627778053283691\n",
      "Epoch: 975/1000 Valid loss: 0.15429683029651642 Valid acc: 0.753333330154419\n",
      "Epoch: 976/1000 Train loss: 0.15886840224266052 Train acc: 0.7637037038803101\n",
      "Epoch: 976/1000 Valid loss: 0.1547888219356537 Valid acc: 0.754444420337677\n",
      "Epoch: 977/1000 Train loss: 0.15910960733890533 Train acc: 0.7638888955116272\n",
      "Epoch: 977/1000 Valid loss: 0.1545730084180832 Valid acc: 0.7583333849906921\n",
      "Epoch: 978/1000 Train loss: 0.1572529673576355 Train acc: 0.7640740871429443\n",
      "Epoch: 978/1000 Valid loss: 0.15532416105270386 Valid acc: 0.7594444155693054\n",
      "Epoch: 979/1000 Train loss: 0.1584191918373108 Train acc: 0.7646296620368958\n",
      "Epoch: 979/1000 Valid loss: 0.1547718644142151 Valid acc: 0.7616665959358215\n",
      "Epoch: 980/1000 Train loss: 0.15818969905376434 Train acc: 0.765740692615509\n",
      "Epoch: 980/1000 Valid loss: 0.15864461660385132 Valid acc: 0.7561111450195312\n",
      "Epoch: 981/1000 Train loss: 0.1599411815404892 Train acc: 0.7644444704055786\n",
      "Epoch: 981/1000 Valid loss: 0.1575947254896164 Valid acc: 0.7594444155693054\n",
      "Epoch: 982/1000 Train loss: 0.15655027329921722 Train acc: 0.7662962675094604\n",
      "Epoch: 982/1000 Valid loss: 0.15787465870380402 Valid acc: 0.7583333849906921\n",
      "Epoch: 983/1000 Train loss: 0.15711364150047302 Train acc: 0.7657407522201538\n",
      "Epoch: 983/1000 Valid loss: 0.15823179483413696 Valid acc: 0.7605555653572083\n",
      "Epoch: 984/1000 Train loss: 0.1575351059436798 Train acc: 0.7662962675094604\n",
      "Epoch: 984/1000 Valid loss: 0.15745483338832855 Valid acc: 0.7588889002799988\n",
      "Epoch: 985/1000 Train loss: 0.157565176486969 Train acc: 0.7651851773262024\n",
      "Epoch: 985/1000 Valid loss: 0.1569254994392395 Valid acc: 0.7622222304344177\n",
      "Epoch: 986/1000 Train loss: 0.15722894668579102 Train acc: 0.764629602432251\n",
      "Epoch: 986/1000 Valid loss: 0.1575210839509964 Valid acc: 0.7599999904632568\n",
      "Epoch: 987/1000 Train loss: 0.15764109790325165 Train acc: 0.76500004529953\n",
      "Epoch: 987/1000 Valid loss: 0.15944553911685944 Valid acc: 0.7549999356269836\n",
      "Epoch: 988/1000 Train loss: 0.157906174659729 Train acc: 0.7638888955116272\n",
      "Epoch: 988/1000 Valid loss: 0.15862227976322174 Valid acc: 0.757777750492096\n",
      "Epoch: 989/1000 Train loss: 0.15619193017482758 Train acc: 0.7655555605888367\n",
      "Epoch: 989/1000 Valid loss: 0.15918618440628052 Valid acc: 0.7572221755981445\n",
      "Epoch: 990/1000 Train loss: 0.1565784066915512 Train acc: 0.765925943851471\n",
      "Epoch: 990/1000 Valid loss: 0.15553522109985352 Valid acc: 0.757777750492096\n",
      "Epoch: 991/1000 Train loss: 0.15953391790390015 Train acc: 0.7651851773262024\n",
      "Epoch: 991/1000 Valid loss: 0.15450268983840942 Valid acc: 0.7605555653572083\n",
      "Epoch: 992/1000 Train loss: 0.1575017273426056 Train acc: 0.76500004529953\n",
      "Epoch: 992/1000 Valid loss: 0.1548144817352295 Valid acc: 0.7561111450195312\n",
      "Epoch: 993/1000 Train loss: 0.15644757449626923 Train acc: 0.7661111354827881\n",
      "Epoch: 993/1000 Valid loss: 0.15046794712543488 Valid acc: 0.7611110806465149\n",
      "Epoch: 994/1000 Train loss: 0.15416963398456573 Train acc: 0.7655555605888367\n",
      "Epoch: 994/1000 Valid loss: 0.15512429177761078 Valid acc: 0.7627778053283691\n",
      "Epoch: 995/1000 Train loss: 0.15483883023262024 Train acc: 0.765740692615509\n",
      "Epoch: 995/1000 Valid loss: 0.14985774457454681 Valid acc: 0.7616665959358215\n",
      "Epoch: 996/1000 Train loss: 0.1533670425415039 Train acc: 0.7662962675094604\n",
      "Epoch: 996/1000 Valid loss: 0.1518658846616745 Valid acc: 0.7622222304344177\n",
      "Epoch: 997/1000 Train loss: 0.1530713140964508 Train acc: 0.7662962675094604\n",
      "Epoch: 997/1000 Valid loss: 0.15144677460193634 Valid acc: 0.7616665959358215\n",
      "Epoch: 998/1000 Train loss: 0.1551932692527771 Train acc: 0.7681481838226318\n",
      "Epoch: 998/1000 Valid loss: 0.15290893614292145 Valid acc: 0.7616665959358215\n",
      "Epoch: 999/1000 Train loss: 0.18964192271232605 Train acc: 0.7529629468917847\n",
      "Epoch: 999/1000 Valid loss: 0.22239816188812256 Valid acc: 0.7238888740539551\n"
     ]
    }
   ],
   "source": [
    "valid_acc, valid_loss = [], []\n",
    "train_acc, train_loss = [], []\n",
    "\n",
    "# with graph.as_default():\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the global variable instead of loading them or if there is nothing to load.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #     # Restore\n",
    "    #     saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    #     saver.restore(sess,\"checkpoints/har-lstm.ckpt\")\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over training batches\n",
    "        state = sess.run(initial_state)\n",
    "        train_acc_batch, train_loss_batch = [], []\n",
    "        for Xbatch, Ybatch in get_batches(Xtrain, Ytrain, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {inputs_: Xbatch, indices_: Ybatch, initial_state: state}\n",
    "            loss, state, acc, _ = sess.run([cost, final_state, accuracy, optimizer], feed_dict)\n",
    "            train_acc_batch.append(acc)\n",
    "            train_loss_batch.append(loss)\n",
    "            \n",
    "        # Print at each epoch/iteration\n",
    "        print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "              \"Train loss: {}\".format(np.mean(train_loss_batch)),\n",
    "              \"Train acc: {}\".format(np.mean(train_acc_batch)))\n",
    "\n",
    "        # Store at each epoch/iteration\n",
    "        train_loss.append(np.mean(train_loss_batch))\n",
    "        train_acc.append(np.mean(train_acc_batch))\n",
    "        \n",
    "        # Loop over validation batches\n",
    "        state = sess.run(initial_state)\n",
    "        valid_acc_batch, valid_loss_batch = [], []\n",
    "        for Xbatch, Ybatch in get_batches(Xvalid, Yvalid, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {inputs_: Xbatch, indices_: Ybatch, initial_state: state}\n",
    "            loss, state, acc = sess.run([cost, final_state, accuracy], feed_dict)\n",
    "            valid_acc_batch.append(acc)\n",
    "            valid_loss_batch.append(loss)\n",
    "            \n",
    "        # Print at each epoch/iteration\n",
    "        print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "              \"Valid loss: {}\".format(np.mean(valid_loss_batch)),\n",
    "              \"Valid acc: {}\".format(np.mean(valid_acc_batch)))\n",
    "\n",
    "        # Store at each epoch/iteration\n",
    "        valid_loss.append(np.mean(valid_loss_batch))\n",
    "        valid_acc.append(np.mean(valid_acc_batch))\n",
    "            \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot training and test loss\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(np.array(train_loss), 'r-', np.array(valid_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXmcU+XV+L8nmS3DJuAIA8MyCCoMqyLiUvfirsW6IGj17UJBrX371vct3WwL7fuz1bZWS1FqF6tYlzpYtdhqfXHBigIyoEARmFEZCCMgiDB78vz+eLJPMklmkklmcr6fTz7Jvfe5N8/NvbnnOec85xwxxqAoiqIoAI5Md0BRFEXJHlQoKIqiKAFUKCiKoigBVCgoiqIoAVQoKIqiKAFUKCiKoigB0ioURORCEdkqIttFZEGU7cNFZKWIrBeRjSJycTr7oyiKorSPpCtOQUScwHvAZ4FaYA1wnTFmc0ibpcB6Y8wSERkHrDDGjExLhxRFUZS4pFNTmAZsN8ZUG2OagceAKyLaGKCv73M/YHca+6MoiqLEIS+Nxx4K7AxZrgVOiWjzQ+AFEfka0As4P439URRFUeKQTqEgUdZF2qquA/5ojPm5iJwKPCwi440x3rADicwF5gL06tXrpBNOOCEtHVYURemprFu3bp8xpiReu3QKhVpgWMhyGW3NQ18CLgQwxrwhIkXA0cBHoY2MMUuBpQBTp041a9euTVefFUVReiQi8kEi7dLpU1gDjBGRchEpAGYBz0S0+RA4D0BExgJFwN409klRFEVph7QJBWNMK3Ar8A9gC/CEMWaTiCwUkct9zb4JfEVENgB/Bm4ymrZVURQlY6TTfIQxZgWwImLdHSGfNwOnp7MPiqIoSuKkVSgoiqLEo6WlhdraWhobGzPdlR5BUVERZWVl5Ofnd2h/FQqKomSU2tpa+vTpw8iRIxGJNmlRSRRjDPv376e2tpby8vIOHUNzHymKklEaGxsZOHCgCoQUICIMHDiwU1qXCgVFUTKOCoTU0dnfUs1HiqKkHbcbZs2Cxx+HwYPD17vd4PVCU5Ndl5cHzc0gYhCBwkIwBvyDXxH7OuEEobi48307ePAgjz76KDfffHNS+1188cU8+uijHHXUUQnv09wM1dVw7LEQy+Tf3Aw7dtjPo0dDQwO8956dlHnccULfvtH3SxWqKSiK0incbjjrLNizJ/xzVRUcdRQ88AAMGQKvvgqlpeBwwLBhBhHDkCGG5mZoaDB4vfbV3GwAgzFWWDQ0BAUCEFhfs8Mbs0/JcPDgQX7zm9+0We/xeNrdb8WKFUkJhPp6eOcdOHwYNm0yvFvVwtq1hnfXN7Pp7SbeXufl4z1NvLPRy5EjhiNHDJs2tAYEAsCOHemfsa9CQekUbjec9Rkve/62LtNdUboI/4N/wwaYPh0mTrQP/OHDrTbw6qtWCEyZAp98AvPmhe9vDNTWgs2E4zd1SNKvhiYHa9dCZxMcLFiwgB07djB58mROPvlkzjnnHGbPns2ECRMA+NznPsdJJ51ERUUFS5cuDew3cuRI9u3bx/vvv8/YsWP5yle+QkVFBTNmzGD//gbWr7eCAGDdOti82Z47QGur0NhqVYVGTz4N3gK8RqiuLcTgCJxjK3lh5+zxSErOuT1UKOQYbrf9I596anBkN33sQU6d1sqGtS1Mn2449VT7hz9xUiu9iz1M7bWFPY/8s82xqqpgxHDDq6uE0kun0DuvkZfGf42zRu1kz54MnJySNvyC4J//hJEj7YN/8mR4803Yt8+2aWmx6yH48ItN6nwI48Z1bv8777yTY489lqqqKu666y7eeustfvKTn7B5s83y//vf/55169axdu1a7r33Xvbv39/mGNu2beOWW25h06ZNHHXUUfz2t0/h8UBNjX2Ax/49IoVdPKxJ7bjjOnauiaA+hZ5GY6PVT48+us0mtxtOOtHg9j2wJ0+Ck4e7efPfpQBMOdnry1homDLZi8EJwDpOYOIXS9l4vs8e3NhIYb9CmpvDR3pHPEWcv+leBC8LF0IUjVzppixaZB/4n/1ser9n2M+/TvF7G5LaxwPQp50GkyfDPfckfLxp06aFTee89957Wb58OQA7d+5k27ZtDBw4MGyf8vJyJk+ezNq1MGjQSXzwwfuANX2lFsEY0upXUE2hJ3DkiB32v/QS7tOv4qySTezZFW4PLSo0DBkC7j3BUUndR8Jza4cElq0QaPsZhL0tR1FaCkVFIC6/QIiG3XfJEusMdLnSdtZKGvFrBkVF9jouWZLKo0cbNvvXJa9BFPdKrn1zM/x7s4eW5ujD9169ggd8+eWX+ec//8kbb7zBhg0bmDJlStTpnoWFhYDVWgoKnHg8Lcl1KiGsryXdE7VUU+hOfPQRDBhgp2f4MQZ379HMpJIW+lHLg+ylhIX/+TG/ebIEtxuGDjUYk5o7yc4QSexYDodVn5Xux6JFsGoVXH89vPEGbNtmSJ3JJ9px7Lqd30xkRB98mLtcQkVFct/u/qCZw/X5bN7kZdx4J3369OHTTz+N2vaTTz6hf//+5OUVs2LFFlavXt3use1sqHQ4g+0xS/o2MeK4ojQcP4gKhWzFGPty+JS5W26x9pj584N2mYMH4ZRTWMD/402mE/pnW/KXEpYI2Jspc3PAQ6cfKtmPyxU+0+dPf/J/6sg9FPpwFJxOOw3T47EWnfp6+PhjKCuzD9OPPw7fe+BA+PRT//TUoF3e5YLShmrcecNpbU08lcO6df5jFADQ4nGyYQOIDOT0009n/PjxuFwuBg0aFNjnwgsv5P7772fSxIkMLTue8eNPobXV9qmlxb4iCU5aSs1/z+EAr1dwOKDFkV6BAGms0ZwuenQ9BWNwv/IeM78+DNmzh+UfncbgsQNgxgzcv3qcmVQiwHL3qQweDC5HE42mMNO9joIhP184/3xYsSJ+ayV7cLvh9tvh6aftQ9s+kJI9SvBhWFEBy5bB0qX22JWVbVtv2bKF4uKx7A1Jmu9y2fgEsIKkpAT27rUP4dGjsd7b0lIYOjThXjU3w8aN0beJwEkntV0fFCTRycuDUaNg+/aO/E7xmTq1Y/tt2bKFsWPHhq0TkXXGmLhHVE0hG3jsMTu8qK1lwYJBvMlxQDnf4k7e31LOvVu+xkWsxU0pINaJ+303XjOgk1+c6Egm8l8Rbx+hpQWef97+uVPvbFPSRWkpOJ1WIBQWBgPKwm3+8ez/wrHHwgUXWEEwaRIsXtz+97a02Ad/m4d/CCNGdOSMghQUWO1j//5g/0Wgf38YNiz6PhMmxBYkAK2t8N57kWuT0xAGDrSC5+BBK1gcDhvfEatP6UaFQjZw3XW4qKeRcK/sn7gJgMmE35VLlsCSJaV03nYZeeNG/7P3ctTz+tRv8Jl3FvNpQ16U743+B7jyyvgPAyX7eOUV+z5jBjz7rH9t6DWOfr0LCuC+++Dee60pKJlrHyoAEnr4h9qTksDjAVdeCw2t+dgAuaBZKxoFBUl/BfEEgsNhBUGoAMzPtwJBxL6316d0o0Ihw7jdMJN/0UgyZiD/SCS1voLSUoPbHX7Migo4bs86pq+9j0Zv9Lu0qCjUDh0ULIMGqU+hOxHpTwgKhFAMffsKhw4F1xQUWNPM0KEwd659ZSujR8P2ja305iAlA7zsdQ6O6heA+KajjjBwoBVMfsHnf9++va2mlClUKGSYRd+ub+MkToQ8GmilKOn9YuFwwPTpDqqq4OST7bo1a2yQTOWgH+E+3IfbW+/k0bePb/Od/gdJcTFcOnQ91NSwZtjnNYCtG+F2h5qKohEU9qECAaxAcDqt87jLaEdT8OcOMsY2GzECPvBVJx49Goa4PmZr82BKvHWMGBV9P683FQLBP3iz7/n5ECubdSKaUiJ5k1KBCoUMERyVdSSjl9BK6gIA+vWD006L7gQEYIaTUkcdffMbELyIw4HXawVDcTHMnAl33+3TCr7xMPzud1D9+ZT1T0k/ixbFaxF98OF0whVXWFNRNmiFzc2wZUv4SLumJujX2rQJWlutc/rfB0uZ4DPd1Nfb/VKrGQT9LyLQK8l4ikjcbhuXunt35/0r7aHBaxmiuto+TNM5pznesf2zXQcMsLOEQpOZhZGXBx4Pde83MJ/7uXKmCezf2GijKwMPhA7aepXM4HIFg9PiXzZDOTvC1ng8ZMZMGOU+W7fOOoUjTS+hEx1aW8FvevXiYMMGO5EpNC9RqnEVesnLa+s4T5R162wf/bOz9u61y+vSlG5MhUKGKC2FZ56B5Mw/id61EvEenc9/Hm6+Oaj2+wOWFi6MaOh0wiefcEfdfJYxh48POLj5Znj7bZvsTM1E3Zfqapg9u70WJuQFDBpMeTlcc419lZdnx/VPh/0/Fmee2Rsw7N27i2996yrCB2H281e/ejbbt69h0gQvFROcTJrU9jj33HMP9f6MedhU3AcPHmzTbsIEO3DzD+IcDrs8cWJKTyuAmo8yxaFDeDx9SE4oJNbW6QzaRUtK4Jhj7GyQ6dOtMJo7NzhvfPHi4GjRj53dZB3IDQ1YTWHvXq7nFT6hH3V18NJLtm2bGSaqKXQrSkutphf7soXfc5NP6xXbzNiF1ONi696hHH90Osw+0Qj1D1hKSobyy188QXNL6PZQhPxCZ8wj3nPPPVx//fUU+4pCrIgR1FNQYP/TXTU7STWFDFBUBNKvL6mcPRSaY8jjCQbS7N1r7agHDlifweLFwXnj/j+3f7ToL1hSXAxz5gRTVMjTlciBj9nEBEDYtClY6KQNKhS6HXV18IUv+B8yIVpBBA5HO36nLuatuhF86SsO1qzp6O0WPM/77vsWTz4ZzN64dOkP+e1vf8T8+edx/fUnMmvWBF555a/4H/wiUFIiHD78PlddPZGSEqG8vJHvf38Ws2dP5M47r8XjaQgE382fP5+pU6dSUVHBD37wA8Am2du9ezfnnHMO55xzDhBMxQ3wi1/8gvHjxzN+/HjuueceWlqgsfF95swZy89//hXOP9+m6G5IQxCQCoUMcNllkEpfwvz5cOGF1hT04ovWcewn8gEfDf9osbExOL001E+wfsa3GEFNWJ9HjrTptdugZRW7HZWV8Mgjflt87KnO/pFqJpMc+msJ/PpBF1VVwn33hW41EZ/b+48Fz3HGjFm8+OLjgeV//vMJLrvsP7jrrkoeeeRtHnxwJffcczu9e1vNG6yjd+RIO4ofMQIeemgJpaXFvPfeRu6447u8++66QPDZT37yE9auXcvGjRt55ZVX2LhxI7fddhtDhgxh5cqVrFy5Mqxn69at4w9/+ANvvvkmq1ev5re//S2ffrqesjLYvn0b3/rWLWzbZlN0P/XUUx34FdsnreYjEbkQ+BXgBB40xtwZsf2XwDm+xWLgGGNM4qWMuhnh88BjPzydTlusZNmyxI67Z4/9Y7tcbdNV19fbgOlHHmn/GHV11j8QalryM7lkNwX45yva0VKvXu3YNFVT6DZExiYEiR21nMnL+5nPhPf3qafsq6AAXn89tGVov2NFGNt1xx8/hQMHPmLv3t0cOLCXPn36c/TRg/nFL77BO++8RmGhg337dnHUUXUMHjw46rjn1Vdf5bbbbgNg4sSJTAz5czzxxBMsXbqU1tZW3G43mzdvDtseyapVq5g5c2YgW+uVV17Ja6+9xuWXXx5I0Q1w0kkn8f7778f+sTpI2jQFEXECi4GLgHHAdSISVg7DGPMNY8xkY8xk4D4gS5TT9JDIn6moiEC+9N27w806oTidNpFYaD4ZvxnI75AqKoIxY2xkajximZb8X7aLMgA+ywtUVLRNXhZAzUfdioDp0BV0ljppBQzHObczjA8IHXGPGQNpeA4lTHU1XHwxFBbaPhUWwiWXwF//GuvBbyJeEE2LOPfcq3jppSd58cXHuOiCq9nw/F3Uf1pHZeU6qqqqGDRoUNSU2aFIFGlRU1PD3XffzUsvvcTGjRu55JJL4h6nvXx0/hTdAE6nk1Y7nSqlpNN8NA3YboypNsY0A48BV7TT/jrgz2nsT2b54ANWN02iyNFE2ymjBqfTRoSuXh2c0RNp1vHjFxyXXRY+FdDf3t+muZlOJ6VzuUD+9BD19AaEF7kg4KOIigqFbkXoPeaw5Wq4mOe4+ZqPqRh6CCcewFCAfZC1tmY2HqG01A6SmpuhsMBLc7OhqAiOPjp2HiYC5S3tRNTwz/ZenTHjWl544XH+7/+e4vLPXUNjvqH82MGMHZvPypUr+cAf/RaDM888k2U+1f7dd99loy9h0qFDh+jVqxf9+vWjrq6O559/PrBPrJTdZ555Jk8//TT19fUcOXKE5cuX85nPfCbh36izpFMoDAV2hizX+ta1QURGAOXA/6WxP5ll5UqW8lUavQW0nTIq/nx4bUbqfrPO6tV2+l95ebjgiCS0fSqmi1ZXw+xj36SYI741hjFjtE5CT6KuDq467wCCHXVWFZzC4sePpnJrBVOmCDezhLc4JWz6cibxeGD+5/fy5h+28OUvNPsGKJFaQFAbcOChIN/LQPYzli0UFkKB04OLoJP2jNEDaaj/lJKSoZx22hDmzJvH2nXrmDp1KsuWLeOEE05ot0/z58/n8OHDTJw4kZ/97GdMmzYNgEmTJjFlyhQqKir44he/yOmnnx7YZ+7cuVx00UUBR7OfE088kZtuuolp06Zxyimn8OUvf5kpU6Z07kdLgrSlzhaRq4ELjDFf9i3fAEwzxnwtSttvAWXRtvm2zwXmAgwfPvykeFI724htt7WI2JwooamDs4k8hwePaTu1LjBlNZQFC+CXv4yXM0HJImLdn0VF0LD+3+BPwZymZ0W0NM9x8afPLyvj3X2DaWwM9q3Q6cGR56ChyYGIwRgoGWgYsf9t22DqVD7Y1szeT/JxFXhpaHZQwl5GDGmFIUNSdFaZpTOps9OpKdQCoclfy4DdMdrOoh3TkTFmqTFmqjFmaonf/d+NqK4Gh8ROtm6MLX6eraUrZwzbQj8O4B95OZ3tzGhS81G3QiT2gMUYwu2WWYrHA07f/8vpFLyOPApdDkpKYOxYoaREaPFYrXwdJ9ro4E+sxt7QbMvO7uUY1u4ekrYo4e5EOoXCGmCMiJSLSAH2wf9MZCMROR7oD7yRxr5klNJSmDN2HYTYMMEEHMIQf9popnC54PkPx/MJ/fGbuzweO6Mpqm1Zp6RmNZGpTNav99epCZ/OOXy4z6Gc5UJh3a5BtLTg02StGbalBT75xE4VLS6276NH2/tyAu/Y6GAJ9+s58DCgd1PaooS7E2kTCsaYVuBW4B/AFuAJY8wmEVkoIpeHNL0OeMx0txJwSbLvUxfF+EPa7al6vfY/53BE5A/KIqqrYfa49T6nnNUS4s5o6tmXstvidtvqYq++CuPH23vO4QiNawna4Z1O3/2Y5UJhwqCPfEFiwXxcMVNAjBhBwdjRNjrYBPcBgxdHRmsYZBNpjVMwxqwAVkSsuyNi+Yfp7EM24P7VEzy/82qiTZnzeq1DODQuIJsYNQoaG4NOLo8Htm2DnTtj7KDmo6ykqCjczbN/v32fNMlmMXGIYZDZjZuhOB1eJk92BnfsAowxUad0tsc6TsTs8Y9r7b5er50uPWpUlB18pucWN5T0b6XxQAOt+cXktdRTJE20yNGdOIPsobPja41oTjWbNgWe8G63HXEN+c9riCYQ5syxed7bxAVkEdXVUNb/ME5s6kl/fERMU5cKhazCfw+25/dvbQWvceCmDBA8XifLl/t8XIXJFH/qGEVFRezfvz/ph9kE3mGAK5hQTvBSWBge0R+N0aNhxOBmyqnBIV68OBgyzBkwMXVnjDHs37+fok4Ic02Il2rGj8fNYGadXsvrbwTrDkRj2TJbhyCbKS2FS8fVsPT1cRQ5W2g2+W3iI8JQn0LWUFUFHZvJaJgzR+y92QXXs6ysjNraWvYmMf3Os+8AH1FCq9TgNQ4EgwF69xby8mySvHZpbmb/viYO+1KB7/u0laP313X8JLKIoqIiysrKOry/CoUU4t70MTP5l62k9npif6aFC9umpsg26vqfwA3Hvck7rpOZMDmB2AfVFDJCVRWccYY1oXQ8T5pBpGt9XPn5+ZTHKkkWg5vHrWQJ5wHC8ccLvbauY8J4w6ExU+Nq3e1NEY86zTrHUKGQKoxh2Ph+eDg1qd3apKnOQhYvzeekk05jzzY45TT44x/baazmo4xx7bVw5Ej8du0jOPCyZ092anzBB/rNgXVbtwKcxIZNHlrfiX+M6mooKzNRtXi9ddWnkBJcLhCH4CF27nRL2zsukSymmcTlsvE8brf9wyxZEidTppqPupSqqmAa8/fe6+zRDEOopfa+5eGj7SeesHNXswB/xUK/jysUj3EmlMW1tBTmXHqQyHxImc7rlC2oUEgBiZQxjJWpsb4+e6ejxlKzHY7sFWI9kZhlUrHV81KDvYmv4BkGD4x44F59dXbkt8A+0AcNwjcAC09n4cpvTWiA5XLBw8/4426CqWa2bcvO/2FXo0IhBaz+zjPEz90efQTtcGRHOcNo+DNoOiMUoBtuSMDRrHp4SqiqgmHDbGzB2LFw6qn2fvFrB9XVqfome48u4WZcX7g6VQdNC3V1UE4Nx7I9ZK2hocWZ0AAr1q3p0KchoEIhJfzyNwUd2q9vX9i1K3uno/ozaHo8VjCIQEUFHDrUzk4qFDqM221Lpk6cCL1724fUlCn29wc4eNAmOiwt7djxHQ4rYMaMCQ8/8Av9Yo4wh0eo+c3z0Q+QJTz/PNRwLDsYQ3DA5RNqS+Kbj2pqYPSIZsJMR0MOs2tXOnvdfVCh0FFeew1XgQcR+FPdhSRWWjP8QXnokP2DZ2vOI7CjsptvtoXR58+H446LI8TUp9BhFi2CN9+Ed96xDuPOytWiIujTx/qtqqpskOTUqXDeeTb1tF8weDxQ5GyhkSL6cojBR6c+R38qqa6G2SzDEfAr+MxHhZ6EzEelpdDqy4VU4LDHaPU41HTkQ2cfdQC3G2ad6cVLK0R1LkdWrQr+u/1qv7/49qxZ2R2rECoAFi9OYkfVFBImXhbdjtLYGKzF4U/JDnDllcEqezNn2nXLp/w/llYOxM3grLejjBoFjcwJWWP/Zw1NzoSqDAJMGd/KxbVLmXvRbpb+bQjuMVdjiz8q2X31s5QFX9nHq5zJFSxHovoSIn0IQfXW/6wMrbDWo0Yoaj5KGv+MmlQTa2ZbaJW96mr7mlS0lcXcSiVXtXUiZRnWjxL9/kr0tqv8wycs5lYm9dpuz3vR5pT1r7ujmkISBEd0NkfKk8yK0bLtTCO/VvDxx7ZQTrRayD0CNR8ljc0v1bljHHMMXHQRvPIKfPihrVnc2JjEoCO0AliWC4XSUrjhBuHhh0M1csOY8lZe/VeCGe3859jcHL6sqFBIhsQHv0JRUfCP7i+N2bdvuGqblDmmu6GaQkK43XZWUWfDAD76CB5/3AqGiy/uwKAjVChkufkI4PBh6FPYzKdNBfi1hlZvEn4B/zm2tIQvKyoUEsXlSryY2PDh8MwzIfba5T1UK4iGmo8Sxu1ObaGvmppwrSCpQcfhw8HP3WDU/Pzz0NgUnqyv5gMnLleCmQH85+gXCt3gnLsKFQoJkugzbtgwm/kUwueQ92itIBQVCgmRrHO5oCBo6YjG1Vd30jfVjcxHYP9bt1+7kydeG0wr+eTRwrWz87j75wmaL9V8FBPVmRJAJHEtYdeu9iNQezzqU2gXfyrrZH0IeXl2avBVV7Xdlp9v0193im5mPho1Ch59bRitWB9CK/kse1RIOK+eCoWYZP/VzwLWr4cRw0PzpLRFxNYZ2LXLzjdftcpmQM1ZVFNog9sNEybY6cjxGDTICoGqKvt+wQVW2/R47KyiY4+11e/69IGjj05BAGQ3Mx9VV0PZMU3BOh+0tF/nI5JIodANBGFXoeajBJg8GT7cCdED1OzDzxjB7Q6PNu0OGVBTjpqPohJZ+aw95s8PT6ceanpMS/S7Md1OKJSWwqXn1rP0sb4U0UAzBe3X+Ygk0tHcDc65q1DxmAgeD0V5rYRnVfRj4w8qKuzIbfZsO5KD7M+AmhbUfNSGZAQCwAMPtL895ebJ+vpw9aWbjJrrPiliHvezmunMK344ud9DHc0xUU0hDtYh6CR65HKQTZvsy+m0Ay//lNQeF5yWKKopAMkLBIhfPD7UPJmSAk2h/gToNg/Iyic80OdWABYf8yOovCnxnf2CT30KbegeQ4IMUr3DUM4O2s+Cau+pK6+02sK8eTZx2bx5OehsVvMRVVU2oV0yExT8tJfT3+Wyx1yyxA7s49a2SJRQ0xF0nwdkr17B+60jtaSdTvUpREE1hXawWoIAx8Zt6/FY52AsW3DOkGNCwe22keqPP25PedYsm0SwoxXQWltja5bV1XD77fa7/JlrU5I7KzLtbXd5QIpYT/uhQ1ZAJEuoUOgugrALUKHQDm+8VM+U013EyoDap481D51+OqxZk4NaQTRyzKewaBG89prNI/TRR5071jXXBE3c0YhMh+HxwLJl8NRTnZzI4A+s8dOdHpB+W9vAgcnvm5enQiEKaRUKInIh8CusQf5BY8ydUdpcA/wQa5/ZYIyZnc4+JcPUM4qIJhAcDjv1NCd9BYnSwzWFSF9BZwXC8cdbDaA9qqth2jQ7+Ghttc+0wYPtgKRTbPcVqxkwwCbn6i6aAsCXvww//SkcdVTy++bnB6WpCoUAabv6IuIEFgMXAeOA60RkXESbMcC3gdONMRXAf6arP8ngt916TPSfx+u1Se1yOkgtFj3cfOSPNUjWVxBK5DO3f/84hYt8lJbCOedYgVBYaO/DpKZhxmLXLqv2+g/U6Ui4LsSfJ6QjGqo/ayB0L0GYZtL5S0wDthtjqo0xzcBjwBURbb4CLDbGHAAwxnRyvJUaqqth9nUGF7F1cmM0SC0qPdh85M9V9O67nTuO1xsemHb22bB7d2L7rlpl3y+/PIUTGfbutRFwfo91dwqqCc1Fnyz5+cH9VVMIkE7z0VBgZ8hyLXBKRJvjAETkdayJ6YfGmL+nsU8JUVrqc+YRe1pHU5Od/QE5GqQWjx6kKbjdMHRoak5pzBhbb9k/KE90MkJkrqQnn7TvHXkWtmHfPigpgZNPtiX2+vRJwUG7iFNPte8335z8vqFzf1Vc6C/VAAAgAElEQVQoBEinphA7/DdIHjAGOBu4DnhQRNoYB0VkroisFZG1e/fuTXlHI3G5wOONPeIdOlSD1GLSw8xHVVVWO0jV6Wzb1rESrNXV4fccWAGTkntu3z6rKfziF/D66zaXd3dh2jSrep0SOd5MgIKQ2uoqFAKkUyjUAsNClsuASCW5FvirMabFGFMDbMUKiTCMMUuNMVONMVNLSkrS1uHg98XeVlFh78O+fYOlDnM6SC2SHiIUqqrsqUyZ0vFjOJ32WTtmTHBE73R2bADh117r64PrOipg2tDQYKVNQQGcdlonD5YBOmqyDNUU8nQipp90CoU1wBgRKReRAmAW8ExEm6eBcwBE5GisOamaDFNTAyOL3EQqNsOHBwvX19XleJBaLLq5T8HvSE5WGDgcMGJE8LPDYQvd7N0L551nZz52tgTrjBmpETBtaG4OHzXnCqHn3GnJ2nNIm3g0xrSKyK3AP7D+gt8bYzaJyEJgrTHmGd+2GSKyGfAA/22M2Z+uPiVKaSm83ziYSAvYhx/aF3SioH2u0A01hc4UvRkxwiZOvOSStlXP/AOIzpZgXbHCJstbujS8ml+nNdRcFQp+TaGgQDWFENL6SxhjVgArItbdEfLZAP/le2UFQYde2xHvyJHw1792dY+6Gd3UfFRY2H4Rm2jMmAE7dtiH/OTJsQcKqRxApErAhNHSkttCIdRRo2hEcyTtPct69YKJE7uuL92SbmI+crvtqH7LluQK3hQXdzyFRSpIi4aaq5qC/5xVKIShERtJ8PHHme5BNyJNmkK8gMFo21980cqq0NeQIbZ4UqICweGwAYsXXND5c8g6clUoqKYQFdUUEqSwMPEAo5wmjeYjvxN4/374+tejp4VYsMDGAdx2m83ekKwmEI3iYisM0lLgJhvIVaHgP+eOJNPrweS0UAjNcOl31tXUwOjhTdS3FuD3K/TqFUwPo8QhTUIhMnjriSfsyx8wGCu4qzOUlubAQMCY3BUKqilEJafNR9HSVJSWgsNjc784HPbBdswxGoOQMGnwKUQ+8EPxr0+1YpITAgFswBrkplDw12Do3Tuz/cgyclIoxCpW4n8dNr0AweuLao7MLKwkQAqf0tXVcNFFsbf7p2emih4tEJ5+Gn772+Dy7bfb91ycktm/v30fMCCz/cgyclIo+FMG5DlsXdo8p5c5c2IPluKVR1RCSIP5qLQ0GBgWjaamzn2d02m/wxj76rECAWDmTDufNZJcjL7012DoSNrtHkwODg9Ci5VYmdjqcbBsWUa71HNIg/koVYd0OGxhGgVbAKKqKrhcV5e5vmQKv4agabPDyMlfo7oaysrAiS1z5XR4KSuz/5FeRR5C01v06hW7Zq7SDinUFNavb19TiEdRkZ1OekVk4vZcZtCg8Pm1uehTGDTIvpeVZbYfWUZOagqlpXDppfDA/Q4cePAaB5ddZksqDujdxJFGF/l5XlpaHepkTpY0mI8mT+7YMys/3w4CNZ05dqrdlVe2XX/NNTbD4xe/2PV9yjRXX21nkZx+eqZ7klXkpFAAqy0fxza2cjzHD/qEPXusXTGPVsDwuRn1lIzsnZo0ArlEmqak7tqVeFun0xah6bFxBe1hTHR72+9/b7M3RrJ0KfTrl/5+ZSMFBfDZz2a6F1lHTgqF4BTHEwDYuucoti73/5f6AvDkCjtNLSVFTHKJFPsU2puOGoucFQhvvgnTp8PDD1tbmb9Yzl/+At/7XrDde+/BQw/Bn/6UuwJBiUlO+hRiDWIdDnA57dxGl0sL53SKFGkK1dV2wowfpzO23MnLs1NXc1IgAPzoR/b9hhuCI+Ann7RmEoBjj4U//tHm3/7xj4MpfxUlhJwUCjU1MHpUqEPZMGYMXH89NHjyAUNDgxbO6RApNh+NGgXLlweXPZ7Yhy4osOmlc5KdO+GFF4LLb75pozOvu84WAtmxAzZsgBtvzFwflW5BTgqF0lI7tx0gH/th+3arTdvUFvbBtmSJ1t5ImhSaj9ozHTkcVjMYNMi+Oxw9NFkd2AhLsBF6LS1ttxtjk0FBeOrUO+6AM86AN96w0lVz/CgJkJNCASBPvIDhczzNzVNWc+GFvhq4YqeqaN3lTpICTcEfZBhZPvfGG63G0NJiY65aWuxyjzQbVVcHbWaFhcFC9X4OHYKTT7bq1A9/aAvYX3ON3da7t41g7mjlICUnyTlHc3D0acOUn+RaWG//b//xhVYaTAEOvDQ0ONR81BFSaD4qLbUmvNCAs/797XOwR+P12t/P6Wxb1WndOjh82D7wa2ttUYjNm+Fb37IvgB/8wO77+9/rTAklaXJOU/CPPosL7ZPGBrAZZs2Cupp6xrEZgzBuXG5G/neaFPsUli4NXz5wwA6Ke5xZr7kZ9u2Dn/3MPtCPO86W+vuv/4Lx4+E734GSEtv2v//bCo5hw2DjRnjuObjzzmA+lnHj4NFHVSAoHSLnNAX/6LO+ycpDj09jeOghsNNRJwCwaZN9uVwa/JQUKfYp+M3poTgcPcis19ho/QGR0q+6Ovh52TJb8m/hQvvgr6qyNydY4dFjnSlKJsg5TQFs4NqNZ9ZwEX8jz5fqwuWCkf0+xkU9oD6FjuI+6OIsXmbPR52/tWL5FG64oRub9TweqxUYY6sBfe1r4QJh+HCrDr30kl2++upgDVinE776VRuEdsstdt0TT3Rt/5UeT85pCuBzSN7/AvNfNXhxUORsoakpn2LnpzRxFEVFdgCnPoXkWfTMJFYxhoX3HuY3j3TsGFVVdtKMCJx9drhPoaKiG/sUnnoKrrqq/TZvv22zdp57bnQT3DHH2PfXXrMqU0VF6vup5DRxh3Mi4ozXplty8CB1HMM854Osvupu5s2DA/WFzDv2RVavhnnz1KeQDIEaFStPwIuTJcv6IZK87d/ttqlojhyx/tTnngvfvmkTPP986vqdFh5/PFicY9EiOzW0oiK+QKiqCqZzjkVolbDvfS836yAoaSURHX+7iNwlIuPS3psuxO2G/RzN9/vdy6QBO1n880ZWeC9iWe1ZiNjp3j1yimOaCDjwC2zVuuIib9LmNxE7e7K+vv12aSj/nBp+8AN7ErNmBdfdcYcVDJs3x95v9Gh7Q06aFP87/LEGAwbYKaiKkmISEQoTgfeAB0VktYjMFZG+iRxcRC4Uka0isl1EFkTZfpOI7BWRKt/ry0n2v8MseuVMVnEGCxtut/aJrVu5nj/xSVMhs2d3VS96Dn4HfmOLkyIaaGySpMxviWoU5eVZlsrcGLjrLjuCD63rGm8fY+xso40bYdu2xH8ov6YwYEBaalcoipgkhl0icibwZ+Ao4C/AImNM1JL2PrPTe8BngVpgDXCdMWZzSJubgKnGmFsT7cPUqVPN2rVrE+5zJMkmWMvaUWkWcuWVUHpoK3Nfuoals1/B3XBUQtpWt70mb7wBp52W3D4vvNC5zJyPP241kTFjbGI7RUkQEVlnjJkar11CPgURuVxElgO/An4OjAKeBdrLNDMN2G6MqTbGNAOPARkvcxIwczhteoti6rlo6AZKiw8SWlxn5EibKkZJnMpKWPwfa5nERhb/cG/C5rdkBELGi2S1tMBjj9lRejICYcECO2uos6ma/ZqCaglKmkjES7UNWAncZYz5V8j6v/g0h1gMBXaGLNcCp0Rp93nfcd4DvmGM2RnZQETmAnMBhg8fnkCXYxMwc3jyKaKRRgp5Yfd4PCbcn/7++3DKKRqj0GGSGM6/8ALMmBG/XXk5/Otf8duljOZmOw302WfhxRdhyxZYuTKxfW+80U4lPfNMOOmk1D3E/T4FFQpKmkhEKEw0xhyOtsEYc1s7+0W7ayOfFM8CfzbGNInIPOAh4Nwo37MUWArWfJRAn9ulrg5uGPEK7+w5mg1N49oIBD8ao9ABkoxoTvbZNnj7KtjbDyZMiN+4qck6cEeMaP+LtmyB3bvhvPOsf+lf/7J+gmefjfjywfCFL9g6Bf7EcytXwmc+Y2cOnXSSjTFwudIXTVxRAVOnWue1oqSBRIRCq4jcAlQAgTvdGBOvfl8tMCxkuQzYHdrAGLM/ZPG3wE8T6E+nqayEm8sbqGqq4Ppey3mkfiZe09YuUV6umkLSJCEU4jmXy8ttrjeANWtgckWLfQCDfZCfcELbnVavtlOYtm2D88+360aNgm98wy736WNnAv3xj9ZutX27dfZG45RTrKYwfLit3HPttUH71a9/Hd72pJPse//+cc+7UwwaZH8MRUkTiQiFh4F/AxcAC4E5wJYE9lsDjBGRcmAXMAsIm9cjIqXGGH/By8sTPG6nCDo1LwbgT0c+H7OtagodIImhf3u+hA0bgoG8AR58CPxxC7/7nR3Nh/Lww3YkH0l1tY0cjkavXvA//2P33bvXVi6bM8dOD50+Xc00Ss6RiNtutDHm+8ARY8xDwCX4EwS1gzGmFbgV+Af2Yf+EMWaTiCwUkct9zW4TkU0isgG4DbipIyeRDAFHs8M+kVw04HI0AuFJdm68UaOZO0UCmsL69eGxWH4cjigCAWzhGL9Z5u67w7/r/ffh1ohJbG+8Ybd9+KGtSvaFL0BZGcyfbyuSrV1rzUs//ak1H7W02EjhefNsimoVCEoOkoim4K/qcVBExgN7gJGJHNwYs4KIGUrGmDtCPn8b+HZCPU0RAUezt4AiRxNN3kJO6FXL5k/LcOLBK07GjevGqRQyTRLmo8mT29aMEbEWkqhs2mRH7y+/bJf/9jfrB6ioCE8g548gnj7dLg8bZtcpihKXRITCUhHpD3wPeAboDXw/rb1KM3V1MG/AE8yduJqlG07hqQPnUIqbh295i0ozE7dbo5k7TIKj61ixCcbYQXtUqqvhssvs6H7rVrj00rZtFi+2hWYURekQ7ZqPRMQBHDLGHDDGvGqMGWWMOcYY80AX9S8tVFbC4qJvMunYwywu+39cSSV1DOapwxdoeotUEUdTCJjxfOYjf1ZatzvGDkeOWGk+apQ1/UTj7LNh7twOd1lRlDhCwRjjxfoFeha+FAOuPy5B3tnIEm62SdweKu5QEjclhATNRwEzXiOJZaX1e/1HjbLTUX/84+C2l16y37dypSaIU5ROkoij+UURuV1EhonIAP8r7T1LJ4cPQ3Mz1d95kNn9VwRqKIDNHqCzjjpBEj6Fujrr000oK+2OHfa9vNy+f/e71vH83HM2zbSiKCkhkWGVPx7hlpB1Bpvqonuybx8ApaNcPH7gAjwEg9e2bbOj2KIijVHoEEnM2Ak10/ljwWJSVWWPPS4kWe+0acn1TVGUuMTVFIwx5VFe3VcgAO5/f8JZvEzR3BvCBIKfHlXuMVMkGNHsdsNZZyVQu2LNGhg71hasVxQlbcTVFEQkSjQQGGP+lPrudA2Lft2fVUzg+vP30/rWeh7ff26gVjN083KPmSbJNBcLFtiqlAsW2CDjqBhjYwouvDAlXVQUJTaJmI9ODvlcBJwHvA10O6EQnAY5AoA/PX8MNlDb4KQVr+RpjEJn6eCU1Icesq+oZrtdu6wDYmrcrL+KonSSuELBGBOWH0BE+mFTX3Q7qqvh9tth+RMtNLTm4yoyDPR+xHnNK/jGsEqWXvasxiikijiaQqzNUdf7i9OfcUbn+qQoSlw6Mn+vHhiT6o50Bf5pkA2teYChoREuK32D37i/CH0r4js7lfgkaD6qqbF55lpbg+vGjLGmpDYsWWJjECZPTlk3FUWJTiI+hWcJprx2AOOAJ9LZqXQRNFkETRxL3J/jD9TTUHB6xvrVo0hAKMSyMEWtStnQYKejXn99avqnKEq7JKIphGQeoxX4wBhTm6b+pBW/+ejpJ5qpby2guBhm9vknd9ddDx+2xj+AEp9UJ5F79FErYBKpn6AoSqdJJHjtQ+BNY8wrxpjXgf0iMjKtvUoTgSja1jxbda0R+no+xiCctf+p+NMilcRpR1NYv76t7MjPj1L+9Nln4ctftnalyy9HUZT0k4hQeJLwvNIe37puSV0dzDvu/1g95EobRds0gEV8n1V8hoULM927HkAc85HLBVOmtN3c0hKSLtvrtUXpZ860yz//uaavUJQuIhGhkGeMafYv+D4XpK9L6aWyEhaPX8Kkoz7g97+H5Z+e78t95GDJEjT3UWeJYz7yJ8LzU1AA/fqFpMt++WVb7ez4421pzJoamxlVUZQuIRGhsDekKA4icgWwL31dSj/ujws568OHWb0aZvf6K8UcAYKZOjWaOQXE0BT8JjyHw8YktLZaIbFnD1BfDzfdFGw8ZgyMHNkVvVUUxUciOvk8YJmI+IvS1gJRo5y7C4u2Xs2qw5N54AHoyyEaKaIo30Njo7P9TJ1KfBKYfVRXZ6PG33nH+o8Dvpz//V/44AN45RUbk+D1xjyGoijpIZHgtR3AdBHpDYgx5tP0dys9BKekWlv1kiUAN+CkldW/eoul754WO5+/khgJCIXKSlsHp6oKTjnFl97i+efhzjuttDjzTNvQkYgiqyhKKon7rxOR/xWRo4wxh40xn4pIfxH5cbz9spFAYRexeRSKi2FO/hPUUsakcS1aYCcVxPEpuFy2yZIlVhEI+HEuPsfWSvj5z7uoo4qiRCORodhFxpiD/gVjzAHg4vR1KX0EpqSaAoqczXZKquMwg6kLFoRXUkMMTcEvmP2TifLyYM6ZO6lhJNx/P5SUdF0fFUVpQyI+BaeIFBpjmgBExAUUprdb6aOuDuYV/pG5l+9hacl3cT9UBk3YaTBK54ljPho1KjwRXmsrLHt1GE9RQ8Ppai5SlEyTyL/wEeAlEfmSiHwJeBF4KL3dSh+VlbDY8TUmjTjI4sWw+Ph7OYuX2fNhc/ydlfgkMCW1rMzOOgVwOg1lzt3UnHkTFHbbsYai9BgSKbLzM+DHwFhs3qO/4889HQcRuVBEtorIdhFZ0E67q0TEiEj6cyN7vTafjq9i/KLjHraBaytOSvtX5wR+oRBj5lBpKVx6qVUkiorAeOEyz9MMnnV21/VRUZSYJKqv78FGNX8eW09hS7wdRMQJLAYuwgqT60RkXJR2fYDbgDcT7Evn8CXrd/3v963D87H+NnBtaZ4GrqWCBGYfffCBDVZ77jmYN7OOPQyCEQmNMxRFSTMxhYKIHCcid4jIFuDXwE7slNRzjDG/jrVfCNOA7caYal8U9GPAFVHaLQJ+BjRG2ZZy3NUNnMXLrP7mk3YmklUYNHAtVfinkbYjFEaOtL6dp56Cxde/QSVXWRVCUZSM056m8G+sVnCZMeYMY8x92LxHiTIUK0j81PrWBRCRKcAwY8xzSRy3Uyz6WQGrOIMH3ppsZyI1WjNGYyMauJYK2jEfRZ2OeuVMXNTrD68oWUJ7QuHzWLPRShH5rYicR2ghgvhEaxsYPoqIA/gl8M24BxKZKyJrRWTt3r17k+hCkMAD6ZG+eHGyZOVY7r/frlu9GpscT7Okdp52NIVAnEiodjZ+AzVyLBxzTBd2UlGUWMQUCsaY5caYa4ETgJeBbwCDRGSJiMxI4Ni1wLCQ5TJgd8hyH2A88LKIvA9MB56J5mw2xiw1xkw1xkwt6eA89sADqdAqO8WFrcyZA+vWwW23wfe/r4FrKaEdTSEQJ9IIRYWGxnovfT/dxeBjvMHpSIqiZJREZh8dMcYsM8Zcin2wVwExZxKFsAYYIyLlIlIAzAKeCTnuJ8aYo40xI40xI4HVwOXGmLUdOZF4BB5IzQ6KaKCx2eY5euABWLUKTZudKuL4FPx5j8YdXccNPMSeDxpg6NCobRVF6XqSihYyxnxsjHnAGHNuAm1bgVuBf2BnKz1hjNkkIgtDs652JXV1cMO5uxjHpoBtu026BZ191DniTEmtrLRmo6rdx1BMg3UyT5/ehR1UFKU90hpCaoxZYYw5zhhzrDHmJ751dxhjnonS9ux0aQl+Kiuh2NlIFVOYc8kBnX2UDtrRFMIczcbBEm5GMLh++6su7qSiKLHImXJWwQypowH407MDAtt09lEKaUdT8NfIXr7chou4qOdKKrn731eSQ7eiomQ1OZNsJuBozm8BoNhlKCuDG2/U2UcppR1Nwe/XsfGDhgZc9OUQg0cVd2kXFUWJTc4MzwKO5landTQ3FXHZZfCb39jtixdntn89hjhxCsFkeLbdEm7mD65AoLmiKBkmZzQF8GVIHfcaq/tdyLx5oppBOogTpzBzZrBJMUeYwyPqx1GULCJnNAXwxSF84Xdw5EPVDNKEe38+s3iZx/c3EumeKS2FrVutEuHEQyNF9L3gNPXjKEoWkVOagtsNZ/19AXscQzLdlR7LogeHsIozWPjYmLD1/plHmzfbZQ9OvDh54MVRGeiloiixyCmhsGgRrNp7AgsPfi3TXelxBKab/qXEphH5+6iwuI82KS6oZ87xa9m1K3N9VhSlLTkhFMLmx+NgycezNFAtxQQe+kXWwVxc0BoW9xE688ghhgYKdQqwomQhOSEUIkepYBgzRgPVUklgdleT2NldLc42D/26Ohg3zvqgx7GZPc39M9dhRVGikhOO5tJSePxx8AQSfwvbttn1RUU6HTJV1NXBvGs+Zu7j57L0s0/h3jM6sC1yOuomJrBpg12vv7+iZA85oSkAzJgBY8ZAkTQBNimnprVILZWVsPiOOiaxkcVfejss66xfW/Ob7FzUM+c8t/7+ipJl5IxQWLECzjsPmk0+RY4mjNG0FmkhRvBa1GjmAfn6+ytKlpET5iM/dXUw7+i/MHfsayydcB9ud6Z71AOJEbwWNZr5yaM1mllRsoycEgqVvzsAA64Fx1kavJYuYmgK1dVw1lmwbZtdLuYIM68t5O57cuoWVJSsJ2fMR4ANVAB45ZXM9qMnE0VTcLlgyJCgQACopxeP/SVPzUeKkmXkllB4//1M96DnE0VT8DuZ/TjwMMa5gxmJFHVVFKVLyS3dvaAg0z3o+URoCm43lJWFW5O8ONnmOZadKzPQP0VR2iW3NIXevTPdg55PhKawaFHMypyxyjgripJBckso5OfjZjBn8bKmzU4XPk3B9dUbAqlF2mIY03u3WvMUJQvJLaHg8bCI77NKzmThwkx3pofi0xSq//fxiNQiYY3YdngI5eVd2jNFURIgZ3wKdp78Urtg7Ah2yRJNc5FyfJpCab96+vaF+vpYDQ01NdJl3VIUJTFyRlOorobZ5f+iWKwEKC7WNBdpIcSnUFdna2BfdFFoAwMYbjx5i05HVZQsJGc0hdJS6Ousp9EUUlRko2s1zUUaCJl95M99NH9+eJMK3uWQ6de1/VIUJSHSKhRE5ELgV4ATeNAYc2fE9nnALYAHOAzMNcZsTld/Pjg8kEHOvTz83CAqK9E0F+kgYvZReHoL8GdI3bHB02ZXRVEyT9rMRyLiBBYDFwHjgOtEZFxEs0eNMROMMZOBnwG/SFd/AEa66qjzlPDUU7B4MWFZPJUU4RcKvvmmbSquFbYyh0eoeeadDHVQUZT2SKdPYRqw3RhTbYxpBh4DrghtYIw5FLLYC2twTjmByms1F9rKa0vQymvpwm8+8mkKYRXXHNDQ5KQvhxg88ZgMdlJRlFikUygMBXaGLNf61oUhIreIyA6spnBbOjoSGK06rB1DncxpJEJTgNCKa4ZxvMse51CbDElRlKwjnT6FaPMN22gCxpjFwGIRmQ18D7ixzYFE5gJzAYYPH550RwKlIr0FFEkTjY1aHzhtRKS5iFpxzTNBK64pSpaSTk2hFhgWslwG7G6n/WPA56JtMMYsNcZMNcZMLSkp6VBn6upgXtlzrJ7wFebNQyOa00WEo7m6GmbODMqKYo4w56ydqqUpSpaSTk1hDTBGRMqBXcAsYHZoAxEZY4zxJ1S+BNhGmqisBM69B1patJZCOgnRFNxumDXLCmCvF5wOL43eIvoe41ItTVGylLQJBWNMq4jcCvwDOyX198aYTSKyEFhrjHkGuFVEzgdagANEMR2lFI8H8nImNCMzhGgKw4bZn9yPx2sFxgNPDeQ3GeiaoijxSesT0hizAlgRse6OkM9fT+f3t6G1VaccpRuHAxf1NP53tN/ZMCf/Se7+8Jou75aiKImRM2kuACsUVFNILyJUM4rZkzdFlb/q4FeU7Ca3hIKaj9KPw0Epe+hb2BRldpGwZP81qqwpShaTW0KhtRWczkz3omcjgot67n/zxCgbDXOOW6MzjxQli8ktoaCaQvpxOHiD6UQPThce23aSmo8UJYvJrSekagrpR4SlfDXKBkM5Ozhhoosoge2KomQJuScUVFNIGzZ6OQ+4Oer2YhpYcZ8bFQqKkr2o+UhJGdXVMPs6QzFHomy1KS7kzM+oo1lRspicEgrupgGc9cJ3NMVFmigthb79hAaKEGyai/LyiBQXszzqaFaULCanhMKig19jVd1xLFyY6Z70XOrqYBybAaGiwvCRuxWv1+AUL40U0be/Ux3NipLFiDFpKWGQNqZOnWrWrl2b1D5tq39Zioo0U2cqifU7h+JwhKe+UBSlaxCRdcaYqfHa5YSmEKinQD2g9RTShf93dvl+52jk53dhhxRFSZqcEAqBegoUUuRsobFR0y2kg0CVNWJ5kg3vv9+VPVIUJVlyZipOXR3My/sdc687xNI+t+N2Z7pHPY+g+SiyvpI1UQ4vaWDw4OKu7paiKEmQM0KhshJwfR1Kb2PxTzPdm55JdTWUlQXq64QggJeTpuaEYqoo3Zrc+pdqRHNaKS21vhrwEkxz4WUMW7ko759U/q0wc51TFCUhckZTADR4rQt4+GEIH2s42MbxbGs9LliAR1GUrCV3NAWv1xaTV00hraxf75995NcUDC4Os+Gib2eyW4qiJEjuCIXWVvuumkJamTwZyvNrfUtWMIyihonTijLXKUVREiZ3hII/YkqFQto5YPpRwbs8zjVU8C4fMwCOOSbT3VIUJQFy5wnp1xTUfJR2do+/EKqqALjm2PUwYABc/bcM90pRlERQTUFJPaFhyyeeCG+9BSUlmeuPoigJkztCQTWFrqOgIKEf2TQAAAlBSURBVPi5d+/M9UNRlKTJPaGgmkL6CdUUevXKXD8URUmatAoFEblQRLaKyHYRWRBl+3+JyGYR2SgiL4nIiLR1Rs1HXceZZwY/q1BQlG5F2oSCiDiBxcBFwDjgOhEZF9FsPTDVGDMR+Avws3T1R81HXcgddwQ/q/lIUboV6dQUpgHbjTHVxphm4DHgitAGxpiVxhh/nuXVQFnaeqOaQtfhdMLo0fazagqK0q1Ip1AYCuwMWa6l/YrtXwKeT1tvVFPoWpqa7LtqCorSrUjnsDlaopuoZd5E5HpgKnBWjO1zgbkAw4cP71hv1NHctezda98HDMhsPxRFSYp0agq1wLCQ5TJgd2QjETkf+C5wuTGmKdqBjDFLjTFTjTFTSzo6372lxb5r6a+u4ZJL7Pvpp2e2H4qiJEU6hcIaYIyIlItIATALeCa0gYhMAR7ACoSP0tiXoKagQqFrWLYMNmzQ8naK0s1Im1AwxrQCtwL/ALYATxhjNonIQhG53NfsLqA38KSIVInIMzEO13n8moKaj7qGwkKYODHTvVAUJUnS+oQ0xqwAVkSsuyPk8/np/P4wVFNQFEWJS+5ENKumoCiKEpfcEwqqKSiKosQkd4SCTklVFEWJS+4IBdUUFEVR4pI7QkEdzYqiKHHJHaGgjmZFUZS45J5QUE1BURQlJrkjFNTRrCiKEpecEQrufXmcxcvsOVCY6a4oiqJkLTkjFBY9O5lVnMHCe/tluiuKoihZS48XCi4XiMCS1ybgxcmSPxYjYtcriqIo4fR4oVBdDbNnQ3G+dTQXuwxz5kBNTYY7piiKkoX0eKFQWgp9+0Jjax5FjmYam+yyZnRWFEVpS48XCgB1dTBvvrD67QLmzRP27Ml0jxRFUbKTnJifWVkZ/Lx4ceb6oSiKku3khKagKIqiJIYKBUVRFCWACgVFURQlgAoFRVEUJYAKBUVRFCWACgVFURQlgAoFRVEUJYAYYzLdh6QQkb3ABx3c/WhgXwq70x3Qc84N9Jxzg86c8whjTEm8Rt1OKHQGEVlrjJma6X50JXrOuYGec27QFees5iNFURQlgAoFRVEUJUCuCYWlme5ABtBzzg30nHODtJ9zTvkUFEVRlPbJNU1BURRFaYecEQoicqGIbBWR7SKyINP9SRUiMkxEVorIFhHZJCJf960fICIvisg233t/33oRkXt9v8NGETkxs2fQMUTEKSLrReQ533K5iLzpO9/HRaTAt77Qt7zdt31kJvvdUUTkKBH5i4j823etT82Ba/wN3z39roj8WUSKeuJ1FpHfi8hHIvJuyLqkr62I3Ohrv01Ebuxof3JCKIiIE1gMXASMA64TkXGZ7VXKaAW+aYwZC0wHbvGd2wLgJWPMGOAl3zLY32CM7zUXWNL1XU4JXwe2hCz/FPil73wPAF/yrf8ScMAYMxr4pa9dd+RXwN+NMScAk7Dn3mOvsYgMBW4DphpjxgNOYBY98zr/EbgwYl1S11ZEBgA/AE4BpgE/8AuSpDHG9PgXcCrwj5DlbwPfznS/0nSufwU+C2wFSn3rSoGtvs8PANeFtA+06y4voMz3RzkXeA4QbEBPXuT1Bv4BnOr7nOdrJ5k+hyTPty9QE9nvHn6NhwI7gQG+6/YccEFPvc7ASODdjl5b4DrggZD1Ye2SeeWEpkDwBvNT61vXo/CpzFOAN4FBxhg3gO/9GF+znvBb3AP8D+D1LQ8EDhpjWn3LoecUOF/f9k987bsTo4C9wB98JrMHRaQXPfgaG2N2AXcDHwJu7HVbR8++zqEke21Tds1zRShIlHU9atqViPQGngL+0xhzqL2mUdZ1m99CRC4FPjLGrAtdHaWpSWBbdyEPOBFYYoyZAhwhaE6IRrc/Z5/p4wqgHBgC9MKaTiLpSdc5EWKdZ8rOP1eEQi0wLGS5DNidob6kHBHJxwqEZcYYf0XqOhEp9W0vBT7yre/uv8XpwOUi8j7wGNaEdA9wlIj4a46HnlPgfH3b+wEfd2WHU0AtUGuMedO3/BeskOip1xjgfKDGGLPXGNMCVAKn0bOvcyjJXtuUXfNcEQprgDG+mQsFWIfVMxnuU0oQEQF+B2wxxvwiZNMzgH8Gwo1YX4N//Rd8sximA5/41dTugDHm28aYMmPMSOx1/D9jzBxgJXCVr1nk+fp/h6t87bvVCNIYswfYKSLH+1adB2ymh15jHx8C00Wk2HeP+8+5x17nCJK9tv8AZohIf5+WNcO3Lnky7WDpQkfOxcB7wA7gu5nuTwrP6wysmrgRqPK9LsbaU18CtvneB/jaC3Ym1g7gHezsjoyfRwfP/WzgOd/nUcBbwHbgSaDQt77It7zdt31UpvvdwXOdDKz1Xeengf49/RoDPwL+DbwLPAwU9sTrDPwZ6zdpwY74v9SRawt80Xf+24H/6Gh/NKJZURRFCZAr5iNFURQlAVQoKIqiKAFUKCiKoigBVCgoiqIoAVQoKIqiKAFUKCg5i4j8y/c+UkRmp/jY34n2XYqS7eiUVCXnEZGzgduNMZcmsY/TGONpZ/thY0zvVPRPUboS1RSUnEVEDvs+3gl8RkSqfDn8nSJyl4is8eWs/6qv/dlia1c8ig0cQkSeFpF1vrz/c33r7gRcvuMtC/0uXyTqXb4aAe+IyLUhx35ZgjUTlvkieRWlS8mL30RRejwLCNEUfA/3T4wxJ4tIIfC6iLzgazsNGG+MqfEtf9EY87GIuIA1IvKUMWaBiNxqjJkc5buuxEYnTwKO9u3zqm/bFKACm7PmdWyep1WpP11FiY1qCorSlhnY/DJV2DTkA7FFTQDeChEIALeJyAZgNTYh2Rja5wzgz8YYjzGmDngFODnk2LXGGC82XcnIlJyNoiSBagqK0hYBvmaMCUso5vM9HIlYPh9b3KVeRF7G5uCJd+xYNIV89qD/TyUDqKagKPAp0Cdk+R/AfF9KckTkOF9Rm0j6YUtA1ovICdhyqH5a/PtH8Cpwrc9vUQKciU3gpihZgY5EFMVmHm31mYH+iK2HPBJ42+fs3Qt8Lsp+fwfmichGbFnE1SHblgIbReRtY1N7+1mOLSO5AZvd9n+MMXt8QkVRMo5OSVUURVECqPlIURRFCaBCQVEURQmgQkFRFEUJoEJBURRFCaBCQVEURQmgQkFRFEUJoEJBURRFCaBCQVEURQnw/wGXqj9HH5yoIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.plot(np.array(train_acc), 'r-', valid_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/har-lstm.ckpt\n",
      "Epoch: 999/1000 Test loss: 0.5031494498252869 Test acc: 0.6679166555404663\n"
     ]
    }
   ],
   "source": [
    "loss, acc = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "\n",
    "    # Loop over test batches\n",
    "    state = sess.run(initial_state)\n",
    "    acc_batch, loss_batch = [], []\n",
    "    for Xbatch, Ybatch in get_batches(Xtest, Ytest, batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed_dict = {inputs_: Xbatch, indices_: Ybatch, initial_state: state}\n",
    "        loss, state, acc = sess.run([cost, final_state, accuracy], feed_dict)\n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Print at each epoch/iteration\n",
    "    print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "          \"Test loss: {}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

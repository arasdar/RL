{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAR classification \n",
    "# Author: Burak Himmetoglu\n",
    "# 8/15/2017\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_data(data_path, split = \"train\"):\n",
    "\t\"\"\" Read data \"\"\"\n",
    "\n",
    "\t# Fixed params\n",
    "\tn_class = 6\n",
    "\tn_steps = 128\n",
    "\n",
    "\t# Paths\n",
    "\tpath_ = os.path.join(data_path, split)\n",
    "\tpath_signals = os.path.join(path_, \"Inertial_Signals\")\n",
    "\n",
    "\t# Read labels and one-hot encode\n",
    "\tlabel_path = os.path.join(path_, \"y_\" + split + \".txt\")\n",
    "\tlabels = pd.read_csv(label_path, header = None)\n",
    "\n",
    "\t# Read time-series data\n",
    "\tchannel_files = os.listdir(path_signals)\n",
    "\tchannel_files.sort()\n",
    "\tn_channels = len(channel_files)\n",
    "\tposix = len(split) + 5\n",
    "\n",
    "\t# Initiate array\n",
    "\tlist_of_channels = []\n",
    "\tX = np.zeros((len(labels), n_steps, n_channels))\n",
    "\ti_ch = 0\n",
    "\tfor fil_ch in channel_files:\n",
    "\t\tchannel_name = fil_ch[:-posix]\n",
    "\t\tdat_ = pd.read_csv(os.path.join(path_signals,fil_ch), delim_whitespace = True, header = None)\n",
    "\t\tX[:,:,i_ch] = dat_.as_matrix()\n",
    "\n",
    "\t\t# Record names\n",
    "\t\tlist_of_channels.append(channel_name)\n",
    "\n",
    "\t\t# iterate\n",
    "\t\ti_ch += 1\n",
    "\n",
    "\t# Return \n",
    "\treturn X, labels[0].values, list_of_channels\n",
    "\n",
    "# def standardize(train, test):\n",
    "# \t\"\"\" Standardize data \"\"\"\n",
    "\n",
    "# \t# Standardize train and test\n",
    "# \tX_train = (train - np.mean(train, axis=0)[None,:,:]) / np.std(train, axis=0)[None,:,:]\n",
    "# \tX_test = (test - np.mean(test, axis=0)[None,:,:]) / np.std(test, axis=0)[None,:,:]\n",
    "\n",
    "# \treturn X_train, X_test\n",
    "\n",
    "# def one_hot(labels, n_class = 6):\n",
    "# \t\"\"\" One-hot encoding \"\"\"\n",
    "# \texpansion = np.eye(n_class)\n",
    "# \ty = expansion[:, labels-1].T\n",
    "# \tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "# \treturn y\n",
    "\n",
    "def get_batches(X, y, batch_size = 100):\n",
    "\t\"\"\" Return a generator for batches \"\"\"\n",
    "\tn_batches = len(X) // batch_size\n",
    "\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "\t# Loop over batches and yield\n",
    "\tfor b in range(0, len(X), batch_size):\n",
    "\t\tyield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/ipykernel_launcher.py:37: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain, list_ch_train = read_data(data_path=\"/home/arasdar/datasets/har-data/\", split=\"train\") # train\n",
    "Xtest, Ytest, list_ch_test = read_data(data_path=\"/home/arasdar/datasets/har-data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize\n",
    "# X_train, X_test = standardize(X_train, X_test)\n",
    "# print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, stratify = Ytrain, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5514, 128, 9) float64\n",
      "(1838, 128, 9) float64\n",
      "(2947, 128, 9) float64\n",
      "(5514,) int64\n",
      "(1838,) int64\n",
      "(2947,) int64\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape, Xtrain.dtype)\n",
    "print(Xvalid.shape, Xvalid.dtype)\n",
    "print(Xtest.shape, Xtest.dtype)\n",
    "print(Ytrain.shape, Ytrain.dtype)\n",
    "print(Yvalid.shape, Yvalid.dtype)\n",
    "print(Ytest.shape, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tr = one_hot(lab_tr)\n",
    "# y_vld = one_hot(lab_vld)\n",
    "# y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 1        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "# with graph.as_default():\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "indices_ = tf.placeholder(tf.int32, [None], name = 'indices')\n",
    "#     keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "#     learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 9)\n",
      "(128, ?, 9)\n",
      "(?, 9)\n",
      "128 (?, 9)\n"
     ]
    }
   ],
   "source": [
    "# with graph.as_default():\n",
    "# Construct the LSTM inputs and LSTM cells\n",
    "print(inputs_.shape)\n",
    "lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "print(lstm_in.shape)\n",
    "lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "print(lstm_in.shape)\n",
    "\n",
    "# Open up the tensor into a list of seq_len pieces\n",
    "lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "print(len(lstm_in), lstm_in[0].shape)\n",
    "\n",
    "# Add LSTM layers\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "#     drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([lstm] * lstm_layers)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with graph.as_default():\n",
    "# with tf.variable_scope('RNN', reuse=True):\n",
    "outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32, initial_state = initial_state)\n",
    "\n",
    "# We only need the last output tensor to pass into a classifier\n",
    "logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "labels = tf.one_hot(depth=n_classes, indices=indices_)\n",
    "\n",
    "# Loss/cost using labels and logits\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "\n",
    "# Accuracy using logits and labels\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "# Optimize using loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost) # No grad clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 (600, 27)\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs), outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"logits/BiasAdd:0\", shape=(600, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Train loss: 1.439217448234558 Train acc: 0.1461111158132553\n",
      "Epoch: 0/1000 Valid loss: 1.4121150970458984 Valid acc: 0.1505555510520935\n",
      "Epoch: 1/1000 Train loss: 1.3941774368286133 Train acc: 0.19925925135612488\n",
      "Epoch: 1/1000 Valid loss: 1.3711084127426147 Valid acc: 0.25333333015441895\n",
      "Epoch: 2/1000 Train loss: 1.3531736135482788 Train acc: 0.2812963128089905\n",
      "Epoch: 2/1000 Valid loss: 1.3281340599060059 Valid acc: 0.30444446206092834\n",
      "Epoch: 3/1000 Train loss: 1.3050353527069092 Train acc: 0.3361111283302307\n",
      "Epoch: 3/1000 Valid loss: 1.2717067003250122 Valid acc: 0.3611111342906952\n",
      "Epoch: 4/1000 Train loss: 1.2444381713867188 Train acc: 0.3409259021282196\n",
      "Epoch: 4/1000 Valid loss: 1.2054648399353027 Valid acc: 0.3188888728618622\n",
      "Epoch: 5/1000 Train loss: 1.191493272781372 Train acc: 0.3248148262500763\n",
      "Epoch: 5/1000 Valid loss: 1.1501469612121582 Valid acc: 0.35500001907348633\n",
      "Epoch: 6/1000 Train loss: 1.1383728981018066 Train acc: 0.3714815080165863\n",
      "Epoch: 6/1000 Valid loss: 1.1008435487747192 Valid acc: 0.38277778029441833\n",
      "Epoch: 7/1000 Train loss: 1.0869498252868652 Train acc: 0.3866666555404663\n",
      "Epoch: 7/1000 Valid loss: 1.0611251592636108 Valid acc: 0.39666667580604553\n",
      "Epoch: 8/1000 Train loss: 1.0335397720336914 Train acc: 0.4103703796863556\n",
      "Epoch: 8/1000 Valid loss: 1.0015106201171875 Valid acc: 0.42666664719581604\n",
      "Epoch: 9/1000 Train loss: 0.9759945273399353 Train acc: 0.44111111760139465\n",
      "Epoch: 9/1000 Valid loss: 0.9394819140434265 Valid acc: 0.4577777683734894\n",
      "Epoch: 10/1000 Train loss: 0.9407131671905518 Train acc: 0.4568518400192261\n",
      "Epoch: 10/1000 Valid loss: 0.9117367267608643 Valid acc: 0.448888897895813\n",
      "Epoch: 11/1000 Train loss: 0.8850787281990051 Train acc: 0.47074073553085327\n",
      "Epoch: 11/1000 Valid loss: 0.8599420189857483 Valid acc: 0.4888888895511627\n",
      "Epoch: 12/1000 Train loss: 0.852165699005127 Train acc: 0.4814814329147339\n",
      "Epoch: 12/1000 Valid loss: 0.8381139636039734 Valid acc: 0.5049999952316284\n",
      "Epoch: 13/1000 Train loss: 0.8176630735397339 Train acc: 0.5140740871429443\n",
      "Epoch: 13/1000 Valid loss: 0.8066802024841309 Valid acc: 0.5294444561004639\n",
      "Epoch: 14/1000 Train loss: 0.7858066558837891 Train acc: 0.5290740728378296\n",
      "Epoch: 14/1000 Valid loss: 0.7693861126899719 Valid acc: 0.5416666865348816\n",
      "Epoch: 15/1000 Train loss: 0.7555534839630127 Train acc: 0.5538888573646545\n",
      "Epoch: 15/1000 Valid loss: 0.7537477016448975 Valid acc: 0.5450000166893005\n",
      "Epoch: 16/1000 Train loss: 0.7458203434944153 Train acc: 0.5537036657333374\n",
      "Epoch: 16/1000 Valid loss: 0.7356789708137512 Valid acc: 0.5588889122009277\n",
      "Epoch: 17/1000 Train loss: 0.7218276262283325 Train acc: 0.5627777576446533\n",
      "Epoch: 17/1000 Valid loss: 0.7254769802093506 Valid acc: 0.5638888478279114\n",
      "Epoch: 18/1000 Train loss: 0.7462777495384216 Train acc: 0.5351852178573608\n",
      "Epoch: 18/1000 Valid loss: 0.7635164260864258 Valid acc: 0.5244444012641907\n",
      "Epoch: 19/1000 Train loss: 0.9831074476242065 Train acc: 0.4224074184894562\n",
      "Epoch: 19/1000 Valid loss: 1.0560795068740845 Valid acc: 0.38722220063209534\n",
      "Epoch: 20/1000 Train loss: 0.9713218212127686 Train acc: 0.4131481647491455\n",
      "Epoch: 20/1000 Valid loss: 0.9734167456626892 Valid acc: 0.40833333134651184\n",
      "Epoch: 21/1000 Train loss: 0.8973851799964905 Train acc: 0.4444444477558136\n",
      "Epoch: 21/1000 Valid loss: 0.8662047982215881 Valid acc: 0.43611112236976624\n",
      "Epoch: 22/1000 Train loss: 0.8702836632728577 Train acc: 0.44240739941596985\n",
      "Epoch: 22/1000 Valid loss: 0.8329775333404541 Valid acc: 0.46388888359069824\n",
      "Epoch: 23/1000 Train loss: 0.8113837242126465 Train acc: 0.47962963581085205\n",
      "Epoch: 23/1000 Valid loss: 0.8073520660400391 Valid acc: 0.47333332896232605\n",
      "Epoch: 24/1000 Train loss: 0.7897903323173523 Train acc: 0.48000001907348633\n",
      "Epoch: 24/1000 Valid loss: 0.7869073748588562 Valid acc: 0.46611109375953674\n",
      "Epoch: 25/1000 Train loss: 0.7726831436157227 Train acc: 0.48537036776542664\n",
      "Epoch: 25/1000 Valid loss: 0.7709372043609619 Valid acc: 0.48777779936790466\n",
      "Epoch: 26/1000 Train loss: 0.762340784072876 Train acc: 0.5051851272583008\n",
      "Epoch: 26/1000 Valid loss: 0.7628268599510193 Valid acc: 0.4950000047683716\n",
      "Epoch: 27/1000 Train loss: 0.752081573009491 Train acc: 0.5079629421234131\n",
      "Epoch: 27/1000 Valid loss: 0.7553601861000061 Valid acc: 0.4933333396911621\n",
      "Epoch: 28/1000 Train loss: 0.7419586181640625 Train acc: 0.5153703689575195\n",
      "Epoch: 28/1000 Valid loss: 0.7510571479797363 Valid acc: 0.49888888001441956\n",
      "Epoch: 29/1000 Train loss: 0.7365360856056213 Train acc: 0.5201852321624756\n",
      "Epoch: 29/1000 Valid loss: 0.7395003437995911 Valid acc: 0.504444420337677\n",
      "Epoch: 30/1000 Train loss: 0.7267300486564636 Train acc: 0.5246296525001526\n",
      "Epoch: 30/1000 Valid loss: 0.7320963740348816 Valid acc: 0.5038889050483704\n",
      "Epoch: 31/1000 Train loss: 0.7152900099754333 Train acc: 0.5325925350189209\n",
      "Epoch: 31/1000 Valid loss: 0.7255713939666748 Valid acc: 0.5244444012641907\n",
      "Epoch: 32/1000 Train loss: 0.70718914270401 Train acc: 0.5377777814865112\n",
      "Epoch: 32/1000 Valid loss: 0.715287983417511 Valid acc: 0.5361111164093018\n",
      "Epoch: 33/1000 Train loss: 0.6974865198135376 Train acc: 0.5514814853668213\n",
      "Epoch: 33/1000 Valid loss: 0.707089900970459 Valid acc: 0.5461111068725586\n",
      "Epoch: 34/1000 Train loss: 0.6885955929756165 Train acc: 0.5605555772781372\n",
      "Epoch: 34/1000 Valid loss: 0.699308454990387 Valid acc: 0.5577778220176697\n",
      "Epoch: 35/1000 Train loss: 0.6806566119194031 Train acc: 0.5699999928474426\n",
      "Epoch: 35/1000 Valid loss: 0.6918603777885437 Valid acc: 0.5616666674613953\n",
      "Epoch: 36/1000 Train loss: 0.6738021373748779 Train acc: 0.5707407593727112\n",
      "Epoch: 36/1000 Valid loss: 0.6832926869392395 Valid acc: 0.5638888478279114\n",
      "Epoch: 37/1000 Train loss: 0.6634619832038879 Train acc: 0.5766666531562805\n",
      "Epoch: 37/1000 Valid loss: 0.6751449704170227 Valid acc: 0.5727777481079102\n",
      "Epoch: 38/1000 Train loss: 0.6528189778327942 Train acc: 0.5881481766700745\n",
      "Epoch: 38/1000 Valid loss: 0.665012776851654 Valid acc: 0.5799999833106995\n",
      "Epoch: 39/1000 Train loss: 0.6442078948020935 Train acc: 0.5959259867668152\n",
      "Epoch: 39/1000 Valid loss: 0.6558248400688171 Valid acc: 0.5844444632530212\n",
      "Epoch: 40/1000 Train loss: 0.6352526545524597 Train acc: 0.5994445085525513\n",
      "Epoch: 40/1000 Valid loss: 0.6494258046150208 Valid acc: 0.5777778029441833\n",
      "Epoch: 41/1000 Train loss: 0.6252932548522949 Train acc: 0.6024073958396912\n",
      "Epoch: 41/1000 Valid loss: 0.6293396353721619 Valid acc: 0.5972222685813904\n",
      "Epoch: 42/1000 Train loss: 0.6119515299797058 Train acc: 0.6087037324905396\n",
      "Epoch: 42/1000 Valid loss: 0.6376191973686218 Valid acc: 0.5933333039283752\n",
      "Epoch: 43/1000 Train loss: 0.6092466711997986 Train acc: 0.609259307384491\n",
      "Epoch: 43/1000 Valid loss: 0.6094472408294678 Valid acc: 0.6050000190734863\n",
      "Epoch: 44/1000 Train loss: 0.5945833921432495 Train acc: 0.6122222542762756\n",
      "Epoch: 44/1000 Valid loss: 0.6112724542617798 Valid acc: 0.5861111283302307\n",
      "Epoch: 45/1000 Train loss: 0.5974707007408142 Train acc: 0.5983333587646484\n",
      "Epoch: 45/1000 Valid loss: 0.6094375252723694 Valid acc: 0.587222158908844\n",
      "Epoch: 46/1000 Train loss: 0.5901401042938232 Train acc: 0.6107407212257385\n",
      "Epoch: 46/1000 Valid loss: 0.604360818862915 Valid acc: 0.5999999642372131\n",
      "Epoch: 47/1000 Train loss: 0.5807134509086609 Train acc: 0.6150000095367432\n",
      "Epoch: 47/1000 Valid loss: 0.5856380462646484 Valid acc: 0.6155555844306946\n",
      "Epoch: 48/1000 Train loss: 0.5694105625152588 Train acc: 0.6209259629249573\n",
      "Epoch: 48/1000 Valid loss: 0.5808818936347961 Valid acc: 0.6094444394111633\n",
      "Epoch: 49/1000 Train loss: 0.5604363083839417 Train acc: 0.6224073767662048\n",
      "Epoch: 49/1000 Valid loss: 0.5846365094184875 Valid acc: 0.597777783870697\n",
      "Epoch: 50/1000 Train loss: 0.5654491782188416 Train acc: 0.6114814281463623\n",
      "Epoch: 50/1000 Valid loss: 0.5782787799835205 Valid acc: 0.6016666889190674\n",
      "Epoch: 51/1000 Train loss: 0.5553894639015198 Train acc: 0.6211110949516296\n",
      "Epoch: 51/1000 Valid loss: 0.5699287056922913 Valid acc: 0.6061111092567444\n",
      "Epoch: 52/1000 Train loss: 0.5540308356285095 Train acc: 0.6188889145851135\n",
      "Epoch: 52/1000 Valid loss: 0.5600228309631348 Valid acc: 0.6127777695655823\n",
      "Epoch: 53/1000 Train loss: 0.548015832901001 Train acc: 0.6251851916313171\n",
      "Epoch: 53/1000 Valid loss: 0.5474540591239929 Valid acc: 0.6194444298744202\n",
      "Epoch: 54/1000 Train loss: 0.5393568873405457 Train acc: 0.6294444799423218\n",
      "Epoch: 54/1000 Valid loss: 0.5567045211791992 Valid acc: 0.6322222352027893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/1000 Train loss: 0.5331711173057556 Train acc: 0.6379629969596863\n",
      "Epoch: 55/1000 Valid loss: 0.5382387042045593 Valid acc: 0.620555579662323\n",
      "Epoch: 56/1000 Train loss: 0.5319458842277527 Train acc: 0.6281481981277466\n",
      "Epoch: 56/1000 Valid loss: 0.5405706763267517 Valid acc: 0.6333333253860474\n",
      "Epoch: 57/1000 Train loss: 0.5184677243232727 Train acc: 0.6370370388031006\n",
      "Epoch: 57/1000 Valid loss: 0.536198079586029 Valid acc: 0.6377777457237244\n",
      "Epoch: 58/1000 Train loss: 0.5206047892570496 Train acc: 0.6320370435714722\n",
      "Epoch: 58/1000 Valid loss: 0.5214328765869141 Valid acc: 0.6383333206176758\n",
      "Epoch: 59/1000 Train loss: 0.5073747038841248 Train acc: 0.6412963271141052\n",
      "Epoch: 59/1000 Valid loss: 0.5114033818244934 Valid acc: 0.6277777552604675\n",
      "Epoch: 60/1000 Train loss: 0.49829113483428955 Train acc: 0.6348148584365845\n",
      "Epoch: 60/1000 Valid loss: 0.5188214182853699 Valid acc: 0.6194444298744202\n",
      "Epoch: 61/1000 Train loss: 0.49408209323883057 Train acc: 0.6355555057525635\n",
      "Epoch: 61/1000 Valid loss: 0.5017619729042053 Valid acc: 0.6311110854148865\n",
      "Epoch: 62/1000 Train loss: 0.48726946115493774 Train acc: 0.6483333110809326\n",
      "Epoch: 62/1000 Valid loss: 0.49507203698158264 Valid acc: 0.6466667056083679\n",
      "Epoch: 63/1000 Train loss: 0.479952335357666 Train acc: 0.6498148441314697\n",
      "Epoch: 63/1000 Valid loss: 0.4847158193588257 Valid acc: 0.6433333158493042\n",
      "Epoch: 64/1000 Train loss: 0.47520849108695984 Train acc: 0.6512963175773621\n",
      "Epoch: 64/1000 Valid loss: 0.4871000051498413 Valid acc: 0.64000004529953\n",
      "Epoch: 65/1000 Train loss: 0.4724689722061157 Train acc: 0.6551851630210876\n",
      "Epoch: 65/1000 Valid loss: 0.4926368296146393 Valid acc: 0.6405555605888367\n",
      "Epoch: 66/1000 Train loss: 0.48021644353866577 Train acc: 0.6492592692375183\n",
      "Epoch: 66/1000 Valid loss: 0.48891106247901917 Valid acc: 0.6366666555404663\n",
      "Epoch: 67/1000 Train loss: 0.5020989775657654 Train acc: 0.6349999904632568\n",
      "Epoch: 67/1000 Valid loss: 0.5678407549858093 Valid acc: 0.5988888740539551\n",
      "Epoch: 68/1000 Train loss: 0.5220115184783936 Train acc: 0.6320369839668274\n",
      "Epoch: 68/1000 Valid loss: 0.5020056366920471 Valid acc: 0.6355555653572083\n",
      "Epoch: 69/1000 Train loss: 0.5016712546348572 Train acc: 0.6377778053283691\n",
      "Epoch: 69/1000 Valid loss: 0.5120479464530945 Valid acc: 0.621666669845581\n",
      "Epoch: 70/1000 Train loss: 0.4982237219810486 Train acc: 0.6331481337547302\n",
      "Epoch: 70/1000 Valid loss: 0.4970199167728424 Valid acc: 0.6322222352027893\n",
      "Epoch: 71/1000 Train loss: 0.48381173610687256 Train acc: 0.6309258937835693\n",
      "Epoch: 71/1000 Valid loss: 0.494060754776001 Valid acc: 0.6211110949516296\n",
      "Epoch: 72/1000 Train loss: 0.46907296776771545 Train acc: 0.6461111307144165\n",
      "Epoch: 72/1000 Valid loss: 0.4792293310165405 Valid acc: 0.6405555605888367\n",
      "Epoch: 73/1000 Train loss: 0.46142420172691345 Train acc: 0.6533333659172058\n",
      "Epoch: 73/1000 Valid loss: 0.4754696786403656 Valid acc: 0.6455555558204651\n",
      "Epoch: 74/1000 Train loss: 0.4545861780643463 Train acc: 0.6572222113609314\n",
      "Epoch: 74/1000 Valid loss: 0.4559776782989502 Valid acc: 0.6566666960716248\n",
      "Epoch: 75/1000 Train loss: 0.4456208050251007 Train acc: 0.6618518233299255\n",
      "Epoch: 75/1000 Valid loss: 0.4627216160297394 Valid acc: 0.6427778005599976\n",
      "Epoch: 76/1000 Train loss: 0.4435842037200928 Train acc: 0.6631481647491455\n",
      "Epoch: 76/1000 Valid loss: 0.4517761766910553 Valid acc: 0.6516666412353516\n",
      "Epoch: 77/1000 Train loss: 0.4359866678714752 Train acc: 0.6625926494598389\n",
      "Epoch: 77/1000 Valid loss: 0.4560154378414154 Valid acc: 0.6500000357627869\n",
      "Epoch: 78/1000 Train loss: 0.44001758098602295 Train acc: 0.6616666316986084\n",
      "Epoch: 78/1000 Valid loss: 0.4474398195743561 Valid acc: 0.6544444561004639\n",
      "Epoch: 79/1000 Train loss: 0.42964059114456177 Train acc: 0.6694444417953491\n",
      "Epoch: 79/1000 Valid loss: 0.44376954436302185 Valid acc: 0.6566666960716248\n",
      "Epoch: 80/1000 Train loss: 0.42548394203186035 Train acc: 0.6653703451156616\n",
      "Epoch: 80/1000 Valid loss: 0.44696807861328125 Valid acc: 0.6544443964958191\n",
      "Epoch: 81/1000 Train loss: 0.42430126667022705 Train acc: 0.6712962985038757\n",
      "Epoch: 81/1000 Valid loss: 0.44159626960754395 Valid acc: 0.6644444465637207\n",
      "Epoch: 82/1000 Train loss: 0.4210675358772278 Train acc: 0.6733333468437195\n",
      "Epoch: 82/1000 Valid loss: 0.43143853545188904 Valid acc: 0.6694445013999939\n",
      "Epoch: 83/1000 Train loss: 0.42152664065361023 Train acc: 0.6724073886871338\n",
      "Epoch: 83/1000 Valid loss: 0.43513116240501404 Valid acc: 0.6688888669013977\n",
      "Epoch: 84/1000 Train loss: 0.4088619649410248 Train acc: 0.6796296238899231\n",
      "Epoch: 84/1000 Valid loss: 0.42935243248939514 Valid acc: 0.666111171245575\n",
      "Epoch: 85/1000 Train loss: 0.41068506240844727 Train acc: 0.6742592453956604\n",
      "Epoch: 85/1000 Valid loss: 0.4307168424129486 Valid acc: 0.6633333563804626\n",
      "Epoch: 86/1000 Train loss: 0.4073474407196045 Train acc: 0.6772222518920898\n",
      "Epoch: 86/1000 Valid loss: 0.43404221534729004 Valid acc: 0.6577777862548828\n",
      "Epoch: 87/1000 Train loss: 0.4126027822494507 Train acc: 0.6725925803184509\n",
      "Epoch: 87/1000 Valid loss: 0.4413067102432251 Valid acc: 0.6483333110809326\n",
      "Epoch: 88/1000 Train loss: 0.42165571451187134 Train acc: 0.6727778315544128\n",
      "Epoch: 88/1000 Valid loss: 0.43626511096954346 Valid acc: 0.6711111068725586\n",
      "Epoch: 89/1000 Train loss: 0.4550643563270569 Train acc: 0.6503703594207764\n",
      "Epoch: 89/1000 Valid loss: 0.47963473200798035 Valid acc: 0.6266666650772095\n",
      "Epoch: 90/1000 Train loss: 0.4449126422405243 Train acc: 0.6579630374908447\n",
      "Epoch: 90/1000 Valid loss: 0.448280930519104 Valid acc: 0.6544444561004639\n",
      "Epoch: 91/1000 Train loss: 0.444050669670105 Train acc: 0.6644444465637207\n",
      "Epoch: 91/1000 Valid loss: 0.44150540232658386 Valid acc: 0.6588888764381409\n",
      "Epoch: 92/1000 Train loss: 0.4518929123878479 Train acc: 0.6533333659172058\n",
      "Epoch: 92/1000 Valid loss: 0.45158910751342773 Valid acc: 0.6544444561004639\n",
      "Epoch: 93/1000 Train loss: 0.4264853298664093 Train acc: 0.6690740585327148\n",
      "Epoch: 93/1000 Valid loss: 0.41906294226646423 Valid acc: 0.6677777767181396\n",
      "Epoch: 94/1000 Train loss: 0.40574467182159424 Train acc: 0.6712963581085205\n",
      "Epoch: 94/1000 Valid loss: 0.42166101932525635 Valid acc: 0.6738889217376709\n",
      "Epoch: 95/1000 Train loss: 0.41289156675338745 Train acc: 0.6762962937355042\n",
      "Epoch: 95/1000 Valid loss: 0.43360140919685364 Valid acc: 0.6555555462837219\n",
      "Epoch: 96/1000 Train loss: 0.454753041267395 Train acc: 0.661481499671936\n",
      "Epoch: 96/1000 Valid loss: 0.4702613353729248 Valid acc: 0.6577777862548828\n",
      "Epoch: 97/1000 Train loss: 0.46975237131118774 Train acc: 0.669259250164032\n",
      "Epoch: 97/1000 Valid loss: 0.4787029027938843 Valid acc: 0.6505555510520935\n",
      "Epoch: 98/1000 Train loss: 0.45120537281036377 Train acc: 0.6607407331466675\n",
      "Epoch: 98/1000 Valid loss: 0.4486054480075836 Valid acc: 0.67166668176651\n",
      "Epoch: 99/1000 Train loss: 0.42145445942878723 Train acc: 0.6751851439476013\n",
      "Epoch: 99/1000 Valid loss: 0.42971527576446533 Valid acc: 0.6616666913032532\n",
      "Epoch: 100/1000 Train loss: 0.41043350100517273 Train acc: 0.6770370006561279\n",
      "Epoch: 100/1000 Valid loss: 0.41224193572998047 Valid acc: 0.6772222518920898\n",
      "Epoch: 101/1000 Train loss: 0.4169951379299164 Train acc: 0.6840741634368896\n",
      "Epoch: 101/1000 Valid loss: 0.433638334274292 Valid acc: 0.6583333611488342\n",
      "Epoch: 102/1000 Train loss: 0.42934998869895935 Train acc: 0.6766666173934937\n",
      "Epoch: 102/1000 Valid loss: 0.45976611971855164 Valid acc: 0.6594443917274475\n",
      "Epoch: 103/1000 Train loss: 0.47851625084877014 Train acc: 0.655925989151001\n",
      "Epoch: 103/1000 Valid loss: 0.465663880109787 Valid acc: 0.6633333563804626\n",
      "Epoch: 104/1000 Train loss: 0.4360869228839874 Train acc: 0.6742593050003052\n",
      "Epoch: 104/1000 Valid loss: 0.4119966924190521 Valid acc: 0.6783333420753479\n",
      "Epoch: 105/1000 Train loss: 0.4066704213619232 Train acc: 0.6968518495559692\n",
      "Epoch: 105/1000 Valid loss: 0.4073012173175812 Valid acc: 0.6805555820465088\n",
      "Epoch: 106/1000 Train loss: 0.3887818157672882 Train acc: 0.7037037014961243\n",
      "Epoch: 106/1000 Valid loss: 0.3789069652557373 Valid acc: 0.6966666579246521\n",
      "Epoch: 107/1000 Train loss: 0.395053505897522 Train acc: 0.6940740942955017\n",
      "Epoch: 107/1000 Valid loss: 0.4162255823612213 Valid acc: 0.6766666769981384\n",
      "Epoch: 108/1000 Train loss: 0.3849393427371979 Train acc: 0.6953704357147217\n",
      "Epoch: 108/1000 Valid loss: 0.4049718379974365 Valid acc: 0.6744444370269775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109/1000 Train loss: 0.428823858499527 Train acc: 0.6794444918632507\n",
      "Epoch: 109/1000 Valid loss: 0.4246574640274048 Valid acc: 0.6644444465637207\n",
      "Epoch: 110/1000 Train loss: 0.4099773168563843 Train acc: 0.6835185289382935\n",
      "Epoch: 110/1000 Valid loss: 0.41836681962013245 Valid acc: 0.662777841091156\n",
      "Epoch: 111/1000 Train loss: 0.40657010674476624 Train acc: 0.6774073839187622\n",
      "Epoch: 111/1000 Valid loss: 0.41456320881843567 Valid acc: 0.6827778220176697\n",
      "Epoch: 112/1000 Train loss: 0.3896823823451996 Train acc: 0.7042592167854309\n",
      "Epoch: 112/1000 Valid loss: 0.3801058232784271 Valid acc: 0.6944444179534912\n",
      "Epoch: 113/1000 Train loss: 0.3911307752132416 Train acc: 0.6899999976158142\n",
      "Epoch: 113/1000 Valid loss: 0.3841873109340668 Valid acc: 0.708888828754425\n",
      "Epoch: 114/1000 Train loss: 0.38506701588630676 Train acc: 0.7000000476837158\n",
      "Epoch: 114/1000 Valid loss: 0.4211454391479492 Valid acc: 0.6566666960716248\n",
      "Epoch: 115/1000 Train loss: 0.36878976225852966 Train acc: 0.7016666531562805\n",
      "Epoch: 115/1000 Valid loss: 0.38023364543914795 Valid acc: 0.7066666483879089\n",
      "Epoch: 116/1000 Train loss: 0.3697178363800049 Train acc: 0.7037036418914795\n",
      "Epoch: 116/1000 Valid loss: 0.39781057834625244 Valid acc: 0.6727778315544128\n",
      "Epoch: 117/1000 Train loss: 0.37320709228515625 Train acc: 0.7000000476837158\n",
      "Epoch: 117/1000 Valid loss: 0.36893925070762634 Valid acc: 0.7011110782623291\n",
      "Epoch: 118/1000 Train loss: 0.34574970602989197 Train acc: 0.7129629254341125\n",
      "Epoch: 118/1000 Valid loss: 0.34795403480529785 Valid acc: 0.7011110782623291\n",
      "Epoch: 119/1000 Train loss: 0.33883070945739746 Train acc: 0.7185185551643372\n",
      "Epoch: 119/1000 Valid loss: 0.35250458121299744 Valid acc: 0.7072222232818604\n",
      "Epoch: 120/1000 Train loss: 0.3430953621864319 Train acc: 0.7170369625091553\n",
      "Epoch: 120/1000 Valid loss: 0.35996389389038086 Valid acc: 0.7055554986000061\n",
      "Epoch: 121/1000 Train loss: 0.36521291732788086 Train acc: 0.7055554986000061\n",
      "Epoch: 121/1000 Valid loss: 0.3769371509552002 Valid acc: 0.6933333277702332\n"
     ]
    }
   ],
   "source": [
    "valid_acc, valid_loss = [], []\n",
    "train_acc, train_loss = [], []\n",
    "\n",
    "# with graph.as_default():\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the global variable instead of loading them or if there is nothing to load.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #     # Restore\n",
    "    #     saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    #     saver.restore(sess,\"checkpoints/har-lstm.ckpt\")\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over training batches\n",
    "        state = sess.run(initial_state)\n",
    "        train_acc_batch, train_loss_batch = [], []\n",
    "        for Xbatch, Ybatch in get_batches(Xtrain, Ytrain, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {inputs_: Xbatch, indices_: Ybatch, initial_state: state}\n",
    "            loss, state, acc, _ = sess.run([cost, final_state, accuracy, optimizer], feed_dict)\n",
    "            train_acc_batch.append(acc)\n",
    "            train_loss_batch.append(loss)\n",
    "            \n",
    "        # Print at each epoch/iteration\n",
    "        print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "              \"Train loss: {}\".format(np.mean(train_loss_batch)),\n",
    "              \"Train acc: {}\".format(np.mean(train_acc_batch)))\n",
    "\n",
    "        # Store at each epoch/iteration\n",
    "        train_loss.append(np.mean(train_loss_batch))\n",
    "        train_acc.append(np.mean(train_acc_batch))\n",
    "        \n",
    "        # Loop over validation batches\n",
    "        state = sess.run(initial_state)\n",
    "        valid_acc_batch, valid_loss_batch = [], []\n",
    "        for Xbatch, Ybatch in get_batches(Xvalid, Yvalid, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed_dict = {inputs_: Xbatch, indices_: Ybatch, initial_state: state}\n",
    "            loss, state, acc = sess.run([cost, final_state, accuracy], feed_dict)\n",
    "            valid_acc_batch.append(acc)\n",
    "            valid_loss_batch.append(loss)\n",
    "            \n",
    "        # Print at each epoch/iteration\n",
    "        print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "              \"Valid loss: {}\".format(np.mean(valid_loss_batch)),\n",
    "              \"Valid acc: {}\".format(np.mean(valid_acc_batch)))\n",
    "\n",
    "        # Store at each epoch/iteration\n",
    "        valid_loss.append(np.mean(valid_loss_batch))\n",
    "        valid_acc.append(np.mean(valid_acc_batch))\n",
    "            \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot training and test loss\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(np.array(train_loss), 'r-', np.array(valid_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracies\n",
    "plt.plot(np.array(train_acc), 'r-', valid_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "\n",
    "    # Loop over test batches\n",
    "    state = sess.run(initial_state)\n",
    "    acc_batch, loss_batch = [], []\n",
    "    for Xbatch, Ybatch in get_batches(Xtest, Ytest, batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed_dict = {inputs_: Xbatch, indices_: Ybatch, initial_state: state}\n",
    "        loss, state, acc = sess.run([cost, final_state, accuracy], feed_dict)\n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Print at each epoch/iteration\n",
    "    print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "          \"Test loss: {}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

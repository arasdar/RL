{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(args):\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "\n",
    "#         env = gym.make(args['env'])\n",
    "#         np.random.seed(int(args['random_seed']))\n",
    "#         tf.set_random_seed(int(args['random_seed']))\n",
    "#         env.seed(int(args['random_seed']))\n",
    "\n",
    "#         state_dim = env.observation_space.shape[0]\n",
    "#         action_dim = env.action_space.shape[0]\n",
    "#         action_bound = env.action_space.high\n",
    "#         # Ensure action bound is symmetric\n",
    "#         assert (env.action_space.high == -env.action_space.low)\n",
    "\n",
    "#         actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\n",
    "#                              float(args['actor_lr']), float(args['tau']),\n",
    "#                              int(args['minibatch_size']))\n",
    "\n",
    "#         critic = CriticNetwork(sess, state_dim, action_dim,\n",
    "#                                float(args['critic_lr']), float(args['tau']),\n",
    "#                                float(args['gamma']),\n",
    "#                                actor.get_num_trainable_vars())\n",
    "        \n",
    "#         actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\n",
    "\n",
    "#         if args['use_gym_monitor']:\n",
    "#             if not args['render_env']:\n",
    "#                 env = wrappers.Monitor(\n",
    "#                     env, args['monitor_dir'], video_callable=False, force=True)\n",
    "#             else:\n",
    "#                 env = wrappers.Monitor(env, args['monitor_dir'], force=True)\n",
    "\n",
    "#         train(sess, env, args, actor, critic, actor_noise)\n",
    "\n",
    "#         if args['use_gym_monitor']:\n",
    "#             env.monitor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if __name__ == '__main__':\n",
    "# parser = argparse.ArgumentParser(description='provide arguments for DDPG agent')\n",
    "\n",
    "# # agent parameters\n",
    "# parser.add_argument('--actor-lr', help='actor network learning rate', default=0.0001)\n",
    "# parser.add_argument('--critic-lr', help='critic network learning rate', default=0.001)\n",
    "# parser.add_argument('--gamma', help='discount factor for critic updates', default=0.99)\n",
    "# parser.add_argument('--tau', help='soft target update parameter', default=0.001)\n",
    "# parser.add_argument('--buffer-size', help='max size of the replay buffer', default=1000000)\n",
    "# parser.add_argument('--minibatch-size', help='size of minibatch for minibatch-SGD', default=64)\n",
    "\n",
    "# # run parameters\n",
    "# parser.add_argument('--env', help='choose the gym env- tested on {Pendulum-v0}', default='Pendulum-v0')\n",
    "# parser.add_argument('--random-seed', help='random seed for repeatability', default=1234)\n",
    "# parser.add_argument('--max-episodes', help='max num of episodes to do while training', default=50000)\n",
    "# parser.add_argument('--max-episode-len', help='max length of 1 episode', default=1000)\n",
    "# parser.add_argument('--render-env', help='render the gym env', action='store_true')\n",
    "# parser.add_argument('--use-gym-monitor', help='record gym results', action='store_true')\n",
    "# parser.add_argument('--monitor-dir', help='directory for storing gym results', default='./results/gym_ddpg')\n",
    "# parser.add_argument('--summary-dir', help='directory for storing tensorboard info', default='./results/tf_ddpg')\n",
    "\n",
    "# parser.set_defaults(render_env=False)\n",
    "# parser.set_defaults(use_gym_monitor=True)\n",
    "\n",
    "# # args = vars(parser.parse_args())\n",
    "\n",
    "# # pp.pprint(args)\n",
    "\n",
    "# # main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent import ActorNetwork, CriticNetwork, OrnsteinUhlenbeckActionNoise\n",
    "import ddpg_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ===========================\n",
    "# # #   Tensorflow Summary Ops\n",
    "# # # ===========================\n",
    "\n",
    "# def build_summaries():\n",
    "#     episode_reward = tf.Variable(0.)\n",
    "#     tf.summary.scalar(\"Reward\", episode_reward)\n",
    "#     episode_ave_max_q = tf.Variable(0.)\n",
    "#     tf.summary.scalar(\"Qmax Value\", episode_ave_max_q)\n",
    "\n",
    "#     summary_vars = [episode_reward, episode_ave_max_q]\n",
    "#     summary_ops = tf.summary.merge_all()\n",
    "\n",
    "#     return summary_ops, summary_vars\n",
    "\n",
    "# # ===========================\n",
    "# #   Agent Training\n",
    "# # ===========================\n",
    "\n",
    "# def train(sess, env, args, actor, critic, actor_noise):\n",
    "\n",
    "# Set up summary Ops\n",
    "# summary_ops, summary_vars = build_summaries()\n",
    "\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     writer = tf.summary.FileWriter(args['summary_dir'], sess.graph)\n",
    "\n",
    "#     # Initialize target network weights\n",
    "#     actor.update_target_network()\n",
    "#     critic.update_target_network()\n",
    "\n",
    "#     # Initialize replay memory\n",
    "#     replay_buffer = ReplayBuffer(int(args['buffer_size']), int(args['random_seed']))\n",
    "\n",
    "#     # Needed to enable BatchNorm. \n",
    "#     # This hurts the performance on Pendulum but could be useful\n",
    "#     # in other environments.\n",
    "#     # tflearn.is_training(True)\n",
    "\n",
    "#     for i in range(int(args['max_episodes'])):\n",
    "\n",
    "#         s = env.reset()\n",
    "\n",
    "#         ep_reward = 0\n",
    "#         ep_ave_max_q = 0\n",
    "\n",
    "#         for j in range(int(args['max_episode_len'])):\n",
    "\n",
    "#             if args['render_env']:\n",
    "#                 env.render()\n",
    "\n",
    "#             # Added exploration noise\n",
    "#             #a = actor.predict(np.reshape(s, (1, 3))) + (1. / (1. + i))\n",
    "#             a = actor.predict(np.reshape(s, (1, actor.s_dim))) + actor_noise()\n",
    "\n",
    "#             s2, r, terminal, info = env.step(a[0])\n",
    "\n",
    "#             replay_buffer.add(np.reshape(s, (actor.s_dim,)), np.reshape(a, (actor.a_dim,)), r,\n",
    "#                               terminal, np.reshape(s2, (actor.s_dim,)))\n",
    "\n",
    "#             # Keep adding experience to the memory until\n",
    "#             # there are at least minibatch size samples\n",
    "#             #if replay_buffer.size() > int(args['minibatch_size']):\n",
    "#             if replay_buffer.size() > int(64):\n",
    "#                 s_batch, a_batch, r_batch, t_batch, s2_batch = \\\n",
    "#                     #replay_buffer.sample_batch(int(args['minibatch_size']))\n",
    "#                     replay_buffer.sample_batch(64))\n",
    "\n",
    "#                 # Calculate targets\n",
    "#                 target_q = critic.predict_target(\n",
    "#                     s2_batch, actor.predict_target(s2_batch))\n",
    "\n",
    "#                 y_i = []\n",
    "#                 for k in range(int(args['minibatch_size'])):\n",
    "#                     if t_batch[k]:\n",
    "#                         y_i.append(r_batch[k])\n",
    "#                     else:\n",
    "#                         y_i.append(r_batch[k] + critic.gamma * target_q[k])\n",
    "\n",
    "#                 # Update the critic given the targets\n",
    "#                 predicted_q_value, _ = critic.train(\n",
    "#                     s_batch, a_batch, np.reshape(y_i, (int(args['minibatch_size']), 1)))\n",
    "\n",
    "#                 ep_ave_max_q += np.amax(predicted_q_value)\n",
    "\n",
    "#                 # Update the actor policy using the sampled gradient\n",
    "#                 a_outs = actor.predict(s_batch)\n",
    "#                 grads = critic.action_gradients(s_batch, a_outs)\n",
    "#                 actor.train(s_batch, grads[0])\n",
    "\n",
    "#                 # Update target networks\n",
    "#                 actor.update_target_network()\n",
    "#                 critic.update_target_network()\n",
    "\n",
    "#             s = s2\n",
    "#             ep_reward += r\n",
    "\n",
    "#             if terminal:\n",
    "\n",
    "#                 summary_str = sess.run(summary_ops, feed_dict={\n",
    "#                     summary_vars[0]: ep_reward,\n",
    "#                     summary_vars[1]: ep_ave_max_q / float(j)\n",
    "#                 })\n",
    "\n",
    "#                 writer.add_summary(summary_str, i)\n",
    "#                 writer.flush()\n",
    "\n",
    "#                 print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f}'.format(int(ep_reward), \\\n",
    "#                         i, (ep_ave_max_q / float(j))))\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as sess:\n",
    "\n",
    "env = gym.make('Pendulum-v0')\n",
    "np.random.seed(int(1234))\n",
    "tf.set_random_seed(int(1234))\n",
    "env.seed(int(123))\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_bound = env.action_space.high\n",
    "# Ensure action bound is symmetric\n",
    "assert (env.action_space.high == -env.action_space.low)\n",
    "\n",
    "actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\n",
    "\n",
    "# #     if True:\n",
    "# #         if not args['render_env']:\n",
    "# #             env = wrappers.Monitor(\n",
    "# #                 env, args['monitor_dir'], video_callable=False, force=True)\n",
    "# #         else:\n",
    "# #             env = wrappers.Monitor(env, args['monitor_dir'], force=True)\n",
    "\n",
    "#     train(sess, env, args, actor, critic, actor_noise)\n",
    "\n",
    "#     if args['use_gym_monitor']:\n",
    "#         env.monitor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 64\n",
    "random_seed = 1234\n",
    "gamma = 0.99\n",
    "tau = 1e-3\n",
    "actor_lr = 1e-4\n",
    "critic_lr = 1e-3\n",
    "max_episodes = 1000\n",
    "max_episode_len = 1000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value FullyConnected_3/W\n\t [[Node: FullyConnected_3/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@FullyConnected_3/W\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](FullyConnected_3/W)]]\n\nCaused by op 'FullyConnected_3/W/read', defined at:\n  File \"/home/arasdar/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/arasdar/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/arasdar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/arasdar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/arasdar/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-0b04b95629ea>\", line 9, in <module>\n    actor_lr, tau, batch_size)\n  File \"/home/arasdar/github/arasdar-RL-git/tensorflow/ddpg_agent.py\", line 50, in __init__\n    self.target_inputs, self.target_out, self.target_scaled_out = self.create_actor_network()\n  File \"/home/arasdar/github/arasdar-RL-git/tensorflow/ddpg_agent.py\", line 79, in create_actor_network\n    net = tflearn.fully_connected(inputs, 400)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tflearn/layers/core.py\", line 157, in fully_connected\n    restore=restore)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tflearn/variables.py\", line 65, in variable\n    validate_shape=validate_shape)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 391, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3053, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value FullyConnected_3/W\n\t [[Node: FullyConnected_3/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@FullyConnected_3/W\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](FullyConnected_3/W)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value FullyConnected_3/W\n\t [[Node: FullyConnected_3/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@FullyConnected_3/W\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](FullyConnected_3/W)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0b04b95629ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                            \u001b[0mcritic_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                            actor.get_num_trainable_vars())\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/arasdar-RL-git/tensorflow/ddpg_agent.py\u001b[0m in \u001b[0;36mupdate_target_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_network_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_num_trainable_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value FullyConnected_3/W\n\t [[Node: FullyConnected_3/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@FullyConnected_3/W\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](FullyConnected_3/W)]]\n\nCaused by op 'FullyConnected_3/W/read', defined at:\n  File \"/home/arasdar/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/arasdar/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/arasdar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/arasdar/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/arasdar/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-0b04b95629ea>\", line 9, in <module>\n    actor_lr, tau, batch_size)\n  File \"/home/arasdar/github/arasdar-RL-git/tensorflow/ddpg_agent.py\", line 50, in __init__\n    self.target_inputs, self.target_out, self.target_scaled_out = self.create_actor_network()\n  File \"/home/arasdar/github/arasdar-RL-git/tensorflow/ddpg_agent.py\", line 79, in create_actor_network\n    net = tflearn.fully_connected(inputs, 400)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tflearn/layers/core.py\", line 157, in fully_connected\n    restore=restore)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tflearn/variables.py\", line 65, in variable\n    validate_shape=validate_shape)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 391, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3053, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/arasdar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value FullyConnected_3/W\n\t [[Node: FullyConnected_3/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@FullyConnected_3/W\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](FullyConnected_3/W)]]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.reset_default_graph()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Initialize target network weights\n",
    "    actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\n",
    "                         actor_lr, tau, batch_size)\n",
    "\n",
    "    critic = CriticNetwork(sess, state_dim, action_dim, \n",
    "                           critic_lr, tau, gamma,\n",
    "                           actor.get_num_trainable_vars())\n",
    "    actor.update_target_network()\n",
    "    critic.update_target_network()\n",
    "\n",
    "#     # Initialize replay memory\n",
    "#     replay_buffer = ReplayBuffer(buffer_size, random_seed)\n",
    "\n",
    "#     # Needed to enable BatchNorm. \n",
    "#     # This hurts the performance on Pendulum but could be useful\n",
    "#     # in other environments.\n",
    "#     # tflearn.is_training(True)\n",
    "\n",
    "#     for i in range(max_episodes):\n",
    "\n",
    "#         s = env.reset()\n",
    "\n",
    "#         ep_reward = 0\n",
    "#         ep_ave_max_q = 0\n",
    "\n",
    "#         for j in range(max_episode_len):\n",
    "\n",
    "#             #if args['render_env']:\n",
    "#             #env.render()\n",
    "\n",
    "#             # Added exploration noise\n",
    "#             #a = actor.predict(np.reshape(s, (1, 3))) + (1. / (1. + i))\n",
    "#             a = actor.predict(np.reshape(s, (1, actor.s_dim))) + actor_noise()\n",
    "\n",
    "#             s2, r, terminal, info = env.step(a[0])\n",
    "\n",
    "#             replay_buffer.add(np.reshape(s, (actor.s_dim,)), np.reshape(a, (actor.a_dim,)), r,\n",
    "#                               terminal, np.reshape(s2, (actor.s_dim,)))\n",
    "\n",
    "#             # Keep adding experience to the memory until\n",
    "#             # there are at least minibatch size samples\n",
    "#             #if replay_buffer.size() > int(args['minibatch_size']):\n",
    "#             if replay_buffer.size() > batch_size:\n",
    "#                 s_batch, a_batch, r_batch, t_batch, s2_batch = replay_buffer.sample_batch(batch_size)\n",
    "#                     #replay_buffer.sample_batch(int(args['minibatch_size']))\n",
    "\n",
    "#                 # Calculate targets\n",
    "#                 target_q = critic.predict_target(\n",
    "#                     s2_batch, actor.predict_target(s2_batch))\n",
    "\n",
    "#                 y_i = []\n",
    "#                 for k in range(batch_size):\n",
    "#                     if t_batch[k]:\n",
    "#                         y_i.append(r_batch[k])\n",
    "#                     else:\n",
    "#                         y_i.append(r_batch[k] + critic.gamma * target_q[k])\n",
    "\n",
    "#                 # Update the critic given the targets\n",
    "#                 predicted_q_value, _ = critic.train(\n",
    "#                     s_batch, a_batch, np.reshape(y_i, batch_size, 1))\n",
    "\n",
    "#                 ep_ave_max_q += np.amax(predicted_q_value)\n",
    "\n",
    "#                 # Update the actor policy using the sampled gradient\n",
    "#                 a_outs = actor.predict(s_batch)\n",
    "#                 grads = critic.action_gradients(s_batch, a_outs)\n",
    "#                 actor.train(s_batch, grads[0])\n",
    "\n",
    "#                 # Update target networks\n",
    "#                 actor.update_target_network()\n",
    "#                 critic.update_target_network()\n",
    "\n",
    "#             s = s2\n",
    "#             ep_reward += r\n",
    "\n",
    "#             if terminal:\n",
    "\n",
    "# #                 summary_str = sess.run(summary_ops, feed_dict={\n",
    "# #                     summary_vars[0]: ep_reward,\n",
    "# #                     summary_vars[1]: ep_ave_max_q / float(j)\n",
    "# #                 })\n",
    "\n",
    "# #                 writer.add_summary(summary_str, i)\n",
    "# #                 writer.flush()\n",
    "\n",
    "#                 print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f}'.format(int(ep_reward), \\\n",
    "#                         i, (ep_ave_max_q / float(j))))\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

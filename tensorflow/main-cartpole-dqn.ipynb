{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning or Q-network (DQN)\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "# env = gym.make('CartPole-v0') # 200 total reward as goal\n",
    "env = gym.make('CartPole-v1') # 500 total reward as goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "# batch = []\n",
    "# for _ in range(1000):\n",
    "#     # env.render()\n",
    "#     action = env.action_space.sample()\n",
    "#     state, reward, done, info = env.step(action) # take a random action\n",
    "#     batch.append([action, state, reward, done, info])\n",
    "#     #print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "#     if done:\n",
    "#         env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch[0], batch[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = np.array([each[0] for each in batch])\n",
    "# states = np.array([each[1] for each in batch])\n",
    "# rewards = np.array([each[2] for each in batch])\n",
    "# dones = np.array([each[3] for each in batch])\n",
    "# infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    return actions, states, targetQs, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_xavier(random_seed=1, dtype=tf.float32, uniform=False):\n",
    "    xavier = tf.contrib.layers.xavier_initializer(\n",
    "        dtype=dtype,\n",
    "        seed=tf.set_random_seed(random_seed), \n",
    "        uniform=uniform) # False: normal\n",
    "    return xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(inputs, units, trainable=True):\n",
    "    outputs = tf.layers.dense(\n",
    "        inputs=inputs,\n",
    "        units=units,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=init_xavier(), # Xavier with normal init\n",
    "        bias_initializer=tf.zeros_initializer(),\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        trainable=trainable,\n",
    "        name=None,\n",
    "        reuse=None)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.leaky_relu(\n",
    "#     features,\n",
    "#     alpha=0.2,\n",
    "#     name=None\n",
    "# )\n",
    "def nl(inputs, alpha=0.2):\n",
    "    outputs = tf.maximum(alpha * inputs, inputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn(inputs, training=True):\n",
    "    outputs = tf.layers.batch_normalization(\n",
    "        inputs=inputs,\n",
    "        axis=-1,\n",
    "        momentum=0.99,\n",
    "        epsilon=0.001,\n",
    "        center=True,\n",
    "        scale=True,\n",
    "        beta_initializer=tf.zeros_initializer(),\n",
    "        gamma_initializer=tf.ones_initializer(),\n",
    "        moving_mean_initializer=tf.zeros_initializer(),\n",
    "        moving_variance_initializer=tf.ones_initializer(),\n",
    "        beta_regularizer=None,\n",
    "        gamma_regularizer=None,\n",
    "        beta_constraint=None,\n",
    "        gamma_constraint=None,\n",
    "        training=training,\n",
    "        trainable=True,\n",
    "        name=None,\n",
    "        reuse=None,\n",
    "        renorm=False,\n",
    "        renorm_clipping=None,\n",
    "        renorm_momentum=0.99,\n",
    "        fused=None,\n",
    "        virtual_batch_size=None,\n",
    "        adjustment=None)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor-Critic/ D/Q\n",
    "def D(states, action_size, hidden_size, reuse=False, alpha=0.2, is_training=False):\n",
    "    with tf.variable_scope('D', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h = mlp(inputs=states, units=hidden_size)\n",
    "        h = bn(inputs=h, training=is_training)\n",
    "        h = nl(h)\n",
    "        print(states.shape, h.shape)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h = mlp(inputs=h, units=hidden_size)\n",
    "        h = bn(inputs=h, training=is_training)\n",
    "        h = nl(h)\n",
    "        print(h.shape)\n",
    "        \n",
    "        # Output layer\n",
    "        actions = mlp(inputs=h, units=action_size)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(actions, states, targetQs, action_size, hidden_size, is_training):\n",
    "    \n",
    "    actions_logits = D(states=states, hidden_size=hidden_size, action_size=action_size, \n",
    "                       is_training=is_training)\n",
    "    \n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    \n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    \n",
    "    loss = tf.reduce_mean((Qs - targetQs)**2)\n",
    "    \n",
    "    return actions_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('D')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=d_vars)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.actions, self.states, self.targetQs, self.is_training = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.loss = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size,\n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs, \n",
    "            is_training=self.is_training)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = model_opt(loss=self.loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state size:{}'.format(states.shape), \n",
    "#       'actions:{}'.format(actions.shape)) \n",
    "# print('action size:', np.max(actions) - np.min(actions)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "action_size = 2\n",
    "state_size = 4\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(?, 64)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "\n",
    "for _ in range(memory_size):\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    \n",
    "    state = next_state\n",
    "    \n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(sess, memory, batch_size):\n",
    "    batch = memory.sample(batch_size)\n",
    "    states = np.array([each[0] for each in batch])\n",
    "    actions = np.array([each[1] for each in batch])\n",
    "    next_states = np.array([each[2] for each in batch])\n",
    "    rewards = np.array([each[3] for each in batch])\n",
    "    dones = np.array([each[4] for each in batch])\n",
    "    \n",
    "    next_actions_logits = sess.run(model.actions_logits, feed_dict = {model.states: next_states, \n",
    "                                                                      model.is_training: False})\n",
    "    \n",
    "    nextQs = np.max(next_actions_logits, axis=1) * (1-dones)\n",
    "    \n",
    "    targetQs = rewards + (gamma * nextQs)\n",
    "    \n",
    "    loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                             model.actions: actions,\n",
    "                                                             model.targetQs: targetQs, \n",
    "                                                             model.is_training: True})\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(sess, state):\n",
    "    \n",
    "    action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1]), \n",
    "                                                              model.is_training: False})\n",
    "    \n",
    "    action = np.argmax(action_logits, axis=1)[0]\n",
    "    #print(action)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:13.0000 R:13.0 loss:0.7316 exploreP:0.9987\n",
      "Episode:1 meanR:19.5000 R:26.0 loss:0.7303 exploreP:0.9961\n",
      "Episode:2 meanR:25.6667 R:38.0 loss:0.6658 exploreP:0.9924\n",
      "Episode:3 meanR:26.7500 R:30.0 loss:0.6524 exploreP:0.9895\n",
      "Episode:4 meanR:24.6000 R:16.0 loss:0.6661 exploreP:0.9879\n",
      "Episode:5 meanR:26.5000 R:36.0 loss:0.6619 exploreP:0.9844\n",
      "Episode:6 meanR:24.8571 R:15.0 loss:0.6307 exploreP:0.9829\n",
      "Episode:7 meanR:25.1250 R:27.0 loss:0.7232 exploreP:0.9803\n",
      "Episode:8 meanR:24.4444 R:19.0 loss:0.6777 exploreP:0.9785\n",
      "Episode:9 meanR:23.5000 R:15.0 loss:0.7151 exploreP:0.9770\n",
      "Episode:10 meanR:23.1818 R:20.0 loss:0.8311 exploreP:0.9751\n",
      "Episode:11 meanR:23.0000 R:21.0 loss:0.7825 exploreP:0.9730\n",
      "Episode:12 meanR:22.9231 R:22.0 loss:0.9048 exploreP:0.9709\n",
      "Episode:13 meanR:22.3571 R:15.0 loss:0.8987 exploreP:0.9695\n",
      "Episode:14 meanR:24.1333 R:49.0 loss:1.0497 exploreP:0.9648\n",
      "Episode:15 meanR:23.5625 R:15.0 loss:1.5216 exploreP:0.9634\n",
      "Episode:16 meanR:23.1176 R:16.0 loss:1.6131 exploreP:0.9618\n",
      "Episode:17 meanR:22.7222 R:16.0 loss:2.3924 exploreP:0.9603\n",
      "Episode:18 meanR:23.5263 R:38.0 loss:2.4661 exploreP:0.9567\n",
      "Episode:19 meanR:22.9500 R:12.0 loss:2.3405 exploreP:0.9556\n",
      "Episode:20 meanR:23.1429 R:27.0 loss:3.8542 exploreP:0.9530\n",
      "Episode:21 meanR:23.8182 R:38.0 loss:4.5692 exploreP:0.9495\n",
      "Episode:22 meanR:23.5652 R:18.0 loss:4.1224 exploreP:0.9478\n",
      "Episode:23 meanR:23.0417 R:11.0 loss:5.0202 exploreP:0.9467\n",
      "Episode:24 meanR:22.8000 R:17.0 loss:5.0468 exploreP:0.9451\n",
      "Episode:25 meanR:22.4615 R:14.0 loss:4.8172 exploreP:0.9438\n",
      "Episode:26 meanR:22.0370 R:11.0 loss:5.4710 exploreP:0.9428\n",
      "Episode:27 meanR:22.7857 R:43.0 loss:5.0513 exploreP:0.9388\n",
      "Episode:28 meanR:23.5517 R:45.0 loss:6.8353 exploreP:0.9346\n",
      "Episode:29 meanR:23.2667 R:15.0 loss:7.4515 exploreP:0.9333\n",
      "Episode:30 meanR:23.0323 R:16.0 loss:6.4679 exploreP:0.9318\n",
      "Episode:31 meanR:23.3125 R:32.0 loss:8.0913 exploreP:0.9288\n",
      "Episode:32 meanR:23.6364 R:34.0 loss:7.7517 exploreP:0.9257\n",
      "Episode:33 meanR:23.9706 R:35.0 loss:9.6669 exploreP:0.9225\n",
      "Episode:34 meanR:23.9143 R:22.0 loss:9.8802 exploreP:0.9205\n",
      "Episode:35 meanR:24.1111 R:31.0 loss:10.0040 exploreP:0.9177\n",
      "Episode:36 meanR:23.7838 R:12.0 loss:10.1840 exploreP:0.9166\n",
      "Episode:37 meanR:23.4737 R:12.0 loss:11.3453 exploreP:0.9155\n",
      "Episode:38 meanR:23.2051 R:13.0 loss:11.6282 exploreP:0.9143\n",
      "Episode:39 meanR:23.0500 R:17.0 loss:9.7533 exploreP:0.9128\n",
      "Episode:40 meanR:22.7317 R:10.0 loss:6.7584 exploreP:0.9119\n",
      "Episode:41 meanR:22.8333 R:27.0 loss:10.1312 exploreP:0.9095\n",
      "Episode:42 meanR:22.5116 R:9.0 loss:9.6028 exploreP:0.9087\n",
      "Episode:43 meanR:22.2727 R:12.0 loss:8.6315 exploreP:0.9076\n",
      "Episode:44 meanR:22.4889 R:32.0 loss:12.4193 exploreP:0.9047\n",
      "Episode:45 meanR:22.3696 R:17.0 loss:13.7138 exploreP:0.9032\n",
      "Episode:46 meanR:22.3830 R:23.0 loss:11.1499 exploreP:0.9011\n",
      "Episode:47 meanR:22.1667 R:12.0 loss:11.8264 exploreP:0.9001\n",
      "Episode:48 meanR:22.2041 R:24.0 loss:12.7225 exploreP:0.8979\n",
      "Episode:49 meanR:22.1400 R:19.0 loss:11.1125 exploreP:0.8963\n",
      "Episode:50 meanR:22.2941 R:30.0 loss:12.5960 exploreP:0.8936\n",
      "Episode:51 meanR:22.2500 R:20.0 loss:15.9525 exploreP:0.8918\n",
      "Episode:52 meanR:22.5094 R:36.0 loss:11.3645 exploreP:0.8887\n",
      "Episode:53 meanR:22.2593 R:9.0 loss:22.2065 exploreP:0.8879\n",
      "Episode:54 meanR:22.3636 R:28.0 loss:16.4467 exploreP:0.8854\n",
      "Episode:55 meanR:22.5357 R:32.0 loss:15.5183 exploreP:0.8826\n",
      "Episode:56 meanR:22.4035 R:15.0 loss:16.1487 exploreP:0.8813\n",
      "Episode:57 meanR:22.7931 R:45.0 loss:15.4934 exploreP:0.8774\n",
      "Episode:58 meanR:22.8305 R:25.0 loss:14.3293 exploreP:0.8752\n",
      "Episode:59 meanR:22.6667 R:13.0 loss:14.5366 exploreP:0.8741\n",
      "Episode:60 meanR:22.5574 R:16.0 loss:12.9760 exploreP:0.8727\n",
      "Episode:61 meanR:22.5806 R:24.0 loss:14.3839 exploreP:0.8707\n",
      "Episode:62 meanR:22.4127 R:12.0 loss:13.7679 exploreP:0.8696\n",
      "Episode:63 meanR:22.2344 R:11.0 loss:14.2334 exploreP:0.8687\n",
      "Episode:64 meanR:22.2923 R:26.0 loss:9.9802 exploreP:0.8665\n",
      "Episode:65 meanR:22.3788 R:28.0 loss:9.8778 exploreP:0.8641\n",
      "Episode:66 meanR:22.2687 R:15.0 loss:6.7229 exploreP:0.8628\n",
      "Episode:67 meanR:22.1029 R:11.0 loss:7.6276 exploreP:0.8618\n",
      "Episode:68 meanR:22.0290 R:17.0 loss:7.1703 exploreP:0.8604\n",
      "Episode:69 meanR:22.3714 R:46.0 loss:7.3504 exploreP:0.8565\n",
      "Episode:70 meanR:22.2958 R:17.0 loss:11.3546 exploreP:0.8551\n",
      "Episode:71 meanR:22.4861 R:36.0 loss:18.0380 exploreP:0.8520\n",
      "Episode:72 meanR:22.4247 R:18.0 loss:23.8505 exploreP:0.8505\n",
      "Episode:73 meanR:22.4730 R:26.0 loss:28.4992 exploreP:0.8483\n",
      "Episode:74 meanR:22.4267 R:19.0 loss:28.6848 exploreP:0.8467\n",
      "Episode:75 meanR:22.3947 R:20.0 loss:28.2318 exploreP:0.8451\n",
      "Episode:76 meanR:22.3117 R:16.0 loss:25.5235 exploreP:0.8437\n",
      "Episode:77 meanR:22.2308 R:16.0 loss:23.1051 exploreP:0.8424\n",
      "Episode:78 meanR:22.1519 R:16.0 loss:28.8992 exploreP:0.8411\n",
      "Episode:79 meanR:22.0750 R:16.0 loss:23.4833 exploreP:0.8397\n",
      "Episode:80 meanR:22.1358 R:27.0 loss:21.0897 exploreP:0.8375\n",
      "Episode:81 meanR:22.0244 R:13.0 loss:20.2307 exploreP:0.8364\n",
      "Episode:82 meanR:21.9036 R:12.0 loss:16.0596 exploreP:0.8354\n",
      "Episode:83 meanR:22.0000 R:30.0 loss:14.0329 exploreP:0.8330\n",
      "Episode:84 meanR:22.4588 R:61.0 loss:13.4691 exploreP:0.8280\n",
      "Episode:85 meanR:22.4186 R:19.0 loss:15.5662 exploreP:0.8264\n",
      "Episode:86 meanR:22.2989 R:12.0 loss:10.3720 exploreP:0.8254\n",
      "Episode:87 meanR:22.2955 R:22.0 loss:10.5643 exploreP:0.8236\n",
      "Episode:88 meanR:22.1910 R:13.0 loss:11.0078 exploreP:0.8226\n",
      "Episode:89 meanR:22.0889 R:13.0 loss:10.8499 exploreP:0.8215\n",
      "Episode:90 meanR:22.0110 R:15.0 loss:9.4535 exploreP:0.8203\n",
      "Episode:91 meanR:22.4130 R:59.0 loss:8.2276 exploreP:0.8155\n",
      "Episode:92 meanR:22.3011 R:12.0 loss:10.1711 exploreP:0.8146\n",
      "Episode:93 meanR:22.2766 R:20.0 loss:8.6120 exploreP:0.8130\n",
      "Episode:94 meanR:22.1684 R:12.0 loss:9.2026 exploreP:0.8120\n",
      "Episode:95 meanR:22.0833 R:14.0 loss:9.7249 exploreP:0.8109\n",
      "Episode:96 meanR:22.1031 R:24.0 loss:8.9364 exploreP:0.8090\n",
      "Episode:97 meanR:22.1020 R:22.0 loss:11.4208 exploreP:0.8072\n",
      "Episode:98 meanR:21.9697 R:9.0 loss:10.1313 exploreP:0.8065\n",
      "Episode:99 meanR:21.9400 R:19.0 loss:9.4506 exploreP:0.8050\n",
      "Episode:100 meanR:21.9400 R:13.0 loss:10.2665 exploreP:0.8039\n",
      "Episode:101 meanR:22.0300 R:35.0 loss:10.3262 exploreP:0.8012\n",
      "Episode:102 meanR:21.7600 R:11.0 loss:15.2442 exploreP:0.8003\n",
      "Episode:103 meanR:21.5900 R:13.0 loss:9.2135 exploreP:0.7993\n",
      "Episode:104 meanR:21.5800 R:15.0 loss:10.6607 exploreP:0.7981\n",
      "Episode:105 meanR:21.3200 R:10.0 loss:12.4496 exploreP:0.7973\n",
      "Episode:106 meanR:21.3900 R:22.0 loss:12.3662 exploreP:0.7956\n",
      "Episode:107 meanR:21.2800 R:16.0 loss:11.9604 exploreP:0.7943\n",
      "Episode:108 meanR:21.2000 R:11.0 loss:15.2991 exploreP:0.7934\n",
      "Episode:109 meanR:21.2600 R:21.0 loss:11.7932 exploreP:0.7918\n",
      "Episode:110 meanR:21.2800 R:22.0 loss:10.7630 exploreP:0.7901\n",
      "Episode:111 meanR:21.2100 R:14.0 loss:12.0660 exploreP:0.7890\n",
      "Episode:112 meanR:21.2600 R:27.0 loss:9.2122 exploreP:0.7869\n",
      "Episode:113 meanR:21.2300 R:12.0 loss:11.4697 exploreP:0.7860\n",
      "Episode:114 meanR:20.9000 R:16.0 loss:10.0149 exploreP:0.7847\n",
      "Episode:115 meanR:21.0500 R:30.0 loss:9.2967 exploreP:0.7824\n",
      "Episode:116 meanR:21.5200 R:63.0 loss:8.8973 exploreP:0.7776\n",
      "Episode:117 meanR:21.9700 R:61.0 loss:7.5769 exploreP:0.7729\n",
      "Episode:118 meanR:22.1300 R:54.0 loss:15.3282 exploreP:0.7688\n",
      "Episode:119 meanR:22.2500 R:24.0 loss:28.6014 exploreP:0.7670\n",
      "Episode:120 meanR:22.4100 R:43.0 loss:28.0665 exploreP:0.7637\n",
      "Episode:121 meanR:22.2200 R:19.0 loss:33.6526 exploreP:0.7623\n",
      "Episode:122 meanR:22.1700 R:13.0 loss:30.4890 exploreP:0.7613\n",
      "Episode:123 meanR:22.4100 R:35.0 loss:21.6394 exploreP:0.7587\n",
      "Episode:124 meanR:22.4800 R:24.0 loss:16.7757 exploreP:0.7569\n",
      "Episode:125 meanR:22.5600 R:22.0 loss:13.8259 exploreP:0.7552\n",
      "Episode:126 meanR:22.7500 R:30.0 loss:13.4051 exploreP:0.7530\n",
      "Episode:127 meanR:22.5400 R:22.0 loss:11.6546 exploreP:0.7514\n",
      "Episode:128 meanR:22.2600 R:17.0 loss:11.8494 exploreP:0.7501\n",
      "Episode:129 meanR:22.7900 R:68.0 loss:9.5069 exploreP:0.7451\n",
      "Episode:130 meanR:23.5400 R:91.0 loss:14.9679 exploreP:0.7384\n",
      "Episode:131 meanR:23.8400 R:62.0 loss:43.3258 exploreP:0.7339\n",
      "Episode:132 meanR:23.8200 R:32.0 loss:43.7003 exploreP:0.7316\n",
      "Episode:133 meanR:23.8500 R:38.0 loss:39.8131 exploreP:0.7289\n",
      "Episode:134 meanR:23.8300 R:20.0 loss:33.2075 exploreP:0.7275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:135 meanR:23.8600 R:34.0 loss:26.9404 exploreP:0.7250\n",
      "Episode:136 meanR:23.9500 R:21.0 loss:20.3799 exploreP:0.7235\n",
      "Episode:137 meanR:24.1500 R:32.0 loss:17.7006 exploreP:0.7212\n",
      "Episode:138 meanR:24.5700 R:55.0 loss:14.7786 exploreP:0.7173\n",
      "Episode:139 meanR:25.0300 R:63.0 loss:10.1156 exploreP:0.7129\n",
      "Episode:140 meanR:25.1900 R:26.0 loss:7.6407 exploreP:0.7111\n",
      "Episode:141 meanR:25.1700 R:25.0 loss:9.1568 exploreP:0.7093\n",
      "Episode:142 meanR:25.5400 R:46.0 loss:7.4909 exploreP:0.7061\n",
      "Episode:143 meanR:25.8000 R:38.0 loss:7.5028 exploreP:0.7035\n",
      "Episode:144 meanR:25.6000 R:12.0 loss:6.1893 exploreP:0.7026\n",
      "Episode:145 meanR:25.6300 R:20.0 loss:6.9465 exploreP:0.7013\n",
      "Episode:146 meanR:26.1300 R:73.0 loss:8.7872 exploreP:0.6962\n",
      "Episode:147 meanR:26.2200 R:21.0 loss:24.1319 exploreP:0.6948\n",
      "Episode:148 meanR:26.1900 R:21.0 loss:22.0682 exploreP:0.6933\n",
      "Episode:149 meanR:26.7500 R:75.0 loss:21.4058 exploreP:0.6882\n",
      "Episode:150 meanR:26.8100 R:36.0 loss:17.6730 exploreP:0.6858\n",
      "Episode:151 meanR:26.7300 R:12.0 loss:13.5307 exploreP:0.6850\n",
      "Episode:152 meanR:26.6700 R:30.0 loss:11.9813 exploreP:0.6830\n",
      "Episode:153 meanR:27.1500 R:57.0 loss:11.4751 exploreP:0.6791\n",
      "Episode:154 meanR:27.1500 R:28.0 loss:9.4431 exploreP:0.6773\n",
      "Episode:155 meanR:26.9700 R:14.0 loss:10.0546 exploreP:0.6763\n",
      "Episode:156 meanR:27.0600 R:24.0 loss:10.2516 exploreP:0.6747\n",
      "Episode:157 meanR:26.7400 R:13.0 loss:12.6512 exploreP:0.6739\n",
      "Episode:158 meanR:26.6700 R:18.0 loss:21.6234 exploreP:0.6727\n",
      "Episode:159 meanR:27.6500 R:111.0 loss:42.0156 exploreP:0.6654\n",
      "Episode:160 meanR:27.6700 R:18.0 loss:37.6702 exploreP:0.6642\n",
      "Episode:161 meanR:27.7100 R:28.0 loss:31.9316 exploreP:0.6624\n",
      "Episode:162 meanR:28.0300 R:44.0 loss:22.1717 exploreP:0.6595\n",
      "Episode:163 meanR:28.3400 R:42.0 loss:17.0785 exploreP:0.6568\n",
      "Episode:164 meanR:28.2600 R:18.0 loss:16.4146 exploreP:0.6556\n",
      "Episode:165 meanR:28.5000 R:52.0 loss:12.9554 exploreP:0.6523\n",
      "Episode:166 meanR:28.7200 R:37.0 loss:9.6663 exploreP:0.6499\n",
      "Episode:167 meanR:29.0100 R:40.0 loss:11.1707 exploreP:0.6473\n",
      "Episode:168 meanR:29.3500 R:51.0 loss:10.1215 exploreP:0.6441\n",
      "Episode:169 meanR:29.1700 R:28.0 loss:9.9194 exploreP:0.6423\n",
      "Episode:170 meanR:29.4800 R:48.0 loss:13.4918 exploreP:0.6393\n",
      "Episode:171 meanR:29.4400 R:32.0 loss:25.5772 exploreP:0.6373\n",
      "Episode:172 meanR:29.4600 R:20.0 loss:29.1079 exploreP:0.6360\n",
      "Episode:173 meanR:29.6000 R:40.0 loss:26.8510 exploreP:0.6335\n",
      "Episode:174 meanR:29.9500 R:54.0 loss:24.2754 exploreP:0.6302\n",
      "Episode:175 meanR:29.9800 R:23.0 loss:28.4027 exploreP:0.6288\n",
      "Episode:176 meanR:30.6600 R:84.0 loss:12.2501 exploreP:0.6236\n",
      "Episode:177 meanR:30.7900 R:29.0 loss:9.3339 exploreP:0.6218\n",
      "Episode:178 meanR:31.2400 R:61.0 loss:13.7390 exploreP:0.6181\n",
      "Episode:179 meanR:31.6900 R:61.0 loss:34.9686 exploreP:0.6144\n",
      "Episode:180 meanR:31.5500 R:13.0 loss:56.5919 exploreP:0.6136\n",
      "Episode:181 meanR:31.6900 R:27.0 loss:38.9388 exploreP:0.6120\n",
      "Episode:182 meanR:31.9700 R:40.0 loss:37.1285 exploreP:0.6096\n",
      "Episode:183 meanR:31.9000 R:23.0 loss:42.1930 exploreP:0.6082\n",
      "Episode:184 meanR:31.4300 R:14.0 loss:33.6705 exploreP:0.6074\n",
      "Episode:185 meanR:31.6100 R:37.0 loss:28.7243 exploreP:0.6051\n",
      "Episode:186 meanR:32.0900 R:60.0 loss:21.6673 exploreP:0.6016\n",
      "Episode:187 meanR:32.4100 R:54.0 loss:16.0226 exploreP:0.5984\n",
      "Episode:188 meanR:32.5300 R:25.0 loss:13.2848 exploreP:0.5969\n",
      "Episode:189 meanR:32.5200 R:12.0 loss:11.4519 exploreP:0.5962\n",
      "Episode:190 meanR:32.6200 R:25.0 loss:13.4011 exploreP:0.5948\n",
      "Episode:191 meanR:32.2500 R:22.0 loss:14.0148 exploreP:0.5935\n",
      "Episode:192 meanR:32.7400 R:61.0 loss:23.7109 exploreP:0.5899\n",
      "Episode:193 meanR:33.1900 R:65.0 loss:40.2368 exploreP:0.5862\n",
      "Episode:194 meanR:33.8600 R:79.0 loss:28.9499 exploreP:0.5816\n",
      "Episode:195 meanR:34.2500 R:53.0 loss:15.8546 exploreP:0.5786\n",
      "Episode:196 meanR:34.6900 R:68.0 loss:13.7684 exploreP:0.5748\n",
      "Episode:197 meanR:35.1900 R:72.0 loss:18.6903 exploreP:0.5707\n",
      "Episode:198 meanR:35.6500 R:55.0 loss:34.5684 exploreP:0.5676\n",
      "Episode:199 meanR:36.3600 R:90.0 loss:29.7238 exploreP:0.5626\n",
      "Episode:200 meanR:36.3500 R:12.0 loss:30.3649 exploreP:0.5620\n",
      "Episode:201 meanR:36.2800 R:28.0 loss:26.2907 exploreP:0.5604\n",
      "Episode:202 meanR:36.8000 R:63.0 loss:21.7420 exploreP:0.5570\n",
      "Episode:203 meanR:37.2400 R:57.0 loss:17.8601 exploreP:0.5539\n",
      "Episode:204 meanR:37.7500 R:66.0 loss:16.2825 exploreP:0.5503\n",
      "Episode:205 meanR:38.0700 R:42.0 loss:23.0068 exploreP:0.5480\n",
      "Episode:206 meanR:38.2000 R:35.0 loss:37.3576 exploreP:0.5461\n",
      "Episode:207 meanR:38.6000 R:56.0 loss:54.0737 exploreP:0.5432\n",
      "Episode:208 meanR:38.7200 R:23.0 loss:50.7840 exploreP:0.5419\n",
      "Episode:209 meanR:38.6800 R:17.0 loss:46.0165 exploreP:0.5410\n",
      "Episode:210 meanR:38.6800 R:22.0 loss:40.0074 exploreP:0.5399\n",
      "Episode:211 meanR:38.6800 R:14.0 loss:49.2231 exploreP:0.5391\n",
      "Episode:212 meanR:38.9900 R:58.0 loss:22.4191 exploreP:0.5361\n",
      "Episode:213 meanR:39.2600 R:39.0 loss:16.4697 exploreP:0.5340\n",
      "Episode:214 meanR:39.9100 R:81.0 loss:16.4089 exploreP:0.5298\n",
      "Episode:215 meanR:40.5000 R:89.0 loss:36.5829 exploreP:0.5252\n",
      "Episode:216 meanR:40.1800 R:31.0 loss:34.1693 exploreP:0.5236\n",
      "Episode:217 meanR:39.8800 R:31.0 loss:38.2997 exploreP:0.5220\n",
      "Episode:218 meanR:39.7800 R:44.0 loss:25.0949 exploreP:0.5197\n",
      "Episode:219 meanR:40.0200 R:48.0 loss:19.6429 exploreP:0.5173\n",
      "Episode:220 meanR:39.8800 R:29.0 loss:20.7429 exploreP:0.5158\n",
      "Episode:221 meanR:40.4000 R:71.0 loss:15.5591 exploreP:0.5123\n",
      "Episode:222 meanR:41.2400 R:97.0 loss:33.6979 exploreP:0.5074\n",
      "Episode:223 meanR:41.3400 R:45.0 loss:55.5925 exploreP:0.5052\n",
      "Episode:224 meanR:41.3800 R:28.0 loss:52.5413 exploreP:0.5038\n",
      "Episode:225 meanR:41.4300 R:27.0 loss:45.0522 exploreP:0.5025\n",
      "Episode:226 meanR:41.7800 R:65.0 loss:34.9378 exploreP:0.4993\n",
      "Episode:227 meanR:42.2000 R:64.0 loss:21.2181 exploreP:0.4961\n",
      "Episode:228 meanR:42.4900 R:46.0 loss:14.4538 exploreP:0.4939\n",
      "Episode:229 meanR:42.5000 R:69.0 loss:27.6003 exploreP:0.4906\n",
      "Episode:230 meanR:42.4000 R:81.0 loss:40.9299 exploreP:0.4867\n",
      "Episode:231 meanR:42.4000 R:62.0 loss:28.0852 exploreP:0.4838\n",
      "Episode:232 meanR:42.9000 R:82.0 loss:23.1552 exploreP:0.4799\n",
      "Episode:233 meanR:42.8000 R:28.0 loss:17.0458 exploreP:0.4786\n",
      "Episode:234 meanR:43.3300 R:73.0 loss:22.3536 exploreP:0.4752\n",
      "Episode:235 meanR:43.4500 R:46.0 loss:41.6983 exploreP:0.4730\n",
      "Episode:236 meanR:44.0400 R:80.0 loss:55.2205 exploreP:0.4693\n",
      "Episode:237 meanR:43.8600 R:14.0 loss:48.4445 exploreP:0.4687\n",
      "Episode:238 meanR:43.5100 R:20.0 loss:52.9140 exploreP:0.4678\n",
      "Episode:239 meanR:43.0100 R:13.0 loss:33.0672 exploreP:0.4672\n",
      "Episode:240 meanR:43.0000 R:25.0 loss:25.5061 exploreP:0.4661\n",
      "Episode:241 meanR:43.2400 R:49.0 loss:19.2495 exploreP:0.4638\n",
      "Episode:242 meanR:43.8800 R:110.0 loss:23.4527 exploreP:0.4589\n",
      "Episode:243 meanR:44.0400 R:54.0 loss:29.3629 exploreP:0.4564\n",
      "Episode:244 meanR:44.6200 R:70.0 loss:31.1185 exploreP:0.4533\n",
      "Episode:245 meanR:44.8600 R:44.0 loss:24.7907 exploreP:0.4514\n",
      "Episode:246 meanR:45.1600 R:103.0 loss:24.8786 exploreP:0.4469\n",
      "Episode:247 meanR:45.8700 R:92.0 loss:36.9903 exploreP:0.4429\n",
      "Episode:248 meanR:46.1000 R:44.0 loss:29.5260 exploreP:0.4410\n",
      "Episode:249 meanR:46.2600 R:91.0 loss:28.6834 exploreP:0.4371\n",
      "Episode:250 meanR:46.2000 R:30.0 loss:19.5014 exploreP:0.4358\n",
      "Episode:251 meanR:47.7700 R:169.0 loss:28.2494 exploreP:0.4286\n",
      "Episode:252 meanR:48.9200 R:145.0 loss:27.1168 exploreP:0.4226\n",
      "Episode:253 meanR:49.5000 R:115.0 loss:43.7191 exploreP:0.4179\n",
      "Episode:254 meanR:49.7000 R:48.0 loss:41.4416 exploreP:0.4159\n",
      "Episode:255 meanR:51.8000 R:224.0 loss:29.3768 exploreP:0.4069\n",
      "Episode:256 meanR:52.9700 R:141.0 loss:29.6865 exploreP:0.4014\n",
      "Episode:257 meanR:53.2300 R:39.0 loss:29.5645 exploreP:0.3999\n",
      "Episode:258 meanR:54.1700 R:112.0 loss:28.1935 exploreP:0.3955\n",
      "Episode:259 meanR:54.6100 R:155.0 loss:30.9564 exploreP:0.3896\n",
      "Episode:260 meanR:54.6800 R:25.0 loss:32.3304 exploreP:0.3886\n",
      "Episode:261 meanR:54.9900 R:59.0 loss:31.6932 exploreP:0.3864\n",
      "Episode:262 meanR:55.5900 R:104.0 loss:33.5207 exploreP:0.3825\n",
      "Episode:263 meanR:55.6100 R:44.0 loss:27.6736 exploreP:0.3809\n",
      "Episode:264 meanR:56.3100 R:88.0 loss:29.9257 exploreP:0.3776\n",
      "Episode:265 meanR:56.5500 R:76.0 loss:31.7132 exploreP:0.3749\n",
      "Episode:266 meanR:57.1900 R:101.0 loss:33.4050 exploreP:0.3712\n",
      "Episode:267 meanR:57.7100 R:92.0 loss:31.1834 exploreP:0.3679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:268 meanR:59.4800 R:228.0 loss:33.2643 exploreP:0.3598\n",
      "Episode:269 meanR:60.8500 R:165.0 loss:38.7922 exploreP:0.3541\n",
      "Episode:270 meanR:61.9200 R:155.0 loss:40.7942 exploreP:0.3488\n",
      "Episode:271 meanR:63.1100 R:151.0 loss:43.6326 exploreP:0.3437\n",
      "Episode:272 meanR:64.8400 R:193.0 loss:45.2881 exploreP:0.3373\n",
      "Episode:273 meanR:65.9400 R:150.0 loss:40.1706 exploreP:0.3325\n",
      "Episode:274 meanR:67.3100 R:191.0 loss:46.0008 exploreP:0.3264\n",
      "Episode:275 meanR:68.3800 R:130.0 loss:47.7376 exploreP:0.3223\n",
      "Episode:276 meanR:70.5400 R:300.0 loss:49.1453 exploreP:0.3131\n",
      "Episode:277 meanR:72.8300 R:258.0 loss:55.5783 exploreP:0.3053\n",
      "Episode:278 meanR:73.4700 R:125.0 loss:59.4734 exploreP:0.3017\n",
      "Episode:279 meanR:73.9400 R:108.0 loss:59.6565 exploreP:0.2985\n",
      "Episode:280 meanR:76.6400 R:283.0 loss:56.1810 exploreP:0.2905\n",
      "Episode:281 meanR:78.4700 R:210.0 loss:55.4755 exploreP:0.2847\n",
      "Episode:282 meanR:80.6400 R:257.0 loss:59.1473 exploreP:0.2777\n",
      "Episode:283 meanR:82.2800 R:187.0 loss:62.9589 exploreP:0.2727\n",
      "Episode:284 meanR:87.0100 R:487.0 loss:64.0570 exploreP:0.2602\n",
      "Episode:285 meanR:88.4400 R:180.0 loss:66.5006 exploreP:0.2558\n",
      "Episode:286 meanR:91.1900 R:335.0 loss:71.2655 exploreP:0.2477\n",
      "Episode:287 meanR:93.9200 R:327.0 loss:65.2898 exploreP:0.2400\n",
      "Episode:288 meanR:95.3100 R:164.0 loss:76.9925 exploreP:0.2363\n",
      "Episode:289 meanR:97.3700 R:218.0 loss:65.4587 exploreP:0.2314\n",
      "Episode:290 meanR:97.5200 R:40.0 loss:70.7037 exploreP:0.2305\n",
      "Episode:291 meanR:99.8300 R:253.0 loss:67.7124 exploreP:0.2250\n",
      "Episode:292 meanR:101.7500 R:253.0 loss:68.5667 exploreP:0.2196\n",
      "Episode:293 meanR:103.4800 R:238.0 loss:72.3806 exploreP:0.2147\n",
      "Episode:294 meanR:106.8500 R:416.0 loss:75.2312 exploreP:0.2064\n",
      "Episode:295 meanR:108.0900 R:177.0 loss:78.5650 exploreP:0.2029\n",
      "Episode:296 meanR:109.6200 R:221.0 loss:87.6110 exploreP:0.1987\n",
      "Episode:297 meanR:110.9400 R:204.0 loss:80.3222 exploreP:0.1949\n",
      "Episode:298 meanR:112.6800 R:229.0 loss:89.1954 exploreP:0.1907\n",
      "Episode:299 meanR:114.4000 R:262.0 loss:84.6552 exploreP:0.1860\n",
      "Episode:300 meanR:116.5500 R:227.0 loss:89.4635 exploreP:0.1821\n",
      "Episode:301 meanR:118.3100 R:204.0 loss:104.7383 exploreP:0.1786\n",
      "Episode:302 meanR:119.9000 R:222.0 loss:106.6154 exploreP:0.1749\n",
      "Episode:303 meanR:121.4100 R:208.0 loss:120.4214 exploreP:0.1715\n",
      "Episode:304 meanR:123.5600 R:281.0 loss:110.7031 exploreP:0.1670\n",
      "Episode:305 meanR:126.0300 R:289.0 loss:120.0290 exploreP:0.1626\n",
      "Episode:306 meanR:128.5400 R:286.0 loss:132.1974 exploreP:0.1583\n",
      "Episode:307 meanR:129.6400 R:166.0 loss:129.2380 exploreP:0.1558\n",
      "Episode:308 meanR:133.2900 R:388.0 loss:113.6041 exploreP:0.1503\n",
      "Episode:309 meanR:136.0000 R:288.0 loss:140.9892 exploreP:0.1463\n",
      "Episode:310 meanR:139.9400 R:416.0 loss:126.0062 exploreP:0.1407\n",
      "Episode:311 meanR:143.0100 R:321.0 loss:131.5180 exploreP:0.1366\n",
      "Episode:312 meanR:145.7100 R:328.0 loss:159.3246 exploreP:0.1325\n",
      "Episode:313 meanR:149.3100 R:399.0 loss:139.6501 exploreP:0.1277\n",
      "Episode:314 meanR:152.6800 R:418.0 loss:133.3599 exploreP:0.1229\n",
      "Episode:315 meanR:154.1300 R:234.0 loss:159.6075 exploreP:0.1203\n",
      "Episode:316 meanR:157.0200 R:320.0 loss:140.9137 exploreP:0.1168\n",
      "Episode:317 meanR:160.1300 R:342.0 loss:147.5802 exploreP:0.1132\n",
      "Episode:318 meanR:161.7000 R:201.0 loss:142.2782 exploreP:0.1112\n",
      "Episode:319 meanR:163.8500 R:263.0 loss:163.3355 exploreP:0.1086\n",
      "Episode:320 meanR:166.5300 R:297.0 loss:120.2975 exploreP:0.1057\n",
      "Episode:321 meanR:168.5100 R:269.0 loss:116.9019 exploreP:0.1031\n",
      "Episode:322 meanR:172.5400 R:500.0 loss:238.8433 exploreP:0.0986\n",
      "Episode:323 meanR:177.0900 R:500.0 loss:292.7287 exploreP:0.0943\n",
      "Episode:324 meanR:181.3700 R:456.0 loss:224.9068 exploreP:0.0905\n",
      "Episode:325 meanR:183.5700 R:247.0 loss:216.3412 exploreP:0.0885\n",
      "Episode:326 meanR:186.1400 R:322.0 loss:187.2398 exploreP:0.0861\n",
      "Episode:327 meanR:187.6400 R:214.0 loss:250.7618 exploreP:0.0844\n",
      "Episode:328 meanR:189.4900 R:231.0 loss:170.1300 exploreP:0.0827\n",
      "Episode:329 meanR:193.0900 R:429.0 loss:187.4588 exploreP:0.0797\n",
      "Episode:330 meanR:194.8700 R:259.0 loss:154.6427 exploreP:0.0779\n",
      "Episode:331 meanR:197.4800 R:323.0 loss:154.9898 exploreP:0.0758\n",
      "Episode:332 meanR:198.8800 R:222.0 loss:252.7084 exploreP:0.0743\n",
      "Episode:333 meanR:201.4400 R:284.0 loss:131.8930 exploreP:0.0725\n",
      "Episode:334 meanR:204.5300 R:382.0 loss:223.4928 exploreP:0.0702\n",
      "Episode:335 meanR:206.1200 R:205.0 loss:111.2590 exploreP:0.0689\n",
      "Episode:336 meanR:207.9400 R:262.0 loss:271.1135 exploreP:0.0674\n",
      "Episode:337 meanR:210.2900 R:249.0 loss:109.0603 exploreP:0.0660\n",
      "Episode:338 meanR:212.0800 R:199.0 loss:273.3595 exploreP:0.0649\n",
      "Episode:339 meanR:213.8600 R:191.0 loss:220.6889 exploreP:0.0639\n",
      "Episode:340 meanR:215.6700 R:206.0 loss:157.0220 exploreP:0.0628\n",
      "Episode:341 meanR:218.6500 R:347.0 loss:182.7693 exploreP:0.0610\n",
      "Episode:342 meanR:219.4500 R:190.0 loss:241.4147 exploreP:0.0600\n",
      "Episode:343 meanR:221.4800 R:257.0 loss:261.7243 exploreP:0.0587\n",
      "Episode:344 meanR:222.8900 R:211.0 loss:145.5755 exploreP:0.0577\n",
      "Episode:345 meanR:224.3200 R:187.0 loss:292.0479 exploreP:0.0568\n",
      "Episode:346 meanR:226.5600 R:327.0 loss:192.8061 exploreP:0.0553\n",
      "Episode:347 meanR:227.3600 R:172.0 loss:288.2585 exploreP:0.0546\n",
      "Episode:348 meanR:229.6100 R:269.0 loss:177.4674 exploreP:0.0534\n",
      "Episode:349 meanR:233.0700 R:437.0 loss:229.8644 exploreP:0.0515\n",
      "Episode:350 meanR:236.4600 R:369.0 loss:158.9362 exploreP:0.0500\n",
      "Episode:351 meanR:237.8700 R:310.0 loss:285.8163 exploreP:0.0488\n",
      "Episode:352 meanR:241.4200 R:500.0 loss:214.2535 exploreP:0.0469\n",
      "Episode:353 meanR:241.8000 R:153.0 loss:96.7227 exploreP:0.0463\n",
      "Episode:354 meanR:243.8100 R:249.0 loss:233.2700 exploreP:0.0454\n",
      "Episode:355 meanR:242.7600 R:119.0 loss:310.6429 exploreP:0.0450\n",
      "Episode:356 meanR:246.3500 R:500.0 loss:236.0524 exploreP:0.0433\n",
      "Episode:357 meanR:247.5900 R:163.0 loss:279.0016 exploreP:0.0428\n",
      "Episode:358 meanR:247.9500 R:148.0 loss:208.0803 exploreP:0.0423\n",
      "Episode:359 meanR:249.1400 R:274.0 loss:322.9729 exploreP:0.0414\n",
      "Episode:360 meanR:249.3400 R:45.0 loss:300.2168 exploreP:0.0413\n",
      "Episode:361 meanR:250.0300 R:128.0 loss:277.2117 exploreP:0.0409\n",
      "Episode:362 meanR:250.7700 R:178.0 loss:255.1813 exploreP:0.0403\n",
      "Episode:363 meanR:251.2600 R:93.0 loss:339.4105 exploreP:0.0401\n",
      "Episode:364 meanR:250.4800 R:10.0 loss:184.2626 exploreP:0.0400\n",
      "Episode:365 meanR:249.8200 R:10.0 loss:386.5697 exploreP:0.0400\n",
      "Episode:366 meanR:248.9100 R:10.0 loss:176.1543 exploreP:0.0400\n",
      "Episode:367 meanR:249.1300 R:114.0 loss:426.9460 exploreP:0.0396\n",
      "Episode:368 meanR:246.9500 R:10.0 loss:881.2144 exploreP:0.0396\n",
      "Episode:369 meanR:245.4000 R:10.0 loss:392.4683 exploreP:0.0396\n",
      "Episode:370 meanR:243.9500 R:10.0 loss:1033.9524 exploreP:0.0395\n",
      "Episode:371 meanR:242.5300 R:9.0 loss:398.2017 exploreP:0.0395\n",
      "Episode:372 meanR:240.6900 R:9.0 loss:304.5283 exploreP:0.0395\n",
      "Episode:373 meanR:239.2800 R:9.0 loss:311.4819 exploreP:0.0395\n",
      "Episode:374 meanR:237.4700 R:10.0 loss:250.6595 exploreP:0.0394\n",
      "Episode:375 meanR:236.2700 R:10.0 loss:336.6005 exploreP:0.0394\n",
      "Episode:376 meanR:233.3800 R:11.0 loss:323.9347 exploreP:0.0394\n",
      "Episode:377 meanR:230.8900 R:9.0 loss:600.3616 exploreP:0.0393\n",
      "Episode:378 meanR:229.7400 R:10.0 loss:451.2543 exploreP:0.0393\n",
      "Episode:379 meanR:228.7600 R:10.0 loss:607.5194 exploreP:0.0393\n",
      "Episode:380 meanR:226.1000 R:17.0 loss:492.9546 exploreP:0.0392\n",
      "Episode:381 meanR:225.1000 R:110.0 loss:366.3645 exploreP:0.0389\n",
      "Episode:382 meanR:222.6200 R:9.0 loss:391.4673 exploreP:0.0389\n",
      "Episode:383 meanR:220.8400 R:9.0 loss:210.8589 exploreP:0.0389\n",
      "Episode:384 meanR:216.1000 R:13.0 loss:181.4713 exploreP:0.0388\n",
      "Episode:385 meanR:214.3900 R:9.0 loss:220.2298 exploreP:0.0388\n",
      "Episode:386 meanR:211.1300 R:9.0 loss:784.3793 exploreP:0.0388\n",
      "Episode:387 meanR:207.9600 R:10.0 loss:136.7693 exploreP:0.0387\n",
      "Episode:388 meanR:206.5000 R:18.0 loss:291.8370 exploreP:0.0387\n",
      "Episode:389 meanR:204.4100 R:9.0 loss:474.8036 exploreP:0.0387\n",
      "Episode:390 meanR:204.1000 R:9.0 loss:83.2607 exploreP:0.0386\n",
      "Episode:391 meanR:201.7400 R:17.0 loss:283.1061 exploreP:0.0386\n",
      "Episode:392 meanR:199.3100 R:10.0 loss:318.7128 exploreP:0.0386\n",
      "Episode:393 meanR:197.0600 R:13.0 loss:289.4231 exploreP:0.0385\n",
      "Episode:394 meanR:193.0000 R:10.0 loss:538.4865 exploreP:0.0385\n",
      "Episode:395 meanR:191.3300 R:10.0 loss:190.7768 exploreP:0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:396 meanR:189.2200 R:10.0 loss:287.3043 exploreP:0.0384\n",
      "Episode:397 meanR:187.2900 R:11.0 loss:343.6892 exploreP:0.0384\n",
      "Episode:398 meanR:185.1000 R:10.0 loss:782.5922 exploreP:0.0384\n",
      "Episode:399 meanR:182.6100 R:13.0 loss:448.9985 exploreP:0.0383\n",
      "Episode:400 meanR:180.5100 R:17.0 loss:301.5961 exploreP:0.0383\n",
      "Episode:401 meanR:179.3000 R:83.0 loss:242.5526 exploreP:0.0381\n",
      "Episode:402 meanR:178.2500 R:117.0 loss:391.7923 exploreP:0.0377\n",
      "Episode:403 meanR:176.2700 R:10.0 loss:900.0452 exploreP:0.0377\n",
      "Episode:404 meanR:173.5600 R:10.0 loss:354.6699 exploreP:0.0377\n",
      "Episode:405 meanR:170.8000 R:13.0 loss:340.9233 exploreP:0.0376\n",
      "Episode:406 meanR:168.1300 R:19.0 loss:550.8918 exploreP:0.0376\n",
      "Episode:407 meanR:166.6500 R:18.0 loss:272.3228 exploreP:0.0375\n",
      "Episode:408 meanR:162.8700 R:10.0 loss:348.6152 exploreP:0.0375\n",
      "Episode:409 meanR:160.0800 R:9.0 loss:565.2644 exploreP:0.0375\n",
      "Episode:410 meanR:156.0100 R:9.0 loss:180.5305 exploreP:0.0375\n",
      "Episode:411 meanR:152.9200 R:12.0 loss:247.7065 exploreP:0.0374\n",
      "Episode:412 meanR:149.7300 R:9.0 loss:268.5059 exploreP:0.0374\n",
      "Episode:413 meanR:145.8400 R:10.0 loss:305.8903 exploreP:0.0374\n",
      "Episode:414 meanR:141.7800 R:12.0 loss:267.2940 exploreP:0.0374\n",
      "Episode:415 meanR:139.5500 R:11.0 loss:337.1923 exploreP:0.0373\n",
      "Episode:416 meanR:136.4500 R:10.0 loss:429.2980 exploreP:0.0373\n",
      "Episode:417 meanR:133.1200 R:9.0 loss:326.1489 exploreP:0.0373\n",
      "Episode:418 meanR:132.0400 R:93.0 loss:298.7289 exploreP:0.0370\n",
      "Episode:419 meanR:129.5300 R:12.0 loss:383.8925 exploreP:0.0370\n",
      "Episode:420 meanR:126.6500 R:9.0 loss:247.3977 exploreP:0.0370\n",
      "Episode:421 meanR:124.0600 R:10.0 loss:204.5448 exploreP:0.0369\n",
      "Episode:422 meanR:119.1500 R:9.0 loss:336.3160 exploreP:0.0369\n",
      "Episode:423 meanR:114.2400 R:9.0 loss:273.0339 exploreP:0.0369\n",
      "Episode:424 meanR:109.7900 R:11.0 loss:285.6059 exploreP:0.0369\n",
      "Episode:425 meanR:107.4300 R:11.0 loss:194.4597 exploreP:0.0368\n",
      "Episode:426 meanR:104.3100 R:10.0 loss:398.6104 exploreP:0.0368\n",
      "Episode:427 meanR:102.2800 R:11.0 loss:129.2540 exploreP:0.0368\n",
      "Episode:428 meanR:100.0700 R:10.0 loss:210.3605 exploreP:0.0367\n",
      "Episode:429 meanR:96.9200 R:114.0 loss:319.7600 exploreP:0.0364\n",
      "Episode:430 meanR:94.4200 R:9.0 loss:251.1397 exploreP:0.0364\n",
      "Episode:431 meanR:91.3200 R:13.0 loss:778.5335 exploreP:0.0364\n",
      "Episode:432 meanR:89.3900 R:29.0 loss:230.7505 exploreP:0.0363\n",
      "Episode:433 meanR:86.6500 R:10.0 loss:293.7857 exploreP:0.0363\n",
      "Episode:434 meanR:82.9200 R:9.0 loss:145.7469 exploreP:0.0363\n",
      "Episode:435 meanR:81.1100 R:24.0 loss:425.4710 exploreP:0.0362\n",
      "Episode:436 meanR:79.1900 R:70.0 loss:381.1077 exploreP:0.0360\n",
      "Episode:437 meanR:76.8000 R:10.0 loss:432.2260 exploreP:0.0360\n",
      "Episode:438 meanR:75.0500 R:24.0 loss:488.0378 exploreP:0.0359\n",
      "Episode:439 meanR:73.3600 R:22.0 loss:428.5959 exploreP:0.0359\n",
      "Episode:440 meanR:71.4800 R:18.0 loss:505.2592 exploreP:0.0358\n",
      "Episode:441 meanR:70.1000 R:209.0 loss:318.1722 exploreP:0.0353\n",
      "Episode:442 meanR:68.3000 R:10.0 loss:396.2430 exploreP:0.0353\n",
      "Episode:443 meanR:65.8300 R:10.0 loss:475.8481 exploreP:0.0352\n",
      "Episode:444 meanR:63.9300 R:21.0 loss:321.4856 exploreP:0.0352\n",
      "Episode:445 meanR:62.1600 R:10.0 loss:475.7915 exploreP:0.0352\n",
      "Episode:446 meanR:60.9100 R:202.0 loss:387.6532 exploreP:0.0347\n",
      "Episode:447 meanR:59.2900 R:10.0 loss:197.2691 exploreP:0.0346\n",
      "Episode:448 meanR:58.3500 R:175.0 loss:477.9492 exploreP:0.0342\n",
      "Episode:449 meanR:55.6800 R:170.0 loss:594.2447 exploreP:0.0338\n",
      "Episode:450 meanR:54.1300 R:214.0 loss:525.4398 exploreP:0.0333\n",
      "Episode:451 meanR:53.3900 R:236.0 loss:506.1414 exploreP:0.0327\n",
      "Episode:452 meanR:50.2800 R:189.0 loss:640.5203 exploreP:0.0323\n",
      "Episode:453 meanR:50.8000 R:205.0 loss:711.6290 exploreP:0.0319\n",
      "Episode:454 meanR:50.3700 R:206.0 loss:707.7604 exploreP:0.0314\n",
      "Episode:455 meanR:51.7500 R:257.0 loss:650.3683 exploreP:0.0309\n",
      "Episode:456 meanR:48.4000 R:165.0 loss:821.9731 exploreP:0.0305\n",
      "Episode:457 meanR:49.9400 R:317.0 loss:678.6125 exploreP:0.0299\n",
      "Episode:458 meanR:50.1900 R:173.0 loss:730.8095 exploreP:0.0296\n",
      "Episode:459 meanR:48.4300 R:98.0 loss:595.3254 exploreP:0.0294\n",
      "Episode:460 meanR:48.5100 R:53.0 loss:690.4923 exploreP:0.0293\n",
      "Episode:461 meanR:48.0800 R:85.0 loss:702.7841 exploreP:0.0291\n",
      "Episode:462 meanR:48.4700 R:217.0 loss:690.8220 exploreP:0.0287\n",
      "Episode:463 meanR:48.5400 R:100.0 loss:660.1887 exploreP:0.0285\n",
      "Episode:464 meanR:51.0900 R:265.0 loss:872.3338 exploreP:0.0280\n",
      "Episode:465 meanR:53.6600 R:267.0 loss:782.1561 exploreP:0.0275\n",
      "Episode:466 meanR:54.0700 R:51.0 loss:965.4351 exploreP:0.0275\n",
      "Episode:467 meanR:53.3400 R:41.0 loss:1015.4912 exploreP:0.0274\n",
      "Episode:468 meanR:53.6000 R:36.0 loss:934.5706 exploreP:0.0273\n",
      "Episode:469 meanR:53.8700 R:37.0 loss:966.4682 exploreP:0.0273\n",
      "Episode:470 meanR:54.4400 R:67.0 loss:735.1166 exploreP:0.0271\n",
      "Episode:471 meanR:54.9700 R:62.0 loss:677.7068 exploreP:0.0270\n",
      "Episode:472 meanR:56.5000 R:162.0 loss:704.9511 exploreP:0.0268\n",
      "Episode:473 meanR:58.2100 R:180.0 loss:829.9679 exploreP:0.0265\n",
      "Episode:474 meanR:61.4700 R:336.0 loss:809.0746 exploreP:0.0259\n",
      "Episode:475 meanR:63.0200 R:165.0 loss:963.7519 exploreP:0.0257\n",
      "Episode:476 meanR:65.4100 R:250.0 loss:938.9730 exploreP:0.0253\n",
      "Episode:477 meanR:69.1400 R:382.0 loss:957.0839 exploreP:0.0247\n",
      "Episode:478 meanR:71.0900 R:205.0 loss:1282.9240 exploreP:0.0244\n",
      "Episode:479 meanR:73.4000 R:241.0 loss:1306.8042 exploreP:0.0241\n",
      "Episode:480 meanR:75.5600 R:233.0 loss:1304.5842 exploreP:0.0237\n",
      "Episode:481 meanR:76.2400 R:178.0 loss:1173.7233 exploreP:0.0235\n",
      "Episode:482 meanR:79.7800 R:363.0 loss:1375.2522 exploreP:0.0230\n",
      "Episode:483 meanR:81.5700 R:188.0 loss:1541.7472 exploreP:0.0228\n",
      "Episode:484 meanR:86.0800 R:464.0 loss:1216.7629 exploreP:0.0222\n",
      "Episode:485 meanR:89.6400 R:365.0 loss:1197.0542 exploreP:0.0218\n",
      "Episode:486 meanR:90.0600 R:51.0 loss:1730.2850 exploreP:0.0217\n",
      "Episode:487 meanR:90.2900 R:33.0 loss:2063.2178 exploreP:0.0217\n",
      "Episode:488 meanR:90.4100 R:30.0 loss:2189.4409 exploreP:0.0216\n",
      "Episode:489 meanR:92.7500 R:243.0 loss:1603.8783 exploreP:0.0213\n",
      "Episode:490 meanR:92.9400 R:28.0 loss:3517.5024 exploreP:0.0213\n",
      "Episode:491 meanR:93.1700 R:40.0 loss:2707.1826 exploreP:0.0213\n",
      "Episode:492 meanR:93.5100 R:44.0 loss:1852.6564 exploreP:0.0212\n",
      "Episode:493 meanR:96.0800 R:270.0 loss:1662.8633 exploreP:0.0209\n",
      "Episode:494 meanR:96.5200 R:54.0 loss:683.1236 exploreP:0.0209\n",
      "Episode:495 meanR:96.6500 R:23.0 loss:4628.1890 exploreP:0.0208\n",
      "Episode:496 meanR:98.2900 R:174.0 loss:2371.5164 exploreP:0.0206\n",
      "Episode:497 meanR:98.5500 R:37.0 loss:2375.6582 exploreP:0.0206\n",
      "Episode:498 meanR:98.7400 R:29.0 loss:1296.5513 exploreP:0.0206\n",
      "Episode:499 meanR:98.7600 R:15.0 loss:2382.5149 exploreP:0.0206\n",
      "Episode:500 meanR:98.9600 R:37.0 loss:1595.9768 exploreP:0.0205\n",
      "Episode:501 meanR:98.3300 R:20.0 loss:844.7135 exploreP:0.0205\n",
      "Episode:502 meanR:97.4600 R:30.0 loss:3216.1267 exploreP:0.0205\n",
      "Episode:503 meanR:97.6300 R:27.0 loss:2144.2151 exploreP:0.0204\n",
      "Episode:504 meanR:97.8300 R:30.0 loss:1818.6521 exploreP:0.0204\n",
      "Episode:505 meanR:97.9700 R:27.0 loss:3103.6455 exploreP:0.0204\n",
      "Episode:506 meanR:97.9700 R:19.0 loss:811.5760 exploreP:0.0204\n",
      "Episode:507 meanR:98.0100 R:22.0 loss:2476.7739 exploreP:0.0203\n",
      "Episode:508 meanR:98.0900 R:18.0 loss:1866.8387 exploreP:0.0203\n",
      "Episode:509 meanR:98.5200 R:52.0 loss:1966.3868 exploreP:0.0203\n",
      "Episode:510 meanR:98.5900 R:16.0 loss:843.4244 exploreP:0.0202\n",
      "Episode:511 meanR:98.6300 R:16.0 loss:1025.1858 exploreP:0.0202\n",
      "Episode:512 meanR:98.8800 R:34.0 loss:1731.9229 exploreP:0.0202\n",
      "Episode:513 meanR:99.2300 R:45.0 loss:1576.5410 exploreP:0.0202\n",
      "Episode:514 meanR:99.4600 R:35.0 loss:1661.8124 exploreP:0.0201\n",
      "Episode:515 meanR:99.9700 R:62.0 loss:2281.8569 exploreP:0.0201\n",
      "Episode:516 meanR:100.4100 R:54.0 loss:1892.0072 exploreP:0.0200\n",
      "Episode:517 meanR:101.1800 R:86.0 loss:1543.3293 exploreP:0.0199\n",
      "Episode:518 meanR:100.3500 R:10.0 loss:3999.9321 exploreP:0.0199\n",
      "Episode:519 meanR:100.3400 R:11.0 loss:815.5206 exploreP:0.0199\n",
      "Episode:520 meanR:100.4400 R:19.0 loss:4243.2983 exploreP:0.0199\n",
      "Episode:521 meanR:100.4900 R:15.0 loss:2571.3159 exploreP:0.0199\n",
      "Episode:522 meanR:100.5000 R:10.0 loss:1163.7711 exploreP:0.0199\n",
      "Episode:523 meanR:100.6200 R:21.0 loss:3669.8105 exploreP:0.0198\n",
      "Episode:524 meanR:100.6900 R:18.0 loss:1170.3413 exploreP:0.0198\n",
      "Episode:525 meanR:100.6800 R:10.0 loss:8631.5146 exploreP:0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:526 meanR:100.8000 R:22.0 loss:5813.0620 exploreP:0.0198\n",
      "Episode:527 meanR:100.9600 R:27.0 loss:2779.1011 exploreP:0.0198\n",
      "Episode:528 meanR:101.3200 R:46.0 loss:2401.9971 exploreP:0.0197\n",
      "Episode:529 meanR:100.6100 R:43.0 loss:2292.7275 exploreP:0.0197\n",
      "Episode:530 meanR:100.7200 R:20.0 loss:2703.8145 exploreP:0.0196\n",
      "Episode:531 meanR:104.3000 R:371.0 loss:2736.7996 exploreP:0.0193\n",
      "Episode:532 meanR:104.1400 R:13.0 loss:1407.4884 exploreP:0.0193\n",
      "Episode:533 meanR:104.2000 R:16.0 loss:2172.2971 exploreP:0.0193\n",
      "Episode:534 meanR:104.2700 R:16.0 loss:3021.2444 exploreP:0.0193\n",
      "Episode:535 meanR:104.1300 R:10.0 loss:1056.3794 exploreP:0.0192\n",
      "Episode:536 meanR:103.5200 R:9.0 loss:1302.6982 exploreP:0.0192\n",
      "Episode:537 meanR:103.5200 R:10.0 loss:361.2984 exploreP:0.0192\n",
      "Episode:538 meanR:103.3800 R:10.0 loss:3241.3257 exploreP:0.0192\n",
      "Episode:539 meanR:103.2600 R:10.0 loss:1974.4030 exploreP:0.0192\n",
      "Episode:540 meanR:103.3600 R:28.0 loss:1742.9647 exploreP:0.0192\n",
      "Episode:541 meanR:101.4700 R:20.0 loss:3664.3667 exploreP:0.0192\n",
      "Episode:542 meanR:101.5500 R:18.0 loss:3076.3328 exploreP:0.0191\n",
      "Episode:543 meanR:101.6600 R:21.0 loss:3285.8347 exploreP:0.0191\n",
      "Episode:544 meanR:101.5900 R:14.0 loss:3304.3413 exploreP:0.0191\n",
      "Episode:545 meanR:101.7100 R:22.0 loss:2044.3500 exploreP:0.0191\n",
      "Episode:546 meanR:99.8500 R:16.0 loss:2373.4509 exploreP:0.0191\n",
      "Episode:547 meanR:100.0000 R:25.0 loss:1994.5808 exploreP:0.0191\n",
      "Episode:548 meanR:98.4300 R:18.0 loss:2254.1902 exploreP:0.0190\n",
      "Episode:549 meanR:96.9000 R:17.0 loss:2193.9475 exploreP:0.0190\n",
      "Episode:550 meanR:95.0000 R:24.0 loss:4140.3911 exploreP:0.0190\n",
      "Episode:551 meanR:92.8600 R:22.0 loss:4487.8184 exploreP:0.0190\n",
      "Episode:552 meanR:91.1400 R:17.0 loss:1305.5570 exploreP:0.0190\n",
      "Episode:553 meanR:89.2800 R:19.0 loss:1146.2875 exploreP:0.0190\n",
      "Episode:554 meanR:87.3800 R:16.0 loss:762.7446 exploreP:0.0189\n",
      "Episode:555 meanR:85.0000 R:19.0 loss:1658.2898 exploreP:0.0189\n",
      "Episode:556 meanR:83.4700 R:12.0 loss:927.1252 exploreP:0.0189\n",
      "Episode:557 meanR:80.4100 R:11.0 loss:1278.5284 exploreP:0.0189\n",
      "Episode:558 meanR:78.8200 R:14.0 loss:2022.0704 exploreP:0.0189\n",
      "Episode:559 meanR:77.9900 R:15.0 loss:2963.3911 exploreP:0.0189\n",
      "Episode:560 meanR:77.5700 R:11.0 loss:426.8194 exploreP:0.0189\n",
      "Episode:561 meanR:76.8700 R:15.0 loss:1561.6472 exploreP:0.0189\n",
      "Episode:562 meanR:74.8200 R:12.0 loss:749.2322 exploreP:0.0188\n",
      "Episode:563 meanR:73.9500 R:13.0 loss:2028.2179 exploreP:0.0188\n",
      "Episode:564 meanR:71.4300 R:13.0 loss:1067.6859 exploreP:0.0188\n",
      "Episode:565 meanR:69.0100 R:25.0 loss:5080.3970 exploreP:0.0188\n",
      "Episode:566 meanR:68.8700 R:37.0 loss:1752.8386 exploreP:0.0188\n",
      "Episode:567 meanR:68.7200 R:26.0 loss:2111.7253 exploreP:0.0187\n",
      "Episode:568 meanR:68.5800 R:22.0 loss:1418.9614 exploreP:0.0187\n",
      "Episode:569 meanR:68.4100 R:20.0 loss:903.9032 exploreP:0.0187\n",
      "Episode:570 meanR:67.9100 R:17.0 loss:2400.8037 exploreP:0.0187\n",
      "Episode:571 meanR:67.6100 R:32.0 loss:2626.4607 exploreP:0.0187\n",
      "Episode:572 meanR:66.3200 R:33.0 loss:2632.6030 exploreP:0.0186\n",
      "Episode:573 meanR:65.0000 R:48.0 loss:3665.5134 exploreP:0.0186\n",
      "Episode:574 meanR:61.9400 R:30.0 loss:2216.6748 exploreP:0.0186\n",
      "Episode:575 meanR:60.5700 R:28.0 loss:3584.3867 exploreP:0.0185\n",
      "Episode:576 meanR:58.3500 R:28.0 loss:2315.8015 exploreP:0.0185\n",
      "Episode:577 meanR:54.8700 R:34.0 loss:2327.8352 exploreP:0.0185\n",
      "Episode:578 meanR:53.0900 R:27.0 loss:1765.8982 exploreP:0.0185\n",
      "Episode:579 meanR:50.8400 R:16.0 loss:2364.4329 exploreP:0.0185\n",
      "Episode:580 meanR:48.6200 R:11.0 loss:854.4283 exploreP:0.0184\n",
      "Episode:581 meanR:46.9600 R:12.0 loss:1620.6188 exploreP:0.0184\n",
      "Episode:582 meanR:43.4500 R:12.0 loss:346.5439 exploreP:0.0184\n",
      "Episode:583 meanR:41.7500 R:18.0 loss:1949.8229 exploreP:0.0184\n",
      "Episode:584 meanR:37.2600 R:15.0 loss:2112.9795 exploreP:0.0184\n",
      "Episode:585 meanR:33.7400 R:13.0 loss:5429.7422 exploreP:0.0184\n",
      "Episode:586 meanR:33.4200 R:19.0 loss:918.5144 exploreP:0.0184\n",
      "Episode:587 meanR:33.2800 R:19.0 loss:3708.8328 exploreP:0.0184\n",
      "Episode:588 meanR:33.1900 R:21.0 loss:1398.2233 exploreP:0.0183\n",
      "Episode:589 meanR:30.9800 R:22.0 loss:1001.4851 exploreP:0.0183\n",
      "Episode:590 meanR:31.0200 R:32.0 loss:1120.2029 exploreP:0.0183\n",
      "Episode:591 meanR:31.2300 R:61.0 loss:1820.0505 exploreP:0.0182\n",
      "Episode:592 meanR:31.1700 R:38.0 loss:1243.6559 exploreP:0.0182\n",
      "Episode:593 meanR:28.7800 R:31.0 loss:1925.6833 exploreP:0.0182\n",
      "Episode:594 meanR:28.5100 R:27.0 loss:623.8954 exploreP:0.0182\n",
      "Episode:595 meanR:28.5800 R:30.0 loss:1642.0901 exploreP:0.0181\n",
      "Episode:596 meanR:26.9800 R:14.0 loss:471.5526 exploreP:0.0181\n",
      "Episode:597 meanR:26.7700 R:16.0 loss:1088.5050 exploreP:0.0181\n",
      "Episode:598 meanR:26.7100 R:23.0 loss:2534.2788 exploreP:0.0181\n",
      "Episode:599 meanR:26.7300 R:17.0 loss:1927.8341 exploreP:0.0181\n",
      "Episode:600 meanR:26.5600 R:20.0 loss:1599.2394 exploreP:0.0181\n",
      "Episode:601 meanR:26.5800 R:22.0 loss:1704.9602 exploreP:0.0180\n",
      "Episode:602 meanR:26.4000 R:12.0 loss:1463.2167 exploreP:0.0180\n",
      "Episode:603 meanR:26.2500 R:12.0 loss:2375.7156 exploreP:0.0180\n",
      "Episode:604 meanR:26.0600 R:11.0 loss:3563.5110 exploreP:0.0180\n",
      "Episode:605 meanR:25.9200 R:13.0 loss:864.5234 exploreP:0.0180\n",
      "Episode:606 meanR:25.8300 R:10.0 loss:528.8119 exploreP:0.0180\n",
      "Episode:607 meanR:25.8200 R:21.0 loss:1457.3245 exploreP:0.0180\n",
      "Episode:608 meanR:25.9100 R:27.0 loss:2604.6301 exploreP:0.0180\n",
      "Episode:609 meanR:25.5100 R:12.0 loss:1780.1718 exploreP:0.0180\n",
      "Episode:610 meanR:25.4700 R:12.0 loss:5185.8716 exploreP:0.0179\n",
      "Episode:611 meanR:25.4100 R:10.0 loss:2129.6992 exploreP:0.0179\n",
      "Episode:612 meanR:25.1900 R:12.0 loss:6306.8540 exploreP:0.0179\n",
      "Episode:613 meanR:24.8400 R:10.0 loss:2116.9578 exploreP:0.0179\n",
      "Episode:614 meanR:24.7000 R:21.0 loss:1985.0604 exploreP:0.0179\n",
      "Episode:615 meanR:24.1900 R:11.0 loss:4317.8721 exploreP:0.0179\n",
      "Episode:616 meanR:23.7600 R:11.0 loss:3304.8857 exploreP:0.0179\n",
      "Episode:617 meanR:23.0200 R:12.0 loss:6130.0913 exploreP:0.0179\n",
      "Episode:618 meanR:23.0300 R:11.0 loss:4064.8657 exploreP:0.0179\n",
      "Episode:619 meanR:23.0200 R:10.0 loss:1193.0339 exploreP:0.0179\n",
      "Episode:620 meanR:22.9300 R:10.0 loss:1637.3701 exploreP:0.0179\n",
      "Episode:621 meanR:22.8700 R:9.0 loss:2818.1802 exploreP:0.0178\n",
      "Episode:622 meanR:22.8600 R:9.0 loss:1890.8094 exploreP:0.0178\n",
      "Episode:623 meanR:22.8300 R:18.0 loss:3295.3750 exploreP:0.0178\n",
      "Episode:624 meanR:22.9100 R:26.0 loss:1279.9843 exploreP:0.0178\n",
      "Episode:625 meanR:23.0200 R:21.0 loss:1701.3214 exploreP:0.0178\n",
      "Episode:626 meanR:23.0300 R:23.0 loss:2110.2788 exploreP:0.0178\n",
      "Episode:627 meanR:23.1300 R:37.0 loss:3539.7163 exploreP:0.0177\n",
      "Episode:628 meanR:22.9200 R:25.0 loss:1098.3938 exploreP:0.0177\n",
      "Episode:629 meanR:22.8400 R:35.0 loss:2019.0748 exploreP:0.0177\n",
      "Episode:630 meanR:22.9700 R:33.0 loss:1545.8115 exploreP:0.0177\n",
      "Episode:631 meanR:19.5900 R:33.0 loss:1954.5273 exploreP:0.0176\n",
      "Episode:632 meanR:19.7100 R:25.0 loss:1404.7416 exploreP:0.0176\n",
      "Episode:633 meanR:19.9200 R:37.0 loss:1749.0698 exploreP:0.0176\n",
      "Episode:634 meanR:20.0100 R:25.0 loss:1500.6301 exploreP:0.0176\n",
      "Episode:635 meanR:20.2100 R:30.0 loss:1510.2452 exploreP:0.0176\n",
      "Episode:636 meanR:20.3600 R:24.0 loss:2304.2332 exploreP:0.0175\n",
      "Episode:637 meanR:20.5200 R:26.0 loss:3024.8545 exploreP:0.0175\n",
      "Episode:638 meanR:20.6600 R:24.0 loss:2165.5833 exploreP:0.0175\n",
      "Episode:639 meanR:20.8900 R:33.0 loss:2585.3862 exploreP:0.0175\n",
      "Episode:640 meanR:20.8400 R:23.0 loss:1845.6646 exploreP:0.0175\n",
      "Episode:641 meanR:20.8700 R:23.0 loss:2350.7856 exploreP:0.0174\n",
      "Episode:642 meanR:20.8900 R:20.0 loss:3544.0469 exploreP:0.0174\n",
      "Episode:643 meanR:20.9100 R:23.0 loss:3321.1372 exploreP:0.0174\n",
      "Episode:644 meanR:21.0600 R:29.0 loss:2458.7388 exploreP:0.0174\n",
      "Episode:645 meanR:21.1300 R:29.0 loss:2758.9963 exploreP:0.0174\n",
      "Episode:646 meanR:21.1700 R:20.0 loss:3664.3660 exploreP:0.0174\n",
      "Episode:647 meanR:21.1500 R:23.0 loss:2147.4172 exploreP:0.0173\n",
      "Episode:648 meanR:21.2600 R:29.0 loss:1588.4387 exploreP:0.0173\n",
      "Episode:649 meanR:21.3600 R:27.0 loss:1657.4406 exploreP:0.0173\n",
      "Episode:650 meanR:21.3800 R:26.0 loss:2865.5569 exploreP:0.0173\n",
      "Episode:651 meanR:21.4500 R:29.0 loss:1738.4364 exploreP:0.0173\n",
      "Episode:652 meanR:21.4200 R:14.0 loss:1657.1832 exploreP:0.0172\n",
      "Episode:653 meanR:21.4400 R:21.0 loss:1725.0940 exploreP:0.0172\n",
      "Episode:654 meanR:21.4000 R:12.0 loss:1654.1470 exploreP:0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:655 meanR:21.3200 R:11.0 loss:2938.3223 exploreP:0.0172\n",
      "Episode:656 meanR:21.3100 R:11.0 loss:3610.4414 exploreP:0.0172\n",
      "Episode:657 meanR:21.3000 R:10.0 loss:1052.2185 exploreP:0.0172\n",
      "Episode:658 meanR:21.3400 R:18.0 loss:2081.1494 exploreP:0.0172\n",
      "Episode:659 meanR:21.3700 R:18.0 loss:1654.2059 exploreP:0.0172\n",
      "Episode:660 meanR:21.4000 R:14.0 loss:2961.7583 exploreP:0.0172\n",
      "Episode:661 meanR:21.4200 R:17.0 loss:1894.7645 exploreP:0.0171\n",
      "Episode:662 meanR:21.5600 R:26.0 loss:896.1749 exploreP:0.0171\n",
      "Episode:663 meanR:21.6800 R:25.0 loss:2172.0664 exploreP:0.0171\n",
      "Episode:664 meanR:21.7800 R:23.0 loss:1677.8098 exploreP:0.0171\n",
      "Episode:665 meanR:21.7300 R:20.0 loss:2921.0962 exploreP:0.0171\n",
      "Episode:666 meanR:21.6400 R:28.0 loss:1937.8044 exploreP:0.0171\n",
      "Episode:667 meanR:21.7700 R:39.0 loss:1585.2126 exploreP:0.0170\n",
      "Episode:668 meanR:21.9300 R:38.0 loss:1528.6593 exploreP:0.0170\n",
      "Episode:669 meanR:21.9900 R:26.0 loss:676.0894 exploreP:0.0170\n",
      "Episode:670 meanR:22.0800 R:26.0 loss:1807.9510 exploreP:0.0170\n",
      "Episode:671 meanR:22.0200 R:26.0 loss:904.0685 exploreP:0.0170\n",
      "Episode:672 meanR:22.3000 R:61.0 loss:2066.2002 exploreP:0.0169\n",
      "Episode:673 meanR:22.0200 R:20.0 loss:1646.5309 exploreP:0.0169\n",
      "Episode:674 meanR:22.1600 R:44.0 loss:2122.9683 exploreP:0.0169\n",
      "Episode:675 meanR:22.1400 R:26.0 loss:3117.9429 exploreP:0.0168\n",
      "Episode:676 meanR:22.0500 R:19.0 loss:1203.7847 exploreP:0.0168\n",
      "Episode:677 meanR:21.9000 R:19.0 loss:2288.7407 exploreP:0.0168\n",
      "Episode:678 meanR:21.8000 R:17.0 loss:1211.2803 exploreP:0.0168\n",
      "Episode:679 meanR:21.8700 R:23.0 loss:2315.0098 exploreP:0.0168\n",
      "Episode:680 meanR:21.9500 R:19.0 loss:2458.1355 exploreP:0.0168\n",
      "Episode:681 meanR:22.0100 R:18.0 loss:2641.3264 exploreP:0.0168\n",
      "Episode:682 meanR:22.0700 R:18.0 loss:675.7121 exploreP:0.0168\n",
      "Episode:683 meanR:22.0800 R:19.0 loss:1250.5133 exploreP:0.0167\n",
      "Episode:684 meanR:22.1000 R:17.0 loss:795.1315 exploreP:0.0167\n",
      "Episode:685 meanR:22.1800 R:21.0 loss:1336.0732 exploreP:0.0167\n",
      "Episode:686 meanR:22.1700 R:18.0 loss:1955.0857 exploreP:0.0167\n",
      "Episode:687 meanR:22.5500 R:57.0 loss:1812.0355 exploreP:0.0167\n",
      "Episode:688 meanR:22.9000 R:56.0 loss:2628.5042 exploreP:0.0166\n",
      "Episode:689 meanR:23.4600 R:78.0 loss:2236.0381 exploreP:0.0166\n",
      "Episode:690 meanR:23.4400 R:30.0 loss:2188.6941 exploreP:0.0166\n",
      "Episode:691 meanR:23.0600 R:23.0 loss:1663.0417 exploreP:0.0165\n",
      "Episode:692 meanR:22.8600 R:18.0 loss:1796.3964 exploreP:0.0165\n",
      "Episode:693 meanR:22.8600 R:31.0 loss:2896.8367 exploreP:0.0165\n",
      "Episode:694 meanR:22.7900 R:20.0 loss:2725.9648 exploreP:0.0165\n",
      "Episode:695 meanR:22.6400 R:15.0 loss:2573.4561 exploreP:0.0165\n",
      "Episode:696 meanR:22.7700 R:27.0 loss:743.2137 exploreP:0.0165\n",
      "Episode:697 meanR:22.9800 R:37.0 loss:2126.9617 exploreP:0.0164\n",
      "Episode:698 meanR:22.9400 R:19.0 loss:1578.6896 exploreP:0.0164\n",
      "Episode:699 meanR:22.9000 R:13.0 loss:4992.0889 exploreP:0.0164\n",
      "Episode:700 meanR:23.0000 R:30.0 loss:2113.9883 exploreP:0.0164\n",
      "Episode:701 meanR:22.9800 R:20.0 loss:2555.8037 exploreP:0.0164\n",
      "Episode:702 meanR:23.1100 R:25.0 loss:5474.1191 exploreP:0.0164\n",
      "Episode:703 meanR:23.2600 R:27.0 loss:2711.9375 exploreP:0.0164\n",
      "Episode:704 meanR:23.3300 R:18.0 loss:5177.6084 exploreP:0.0164\n",
      "Episode:705 meanR:23.3900 R:19.0 loss:2676.3306 exploreP:0.0163\n",
      "Episode:706 meanR:23.5400 R:25.0 loss:1781.7314 exploreP:0.0163\n",
      "Episode:707 meanR:23.5600 R:23.0 loss:3357.8838 exploreP:0.0163\n",
      "Episode:708 meanR:23.4900 R:20.0 loss:3657.5210 exploreP:0.0163\n",
      "Episode:709 meanR:23.6500 R:28.0 loss:2243.4075 exploreP:0.0163\n",
      "Episode:710 meanR:23.8400 R:31.0 loss:1773.4341 exploreP:0.0163\n",
      "Episode:711 meanR:24.0200 R:28.0 loss:1979.6221 exploreP:0.0162\n",
      "Episode:712 meanR:24.0900 R:19.0 loss:1943.9462 exploreP:0.0162\n",
      "Episode:713 meanR:24.2100 R:22.0 loss:1358.6105 exploreP:0.0162\n",
      "Episode:714 meanR:24.2800 R:28.0 loss:2070.8528 exploreP:0.0162\n",
      "Episode:715 meanR:24.4700 R:30.0 loss:2654.8030 exploreP:0.0162\n",
      "Episode:716 meanR:24.5400 R:18.0 loss:2638.6086 exploreP:0.0162\n",
      "Episode:717 meanR:24.6000 R:18.0 loss:2941.5049 exploreP:0.0162\n",
      "Episode:718 meanR:24.6800 R:19.0 loss:2020.9556 exploreP:0.0161\n",
      "Episode:719 meanR:24.8300 R:25.0 loss:1251.2366 exploreP:0.0161\n",
      "Episode:720 meanR:24.9900 R:26.0 loss:2685.4976 exploreP:0.0161\n",
      "Episode:721 meanR:25.2000 R:30.0 loss:2686.4695 exploreP:0.0161\n",
      "Episode:722 meanR:25.3400 R:23.0 loss:1617.1663 exploreP:0.0161\n",
      "Episode:723 meanR:25.4400 R:28.0 loss:2552.7891 exploreP:0.0161\n",
      "Episode:724 meanR:25.4000 R:22.0 loss:3428.4329 exploreP:0.0161\n",
      "Episode:725 meanR:25.4000 R:21.0 loss:1378.7750 exploreP:0.0160\n",
      "Episode:726 meanR:25.3800 R:21.0 loss:3897.4058 exploreP:0.0160\n",
      "Episode:727 meanR:25.2000 R:19.0 loss:816.3514 exploreP:0.0160\n",
      "Episode:728 meanR:25.2100 R:26.0 loss:2986.1106 exploreP:0.0160\n",
      "Episode:729 meanR:25.0800 R:22.0 loss:1864.9792 exploreP:0.0160\n",
      "Episode:730 meanR:24.9300 R:18.0 loss:2036.9091 exploreP:0.0160\n",
      "Episode:731 meanR:24.7700 R:17.0 loss:1602.8040 exploreP:0.0160\n",
      "Episode:732 meanR:24.7400 R:22.0 loss:3177.4407 exploreP:0.0160\n",
      "Episode:733 meanR:24.5500 R:18.0 loss:2153.8047 exploreP:0.0159\n",
      "Episode:734 meanR:24.4900 R:19.0 loss:1283.2897 exploreP:0.0159\n",
      "Episode:735 meanR:24.3900 R:20.0 loss:2364.1116 exploreP:0.0159\n",
      "Episode:736 meanR:24.4300 R:28.0 loss:3645.5315 exploreP:0.0159\n",
      "Episode:737 meanR:24.3700 R:20.0 loss:2038.9095 exploreP:0.0159\n",
      "Episode:738 meanR:24.3700 R:24.0 loss:2828.8030 exploreP:0.0159\n",
      "Episode:739 meanR:24.3200 R:28.0 loss:2039.6136 exploreP:0.0159\n",
      "Episode:740 meanR:24.4100 R:32.0 loss:2866.7910 exploreP:0.0158\n",
      "Episode:741 meanR:24.4300 R:25.0 loss:1581.5372 exploreP:0.0158\n",
      "Episode:742 meanR:24.3900 R:16.0 loss:2276.7229 exploreP:0.0158\n",
      "Episode:743 meanR:24.3700 R:21.0 loss:1761.1650 exploreP:0.0158\n",
      "Episode:744 meanR:24.3700 R:29.0 loss:2119.7380 exploreP:0.0158\n",
      "Episode:745 meanR:24.3200 R:24.0 loss:1675.2308 exploreP:0.0158\n",
      "Episode:746 meanR:24.3900 R:27.0 loss:1478.4135 exploreP:0.0158\n",
      "Episode:747 meanR:24.4600 R:30.0 loss:1989.5366 exploreP:0.0157\n",
      "Episode:748 meanR:24.4300 R:26.0 loss:2433.7888 exploreP:0.0157\n",
      "Episode:749 meanR:24.3700 R:21.0 loss:1638.1920 exploreP:0.0157\n",
      "Episode:750 meanR:24.3300 R:22.0 loss:2692.7197 exploreP:0.0157\n",
      "Episode:751 meanR:24.2600 R:22.0 loss:2120.6506 exploreP:0.0157\n",
      "Episode:752 meanR:24.4100 R:29.0 loss:3234.3389 exploreP:0.0157\n",
      "Episode:753 meanR:24.4100 R:21.0 loss:3096.3958 exploreP:0.0157\n",
      "Episode:754 meanR:24.4700 R:18.0 loss:1667.4751 exploreP:0.0157\n",
      "Episode:755 meanR:24.5200 R:16.0 loss:2390.4312 exploreP:0.0156\n",
      "Episode:756 meanR:24.6200 R:21.0 loss:5285.2974 exploreP:0.0156\n",
      "Episode:757 meanR:24.6500 R:13.0 loss:5668.7163 exploreP:0.0156\n",
      "Episode:758 meanR:24.6000 R:13.0 loss:939.2878 exploreP:0.0156\n",
      "Episode:759 meanR:24.6300 R:21.0 loss:3303.4795 exploreP:0.0156\n",
      "Episode:760 meanR:24.7000 R:21.0 loss:2750.8267 exploreP:0.0156\n",
      "Episode:761 meanR:24.7200 R:19.0 loss:2929.9968 exploreP:0.0156\n",
      "Episode:762 meanR:24.5900 R:13.0 loss:2931.7056 exploreP:0.0156\n",
      "Episode:763 meanR:24.5400 R:20.0 loss:1988.1536 exploreP:0.0156\n",
      "Episode:764 meanR:24.5800 R:27.0 loss:3030.9907 exploreP:0.0155\n",
      "Episode:765 meanR:24.5900 R:21.0 loss:4864.6274 exploreP:0.0155\n",
      "Episode:766 meanR:24.5300 R:22.0 loss:1567.9821 exploreP:0.0155\n",
      "Episode:767 meanR:24.3800 R:24.0 loss:3469.9473 exploreP:0.0155\n",
      "Episode:768 meanR:24.1800 R:18.0 loss:2400.1475 exploreP:0.0155\n",
      "Episode:769 meanR:24.1400 R:22.0 loss:1133.8818 exploreP:0.0155\n",
      "Episode:770 meanR:24.0000 R:12.0 loss:3974.3164 exploreP:0.0155\n",
      "Episode:771 meanR:23.9200 R:18.0 loss:1469.0618 exploreP:0.0155\n",
      "Episode:772 meanR:23.5400 R:23.0 loss:1955.4293 exploreP:0.0155\n",
      "Episode:773 meanR:23.5600 R:22.0 loss:1730.8173 exploreP:0.0154\n",
      "Episode:774 meanR:23.2500 R:13.0 loss:1073.6222 exploreP:0.0154\n",
      "Episode:775 meanR:23.2600 R:27.0 loss:1881.8898 exploreP:0.0154\n",
      "Episode:776 meanR:23.1900 R:12.0 loss:4075.5398 exploreP:0.0154\n",
      "Episode:777 meanR:23.2000 R:20.0 loss:1872.8539 exploreP:0.0154\n",
      "Episode:778 meanR:23.3100 R:28.0 loss:2006.3207 exploreP:0.0154\n",
      "Episode:779 meanR:23.2800 R:20.0 loss:2913.1360 exploreP:0.0154\n",
      "Episode:780 meanR:23.2200 R:13.0 loss:1663.2343 exploreP:0.0154\n",
      "Episode:781 meanR:23.1600 R:12.0 loss:1330.2833 exploreP:0.0154\n",
      "Episode:782 meanR:23.1000 R:12.0 loss:2210.1172 exploreP:0.0154\n",
      "Episode:783 meanR:23.0100 R:10.0 loss:1124.5549 exploreP:0.0154\n",
      "Episode:784 meanR:22.9400 R:10.0 loss:965.3407 exploreP:0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:785 meanR:22.8600 R:13.0 loss:1652.4178 exploreP:0.0153\n",
      "Episode:786 meanR:22.8900 R:21.0 loss:1639.8479 exploreP:0.0153\n",
      "Episode:787 meanR:22.5200 R:20.0 loss:1549.7046 exploreP:0.0153\n",
      "Episode:788 meanR:22.1700 R:21.0 loss:7106.1333 exploreP:0.0153\n",
      "Episode:789 meanR:21.6200 R:23.0 loss:1477.8833 exploreP:0.0153\n",
      "Episode:790 meanR:21.5800 R:26.0 loss:3315.0940 exploreP:0.0153\n",
      "Episode:791 meanR:21.6300 R:28.0 loss:3091.3274 exploreP:0.0153\n",
      "Episode:792 meanR:21.6900 R:24.0 loss:4455.4341 exploreP:0.0153\n",
      "Episode:793 meanR:21.5600 R:18.0 loss:2986.6182 exploreP:0.0152\n",
      "Episode:794 meanR:21.5300 R:17.0 loss:2672.8369 exploreP:0.0152\n",
      "Episode:795 meanR:21.5800 R:20.0 loss:2682.4592 exploreP:0.0152\n",
      "Episode:796 meanR:21.5500 R:24.0 loss:3584.4163 exploreP:0.0152\n",
      "Episode:797 meanR:21.4300 R:25.0 loss:2541.3396 exploreP:0.0152\n",
      "Episode:798 meanR:21.5000 R:26.0 loss:4768.2383 exploreP:0.0152\n",
      "Episode:799 meanR:21.5800 R:21.0 loss:5150.6021 exploreP:0.0152\n",
      "Episode:800 meanR:21.4500 R:17.0 loss:5002.3921 exploreP:0.0152\n",
      "Episode:801 meanR:21.5100 R:26.0 loss:1657.2715 exploreP:0.0152\n",
      "Episode:802 meanR:21.5500 R:29.0 loss:2673.5474 exploreP:0.0151\n",
      "Episode:803 meanR:21.4600 R:18.0 loss:1112.9224 exploreP:0.0151\n",
      "Episode:804 meanR:21.5500 R:27.0 loss:2734.6885 exploreP:0.0151\n",
      "Episode:805 meanR:21.6000 R:24.0 loss:1708.5791 exploreP:0.0151\n",
      "Episode:806 meanR:21.5400 R:19.0 loss:4953.6392 exploreP:0.0151\n",
      "Episode:807 meanR:21.5500 R:24.0 loss:4315.1846 exploreP:0.0151\n",
      "Episode:808 meanR:21.5800 R:23.0 loss:4934.9131 exploreP:0.0151\n",
      "Episode:809 meanR:21.4900 R:19.0 loss:1351.8389 exploreP:0.0151\n",
      "Episode:810 meanR:21.3800 R:20.0 loss:1541.5671 exploreP:0.0151\n",
      "Episode:811 meanR:21.3100 R:21.0 loss:1657.4408 exploreP:0.0150\n",
      "Episode:812 meanR:21.3500 R:23.0 loss:2851.1179 exploreP:0.0150\n",
      "Episode:813 meanR:21.2900 R:16.0 loss:2711.3018 exploreP:0.0150\n",
      "Episode:814 meanR:21.2100 R:20.0 loss:2411.2478 exploreP:0.0150\n",
      "Episode:815 meanR:21.0700 R:16.0 loss:1063.8306 exploreP:0.0150\n",
      "Episode:816 meanR:21.0400 R:15.0 loss:2298.4609 exploreP:0.0150\n",
      "Episode:817 meanR:21.0200 R:16.0 loss:3590.4561 exploreP:0.0150\n",
      "Episode:818 meanR:21.0000 R:17.0 loss:3648.9441 exploreP:0.0150\n",
      "Episode:819 meanR:21.0100 R:26.0 loss:3271.7295 exploreP:0.0150\n",
      "Episode:820 meanR:20.9800 R:23.0 loss:3510.1987 exploreP:0.0150\n",
      "Episode:821 meanR:20.8300 R:15.0 loss:2229.9705 exploreP:0.0150\n",
      "Episode:822 meanR:20.8200 R:22.0 loss:3269.0049 exploreP:0.0149\n",
      "Episode:823 meanR:20.7600 R:22.0 loss:2410.1787 exploreP:0.0149\n",
      "Episode:824 meanR:20.7900 R:25.0 loss:1867.4070 exploreP:0.0149\n",
      "Episode:825 meanR:20.7700 R:19.0 loss:3214.5557 exploreP:0.0149\n",
      "Episode:826 meanR:20.7100 R:15.0 loss:2737.7727 exploreP:0.0149\n",
      "Episode:827 meanR:20.7700 R:25.0 loss:2700.2798 exploreP:0.0149\n",
      "Episode:828 meanR:20.7100 R:20.0 loss:4045.3184 exploreP:0.0149\n",
      "Episode:829 meanR:20.6900 R:20.0 loss:1943.5590 exploreP:0.0149\n",
      "Episode:830 meanR:20.7200 R:21.0 loss:3925.4724 exploreP:0.0149\n",
      "Episode:831 meanR:20.7600 R:21.0 loss:2797.6582 exploreP:0.0148\n",
      "Episode:832 meanR:20.7400 R:20.0 loss:2533.6931 exploreP:0.0148\n",
      "Episode:833 meanR:20.8200 R:26.0 loss:3595.3638 exploreP:0.0148\n",
      "Episode:834 meanR:20.8700 R:24.0 loss:2237.9524 exploreP:0.0148\n",
      "Episode:835 meanR:20.9200 R:25.0 loss:4008.3440 exploreP:0.0148\n",
      "Episode:836 meanR:20.8100 R:17.0 loss:3592.2864 exploreP:0.0148\n",
      "Episode:837 meanR:20.8500 R:24.0 loss:4841.3120 exploreP:0.0148\n",
      "Episode:838 meanR:20.8100 R:20.0 loss:1667.9348 exploreP:0.0148\n",
      "Episode:839 meanR:20.7600 R:23.0 loss:2923.4521 exploreP:0.0148\n",
      "Episode:840 meanR:20.6500 R:21.0 loss:1207.3778 exploreP:0.0148\n",
      "Episode:841 meanR:20.6300 R:23.0 loss:1238.1808 exploreP:0.0147\n",
      "Episode:842 meanR:20.7600 R:29.0 loss:3195.3589 exploreP:0.0147\n",
      "Episode:843 meanR:20.8000 R:25.0 loss:1748.5614 exploreP:0.0147\n",
      "Episode:844 meanR:20.6800 R:17.0 loss:3919.0386 exploreP:0.0147\n",
      "Episode:845 meanR:20.5800 R:14.0 loss:1286.5629 exploreP:0.0147\n",
      "Episode:846 meanR:20.4200 R:11.0 loss:1996.5323 exploreP:0.0147\n",
      "Episode:847 meanR:20.3200 R:20.0 loss:1907.9486 exploreP:0.0147\n",
      "Episode:848 meanR:20.2700 R:21.0 loss:3067.5566 exploreP:0.0147\n",
      "Episode:849 meanR:20.1700 R:11.0 loss:5201.2402 exploreP:0.0147\n",
      "Episode:850 meanR:20.2000 R:25.0 loss:1990.1863 exploreP:0.0147\n",
      "Episode:851 meanR:20.1100 R:13.0 loss:2200.8909 exploreP:0.0147\n",
      "Episode:852 meanR:20.0200 R:20.0 loss:2164.6313 exploreP:0.0146\n",
      "Episode:853 meanR:19.9500 R:14.0 loss:3362.2026 exploreP:0.0146\n",
      "Episode:854 meanR:19.9500 R:18.0 loss:1498.8373 exploreP:0.0146\n",
      "Episode:855 meanR:19.9600 R:17.0 loss:2456.3298 exploreP:0.0146\n",
      "Episode:856 meanR:19.8900 R:14.0 loss:949.4487 exploreP:0.0146\n",
      "Episode:857 meanR:19.9200 R:16.0 loss:3443.0122 exploreP:0.0146\n",
      "Episode:858 meanR:19.9300 R:14.0 loss:2969.7576 exploreP:0.0146\n",
      "Episode:859 meanR:19.9500 R:23.0 loss:4206.1548 exploreP:0.0146\n",
      "Episode:860 meanR:19.9500 R:21.0 loss:1809.6573 exploreP:0.0146\n",
      "Episode:861 meanR:19.9300 R:17.0 loss:7450.3926 exploreP:0.0146\n",
      "Episode:862 meanR:20.0200 R:22.0 loss:1380.1583 exploreP:0.0146\n",
      "Episode:863 meanR:20.0900 R:27.0 loss:2098.9768 exploreP:0.0146\n",
      "Episode:864 meanR:20.0000 R:18.0 loss:2191.0222 exploreP:0.0145\n",
      "Episode:865 meanR:20.0300 R:24.0 loss:3584.8838 exploreP:0.0145\n",
      "Episode:866 meanR:20.0500 R:24.0 loss:2816.2156 exploreP:0.0145\n",
      "Episode:867 meanR:20.0400 R:23.0 loss:665.5869 exploreP:0.0145\n",
      "Episode:868 meanR:20.0800 R:22.0 loss:3554.3923 exploreP:0.0145\n",
      "Episode:869 meanR:20.1000 R:24.0 loss:3994.1135 exploreP:0.0145\n",
      "Episode:870 meanR:20.2000 R:22.0 loss:6355.9297 exploreP:0.0145\n",
      "Episode:871 meanR:20.2300 R:21.0 loss:2249.2971 exploreP:0.0145\n",
      "Episode:872 meanR:20.2200 R:22.0 loss:3538.4607 exploreP:0.0145\n",
      "Episode:873 meanR:20.1900 R:19.0 loss:1395.9762 exploreP:0.0145\n",
      "Episode:874 meanR:20.2700 R:21.0 loss:2854.2654 exploreP:0.0144\n",
      "Episode:875 meanR:20.1800 R:18.0 loss:2545.4167 exploreP:0.0144\n",
      "Episode:876 meanR:20.2300 R:17.0 loss:2451.8972 exploreP:0.0144\n",
      "Episode:877 meanR:20.2700 R:24.0 loss:2691.1016 exploreP:0.0144\n",
      "Episode:878 meanR:20.1900 R:20.0 loss:2862.0037 exploreP:0.0144\n",
      "Episode:879 meanR:20.2500 R:26.0 loss:3623.8528 exploreP:0.0144\n",
      "Episode:880 meanR:20.3200 R:20.0 loss:13849.1016 exploreP:0.0144\n",
      "Episode:881 meanR:20.4300 R:23.0 loss:4546.0508 exploreP:0.0144\n",
      "Episode:882 meanR:20.5500 R:24.0 loss:5243.6265 exploreP:0.0144\n",
      "Episode:883 meanR:20.6700 R:22.0 loss:3532.1292 exploreP:0.0144\n",
      "Episode:884 meanR:20.7300 R:16.0 loss:3999.3325 exploreP:0.0144\n",
      "Episode:885 meanR:20.8000 R:20.0 loss:3901.8516 exploreP:0.0143\n",
      "Episode:886 meanR:20.8000 R:21.0 loss:3803.4214 exploreP:0.0143\n",
      "Episode:887 meanR:20.8000 R:20.0 loss:2337.0962 exploreP:0.0143\n",
      "Episode:888 meanR:20.8300 R:24.0 loss:3067.9844 exploreP:0.0143\n",
      "Episode:889 meanR:20.7500 R:15.0 loss:1446.8922 exploreP:0.0143\n",
      "Episode:890 meanR:20.6800 R:19.0 loss:2599.4160 exploreP:0.0143\n",
      "Episode:891 meanR:20.6300 R:23.0 loss:3329.6672 exploreP:0.0143\n",
      "Episode:892 meanR:20.6200 R:23.0 loss:5125.5679 exploreP:0.0143\n",
      "Episode:893 meanR:20.7100 R:27.0 loss:2288.3435 exploreP:0.0143\n",
      "Episode:894 meanR:20.7200 R:18.0 loss:3035.2664 exploreP:0.0143\n",
      "Episode:895 meanR:20.7200 R:20.0 loss:3156.3518 exploreP:0.0143\n",
      "Episode:896 meanR:20.7500 R:27.0 loss:3341.1626 exploreP:0.0142\n",
      "Episode:897 meanR:20.6900 R:19.0 loss:2353.9155 exploreP:0.0142\n",
      "Episode:898 meanR:20.6700 R:24.0 loss:2757.2961 exploreP:0.0142\n",
      "Episode:899 meanR:20.6500 R:19.0 loss:4637.2148 exploreP:0.0142\n",
      "Episode:900 meanR:20.6900 R:21.0 loss:7146.1250 exploreP:0.0142\n",
      "Episode:901 meanR:20.6700 R:24.0 loss:2454.3032 exploreP:0.0142\n",
      "Episode:902 meanR:20.5700 R:19.0 loss:3120.6365 exploreP:0.0142\n",
      "Episode:903 meanR:20.5700 R:18.0 loss:4759.9668 exploreP:0.0142\n",
      "Episode:904 meanR:20.5000 R:20.0 loss:1589.0210 exploreP:0.0142\n",
      "Episode:905 meanR:20.5300 R:27.0 loss:6155.8657 exploreP:0.0142\n",
      "Episode:906 meanR:20.5400 R:20.0 loss:3420.8074 exploreP:0.0142\n",
      "Episode:907 meanR:20.4900 R:19.0 loss:5894.6631 exploreP:0.0141\n",
      "Episode:908 meanR:20.5400 R:28.0 loss:2093.3499 exploreP:0.0141\n",
      "Episode:909 meanR:20.6000 R:25.0 loss:4175.0176 exploreP:0.0141\n",
      "Episode:910 meanR:20.8200 R:42.0 loss:5834.0166 exploreP:0.0141\n",
      "Episode:911 meanR:20.9300 R:32.0 loss:5890.6167 exploreP:0.0141\n",
      "Episode:912 meanR:20.9300 R:23.0 loss:5003.8169 exploreP:0.0141\n",
      "Episode:913 meanR:21.0300 R:26.0 loss:3954.0835 exploreP:0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:914 meanR:21.0600 R:23.0 loss:3825.1968 exploreP:0.0141\n",
      "Episode:915 meanR:21.1800 R:28.0 loss:3472.6624 exploreP:0.0141\n",
      "Episode:916 meanR:21.2900 R:26.0 loss:4309.2749 exploreP:0.0140\n",
      "Episode:917 meanR:21.3800 R:25.0 loss:3618.2410 exploreP:0.0140\n",
      "Episode:918 meanR:21.4300 R:22.0 loss:2828.5847 exploreP:0.0140\n",
      "Episode:919 meanR:21.4100 R:24.0 loss:4538.7397 exploreP:0.0140\n",
      "Episode:920 meanR:21.4500 R:27.0 loss:4916.0718 exploreP:0.0140\n",
      "Episode:921 meanR:21.5400 R:24.0 loss:7353.4243 exploreP:0.0140\n",
      "Episode:922 meanR:21.5300 R:21.0 loss:2450.1216 exploreP:0.0140\n",
      "Episode:923 meanR:21.5800 R:27.0 loss:5329.8999 exploreP:0.0140\n",
      "Episode:924 meanR:21.5800 R:25.0 loss:1483.6223 exploreP:0.0140\n",
      "Episode:925 meanR:21.6000 R:21.0 loss:7883.2695 exploreP:0.0140\n",
      "Episode:926 meanR:21.6600 R:21.0 loss:2874.3040 exploreP:0.0139\n",
      "Episode:927 meanR:21.6600 R:25.0 loss:1906.8071 exploreP:0.0139\n",
      "Episode:928 meanR:21.7100 R:25.0 loss:2177.9475 exploreP:0.0139\n",
      "Episode:929 meanR:21.7700 R:26.0 loss:6727.8491 exploreP:0.0139\n",
      "Episode:930 meanR:21.8300 R:27.0 loss:5456.1021 exploreP:0.0139\n",
      "Episode:931 meanR:21.8500 R:23.0 loss:5079.5430 exploreP:0.0139\n",
      "Episode:932 meanR:22.0400 R:39.0 loss:2672.4312 exploreP:0.0139\n",
      "Episode:933 meanR:22.0900 R:31.0 loss:2281.8723 exploreP:0.0139\n",
      "Episode:934 meanR:22.1400 R:29.0 loss:3260.1665 exploreP:0.0139\n",
      "Episode:935 meanR:22.1600 R:27.0 loss:6719.8838 exploreP:0.0138\n",
      "Episode:936 meanR:22.2500 R:26.0 loss:12879.2090 exploreP:0.0138\n",
      "Episode:937 meanR:22.3300 R:32.0 loss:8888.6738 exploreP:0.0138\n",
      "Episode:938 meanR:22.3700 R:24.0 loss:6797.5366 exploreP:0.0138\n",
      "Episode:939 meanR:22.4700 R:33.0 loss:3879.6931 exploreP:0.0138\n",
      "Episode:940 meanR:22.5200 R:26.0 loss:4137.0400 exploreP:0.0138\n",
      "Episode:941 meanR:22.6300 R:34.0 loss:4026.1052 exploreP:0.0138\n",
      "Episode:942 meanR:22.7000 R:36.0 loss:7706.7266 exploreP:0.0138\n",
      "Episode:943 meanR:22.8500 R:40.0 loss:2732.5090 exploreP:0.0138\n",
      "Episode:944 meanR:22.9900 R:31.0 loss:3835.8572 exploreP:0.0137\n",
      "Episode:945 meanR:23.0900 R:24.0 loss:6471.2124 exploreP:0.0137\n",
      "Episode:946 meanR:23.2600 R:28.0 loss:5401.4819 exploreP:0.0137\n",
      "Episode:947 meanR:23.3500 R:29.0 loss:5562.7622 exploreP:0.0137\n",
      "Episode:948 meanR:23.4700 R:33.0 loss:3279.6445 exploreP:0.0137\n",
      "Episode:949 meanR:23.6200 R:26.0 loss:2453.1262 exploreP:0.0137\n",
      "Episode:950 meanR:23.5700 R:20.0 loss:2779.7534 exploreP:0.0137\n",
      "Episode:951 meanR:23.7600 R:32.0 loss:4999.1865 exploreP:0.0137\n",
      "Episode:952 meanR:23.8800 R:32.0 loss:3296.1653 exploreP:0.0137\n",
      "Episode:953 meanR:24.0300 R:29.0 loss:4291.6895 exploreP:0.0136\n",
      "Episode:954 meanR:24.1700 R:32.0 loss:1543.3757 exploreP:0.0136\n",
      "Episode:955 meanR:24.3100 R:31.0 loss:3750.9292 exploreP:0.0136\n",
      "Episode:956 meanR:24.4300 R:26.0 loss:4616.8481 exploreP:0.0136\n",
      "Episode:957 meanR:24.6400 R:37.0 loss:6809.5308 exploreP:0.0136\n",
      "Episode:958 meanR:24.8800 R:38.0 loss:5222.1631 exploreP:0.0136\n",
      "Episode:959 meanR:24.9700 R:32.0 loss:1466.1246 exploreP:0.0136\n",
      "Episode:960 meanR:25.3400 R:58.0 loss:4819.2500 exploreP:0.0136\n",
      "Episode:961 meanR:25.9500 R:78.0 loss:4772.9995 exploreP:0.0135\n",
      "Episode:962 meanR:27.1100 R:138.0 loss:6077.7969 exploreP:0.0135\n",
      "Episode:963 meanR:27.1900 R:35.0 loss:6495.6509 exploreP:0.0135\n",
      "Episode:964 meanR:27.3800 R:37.0 loss:2469.1365 exploreP:0.0135\n",
      "Episode:965 meanR:27.8400 R:70.0 loss:754.5795 exploreP:0.0134\n",
      "Episode:966 meanR:27.7400 R:14.0 loss:357.3515 exploreP:0.0134\n",
      "Episode:967 meanR:29.3400 R:183.0 loss:315.6304 exploreP:0.0134\n",
      "Episode:968 meanR:29.2300 R:11.0 loss:516.7947 exploreP:0.0134\n",
      "Episode:969 meanR:29.1600 R:17.0 loss:263.9977 exploreP:0.0134\n",
      "Episode:970 meanR:29.0200 R:8.0 loss:330.0653 exploreP:0.0134\n",
      "Episode:971 meanR:28.9200 R:11.0 loss:478.4090 exploreP:0.0133\n",
      "Episode:972 meanR:28.8000 R:10.0 loss:578.2017 exploreP:0.0133\n",
      "Episode:973 meanR:28.7000 R:9.0 loss:712.1839 exploreP:0.0133\n",
      "Episode:974 meanR:28.5800 R:9.0 loss:603.9114 exploreP:0.0133\n",
      "Episode:975 meanR:28.5100 R:11.0 loss:361.0764 exploreP:0.0133\n",
      "Episode:976 meanR:28.4400 R:10.0 loss:354.5109 exploreP:0.0133\n",
      "Episode:977 meanR:28.2900 R:9.0 loss:296.4441 exploreP:0.0133\n",
      "Episode:978 meanR:28.1800 R:9.0 loss:361.3043 exploreP:0.0133\n",
      "Episode:979 meanR:28.0200 R:10.0 loss:437.9832 exploreP:0.0133\n",
      "Episode:980 meanR:27.9200 R:10.0 loss:399.7099 exploreP:0.0133\n",
      "Episode:981 meanR:27.8000 R:11.0 loss:374.4718 exploreP:0.0133\n",
      "Episode:982 meanR:27.6500 R:9.0 loss:300.2722 exploreP:0.0133\n",
      "Episode:983 meanR:27.5300 R:10.0 loss:332.1299 exploreP:0.0133\n",
      "Episode:984 meanR:27.4700 R:10.0 loss:623.8093 exploreP:0.0133\n",
      "Episode:985 meanR:27.3700 R:10.0 loss:1215.5302 exploreP:0.0133\n",
      "Episode:986 meanR:27.2600 R:10.0 loss:2491.0786 exploreP:0.0133\n",
      "Episode:987 meanR:27.1500 R:9.0 loss:2907.3362 exploreP:0.0133\n",
      "Episode:988 meanR:27.0100 R:10.0 loss:2292.0710 exploreP:0.0133\n",
      "Episode:989 meanR:26.9400 R:8.0 loss:1917.7998 exploreP:0.0133\n",
      "Episode:990 meanR:26.8400 R:9.0 loss:685.4069 exploreP:0.0133\n",
      "Episode:991 meanR:26.7100 R:10.0 loss:1200.1526 exploreP:0.0133\n",
      "Episode:992 meanR:26.5800 R:10.0 loss:712.7007 exploreP:0.0133\n",
      "Episode:993 meanR:26.4100 R:10.0 loss:1298.5267 exploreP:0.0133\n",
      "Episode:994 meanR:26.3300 R:10.0 loss:1667.2018 exploreP:0.0133\n",
      "Episode:995 meanR:26.2300 R:10.0 loss:1604.9812 exploreP:0.0133\n",
      "Episode:996 meanR:26.0500 R:9.0 loss:2438.8323 exploreP:0.0133\n",
      "Episode:997 meanR:25.9500 R:9.0 loss:2621.0046 exploreP:0.0133\n",
      "Episode:998 meanR:25.8100 R:10.0 loss:3528.0300 exploreP:0.0133\n",
      "Episode:999 meanR:25.7200 R:10.0 loss:4062.8540 exploreP:0.0133\n",
      "Episode:1000 meanR:25.5900 R:8.0 loss:4056.8306 exploreP:0.0133\n",
      "Episode:1001 meanR:25.4400 R:9.0 loss:2546.3987 exploreP:0.0133\n",
      "Episode:1002 meanR:25.3500 R:10.0 loss:1723.0920 exploreP:0.0132\n",
      "Episode:1003 meanR:25.2800 R:11.0 loss:1970.1353 exploreP:0.0132\n",
      "Episode:1004 meanR:25.1700 R:9.0 loss:1079.3304 exploreP:0.0132\n",
      "Episode:1005 meanR:25.0000 R:10.0 loss:1611.6165 exploreP:0.0132\n",
      "Episode:1006 meanR:24.9000 R:10.0 loss:1451.7795 exploreP:0.0132\n",
      "Episode:1007 meanR:24.8100 R:10.0 loss:1562.0719 exploreP:0.0132\n",
      "Episode:1008 meanR:24.6300 R:10.0 loss:2174.4360 exploreP:0.0132\n",
      "Episode:1009 meanR:24.4600 R:8.0 loss:1805.8638 exploreP:0.0132\n",
      "Episode:1010 meanR:24.1300 R:9.0 loss:2125.4604 exploreP:0.0132\n",
      "Episode:1011 meanR:23.9300 R:12.0 loss:2746.5439 exploreP:0.0132\n",
      "Episode:1012 meanR:23.8000 R:10.0 loss:4648.8853 exploreP:0.0132\n",
      "Episode:1013 meanR:23.6300 R:9.0 loss:13100.4287 exploreP:0.0132\n",
      "Episode:1014 meanR:23.5100 R:11.0 loss:9075.2441 exploreP:0.0132\n",
      "Episode:1015 meanR:23.3300 R:10.0 loss:8768.8467 exploreP:0.0132\n",
      "Episode:1016 meanR:23.1700 R:10.0 loss:5247.8877 exploreP:0.0132\n",
      "Episode:1017 meanR:23.0000 R:8.0 loss:11953.4238 exploreP:0.0132\n",
      "Episode:1018 meanR:22.8800 R:10.0 loss:5263.7173 exploreP:0.0132\n",
      "Episode:1019 meanR:22.7300 R:9.0 loss:8298.1748 exploreP:0.0132\n",
      "Episode:1020 meanR:22.5600 R:10.0 loss:5546.3232 exploreP:0.0132\n",
      "Episode:1021 meanR:22.4100 R:9.0 loss:9266.0801 exploreP:0.0132\n",
      "Episode:1022 meanR:22.2900 R:9.0 loss:5227.3394 exploreP:0.0132\n",
      "Episode:1023 meanR:22.1200 R:10.0 loss:2457.0481 exploreP:0.0132\n",
      "Episode:1024 meanR:21.9600 R:9.0 loss:3818.5286 exploreP:0.0132\n",
      "Episode:1025 meanR:21.8400 R:9.0 loss:4086.8186 exploreP:0.0132\n",
      "Episode:1026 meanR:21.7300 R:10.0 loss:1051.6411 exploreP:0.0132\n",
      "Episode:1027 meanR:21.5800 R:10.0 loss:2551.6189 exploreP:0.0132\n",
      "Episode:1028 meanR:21.4200 R:9.0 loss:1373.8722 exploreP:0.0132\n",
      "Episode:1029 meanR:21.2500 R:9.0 loss:2165.0769 exploreP:0.0132\n",
      "Episode:1030 meanR:21.0700 R:9.0 loss:2339.9541 exploreP:0.0132\n",
      "Episode:1031 meanR:20.9300 R:9.0 loss:3566.9336 exploreP:0.0132\n",
      "Episode:1032 meanR:20.6400 R:10.0 loss:3276.6448 exploreP:0.0132\n",
      "Episode:1033 meanR:20.4300 R:10.0 loss:2654.2251 exploreP:0.0132\n",
      "Episode:1034 meanR:20.2300 R:9.0 loss:4506.3047 exploreP:0.0132\n",
      "Episode:1035 meanR:20.0600 R:10.0 loss:4629.3774 exploreP:0.0131\n",
      "Episode:1036 meanR:19.8900 R:9.0 loss:6502.0244 exploreP:0.0131\n",
      "Episode:1037 meanR:19.6700 R:10.0 loss:5510.0869 exploreP:0.0131\n",
      "Episode:1038 meanR:19.5200 R:9.0 loss:4930.5332 exploreP:0.0131\n",
      "Episode:1039 meanR:19.2900 R:10.0 loss:5010.3857 exploreP:0.0131\n",
      "Episode:1040 meanR:19.1300 R:10.0 loss:4887.2544 exploreP:0.0131\n",
      "Episode:1041 meanR:18.8900 R:10.0 loss:4224.4463 exploreP:0.0131\n",
      "Episode:1042 meanR:18.6300 R:10.0 loss:3343.0085 exploreP:0.0131\n",
      "Episode:1043 meanR:18.3200 R:9.0 loss:3040.7339 exploreP:0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1044 meanR:18.1000 R:9.0 loss:4441.1553 exploreP:0.0131\n",
      "Episode:1045 meanR:17.9600 R:10.0 loss:2354.9578 exploreP:0.0131\n",
      "Episode:1046 meanR:17.7700 R:9.0 loss:1885.0005 exploreP:0.0131\n",
      "Episode:1047 meanR:17.5600 R:8.0 loss:1420.5527 exploreP:0.0131\n",
      "Episode:1048 meanR:17.3100 R:8.0 loss:1085.6451 exploreP:0.0131\n",
      "Episode:1049 meanR:17.1500 R:10.0 loss:1033.7991 exploreP:0.0131\n",
      "Episode:1050 meanR:17.0400 R:9.0 loss:678.2401 exploreP:0.0131\n",
      "Episode:1051 meanR:16.8200 R:10.0 loss:793.7507 exploreP:0.0131\n",
      "Episode:1052 meanR:16.5900 R:9.0 loss:604.2222 exploreP:0.0131\n",
      "Episode:1053 meanR:16.4000 R:10.0 loss:744.4958 exploreP:0.0131\n",
      "Episode:1054 meanR:16.1700 R:9.0 loss:974.8577 exploreP:0.0131\n",
      "Episode:1055 meanR:15.9600 R:10.0 loss:1224.3180 exploreP:0.0131\n",
      "Episode:1056 meanR:15.8000 R:10.0 loss:1885.6934 exploreP:0.0131\n",
      "Episode:1057 meanR:15.5300 R:10.0 loss:1649.2731 exploreP:0.0131\n",
      "Episode:1058 meanR:15.2600 R:11.0 loss:2849.9873 exploreP:0.0131\n",
      "Episode:1059 meanR:15.0300 R:9.0 loss:4326.7983 exploreP:0.0131\n",
      "Episode:1060 meanR:14.5500 R:10.0 loss:5062.1572 exploreP:0.0131\n",
      "Episode:1061 meanR:13.8700 R:10.0 loss:5149.1655 exploreP:0.0131\n",
      "Episode:1062 meanR:12.5800 R:9.0 loss:6433.9590 exploreP:0.0131\n",
      "Episode:1063 meanR:12.3200 R:9.0 loss:5887.3574 exploreP:0.0131\n",
      "Episode:1064 meanR:12.0400 R:9.0 loss:14228.3125 exploreP:0.0131\n",
      "Episode:1065 meanR:11.4300 R:9.0 loss:10671.4609 exploreP:0.0131\n",
      "Episode:1066 meanR:11.4100 R:12.0 loss:10292.1670 exploreP:0.0131\n",
      "Episode:1067 meanR:9.6700 R:9.0 loss:8774.6660 exploreP:0.0131\n",
      "Episode:1068 meanR:9.6500 R:9.0 loss:12352.0625 exploreP:0.0131\n",
      "Episode:1069 meanR:9.5800 R:10.0 loss:9778.1035 exploreP:0.0130\n",
      "Episode:1070 meanR:9.5900 R:9.0 loss:5677.5386 exploreP:0.0130\n",
      "Episode:1071 meanR:9.5800 R:10.0 loss:3820.0188 exploreP:0.0130\n",
      "Episode:1072 meanR:9.5700 R:9.0 loss:2358.2764 exploreP:0.0130\n",
      "Episode:1073 meanR:9.5800 R:10.0 loss:1324.8334 exploreP:0.0130\n",
      "Episode:1074 meanR:9.5800 R:9.0 loss:933.7732 exploreP:0.0130\n",
      "Episode:1075 meanR:9.5500 R:8.0 loss:714.2072 exploreP:0.0130\n",
      "Episode:1076 meanR:9.5500 R:10.0 loss:821.7210 exploreP:0.0130\n",
      "Episode:1077 meanR:9.5600 R:10.0 loss:466.9629 exploreP:0.0130\n",
      "Episode:1078 meanR:9.5700 R:10.0 loss:998.2355 exploreP:0.0130\n",
      "Episode:1079 meanR:9.5600 R:9.0 loss:1080.6675 exploreP:0.0130\n",
      "Episode:1080 meanR:9.5500 R:9.0 loss:1876.2899 exploreP:0.0130\n",
      "Episode:1081 meanR:9.5300 R:9.0 loss:2451.8323 exploreP:0.0130\n",
      "Episode:1082 meanR:9.5300 R:9.0 loss:2588.5916 exploreP:0.0130\n",
      "Episode:1083 meanR:9.5300 R:10.0 loss:4053.3269 exploreP:0.0130\n",
      "Episode:1084 meanR:9.5200 R:9.0 loss:3891.1826 exploreP:0.0130\n",
      "Episode:1085 meanR:9.5200 R:10.0 loss:3324.3879 exploreP:0.0130\n",
      "Episode:1086 meanR:9.5200 R:10.0 loss:4919.7354 exploreP:0.0130\n",
      "Episode:1087 meanR:9.5300 R:10.0 loss:4133.0146 exploreP:0.0130\n",
      "Episode:1088 meanR:9.5200 R:9.0 loss:4317.5864 exploreP:0.0130\n",
      "Episode:1089 meanR:9.5200 R:8.0 loss:5574.6099 exploreP:0.0130\n",
      "Episode:1090 meanR:9.5200 R:9.0 loss:6103.9238 exploreP:0.0130\n",
      "Episode:1091 meanR:9.5300 R:11.0 loss:5642.1558 exploreP:0.0130\n",
      "Episode:1092 meanR:9.5300 R:10.0 loss:6712.0430 exploreP:0.0130\n",
      "Episode:1093 meanR:9.5100 R:8.0 loss:3504.8545 exploreP:0.0130\n",
      "Episode:1094 meanR:9.5000 R:9.0 loss:5070.0391 exploreP:0.0130\n",
      "Episode:1095 meanR:9.4900 R:9.0 loss:3409.7080 exploreP:0.0130\n",
      "Episode:1096 meanR:9.5000 R:10.0 loss:5073.4028 exploreP:0.0130\n",
      "Episode:1097 meanR:9.5300 R:12.0 loss:2794.3057 exploreP:0.0130\n",
      "Episode:1098 meanR:9.5200 R:9.0 loss:3934.3193 exploreP:0.0130\n",
      "Episode:1099 meanR:9.5200 R:10.0 loss:2911.0391 exploreP:0.0130\n",
      "Episode:1100 meanR:9.5300 R:9.0 loss:2443.0642 exploreP:0.0130\n",
      "Episode:1101 meanR:9.5300 R:9.0 loss:3058.6362 exploreP:0.0130\n",
      "Episode:1102 meanR:9.5200 R:9.0 loss:2399.3691 exploreP:0.0130\n",
      "Episode:1103 meanR:9.4900 R:8.0 loss:1825.4912 exploreP:0.0130\n",
      "Episode:1104 meanR:9.4900 R:9.0 loss:1643.1122 exploreP:0.0129\n",
      "Episode:1105 meanR:9.4900 R:10.0 loss:1242.6542 exploreP:0.0129\n",
      "Episode:1106 meanR:9.4900 R:10.0 loss:1804.5127 exploreP:0.0129\n",
      "Episode:1107 meanR:9.4900 R:10.0 loss:1252.2985 exploreP:0.0129\n",
      "Episode:1108 meanR:9.4900 R:10.0 loss:714.5834 exploreP:0.0129\n",
      "Episode:1109 meanR:9.5000 R:9.0 loss:750.1920 exploreP:0.0129\n",
      "Episode:1110 meanR:9.5000 R:9.0 loss:921.9223 exploreP:0.0129\n",
      "Episode:1111 meanR:9.4800 R:10.0 loss:571.1913 exploreP:0.0129\n",
      "Episode:1112 meanR:9.4700 R:9.0 loss:486.9612 exploreP:0.0129\n",
      "Episode:1113 meanR:9.4800 R:10.0 loss:834.2106 exploreP:0.0129\n",
      "Episode:1114 meanR:9.4600 R:9.0 loss:361.5811 exploreP:0.0129\n",
      "Episode:1115 meanR:9.4500 R:9.0 loss:441.0876 exploreP:0.0129\n",
      "Episode:1116 meanR:9.4500 R:10.0 loss:314.5265 exploreP:0.0129\n",
      "Episode:1117 meanR:9.4600 R:9.0 loss:456.0502 exploreP:0.0129\n",
      "Episode:1118 meanR:9.4500 R:9.0 loss:509.2898 exploreP:0.0129\n",
      "Episode:1119 meanR:9.4500 R:9.0 loss:506.0662 exploreP:0.0129\n",
      "Episode:1120 meanR:9.4400 R:9.0 loss:717.9524 exploreP:0.0129\n",
      "Episode:1121 meanR:9.4500 R:10.0 loss:670.9473 exploreP:0.0129\n",
      "Episode:1122 meanR:9.4600 R:10.0 loss:672.2382 exploreP:0.0129\n",
      "Episode:1123 meanR:9.4600 R:10.0 loss:952.3674 exploreP:0.0129\n",
      "Episode:1124 meanR:9.4700 R:10.0 loss:1317.0873 exploreP:0.0129\n",
      "Episode:1125 meanR:9.4800 R:10.0 loss:1038.8831 exploreP:0.0129\n",
      "Episode:1126 meanR:9.4700 R:9.0 loss:1283.7661 exploreP:0.0129\n",
      "Episode:1127 meanR:9.4700 R:10.0 loss:2215.6379 exploreP:0.0129\n",
      "Episode:1128 meanR:9.4700 R:9.0 loss:2472.5479 exploreP:0.0129\n",
      "Episode:1129 meanR:9.4800 R:10.0 loss:2417.0637 exploreP:0.0129\n",
      "Episode:1130 meanR:9.4800 R:9.0 loss:1822.7185 exploreP:0.0129\n",
      "Episode:1131 meanR:9.4900 R:10.0 loss:2636.7407 exploreP:0.0129\n",
      "Episode:1132 meanR:9.4800 R:9.0 loss:2812.7646 exploreP:0.0129\n",
      "Episode:1133 meanR:9.4600 R:8.0 loss:3349.3911 exploreP:0.0129\n",
      "Episode:1134 meanR:9.4600 R:9.0 loss:3912.7236 exploreP:0.0129\n",
      "Episode:1135 meanR:9.4600 R:10.0 loss:5593.0957 exploreP:0.0129\n",
      "Episode:1136 meanR:9.4600 R:9.0 loss:7878.1104 exploreP:0.0129\n",
      "Episode:1137 meanR:9.4600 R:10.0 loss:8930.9043 exploreP:0.0129\n",
      "Episode:1138 meanR:9.4600 R:9.0 loss:7064.9463 exploreP:0.0129\n",
      "Episode:1139 meanR:9.4400 R:8.0 loss:10963.9844 exploreP:0.0129\n",
      "Episode:1140 meanR:9.4200 R:8.0 loss:8129.6152 exploreP:0.0129\n",
      "Episode:1141 meanR:9.4200 R:10.0 loss:7305.6812 exploreP:0.0128\n",
      "Episode:1142 meanR:9.4000 R:8.0 loss:6398.0630 exploreP:0.0128\n",
      "Episode:1143 meanR:9.4000 R:9.0 loss:3819.9558 exploreP:0.0128\n",
      "Episode:1144 meanR:9.3900 R:8.0 loss:3629.3594 exploreP:0.0128\n",
      "Episode:1145 meanR:9.3800 R:9.0 loss:4803.4722 exploreP:0.0128\n",
      "Episode:1146 meanR:9.3700 R:8.0 loss:1595.2424 exploreP:0.0128\n",
      "Episode:1147 meanR:9.3800 R:9.0 loss:1751.3354 exploreP:0.0128\n",
      "Episode:1148 meanR:9.3900 R:9.0 loss:1634.5636 exploreP:0.0128\n",
      "Episode:1149 meanR:9.3900 R:10.0 loss:970.2601 exploreP:0.0128\n",
      "Episode:1150 meanR:9.3900 R:9.0 loss:701.9181 exploreP:0.0128\n",
      "Episode:1151 meanR:9.3900 R:10.0 loss:666.1609 exploreP:0.0128\n",
      "Episode:1152 meanR:9.4000 R:10.0 loss:537.6243 exploreP:0.0128\n",
      "Episode:1153 meanR:9.4000 R:10.0 loss:942.9066 exploreP:0.0128\n",
      "Episode:1154 meanR:9.4000 R:9.0 loss:1283.4305 exploreP:0.0128\n",
      "Episode:1155 meanR:9.3800 R:8.0 loss:1884.5059 exploreP:0.0128\n",
      "Episode:1156 meanR:9.3800 R:10.0 loss:1923.2162 exploreP:0.0128\n",
      "Episode:1157 meanR:9.3600 R:8.0 loss:3195.7061 exploreP:0.0128\n",
      "Episode:1158 meanR:9.3500 R:10.0 loss:4576.7144 exploreP:0.0128\n",
      "Episode:1159 meanR:9.3500 R:9.0 loss:5806.4863 exploreP:0.0128\n",
      "Episode:1160 meanR:9.4300 R:18.0 loss:5949.7129 exploreP:0.0128\n",
      "Episode:1161 meanR:9.4300 R:10.0 loss:6243.5928 exploreP:0.0128\n",
      "Episode:1162 meanR:9.4400 R:10.0 loss:6800.6768 exploreP:0.0128\n",
      "Episode:1163 meanR:9.4600 R:11.0 loss:7252.5645 exploreP:0.0128\n",
      "Episode:1164 meanR:9.4500 R:8.0 loss:8583.7588 exploreP:0.0128\n",
      "Episode:1165 meanR:9.4600 R:10.0 loss:9264.2334 exploreP:0.0128\n",
      "Episode:1166 meanR:9.4400 R:10.0 loss:8605.2441 exploreP:0.0128\n",
      "Episode:1167 meanR:9.4400 R:9.0 loss:8045.4351 exploreP:0.0128\n",
      "Episode:1168 meanR:9.4500 R:10.0 loss:7786.2783 exploreP:0.0128\n",
      "Episode:1169 meanR:9.4400 R:9.0 loss:10278.4980 exploreP:0.0128\n",
      "Episode:1170 meanR:9.4500 R:10.0 loss:7882.8086 exploreP:0.0128\n",
      "Episode:1171 meanR:9.4600 R:11.0 loss:6666.0122 exploreP:0.0128\n",
      "Episode:1172 meanR:9.4700 R:10.0 loss:7593.5415 exploreP:0.0128\n",
      "Episode:1173 meanR:9.4600 R:9.0 loss:8676.4990 exploreP:0.0128\n",
      "Episode:1174 meanR:9.4700 R:10.0 loss:5532.3662 exploreP:0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1175 meanR:9.4900 R:10.0 loss:6670.2358 exploreP:0.0128\n",
      "Episode:1176 meanR:9.4900 R:10.0 loss:3773.6050 exploreP:0.0128\n",
      "Episode:1177 meanR:9.4800 R:9.0 loss:4422.4165 exploreP:0.0128\n",
      "Episode:1178 meanR:9.4800 R:10.0 loss:3839.6250 exploreP:0.0127\n",
      "Episode:1179 meanR:9.4900 R:10.0 loss:2703.5720 exploreP:0.0127\n",
      "Episode:1180 meanR:9.5000 R:10.0 loss:2105.7424 exploreP:0.0127\n",
      "Episode:1181 meanR:9.5100 R:10.0 loss:1754.7826 exploreP:0.0127\n",
      "Episode:1182 meanR:9.5200 R:10.0 loss:1464.9938 exploreP:0.0127\n",
      "Episode:1183 meanR:9.5200 R:10.0 loss:1967.2551 exploreP:0.0127\n",
      "Episode:1184 meanR:9.5300 R:10.0 loss:1272.0416 exploreP:0.0127\n",
      "Episode:1185 meanR:9.5300 R:10.0 loss:1032.5768 exploreP:0.0127\n",
      "Episode:1186 meanR:9.5300 R:10.0 loss:924.0382 exploreP:0.0127\n",
      "Episode:1187 meanR:9.5300 R:10.0 loss:682.6417 exploreP:0.0127\n",
      "Episode:1188 meanR:9.5700 R:13.0 loss:915.8109 exploreP:0.0127\n",
      "Episode:1189 meanR:9.5900 R:10.0 loss:590.0560 exploreP:0.0127\n",
      "Episode:1190 meanR:9.6000 R:10.0 loss:600.1468 exploreP:0.0127\n",
      "Episode:1191 meanR:9.6100 R:12.0 loss:730.7814 exploreP:0.0127\n",
      "Episode:1192 meanR:9.6100 R:10.0 loss:573.3356 exploreP:0.0127\n",
      "Episode:1193 meanR:9.6400 R:11.0 loss:761.9423 exploreP:0.0127\n",
      "Episode:1194 meanR:9.6500 R:10.0 loss:682.8583 exploreP:0.0127\n",
      "Episode:1195 meanR:9.6600 R:10.0 loss:795.2867 exploreP:0.0127\n",
      "Episode:1196 meanR:9.6600 R:10.0 loss:907.5284 exploreP:0.0127\n",
      "Episode:1197 meanR:9.6400 R:10.0 loss:1061.2452 exploreP:0.0127\n",
      "Episode:1198 meanR:9.6600 R:11.0 loss:1249.3741 exploreP:0.0127\n",
      "Episode:1199 meanR:9.6600 R:10.0 loss:1752.7629 exploreP:0.0127\n",
      "Episode:1200 meanR:9.6600 R:9.0 loss:2113.5901 exploreP:0.0127\n",
      "Episode:1201 meanR:9.6500 R:8.0 loss:2349.5378 exploreP:0.0127\n",
      "Episode:1202 meanR:9.6500 R:9.0 loss:2791.1208 exploreP:0.0127\n",
      "Episode:1203 meanR:9.6500 R:8.0 loss:4089.3552 exploreP:0.0127\n",
      "Episode:1204 meanR:9.6400 R:8.0 loss:4935.0835 exploreP:0.0127\n",
      "Episode:1205 meanR:9.6400 R:10.0 loss:6849.2686 exploreP:0.0127\n",
      "Episode:1206 meanR:9.6400 R:10.0 loss:8186.3491 exploreP:0.0127\n",
      "Episode:1207 meanR:9.6300 R:9.0 loss:7318.2534 exploreP:0.0127\n",
      "Episode:1208 meanR:9.6300 R:10.0 loss:8790.3145 exploreP:0.0127\n",
      "Episode:1209 meanR:9.6400 R:10.0 loss:7965.1162 exploreP:0.0127\n",
      "Episode:1210 meanR:9.6300 R:8.0 loss:7330.2007 exploreP:0.0127\n",
      "Episode:1211 meanR:9.6300 R:10.0 loss:5730.7412 exploreP:0.0127\n",
      "Episode:1212 meanR:9.6200 R:8.0 loss:5632.9316 exploreP:0.0127\n",
      "Episode:1213 meanR:9.6300 R:11.0 loss:2493.3225 exploreP:0.0127\n",
      "Episode:1214 meanR:9.6300 R:9.0 loss:2291.5510 exploreP:0.0127\n",
      "Episode:1215 meanR:9.6400 R:10.0 loss:1482.0023 exploreP:0.0127\n",
      "Episode:1216 meanR:9.6200 R:8.0 loss:993.5482 exploreP:0.0126\n",
      "Episode:1217 meanR:9.6300 R:10.0 loss:1179.5500 exploreP:0.0126\n",
      "Episode:1218 meanR:9.6300 R:9.0 loss:752.1565 exploreP:0.0126\n",
      "Episode:1219 meanR:9.6300 R:9.0 loss:485.6232 exploreP:0.0126\n",
      "Episode:1220 meanR:9.6300 R:9.0 loss:556.0193 exploreP:0.0126\n",
      "Episode:1221 meanR:9.6400 R:11.0 loss:752.9912 exploreP:0.0126\n",
      "Episode:1222 meanR:9.6200 R:8.0 loss:677.0084 exploreP:0.0126\n",
      "Episode:1223 meanR:9.6200 R:10.0 loss:942.1522 exploreP:0.0126\n",
      "Episode:1224 meanR:9.6200 R:10.0 loss:1433.2806 exploreP:0.0126\n",
      "Episode:1225 meanR:9.7900 R:27.0 loss:2385.0720 exploreP:0.0126\n",
      "Episode:1226 meanR:9.9200 R:22.0 loss:4174.2583 exploreP:0.0126\n",
      "Episode:1227 meanR:10.0200 R:20.0 loss:7000.4048 exploreP:0.0126\n",
      "Episode:1228 meanR:10.1300 R:20.0 loss:10387.6768 exploreP:0.0126\n",
      "Episode:1229 meanR:10.1300 R:10.0 loss:9850.7549 exploreP:0.0126\n",
      "Episode:1230 meanR:10.1400 R:10.0 loss:11885.5459 exploreP:0.0126\n",
      "Episode:1231 meanR:10.1300 R:9.0 loss:11587.1836 exploreP:0.0126\n",
      "Episode:1232 meanR:10.1400 R:10.0 loss:14088.5137 exploreP:0.0126\n",
      "Episode:1233 meanR:10.1600 R:10.0 loss:10850.5127 exploreP:0.0126\n",
      "Episode:1234 meanR:10.1700 R:10.0 loss:12714.8574 exploreP:0.0126\n",
      "Episode:1235 meanR:10.1600 R:9.0 loss:12782.6436 exploreP:0.0126\n",
      "Episode:1236 meanR:10.1700 R:10.0 loss:8408.7285 exploreP:0.0126\n",
      "Episode:1237 meanR:10.1800 R:11.0 loss:7656.0127 exploreP:0.0126\n",
      "Episode:1238 meanR:10.1900 R:10.0 loss:8975.7451 exploreP:0.0126\n",
      "Episode:1239 meanR:10.2100 R:10.0 loss:10418.6162 exploreP:0.0126\n",
      "Episode:1240 meanR:10.2200 R:9.0 loss:8411.4316 exploreP:0.0126\n",
      "Episode:1241 meanR:10.2100 R:9.0 loss:8171.5928 exploreP:0.0126\n",
      "Episode:1242 meanR:10.2300 R:10.0 loss:5995.9795 exploreP:0.0126\n",
      "Episode:1243 meanR:10.2500 R:11.0 loss:3637.0571 exploreP:0.0126\n",
      "Episode:1244 meanR:10.2700 R:10.0 loss:7480.5093 exploreP:0.0126\n",
      "Episode:1245 meanR:10.2800 R:10.0 loss:3065.5603 exploreP:0.0126\n",
      "Episode:1246 meanR:10.2800 R:8.0 loss:4111.2305 exploreP:0.0126\n",
      "Episode:1247 meanR:10.2800 R:9.0 loss:1358.4625 exploreP:0.0126\n",
      "Episode:1248 meanR:10.2900 R:10.0 loss:2080.3757 exploreP:0.0126\n",
      "Episode:1249 meanR:10.2800 R:9.0 loss:837.2968 exploreP:0.0126\n",
      "Episode:1250 meanR:10.2800 R:9.0 loss:1754.3179 exploreP:0.0126\n",
      "Episode:1251 meanR:10.2800 R:10.0 loss:1735.2679 exploreP:0.0125\n",
      "Episode:1252 meanR:10.2800 R:10.0 loss:1011.3078 exploreP:0.0125\n",
      "Episode:1253 meanR:10.2800 R:10.0 loss:894.9578 exploreP:0.0125\n",
      "Episode:1254 meanR:10.2900 R:10.0 loss:898.2313 exploreP:0.0125\n",
      "Episode:1255 meanR:10.3000 R:9.0 loss:1101.1108 exploreP:0.0125\n",
      "Episode:1256 meanR:10.2900 R:9.0 loss:1411.7799 exploreP:0.0125\n",
      "Episode:1257 meanR:10.3100 R:10.0 loss:1197.0437 exploreP:0.0125\n",
      "Episode:1258 meanR:10.3100 R:10.0 loss:1935.6801 exploreP:0.0125\n",
      "Episode:1259 meanR:10.3200 R:10.0 loss:1850.5287 exploreP:0.0125\n",
      "Episode:1260 meanR:10.2300 R:9.0 loss:2677.2649 exploreP:0.0125\n",
      "Episode:1261 meanR:10.2100 R:8.0 loss:2676.4600 exploreP:0.0125\n",
      "Episode:1262 meanR:10.2000 R:9.0 loss:3847.7043 exploreP:0.0125\n",
      "Episode:1263 meanR:10.1900 R:10.0 loss:4594.7397 exploreP:0.0125\n",
      "Episode:1264 meanR:10.9900 R:88.0 loss:8747.5977 exploreP:0.0125\n",
      "Episode:1265 meanR:11.0100 R:12.0 loss:4836.0581 exploreP:0.0125\n",
      "Episode:1266 meanR:11.0100 R:10.0 loss:3101.4688 exploreP:0.0125\n",
      "Episode:1267 meanR:11.0800 R:16.0 loss:2709.9751 exploreP:0.0125\n",
      "Episode:1268 meanR:11.1300 R:15.0 loss:2531.3831 exploreP:0.0125\n",
      "Episode:1269 meanR:11.1400 R:10.0 loss:1624.5587 exploreP:0.0125\n",
      "Episode:1270 meanR:11.1400 R:10.0 loss:1204.0175 exploreP:0.0125\n",
      "Episode:1271 meanR:11.1200 R:9.0 loss:1019.1874 exploreP:0.0125\n",
      "Episode:1272 meanR:11.1200 R:10.0 loss:697.5086 exploreP:0.0125\n",
      "Episode:1273 meanR:11.2600 R:23.0 loss:827.5621 exploreP:0.0125\n",
      "Episode:1274 meanR:11.2700 R:11.0 loss:1124.3700 exploreP:0.0125\n",
      "Episode:1275 meanR:11.3200 R:15.0 loss:1099.5222 exploreP:0.0125\n",
      "Episode:1276 meanR:11.4400 R:22.0 loss:3213.0974 exploreP:0.0125\n",
      "Episode:1277 meanR:11.5700 R:22.0 loss:4848.1606 exploreP:0.0125\n",
      "Episode:1278 meanR:11.6400 R:17.0 loss:6771.9375 exploreP:0.0124\n",
      "Episode:1279 meanR:11.7100 R:17.0 loss:9160.0146 exploreP:0.0124\n",
      "Episode:1280 meanR:11.8000 R:19.0 loss:14393.4492 exploreP:0.0124\n",
      "Episode:1281 meanR:11.8500 R:15.0 loss:12105.7607 exploreP:0.0124\n",
      "Episode:1282 meanR:11.8700 R:12.0 loss:11631.9033 exploreP:0.0124\n",
      "Episode:1283 meanR:11.8600 R:9.0 loss:17625.3691 exploreP:0.0124\n",
      "Episode:1284 meanR:11.8600 R:10.0 loss:8109.6313 exploreP:0.0124\n",
      "Episode:1285 meanR:11.8500 R:9.0 loss:12966.5068 exploreP:0.0124\n",
      "Episode:1286 meanR:11.8800 R:13.0 loss:9478.8174 exploreP:0.0124\n",
      "Episode:1287 meanR:11.8700 R:9.0 loss:8794.1348 exploreP:0.0124\n",
      "Episode:1288 meanR:11.8400 R:10.0 loss:8831.0244 exploreP:0.0124\n",
      "Episode:1289 meanR:11.8300 R:9.0 loss:8048.4053 exploreP:0.0124\n",
      "Episode:1290 meanR:11.8200 R:9.0 loss:4182.5615 exploreP:0.0124\n",
      "Episode:1291 meanR:11.7900 R:9.0 loss:4735.7559 exploreP:0.0124\n",
      "Episode:1292 meanR:11.7800 R:9.0 loss:3370.7061 exploreP:0.0124\n",
      "Episode:1293 meanR:11.7700 R:10.0 loss:3626.7246 exploreP:0.0124\n",
      "Episode:1294 meanR:11.7700 R:10.0 loss:2175.9124 exploreP:0.0124\n",
      "Episode:1295 meanR:11.7700 R:10.0 loss:2876.1460 exploreP:0.0124\n",
      "Episode:1296 meanR:11.7700 R:10.0 loss:2132.6367 exploreP:0.0124\n",
      "Episode:1297 meanR:11.7700 R:10.0 loss:1543.2069 exploreP:0.0124\n",
      "Episode:1298 meanR:11.7700 R:11.0 loss:758.6198 exploreP:0.0124\n",
      "Episode:1299 meanR:11.7700 R:10.0 loss:1761.5836 exploreP:0.0124\n",
      "Episode:1300 meanR:11.7700 R:9.0 loss:1187.9247 exploreP:0.0124\n",
      "Episode:1301 meanR:11.7900 R:10.0 loss:1238.8196 exploreP:0.0124\n",
      "Episode:1302 meanR:11.8000 R:10.0 loss:2028.4055 exploreP:0.0124\n",
      "Episode:1303 meanR:11.8200 R:10.0 loss:1248.3165 exploreP:0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1304 meanR:11.8400 R:10.0 loss:1808.0309 exploreP:0.0124\n",
      "Episode:1305 meanR:11.8400 R:10.0 loss:2057.7593 exploreP:0.0124\n",
      "Episode:1306 meanR:12.8800 R:114.0 loss:4539.3701 exploreP:0.0123\n",
      "Episode:1307 meanR:14.2800 R:149.0 loss:3648.9644 exploreP:0.0123\n",
      "Episode:1308 meanR:14.4000 R:22.0 loss:885.3043 exploreP:0.0123\n",
      "Episode:1309 meanR:14.5200 R:22.0 loss:1497.7935 exploreP:0.0123\n",
      "Episode:1310 meanR:14.6900 R:25.0 loss:3142.8765 exploreP:0.0123\n",
      "Episode:1311 meanR:14.8100 R:22.0 loss:4895.2183 exploreP:0.0123\n",
      "Episode:1312 meanR:14.9600 R:23.0 loss:6748.2002 exploreP:0.0123\n",
      "Episode:1313 meanR:14.9900 R:14.0 loss:7222.4951 exploreP:0.0123\n",
      "Episode:1314 meanR:15.0600 R:16.0 loss:9537.6748 exploreP:0.0123\n",
      "Episode:1315 meanR:15.1000 R:14.0 loss:6177.0767 exploreP:0.0123\n",
      "Episode:1316 meanR:15.1200 R:10.0 loss:7755.1108 exploreP:0.0123\n",
      "Episode:1317 meanR:15.1800 R:16.0 loss:7969.9092 exploreP:0.0123\n",
      "Episode:1318 meanR:15.2100 R:12.0 loss:8265.8389 exploreP:0.0123\n",
      "Episode:1319 meanR:15.2200 R:10.0 loss:6599.3188 exploreP:0.0123\n",
      "Episode:1320 meanR:15.2300 R:10.0 loss:6237.6660 exploreP:0.0123\n",
      "Episode:1321 meanR:15.2100 R:9.0 loss:5818.9595 exploreP:0.0123\n",
      "Episode:1322 meanR:15.2600 R:13.0 loss:6715.1978 exploreP:0.0123\n",
      "Episode:1323 meanR:15.2600 R:10.0 loss:3702.1960 exploreP:0.0123\n",
      "Episode:1324 meanR:15.2600 R:10.0 loss:3121.3716 exploreP:0.0123\n",
      "Episode:1325 meanR:15.0800 R:9.0 loss:3597.2512 exploreP:0.0123\n",
      "Episode:1326 meanR:15.0400 R:18.0 loss:3017.4099 exploreP:0.0123\n",
      "Episode:1327 meanR:15.0000 R:16.0 loss:1312.9897 exploreP:0.0122\n",
      "Episode:1328 meanR:14.8900 R:9.0 loss:1984.3680 exploreP:0.0122\n",
      "Episode:1329 meanR:14.8800 R:9.0 loss:1244.4697 exploreP:0.0122\n",
      "Episode:1330 meanR:14.8800 R:10.0 loss:1211.4547 exploreP:0.0122\n",
      "Episode:1331 meanR:14.8900 R:10.0 loss:1064.4603 exploreP:0.0122\n",
      "Episode:1332 meanR:14.8900 R:10.0 loss:1110.3593 exploreP:0.0122\n",
      "Episode:1333 meanR:14.9000 R:11.0 loss:1662.5007 exploreP:0.0122\n",
      "Episode:1334 meanR:14.9000 R:10.0 loss:1372.2192 exploreP:0.0122\n",
      "Episode:1335 meanR:14.9200 R:11.0 loss:2010.9218 exploreP:0.0122\n",
      "Episode:1336 meanR:14.9100 R:9.0 loss:1409.2632 exploreP:0.0122\n",
      "Episode:1337 meanR:14.9000 R:10.0 loss:1711.1692 exploreP:0.0122\n",
      "Episode:1338 meanR:14.9000 R:10.0 loss:1241.0879 exploreP:0.0122\n",
      "Episode:1339 meanR:14.8900 R:9.0 loss:1851.5137 exploreP:0.0122\n",
      "Episode:1340 meanR:14.9000 R:10.0 loss:1776.6375 exploreP:0.0122\n",
      "Episode:1341 meanR:14.9300 R:12.0 loss:2843.6428 exploreP:0.0122\n",
      "Episode:1342 meanR:14.9200 R:9.0 loss:3631.6099 exploreP:0.0122\n",
      "Episode:1343 meanR:17.3400 R:253.0 loss:3334.7117 exploreP:0.0122\n",
      "Episode:1344 meanR:17.5500 R:31.0 loss:1296.5216 exploreP:0.0122\n",
      "Episode:1345 meanR:17.7400 R:29.0 loss:3019.9937 exploreP:0.0121\n",
      "Episode:1346 meanR:18.0000 R:34.0 loss:4241.7402 exploreP:0.0121\n",
      "Episode:1347 meanR:18.0800 R:17.0 loss:4085.3340 exploreP:0.0121\n",
      "Episode:1348 meanR:18.1700 R:19.0 loss:4756.9648 exploreP:0.0121\n",
      "Episode:1349 meanR:18.2700 R:19.0 loss:5230.4380 exploreP:0.0121\n",
      "Episode:1350 meanR:18.2800 R:10.0 loss:2233.0239 exploreP:0.0121\n",
      "Episode:1351 meanR:18.3600 R:18.0 loss:3533.7441 exploreP:0.0121\n",
      "Episode:1352 meanR:18.3600 R:10.0 loss:4022.0469 exploreP:0.0121\n",
      "Episode:1353 meanR:18.3600 R:10.0 loss:3438.9629 exploreP:0.0121\n",
      "Episode:1354 meanR:18.4200 R:16.0 loss:1939.6769 exploreP:0.0121\n",
      "Episode:1355 meanR:18.4300 R:10.0 loss:2297.8242 exploreP:0.0121\n",
      "Episode:1356 meanR:18.5000 R:16.0 loss:1222.6847 exploreP:0.0121\n",
      "Episode:1357 meanR:18.5000 R:10.0 loss:1478.6453 exploreP:0.0121\n",
      "Episode:1358 meanR:18.6100 R:21.0 loss:1383.9526 exploreP:0.0121\n",
      "Episode:1359 meanR:19.9200 R:141.0 loss:5584.5938 exploreP:0.0121\n",
      "Episode:1360 meanR:20.1500 R:32.0 loss:4812.2378 exploreP:0.0121\n",
      "Episode:1361 meanR:20.3500 R:28.0 loss:3189.1875 exploreP:0.0121\n",
      "Episode:1362 meanR:20.5200 R:26.0 loss:3083.9260 exploreP:0.0121\n",
      "Episode:1363 meanR:20.7200 R:30.0 loss:3402.0164 exploreP:0.0120\n",
      "Episode:1364 meanR:20.0800 R:24.0 loss:3398.7546 exploreP:0.0120\n",
      "Episode:1365 meanR:20.2500 R:29.0 loss:6999.8193 exploreP:0.0120\n",
      "Episode:1366 meanR:20.3600 R:21.0 loss:8271.0840 exploreP:0.0120\n",
      "Episode:1367 meanR:20.3800 R:18.0 loss:8667.0176 exploreP:0.0120\n",
      "Episode:1368 meanR:20.4000 R:17.0 loss:5729.1592 exploreP:0.0120\n",
      "Episode:1369 meanR:20.5000 R:20.0 loss:5417.2334 exploreP:0.0120\n",
      "Episode:1370 meanR:20.5200 R:12.0 loss:2828.4685 exploreP:0.0120\n",
      "Episode:1371 meanR:23.3100 R:288.0 loss:5329.4419 exploreP:0.0120\n",
      "Episode:1372 meanR:23.9400 R:73.0 loss:7577.9673 exploreP:0.0119\n",
      "Episode:1373 meanR:28.7100 R:500.0 loss:8478.1074 exploreP:0.0119\n",
      "Episode:1374 meanR:33.6000 R:500.0 loss:5878.6885 exploreP:0.0118\n",
      "Episode:1375 meanR:34.7400 R:129.0 loss:3903.4573 exploreP:0.0117\n",
      "Episode:1376 meanR:35.7300 R:121.0 loss:7320.4199 exploreP:0.0117\n",
      "Episode:1377 meanR:36.8500 R:134.0 loss:6352.4292 exploreP:0.0117\n",
      "Episode:1378 meanR:37.8400 R:116.0 loss:5554.0425 exploreP:0.0117\n",
      "Episode:1379 meanR:38.9400 R:127.0 loss:4956.8765 exploreP:0.0117\n",
      "Episode:1380 meanR:39.9900 R:124.0 loss:6570.2300 exploreP:0.0116\n",
      "Episode:1381 meanR:41.2500 R:141.0 loss:7648.1792 exploreP:0.0116\n",
      "Episode:1382 meanR:42.5200 R:139.0 loss:5538.8716 exploreP:0.0116\n",
      "Episode:1383 meanR:43.6200 R:119.0 loss:2339.7959 exploreP:0.0116\n",
      "Episode:1384 meanR:44.1100 R:59.0 loss:2181.7759 exploreP:0.0116\n",
      "Episode:1385 meanR:44.6000 R:58.0 loss:1780.4191 exploreP:0.0116\n",
      "Episode:1386 meanR:45.0000 R:53.0 loss:952.6173 exploreP:0.0115\n",
      "Episode:1387 meanR:45.4700 R:56.0 loss:668.1714 exploreP:0.0115\n",
      "Episode:1388 meanR:45.9300 R:56.0 loss:1752.7136 exploreP:0.0115\n",
      "Episode:1389 meanR:46.8800 R:104.0 loss:6288.8989 exploreP:0.0115\n",
      "Episode:1390 meanR:48.0400 R:125.0 loss:6313.6519 exploreP:0.0115\n",
      "Episode:1391 meanR:49.0500 R:110.0 loss:3469.2620 exploreP:0.0115\n",
      "Episode:1392 meanR:49.7100 R:75.0 loss:2980.2986 exploreP:0.0115\n",
      "Episode:1393 meanR:50.6100 R:100.0 loss:4412.0576 exploreP:0.0115\n",
      "Episode:1394 meanR:51.4600 R:95.0 loss:1934.1263 exploreP:0.0114\n",
      "Episode:1395 meanR:51.7200 R:36.0 loss:1051.6279 exploreP:0.0114\n",
      "Episode:1396 meanR:51.9700 R:35.0 loss:2646.0857 exploreP:0.0114\n",
      "Episode:1397 meanR:52.9300 R:106.0 loss:9503.3818 exploreP:0.0114\n",
      "Episode:1398 meanR:53.9800 R:116.0 loss:7045.5786 exploreP:0.0114\n",
      "Episode:1399 meanR:55.1000 R:122.0 loss:2714.0828 exploreP:0.0114\n",
      "Episode:1400 meanR:55.9600 R:95.0 loss:2388.3313 exploreP:0.0114\n",
      "Episode:1401 meanR:56.1600 R:30.0 loss:6855.1963 exploreP:0.0114\n",
      "Episode:1402 meanR:57.0500 R:99.0 loss:5487.1968 exploreP:0.0113\n",
      "Episode:1403 meanR:57.9300 R:98.0 loss:1533.4907 exploreP:0.0113\n",
      "Episode:1404 meanR:58.0800 R:25.0 loss:681.1464 exploreP:0.0113\n",
      "Episode:1405 meanR:58.3600 R:38.0 loss:1439.3385 exploreP:0.0113\n",
      "Episode:1406 meanR:57.6000 R:38.0 loss:2633.1333 exploreP:0.0113\n",
      "Episode:1407 meanR:56.4500 R:34.0 loss:5771.5405 exploreP:0.0113\n",
      "Episode:1408 meanR:57.4900 R:126.0 loss:13450.6299 exploreP:0.0113\n",
      "Episode:1409 meanR:58.5400 R:127.0 loss:7593.1030 exploreP:0.0113\n",
      "Episode:1410 meanR:59.1200 R:83.0 loss:2327.9817 exploreP:0.0113\n",
      "Episode:1411 meanR:59.2900 R:39.0 loss:2932.1309 exploreP:0.0113\n",
      "Episode:1412 meanR:59.7100 R:65.0 loss:5874.5928 exploreP:0.0113\n",
      "Episode:1413 meanR:59.8600 R:29.0 loss:3166.6318 exploreP:0.0113\n",
      "Episode:1414 meanR:60.3700 R:67.0 loss:1580.2104 exploreP:0.0112\n",
      "Episode:1415 meanR:60.6100 R:38.0 loss:657.7664 exploreP:0.0112\n",
      "Episode:1416 meanR:60.8200 R:31.0 loss:635.9101 exploreP:0.0112\n",
      "Episode:1417 meanR:61.0300 R:37.0 loss:368.9885 exploreP:0.0112\n",
      "Episode:1418 meanR:61.3600 R:45.0 loss:424.7114 exploreP:0.0112\n",
      "Episode:1419 meanR:61.6000 R:34.0 loss:566.5198 exploreP:0.0112\n",
      "Episode:1420 meanR:61.9300 R:43.0 loss:892.3916 exploreP:0.0112\n",
      "Episode:1421 meanR:62.2000 R:36.0 loss:1293.1854 exploreP:0.0112\n",
      "Episode:1422 meanR:62.5200 R:45.0 loss:1492.1210 exploreP:0.0112\n",
      "Episode:1423 meanR:62.8900 R:47.0 loss:1988.3763 exploreP:0.0112\n",
      "Episode:1424 meanR:63.3200 R:53.0 loss:4975.9951 exploreP:0.0112\n",
      "Episode:1425 meanR:64.4500 R:122.0 loss:12884.4648 exploreP:0.0112\n",
      "Episode:1426 meanR:65.3700 R:110.0 loss:9118.3359 exploreP:0.0112\n",
      "Episode:1427 meanR:65.8500 R:64.0 loss:5686.2739 exploreP:0.0112\n",
      "Episode:1428 meanR:66.8000 R:104.0 loss:3992.5715 exploreP:0.0112\n",
      "Episode:1429 meanR:67.0700 R:36.0 loss:2995.3994 exploreP:0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1430 meanR:67.3400 R:37.0 loss:2603.2766 exploreP:0.0111\n",
      "Episode:1431 meanR:67.6300 R:39.0 loss:3303.7590 exploreP:0.0111\n",
      "Episode:1432 meanR:68.0100 R:48.0 loss:5444.9102 exploreP:0.0111\n",
      "Episode:1433 meanR:68.1800 R:28.0 loss:6763.8086 exploreP:0.0111\n",
      "Episode:1434 meanR:68.9500 R:87.0 loss:3015.9504 exploreP:0.0111\n",
      "Episode:1435 meanR:69.5300 R:69.0 loss:666.4903 exploreP:0.0111\n",
      "Episode:1436 meanR:70.2200 R:78.0 loss:1294.4814 exploreP:0.0111\n",
      "Episode:1437 meanR:70.9200 R:80.0 loss:1330.0583 exploreP:0.0111\n",
      "Episode:1438 meanR:71.5600 R:74.0 loss:1762.3890 exploreP:0.0111\n",
      "Episode:1439 meanR:71.9100 R:44.0 loss:7493.2422 exploreP:0.0111\n",
      "Episode:1440 meanR:73.2800 R:147.0 loss:9851.3760 exploreP:0.0111\n",
      "Episode:1441 meanR:73.6600 R:50.0 loss:8200.1562 exploreP:0.0111\n",
      "Episode:1442 meanR:74.0700 R:50.0 loss:7275.8481 exploreP:0.0111\n",
      "Episode:1443 meanR:72.1800 R:64.0 loss:4545.8320 exploreP:0.0110\n",
      "Episode:1444 meanR:72.6800 R:81.0 loss:3619.8098 exploreP:0.0110\n",
      "Episode:1445 meanR:72.6100 R:22.0 loss:2588.9121 exploreP:0.0110\n",
      "Episode:1446 meanR:72.5200 R:25.0 loss:2504.1987 exploreP:0.0110\n",
      "Episode:1447 meanR:72.6700 R:32.0 loss:2513.0933 exploreP:0.0110\n",
      "Episode:1448 meanR:72.9000 R:42.0 loss:3017.2034 exploreP:0.0110\n",
      "Episode:1449 meanR:73.1500 R:44.0 loss:5467.4365 exploreP:0.0110\n",
      "Episode:1450 meanR:74.2400 R:119.0 loss:1884.0254 exploreP:0.0110\n",
      "Episode:1451 meanR:75.2500 R:119.0 loss:922.2778 exploreP:0.0110\n",
      "Episode:1452 meanR:76.3800 R:123.0 loss:375.2140 exploreP:0.0110\n",
      "Episode:1453 meanR:77.4700 R:119.0 loss:323.6744 exploreP:0.0110\n",
      "Episode:1454 meanR:78.5500 R:124.0 loss:320.7437 exploreP:0.0110\n",
      "Episode:1455 meanR:79.7500 R:130.0 loss:502.5416 exploreP:0.0110\n",
      "Episode:1456 meanR:80.9800 R:139.0 loss:925.1884 exploreP:0.0109\n",
      "Episode:1457 meanR:82.6000 R:172.0 loss:13685.0332 exploreP:0.0109\n",
      "Episode:1458 meanR:83.5800 R:119.0 loss:11813.6211 exploreP:0.0109\n",
      "Episode:1459 meanR:83.3300 R:116.0 loss:6411.7017 exploreP:0.0109\n",
      "Episode:1460 meanR:84.1300 R:112.0 loss:6630.0850 exploreP:0.0109\n",
      "Episode:1461 meanR:84.9000 R:105.0 loss:5714.8296 exploreP:0.0109\n",
      "Episode:1462 meanR:86.7900 R:215.0 loss:1469.0444 exploreP:0.0109\n",
      "Episode:1463 meanR:87.6300 R:114.0 loss:545.5683 exploreP:0.0109\n",
      "Episode:1464 meanR:88.4200 R:103.0 loss:390.1717 exploreP:0.0108\n",
      "Episode:1465 meanR:89.1300 R:100.0 loss:281.4943 exploreP:0.0108\n",
      "Episode:1466 meanR:89.9100 R:99.0 loss:326.2909 exploreP:0.0108\n",
      "Episode:1467 meanR:90.9100 R:118.0 loss:660.2042 exploreP:0.0108\n",
      "Episode:1468 meanR:91.8500 R:111.0 loss:4376.6978 exploreP:0.0108\n",
      "Episode:1469 meanR:92.8800 R:123.0 loss:19913.8457 exploreP:0.0108\n",
      "Episode:1470 meanR:92.9600 R:20.0 loss:11106.6416 exploreP:0.0108\n",
      "Episode:1471 meanR:90.2400 R:16.0 loss:13399.0820 exploreP:0.0108\n",
      "Episode:1472 meanR:89.7300 R:22.0 loss:13568.2783 exploreP:0.0108\n",
      "Episode:1473 meanR:85.6300 R:90.0 loss:8556.8506 exploreP:0.0108\n",
      "Episode:1474 meanR:80.8000 R:17.0 loss:8627.1328 exploreP:0.0108\n",
      "Episode:1475 meanR:79.6600 R:15.0 loss:7871.3491 exploreP:0.0108\n",
      "Episode:1476 meanR:79.3900 R:94.0 loss:7289.4243 exploreP:0.0108\n",
      "Episode:1477 meanR:79.0300 R:98.0 loss:7365.8379 exploreP:0.0108\n",
      "Episode:1478 meanR:79.1300 R:126.0 loss:3136.4426 exploreP:0.0108\n",
      "Episode:1479 meanR:78.8300 R:97.0 loss:1618.8241 exploreP:0.0108\n",
      "Episode:1480 meanR:77.8000 R:21.0 loss:1198.1005 exploreP:0.0108\n",
      "Episode:1481 meanR:76.5700 R:18.0 loss:1076.2618 exploreP:0.0107\n",
      "Episode:1482 meanR:75.3400 R:16.0 loss:791.6792 exploreP:0.0107\n",
      "Episode:1483 meanR:74.3000 R:15.0 loss:962.4269 exploreP:0.0107\n",
      "Episode:1484 meanR:73.8700 R:16.0 loss:650.8695 exploreP:0.0107\n",
      "Episode:1485 meanR:73.4400 R:15.0 loss:692.4066 exploreP:0.0107\n",
      "Episode:1486 meanR:73.0400 R:13.0 loss:732.7555 exploreP:0.0107\n",
      "Episode:1487 meanR:72.6000 R:12.0 loss:511.8750 exploreP:0.0107\n",
      "Episode:1488 meanR:72.1700 R:13.0 loss:600.2897 exploreP:0.0107\n",
      "Episode:1489 meanR:71.2500 R:12.0 loss:443.6231 exploreP:0.0107\n",
      "Episode:1490 meanR:70.1300 R:13.0 loss:658.7733 exploreP:0.0107\n",
      "Episode:1491 meanR:69.1700 R:14.0 loss:715.4297 exploreP:0.0107\n",
      "Episode:1492 meanR:68.5500 R:13.0 loss:443.7837 exploreP:0.0107\n",
      "Episode:1493 meanR:67.6800 R:13.0 loss:312.7086 exploreP:0.0107\n",
      "Episode:1494 meanR:66.8600 R:13.0 loss:399.9921 exploreP:0.0107\n",
      "Episode:1495 meanR:66.6200 R:12.0 loss:311.2701 exploreP:0.0107\n",
      "Episode:1496 meanR:66.4100 R:14.0 loss:671.8248 exploreP:0.0107\n",
      "Episode:1497 meanR:65.4800 R:13.0 loss:317.8405 exploreP:0.0107\n",
      "Episode:1498 meanR:64.4400 R:12.0 loss:319.7484 exploreP:0.0107\n",
      "Episode:1499 meanR:63.3400 R:12.0 loss:468.0792 exploreP:0.0107\n",
      "Episode:1500 meanR:62.5200 R:13.0 loss:319.1206 exploreP:0.0107\n",
      "Episode:1501 meanR:62.3500 R:13.0 loss:332.5145 exploreP:0.0107\n",
      "Episode:1502 meanR:61.5000 R:14.0 loss:225.0097 exploreP:0.0107\n",
      "Episode:1503 meanR:60.6500 R:13.0 loss:336.1394 exploreP:0.0107\n",
      "Episode:1504 meanR:60.5300 R:13.0 loss:344.2900 exploreP:0.0107\n",
      "Episode:1505 meanR:60.3100 R:16.0 loss:211.9291 exploreP:0.0107\n",
      "Episode:1506 meanR:60.0600 R:13.0 loss:463.4646 exploreP:0.0107\n",
      "Episode:1507 meanR:59.8600 R:14.0 loss:379.7575 exploreP:0.0107\n",
      "Episode:1508 meanR:58.7500 R:15.0 loss:510.5455 exploreP:0.0107\n",
      "Episode:1509 meanR:57.6400 R:16.0 loss:523.6576 exploreP:0.0107\n",
      "Episode:1510 meanR:56.9900 R:18.0 loss:524.5469 exploreP:0.0107\n",
      "Episode:1511 meanR:56.8200 R:22.0 loss:926.5825 exploreP:0.0107\n",
      "Episode:1512 meanR:57.1500 R:98.0 loss:2208.6548 exploreP:0.0107\n",
      "Episode:1513 meanR:57.5500 R:69.0 loss:15021.9043 exploreP:0.0107\n",
      "Episode:1514 meanR:58.0200 R:114.0 loss:25774.6445 exploreP:0.0107\n",
      "Episode:1515 meanR:57.7800 R:14.0 loss:10726.0322 exploreP:0.0107\n",
      "Episode:1516 meanR:57.6200 R:15.0 loss:8259.3164 exploreP:0.0107\n",
      "Episode:1517 meanR:57.3900 R:14.0 loss:10555.2344 exploreP:0.0107\n",
      "Episode:1518 meanR:57.0800 R:14.0 loss:6763.2197 exploreP:0.0107\n",
      "Episode:1519 meanR:56.8900 R:15.0 loss:11395.2168 exploreP:0.0107\n",
      "Episode:1520 meanR:56.5900 R:13.0 loss:9089.4727 exploreP:0.0107\n",
      "Episode:1521 meanR:56.4000 R:17.0 loss:8441.1045 exploreP:0.0107\n",
      "Episode:1522 meanR:56.0900 R:14.0 loss:9467.1621 exploreP:0.0107\n",
      "Episode:1523 meanR:55.7600 R:14.0 loss:10290.3115 exploreP:0.0107\n",
      "Episode:1524 meanR:55.4000 R:17.0 loss:6679.1743 exploreP:0.0107\n",
      "Episode:1525 meanR:54.3200 R:14.0 loss:9380.0928 exploreP:0.0107\n",
      "Episode:1526 meanR:53.4400 R:22.0 loss:9656.9639 exploreP:0.0107\n",
      "Episode:1527 meanR:53.3500 R:55.0 loss:6464.1313 exploreP:0.0107\n",
      "Episode:1528 meanR:53.3000 R:99.0 loss:3438.5840 exploreP:0.0107\n",
      "Episode:1529 meanR:53.1600 R:22.0 loss:1904.3964 exploreP:0.0107\n",
      "Episode:1530 meanR:52.9600 R:17.0 loss:1873.7798 exploreP:0.0107\n",
      "Episode:1531 meanR:52.7300 R:16.0 loss:1686.8118 exploreP:0.0107\n",
      "Episode:1532 meanR:52.4000 R:15.0 loss:1654.8699 exploreP:0.0107\n",
      "Episode:1533 meanR:52.2700 R:15.0 loss:1898.9490 exploreP:0.0107\n",
      "Episode:1534 meanR:51.5200 R:12.0 loss:1676.6885 exploreP:0.0107\n",
      "Episode:1535 meanR:50.9600 R:13.0 loss:1872.1860 exploreP:0.0107\n",
      "Episode:1536 meanR:50.3100 R:13.0 loss:1333.2921 exploreP:0.0107\n",
      "Episode:1537 meanR:49.6300 R:12.0 loss:1698.1021 exploreP:0.0107\n",
      "Episode:1538 meanR:48.9800 R:9.0 loss:1687.1394 exploreP:0.0107\n",
      "Episode:1539 meanR:48.6400 R:10.0 loss:1977.3936 exploreP:0.0107\n",
      "Episode:1540 meanR:47.2800 R:11.0 loss:1799.5481 exploreP:0.0107\n",
      "Episode:1541 meanR:46.8800 R:10.0 loss:1103.5457 exploreP:0.0107\n",
      "Episode:1542 meanR:46.4800 R:10.0 loss:846.9658 exploreP:0.0107\n",
      "Episode:1543 meanR:45.9400 R:10.0 loss:1361.1189 exploreP:0.0107\n",
      "Episode:1544 meanR:45.2200 R:9.0 loss:1114.6292 exploreP:0.0107\n",
      "Episode:1545 meanR:45.0900 R:9.0 loss:693.3968 exploreP:0.0107\n",
      "Episode:1546 meanR:44.9300 R:9.0 loss:641.5449 exploreP:0.0107\n",
      "Episode:1547 meanR:44.6900 R:8.0 loss:1003.2254 exploreP:0.0107\n",
      "Episode:1548 meanR:44.3700 R:10.0 loss:804.3767 exploreP:0.0107\n",
      "Episode:1549 meanR:44.0300 R:10.0 loss:506.4879 exploreP:0.0107\n",
      "Episode:1550 meanR:42.9300 R:9.0 loss:359.3095 exploreP:0.0107\n",
      "Episode:1551 meanR:41.8400 R:10.0 loss:528.2924 exploreP:0.0107\n",
      "Episode:1552 meanR:40.7100 R:10.0 loss:444.7318 exploreP:0.0107\n",
      "Episode:1553 meanR:39.6200 R:10.0 loss:560.3201 exploreP:0.0107\n",
      "Episode:1554 meanR:38.4800 R:10.0 loss:571.0344 exploreP:0.0107\n",
      "Episode:1555 meanR:37.2800 R:10.0 loss:373.2590 exploreP:0.0107\n",
      "Episode:1556 meanR:35.9700 R:8.0 loss:301.8350 exploreP:0.0107\n",
      "Episode:1557 meanR:34.3400 R:9.0 loss:434.1501 exploreP:0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1558 meanR:33.2600 R:11.0 loss:711.6642 exploreP:0.0107\n",
      "Episode:1559 meanR:32.2100 R:11.0 loss:625.8873 exploreP:0.0107\n",
      "Episode:1560 meanR:31.2000 R:11.0 loss:771.8405 exploreP:0.0107\n",
      "Episode:1561 meanR:30.2800 R:13.0 loss:669.6840 exploreP:0.0107\n",
      "Episode:1562 meanR:28.2500 R:12.0 loss:801.5320 exploreP:0.0106\n",
      "Episode:1563 meanR:27.2700 R:16.0 loss:997.3898 exploreP:0.0106\n",
      "Episode:1564 meanR:26.4500 R:21.0 loss:1490.1390 exploreP:0.0106\n",
      "Episode:1565 meanR:25.8100 R:36.0 loss:1161.2115 exploreP:0.0106\n",
      "Episode:1566 meanR:25.7300 R:91.0 loss:2458.9661 exploreP:0.0106\n",
      "Episode:1567 meanR:25.1000 R:55.0 loss:4423.5508 exploreP:0.0106\n",
      "Episode:1568 meanR:24.6000 R:61.0 loss:15143.4736 exploreP:0.0106\n",
      "Episode:1569 meanR:24.5300 R:116.0 loss:17297.3652 exploreP:0.0106\n",
      "Episode:1570 meanR:24.4400 R:11.0 loss:13092.8467 exploreP:0.0106\n",
      "Episode:1571 meanR:24.4100 R:13.0 loss:9976.2256 exploreP:0.0106\n",
      "Episode:1572 meanR:24.3400 R:15.0 loss:9795.0693 exploreP:0.0106\n",
      "Episode:1573 meanR:23.5800 R:14.0 loss:10668.1357 exploreP:0.0106\n",
      "Episode:1574 meanR:23.5400 R:13.0 loss:8672.3252 exploreP:0.0106\n",
      "Episode:1575 meanR:23.5200 R:13.0 loss:7859.2861 exploreP:0.0106\n",
      "Episode:1576 meanR:22.7300 R:15.0 loss:6702.2207 exploreP:0.0106\n",
      "Episode:1577 meanR:21.9300 R:18.0 loss:7253.2759 exploreP:0.0106\n",
      "Episode:1578 meanR:20.8600 R:19.0 loss:8113.2490 exploreP:0.0106\n",
      "Episode:1579 meanR:20.0400 R:15.0 loss:9620.5742 exploreP:0.0106\n",
      "Episode:1580 meanR:20.7400 R:91.0 loss:6391.7065 exploreP:0.0106\n",
      "Episode:1581 meanR:21.0800 R:52.0 loss:4906.1348 exploreP:0.0106\n",
      "Episode:1582 meanR:21.4500 R:53.0 loss:3397.9631 exploreP:0.0106\n",
      "Episode:1583 meanR:21.6400 R:34.0 loss:3050.3953 exploreP:0.0106\n",
      "Episode:1584 meanR:21.7100 R:23.0 loss:2718.4922 exploreP:0.0106\n",
      "Episode:1585 meanR:21.7800 R:22.0 loss:3238.9478 exploreP:0.0106\n",
      "Episode:1586 meanR:21.8200 R:17.0 loss:2665.1882 exploreP:0.0106\n",
      "Episode:1587 meanR:21.8500 R:15.0 loss:2829.8901 exploreP:0.0106\n",
      "Episode:1588 meanR:21.8800 R:16.0 loss:2796.9990 exploreP:0.0106\n",
      "Episode:1589 meanR:21.9100 R:15.0 loss:2555.1741 exploreP:0.0106\n",
      "Episode:1590 meanR:21.9300 R:15.0 loss:2204.8286 exploreP:0.0106\n",
      "Episode:1591 meanR:21.9400 R:15.0 loss:2084.7947 exploreP:0.0106\n",
      "Episode:1592 meanR:21.9600 R:15.0 loss:1834.4553 exploreP:0.0106\n",
      "Episode:1593 meanR:21.9600 R:13.0 loss:1525.0347 exploreP:0.0106\n",
      "Episode:1594 meanR:21.9600 R:13.0 loss:1182.0240 exploreP:0.0106\n",
      "Episode:1595 meanR:21.9600 R:12.0 loss:1115.6073 exploreP:0.0106\n",
      "Episode:1596 meanR:21.9300 R:11.0 loss:675.5512 exploreP:0.0106\n",
      "Episode:1597 meanR:21.9200 R:12.0 loss:1039.6263 exploreP:0.0106\n",
      "Episode:1598 meanR:21.9100 R:11.0 loss:744.2804 exploreP:0.0106\n",
      "Episode:1599 meanR:21.9100 R:12.0 loss:709.3745 exploreP:0.0106\n",
      "Episode:1600 meanR:21.8800 R:10.0 loss:439.3239 exploreP:0.0106\n",
      "Episode:1601 meanR:21.8500 R:10.0 loss:435.3380 exploreP:0.0106\n",
      "Episode:1602 meanR:21.8200 R:11.0 loss:330.9282 exploreP:0.0106\n",
      "Episode:1603 meanR:21.8000 R:11.0 loss:387.1773 exploreP:0.0106\n",
      "Episode:1604 meanR:21.7800 R:11.0 loss:461.3819 exploreP:0.0106\n",
      "Episode:1605 meanR:21.7100 R:9.0 loss:516.1682 exploreP:0.0106\n",
      "Episode:1606 meanR:21.6700 R:9.0 loss:418.1581 exploreP:0.0106\n",
      "Episode:1607 meanR:21.6300 R:10.0 loss:512.7892 exploreP:0.0106\n",
      "Episode:1608 meanR:21.5700 R:9.0 loss:751.0606 exploreP:0.0106\n",
      "Episode:1609 meanR:21.5100 R:10.0 loss:748.4617 exploreP:0.0106\n",
      "Episode:1610 meanR:21.4400 R:11.0 loss:1114.2726 exploreP:0.0106\n",
      "Episode:1611 meanR:21.3300 R:11.0 loss:874.0781 exploreP:0.0106\n",
      "Episode:1612 meanR:20.4600 R:11.0 loss:1300.5377 exploreP:0.0106\n",
      "Episode:1613 meanR:19.9000 R:13.0 loss:1283.4998 exploreP:0.0106\n",
      "Episode:1614 meanR:18.9200 R:16.0 loss:1522.4258 exploreP:0.0106\n",
      "Episode:1615 meanR:18.9500 R:17.0 loss:1642.0090 exploreP:0.0106\n",
      "Episode:1616 meanR:18.9700 R:17.0 loss:2101.8079 exploreP:0.0106\n",
      "Episode:1617 meanR:19.0000 R:17.0 loss:2377.0542 exploreP:0.0106\n",
      "Episode:1618 meanR:19.1000 R:24.0 loss:3207.6340 exploreP:0.0106\n",
      "Episode:1619 meanR:19.2600 R:31.0 loss:3041.8618 exploreP:0.0106\n",
      "Episode:1620 meanR:19.5000 R:37.0 loss:4701.1582 exploreP:0.0106\n",
      "Episode:1621 meanR:19.8600 R:53.0 loss:11323.2109 exploreP:0.0106\n",
      "Episode:1622 meanR:20.7700 R:105.0 loss:22461.8164 exploreP:0.0106\n",
      "Episode:1623 meanR:20.7300 R:10.0 loss:15027.7373 exploreP:0.0106\n",
      "Episode:1624 meanR:20.6500 R:9.0 loss:15384.3018 exploreP:0.0106\n",
      "Episode:1625 meanR:20.6200 R:11.0 loss:7289.6216 exploreP:0.0106\n",
      "Episode:1626 meanR:20.4900 R:9.0 loss:7001.6929 exploreP:0.0106\n",
      "Episode:1627 meanR:20.0400 R:10.0 loss:13684.4736 exploreP:0.0106\n",
      "Episode:1628 meanR:19.1400 R:9.0 loss:10045.9639 exploreP:0.0106\n",
      "Episode:1629 meanR:19.0300 R:11.0 loss:7534.5396 exploreP:0.0106\n",
      "Episode:1630 meanR:18.9500 R:9.0 loss:9612.0352 exploreP:0.0106\n",
      "Episode:1631 meanR:18.9000 R:11.0 loss:10468.3896 exploreP:0.0106\n",
      "Episode:1632 meanR:18.8500 R:10.0 loss:12028.7568 exploreP:0.0106\n",
      "Episode:1633 meanR:18.8000 R:10.0 loss:7238.3369 exploreP:0.0106\n",
      "Episode:1634 meanR:18.8000 R:12.0 loss:7032.8188 exploreP:0.0106\n",
      "Episode:1635 meanR:18.7600 R:9.0 loss:9076.8477 exploreP:0.0106\n",
      "Episode:1636 meanR:18.7500 R:12.0 loss:7658.5005 exploreP:0.0106\n",
      "Episode:1637 meanR:18.7700 R:14.0 loss:9684.2754 exploreP:0.0106\n",
      "Episode:1638 meanR:18.8400 R:16.0 loss:7589.0620 exploreP:0.0106\n",
      "Episode:1639 meanR:18.9300 R:19.0 loss:7076.0386 exploreP:0.0106\n",
      "Episode:1640 meanR:19.7100 R:89.0 loss:3315.4023 exploreP:0.0105\n",
      "Episode:1641 meanR:19.7700 R:16.0 loss:2603.4661 exploreP:0.0105\n",
      "Episode:1642 meanR:19.8400 R:17.0 loss:2492.1360 exploreP:0.0105\n",
      "Episode:1643 meanR:19.9400 R:20.0 loss:2749.0295 exploreP:0.0105\n",
      "Episode:1644 meanR:20.0300 R:18.0 loss:2808.1436 exploreP:0.0105\n",
      "Episode:1645 meanR:20.0800 R:14.0 loss:4562.3086 exploreP:0.0105\n",
      "Episode:1646 meanR:20.1200 R:13.0 loss:4046.9441 exploreP:0.0105\n",
      "Episode:1647 meanR:20.2000 R:16.0 loss:3791.6621 exploreP:0.0105\n",
      "Episode:1648 meanR:20.2300 R:13.0 loss:3856.4653 exploreP:0.0105\n",
      "Episode:1649 meanR:20.2600 R:13.0 loss:5307.2661 exploreP:0.0105\n",
      "Episode:1650 meanR:20.2700 R:10.0 loss:5295.1997 exploreP:0.0105\n",
      "Episode:1651 meanR:20.2600 R:9.0 loss:4789.0156 exploreP:0.0105\n",
      "Episode:1652 meanR:20.2700 R:11.0 loss:3643.3430 exploreP:0.0105\n",
      "Episode:1653 meanR:20.2800 R:11.0 loss:3490.0298 exploreP:0.0105\n",
      "Episode:1654 meanR:20.2800 R:10.0 loss:3980.5884 exploreP:0.0105\n",
      "Episode:1655 meanR:20.2800 R:10.0 loss:3448.4480 exploreP:0.0105\n",
      "Episode:1656 meanR:20.3000 R:10.0 loss:2585.4929 exploreP:0.0105\n",
      "Episode:1657 meanR:20.3000 R:9.0 loss:2056.8032 exploreP:0.0105\n",
      "Episode:1658 meanR:20.2800 R:9.0 loss:1683.0511 exploreP:0.0105\n",
      "Episode:1659 meanR:20.2600 R:9.0 loss:1013.9893 exploreP:0.0105\n",
      "Episode:1660 meanR:20.2500 R:10.0 loss:1282.6024 exploreP:0.0105\n",
      "Episode:1661 meanR:20.2200 R:10.0 loss:779.3797 exploreP:0.0105\n",
      "Episode:1662 meanR:20.1800 R:8.0 loss:803.8586 exploreP:0.0105\n",
      "Episode:1663 meanR:20.1000 R:8.0 loss:688.8525 exploreP:0.0105\n",
      "Episode:1664 meanR:19.9900 R:10.0 loss:703.5915 exploreP:0.0105\n",
      "Episode:1665 meanR:19.7200 R:9.0 loss:919.7165 exploreP:0.0105\n",
      "Episode:1666 meanR:18.8900 R:8.0 loss:837.2714 exploreP:0.0105\n",
      "Episode:1667 meanR:18.4300 R:9.0 loss:488.2969 exploreP:0.0105\n",
      "Episode:1668 meanR:17.9200 R:10.0 loss:1744.6556 exploreP:0.0105\n",
      "Episode:1669 meanR:16.8700 R:11.0 loss:1526.9442 exploreP:0.0105\n",
      "Episode:1670 meanR:16.8700 R:11.0 loss:1899.0023 exploreP:0.0105\n",
      "Episode:1671 meanR:16.8400 R:10.0 loss:2486.4248 exploreP:0.0105\n",
      "Episode:1672 meanR:16.7800 R:9.0 loss:2546.1926 exploreP:0.0105\n",
      "Episode:1673 meanR:16.7300 R:9.0 loss:1325.3462 exploreP:0.0105\n",
      "Episode:1674 meanR:16.6900 R:9.0 loss:2004.0443 exploreP:0.0105\n",
      "Episode:1675 meanR:16.6400 R:8.0 loss:1694.9263 exploreP:0.0105\n",
      "Episode:1676 meanR:16.5900 R:10.0 loss:2573.8667 exploreP:0.0105\n",
      "Episode:1677 meanR:16.5100 R:10.0 loss:1972.6051 exploreP:0.0105\n",
      "Episode:1678 meanR:16.4100 R:9.0 loss:5051.1953 exploreP:0.0105\n",
      "Episode:1679 meanR:16.3600 R:10.0 loss:3148.2263 exploreP:0.0105\n",
      "Episode:1680 meanR:15.5400 R:9.0 loss:4203.9248 exploreP:0.0105\n",
      "Episode:1681 meanR:15.1000 R:8.0 loss:3936.5576 exploreP:0.0105\n",
      "Episode:1682 meanR:14.6600 R:9.0 loss:4074.1216 exploreP:0.0105\n",
      "Episode:1683 meanR:14.4100 R:9.0 loss:2059.2349 exploreP:0.0105\n",
      "Episode:1684 meanR:14.2900 R:11.0 loss:3811.2424 exploreP:0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1685 meanR:14.1700 R:10.0 loss:3727.3110 exploreP:0.0105\n",
      "Episode:1686 meanR:14.1000 R:10.0 loss:4695.0449 exploreP:0.0105\n",
      "Episode:1687 meanR:14.0300 R:8.0 loss:4425.9185 exploreP:0.0105\n",
      "Episode:1688 meanR:13.9600 R:9.0 loss:4722.1201 exploreP:0.0105\n",
      "Episode:1689 meanR:13.9000 R:9.0 loss:4841.4199 exploreP:0.0105\n",
      "Episode:1690 meanR:13.8400 R:9.0 loss:5843.0601 exploreP:0.0105\n",
      "Episode:1691 meanR:13.7800 R:9.0 loss:5869.7002 exploreP:0.0105\n",
      "Episode:1692 meanR:13.7300 R:10.0 loss:5495.0752 exploreP:0.0105\n",
      "Episode:1693 meanR:13.7000 R:10.0 loss:6889.4673 exploreP:0.0105\n",
      "Episode:1694 meanR:13.6800 R:11.0 loss:8495.0918 exploreP:0.0105\n",
      "Episode:1695 meanR:13.6500 R:9.0 loss:6679.8188 exploreP:0.0105\n",
      "Episode:1696 meanR:13.6400 R:10.0 loss:10713.9570 exploreP:0.0105\n",
      "Episode:1697 meanR:13.6200 R:10.0 loss:7826.0444 exploreP:0.0105\n",
      "Episode:1698 meanR:13.5900 R:8.0 loss:11743.1670 exploreP:0.0105\n",
      "Episode:1699 meanR:13.5800 R:11.0 loss:9501.1660 exploreP:0.0105\n",
      "Episode:1700 meanR:13.5700 R:9.0 loss:16698.0332 exploreP:0.0105\n",
      "Episode:1701 meanR:13.5700 R:10.0 loss:17615.7559 exploreP:0.0105\n",
      "Episode:1702 meanR:13.5500 R:9.0 loss:19673.4453 exploreP:0.0105\n",
      "Episode:1703 meanR:13.5400 R:10.0 loss:18747.5977 exploreP:0.0105\n",
      "Episode:1704 meanR:13.5200 R:9.0 loss:20158.8477 exploreP:0.0105\n",
      "Episode:1705 meanR:13.5400 R:11.0 loss:25276.3516 exploreP:0.0105\n",
      "Episode:1706 meanR:13.5400 R:9.0 loss:16820.0039 exploreP:0.0105\n",
      "Episode:1707 meanR:13.5200 R:8.0 loss:16500.7656 exploreP:0.0105\n",
      "Episode:1708 meanR:13.5100 R:8.0 loss:15354.6582 exploreP:0.0105\n",
      "Episode:1709 meanR:13.5100 R:10.0 loss:13722.0283 exploreP:0.0105\n",
      "Episode:1710 meanR:13.5000 R:10.0 loss:17062.5293 exploreP:0.0105\n",
      "Episode:1711 meanR:13.4900 R:10.0 loss:11743.1465 exploreP:0.0105\n",
      "Episode:1712 meanR:13.4700 R:9.0 loss:16368.2148 exploreP:0.0105\n",
      "Episode:1713 meanR:13.4200 R:8.0 loss:9878.0469 exploreP:0.0105\n",
      "Episode:1714 meanR:13.3500 R:9.0 loss:14381.1191 exploreP:0.0105\n",
      "Episode:1715 meanR:13.3000 R:12.0 loss:8982.7783 exploreP:0.0105\n",
      "Episode:1716 meanR:13.2200 R:9.0 loss:7579.3003 exploreP:0.0105\n",
      "Episode:1717 meanR:13.1400 R:9.0 loss:9225.1963 exploreP:0.0105\n",
      "Episode:1718 meanR:12.9900 R:9.0 loss:11584.1875 exploreP:0.0105\n",
      "Episode:1719 meanR:12.7800 R:10.0 loss:7946.1748 exploreP:0.0105\n",
      "Episode:1720 meanR:12.5100 R:10.0 loss:12354.1934 exploreP:0.0105\n",
      "Episode:1721 meanR:12.0800 R:10.0 loss:8075.8984 exploreP:0.0105\n",
      "Episode:1722 meanR:11.1300 R:10.0 loss:7944.3359 exploreP:0.0105\n",
      "Episode:1723 meanR:11.1300 R:10.0 loss:6984.4155 exploreP:0.0105\n",
      "Episode:1724 meanR:11.1300 R:9.0 loss:6654.6221 exploreP:0.0105\n",
      "Episode:1725 meanR:11.1100 R:9.0 loss:5515.8555 exploreP:0.0105\n",
      "Episode:1726 meanR:11.1200 R:10.0 loss:2692.1724 exploreP:0.0105\n",
      "Episode:1727 meanR:11.1700 R:15.0 loss:4762.5444 exploreP:0.0105\n",
      "Episode:1728 meanR:11.1900 R:11.0 loss:3949.2556 exploreP:0.0105\n",
      "Episode:1729 meanR:11.2600 R:18.0 loss:2187.4016 exploreP:0.0105\n",
      "Episode:1730 meanR:11.5100 R:34.0 loss:2071.7471 exploreP:0.0105\n",
      "Episode:1731 meanR:11.5500 R:15.0 loss:1932.2042 exploreP:0.0105\n",
      "Episode:1732 meanR:11.6800 R:23.0 loss:1887.7994 exploreP:0.0105\n",
      "Episode:1733 meanR:11.8600 R:28.0 loss:1875.6525 exploreP:0.0105\n",
      "Episode:1734 meanR:11.9300 R:19.0 loss:2493.6895 exploreP:0.0105\n",
      "Episode:1735 meanR:12.0500 R:21.0 loss:2462.6318 exploreP:0.0105\n",
      "Episode:1736 meanR:12.1500 R:22.0 loss:4700.9175 exploreP:0.0105\n",
      "Episode:1737 meanR:12.2300 R:22.0 loss:5718.9971 exploreP:0.0105\n",
      "Episode:1738 meanR:12.2600 R:19.0 loss:9272.4297 exploreP:0.0105\n",
      "Episode:1739 meanR:12.2300 R:16.0 loss:12711.7803 exploreP:0.0105\n",
      "Episode:1740 meanR:11.5000 R:16.0 loss:14392.2324 exploreP:0.0105\n",
      "Episode:1741 meanR:11.4800 R:14.0 loss:18927.5898 exploreP:0.0105\n",
      "Episode:1742 meanR:11.4100 R:10.0 loss:10964.2598 exploreP:0.0105\n",
      "Episode:1743 meanR:11.3200 R:11.0 loss:11782.8135 exploreP:0.0105\n",
      "Episode:1744 meanR:11.2500 R:11.0 loss:19725.3926 exploreP:0.0105\n",
      "Episode:1745 meanR:11.2100 R:10.0 loss:16564.0215 exploreP:0.0105\n",
      "Episode:1746 meanR:11.1900 R:11.0 loss:12913.9658 exploreP:0.0105\n",
      "Episode:1747 meanR:11.1400 R:11.0 loss:13716.3398 exploreP:0.0105\n",
      "Episode:1748 meanR:11.1100 R:10.0 loss:8703.0801 exploreP:0.0105\n",
      "Episode:1749 meanR:11.0900 R:11.0 loss:7004.9692 exploreP:0.0105\n",
      "Episode:1750 meanR:11.0900 R:10.0 loss:9353.9639 exploreP:0.0105\n",
      "Episode:1751 meanR:11.0900 R:9.0 loss:8594.8164 exploreP:0.0105\n",
      "Episode:1752 meanR:11.1000 R:12.0 loss:5137.6460 exploreP:0.0105\n",
      "Episode:1753 meanR:11.0900 R:10.0 loss:3904.9648 exploreP:0.0105\n",
      "Episode:1754 meanR:11.0800 R:9.0 loss:5249.5874 exploreP:0.0105\n",
      "Episode:1755 meanR:11.0600 R:8.0 loss:2726.0115 exploreP:0.0105\n",
      "Episode:1756 meanR:11.0500 R:9.0 loss:2997.3928 exploreP:0.0105\n",
      "Episode:1757 meanR:11.0600 R:10.0 loss:3218.0386 exploreP:0.0105\n",
      "Episode:1758 meanR:11.0700 R:10.0 loss:2411.5620 exploreP:0.0105\n",
      "Episode:1759 meanR:11.0700 R:9.0 loss:2487.1956 exploreP:0.0105\n",
      "Episode:1760 meanR:11.0700 R:10.0 loss:2578.0188 exploreP:0.0105\n",
      "Episode:1761 meanR:11.0600 R:9.0 loss:3292.6714 exploreP:0.0105\n",
      "Episode:1762 meanR:11.0700 R:9.0 loss:3595.0530 exploreP:0.0105\n",
      "Episode:1763 meanR:11.0900 R:10.0 loss:3751.1230 exploreP:0.0105\n",
      "Episode:1764 meanR:11.0800 R:9.0 loss:3579.7119 exploreP:0.0105\n",
      "Episode:1765 meanR:11.0900 R:10.0 loss:6159.6523 exploreP:0.0105\n",
      "Episode:1766 meanR:11.1000 R:9.0 loss:5871.0947 exploreP:0.0105\n",
      "Episode:1767 meanR:11.1100 R:10.0 loss:4887.6724 exploreP:0.0105\n",
      "Episode:1768 meanR:11.0900 R:8.0 loss:3320.3442 exploreP:0.0105\n",
      "Episode:1769 meanR:11.0700 R:9.0 loss:2374.8198 exploreP:0.0105\n",
      "Episode:1770 meanR:11.0600 R:10.0 loss:4525.2397 exploreP:0.0105\n",
      "Episode:1771 meanR:11.0600 R:10.0 loss:6395.9868 exploreP:0.0105\n",
      "Episode:1772 meanR:11.0600 R:9.0 loss:7067.9077 exploreP:0.0105\n",
      "Episode:1773 meanR:11.0500 R:8.0 loss:4384.0767 exploreP:0.0105\n",
      "Episode:1774 meanR:11.0500 R:9.0 loss:7732.2603 exploreP:0.0105\n",
      "Episode:1775 meanR:11.0600 R:9.0 loss:3891.6646 exploreP:0.0105\n",
      "Episode:1776 meanR:11.0500 R:9.0 loss:4067.2058 exploreP:0.0105\n",
      "Episode:1777 meanR:11.0500 R:10.0 loss:4699.8408 exploreP:0.0105\n",
      "Episode:1778 meanR:11.0500 R:9.0 loss:5920.2070 exploreP:0.0105\n",
      "Episode:1779 meanR:11.0400 R:9.0 loss:5638.8872 exploreP:0.0105\n",
      "Episode:1780 meanR:11.0600 R:11.0 loss:5966.7954 exploreP:0.0105\n",
      "Episode:1781 meanR:11.0800 R:10.0 loss:6002.9912 exploreP:0.0105\n",
      "Episode:1782 meanR:11.0800 R:9.0 loss:5469.3325 exploreP:0.0105\n",
      "Episode:1783 meanR:11.0900 R:10.0 loss:5341.0654 exploreP:0.0105\n",
      "Episode:1784 meanR:11.0700 R:9.0 loss:5578.5625 exploreP:0.0105\n",
      "Episode:1785 meanR:11.0600 R:9.0 loss:6753.4116 exploreP:0.0105\n",
      "Episode:1786 meanR:11.0600 R:10.0 loss:7330.5806 exploreP:0.0105\n",
      "Episode:1787 meanR:11.0700 R:9.0 loss:11781.3613 exploreP:0.0105\n",
      "Episode:1788 meanR:11.0800 R:10.0 loss:11237.9609 exploreP:0.0105\n",
      "Episode:1789 meanR:11.1100 R:12.0 loss:12059.5068 exploreP:0.0105\n",
      "Episode:1790 meanR:11.1200 R:10.0 loss:14664.3203 exploreP:0.0105\n",
      "Episode:1791 meanR:11.1200 R:9.0 loss:14822.4756 exploreP:0.0105\n",
      "Episode:1792 meanR:11.1200 R:10.0 loss:16930.4180 exploreP:0.0105\n",
      "Episode:1793 meanR:11.1200 R:10.0 loss:18606.3242 exploreP:0.0105\n",
      "Episode:1794 meanR:11.1000 R:9.0 loss:28318.3184 exploreP:0.0105\n",
      "Episode:1795 meanR:11.1000 R:9.0 loss:17872.3145 exploreP:0.0105\n",
      "Episode:1796 meanR:11.0800 R:8.0 loss:21985.3750 exploreP:0.0105\n",
      "Episode:1797 meanR:11.0800 R:10.0 loss:17512.1211 exploreP:0.0105\n",
      "Episode:1798 meanR:11.1000 R:10.0 loss:18575.2754 exploreP:0.0105\n",
      "Episode:1799 meanR:11.0900 R:10.0 loss:24596.1504 exploreP:0.0105\n",
      "Episode:1800 meanR:11.0900 R:9.0 loss:14971.6768 exploreP:0.0105\n",
      "Episode:1801 meanR:11.0800 R:9.0 loss:12338.8457 exploreP:0.0105\n",
      "Episode:1802 meanR:11.0700 R:8.0 loss:17116.5430 exploreP:0.0105\n",
      "Episode:1803 meanR:11.0700 R:10.0 loss:11656.9346 exploreP:0.0105\n",
      "Episode:1804 meanR:11.0800 R:10.0 loss:11548.9814 exploreP:0.0105\n",
      "Episode:1805 meanR:11.0700 R:10.0 loss:15579.4160 exploreP:0.0105\n",
      "Episode:1806 meanR:11.0700 R:9.0 loss:12838.2334 exploreP:0.0105\n",
      "Episode:1807 meanR:11.0900 R:10.0 loss:10176.5332 exploreP:0.0105\n",
      "Episode:1808 meanR:11.0900 R:8.0 loss:9274.3809 exploreP:0.0105\n",
      "Episode:1809 meanR:11.0900 R:10.0 loss:8189.6265 exploreP:0.0105\n",
      "Episode:1810 meanR:11.0700 R:8.0 loss:6628.4424 exploreP:0.0105\n",
      "Episode:1811 meanR:11.0600 R:9.0 loss:7422.7134 exploreP:0.0105\n",
      "Episode:1812 meanR:11.0700 R:10.0 loss:7480.3311 exploreP:0.0105\n",
      "Episode:1813 meanR:11.0700 R:8.0 loss:10830.7119 exploreP:0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1814 meanR:11.0700 R:9.0 loss:9132.3838 exploreP:0.0105\n",
      "Episode:1815 meanR:11.0400 R:9.0 loss:6770.0298 exploreP:0.0105\n",
      "Episode:1816 meanR:11.0400 R:9.0 loss:7337.2300 exploreP:0.0105\n",
      "Episode:1817 meanR:11.0500 R:10.0 loss:10832.1602 exploreP:0.0105\n",
      "Episode:1818 meanR:11.0600 R:10.0 loss:8762.6504 exploreP:0.0105\n",
      "Episode:1819 meanR:11.0400 R:8.0 loss:5011.9600 exploreP:0.0105\n",
      "Episode:1820 meanR:11.0400 R:10.0 loss:4466.6406 exploreP:0.0105\n",
      "Episode:1821 meanR:11.0400 R:10.0 loss:5573.6982 exploreP:0.0104\n",
      "Episode:1822 meanR:11.0400 R:10.0 loss:4550.0137 exploreP:0.0104\n",
      "Episode:1823 meanR:11.0300 R:9.0 loss:5719.7363 exploreP:0.0104\n",
      "Episode:1824 meanR:11.0300 R:9.0 loss:2275.5564 exploreP:0.0104\n",
      "Episode:1825 meanR:11.0300 R:9.0 loss:3758.8525 exploreP:0.0104\n",
      "Episode:1826 meanR:11.0300 R:10.0 loss:2266.6780 exploreP:0.0104\n",
      "Episode:1827 meanR:10.9700 R:9.0 loss:1399.9871 exploreP:0.0104\n",
      "Episode:1828 meanR:10.9600 R:10.0 loss:2266.5234 exploreP:0.0104\n",
      "Episode:1829 meanR:10.8800 R:10.0 loss:1708.5176 exploreP:0.0104\n",
      "Episode:1830 meanR:10.6300 R:9.0 loss:2319.6562 exploreP:0.0104\n",
      "Episode:1831 meanR:10.5600 R:8.0 loss:1337.6692 exploreP:0.0104\n",
      "Episode:1832 meanR:10.4300 R:10.0 loss:2569.8716 exploreP:0.0104\n",
      "Episode:1833 meanR:10.2500 R:10.0 loss:1541.2640 exploreP:0.0104\n",
      "Episode:1834 meanR:10.1500 R:9.0 loss:1195.0634 exploreP:0.0104\n",
      "Episode:1835 meanR:10.0300 R:9.0 loss:2417.4141 exploreP:0.0104\n",
      "Episode:1836 meanR:9.9000 R:9.0 loss:1597.9097 exploreP:0.0104\n",
      "Episode:1837 meanR:9.7700 R:9.0 loss:1927.5170 exploreP:0.0104\n",
      "Episode:1838 meanR:9.6700 R:9.0 loss:1791.5171 exploreP:0.0104\n",
      "Episode:1839 meanR:9.7300 R:22.0 loss:2395.8645 exploreP:0.0104\n",
      "Episode:1840 meanR:9.7600 R:19.0 loss:2689.9775 exploreP:0.0104\n",
      "Episode:1841 meanR:9.7800 R:16.0 loss:3057.8013 exploreP:0.0104\n",
      "Episode:1842 meanR:9.8400 R:16.0 loss:4204.3936 exploreP:0.0104\n",
      "Episode:1843 meanR:9.8900 R:16.0 loss:4924.0889 exploreP:0.0104\n",
      "Episode:1844 meanR:9.9000 R:12.0 loss:7457.2290 exploreP:0.0104\n",
      "Episode:1845 meanR:9.9500 R:15.0 loss:11445.2764 exploreP:0.0104\n",
      "Episode:1846 meanR:10.0000 R:16.0 loss:11250.8496 exploreP:0.0104\n",
      "Episode:1847 meanR:10.0300 R:14.0 loss:15467.0488 exploreP:0.0104\n",
      "Episode:1848 meanR:10.0600 R:13.0 loss:14736.7393 exploreP:0.0104\n",
      "Episode:1849 meanR:10.0700 R:12.0 loss:13825.8740 exploreP:0.0104\n",
      "Episode:1850 meanR:10.0700 R:10.0 loss:9670.3965 exploreP:0.0104\n",
      "Episode:1851 meanR:10.0900 R:11.0 loss:5890.5195 exploreP:0.0104\n",
      "Episode:1852 meanR:10.0900 R:12.0 loss:6932.2637 exploreP:0.0104\n",
      "Episode:1853 meanR:10.0900 R:10.0 loss:5382.7695 exploreP:0.0104\n",
      "Episode:1854 meanR:10.1000 R:10.0 loss:5723.5171 exploreP:0.0104\n",
      "Episode:1855 meanR:10.1200 R:10.0 loss:5687.9873 exploreP:0.0104\n",
      "Episode:1856 meanR:10.1200 R:9.0 loss:3884.0808 exploreP:0.0104\n",
      "Episode:1857 meanR:10.1200 R:10.0 loss:4505.4639 exploreP:0.0104\n",
      "Episode:1858 meanR:10.1200 R:10.0 loss:4011.7214 exploreP:0.0104\n",
      "Episode:1859 meanR:10.1300 R:10.0 loss:2979.4229 exploreP:0.0104\n",
      "Episode:1860 meanR:10.1200 R:9.0 loss:3318.5681 exploreP:0.0104\n",
      "Episode:1861 meanR:10.1200 R:9.0 loss:3603.1860 exploreP:0.0104\n",
      "Episode:1862 meanR:10.1300 R:10.0 loss:3742.1411 exploreP:0.0104\n",
      "Episode:1863 meanR:10.1200 R:9.0 loss:2960.3325 exploreP:0.0104\n",
      "Episode:1864 meanR:10.1200 R:9.0 loss:3484.8208 exploreP:0.0104\n",
      "Episode:1865 meanR:10.1200 R:10.0 loss:3586.0181 exploreP:0.0104\n",
      "Episode:1866 meanR:10.1300 R:10.0 loss:3372.8960 exploreP:0.0104\n",
      "Episode:1867 meanR:10.1100 R:8.0 loss:3280.4646 exploreP:0.0104\n",
      "Episode:1868 meanR:10.1200 R:9.0 loss:4818.4395 exploreP:0.0104\n",
      "Episode:1869 meanR:10.1500 R:12.0 loss:3811.0498 exploreP:0.0104\n",
      "Episode:1870 meanR:10.1500 R:10.0 loss:5026.0386 exploreP:0.0104\n",
      "Episode:1871 meanR:10.1500 R:10.0 loss:5910.7637 exploreP:0.0104\n",
      "Episode:1872 meanR:10.1600 R:10.0 loss:3544.7583 exploreP:0.0104\n",
      "Episode:1873 meanR:10.1600 R:8.0 loss:5419.2095 exploreP:0.0104\n",
      "Episode:1874 meanR:10.1500 R:8.0 loss:5689.8457 exploreP:0.0104\n",
      "Episode:1875 meanR:10.1600 R:10.0 loss:5317.7651 exploreP:0.0104\n",
      "Episode:1876 meanR:10.1600 R:9.0 loss:7869.8726 exploreP:0.0104\n",
      "Episode:1877 meanR:10.1500 R:9.0 loss:4171.8315 exploreP:0.0104\n",
      "Episode:1878 meanR:10.1500 R:9.0 loss:3871.4854 exploreP:0.0104\n",
      "Episode:1879 meanR:10.1600 R:10.0 loss:6119.2642 exploreP:0.0104\n",
      "Episode:1880 meanR:10.1400 R:9.0 loss:5261.7861 exploreP:0.0104\n",
      "Episode:1881 meanR:10.1200 R:8.0 loss:4573.7349 exploreP:0.0104\n",
      "Episode:1882 meanR:10.1300 R:10.0 loss:3794.4790 exploreP:0.0104\n",
      "Episode:1883 meanR:10.1200 R:9.0 loss:5873.4971 exploreP:0.0104\n",
      "Episode:1884 meanR:10.1300 R:10.0 loss:4990.5576 exploreP:0.0104\n",
      "Episode:1885 meanR:10.1200 R:8.0 loss:4911.1162 exploreP:0.0104\n",
      "Episode:1886 meanR:10.1200 R:10.0 loss:4561.0498 exploreP:0.0104\n",
      "Episode:1887 meanR:10.1300 R:10.0 loss:4761.5508 exploreP:0.0104\n",
      "Episode:1888 meanR:10.1300 R:10.0 loss:7598.9268 exploreP:0.0104\n",
      "Episode:1889 meanR:10.1000 R:9.0 loss:5485.8818 exploreP:0.0104\n",
      "Episode:1890 meanR:10.0800 R:8.0 loss:6109.0137 exploreP:0.0104\n",
      "Episode:1891 meanR:10.1000 R:11.0 loss:5635.1934 exploreP:0.0104\n",
      "Episode:1892 meanR:10.0900 R:9.0 loss:7047.2544 exploreP:0.0104\n",
      "Episode:1893 meanR:10.0800 R:9.0 loss:6023.7441 exploreP:0.0104\n",
      "Episode:1894 meanR:10.0800 R:9.0 loss:6964.0493 exploreP:0.0104\n",
      "Episode:1895 meanR:10.0800 R:9.0 loss:8451.5723 exploreP:0.0104\n",
      "Episode:1896 meanR:10.0900 R:9.0 loss:7208.2808 exploreP:0.0104\n",
      "Episode:1897 meanR:10.0700 R:8.0 loss:6571.7427 exploreP:0.0104\n",
      "Episode:1898 meanR:10.0700 R:10.0 loss:10142.6719 exploreP:0.0104\n",
      "Episode:1899 meanR:10.0600 R:9.0 loss:9481.6221 exploreP:0.0104\n",
      "Episode:1900 meanR:10.0600 R:9.0 loss:9105.3750 exploreP:0.0104\n",
      "Episode:1901 meanR:10.0700 R:10.0 loss:8422.2012 exploreP:0.0104\n",
      "Episode:1902 meanR:10.0900 R:10.0 loss:12821.5332 exploreP:0.0104\n",
      "Episode:1903 meanR:10.0800 R:9.0 loss:14678.5088 exploreP:0.0104\n",
      "Episode:1904 meanR:10.0800 R:10.0 loss:17499.9941 exploreP:0.0104\n",
      "Episode:1905 meanR:10.0800 R:10.0 loss:20225.9414 exploreP:0.0104\n",
      "Episode:1906 meanR:10.0700 R:8.0 loss:24951.6406 exploreP:0.0104\n",
      "Episode:1907 meanR:10.0700 R:10.0 loss:17030.1992 exploreP:0.0104\n",
      "Episode:1908 meanR:10.0900 R:10.0 loss:23125.8828 exploreP:0.0104\n",
      "Episode:1909 meanR:10.0800 R:9.0 loss:23796.7871 exploreP:0.0104\n",
      "Episode:1910 meanR:10.0800 R:8.0 loss:16913.2773 exploreP:0.0104\n",
      "Episode:1911 meanR:10.0700 R:8.0 loss:24611.3594 exploreP:0.0104\n",
      "Episode:1912 meanR:10.0600 R:9.0 loss:17806.1504 exploreP:0.0104\n",
      "Episode:1913 meanR:10.0700 R:9.0 loss:10823.8652 exploreP:0.0104\n",
      "Episode:1914 meanR:10.0800 R:10.0 loss:14697.4326 exploreP:0.0104\n",
      "Episode:1915 meanR:10.0900 R:10.0 loss:12899.6982 exploreP:0.0104\n",
      "Episode:1916 meanR:10.0900 R:9.0 loss:17109.0469 exploreP:0.0104\n",
      "Episode:1917 meanR:10.0700 R:8.0 loss:8166.5259 exploreP:0.0104\n",
      "Episode:1918 meanR:10.0700 R:10.0 loss:13487.1201 exploreP:0.0104\n",
      "Episode:1919 meanR:10.0800 R:9.0 loss:12484.0742 exploreP:0.0104\n",
      "Episode:1920 meanR:10.0700 R:9.0 loss:10865.9697 exploreP:0.0104\n",
      "Episode:1921 meanR:10.0500 R:8.0 loss:11725.9531 exploreP:0.0104\n",
      "Episode:1922 meanR:10.0500 R:10.0 loss:7397.1025 exploreP:0.0104\n",
      "Episode:1923 meanR:10.0600 R:10.0 loss:8844.7559 exploreP:0.0104\n",
      "Episode:1924 meanR:10.0600 R:9.0 loss:9543.8867 exploreP:0.0104\n",
      "Episode:1925 meanR:10.0700 R:10.0 loss:8931.8838 exploreP:0.0104\n",
      "Episode:1926 meanR:10.0600 R:9.0 loss:6893.3750 exploreP:0.0104\n",
      "Episode:1927 meanR:10.0500 R:8.0 loss:9094.6221 exploreP:0.0104\n",
      "Episode:1928 meanR:10.0400 R:9.0 loss:7932.4810 exploreP:0.0104\n",
      "Episode:1929 meanR:10.0300 R:9.0 loss:8197.7539 exploreP:0.0104\n",
      "Episode:1930 meanR:10.0200 R:8.0 loss:10028.4971 exploreP:0.0104\n",
      "Episode:1931 meanR:10.0300 R:9.0 loss:11218.7773 exploreP:0.0104\n",
      "Episode:1932 meanR:10.0200 R:9.0 loss:7295.2144 exploreP:0.0104\n",
      "Episode:1933 meanR:10.0200 R:10.0 loss:6227.3618 exploreP:0.0104\n",
      "Episode:1934 meanR:10.0300 R:10.0 loss:7527.9688 exploreP:0.0104\n",
      "Episode:1935 meanR:10.0400 R:10.0 loss:6821.0537 exploreP:0.0104\n",
      "Episode:1936 meanR:10.0400 R:9.0 loss:5985.2744 exploreP:0.0104\n",
      "Episode:1937 meanR:10.0300 R:8.0 loss:4797.3213 exploreP:0.0104\n",
      "Episode:1938 meanR:10.0200 R:8.0 loss:5851.1865 exploreP:0.0104\n",
      "Episode:1939 meanR:9.8900 R:9.0 loss:5795.1387 exploreP:0.0104\n",
      "Episode:1940 meanR:9.8200 R:12.0 loss:3428.5664 exploreP:0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1941 meanR:9.7600 R:10.0 loss:2136.6458 exploreP:0.0104\n",
      "Episode:1942 meanR:9.7100 R:11.0 loss:2564.5469 exploreP:0.0104\n",
      "Episode:1943 meanR:9.6500 R:10.0 loss:3889.8496 exploreP:0.0104\n",
      "Episode:1944 meanR:9.6200 R:9.0 loss:2783.4316 exploreP:0.0104\n",
      "Episode:1945 meanR:9.5600 R:9.0 loss:1600.2604 exploreP:0.0104\n",
      "Episode:1946 meanR:9.4900 R:9.0 loss:3785.9072 exploreP:0.0104\n",
      "Episode:1947 meanR:9.4300 R:8.0 loss:4234.0376 exploreP:0.0104\n",
      "Episode:1948 meanR:9.3800 R:8.0 loss:2943.8101 exploreP:0.0104\n",
      "Episode:1949 meanR:9.3600 R:10.0 loss:2677.5378 exploreP:0.0104\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = act(sess, state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            \n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            loss = learn(sess, memory, batch_size)\n",
    "            loss_batch.append(loss)\n",
    "            \n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcZGV97/HPr6p6n6Vn3xeGmWETGGBEUIICbiwCrkCMYMIVjdzcGGNu0Nxo9N7kmntjNCZGRfEGEqPihqi4IIsKyMCwDAwgzMLMdE/vS3V17dvv/lGnoR16emqGqa7qru/79epXnfPUqapv9dTUr5/nnPMcc3dEREQOFKp2ABERqU0qECIiMiEVCBERmZAKhIiITEgFQkREJqQCISIiE1KBEBGRCalAiIjIhFQgRERkQpFqB3g5Fi5c6GvXrq12DBGRaeWRRx4ZcPdFh9puWheItWvXsnXr1mrHEBGZVsxsbznbaYhJREQmpAIhIiITUoEQEZEJqUCIiMiEVCBERGRCFS0QZrbHzJ40s8fNbGvQNt/M7jSzHcHtvKDdzOzzZrbTzJ4ws9MrmU1ERCY3FT2I89x9k7tvDtZvAO5y9w3AXcE6wIXAhuDnOuCLU5BNREQOohrnQVwGvC5Yvhm4F/jLoP0WL10D9UEzazezZe7eXYWMIiJTKp/Pk0wmAYilcjzVNUIslSOTL5AvFCkWnULRKbhTKBR5zQkr2LR2cUUzVbpAOPBzM3Pgy+5+I7Bk7Evf3bvNbOwdrgA6xj22M2j7nQJhZtdR6mGwevXqCscXEam8TCZDZ2cn3cMJfvpUD/fvHCBf8Ekf09LcOO0LxGvcvSsoAnea2W8n2dYmaHvJbygoMjcCbN68efLfoIhIjXJ3CoUC8XicHfv2c/u2br7zTBIsxGWbjufiU5azaHYTLY0RGkJGOBwibEY4bDSEwzQ3hCuesaIFwt27gts+M/s+cCbQOzZ0ZGbLgL5g805g1biHrwS6KplPRKQaMpkM+/btI5cv8KNtXfzk6V6687N416vWcf1561kyp7naEYEKFggzawNC7j4aLL8R+BRwO3AN8Ong9gfBQ24H/quZfRN4FTCi/Q8iMtMkk0k6OzvJFYr846+6ue/5GG865Ti+9sbjOGZhW7Xj/Y5K9iCWAN83s7HX+U93/6mZPQzcambXAvuAdwbb3wFcBOwEksAfVjCbiMiUKxQKdHV1YWb8+xOj3PV8kr976+n8/qtqc39qxQqEu+8GTp2gfRC4YIJ2B66vVB4RkWqLRqMUCgU6sq1887E+3v/adTVbHEBnUouITIliscjw8DDW0MzHf/Qc6xfP4s9ev7HasSY1ra8HISIyXYz1Hr79VJzuWJrv/fGrp+RIpJdDPQgRkQob6z3EciFufqiLd56xktNWz6t2rENSD0JEpML6+/vJ5/P826PDREIh/vyNx1U7UlnUgxARqaBUKkU0GqUrGeLHTw/ygdceWzPnORyKCoSISIW4Oz09PYTDEf7p/h6WzGnifeceU+1YZVOBEBGpkKGhIbLZLI/0FXm8M8ZfvOl4Whunz8i+CoSISAW4O8PDw4Qam/mHe/ayaVU7bzttRbVjHZbpU8pERKaR0dFRCoUC3316lP7RDF+9ejOh0ERzktYu9SBERI6yXC5Hb28vA8kC/29LF+/avJJTV7VXO9ZhU4EQETnKuru7yeYK/PP9PTRHIvzFm46vdqQjoiEmEZGjKJFIkEwm+Y8nojzYmeKfrzqNRbObqh3riKhAiIgcBYVCgWQyydDQEL/cOcQ3Hh/ig69bz1tOXV7taEdMBUJE5CgYGBggGo3y255RvvBAHxccv4KPTJMzpg9G+yBERF6mTCZDNBolG2rkU/cOsGhBO5+9ctO0O2rpQOpBiIi8DOl0mr179+LufPquTlIFuPXqzcxpbqh2tJdNPQgRkZdhaGiIcDjM7nQL9++J8VcXn8Cxi2ZVO9ZRoQIhInKECoUC8XicOXPm8IVf7WPNglau2Lyq2rGOGhUIEZEjFIvFcHce68nwVFeMPzl/A5HwzPlanTnvRERkisViMZqbm7l5y36Wz23msk3T95DWiahAiIgcgUwmQzqdpj8T4oFdg7zn7LU0zKDeA6hAiIgckZGREcyMbz8+SHNDiKvOnDn7HsaoQIiIHCZ3Z3R0lHyoke8/0c1bT1tJe2tjtWMddToPQkTkMCUSCfL5PHfsjJPNF7n2nLXVjlQR6kGIiBymkZERYukCNz3YxYWvWMr6xbOrHakiVCBERA5DKpViJDbK5+/vouDw0QtPqHakitEQk4jIIYwdsZTL5Xjouf18Y8se7usN85l3bWL1gtZqx6sYFQgRkYMoFosMDQ0xODjIQDzDF+7Zxb6hJLTM5V9+/wwuPmVZtSNWlAqEiMhB9PX1MTIyQjEU4a/u3MtQuoWPXn4Gl21aTmvjzP/6nPnvUETkCBQKBWKxGO3t7Xzu/j72jeT49gfO5ow186sdbcpoJ7WIyATi8XjpfIdiA7du7eA9Z62pq+IAU1AgzCxsZo+Z2Y+C9WPMbIuZ7TCzb5lZY9DeFKzvDO5fW+lsIiIHMzo6SmNjI197cD9hM/74deurHWnKTUUP4k+BZ8at/z3wWXffAAwD1wbt1wLD7r4e+GywnYjIlMvn8ySTSQrhZr6ztZN3bF7J0rnN1Y415SpaIMxsJXAx8NVg3YDzge8Em9wMXB4sXxasE9x/QbC9iMiUGh0dxd359Z442UKRq89eU+1IVVHpHsTngP8OFIP1BUDU3fPBeiewIlheAXQABPePBNuLiEyp0dFRmpqauO3JPk5YNofjl86pdqSqqFiBMLNLgD53f2R88wSbehn3jX/e68xsq5lt7e/vPwpJRURelMvlSKVSRPNhtnVEefvpKw79oBmqkj2I1wCXmtke4JuUhpY+B7Sb2djhtSuBrmC5E1gFENw/Fxg68End/UZ33+zumxctWlTB+CJSj2KxGAB37RwlZHDpqTPrIkCHo2IFwt0/6u4r3X0tcCVwt7u/G7gHeEew2TXAD4Ll24N1gvvvdveX9CBERCpp7CpxP36qj1cds4DFc+pv5/SYapwH8ZfAh81sJ6V9DDcF7TcBC4L2DwM3VCGbiNSxTCZDNpulPxNmd39ixk+lcShTcia1u98L3Bss7wbOnGCbNPDOqcgjIjKRWCyGmXH3rhHCIePCVyytdqSq0pnUIiK8eJW4lpYWfry9j1cfu4AFs5qqHauqVCBEROCF6by7kyH2Dia5+OT6Hl4CFQgREaA0vBQKhfjFriiRkPHmOh9eAhUIEZEXhpfa2tq448leztmwkPbWxmrHqjoVCBGpe8lkkkKhwN5Ykc7hFJecUr/nPoynAiEidS8WixEOh7lzxwiN4RBvOHFJtSPVBBUIEalr7k4ikaC1tY2fbO/h3I0LmdvSUO1YNUEFQkTq2tjw0u6RPN0jaQ0vjaMCISJ1LR6Pl45eem6ExkiI12t46QUqECJSt9ydeDxOc0srd2zv4bzjFjGraUommJgW9JsQkbqVTqfJ5/N0pPL0jWY0vHQA9SBEpG7F43HMjF/siNLcEOKCExZXO1JNUYEQkboVj8dpamrmJ9v7uOD4JbQ2alBlPP02RKQujU3t3ZFqYDCR5ZI6n9p7IupBiEhdisfjAPz02ShtjWHOO17DSwdSgRCRuhSPxymGG/jx9j4u3bSc5oZwtSPVHA0xiUjdyWazpNNptnRlSeUKXPHK1dWOVJPUgxCRuhONRjEzvr99iOOXzubUlXOrHakmqUCISF0Zm9q7N+Vs2x/nileuwsyqHasmqUCISF1JpVLk83l+sSNGYyTEW09bUe1INUsFQkTqRiaToauri4Ib398+yJtPWqoLA03ikAXCzN5mZrOD5RvM7FYz21T5aCIiR1d/fz+FQoFH+iGWLnDVmdo5PZlyehB/4+6jZvZq4C3At4AvVTaWiMjRVSgUSCaTtM+bz9e2dHHKyrmctW5+tWPVtHIKRCG4vQT4V3f/LtBUuUgiIkdfIpHA3Xm4M8HzAwnef+6x2jl9COWcB9FtZl8A3gxsNrNGtO9CRKaZeDxOOBzmKw90snp+K29+xdJqR6p55XzRvwv4JXCxuw8DC4EbKppKROQoGrus6PPRAts6R3jfuesIh9R7OJSD9iDMbM641Z+Oa4sD91c4l4jIUROLxSgWi3xrWz8L2hp55xkrqx1pWphsiOkpwAEDlgOjwfIsYD+g3f8iUvNyuRx9fX3sj+X4xY4RPvyGjZp3qUwHHWJy91Xuvhr4IfBWd29397nA5ZSOZBIRqWnuTkdHB5lcnn+9v4uFsxq55uy11Y41bZSzD+JMd799bMXdfwicV7lIIiIvn7uTyWRIZ7J88cF+tvbk+J+XvYK5rQ3VjjZtlHMU05CZ3QD8B6Uhpz8AhiuaSkTkZejt7SUajVIoOl/59fPcsTvPxy95BReerIsCHY5yCsTvA58EfkKpQPwKuKqSoUREjlQ8HicajdIVTXHj/ft4sj/PX128iT8655hqR5t2Ji0QZhYGPuLu1x/uE5tZM6Vi0hS8znfc/RNmdgzwTWA+8CjwHnfPmlkTcAtwBjAIXOHuew73dUWkPhWLRTKZDL29vdz73ACf2TLC7KYW/uHdJ+uchyM0aYFw94KZnXmEz50Bznf3uJk1APeZ2U+ADwOfdfdvmtmXgGuBLwa3w+6+3syuBP4euOIIX1tE6khPTw8jIyN0RVP8cFsX9zyf4NUb1/AP7zyVhbM08cORKmeI6VEz+x7wbSAx1jh+x/VE3N0pnTMB0BD8OHA+pWErgJuBv6FUIC4LlgG+A/yLmVnwPCIiv6NYLJJMJkmn0/x2Xw/feaSTLR0JUuE2rj3/FP70go2EdDLcy1JOgVhCqTBcNK7NgUkLBLwwRPUIsB74ArALiLp7PtikExibjH0F0AHg7nkzGwEWAANlZBSROlIoFOjo6KBvOM4vftvLz5/pYzTczu+/bhPvffVaFqjXcFQcskC4+3uO9MndvQBsMrN24PvACRNtFtxOVOpf0nsws+uA6wBWr9a5eiL1Ip/PMzIyQj6fp7t/iNse28/tvx0lXTTOP3EdH7/sVBbPaa52zBnlkAUi2Hn8XuAk4IXfvrtfV+6LuHvUzO4FzgLazSwS9CJWAl3BZp3AKqDTzCLAXGBogue6EbgRYPPmzRp+EqkD7s6ePXsoFAo81zPKV+/bzc54A2/ZfCwfeO2xrF3YVu2IM1I5J8rdAqylNN33FuBYIH2oB5nZoqDngJm1AK8HngHuAd4RbHYN8INg+fZgneD+u7X/QUQARkdHKRQKbO3J81c/6yDZOI+vf/A8Pv32U1QcKqicfRAb3f0KM7vY3W8ys1uAn5XxuGXAzcF+iBBwq7v/yMyeBr5pZv8LeAy4Kdj+JuDfzWwnpZ7DlYf9bkRkxonFYvT19TGcLvLJO/ey+ZhlfPk9ZzC7WWdEV1o5BSIX3EbN7ASgF1hzqAe5+xPAaRO07wZecuisu6eBd5aRR0TqRCqVoru7m+bmZm56dIBIKMRnr9ik4jBFyhliusnM5gGfoNRzeA74TEVTiYhQOivazNibbubOZwf5r+evZ4l2RE+Zco5i+nKweA+a4ltEplA8Hqe5uZnP/HAnK9pbuFbTZUypco5ieg74DfBr4Ffu/lzFU4lI3ctms2SzWXaNhtjWEeXTbzuZpoiu4zCVyhli2kTpjOcVlM5u3mVm365sLBGpZ+7OwMAA7s6XHtjP6vmtvF1XgZty5RSIDKWrySWAFKUzm2OVDCUi9S0ajTI6OsqzUXiiK8F/u2ADDeFyvq7kaCrnKKYRSpcf/RzwPnfvq2wkEal38XichoZGvvJwJ2sWtHL5puXVjlSXyinJ1wAPAB8EbjGzvzaz11Y2lojUq3w+TyqV4u5dMbbvj/Gh128got5DVZRzFNN3ge+a2XrgYkrTdf8PStd5EBE5qvr7++kfzfD5X3dy7sZFXL5pxaEfJBVxyLJsZt8ysx3Al4F5wB8FtyIiR42709XVxXB0hH95oAe3CP/7bSdjpim7q6WcfRCfAx4eN0W3iMhRVSwW6e7uJh6P85Nno/xmf4Z/uvI0VrS3VDtaXStnYO9x4CNm9kUAM1tvZhdWNpaI1JOBgQHi8ThDhWb+9aEhLtu0gss0tFR15RSIrwXb/V6w3gX8XcUSiUhdyefzRKNR5s6dyz/d18W81kY+dekrqh1LKK9AbHD3vyOYtM/dk0x8cR8RkcM2PDwMwO4YPLh7iOvPO5a5rZqMrxaUUyCyZtZMcHU3MzsGyFY0lYjUhWKxSDQaZfbs2Xz94S7mtTZw1Zma8q1WlLOT+lPAT4GVZnYz8Frg2oqmEpG6kEwmKRaLFMLN/PzpHq4+ey3NDZpvqVZMWiCsdHzZNkrXaXg1paGlv9DZ1CJyNCSTSUKhEHfvjJIrOO/avKrakWScSQuEu7uZ/cjdz+DFS4OKiBwViUSClpYW7nxmP+sWtXHc0tnVjiTjlLMP4iEzO73iSUSkruRyObLZLMVwI7/ZNcgbT1xa7UhygHL2QZwDvM/MdlGa0dUodS5UNETkiCUSCQAe7kyQLzpvPGlJlRPJgcopEJdXPIWI1J1kMkkkEuGu54ZYNLuJTSvbqx1JDlDOZH27piKIiNQPdyeZTNLY3Mq9z+7g8tNWEArp9Kpaozl0RWTKpdNpCoUCT/enSWYLvPFEDS/VIhUIEZlyiUQCM+OenTFmN0V49bELqx1JJqACISJTLh6P09jYxC9+289rj1tEY0RfRbXooPsgzGyYYHqNA++idBTT/IqlEpEZK5vNkslk2D0aYjCR5ZJTdDnRWjXZTmr1+UTkqBsaGiIUCvHzHTHmNEc47/hF1Y4kB3HQAuHuhfHrZjYfaB7X1FWpUCIycyWTSfKhRu54qo+3n7GSpojmXqpV5Vxy9GIzew7oBLYEt3dXOpiIzDzZbJZcLsedzw2TyRe55uy11Y4kkyhnz9DfAq8BnnX3VcCbgHsrGUpEZqZEIkE8k+ffHurm3I2LNPdSjSunQOTdvR8ImZm5+52AptkQkcOSSqUYGBjg9if7iaaLfOyi46sdSQ6hnKk2RsysDbgPuMXM+oBiZWOJyEySTqfZv38/9+8e5uvbR3n3q47h+KVzqh1LDqGcHsTlQBr4EKWhpf3AJRXMJCIzSCKRoKOjg1/vHORv7+3hrGMX87GLTqh2LClDOQXio+5ecPecu9/k7v8IfPhQDzKzVWZ2j5k9Y2ZPmdmfBu3zzexOM9sR3M4L2s3MPm9mO83sCU0xLjL9jY6Osn//fu7bNcz/+mUfZ61fwlev2UxLo45cmg7KKRBvnqDt4jIelwf+3N1PAM4CrjezE4EbgLvcfQNwV7AOcCGwIfi5DvhiGa8hIjUqHo/T3d3Nfc+P8Kl7e3nNhiV85erNuqToNDLZmdTvBz4AbDSzR8fdNRvYeqgndvduoDtYHjWzZ4AVwGXA64LNbqY0bPWXQfst7u7Ag2bWbmbLgucRkWkkkUiwf/9+fvHsEP/wwADnblzCl99zhorDNDPZTupbKf2F/7958a98gNHDvSa1ma0FTqN0HsWSsS99d+82s8XBZiuAjnEP6wzaVCBEppFYLEbH/i5u2bKfb/82yZtOWs7nrtyk4jANTXYm9TAwDLzTzF5B6cpyAL8Gyi4QZjYL+C7wIXePmR10zveJ7njJXFBmdh2lIShWr15dbgwRqbB0Os3AwADdg1H++Zf7+HVXkT+54Dg+dMEGXethmirnTOrrKfUmVgc/t5rZB8t5cjNroFQcvu7u3wuae81sWXD/Ml4sNp3AqnEPX8kE03m4+43uvtndNy9apDlcRGpBOp1m37599EVH+fhP9/JQH3z+qtP58Bs2qjhMY+XspH4/cKa7f8zdPwa8itK+iUlZqatwE/BMcOTTmNuBa4Lla4AfjGu/Ojia6SxgRPsfRGrf6OgonZ2dFDE+/eshdo+G+Pr7zuItp2qW1umunBPlDMiNW88x8XDQgV4DvAd40sweD9o+BnyaUi/kWmAf8M7gvjuAi4CdQBL4wzJeQ0SqyN3p7e0lHA7zlUeGeWhvlM9fdRpnrNHVAGaCyY5iirh7Hvh3SkcVfTe4662Ujj6alLvfx8ELyQUTbO/A9YdMLCI1I5PJUCgUuHtPhm891s2fnL+eS9VzmDEm60E8BJzu7v/HzO4Bfo/SF/4H3P3hKUknIjUrnU7T0dFB90iK/3t3J286aSl/9vqN1Y4lR9FkBeKFv/6DgqCiICJAqeewb98+3J1vbBumuaGBv3vrydohPcNMViAWmdlBp9Q4YMeziNSRnp4ezIxen8PPdu3khguPZ8GspmrHkqNssgIRBmZR3g5pEakT2WyWdDrNwoWL+NDXn2JFewvvffXaaseSCpisQHS7+6emLImITAupVAqAx7pSPNUV47NXnKqzpGeoyc6DUM9BRF4imUwSiUS47cle5rU2cPHJOmppppqsQLzkUFQRqW+pVIrR0VE80sidT/dyySnLaYyUc76tTEcH/Zd196GpDCIitW9wcJBwOMwjvQUy+SJvPX1FtSNJBan0i0hZ3J1kMsns2bO57fEejlnYxmmr2qsdSypIBUJEypJOp3F3YjnjwecHuXzTCiaZnVlmABUIESlLMpkE4GfPDuEOl5+mndMznQqEiJQllUrR2NjIbY/3cMaaeaxZ0FbtSFJhKhAickjFYpFUKkVXvMiOvjhvPU07p+tBOdN9i0idGx4eplgscteuBA1h45JTllU7kkwB9SBE5JASiQQNjU3cvn2A845bTHtrY7UjyRRQD0JEJjU4OEgqlWL3aIiBeIa36dyHuqEehIgclLszNDRES0sLP9sxytyWBs47fnG1Y8kUUYEQkYPKZrMUi0UaW2bxs6f7uPiUZTRFNDFfvVCBEJGDSiQSAPxm3yipXIHLdDnRuqICISIHlUgkaGpq4sfb+1g2t5lXrp1f7UgyhVQgRGRChUKBVCqFh5v45XP9XHLKMl1StM6oQIjIhJLJJO7Ob/bFyRWct2h4qe6oQIjIhOLxOOFwmDueHmTNglZOXjG32pFkiqlAiMhLuDuJRIIsDTywe5BLT12umVvrkE6UE5GXSKfTFAoF7uvIUHS4VMNLdUk9CBF5iUQigZlx+1MDnLxiLhuWzK52JKkCFQgR+R35fJ5oNEpvssD27rim1qhjKhAi8juGh4cpFArctStJJGQaXqpjKhAi8gJ3Z2RkhJQ38J+P9XH5aStYMKup2rGkSrSTWkReEI/HKRQK/OfjQ+DwZ2/YWO1IUkXqQYjIC4aHh+mL5/jOtj7ec/YaVrS3VDuSVJEKhIgAMDAwQCqV4htPDNPa2MD1562vdiSpsooVCDP7mpn1mdn2cW3zzexOM9sR3M4L2s3MPm9mO83sCTM7vVK5ROSlUqkUg4ODdMTy3PHsCNedu475bbpqXL2rZA/i34A3H9B2A3CXu28A7grWAS4ENgQ/1wFfrGAuERmnWCzS19dHOBzmq4+OsHBWE9eec0y1Y0kNqFiBcPdfAUMHNF8G3Bws3wxcPq79Fi95EGg3M10VXWQKDA8Pk06neT4R4cHnh/mT8zfQ1qTjV2Tq90EscfdugOB27NqFK4COcdt1Bm0vYWbXmdlWM9va399f0bAiM527E41GaW1t5Z9+1cHKeS1cdebqaseSGlErO6knmgXMJ9rQ3W90983uvnnRokUVjiUysyWTSfL5PA91Z9m+P8afv3EjjZFa+VqQapvqT0Lv2NBRcNsXtHcCq8ZttxLomuJsInUnkUiQKzif+cXznLR8Dpeeqmk15EVTXSBuB64Jlq8BfjCu/ergaKazgJGxoSgRqYxkMkk0GuUnz0bpimX4xFtOIqwrxsk4FdsTZWbfAF4HLDSzTuATwKeBW83sWmAf8M5g8zuAi4CdQBL4w0rlEpHS5UR7enqIpovc9Mggbzl1OWceo+tNy++qWIFw96sOctcFE2zrwPWVyiIiL3J3enp6yGSzfGFLP1iIGy48vtqxpAbpWDaROjM8PEw8Hud7z4zyy10xPv22kzWlhkxIhyuI1JFMJsPg4CD37orxlS19XH32Gq7UYa1yEOpBiNSJaDRKX18fD+we5v/+upc3nricj19yYrVjSQ1TgRCpA7FYjP1dPXx7Wx//vi3KmesW8/mrTiMS1iCCHJwKhMgMlk6nGRgY4KEd3dz6WC9b+uC9rzmWj154gk6Ik0NSgRCZgXK5HENDQ2z5bQfff7ybx3oytM1u5wvvPomLTtY0Z1IeFQiRGSSbzTIwMMDju3u47bFOtnZlaGyby4cvPZkrXrmKpki42hFlGlGBEJkBMpkMfX19PNMxwPcf388DHWmaWmbxwYtewR+ctYbmBhUGOXwqECLTWDKZZGRkhKf39XLbY938cm+SSHMr73/TJq45e62m7ZaXRZ8ekWlobOfzzq4BfrCtm/ufj5FpmMO1F5zCH52zltnNDdWOKDOACoTINFIsFhkYGODZfT388Ikefr5zlFyklfe+9lTe93vraG/VZULl6FGBEJkG0uk0Q0NDbN3ZzS+e7uH+fUmS4Vbec86JvP/cdSyY1VTtiDIDqUCI1Kixq70NDw/zyJ4Bbt/WzVN9WSLNbbzr3JP5w1evZfGc5mrHlBlMBUKkBqVSKfr6+ugdGuWrD+7nwX1x5s5t5yOXb+Btp6/QUUkyJVQgRGpMPB5n//79PNoR458f6GUoF+aGS07n3WetoUFTY8gUUoEQqRHFYpH+gUEe2dHJbdt6uHNfgZNWzOWWKzaxfvHsaseTOqQCITKFstks2VyeaDLLQCzFnr4onf0jdA/H6Ykm2DuYJJoLkWuczV9fchJXn71GE+pJ1ahAiBxl6XSaWCJJ13CK3V39dA3G6Ivn6ImlGYilGExkKRYdAAeyRGhpamTp/FmcffJyTj92GW84aSmzdJKbVJk+gSJHwN0pFAoMjcR4ak8fO3tH2D+coieaoGckyWAiCw55QmQ8QltTmOXtLaxavpSzFsxiQVsT82c1s2bxXNYtmqXzF6QmqUCIHIK7k81mSafTPN87wva9vezsibK7P0HHUJJU0ch7iOaGMMvmtbEBzei3AAALvklEQVR25TJ+b/E81sxv4Zgl7axbOIv21gbMrNpvReSwqECITKBYLJJMJukbHOLhHd1s64iyrXOEWCpHljBEmli/dC5veOVaNq1bwikr57KivUVFQGYUFQipa+5OLpcjlkjSOZSgazhJ50CMrv5hdvfHeX4wRbwYIdLYzKvWr+Ws9Ys4fc0CNi6ZpZ3HMuOpQEhdyOfzpWsljKbZ2RPl+d4ROgdH6BocpWckxVAi98K2RYxCuJljli3gknM2cs6Gxbxy7XxdgU3qjgqEzBjuTj6fJ51Os39wlOe6h9nbO0z3cIKukTTdIymSmQIABYxwpIGl82azbvUCzl88l9ULZ7Fy/izWLpzFwlmNGi6SuqcCIdNWoVAgl8vR0TvEU/v62NU7wvP9cfYMJBhJ5XAg5Q3Mamli1YI2zjhhOesWzWbd0rkct6ydZXOaCYVUBEQORgVCpoWxI4m6BmM8uaePHV2D7BkYZe9gguFEjgxhch5m6fzZnHDsWk5atYCTV7azYfFs5rXpEFKRI6ECQekC7x0dHUQaGtk5nGdX9xCjmSJzZ7WysL2N5kiIpnCIhpCTyeUZTeeJjiaJJVPEEimGE1mG0wXyboARDkEoFCEUDhE2I2RGOAxhK90XNgiHwoRCRiQUImROJBSiIRKiIRymIRKmIRKiMRKmMRKiqSFSuo2EaIpEaGoM09wQpqWxkebGCC1NEVoawrQ2RgjPgL+Ii8UiiUSCvX1RdvXG2Nk7yu7eYToGRhlOlnoGGSIsmjeHjWtWcdLKBZy8egEnLZ+jC+WIHEV1WSAymQzxeJz29nb279/P9n393LdjgMc6osTT+bKewymdBGWhCO1tTcxvDdNgYDiFAuSKabzoFNwpFosU3Sk6FIpQcCgUHfcixaK/sJ4vFktPfASKGA6Ew2GaImEaGyI0N4RLBaQxMu62gaZImKZIiOaGEI2REGZGsVCg6EXcoQjghrtTtBDhUIiGsBHCaQiXxu7BKRY9yF96bz72HseWi8F7f+H9O14s3RaKY9sXKBYKpDI54ukcyUyWVCZHLJ0nmS1QIIRjLG1v5dg1Kzlh5QJOWb2AV6xs15nGIhVWl//DEokEAwMDDAwMALCjP8Udz+c494SNvGHjPDatbmfx3Db6o3H6R1Nk8062UCRbgMaGCHNbGpg/u4V5bU20NoYn3Znp7mXfXywWyRWKZHJ5srkC6XyBbK5IJp8nnSuSzhXI5AtkcgUy2TyZXK60nMuTzuVJZ/Oks4VxyznSuQLpTIrR0dJzZgpFcvkimcLvFiN/4bZUCI4mMwiZYRYsY5gZFir1uCwUoqmhgdbmBtpa2pg/r5ETZrWxfvl8Tlw+lxOWzVExEKkCcz+6XwZTafPmzb5169YjemwikSAWi9Hc3ExD62wiIauLOfbz+Rd7SNlCkXSuCEAkXOophMwAf+FL3YtFcoUC2VwBQmGy+SK5fD74wjciISMU/BilYTRwwiGjIRwO7iv1UnRUkEhtMLNH3H3zobar2z/L2traaGtrq3aMKReJRMYtQ+shr1QZpokGaKloLBGpQTrzR0REJlRTBcLM3mxmz5rZTjO7odp5RETqWc0UCDMLA18ALgROBK4ysxOrm0pEpH7VTIEAzgR2uvtud88C3wQuq3ImEZG6VUsFYgXQMW69M2j7HWZ2nZltNbOt/f39UxZORKTe1FKBmOgYyJccg+vuN7r7ZnffvGjRoimIJSJSn2qpQHQCq8atrwS6qpRFRKTu1VKBeBjYYGbHmFkjcCVwe5UziYjUrZo6k9rMLgI+B4SBr7n73x5i+35g7xG+3EJg4AgfWw3KW1nKW1nKW1mHm3eNux9yjL6mCsRUMrOt5ZxqXiuUt7KUt7KUt7IqlbeWhphERKSGqECIiMiE6rlA3FjtAIdJeStLeStLeSurInnrdh+EiIhMrp57ECIiMom6LBC1OGusmX3NzPrMbPu4tvlmdqeZ7Qhu5wXtZmafD/I/YWanVyHvKjO7x8yeMbOnzOxPazmzmTWb2UNmti3I+8mg/Rgz2xLk/VZwDg5m1hSs7wzuXzuVeYMMYTN7zMx+VOtZgxx7zOxJM3vczLYGbTX5eQgytJvZd8zst8Hn+OxazWtmxwW/17GfmJl9qOJ53b2ufiidY7ELWAc0AtuAE2sg17nA6cD2cW3/B7ghWL4B+Ptg+SLgJ5SmJzkL2FKFvMuA04Pl2cBzlGbhrcnMwevOCpYbgC1BjluBK4P2LwF/HCx/EPhSsHwl8K0q/I4/DPwn8KNgvWazBq+9B1h4QFtNfh6CDDcD/yVYbgTaaznvuNxhoAdYU+m8VXmD1fwBzgZ+Nm79o8BHq50ryLL2gALxLLAsWF4GPBssfxm4aqLtqpj9B8AbpkNmoBV4FHgVpZOLIgd+NoCfAWcHy5FgO5vCjCuBu4DzgR8F/9FrMuu4zBMViJr8PABzgOcP/D3Vat4DMr4RuH8q8tbjEFNZs8bWiCXu3g0Q3C4O2mvqPQRDGqdR+qu8ZjMHQzaPA33AnZR6klF3H7tQ9/hML+QN7h8BFkxh3M8B/x0oBusLqN2sYxz4uZk9YmbXBW21+nlYB/QD/y8YxvuqmbXVcN7xrgS+ESxXNG89FoiyZo2tcTXzHsxsFvBd4EPuHpts0wnapjSzuxfcfROlv87PBE6YJFPV8prZJUCfuz8yvnmSPFX/3QZe4+6nU7ro1/Vmdu4k21Y7c4TSkO4X3f00IEFpiOZgqp23FKK03+lS4NuH2nSCtsPOW48FYjrNGttrZssAgtu+oL0m3oOZNVAqDl939+8FzTWdGcDdo8C9lMZm280sMkGmF/IG988FhqYo4muAS81sD6ULZ51PqUdRi1lf4O5dwW0f8H1KRbhWPw+dQKe7bwnWv0OpYNRq3jEXAo+6e2+wXtG89VggptOssbcD1wTL11Aa5x9rvzo4UuEsYGSsmzlVzMyAm4Bn3P0fx91Vk5nNbJGZtQfLLcDrgWeAe4B3HCTv2Pt4B3C3B4O5lebuH3X3le6+ltLn8253f3ctZh1jZm1mNntsmdI4+XZq9PPg7j1Ah5kdFzRdADxdq3nHuYoXh5fGclUubzV2slT7h9Ie/ucojUH/VbXzBJm+AXQDOUrV/1pK48h3ATuC2/nBtkbp+t27gCeBzVXIew6lLusTwOPBz0W1mhk4BXgsyLsd+HjQvg54CNhJqdveFLQ3B+s7g/vXVelz8TpePIqpZrMG2bYFP0+N/b+q1c9DkGETsDX4TNwGzKvxvK3AIDB3XFtF8+pMahERmVA9DjGJiEgZVCBERGRCKhAiIjIhFQgREZmQCoSIiExIBUJkHDMrHDBr5qSz/ZrZB8zs6qPwunvMbOHLfR6Ro0mHuYqMY2Zxd59VhdfdQ+lY9YGpfm2Rg1EPQqQMwV/4f2+la0o8ZGbrg/a/MbOPBMv/zcyeDubf/2bQNt/MbgvaHjSzU4L2BWb282CiuC8zbu4cM/uD4DUeN7Mvm1m4Cm9ZRAVC5AAtBwwxXTHuvpi7nwn8C6W5kQ50A3Cau58CfCBo+yTwWND2MeCWoP0TwH1emijudmA1gJmdAFxBaeK7TUABePfRfYsi5YkcehORupIKvpgn8o1xt5+d4P4ngK+b2W2Upm6A0pQkbwdw97uDnsNcSheIelvQ/mMzGw62vwA4A3i4NN0VLbw4AZvIlFKBECmfH2R5zMWUvvgvBf7azE5i8mmXJ3oOA25294++nKAiR4OGmETKd8W429+Mv8PMQsAqd7+H0oV+2oFZwK8IhojM7HXAgJeumzG+/UJKE8VBacK1d5jZ4uC++Wa2poLvSeSg1IMQ+V0twVXnxvzU3ccOdW0ysy2U/rC66oDHhYH/CIaPDPisu0fN7G8oXbXsCSDJi1MzfxL4hpk9CvwS2Afg7k+b2f+gdGW2EKXZfa8H9h7tNypyKDrMVaQMOgxV6pGGmEREZELqQYiIyITUgxARkQmpQIiIyIRUIEREZEIqECIiMiEVCBERmZAKhIiITOj/AwEoTB246kS/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model-qn.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "# Creating a gym env\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# A training graph session\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-qn.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        # Closing the env\n",
    "        print('total_reward: {}'.format(total_reward))\n",
    "# Close the env at the end\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning or Q-network (DQN)\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.12.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned. Then run this command `pip install -e gym/[all]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "## Create the Cart-Pole game environment\n",
    "# env = gym.make('CartPole-v0') # 200 total reward as goal\n",
    "env = gym.make('CartPole-v1') # 500 total reward as goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "# batch = []\n",
    "# for _ in range(1000):\n",
    "#     # env.render()\n",
    "#     action = env.action_space.sample()\n",
    "#     state, reward, done, info = env.step(action) # take a random action\n",
    "#     batch.append([action, state, reward, done, info])\n",
    "#     #print('state, action, reward, done, info:', state, action, reward, done, info)\n",
    "#     if done:\n",
    "#         env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch[0], batch[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = np.array([each[0] for each in batch])\n",
    "# states = np.array([each[1] for each in batch])\n",
    "# rewards = np.array([each[2] for each in batch])\n",
    "# dones = np.array([each[3] for each in batch])\n",
    "# infos = np.array([each[4] for each in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rewards[-20:])\n",
    "# print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "# print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "# print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "# print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "# print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "# print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    return actions, states, targetQs, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_xavier(random_seed=1, dtype=tf.float32, uniform=False):\n",
    "    xavier = tf.contrib.layers.xavier_initializer(\n",
    "        dtype=dtype,\n",
    "        seed=tf.set_random_seed(random_seed), \n",
    "        uniform=uniform) # False: normal\n",
    "    return xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(inputs, units, trainable=True):\n",
    "    outputs = tf.layers.dense(\n",
    "        inputs=inputs,\n",
    "        units=units,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=init_xavier(), # Xavier with normal init\n",
    "        bias_initializer=tf.zeros_initializer(),\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        trainable=trainable,\n",
    "        name=None,\n",
    "        reuse=None)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.leaky_relu(\n",
    "#     features,\n",
    "#     alpha=0.2,\n",
    "#     name=None\n",
    "# )\n",
    "def nl(inputs, alpha=0.2):\n",
    "    outputs = tf.maximum(alpha * inputs, inputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn(inputs, training=True):\n",
    "    outputs = tf.layers.batch_normalization(\n",
    "        inputs=inputs,\n",
    "        axis=-1,\n",
    "        momentum=0.99,\n",
    "        epsilon=0.001,\n",
    "        center=True,\n",
    "        scale=True,\n",
    "        beta_initializer=tf.zeros_initializer(),\n",
    "        gamma_initializer=tf.ones_initializer(),\n",
    "        moving_mean_initializer=tf.zeros_initializer(),\n",
    "        moving_variance_initializer=tf.ones_initializer(),\n",
    "        beta_regularizer=None,\n",
    "        gamma_regularizer=None,\n",
    "        beta_constraint=None,\n",
    "        gamma_constraint=None,\n",
    "        training=training,\n",
    "        trainable=True,\n",
    "        name=None,\n",
    "        reuse=None,\n",
    "        renorm=False,\n",
    "        renorm_clipping=None,\n",
    "        renorm_momentum=0.99,\n",
    "        fused=None,\n",
    "        virtual_batch_size=None,\n",
    "        adjustment=None)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor-Critic/ D/Q\n",
    "def D(states, action_size, hidden_size, reuse=False, alpha=0.2, is_training=False):\n",
    "    with tf.variable_scope('D', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h = mlp(inputs=states, units=hidden_size)\n",
    "        h = bn(inputs=h, training=is_training)\n",
    "        h = nl(h)\n",
    "        print(states.shape, h.shape)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h = mlp(inputs=h, units=hidden_size)\n",
    "        h = bn(inputs=h, training=is_training)\n",
    "        h = nl(h)\n",
    "        print(h.shape)\n",
    "        \n",
    "        # Output layer\n",
    "        actions = mlp(inputs=h, units=action_size)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor-Critic/ D/Q\n",
    "def D_target(states, action_size, hidden_size, reuse=False, alpha=0.2, is_training=False):\n",
    "    with tf.variable_scope('D_target', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h = mlp(inputs=states, units=hidden_size)\n",
    "        h = bn(inputs=h, training=is_training)\n",
    "        h = nl(h)\n",
    "        print(states.shape, h.shape)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h = mlp(inputs=h, units=hidden_size)\n",
    "        h = bn(inputs=h, training=is_training)\n",
    "        h = nl(h)\n",
    "        print(h.shape)\n",
    "        \n",
    "        # Output layer\n",
    "        actions = mlp(inputs=h, units=action_size)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(actions, states, targetQs, action_size, hidden_size, is_training):\n",
    "    \n",
    "    actions_logits = D(states=states, hidden_size=hidden_size, action_size=action_size, \n",
    "                       is_training=is_training)\n",
    "    actions_target = D_target(states=states, hidden_size=hidden_size, action_size=action_size, \n",
    "                              is_training=is_training)\n",
    "    \n",
    "    actions_labels = tf.one_hot(indices=actions, depth=action_size, dtype=actions_logits.dtype)\n",
    "    \n",
    "    Qs = tf.reduce_max(actions_logits*actions_labels, axis=1)\n",
    "    \n",
    "    loss = tf.reduce_mean((Qs - targetQs)**2)\n",
    "    \n",
    "    return actions_logits, loss, actions_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(loss, learning_rate, gamma):\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('D')]\n",
    "    d_vars_tgt = [var for var in t_vars if var.name.startswith('D_target')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): # Required for batchnorm (BN)\n",
    "        opt = tf.train.AdamOptimizer(learning_rate).minimize(loss, var_list=d_vars)\n",
    "        \n",
    "        opt_tgt = [d_vars_tgt[i].assign((d_vars_tgt[i]*gamma) + (d_vars[i]*(1 - gamma))) \n",
    "                   for i in range(len(d_vars_tgt))]\n",
    "\n",
    "    return opt, opt_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate, gamma):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.actions, self.states, self.targetQs, self.is_training = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.loss, self.actions_target = model_loss(\n",
    "            action_size=action_size, hidden_size=hidden_size,\n",
    "            states=self.states, actions=self.actions, targetQs=self.targetQs, \n",
    "            is_training=self.is_training)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt, self.opt_target = model_opt(loss=self.loss, learning_rate=learning_rate, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('state size:{}'.format(states.shape), \n",
    "#       'actions:{}'.format(actions.shape)) \n",
    "# print('action size:', np.max(actions) - np.min(actions)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "action_size = 2\n",
    "state_size = 4\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 128               # experience mini-batch size\n",
    "gamma = 0.99                   # future reward discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4) (?, 64)\n",
      "(?, 64)\n",
      "(?, 4) (?, 64)\n",
      "(?, 64)\n"
     ]
    }
   ],
   "source": [
    "# Reset/init the graph/session\n",
    "graph = tf.reset_default_graph()\n",
    "\n",
    "# Init the model\n",
    "model = Model(action_size=action_size, hidden_size=hidden_size, state_size=state_size, \n",
    "              learning_rate=learning_rate, gamma=gamma)\n",
    "\n",
    "# Init the memory\n",
    "memory = Memory(max_size=memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the memory (exprience memory)\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "\n",
    "for _ in range(memory_size):\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "    \n",
    "    state = next_state\n",
    "    \n",
    "    if done is True:\n",
    "        state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(sess, memory, batch_size):\n",
    "    batch = memory.sample(batch_size)\n",
    "    states = np.array([each[0] for each in batch])\n",
    "    actions = np.array([each[1] for each in batch])\n",
    "    next_states = np.array([each[2] for each in batch])\n",
    "    rewards = np.array([each[3] for each in batch])\n",
    "    dones = np.array([each[4] for each in batch])\n",
    "    \n",
    "    next_actions_target = sess.run(model.actions_target, feed_dict = {model.states: next_states, \n",
    "                                                                      model.is_training: False})\n",
    "    \n",
    "    nextQs = np.max(next_actions_target, axis=1) * (1-dones)\n",
    "    \n",
    "    targetQs = rewards + (gamma * nextQs)\n",
    "    \n",
    "    loss, _ = sess.run([model.loss, model.opt], feed_dict = {model.states: states, \n",
    "                                                             model.actions: actions,\n",
    "                                                             model.targetQs: targetQs, \n",
    "                                                             model.is_training: True})\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(sess, state):\n",
    "    \n",
    "    action_logits = sess.run(model.actions_logits, feed_dict={model.states: state.reshape([1, -1]), \n",
    "                                                              model.is_training: False})\n",
    "    \n",
    "    action = np.argmax(action_logits, axis=1)[0]\n",
    "    #print(action)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:0 meanR:14.0000 R:14.0 loss:0.8083 exploreP:0.9986\n",
      "Episode:1 meanR:17.0000 R:20.0 loss:0.8188 exploreP:0.9966\n",
      "Episode:2 meanR:23.0000 R:35.0 loss:0.8222 exploreP:0.9932\n",
      "Episode:3 meanR:31.0000 R:55.0 loss:0.8066 exploreP:0.9878\n",
      "Episode:4 meanR:28.6000 R:19.0 loss:0.7916 exploreP:0.9859\n",
      "Episode:5 meanR:26.5000 R:16.0 loss:0.8350 exploreP:0.9844\n",
      "Episode:6 meanR:25.7143 R:21.0 loss:0.8666 exploreP:0.9823\n",
      "Episode:7 meanR:24.5000 R:16.0 loss:0.8801 exploreP:0.9808\n",
      "Episode:8 meanR:24.7778 R:27.0 loss:0.9115 exploreP:0.9782\n",
      "Episode:9 meanR:23.6000 R:13.0 loss:0.9706 exploreP:0.9769\n",
      "Episode:10 meanR:22.5455 R:12.0 loss:0.9123 exploreP:0.9757\n",
      "Episode:11 meanR:23.3333 R:32.0 loss:0.9816 exploreP:0.9727\n",
      "Episode:12 meanR:23.0769 R:20.0 loss:1.0080 exploreP:0.9707\n",
      "Episode:13 meanR:22.5714 R:16.0 loss:0.9181 exploreP:0.9692\n",
      "Episode:14 meanR:21.8000 R:11.0 loss:0.9314 exploreP:0.9682\n",
      "Episode:15 meanR:22.5000 R:33.0 loss:0.8169 exploreP:0.9650\n",
      "Episode:16 meanR:21.8235 R:11.0 loss:0.7035 exploreP:0.9639\n",
      "Episode:17 meanR:21.5556 R:17.0 loss:0.5977 exploreP:0.9623\n",
      "Episode:18 meanR:21.1053 R:13.0 loss:0.5157 exploreP:0.9611\n",
      "Episode:19 meanR:20.7500 R:14.0 loss:0.5004 exploreP:0.9598\n",
      "Episode:20 meanR:21.4762 R:36.0 loss:0.3990 exploreP:0.9563\n",
      "Episode:21 meanR:21.2727 R:17.0 loss:0.2944 exploreP:0.9547\n",
      "Episode:22 meanR:21.1739 R:19.0 loss:0.2239 exploreP:0.9529\n",
      "Episode:23 meanR:20.8333 R:13.0 loss:0.1865 exploreP:0.9517\n",
      "Episode:24 meanR:21.8000 R:45.0 loss:0.1345 exploreP:0.9475\n",
      "Episode:25 meanR:21.6923 R:19.0 loss:0.1086 exploreP:0.9457\n",
      "Episode:26 meanR:21.6296 R:20.0 loss:0.0912 exploreP:0.9438\n",
      "Episode:27 meanR:21.3571 R:14.0 loss:0.0704 exploreP:0.9425\n",
      "Episode:28 meanR:20.9655 R:10.0 loss:0.0693 exploreP:0.9416\n",
      "Episode:29 meanR:20.6667 R:12.0 loss:0.0747 exploreP:0.9405\n",
      "Episode:30 meanR:21.0323 R:32.0 loss:0.0662 exploreP:0.9375\n",
      "Episode:31 meanR:20.8750 R:16.0 loss:0.0592 exploreP:0.9360\n",
      "Episode:32 meanR:21.7273 R:49.0 loss:0.0650 exploreP:0.9315\n",
      "Episode:33 meanR:22.0882 R:34.0 loss:0.0618 exploreP:0.9284\n",
      "Episode:34 meanR:22.2571 R:28.0 loss:0.0580 exploreP:0.9258\n",
      "Episode:35 meanR:22.3333 R:25.0 loss:0.0638 exploreP:0.9235\n",
      "Episode:36 meanR:22.3784 R:24.0 loss:0.0497 exploreP:0.9213\n",
      "Episode:37 meanR:22.3158 R:20.0 loss:0.0496 exploreP:0.9195\n",
      "Episode:38 meanR:22.0513 R:12.0 loss:0.0523 exploreP:0.9184\n",
      "Episode:39 meanR:22.2000 R:28.0 loss:0.0530 exploreP:0.9159\n",
      "Episode:40 meanR:22.7317 R:44.0 loss:0.0498 exploreP:0.9119\n",
      "Episode:41 meanR:22.5476 R:15.0 loss:0.0633 exploreP:0.9105\n",
      "Episode:42 meanR:22.3256 R:13.0 loss:0.0517 exploreP:0.9094\n",
      "Episode:43 meanR:22.3636 R:24.0 loss:0.0559 exploreP:0.9072\n",
      "Episode:44 meanR:22.8667 R:45.0 loss:0.0465 exploreP:0.9032\n",
      "Episode:45 meanR:22.7826 R:19.0 loss:0.0472 exploreP:0.9015\n",
      "Episode:46 meanR:22.7872 R:23.0 loss:0.0412 exploreP:0.8995\n",
      "Episode:47 meanR:22.9792 R:32.0 loss:0.0488 exploreP:0.8966\n",
      "Episode:48 meanR:23.4694 R:47.0 loss:0.0457 exploreP:0.8925\n",
      "Episode:49 meanR:23.9400 R:47.0 loss:0.0462 exploreP:0.8883\n",
      "Episode:50 meanR:24.8431 R:70.0 loss:0.0414 exploreP:0.8822\n",
      "Episode:51 meanR:24.7308 R:19.0 loss:0.0454 exploreP:0.8805\n",
      "Episode:52 meanR:24.4906 R:12.0 loss:0.0361 exploreP:0.8795\n",
      "Episode:53 meanR:24.2593 R:12.0 loss:0.0386 exploreP:0.8784\n",
      "Episode:54 meanR:24.6909 R:48.0 loss:0.0404 exploreP:0.8743\n",
      "Episode:55 meanR:24.8393 R:33.0 loss:0.0387 exploreP:0.8714\n",
      "Episode:56 meanR:24.5965 R:11.0 loss:0.0389 exploreP:0.8705\n",
      "Episode:57 meanR:24.4138 R:14.0 loss:0.0445 exploreP:0.8693\n",
      "Episode:58 meanR:24.8475 R:50.0 loss:0.0407 exploreP:0.8650\n",
      "Episode:59 meanR:24.7667 R:20.0 loss:0.0433 exploreP:0.8633\n",
      "Episode:60 meanR:24.5246 R:10.0 loss:0.0313 exploreP:0.8624\n",
      "Episode:61 meanR:24.8226 R:43.0 loss:0.0387 exploreP:0.8588\n",
      "Episode:62 meanR:25.2381 R:51.0 loss:0.0424 exploreP:0.8545\n",
      "Episode:63 meanR:25.3438 R:32.0 loss:0.0401 exploreP:0.8518\n",
      "Episode:64 meanR:25.3231 R:24.0 loss:0.0426 exploreP:0.8498\n",
      "Episode:65 meanR:25.3485 R:27.0 loss:0.0387 exploreP:0.8475\n",
      "Episode:66 meanR:25.2239 R:17.0 loss:0.0423 exploreP:0.8461\n",
      "Episode:67 meanR:25.2353 R:26.0 loss:0.0409 exploreP:0.8439\n",
      "Episode:68 meanR:25.0725 R:14.0 loss:0.0361 exploreP:0.8427\n",
      "Episode:69 meanR:25.2857 R:40.0 loss:0.0336 exploreP:0.8394\n",
      "Episode:70 meanR:25.1972 R:19.0 loss:0.0363 exploreP:0.8378\n",
      "Episode:71 meanR:25.0833 R:17.0 loss:0.0364 exploreP:0.8364\n",
      "Episode:72 meanR:25.5342 R:58.0 loss:0.0341 exploreP:0.8316\n",
      "Episode:73 meanR:25.3919 R:15.0 loss:0.0325 exploreP:0.8304\n",
      "Episode:74 meanR:25.4267 R:28.0 loss:0.0356 exploreP:0.8281\n",
      "Episode:75 meanR:25.4737 R:29.0 loss:0.0405 exploreP:0.8257\n",
      "Episode:76 meanR:25.2727 R:10.0 loss:0.0335 exploreP:0.8249\n",
      "Episode:77 meanR:25.2051 R:20.0 loss:0.0359 exploreP:0.8233\n",
      "Episode:78 meanR:25.2785 R:31.0 loss:0.0394 exploreP:0.8208\n",
      "Episode:79 meanR:25.2250 R:21.0 loss:0.0393 exploreP:0.8191\n",
      "Episode:80 meanR:25.0370 R:10.0 loss:0.0374 exploreP:0.8183\n",
      "Episode:81 meanR:25.0610 R:27.0 loss:0.0354 exploreP:0.8161\n",
      "Episode:82 meanR:25.2771 R:43.0 loss:0.0349 exploreP:0.8126\n",
      "Episode:83 meanR:25.1429 R:14.0 loss:0.0345 exploreP:0.8115\n",
      "Episode:84 meanR:25.0824 R:20.0 loss:0.0314 exploreP:0.8099\n",
      "Episode:85 meanR:25.0349 R:21.0 loss:0.0403 exploreP:0.8082\n",
      "Episode:86 meanR:25.8506 R:96.0 loss:0.0358 exploreP:0.8006\n",
      "Episode:87 meanR:25.8068 R:22.0 loss:0.0323 exploreP:0.7989\n",
      "Episode:88 meanR:25.6517 R:12.0 loss:0.0335 exploreP:0.7979\n",
      "Episode:89 meanR:25.6778 R:28.0 loss:0.0320 exploreP:0.7957\n",
      "Episode:90 meanR:26.3736 R:89.0 loss:0.0347 exploreP:0.7888\n",
      "Episode:91 meanR:26.5543 R:43.0 loss:0.0326 exploreP:0.7854\n",
      "Episode:92 meanR:26.4516 R:17.0 loss:0.0339 exploreP:0.7841\n",
      "Episode:93 meanR:26.4787 R:29.0 loss:0.0315 exploreP:0.7819\n",
      "Episode:94 meanR:26.6316 R:41.0 loss:0.0342 exploreP:0.7787\n",
      "Episode:95 meanR:26.4688 R:11.0 loss:0.0353 exploreP:0.7779\n",
      "Episode:96 meanR:26.9175 R:70.0 loss:0.0347 exploreP:0.7725\n",
      "Episode:97 meanR:26.7857 R:14.0 loss:0.0300 exploreP:0.7714\n",
      "Episode:98 meanR:27.7273 R:120.0 loss:0.0339 exploreP:0.7624\n",
      "Episode:99 meanR:28.2300 R:78.0 loss:0.0343 exploreP:0.7565\n",
      "Episode:100 meanR:28.2100 R:12.0 loss:0.0418 exploreP:0.7556\n",
      "Episode:101 meanR:28.3300 R:32.0 loss:0.0370 exploreP:0.7532\n",
      "Episode:102 meanR:28.2100 R:23.0 loss:0.0312 exploreP:0.7515\n",
      "Episode:103 meanR:27.7500 R:9.0 loss:0.0287 exploreP:0.7509\n",
      "Episode:104 meanR:27.9300 R:37.0 loss:0.0319 exploreP:0.7481\n",
      "Episode:105 meanR:27.9400 R:17.0 loss:0.0335 exploreP:0.7469\n",
      "Episode:106 meanR:28.1600 R:43.0 loss:0.0347 exploreP:0.7437\n",
      "Episode:107 meanR:28.1200 R:12.0 loss:0.0341 exploreP:0.7428\n",
      "Episode:108 meanR:28.2600 R:41.0 loss:0.0339 exploreP:0.7398\n",
      "Episode:109 meanR:28.2600 R:13.0 loss:0.0365 exploreP:0.7389\n",
      "Episode:110 meanR:28.2600 R:12.0 loss:0.0356 exploreP:0.7380\n",
      "Episode:111 meanR:28.2700 R:33.0 loss:0.0328 exploreP:0.7356\n",
      "Episode:112 meanR:28.2000 R:13.0 loss:0.0351 exploreP:0.7347\n",
      "Episode:113 meanR:28.2000 R:16.0 loss:0.0291 exploreP:0.7335\n",
      "Episode:114 meanR:28.3700 R:28.0 loss:0.0328 exploreP:0.7315\n",
      "Episode:115 meanR:28.4700 R:43.0 loss:0.0364 exploreP:0.7284\n",
      "Episode:116 meanR:28.5800 R:22.0 loss:0.0350 exploreP:0.7268\n",
      "Episode:117 meanR:29.0100 R:60.0 loss:0.0330 exploreP:0.7225\n",
      "Episode:118 meanR:29.0000 R:12.0 loss:0.0372 exploreP:0.7217\n",
      "Episode:119 meanR:29.3100 R:45.0 loss:0.0345 exploreP:0.7185\n",
      "Episode:120 meanR:29.7900 R:84.0 loss:0.0352 exploreP:0.7125\n",
      "Episode:121 meanR:29.8200 R:20.0 loss:0.0316 exploreP:0.7111\n",
      "Episode:122 meanR:30.0300 R:40.0 loss:0.0319 exploreP:0.7083\n",
      "Episode:123 meanR:30.5600 R:66.0 loss:0.0305 exploreP:0.7037\n",
      "Episode:124 meanR:30.2600 R:15.0 loss:0.0354 exploreP:0.7027\n",
      "Episode:125 meanR:30.3800 R:31.0 loss:0.0333 exploreP:0.7006\n",
      "Episode:126 meanR:30.5600 R:38.0 loss:0.0324 exploreP:0.6979\n",
      "Episode:127 meanR:30.6000 R:18.0 loss:0.0301 exploreP:0.6967\n",
      "Episode:128 meanR:30.8100 R:31.0 loss:0.0336 exploreP:0.6946\n",
      "Episode:129 meanR:30.9200 R:23.0 loss:0.0321 exploreP:0.6930\n",
      "Episode:130 meanR:31.0400 R:44.0 loss:0.0327 exploreP:0.6900\n",
      "Episode:131 meanR:31.5900 R:71.0 loss:0.0340 exploreP:0.6852\n",
      "Episode:132 meanR:31.3800 R:28.0 loss:0.0366 exploreP:0.6833\n",
      "Episode:133 meanR:31.1500 R:11.0 loss:0.0334 exploreP:0.6826\n",
      "Episode:134 meanR:31.0300 R:16.0 loss:0.0391 exploreP:0.6815\n",
      "Episode:135 meanR:30.9200 R:14.0 loss:0.0328 exploreP:0.6806\n",
      "Episode:136 meanR:30.8000 R:12.0 loss:0.0349 exploreP:0.6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:137 meanR:31.4100 R:81.0 loss:0.0314 exploreP:0.6743\n",
      "Episode:138 meanR:31.4400 R:15.0 loss:0.0332 exploreP:0.6734\n",
      "Episode:139 meanR:31.4200 R:26.0 loss:0.0342 exploreP:0.6716\n",
      "Episode:140 meanR:31.6000 R:62.0 loss:0.0367 exploreP:0.6675\n",
      "Episode:141 meanR:31.6400 R:19.0 loss:0.0338 exploreP:0.6663\n",
      "Episode:142 meanR:31.8000 R:29.0 loss:0.0380 exploreP:0.6644\n",
      "Episode:143 meanR:31.7200 R:16.0 loss:0.0311 exploreP:0.6633\n",
      "Episode:144 meanR:31.4000 R:13.0 loss:0.0294 exploreP:0.6625\n",
      "Episode:145 meanR:31.3300 R:12.0 loss:0.0354 exploreP:0.6617\n",
      "Episode:146 meanR:31.2900 R:19.0 loss:0.0308 exploreP:0.6605\n",
      "Episode:147 meanR:31.6500 R:68.0 loss:0.0329 exploreP:0.6561\n",
      "Episode:148 meanR:31.6900 R:51.0 loss:0.0336 exploreP:0.6528\n",
      "Episode:149 meanR:31.4500 R:23.0 loss:0.0322 exploreP:0.6513\n",
      "Episode:150 meanR:30.8400 R:9.0 loss:0.0358 exploreP:0.6507\n",
      "Episode:151 meanR:31.0800 R:43.0 loss:0.0329 exploreP:0.6480\n",
      "Episode:152 meanR:31.4100 R:45.0 loss:0.0314 exploreP:0.6451\n",
      "Episode:153 meanR:31.4300 R:14.0 loss:0.0371 exploreP:0.6442\n",
      "Episode:154 meanR:31.0900 R:14.0 loss:0.0305 exploreP:0.6433\n",
      "Episode:155 meanR:31.2000 R:44.0 loss:0.0305 exploreP:0.6406\n",
      "Episode:156 meanR:31.2900 R:20.0 loss:0.0360 exploreP:0.6393\n",
      "Episode:157 meanR:31.2500 R:10.0 loss:0.0344 exploreP:0.6387\n",
      "Episode:158 meanR:30.8500 R:10.0 loss:0.0300 exploreP:0.6380\n",
      "Episode:159 meanR:30.9100 R:26.0 loss:0.0317 exploreP:0.6364\n",
      "Episode:160 meanR:31.3700 R:56.0 loss:0.0340 exploreP:0.6329\n",
      "Episode:161 meanR:31.1200 R:18.0 loss:0.0351 exploreP:0.6318\n",
      "Episode:162 meanR:30.7500 R:14.0 loss:0.0339 exploreP:0.6309\n",
      "Episode:163 meanR:30.6600 R:23.0 loss:0.0333 exploreP:0.6295\n",
      "Episode:164 meanR:30.7500 R:33.0 loss:0.0328 exploreP:0.6275\n",
      "Episode:165 meanR:30.7300 R:25.0 loss:0.0331 exploreP:0.6259\n",
      "Episode:166 meanR:30.7000 R:14.0 loss:0.0277 exploreP:0.6251\n",
      "Episode:167 meanR:30.8900 R:45.0 loss:0.0317 exploreP:0.6223\n",
      "Episode:168 meanR:31.2800 R:53.0 loss:0.0343 exploreP:0.6191\n",
      "Episode:169 meanR:31.3000 R:42.0 loss:0.0307 exploreP:0.6165\n",
      "Episode:170 meanR:31.2000 R:9.0 loss:0.0316 exploreP:0.6160\n",
      "Episode:171 meanR:31.2000 R:17.0 loss:0.0295 exploreP:0.6149\n",
      "Episode:172 meanR:30.7200 R:10.0 loss:0.0298 exploreP:0.6143\n",
      "Episode:173 meanR:30.7900 R:22.0 loss:0.0347 exploreP:0.6130\n",
      "Episode:174 meanR:30.6200 R:11.0 loss:0.0328 exploreP:0.6123\n",
      "Episode:175 meanR:30.4500 R:12.0 loss:0.0344 exploreP:0.6116\n",
      "Episode:176 meanR:30.6000 R:25.0 loss:0.0302 exploreP:0.6101\n",
      "Episode:177 meanR:30.7500 R:35.0 loss:0.0320 exploreP:0.6080\n",
      "Episode:178 meanR:30.5900 R:15.0 loss:0.0345 exploreP:0.6071\n",
      "Episode:179 meanR:30.5500 R:17.0 loss:0.0289 exploreP:0.6061\n",
      "Episode:180 meanR:30.5700 R:12.0 loss:0.0324 exploreP:0.6054\n",
      "Episode:181 meanR:30.4700 R:17.0 loss:0.0288 exploreP:0.6044\n",
      "Episode:182 meanR:30.4400 R:40.0 loss:0.0349 exploreP:0.6020\n",
      "Episode:183 meanR:30.6500 R:35.0 loss:0.0287 exploreP:0.5999\n",
      "Episode:184 meanR:30.6000 R:15.0 loss:0.0276 exploreP:0.5990\n",
      "Episode:185 meanR:30.5000 R:11.0 loss:0.0314 exploreP:0.5984\n",
      "Episode:186 meanR:29.7100 R:17.0 loss:0.0264 exploreP:0.5974\n",
      "Episode:187 meanR:29.6300 R:14.0 loss:0.0352 exploreP:0.5966\n",
      "Episode:188 meanR:29.6000 R:9.0 loss:0.0271 exploreP:0.5960\n",
      "Episode:189 meanR:29.5000 R:18.0 loss:0.0310 exploreP:0.5950\n",
      "Episode:190 meanR:29.0800 R:47.0 loss:0.0291 exploreP:0.5923\n",
      "Episode:191 meanR:28.8000 R:15.0 loss:0.0304 exploreP:0.5914\n",
      "Episode:192 meanR:28.7700 R:14.0 loss:0.0337 exploreP:0.5906\n",
      "Episode:193 meanR:28.5800 R:10.0 loss:0.0325 exploreP:0.5900\n",
      "Episode:194 meanR:28.3200 R:15.0 loss:0.0364 exploreP:0.5891\n",
      "Episode:195 meanR:28.8200 R:61.0 loss:0.0318 exploreP:0.5856\n",
      "Episode:196 meanR:28.2400 R:12.0 loss:0.0358 exploreP:0.5849\n",
      "Episode:197 meanR:28.5800 R:48.0 loss:0.0301 exploreP:0.5822\n",
      "Episode:198 meanR:27.4900 R:11.0 loss:0.0351 exploreP:0.5815\n",
      "Episode:199 meanR:26.9300 R:22.0 loss:0.0317 exploreP:0.5803\n",
      "Episode:200 meanR:26.9100 R:10.0 loss:0.0340 exploreP:0.5797\n",
      "Episode:201 meanR:26.8100 R:22.0 loss:0.0310 exploreP:0.5784\n",
      "Episode:202 meanR:26.8000 R:22.0 loss:0.0311 exploreP:0.5772\n",
      "Episode:203 meanR:28.0100 R:130.0 loss:0.0305 exploreP:0.5699\n",
      "Episode:204 meanR:27.8800 R:24.0 loss:0.0309 exploreP:0.5685\n",
      "Episode:205 meanR:27.8000 R:9.0 loss:0.0286 exploreP:0.5680\n",
      "Episode:206 meanR:27.5600 R:19.0 loss:0.0395 exploreP:0.5670\n",
      "Episode:207 meanR:28.1300 R:69.0 loss:0.0327 exploreP:0.5631\n",
      "Episode:208 meanR:28.1800 R:46.0 loss:0.0322 exploreP:0.5606\n",
      "Episode:209 meanR:28.5300 R:48.0 loss:0.0334 exploreP:0.5580\n",
      "Episode:210 meanR:29.2000 R:79.0 loss:0.0315 exploreP:0.5536\n",
      "Episode:211 meanR:29.0000 R:13.0 loss:0.0321 exploreP:0.5529\n",
      "Episode:212 meanR:29.0700 R:20.0 loss:0.0337 exploreP:0.5519\n",
      "Episode:213 meanR:29.0800 R:17.0 loss:0.0321 exploreP:0.5509\n",
      "Episode:214 meanR:28.8800 R:8.0 loss:0.0291 exploreP:0.5505\n",
      "Episode:215 meanR:28.5400 R:9.0 loss:0.0305 exploreP:0.5500\n",
      "Episode:216 meanR:28.6300 R:31.0 loss:0.0335 exploreP:0.5483\n",
      "Episode:217 meanR:28.1300 R:10.0 loss:0.0343 exploreP:0.5478\n",
      "Episode:218 meanR:28.1200 R:11.0 loss:0.0304 exploreP:0.5472\n",
      "Episode:219 meanR:27.8200 R:15.0 loss:0.0360 exploreP:0.5464\n",
      "Episode:220 meanR:27.3300 R:35.0 loss:0.0339 exploreP:0.5445\n",
      "Episode:221 meanR:27.3200 R:19.0 loss:0.0331 exploreP:0.5435\n",
      "Episode:222 meanR:27.1700 R:25.0 loss:0.0329 exploreP:0.5422\n",
      "Episode:223 meanR:26.6300 R:12.0 loss:0.0332 exploreP:0.5416\n",
      "Episode:224 meanR:26.6700 R:19.0 loss:0.0284 exploreP:0.5405\n",
      "Episode:225 meanR:26.5500 R:19.0 loss:0.0304 exploreP:0.5395\n",
      "Episode:226 meanR:26.5100 R:34.0 loss:0.0340 exploreP:0.5377\n",
      "Episode:227 meanR:26.7700 R:44.0 loss:0.0336 exploreP:0.5354\n",
      "Episode:228 meanR:26.5600 R:10.0 loss:0.0387 exploreP:0.5349\n",
      "Episode:229 meanR:26.7400 R:41.0 loss:0.0327 exploreP:0.5328\n",
      "Episode:230 meanR:26.4200 R:12.0 loss:0.0346 exploreP:0.5321\n",
      "Episode:231 meanR:25.8300 R:12.0 loss:0.0378 exploreP:0.5315\n",
      "Episode:232 meanR:25.8800 R:33.0 loss:0.0352 exploreP:0.5298\n",
      "Episode:233 meanR:26.0400 R:27.0 loss:0.0293 exploreP:0.5284\n",
      "Episode:234 meanR:26.1900 R:31.0 loss:0.0358 exploreP:0.5268\n",
      "Episode:235 meanR:27.4100 R:136.0 loss:0.0332 exploreP:0.5198\n",
      "Episode:236 meanR:27.4900 R:20.0 loss:0.0537 exploreP:0.5188\n",
      "Episode:237 meanR:26.9300 R:25.0 loss:0.0399 exploreP:0.5175\n",
      "Episode:238 meanR:26.9800 R:20.0 loss:0.0434 exploreP:0.5165\n",
      "Episode:239 meanR:26.8500 R:13.0 loss:0.0432 exploreP:0.5158\n",
      "Episode:240 meanR:26.7900 R:56.0 loss:0.0369 exploreP:0.5130\n",
      "Episode:241 meanR:26.7300 R:13.0 loss:0.0384 exploreP:0.5124\n",
      "Episode:242 meanR:26.5600 R:12.0 loss:0.0336 exploreP:0.5118\n",
      "Episode:243 meanR:26.4900 R:9.0 loss:0.0306 exploreP:0.5113\n",
      "Episode:244 meanR:26.4800 R:12.0 loss:0.0384 exploreP:0.5107\n",
      "Episode:245 meanR:26.5300 R:17.0 loss:0.0359 exploreP:0.5098\n",
      "Episode:246 meanR:26.4400 R:10.0 loss:0.0327 exploreP:0.5093\n",
      "Episode:247 meanR:26.8500 R:109.0 loss:0.0386 exploreP:0.5039\n",
      "Episode:248 meanR:27.3300 R:99.0 loss:0.0383 exploreP:0.4991\n",
      "Episode:249 meanR:27.3600 R:26.0 loss:0.0372 exploreP:0.4978\n",
      "Episode:250 meanR:27.5500 R:28.0 loss:0.0394 exploreP:0.4964\n",
      "Episode:251 meanR:27.2200 R:10.0 loss:0.0354 exploreP:0.4959\n",
      "Episode:252 meanR:26.8800 R:11.0 loss:0.0441 exploreP:0.4954\n",
      "Episode:253 meanR:26.8800 R:14.0 loss:0.0364 exploreP:0.4947\n",
      "Episode:254 meanR:26.8900 R:15.0 loss:0.0372 exploreP:0.4940\n",
      "Episode:255 meanR:26.6400 R:19.0 loss:0.0374 exploreP:0.4931\n",
      "Episode:256 meanR:26.5300 R:9.0 loss:0.0412 exploreP:0.4927\n",
      "Episode:257 meanR:26.5400 R:11.0 loss:0.0434 exploreP:0.4921\n",
      "Episode:258 meanR:26.5500 R:11.0 loss:0.0390 exploreP:0.4916\n",
      "Episode:259 meanR:26.4900 R:20.0 loss:0.0411 exploreP:0.4906\n",
      "Episode:260 meanR:26.1400 R:21.0 loss:0.0381 exploreP:0.4896\n",
      "Episode:261 meanR:26.1700 R:21.0 loss:0.0360 exploreP:0.4886\n",
      "Episode:262 meanR:26.1900 R:16.0 loss:0.0387 exploreP:0.4879\n",
      "Episode:263 meanR:26.0500 R:9.0 loss:0.0393 exploreP:0.4874\n",
      "Episode:264 meanR:25.8300 R:11.0 loss:0.0340 exploreP:0.4869\n",
      "Episode:265 meanR:25.8400 R:26.0 loss:0.0384 exploreP:0.4857\n",
      "Episode:266 meanR:25.9000 R:20.0 loss:0.0385 exploreP:0.4847\n",
      "Episode:267 meanR:25.7800 R:33.0 loss:0.0412 exploreP:0.4831\n",
      "Episode:268 meanR:25.4400 R:19.0 loss:0.0371 exploreP:0.4822\n",
      "Episode:269 meanR:25.1900 R:17.0 loss:0.0353 exploreP:0.4814\n",
      "Episode:270 meanR:25.2300 R:13.0 loss:0.0373 exploreP:0.4808\n",
      "Episode:271 meanR:25.3100 R:25.0 loss:0.0405 exploreP:0.4797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:272 meanR:25.5800 R:37.0 loss:0.0388 exploreP:0.4779\n",
      "Episode:273 meanR:25.5600 R:20.0 loss:0.0399 exploreP:0.4770\n",
      "Episode:274 meanR:25.5500 R:10.0 loss:0.0357 exploreP:0.4765\n",
      "Episode:275 meanR:25.5700 R:14.0 loss:0.0359 exploreP:0.4759\n",
      "Episode:276 meanR:25.4300 R:11.0 loss:0.0370 exploreP:0.4754\n",
      "Episode:277 meanR:25.3900 R:31.0 loss:0.0395 exploreP:0.4739\n",
      "Episode:278 meanR:25.4200 R:18.0 loss:0.0351 exploreP:0.4731\n",
      "Episode:279 meanR:25.3700 R:12.0 loss:0.0384 exploreP:0.4725\n",
      "Episode:280 meanR:25.5300 R:28.0 loss:0.0375 exploreP:0.4712\n",
      "Episode:281 meanR:25.4700 R:11.0 loss:0.0335 exploreP:0.4707\n",
      "Episode:282 meanR:25.1900 R:12.0 loss:0.0317 exploreP:0.4702\n",
      "Episode:283 meanR:25.1800 R:34.0 loss:0.0371 exploreP:0.4686\n",
      "Episode:284 meanR:25.1700 R:14.0 loss:0.0329 exploreP:0.4680\n",
      "Episode:285 meanR:25.1600 R:10.0 loss:0.0338 exploreP:0.4675\n",
      "Episode:286 meanR:25.1400 R:15.0 loss:0.0371 exploreP:0.4668\n",
      "Episode:287 meanR:25.1400 R:14.0 loss:0.0425 exploreP:0.4662\n",
      "Episode:288 meanR:25.2400 R:19.0 loss:0.0402 exploreP:0.4653\n",
      "Episode:289 meanR:25.3800 R:32.0 loss:0.0403 exploreP:0.4639\n",
      "Episode:290 meanR:25.2900 R:38.0 loss:0.0375 exploreP:0.4621\n",
      "Episode:291 meanR:25.2600 R:12.0 loss:0.0395 exploreP:0.4616\n",
      "Episode:292 meanR:25.2200 R:10.0 loss:0.0334 exploreP:0.4612\n",
      "Episode:293 meanR:25.2400 R:12.0 loss:0.0388 exploreP:0.4606\n",
      "Episode:294 meanR:25.2900 R:20.0 loss:0.0390 exploreP:0.4597\n",
      "Episode:295 meanR:24.8400 R:16.0 loss:0.0393 exploreP:0.4590\n",
      "Episode:296 meanR:24.8300 R:11.0 loss:0.0405 exploreP:0.4585\n",
      "Episode:297 meanR:24.6400 R:29.0 loss:0.0372 exploreP:0.4572\n",
      "Episode:298 meanR:24.6700 R:14.0 loss:0.0402 exploreP:0.4566\n",
      "Episode:299 meanR:24.7000 R:25.0 loss:0.0424 exploreP:0.4555\n",
      "Episode:300 meanR:24.7100 R:11.0 loss:0.0361 exploreP:0.4550\n",
      "Episode:301 meanR:24.6000 R:11.0 loss:0.0426 exploreP:0.4545\n",
      "Episode:302 meanR:24.6300 R:25.0 loss:0.0382 exploreP:0.4534\n",
      "Episode:303 meanR:23.5500 R:22.0 loss:0.0341 exploreP:0.4524\n",
      "Episode:304 meanR:23.4100 R:10.0 loss:0.0336 exploreP:0.4520\n",
      "Episode:305 meanR:23.4400 R:12.0 loss:0.0326 exploreP:0.4514\n",
      "Episode:306 meanR:23.5100 R:26.0 loss:0.0342 exploreP:0.4503\n",
      "Episode:307 meanR:23.0200 R:20.0 loss:0.0391 exploreP:0.4494\n",
      "Episode:308 meanR:22.7600 R:20.0 loss:0.0392 exploreP:0.4485\n",
      "Episode:309 meanR:22.4600 R:18.0 loss:0.0391 exploreP:0.4477\n",
      "Episode:310 meanR:21.8400 R:17.0 loss:0.0382 exploreP:0.4470\n",
      "Episode:311 meanR:21.9100 R:20.0 loss:0.0378 exploreP:0.4461\n",
      "Episode:312 meanR:21.8200 R:11.0 loss:0.0387 exploreP:0.4456\n",
      "Episode:313 meanR:21.7800 R:13.0 loss:0.0441 exploreP:0.4451\n",
      "Episode:314 meanR:21.8200 R:12.0 loss:0.0391 exploreP:0.4445\n",
      "Episode:315 meanR:21.9000 R:17.0 loss:0.0381 exploreP:0.4438\n",
      "Episode:316 meanR:21.7300 R:14.0 loss:0.0334 exploreP:0.4432\n",
      "Episode:317 meanR:21.9300 R:30.0 loss:0.0428 exploreP:0.4419\n",
      "Episode:318 meanR:21.9200 R:10.0 loss:0.0353 exploreP:0.4415\n",
      "Episode:319 meanR:21.8700 R:10.0 loss:0.0456 exploreP:0.4410\n",
      "Episode:320 meanR:21.6200 R:10.0 loss:0.0415 exploreP:0.4406\n",
      "Episode:321 meanR:21.5900 R:16.0 loss:0.0370 exploreP:0.4399\n",
      "Episode:322 meanR:21.5000 R:16.0 loss:0.0370 exploreP:0.4392\n",
      "Episode:323 meanR:21.4900 R:11.0 loss:0.0319 exploreP:0.4388\n",
      "Episode:324 meanR:21.4800 R:18.0 loss:0.0345 exploreP:0.4380\n",
      "Episode:325 meanR:21.6100 R:32.0 loss:0.0333 exploreP:0.4366\n",
      "Episode:326 meanR:21.5300 R:26.0 loss:0.0421 exploreP:0.4355\n",
      "Episode:327 meanR:21.1800 R:9.0 loss:0.0483 exploreP:0.4351\n",
      "Episode:328 meanR:21.2200 R:14.0 loss:0.0361 exploreP:0.4345\n",
      "Episode:329 meanR:20.9200 R:11.0 loss:0.0359 exploreP:0.4341\n",
      "Episode:330 meanR:20.8900 R:9.0 loss:0.0336 exploreP:0.4337\n",
      "Episode:331 meanR:20.9200 R:15.0 loss:0.0424 exploreP:0.4331\n",
      "Episode:332 meanR:20.6900 R:10.0 loss:0.0464 exploreP:0.4326\n",
      "Episode:333 meanR:20.5300 R:11.0 loss:0.0437 exploreP:0.4322\n",
      "Episode:334 meanR:20.3900 R:17.0 loss:0.0372 exploreP:0.4315\n",
      "Episode:335 meanR:19.1600 R:13.0 loss:0.0355 exploreP:0.4309\n",
      "Episode:336 meanR:19.1900 R:23.0 loss:0.0355 exploreP:0.4299\n",
      "Episode:337 meanR:19.0300 R:9.0 loss:0.0386 exploreP:0.4296\n",
      "Episode:338 meanR:19.2900 R:46.0 loss:0.0392 exploreP:0.4276\n",
      "Episode:339 meanR:19.2900 R:13.0 loss:0.0386 exploreP:0.4271\n",
      "Episode:340 meanR:18.8600 R:13.0 loss:0.0356 exploreP:0.4265\n",
      "Episode:341 meanR:18.9100 R:18.0 loss:0.0379 exploreP:0.4258\n",
      "Episode:342 meanR:18.9600 R:17.0 loss:0.0402 exploreP:0.4251\n",
      "Episode:343 meanR:19.0300 R:16.0 loss:0.0378 exploreP:0.4244\n",
      "Episode:344 meanR:19.1500 R:24.0 loss:0.0355 exploreP:0.4234\n",
      "Episode:345 meanR:19.6900 R:71.0 loss:0.0382 exploreP:0.4205\n",
      "Episode:346 meanR:20.0900 R:50.0 loss:0.0386 exploreP:0.4185\n",
      "Episode:347 meanR:19.1000 R:10.0 loss:0.0281 exploreP:0.4181\n",
      "Episode:348 meanR:18.2100 R:10.0 loss:0.0344 exploreP:0.4176\n",
      "Episode:349 meanR:18.0700 R:12.0 loss:0.0379 exploreP:0.4172\n",
      "Episode:350 meanR:17.8900 R:10.0 loss:0.0331 exploreP:0.4168\n",
      "Episode:351 meanR:18.0800 R:29.0 loss:0.0381 exploreP:0.4156\n",
      "Episode:352 meanR:18.0700 R:10.0 loss:0.0363 exploreP:0.4152\n",
      "Episode:353 meanR:18.0700 R:14.0 loss:0.0311 exploreP:0.4146\n",
      "Episode:354 meanR:18.0000 R:8.0 loss:0.0382 exploreP:0.4143\n",
      "Episode:355 meanR:17.9900 R:18.0 loss:0.0406 exploreP:0.4136\n",
      "Episode:356 meanR:18.0800 R:18.0 loss:0.0378 exploreP:0.4128\n",
      "Episode:357 meanR:18.1400 R:17.0 loss:0.0388 exploreP:0.4121\n",
      "Episode:358 meanR:18.1800 R:15.0 loss:0.0330 exploreP:0.4115\n",
      "Episode:359 meanR:18.2200 R:24.0 loss:0.0367 exploreP:0.4106\n",
      "Episode:360 meanR:18.1200 R:11.0 loss:0.0386 exploreP:0.4101\n",
      "Episode:361 meanR:18.1300 R:22.0 loss:0.0325 exploreP:0.4093\n",
      "Episode:362 meanR:18.0900 R:12.0 loss:0.0362 exploreP:0.4088\n",
      "Episode:363 meanR:18.3700 R:37.0 loss:0.0363 exploreP:0.4073\n",
      "Episode:364 meanR:18.3900 R:13.0 loss:0.0355 exploreP:0.4068\n",
      "Episode:365 meanR:18.3900 R:26.0 loss:0.0353 exploreP:0.4058\n",
      "Episode:366 meanR:18.2800 R:9.0 loss:0.0381 exploreP:0.4054\n",
      "Episode:367 meanR:18.0500 R:10.0 loss:0.0383 exploreP:0.4050\n",
      "Episode:368 meanR:18.0200 R:16.0 loss:0.0358 exploreP:0.4044\n",
      "Episode:369 meanR:18.0100 R:16.0 loss:0.0323 exploreP:0.4037\n",
      "Episode:370 meanR:18.0200 R:14.0 loss:0.0357 exploreP:0.4032\n",
      "Episode:371 meanR:17.9800 R:21.0 loss:0.0366 exploreP:0.4024\n",
      "Episode:372 meanR:17.7300 R:12.0 loss:0.0386 exploreP:0.4019\n",
      "Episode:373 meanR:17.7300 R:20.0 loss:0.0372 exploreP:0.4011\n",
      "Episode:374 meanR:17.7300 R:10.0 loss:0.0362 exploreP:0.4007\n",
      "Episode:375 meanR:17.7000 R:11.0 loss:0.0384 exploreP:0.4003\n",
      "Episode:376 meanR:17.7700 R:18.0 loss:0.0382 exploreP:0.3996\n",
      "Episode:377 meanR:17.6800 R:22.0 loss:0.0401 exploreP:0.3987\n",
      "Episode:378 meanR:17.6000 R:10.0 loss:0.0352 exploreP:0.3983\n",
      "Episode:379 meanR:17.8400 R:36.0 loss:0.0331 exploreP:0.3970\n",
      "Episode:380 meanR:17.6500 R:9.0 loss:0.0336 exploreP:0.3966\n",
      "Episode:381 meanR:17.7400 R:20.0 loss:0.0374 exploreP:0.3958\n",
      "Episode:382 meanR:17.7600 R:14.0 loss:0.0388 exploreP:0.3953\n",
      "Episode:383 meanR:17.5100 R:9.0 loss:0.0439 exploreP:0.3949\n",
      "Episode:384 meanR:17.4900 R:12.0 loss:0.0392 exploreP:0.3945\n",
      "Episode:385 meanR:17.5000 R:11.0 loss:0.0417 exploreP:0.3941\n",
      "Episode:386 meanR:17.4600 R:11.0 loss:0.0388 exploreP:0.3936\n",
      "Episode:387 meanR:17.5100 R:19.0 loss:0.0349 exploreP:0.3929\n",
      "Episode:388 meanR:17.4100 R:9.0 loss:0.0332 exploreP:0.3926\n",
      "Episode:389 meanR:17.2000 R:11.0 loss:0.0361 exploreP:0.3921\n",
      "Episode:390 meanR:16.9100 R:9.0 loss:0.0373 exploreP:0.3918\n",
      "Episode:391 meanR:16.9200 R:13.0 loss:0.0374 exploreP:0.3913\n",
      "Episode:392 meanR:17.0600 R:24.0 loss:0.0367 exploreP:0.3904\n",
      "Episode:393 meanR:17.0700 R:13.0 loss:0.0356 exploreP:0.3899\n",
      "Episode:394 meanR:17.1400 R:27.0 loss:0.0398 exploreP:0.3889\n",
      "Episode:395 meanR:17.1000 R:12.0 loss:0.0377 exploreP:0.3884\n",
      "Episode:396 meanR:17.1200 R:13.0 loss:0.0306 exploreP:0.3879\n",
      "Episode:397 meanR:17.0400 R:21.0 loss:0.0339 exploreP:0.3871\n",
      "Episode:398 meanR:17.0000 R:10.0 loss:0.0357 exploreP:0.3868\n",
      "Episode:399 meanR:16.9500 R:20.0 loss:0.0381 exploreP:0.3860\n",
      "Episode:400 meanR:17.0200 R:18.0 loss:0.0337 exploreP:0.3853\n",
      "Episode:401 meanR:17.0900 R:18.0 loss:0.0318 exploreP:0.3847\n",
      "Episode:402 meanR:16.9200 R:8.0 loss:0.0488 exploreP:0.3844\n",
      "Episode:403 meanR:16.8100 R:11.0 loss:0.0322 exploreP:0.3839\n",
      "Episode:404 meanR:16.8300 R:12.0 loss:0.0349 exploreP:0.3835\n",
      "Episode:405 meanR:16.8200 R:11.0 loss:0.0276 exploreP:0.3831\n",
      "Episode:406 meanR:16.8000 R:24.0 loss:0.0386 exploreP:0.3822\n",
      "Episode:407 meanR:16.7100 R:11.0 loss:0.0421 exploreP:0.3818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:408 meanR:16.6700 R:16.0 loss:0.0363 exploreP:0.3812\n",
      "Episode:409 meanR:16.5900 R:10.0 loss:0.0359 exploreP:0.3808\n",
      "Episode:410 meanR:16.5400 R:12.0 loss:0.0328 exploreP:0.3804\n",
      "Episode:411 meanR:16.4900 R:15.0 loss:0.0350 exploreP:0.3798\n",
      "Episode:412 meanR:16.5400 R:16.0 loss:0.0359 exploreP:0.3792\n",
      "Episode:413 meanR:16.6700 R:26.0 loss:0.0351 exploreP:0.3783\n",
      "Episode:414 meanR:16.6600 R:11.0 loss:0.0344 exploreP:0.3779\n",
      "Episode:415 meanR:16.6100 R:12.0 loss:0.0343 exploreP:0.3774\n",
      "Episode:416 meanR:16.5800 R:11.0 loss:0.0362 exploreP:0.3770\n",
      "Episode:417 meanR:16.3800 R:10.0 loss:0.0380 exploreP:0.3766\n",
      "Episode:418 meanR:16.4000 R:12.0 loss:0.0351 exploreP:0.3762\n",
      "Episode:419 meanR:16.4200 R:12.0 loss:0.0409 exploreP:0.3758\n",
      "Episode:420 meanR:16.4100 R:9.0 loss:0.0329 exploreP:0.3754\n",
      "Episode:421 meanR:16.3400 R:9.0 loss:0.0362 exploreP:0.3751\n",
      "Episode:422 meanR:16.4600 R:28.0 loss:0.0340 exploreP:0.3741\n",
      "Episode:423 meanR:16.4900 R:14.0 loss:0.0316 exploreP:0.3736\n",
      "Episode:424 meanR:16.6500 R:34.0 loss:0.0384 exploreP:0.3723\n",
      "Episode:425 meanR:16.4300 R:10.0 loss:0.0347 exploreP:0.3720\n",
      "Episode:426 meanR:16.3100 R:14.0 loss:0.0369 exploreP:0.3715\n",
      "Episode:427 meanR:16.3200 R:10.0 loss:0.0421 exploreP:0.3711\n",
      "Episode:428 meanR:16.4000 R:22.0 loss:0.0346 exploreP:0.3703\n",
      "Episode:429 meanR:16.5300 R:24.0 loss:0.0360 exploreP:0.3695\n",
      "Episode:430 meanR:16.5500 R:11.0 loss:0.0339 exploreP:0.3691\n",
      "Episode:431 meanR:17.1300 R:73.0 loss:0.0325 exploreP:0.3665\n",
      "Episode:432 meanR:17.1600 R:13.0 loss:0.0367 exploreP:0.3660\n",
      "Episode:433 meanR:17.2300 R:18.0 loss:0.0365 exploreP:0.3654\n",
      "Episode:434 meanR:17.3100 R:25.0 loss:0.0390 exploreP:0.3645\n",
      "Episode:435 meanR:17.3300 R:15.0 loss:0.0374 exploreP:0.3639\n",
      "Episode:436 meanR:17.3900 R:29.0 loss:0.0326 exploreP:0.3629\n",
      "Episode:437 meanR:17.4300 R:13.0 loss:0.0323 exploreP:0.3624\n",
      "Episode:438 meanR:17.1600 R:19.0 loss:0.0338 exploreP:0.3618\n",
      "Episode:439 meanR:17.3700 R:34.0 loss:0.0365 exploreP:0.3606\n",
      "Episode:440 meanR:17.3600 R:12.0 loss:0.0354 exploreP:0.3602\n",
      "Episode:441 meanR:17.3000 R:12.0 loss:0.0350 exploreP:0.3597\n",
      "Episode:442 meanR:17.2300 R:10.0 loss:0.0353 exploreP:0.3594\n",
      "Episode:443 meanR:17.3200 R:25.0 loss:0.0357 exploreP:0.3585\n",
      "Episode:444 meanR:17.4400 R:36.0 loss:0.0345 exploreP:0.3573\n",
      "Episode:445 meanR:16.8400 R:11.0 loss:0.0387 exploreP:0.3569\n",
      "Episode:446 meanR:16.4900 R:15.0 loss:0.0308 exploreP:0.3564\n",
      "Episode:447 meanR:16.4900 R:10.0 loss:0.0402 exploreP:0.3560\n",
      "Episode:448 meanR:16.5400 R:15.0 loss:0.0356 exploreP:0.3555\n",
      "Episode:449 meanR:16.6800 R:26.0 loss:0.0362 exploreP:0.3546\n",
      "Episode:450 meanR:16.8300 R:25.0 loss:0.0315 exploreP:0.3537\n",
      "Episode:451 meanR:16.6300 R:9.0 loss:0.0319 exploreP:0.3534\n",
      "Episode:452 meanR:16.8400 R:31.0 loss:0.0353 exploreP:0.3524\n",
      "Episode:453 meanR:16.8200 R:12.0 loss:0.0315 exploreP:0.3520\n",
      "Episode:454 meanR:16.9000 R:16.0 loss:0.0360 exploreP:0.3514\n",
      "Episode:455 meanR:16.8200 R:10.0 loss:0.0335 exploreP:0.3511\n",
      "Episode:456 meanR:16.7900 R:15.0 loss:0.0323 exploreP:0.3506\n",
      "Episode:457 meanR:16.7300 R:11.0 loss:0.0362 exploreP:0.3502\n",
      "Episode:458 meanR:16.6600 R:8.0 loss:0.0341 exploreP:0.3499\n",
      "Episode:459 meanR:16.5200 R:10.0 loss:0.0311 exploreP:0.3496\n",
      "Episode:460 meanR:16.5500 R:14.0 loss:0.0379 exploreP:0.3491\n",
      "Episode:461 meanR:16.4200 R:9.0 loss:0.0333 exploreP:0.3488\n",
      "Episode:462 meanR:16.4600 R:16.0 loss:0.0362 exploreP:0.3483\n",
      "Episode:463 meanR:16.3400 R:25.0 loss:0.0342 exploreP:0.3474\n",
      "Episode:464 meanR:16.3500 R:14.0 loss:0.0294 exploreP:0.3469\n",
      "Episode:465 meanR:16.2900 R:20.0 loss:0.0384 exploreP:0.3463\n",
      "Episode:466 meanR:16.3000 R:10.0 loss:0.0313 exploreP:0.3459\n",
      "Episode:467 meanR:16.3200 R:12.0 loss:0.0376 exploreP:0.3455\n",
      "Episode:468 meanR:16.4000 R:24.0 loss:0.0335 exploreP:0.3447\n",
      "Episode:469 meanR:16.3600 R:12.0 loss:0.0347 exploreP:0.3443\n",
      "Episode:470 meanR:16.4700 R:25.0 loss:0.0331 exploreP:0.3435\n",
      "Episode:471 meanR:16.3800 R:12.0 loss:0.0278 exploreP:0.3431\n",
      "Episode:472 meanR:16.4600 R:20.0 loss:0.0344 exploreP:0.3424\n",
      "Episode:473 meanR:16.4800 R:22.0 loss:0.0342 exploreP:0.3417\n",
      "Episode:474 meanR:16.5000 R:12.0 loss:0.0322 exploreP:0.3413\n",
      "Episode:475 meanR:16.5100 R:12.0 loss:0.0380 exploreP:0.3409\n",
      "Episode:476 meanR:16.4500 R:12.0 loss:0.0344 exploreP:0.3405\n",
      "Episode:477 meanR:16.4200 R:19.0 loss:0.0377 exploreP:0.3399\n",
      "Episode:478 meanR:16.5100 R:19.0 loss:0.0320 exploreP:0.3392\n",
      "Episode:479 meanR:16.2500 R:10.0 loss:0.0336 exploreP:0.3389\n",
      "Episode:480 meanR:16.3000 R:14.0 loss:0.0314 exploreP:0.3385\n",
      "Episode:481 meanR:16.2200 R:12.0 loss:0.0384 exploreP:0.3381\n",
      "Episode:482 meanR:16.1700 R:9.0 loss:0.0344 exploreP:0.3378\n",
      "Episode:483 meanR:16.2200 R:14.0 loss:0.0300 exploreP:0.3373\n",
      "Episode:484 meanR:16.2200 R:12.0 loss:0.0366 exploreP:0.3369\n",
      "Episode:485 meanR:16.2200 R:11.0 loss:0.0331 exploreP:0.3366\n",
      "Episode:486 meanR:16.2100 R:10.0 loss:0.0296 exploreP:0.3362\n",
      "Episode:487 meanR:16.1400 R:12.0 loss:0.0354 exploreP:0.3358\n",
      "Episode:488 meanR:16.1500 R:10.0 loss:0.0380 exploreP:0.3355\n",
      "Episode:489 meanR:16.2100 R:17.0 loss:0.0346 exploreP:0.3350\n",
      "Episode:490 meanR:16.3800 R:26.0 loss:0.0346 exploreP:0.3341\n",
      "Episode:491 meanR:16.4300 R:18.0 loss:0.0336 exploreP:0.3335\n",
      "Episode:492 meanR:16.3100 R:12.0 loss:0.0318 exploreP:0.3331\n",
      "Episode:493 meanR:16.2800 R:10.0 loss:0.0318 exploreP:0.3328\n",
      "Episode:494 meanR:16.1200 R:11.0 loss:0.0382 exploreP:0.3325\n",
      "Episode:495 meanR:16.2200 R:22.0 loss:0.0298 exploreP:0.3318\n",
      "Episode:496 meanR:16.3100 R:22.0 loss:0.0331 exploreP:0.3311\n",
      "Episode:497 meanR:16.2200 R:12.0 loss:0.0331 exploreP:0.3307\n",
      "Episode:498 meanR:16.2100 R:9.0 loss:0.0337 exploreP:0.3304\n",
      "Episode:499 meanR:16.1500 R:14.0 loss:0.0309 exploreP:0.3299\n",
      "Episode:500 meanR:16.1000 R:13.0 loss:0.0338 exploreP:0.3295\n",
      "Episode:501 meanR:16.1700 R:25.0 loss:0.0339 exploreP:0.3287\n",
      "Episode:502 meanR:16.3100 R:22.0 loss:0.0300 exploreP:0.3280\n",
      "Episode:503 meanR:16.3100 R:11.0 loss:0.0323 exploreP:0.3277\n",
      "Episode:504 meanR:16.3200 R:13.0 loss:0.0304 exploreP:0.3273\n",
      "Episode:505 meanR:16.3200 R:11.0 loss:0.0337 exploreP:0.3269\n",
      "Episode:506 meanR:16.1800 R:10.0 loss:0.0307 exploreP:0.3266\n",
      "Episode:507 meanR:16.2600 R:19.0 loss:0.0350 exploreP:0.3260\n",
      "Episode:508 meanR:16.2400 R:14.0 loss:0.0339 exploreP:0.3255\n",
      "Episode:509 meanR:16.2300 R:9.0 loss:0.0308 exploreP:0.3253\n",
      "Episode:510 meanR:16.2300 R:12.0 loss:0.0320 exploreP:0.3249\n",
      "Episode:511 meanR:16.1800 R:10.0 loss:0.0333 exploreP:0.3246\n",
      "Episode:512 meanR:16.1200 R:10.0 loss:0.0325 exploreP:0.3243\n",
      "Episode:513 meanR:15.9700 R:11.0 loss:0.0314 exploreP:0.3239\n",
      "Episode:514 meanR:15.9500 R:9.0 loss:0.0320 exploreP:0.3236\n",
      "Episode:515 meanR:15.9400 R:11.0 loss:0.0329 exploreP:0.3233\n",
      "Episode:516 meanR:15.9600 R:13.0 loss:0.0343 exploreP:0.3229\n",
      "Episode:517 meanR:15.9500 R:9.0 loss:0.0439 exploreP:0.3226\n",
      "Episode:518 meanR:15.9400 R:11.0 loss:0.0417 exploreP:0.3223\n",
      "Episode:519 meanR:16.0300 R:21.0 loss:0.0301 exploreP:0.3216\n",
      "Episode:520 meanR:16.0400 R:10.0 loss:0.0374 exploreP:0.3213\n",
      "Episode:521 meanR:16.1800 R:23.0 loss:0.0322 exploreP:0.3206\n",
      "Episode:522 meanR:16.1200 R:22.0 loss:0.0300 exploreP:0.3199\n",
      "Episode:523 meanR:16.0900 R:11.0 loss:0.0319 exploreP:0.3195\n",
      "Episode:524 meanR:15.8600 R:11.0 loss:0.0359 exploreP:0.3192\n",
      "Episode:525 meanR:15.8800 R:12.0 loss:0.0245 exploreP:0.3188\n",
      "Episode:526 meanR:15.9000 R:16.0 loss:0.0359 exploreP:0.3183\n",
      "Episode:527 meanR:15.8900 R:9.0 loss:0.0290 exploreP:0.3181\n",
      "Episode:528 meanR:15.8800 R:21.0 loss:0.0316 exploreP:0.3174\n",
      "Episode:529 meanR:15.8800 R:24.0 loss:0.0326 exploreP:0.3167\n",
      "Episode:530 meanR:15.8700 R:10.0 loss:0.0386 exploreP:0.3164\n",
      "Episode:531 meanR:15.2400 R:10.0 loss:0.0283 exploreP:0.3161\n",
      "Episode:532 meanR:15.2200 R:11.0 loss:0.0364 exploreP:0.3157\n",
      "Episode:533 meanR:15.2700 R:23.0 loss:0.0317 exploreP:0.3150\n",
      "Episode:534 meanR:15.1500 R:13.0 loss:0.0308 exploreP:0.3146\n",
      "Episode:535 meanR:15.1100 R:11.0 loss:0.0334 exploreP:0.3143\n",
      "Episode:536 meanR:14.9500 R:13.0 loss:0.0363 exploreP:0.3139\n",
      "Episode:537 meanR:14.9800 R:16.0 loss:0.0388 exploreP:0.3134\n",
      "Episode:538 meanR:14.9900 R:20.0 loss:0.0328 exploreP:0.3128\n",
      "Episode:539 meanR:14.7700 R:12.0 loss:0.0345 exploreP:0.3124\n",
      "Episode:540 meanR:14.7800 R:13.0 loss:0.0333 exploreP:0.3121\n",
      "Episode:541 meanR:14.7600 R:10.0 loss:0.0299 exploreP:0.3118\n",
      "Episode:542 meanR:14.7600 R:10.0 loss:0.0413 exploreP:0.3115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:543 meanR:14.6800 R:17.0 loss:0.0378 exploreP:0.3109\n",
      "Episode:544 meanR:14.4200 R:10.0 loss:0.0327 exploreP:0.3106\n",
      "Episode:545 meanR:14.4000 R:9.0 loss:0.0371 exploreP:0.3104\n",
      "Episode:546 meanR:14.3800 R:13.0 loss:0.0337 exploreP:0.3100\n",
      "Episode:547 meanR:14.4600 R:18.0 loss:0.0324 exploreP:0.3094\n",
      "Episode:548 meanR:14.5300 R:22.0 loss:0.0344 exploreP:0.3088\n",
      "Episode:549 meanR:14.5400 R:27.0 loss:0.0328 exploreP:0.3080\n",
      "Episode:550 meanR:14.4800 R:19.0 loss:0.0319 exploreP:0.3074\n",
      "Episode:551 meanR:14.5400 R:15.0 loss:0.0333 exploreP:0.3070\n",
      "Episode:552 meanR:14.3200 R:9.0 loss:0.0329 exploreP:0.3067\n",
      "Episode:553 meanR:14.4900 R:29.0 loss:0.0324 exploreP:0.3058\n",
      "Episode:554 meanR:14.4200 R:9.0 loss:0.0302 exploreP:0.3056\n",
      "Episode:555 meanR:14.4900 R:17.0 loss:0.0326 exploreP:0.3051\n",
      "Episode:556 meanR:14.5600 R:22.0 loss:0.0323 exploreP:0.3044\n",
      "Episode:557 meanR:14.5600 R:11.0 loss:0.0281 exploreP:0.3041\n",
      "Episode:558 meanR:14.5800 R:10.0 loss:0.0371 exploreP:0.3038\n",
      "Episode:559 meanR:14.6000 R:12.0 loss:0.0330 exploreP:0.3034\n",
      "Episode:560 meanR:14.5600 R:10.0 loss:0.0300 exploreP:0.3032\n",
      "Episode:561 meanR:14.5900 R:12.0 loss:0.0361 exploreP:0.3028\n",
      "Episode:562 meanR:14.8100 R:38.0 loss:0.0339 exploreP:0.3017\n",
      "Episode:563 meanR:14.7600 R:20.0 loss:0.0334 exploreP:0.3011\n",
      "Episode:564 meanR:14.7300 R:11.0 loss:0.0364 exploreP:0.3008\n",
      "Episode:565 meanR:14.6300 R:10.0 loss:0.0327 exploreP:0.3005\n",
      "Episode:566 meanR:14.6200 R:9.0 loss:0.0307 exploreP:0.3002\n",
      "Episode:567 meanR:14.6700 R:17.0 loss:0.0305 exploreP:0.2997\n",
      "Episode:568 meanR:14.5300 R:10.0 loss:0.0304 exploreP:0.2995\n",
      "Episode:569 meanR:14.5600 R:15.0 loss:0.0310 exploreP:0.2990\n",
      "Episode:570 meanR:14.5000 R:19.0 loss:0.0347 exploreP:0.2985\n",
      "Episode:571 meanR:14.5000 R:12.0 loss:0.0317 exploreP:0.2981\n",
      "Episode:572 meanR:14.3900 R:9.0 loss:0.0319 exploreP:0.2979\n",
      "Episode:573 meanR:14.4200 R:25.0 loss:0.0336 exploreP:0.2972\n",
      "Episode:574 meanR:14.4800 R:18.0 loss:0.0357 exploreP:0.2966\n",
      "Episode:575 meanR:14.4900 R:13.0 loss:0.0298 exploreP:0.2963\n",
      "Episode:576 meanR:14.5600 R:19.0 loss:0.0273 exploreP:0.2957\n",
      "Episode:577 meanR:14.4700 R:10.0 loss:0.0344 exploreP:0.2954\n",
      "Episode:578 meanR:14.3800 R:10.0 loss:0.0332 exploreP:0.2951\n",
      "Episode:579 meanR:14.5200 R:24.0 loss:0.0313 exploreP:0.2945\n",
      "Episode:580 meanR:14.6000 R:22.0 loss:0.0332 exploreP:0.2938\n",
      "Episode:581 meanR:14.6300 R:15.0 loss:0.0313 exploreP:0.2934\n",
      "Episode:582 meanR:14.7200 R:18.0 loss:0.0352 exploreP:0.2929\n",
      "Episode:583 meanR:14.7400 R:16.0 loss:0.0379 exploreP:0.2925\n",
      "Episode:584 meanR:14.8200 R:20.0 loss:0.0311 exploreP:0.2919\n",
      "Episode:585 meanR:14.8100 R:10.0 loss:0.0364 exploreP:0.2916\n",
      "Episode:586 meanR:14.8800 R:17.0 loss:0.0349 exploreP:0.2911\n",
      "Episode:587 meanR:15.0000 R:24.0 loss:0.0334 exploreP:0.2905\n",
      "Episode:588 meanR:15.0800 R:18.0 loss:0.0310 exploreP:0.2899\n",
      "Episode:589 meanR:15.0000 R:9.0 loss:0.0328 exploreP:0.2897\n",
      "Episode:590 meanR:14.9000 R:16.0 loss:0.0310 exploreP:0.2892\n",
      "Episode:591 meanR:14.9200 R:20.0 loss:0.0362 exploreP:0.2887\n",
      "Episode:592 meanR:15.0100 R:21.0 loss:0.0332 exploreP:0.2881\n",
      "Episode:593 meanR:15.0800 R:17.0 loss:0.0358 exploreP:0.2876\n",
      "Episode:594 meanR:15.0900 R:12.0 loss:0.0290 exploreP:0.2873\n",
      "Episode:595 meanR:15.0400 R:17.0 loss:0.0306 exploreP:0.2868\n",
      "Episode:596 meanR:15.0400 R:22.0 loss:0.0314 exploreP:0.2862\n",
      "Episode:597 meanR:15.0200 R:10.0 loss:0.0320 exploreP:0.2859\n",
      "Episode:598 meanR:15.0400 R:11.0 loss:0.0291 exploreP:0.2856\n",
      "Episode:599 meanR:15.0300 R:13.0 loss:0.0296 exploreP:0.2853\n",
      "Episode:600 meanR:14.9900 R:9.0 loss:0.0312 exploreP:0.2850\n",
      "Episode:601 meanR:14.8500 R:11.0 loss:0.0282 exploreP:0.2847\n",
      "Episode:602 meanR:14.7400 R:11.0 loss:0.0313 exploreP:0.2844\n",
      "Episode:603 meanR:14.7400 R:11.0 loss:0.0290 exploreP:0.2841\n",
      "Episode:604 meanR:14.8500 R:24.0 loss:0.0292 exploreP:0.2835\n",
      "Episode:605 meanR:14.8300 R:9.0 loss:0.0290 exploreP:0.2832\n",
      "Episode:606 meanR:14.8300 R:10.0 loss:0.0307 exploreP:0.2830\n",
      "Episode:607 meanR:14.8700 R:23.0 loss:0.0316 exploreP:0.2823\n",
      "Episode:608 meanR:14.8600 R:13.0 loss:0.0322 exploreP:0.2820\n",
      "Episode:609 meanR:14.8700 R:10.0 loss:0.0312 exploreP:0.2817\n",
      "Episode:610 meanR:14.8500 R:10.0 loss:0.0298 exploreP:0.2814\n",
      "Episode:611 meanR:14.9100 R:16.0 loss:0.0336 exploreP:0.2810\n",
      "Episode:612 meanR:14.9800 R:17.0 loss:0.0308 exploreP:0.2805\n",
      "Episode:613 meanR:14.9900 R:12.0 loss:0.0405 exploreP:0.2802\n",
      "Episode:614 meanR:15.0200 R:12.0 loss:0.0301 exploreP:0.2799\n",
      "Episode:615 meanR:15.0500 R:14.0 loss:0.0288 exploreP:0.2795\n",
      "Episode:616 meanR:15.0800 R:16.0 loss:0.0290 exploreP:0.2791\n",
      "Episode:617 meanR:15.1000 R:11.0 loss:0.0302 exploreP:0.2788\n",
      "Episode:618 meanR:15.0900 R:10.0 loss:0.0267 exploreP:0.2785\n",
      "Episode:619 meanR:15.0200 R:14.0 loss:0.0303 exploreP:0.2781\n",
      "Episode:620 meanR:15.0800 R:16.0 loss:0.0376 exploreP:0.2777\n",
      "Episode:621 meanR:15.0700 R:22.0 loss:0.0333 exploreP:0.2771\n",
      "Episode:622 meanR:14.9500 R:10.0 loss:0.0322 exploreP:0.2769\n",
      "Episode:623 meanR:15.0300 R:19.0 loss:0.0256 exploreP:0.2763\n",
      "Episode:624 meanR:15.1200 R:20.0 loss:0.0363 exploreP:0.2758\n",
      "Episode:625 meanR:15.1000 R:10.0 loss:0.0363 exploreP:0.2756\n",
      "Episode:626 meanR:15.0600 R:12.0 loss:0.0291 exploreP:0.2752\n",
      "Episode:627 meanR:15.1800 R:21.0 loss:0.0342 exploreP:0.2747\n",
      "Episode:628 meanR:15.0900 R:12.0 loss:0.0334 exploreP:0.2744\n",
      "Episode:629 meanR:15.0300 R:18.0 loss:0.0319 exploreP:0.2739\n",
      "Episode:630 meanR:15.1000 R:17.0 loss:0.0306 exploreP:0.2734\n",
      "Episode:631 meanR:15.3300 R:33.0 loss:0.0326 exploreP:0.2726\n",
      "Episode:632 meanR:15.3500 R:13.0 loss:0.0291 exploreP:0.2722\n",
      "Episode:633 meanR:15.2300 R:11.0 loss:0.0287 exploreP:0.2719\n",
      "Episode:634 meanR:15.2500 R:15.0 loss:0.0370 exploreP:0.2715\n",
      "Episode:635 meanR:15.2400 R:10.0 loss:0.0271 exploreP:0.2713\n",
      "Episode:636 meanR:15.2400 R:13.0 loss:0.0306 exploreP:0.2709\n",
      "Episode:637 meanR:15.2800 R:20.0 loss:0.0334 exploreP:0.2704\n",
      "Episode:638 meanR:15.3000 R:22.0 loss:0.0344 exploreP:0.2699\n",
      "Episode:639 meanR:15.3700 R:19.0 loss:0.0289 exploreP:0.2694\n",
      "Episode:640 meanR:15.4200 R:18.0 loss:0.0270 exploreP:0.2689\n",
      "Episode:641 meanR:15.4400 R:12.0 loss:0.0328 exploreP:0.2686\n",
      "Episode:642 meanR:15.4800 R:14.0 loss:0.0286 exploreP:0.2682\n",
      "Episode:643 meanR:15.4100 R:10.0 loss:0.0295 exploreP:0.2680\n",
      "Episode:644 meanR:15.4200 R:11.0 loss:0.0298 exploreP:0.2677\n",
      "Episode:645 meanR:15.5100 R:18.0 loss:0.0281 exploreP:0.2672\n",
      "Episode:646 meanR:15.5500 R:17.0 loss:0.0281 exploreP:0.2668\n",
      "Episode:647 meanR:15.5200 R:15.0 loss:0.0330 exploreP:0.2664\n",
      "Episode:648 meanR:15.5000 R:20.0 loss:0.0295 exploreP:0.2659\n",
      "Episode:649 meanR:15.4400 R:21.0 loss:0.0377 exploreP:0.2653\n",
      "Episode:650 meanR:15.3500 R:10.0 loss:0.0321 exploreP:0.2651\n",
      "Episode:651 meanR:15.2900 R:9.0 loss:0.0289 exploreP:0.2649\n",
      "Episode:652 meanR:15.3900 R:19.0 loss:0.0338 exploreP:0.2644\n",
      "Episode:653 meanR:15.3400 R:24.0 loss:0.0317 exploreP:0.2638\n",
      "Episode:654 meanR:15.3800 R:13.0 loss:0.0283 exploreP:0.2634\n",
      "Episode:655 meanR:15.4500 R:24.0 loss:0.0324 exploreP:0.2628\n",
      "Episode:656 meanR:15.3900 R:16.0 loss:0.0340 exploreP:0.2624\n",
      "Episode:657 meanR:15.3800 R:10.0 loss:0.0311 exploreP:0.2622\n",
      "Episode:658 meanR:15.3900 R:11.0 loss:0.0270 exploreP:0.2619\n",
      "Episode:659 meanR:15.4800 R:21.0 loss:0.0314 exploreP:0.2614\n",
      "Episode:660 meanR:15.6100 R:23.0 loss:0.0317 exploreP:0.2608\n",
      "Episode:661 meanR:15.6300 R:14.0 loss:0.0291 exploreP:0.2604\n",
      "Episode:662 meanR:15.4800 R:23.0 loss:0.0275 exploreP:0.2599\n",
      "Episode:663 meanR:15.4400 R:16.0 loss:0.0339 exploreP:0.2595\n",
      "Episode:664 meanR:15.5200 R:19.0 loss:0.0286 exploreP:0.2590\n",
      "Episode:665 meanR:15.6600 R:24.0 loss:0.0299 exploreP:0.2584\n",
      "Episode:666 meanR:15.7300 R:16.0 loss:0.0286 exploreP:0.2580\n",
      "Episode:667 meanR:15.7100 R:15.0 loss:0.0313 exploreP:0.2576\n",
      "Episode:668 meanR:15.7200 R:11.0 loss:0.0317 exploreP:0.2574\n",
      "Episode:669 meanR:15.7100 R:14.0 loss:0.0293 exploreP:0.2570\n",
      "Episode:670 meanR:15.6800 R:16.0 loss:0.0285 exploreP:0.2566\n",
      "Episode:671 meanR:15.7400 R:18.0 loss:0.0290 exploreP:0.2562\n",
      "Episode:672 meanR:15.8200 R:17.0 loss:0.0296 exploreP:0.2557\n",
      "Episode:673 meanR:15.8200 R:25.0 loss:0.0333 exploreP:0.2551\n",
      "Episode:674 meanR:15.8900 R:25.0 loss:0.0290 exploreP:0.2545\n",
      "Episode:675 meanR:15.9900 R:23.0 loss:0.0336 exploreP:0.2540\n",
      "Episode:676 meanR:15.9000 R:10.0 loss:0.0332 exploreP:0.2537\n",
      "Episode:677 meanR:15.9300 R:13.0 loss:0.0267 exploreP:0.2534\n",
      "Episode:678 meanR:16.0300 R:20.0 loss:0.0327 exploreP:0.2529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:679 meanR:15.9100 R:12.0 loss:0.0250 exploreP:0.2526\n",
      "Episode:680 meanR:15.8600 R:17.0 loss:0.0291 exploreP:0.2522\n",
      "Episode:681 meanR:15.8100 R:10.0 loss:0.0287 exploreP:0.2520\n",
      "Episode:682 meanR:15.7900 R:16.0 loss:0.0261 exploreP:0.2516\n",
      "Episode:683 meanR:15.7700 R:14.0 loss:0.0355 exploreP:0.2512\n",
      "Episode:684 meanR:15.7300 R:16.0 loss:0.0315 exploreP:0.2509\n",
      "Episode:685 meanR:15.8100 R:18.0 loss:0.0277 exploreP:0.2504\n",
      "Episode:686 meanR:15.7900 R:15.0 loss:0.0295 exploreP:0.2501\n",
      "Episode:687 meanR:15.7300 R:18.0 loss:0.0313 exploreP:0.2496\n",
      "Episode:688 meanR:15.7300 R:18.0 loss:0.0332 exploreP:0.2492\n",
      "Episode:689 meanR:15.7900 R:15.0 loss:0.0314 exploreP:0.2488\n",
      "Episode:690 meanR:15.7800 R:15.0 loss:0.0319 exploreP:0.2485\n",
      "Episode:691 meanR:15.6800 R:10.0 loss:0.0258 exploreP:0.2482\n",
      "Episode:692 meanR:15.5700 R:10.0 loss:0.0278 exploreP:0.2480\n",
      "Episode:693 meanR:15.5800 R:18.0 loss:0.0336 exploreP:0.2476\n",
      "Episode:694 meanR:15.6300 R:17.0 loss:0.0338 exploreP:0.2472\n",
      "Episode:695 meanR:15.6400 R:18.0 loss:0.0282 exploreP:0.2468\n",
      "Episode:696 meanR:15.6000 R:18.0 loss:0.0298 exploreP:0.2463\n",
      "Episode:697 meanR:15.7300 R:23.0 loss:0.0321 exploreP:0.2458\n",
      "Episode:698 meanR:15.8200 R:20.0 loss:0.0314 exploreP:0.2453\n",
      "Episode:699 meanR:15.8300 R:14.0 loss:0.0318 exploreP:0.2450\n",
      "Episode:700 meanR:15.9100 R:17.0 loss:0.0309 exploreP:0.2446\n",
      "Episode:701 meanR:15.9700 R:17.0 loss:0.0287 exploreP:0.2442\n",
      "Episode:702 meanR:16.0800 R:22.0 loss:0.0295 exploreP:0.2437\n",
      "Episode:703 meanR:16.1700 R:20.0 loss:0.0332 exploreP:0.2432\n",
      "Episode:704 meanR:16.0400 R:11.0 loss:0.0310 exploreP:0.2429\n",
      "Episode:705 meanR:16.1500 R:20.0 loss:0.0263 exploreP:0.2425\n",
      "Episode:706 meanR:16.1800 R:13.0 loss:0.0336 exploreP:0.2422\n",
      "Episode:707 meanR:16.1300 R:18.0 loss:0.0287 exploreP:0.2418\n",
      "Episode:708 meanR:16.1800 R:18.0 loss:0.0289 exploreP:0.2413\n",
      "Episode:709 meanR:16.1800 R:10.0 loss:0.0278 exploreP:0.2411\n",
      "Episode:710 meanR:16.2800 R:20.0 loss:0.0309 exploreP:0.2407\n",
      "Episode:711 meanR:16.3200 R:20.0 loss:0.0332 exploreP:0.2402\n",
      "Episode:712 meanR:16.2500 R:10.0 loss:0.0290 exploreP:0.2400\n",
      "Episode:713 meanR:16.2200 R:9.0 loss:0.0324 exploreP:0.2398\n",
      "Episode:714 meanR:16.2200 R:12.0 loss:0.0310 exploreP:0.2395\n",
      "Episode:715 meanR:16.2400 R:16.0 loss:0.0355 exploreP:0.2391\n",
      "Episode:716 meanR:16.2400 R:16.0 loss:0.0322 exploreP:0.2387\n",
      "Episode:717 meanR:16.2700 R:14.0 loss:0.0284 exploreP:0.2384\n",
      "Episode:718 meanR:16.2800 R:11.0 loss:0.0306 exploreP:0.2382\n",
      "Episode:719 meanR:16.3100 R:17.0 loss:0.0287 exploreP:0.2378\n",
      "Episode:720 meanR:16.3300 R:18.0 loss:0.0356 exploreP:0.2374\n",
      "Episode:721 meanR:16.2900 R:18.0 loss:0.0373 exploreP:0.2370\n",
      "Episode:722 meanR:16.3700 R:18.0 loss:0.0276 exploreP:0.2366\n",
      "Episode:723 meanR:16.3600 R:18.0 loss:0.0329 exploreP:0.2362\n",
      "Episode:724 meanR:16.3400 R:18.0 loss:0.0271 exploreP:0.2357\n",
      "Episode:725 meanR:16.4700 R:23.0 loss:0.0333 exploreP:0.2352\n",
      "Episode:726 meanR:16.5200 R:17.0 loss:0.0281 exploreP:0.2348\n",
      "Episode:727 meanR:16.5200 R:21.0 loss:0.0347 exploreP:0.2344\n",
      "Episode:728 meanR:16.5700 R:17.0 loss:0.0291 exploreP:0.2340\n",
      "Episode:729 meanR:16.5800 R:19.0 loss:0.0321 exploreP:0.2336\n",
      "Episode:730 meanR:16.5000 R:9.0 loss:0.0286 exploreP:0.2334\n",
      "Episode:731 meanR:16.3100 R:14.0 loss:0.0311 exploreP:0.2331\n",
      "Episode:732 meanR:16.2800 R:10.0 loss:0.0299 exploreP:0.2328\n",
      "Episode:733 meanR:16.3300 R:16.0 loss:0.0291 exploreP:0.2325\n",
      "Episode:734 meanR:16.3900 R:21.0 loss:0.0277 exploreP:0.2320\n",
      "Episode:735 meanR:16.4300 R:14.0 loss:0.0303 exploreP:0.2317\n",
      "Episode:736 meanR:16.5000 R:20.0 loss:0.0317 exploreP:0.2313\n",
      "Episode:737 meanR:16.4700 R:17.0 loss:0.0312 exploreP:0.2309\n",
      "Episode:738 meanR:16.3700 R:12.0 loss:0.0383 exploreP:0.2306\n",
      "Episode:739 meanR:16.3100 R:13.0 loss:0.0287 exploreP:0.2303\n",
      "Episode:740 meanR:16.3200 R:19.0 loss:0.0261 exploreP:0.2299\n",
      "Episode:741 meanR:16.3000 R:10.0 loss:0.0304 exploreP:0.2297\n",
      "Episode:742 meanR:16.3800 R:22.0 loss:0.0287 exploreP:0.2292\n",
      "Episode:743 meanR:16.4700 R:19.0 loss:0.0301 exploreP:0.2288\n",
      "Episode:744 meanR:16.5400 R:18.0 loss:0.0286 exploreP:0.2284\n",
      "Episode:745 meanR:16.5400 R:18.0 loss:0.0407 exploreP:0.2280\n",
      "Episode:746 meanR:16.4900 R:12.0 loss:0.0272 exploreP:0.2277\n",
      "Episode:747 meanR:16.4900 R:15.0 loss:0.0291 exploreP:0.2274\n",
      "Episode:748 meanR:16.4200 R:13.0 loss:0.0352 exploreP:0.2271\n",
      "Episode:749 meanR:16.3000 R:9.0 loss:0.0313 exploreP:0.2269\n",
      "Episode:750 meanR:16.4000 R:20.0 loss:0.0278 exploreP:0.2265\n",
      "Episode:751 meanR:16.4100 R:10.0 loss:0.0333 exploreP:0.2263\n",
      "Episode:752 meanR:16.3800 R:16.0 loss:0.0298 exploreP:0.2259\n",
      "Episode:753 meanR:16.3200 R:18.0 loss:0.0318 exploreP:0.2256\n",
      "Episode:754 meanR:16.4000 R:21.0 loss:0.0313 exploreP:0.2251\n",
      "Episode:755 meanR:16.2800 R:12.0 loss:0.0305 exploreP:0.2248\n",
      "Episode:756 meanR:16.3300 R:21.0 loss:0.0312 exploreP:0.2244\n",
      "Episode:757 meanR:16.3100 R:8.0 loss:0.0286 exploreP:0.2242\n",
      "Episode:758 meanR:16.3800 R:18.0 loss:0.0283 exploreP:0.2238\n",
      "Episode:759 meanR:16.2500 R:8.0 loss:0.0297 exploreP:0.2237\n",
      "Episode:760 meanR:16.1400 R:12.0 loss:0.0274 exploreP:0.2234\n",
      "Episode:761 meanR:16.1500 R:15.0 loss:0.0262 exploreP:0.2231\n",
      "Episode:762 meanR:16.0800 R:16.0 loss:0.0328 exploreP:0.2227\n",
      "Episode:763 meanR:16.0800 R:16.0 loss:0.0290 exploreP:0.2224\n",
      "Episode:764 meanR:16.0000 R:11.0 loss:0.0285 exploreP:0.2222\n",
      "Episode:765 meanR:15.9400 R:18.0 loss:0.0341 exploreP:0.2218\n",
      "Episode:766 meanR:15.9400 R:16.0 loss:0.0305 exploreP:0.2215\n",
      "Episode:767 meanR:15.9400 R:15.0 loss:0.0308 exploreP:0.2211\n",
      "Episode:768 meanR:15.9300 R:10.0 loss:0.0300 exploreP:0.2209\n",
      "Episode:769 meanR:15.9600 R:17.0 loss:0.0307 exploreP:0.2206\n",
      "Episode:770 meanR:15.8800 R:8.0 loss:0.0308 exploreP:0.2204\n",
      "Episode:771 meanR:15.8100 R:11.0 loss:0.0274 exploreP:0.2202\n",
      "Episode:772 meanR:15.7400 R:10.0 loss:0.0381 exploreP:0.2200\n",
      "Episode:773 meanR:15.7700 R:28.0 loss:0.0296 exploreP:0.2194\n",
      "Episode:774 meanR:15.6100 R:9.0 loss:0.0306 exploreP:0.2192\n",
      "Episode:775 meanR:15.5500 R:17.0 loss:0.0318 exploreP:0.2188\n",
      "Episode:776 meanR:15.6200 R:17.0 loss:0.0326 exploreP:0.2185\n",
      "Episode:777 meanR:15.6900 R:20.0 loss:0.0314 exploreP:0.2181\n",
      "Episode:778 meanR:15.6500 R:16.0 loss:0.0271 exploreP:0.2177\n",
      "Episode:779 meanR:15.6700 R:14.0 loss:0.0285 exploreP:0.2174\n",
      "Episode:780 meanR:15.6700 R:17.0 loss:0.0293 exploreP:0.2171\n",
      "Episode:781 meanR:15.7200 R:15.0 loss:0.0333 exploreP:0.2168\n",
      "Episode:782 meanR:15.6800 R:12.0 loss:0.0360 exploreP:0.2165\n",
      "Episode:783 meanR:15.7300 R:19.0 loss:0.0285 exploreP:0.2161\n",
      "Episode:784 meanR:15.7500 R:18.0 loss:0.0319 exploreP:0.2158\n",
      "Episode:785 meanR:15.7900 R:22.0 loss:0.0298 exploreP:0.2153\n",
      "Episode:786 meanR:15.7400 R:10.0 loss:0.0307 exploreP:0.2151\n",
      "Episode:787 meanR:15.7200 R:16.0 loss:0.0289 exploreP:0.2148\n",
      "Episode:788 meanR:15.7300 R:19.0 loss:0.0300 exploreP:0.2144\n",
      "Episode:789 meanR:15.6900 R:11.0 loss:0.0301 exploreP:0.2142\n",
      "Episode:790 meanR:15.6400 R:10.0 loss:0.0370 exploreP:0.2140\n",
      "Episode:791 meanR:15.7000 R:16.0 loss:0.0297 exploreP:0.2136\n",
      "Episode:792 meanR:15.7100 R:11.0 loss:0.0342 exploreP:0.2134\n",
      "Episode:793 meanR:15.6200 R:9.0 loss:0.0296 exploreP:0.2132\n",
      "Episode:794 meanR:15.6000 R:15.0 loss:0.0279 exploreP:0.2129\n",
      "Episode:795 meanR:15.6200 R:20.0 loss:0.0276 exploreP:0.2125\n",
      "Episode:796 meanR:15.6100 R:17.0 loss:0.0308 exploreP:0.2122\n",
      "Episode:797 meanR:15.6000 R:22.0 loss:0.0282 exploreP:0.2117\n",
      "Episode:798 meanR:15.5100 R:11.0 loss:0.0258 exploreP:0.2115\n",
      "Episode:799 meanR:15.5400 R:17.0 loss:0.0293 exploreP:0.2112\n",
      "Episode:800 meanR:15.4800 R:11.0 loss:0.0255 exploreP:0.2109\n",
      "Episode:801 meanR:15.5000 R:19.0 loss:0.0269 exploreP:0.2106\n",
      "Episode:802 meanR:15.4300 R:15.0 loss:0.0363 exploreP:0.2103\n",
      "Episode:803 meanR:15.3600 R:13.0 loss:0.0285 exploreP:0.2100\n",
      "Episode:804 meanR:15.4000 R:15.0 loss:0.0293 exploreP:0.2097\n",
      "Episode:805 meanR:15.3000 R:10.0 loss:0.0271 exploreP:0.2095\n",
      "Episode:806 meanR:15.3800 R:21.0 loss:0.0293 exploreP:0.2091\n",
      "Episode:807 meanR:15.3300 R:13.0 loss:0.0304 exploreP:0.2088\n",
      "Episode:808 meanR:15.3700 R:22.0 loss:0.0287 exploreP:0.2084\n",
      "Episode:809 meanR:15.4100 R:14.0 loss:0.0322 exploreP:0.2081\n",
      "Episode:810 meanR:15.3300 R:12.0 loss:0.0308 exploreP:0.2079\n",
      "Episode:811 meanR:15.3000 R:17.0 loss:0.0260 exploreP:0.2075\n",
      "Episode:812 meanR:15.4000 R:20.0 loss:0.0260 exploreP:0.2071\n",
      "Episode:813 meanR:15.4900 R:18.0 loss:0.0328 exploreP:0.2068\n",
      "Episode:814 meanR:15.5300 R:16.0 loss:0.0298 exploreP:0.2065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:815 meanR:15.5600 R:19.0 loss:0.0314 exploreP:0.2061\n",
      "Episode:816 meanR:15.5900 R:19.0 loss:0.0266 exploreP:0.2057\n",
      "Episode:817 meanR:15.6100 R:16.0 loss:0.0317 exploreP:0.2054\n",
      "Episode:818 meanR:15.6000 R:10.0 loss:0.0293 exploreP:0.2052\n",
      "Episode:819 meanR:15.5300 R:10.0 loss:0.0237 exploreP:0.2050\n",
      "Episode:820 meanR:15.4700 R:12.0 loss:0.0277 exploreP:0.2048\n",
      "Episode:821 meanR:15.4500 R:16.0 loss:0.0296 exploreP:0.2045\n",
      "Episode:822 meanR:15.3900 R:12.0 loss:0.0264 exploreP:0.2042\n",
      "Episode:823 meanR:15.4000 R:19.0 loss:0.0312 exploreP:0.2039\n",
      "Episode:824 meanR:15.3900 R:17.0 loss:0.0329 exploreP:0.2035\n",
      "Episode:825 meanR:15.3400 R:18.0 loss:0.0254 exploreP:0.2032\n",
      "Episode:826 meanR:15.2900 R:12.0 loss:0.0256 exploreP:0.2030\n",
      "Episode:827 meanR:15.2400 R:16.0 loss:0.0269 exploreP:0.2027\n",
      "Episode:828 meanR:15.2000 R:13.0 loss:0.0295 exploreP:0.2024\n",
      "Episode:829 meanR:15.1200 R:11.0 loss:0.0253 exploreP:0.2022\n",
      "Episode:830 meanR:15.1300 R:10.0 loss:0.0274 exploreP:0.2020\n",
      "Episode:831 meanR:15.1800 R:19.0 loss:0.0292 exploreP:0.2016\n",
      "Episode:832 meanR:15.2200 R:14.0 loss:0.0273 exploreP:0.2014\n",
      "Episode:833 meanR:15.2400 R:18.0 loss:0.0309 exploreP:0.2010\n",
      "Episode:834 meanR:15.1900 R:16.0 loss:0.0309 exploreP:0.2007\n",
      "Episode:835 meanR:15.1600 R:11.0 loss:0.0253 exploreP:0.2005\n",
      "Episode:836 meanR:15.1000 R:14.0 loss:0.0297 exploreP:0.2002\n",
      "Episode:837 meanR:15.0900 R:16.0 loss:0.0247 exploreP:0.1999\n",
      "Episode:838 meanR:15.1100 R:14.0 loss:0.0263 exploreP:0.1997\n",
      "Episode:839 meanR:15.0700 R:9.0 loss:0.0275 exploreP:0.1995\n",
      "Episode:840 meanR:15.0200 R:14.0 loss:0.0285 exploreP:0.1992\n",
      "Episode:841 meanR:15.0200 R:10.0 loss:0.0365 exploreP:0.1990\n",
      "Episode:842 meanR:14.9500 R:15.0 loss:0.0265 exploreP:0.1988\n",
      "Episode:843 meanR:14.8900 R:13.0 loss:0.0265 exploreP:0.1985\n",
      "Episode:844 meanR:14.8200 R:11.0 loss:0.0307 exploreP:0.1983\n",
      "Episode:845 meanR:14.7900 R:15.0 loss:0.0268 exploreP:0.1980\n",
      "Episode:846 meanR:14.7600 R:9.0 loss:0.0366 exploreP:0.1979\n",
      "Episode:847 meanR:14.7900 R:18.0 loss:0.0253 exploreP:0.1975\n",
      "Episode:848 meanR:14.8400 R:18.0 loss:0.0278 exploreP:0.1972\n",
      "Episode:849 meanR:14.8800 R:13.0 loss:0.0316 exploreP:0.1969\n",
      "Episode:850 meanR:14.8200 R:14.0 loss:0.0288 exploreP:0.1967\n",
      "Episode:851 meanR:14.8800 R:16.0 loss:0.0303 exploreP:0.1964\n",
      "Episode:852 meanR:14.8700 R:15.0 loss:0.0249 exploreP:0.1961\n",
      "Episode:853 meanR:14.7800 R:9.0 loss:0.0286 exploreP:0.1959\n",
      "Episode:854 meanR:14.7000 R:13.0 loss:0.0295 exploreP:0.1957\n",
      "Episode:855 meanR:14.7600 R:18.0 loss:0.0302 exploreP:0.1954\n",
      "Episode:856 meanR:14.7200 R:17.0 loss:0.0364 exploreP:0.1950\n",
      "Episode:857 meanR:14.7700 R:13.0 loss:0.0293 exploreP:0.1948\n",
      "Episode:858 meanR:14.7300 R:14.0 loss:0.0291 exploreP:0.1945\n",
      "Episode:859 meanR:14.8300 R:18.0 loss:0.0285 exploreP:0.1942\n",
      "Episode:860 meanR:14.8000 R:9.0 loss:0.0284 exploreP:0.1940\n",
      "Episode:861 meanR:14.8100 R:16.0 loss:0.0295 exploreP:0.1938\n",
      "Episode:862 meanR:14.7700 R:12.0 loss:0.0340 exploreP:0.1935\n",
      "Episode:863 meanR:14.7100 R:10.0 loss:0.0259 exploreP:0.1934\n",
      "Episode:864 meanR:14.7700 R:17.0 loss:0.0310 exploreP:0.1930\n",
      "Episode:865 meanR:14.7900 R:20.0 loss:0.0260 exploreP:0.1927\n",
      "Episode:866 meanR:14.8200 R:19.0 loss:0.0318 exploreP:0.1923\n",
      "Episode:867 meanR:14.8600 R:19.0 loss:0.0318 exploreP:0.1920\n",
      "Episode:868 meanR:14.9600 R:20.0 loss:0.0298 exploreP:0.1916\n",
      "Episode:869 meanR:14.9700 R:18.0 loss:0.0323 exploreP:0.1913\n",
      "Episode:870 meanR:15.0200 R:13.0 loss:0.0294 exploreP:0.1911\n",
      "Episode:871 meanR:15.0500 R:14.0 loss:0.0299 exploreP:0.1908\n",
      "Episode:872 meanR:15.1200 R:17.0 loss:0.0306 exploreP:0.1905\n",
      "Episode:873 meanR:15.0300 R:19.0 loss:0.0299 exploreP:0.1902\n",
      "Episode:874 meanR:15.1100 R:17.0 loss:0.0317 exploreP:0.1898\n",
      "Episode:875 meanR:15.1200 R:18.0 loss:0.0296 exploreP:0.1895\n",
      "Episode:876 meanR:15.0900 R:14.0 loss:0.0358 exploreP:0.1893\n",
      "Episode:877 meanR:15.0400 R:15.0 loss:0.0361 exploreP:0.1890\n",
      "Episode:878 meanR:15.0100 R:13.0 loss:0.0367 exploreP:0.1888\n",
      "Episode:879 meanR:15.0500 R:18.0 loss:0.0344 exploreP:0.1884\n",
      "Episode:880 meanR:15.0300 R:15.0 loss:0.0363 exploreP:0.1882\n",
      "Episode:881 meanR:15.0500 R:17.0 loss:0.0289 exploreP:0.1879\n",
      "Episode:882 meanR:15.0900 R:16.0 loss:0.0384 exploreP:0.1876\n",
      "Episode:883 meanR:15.0700 R:17.0 loss:0.0312 exploreP:0.1873\n",
      "Episode:884 meanR:15.0800 R:19.0 loss:0.0311 exploreP:0.1870\n",
      "Episode:885 meanR:14.9600 R:10.0 loss:0.0373 exploreP:0.1868\n",
      "Episode:886 meanR:14.9800 R:12.0 loss:0.0328 exploreP:0.1866\n",
      "Episode:887 meanR:15.0000 R:18.0 loss:0.0327 exploreP:0.1863\n",
      "Episode:888 meanR:14.9500 R:14.0 loss:0.0370 exploreP:0.1860\n",
      "Episode:889 meanR:14.9800 R:14.0 loss:0.0261 exploreP:0.1858\n",
      "Episode:890 meanR:15.0400 R:16.0 loss:0.0365 exploreP:0.1855\n",
      "Episode:891 meanR:15.0300 R:15.0 loss:0.0332 exploreP:0.1852\n",
      "Episode:892 meanR:15.1500 R:23.0 loss:0.0313 exploreP:0.1848\n",
      "Episode:893 meanR:15.2200 R:16.0 loss:0.0316 exploreP:0.1845\n",
      "Episode:894 meanR:15.2400 R:17.0 loss:0.0334 exploreP:0.1842\n",
      "Episode:895 meanR:15.2000 R:16.0 loss:0.0305 exploreP:0.1840\n",
      "Episode:896 meanR:15.1600 R:13.0 loss:0.0347 exploreP:0.1837\n",
      "Episode:897 meanR:15.1400 R:20.0 loss:0.0352 exploreP:0.1834\n",
      "Episode:898 meanR:15.2100 R:18.0 loss:0.0325 exploreP:0.1831\n",
      "Episode:899 meanR:15.1900 R:15.0 loss:0.0285 exploreP:0.1828\n",
      "Episode:900 meanR:15.2100 R:13.0 loss:0.0290 exploreP:0.1826\n",
      "Episode:901 meanR:15.1700 R:15.0 loss:0.0378 exploreP:0.1823\n",
      "Episode:902 meanR:15.1800 R:16.0 loss:0.0333 exploreP:0.1821\n",
      "Episode:903 meanR:15.2100 R:16.0 loss:0.0329 exploreP:0.1818\n",
      "Episode:904 meanR:15.2300 R:17.0 loss:0.0327 exploreP:0.1815\n",
      "Episode:905 meanR:15.2600 R:13.0 loss:0.0298 exploreP:0.1813\n",
      "Episode:906 meanR:15.1800 R:13.0 loss:0.0339 exploreP:0.1810\n",
      "Episode:907 meanR:15.1700 R:12.0 loss:0.0329 exploreP:0.1808\n",
      "Episode:908 meanR:15.1200 R:17.0 loss:0.0309 exploreP:0.1805\n",
      "Episode:909 meanR:15.1100 R:13.0 loss:0.0350 exploreP:0.1803\n",
      "Episode:910 meanR:15.1400 R:15.0 loss:0.0300 exploreP:0.1801\n",
      "Episode:911 meanR:15.1500 R:18.0 loss:0.0351 exploreP:0.1798\n",
      "Episode:912 meanR:15.0900 R:14.0 loss:0.0368 exploreP:0.1795\n",
      "Episode:913 meanR:15.0900 R:18.0 loss:0.0308 exploreP:0.1792\n",
      "Episode:914 meanR:15.1000 R:17.0 loss:0.0320 exploreP:0.1789\n",
      "Episode:915 meanR:15.3000 R:39.0 loss:0.0325 exploreP:0.1783\n",
      "Episode:916 meanR:15.2600 R:15.0 loss:0.0373 exploreP:0.1780\n",
      "Episode:917 meanR:15.2800 R:18.0 loss:0.0358 exploreP:0.1777\n",
      "Episode:918 meanR:15.3400 R:16.0 loss:0.0305 exploreP:0.1775\n",
      "Episode:919 meanR:15.4200 R:18.0 loss:0.0231 exploreP:0.1772\n",
      "Episode:920 meanR:15.4500 R:15.0 loss:0.0334 exploreP:0.1769\n",
      "Episode:921 meanR:15.4500 R:16.0 loss:0.0305 exploreP:0.1766\n",
      "Episode:922 meanR:15.5100 R:18.0 loss:0.0314 exploreP:0.1763\n",
      "Episode:923 meanR:15.4900 R:17.0 loss:0.0347 exploreP:0.1761\n",
      "Episode:924 meanR:15.4900 R:17.0 loss:0.0330 exploreP:0.1758\n",
      "Episode:925 meanR:15.4800 R:17.0 loss:0.0345 exploreP:0.1755\n",
      "Episode:926 meanR:15.5500 R:19.0 loss:0.0379 exploreP:0.1752\n",
      "Episode:927 meanR:15.5400 R:15.0 loss:0.0294 exploreP:0.1749\n",
      "Episode:928 meanR:15.5100 R:10.0 loss:0.0325 exploreP:0.1748\n",
      "Episode:929 meanR:15.5000 R:10.0 loss:0.0310 exploreP:0.1746\n",
      "Episode:930 meanR:15.5500 R:15.0 loss:0.0309 exploreP:0.1744\n",
      "Episode:931 meanR:15.5500 R:19.0 loss:0.0329 exploreP:0.1740\n",
      "Episode:932 meanR:15.6000 R:19.0 loss:0.0333 exploreP:0.1737\n",
      "Episode:933 meanR:15.6100 R:19.0 loss:0.0322 exploreP:0.1734\n",
      "Episode:934 meanR:15.6400 R:19.0 loss:0.0353 exploreP:0.1731\n",
      "Episode:935 meanR:15.6400 R:11.0 loss:0.0334 exploreP:0.1729\n",
      "Episode:936 meanR:15.6700 R:17.0 loss:0.0299 exploreP:0.1727\n",
      "Episode:937 meanR:15.6400 R:13.0 loss:0.0348 exploreP:0.1724\n",
      "Episode:938 meanR:15.6500 R:15.0 loss:0.0353 exploreP:0.1722\n",
      "Episode:939 meanR:15.7100 R:15.0 loss:0.0355 exploreP:0.1720\n",
      "Episode:940 meanR:15.7300 R:16.0 loss:0.0299 exploreP:0.1717\n",
      "Episode:941 meanR:15.8200 R:19.0 loss:0.0340 exploreP:0.1714\n",
      "Episode:942 meanR:15.8600 R:19.0 loss:0.0323 exploreP:0.1711\n",
      "Episode:943 meanR:15.8700 R:14.0 loss:0.0290 exploreP:0.1709\n",
      "Episode:944 meanR:15.8900 R:13.0 loss:0.0383 exploreP:0.1706\n",
      "Episode:945 meanR:15.9200 R:18.0 loss:0.0373 exploreP:0.1704\n",
      "Episode:946 meanR:16.0100 R:18.0 loss:0.0298 exploreP:0.1701\n",
      "Episode:947 meanR:15.9600 R:13.0 loss:0.0316 exploreP:0.1699\n",
      "Episode:948 meanR:15.9400 R:16.0 loss:0.0283 exploreP:0.1696\n",
      "Episode:949 meanR:15.9500 R:14.0 loss:0.0326 exploreP:0.1694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:950 meanR:15.9900 R:18.0 loss:0.0293 exploreP:0.1691\n",
      "Episode:951 meanR:16.0300 R:20.0 loss:0.0319 exploreP:0.1688\n",
      "Episode:952 meanR:16.1300 R:25.0 loss:0.0311 exploreP:0.1684\n",
      "Episode:953 meanR:16.2500 R:21.0 loss:0.0279 exploreP:0.1680\n",
      "Episode:954 meanR:16.2700 R:15.0 loss:0.0353 exploreP:0.1678\n",
      "Episode:955 meanR:16.1800 R:9.0 loss:0.0304 exploreP:0.1677\n",
      "Episode:956 meanR:16.1500 R:14.0 loss:0.0292 exploreP:0.1674\n",
      "Episode:957 meanR:16.1100 R:9.0 loss:0.0309 exploreP:0.1673\n",
      "Episode:958 meanR:16.1500 R:18.0 loss:0.0382 exploreP:0.1670\n",
      "Episode:959 meanR:16.1000 R:13.0 loss:0.0340 exploreP:0.1668\n",
      "Episode:960 meanR:16.1400 R:13.0 loss:0.0314 exploreP:0.1666\n",
      "Episode:961 meanR:16.1500 R:17.0 loss:0.0277 exploreP:0.1664\n",
      "Episode:962 meanR:16.2100 R:18.0 loss:0.0331 exploreP:0.1661\n",
      "Episode:963 meanR:16.2700 R:16.0 loss:0.0304 exploreP:0.1658\n",
      "Episode:964 meanR:16.2500 R:15.0 loss:0.0294 exploreP:0.1656\n",
      "Episode:965 meanR:16.1900 R:14.0 loss:0.0341 exploreP:0.1654\n",
      "Episode:966 meanR:16.1700 R:17.0 loss:0.0330 exploreP:0.1651\n",
      "Episode:967 meanR:16.1700 R:19.0 loss:0.0295 exploreP:0.1648\n",
      "Episode:968 meanR:16.1000 R:13.0 loss:0.0314 exploreP:0.1646\n",
      "Episode:969 meanR:16.0900 R:17.0 loss:0.0335 exploreP:0.1643\n",
      "Episode:970 meanR:16.1100 R:15.0 loss:0.0276 exploreP:0.1641\n",
      "Episode:971 meanR:16.1600 R:19.0 loss:0.0296 exploreP:0.1638\n",
      "Episode:972 meanR:16.1700 R:18.0 loss:0.0369 exploreP:0.1635\n",
      "Episode:973 meanR:16.1100 R:13.0 loss:0.0347 exploreP:0.1633\n",
      "Episode:974 meanR:16.0900 R:15.0 loss:0.0341 exploreP:0.1631\n",
      "Episode:975 meanR:16.0200 R:11.0 loss:0.0362 exploreP:0.1629\n",
      "Episode:976 meanR:16.0700 R:19.0 loss:0.0304 exploreP:0.1627\n",
      "Episode:977 meanR:16.1000 R:18.0 loss:0.0286 exploreP:0.1624\n",
      "Episode:978 meanR:16.1000 R:13.0 loss:0.0320 exploreP:0.1622\n",
      "Episode:979 meanR:16.0900 R:17.0 loss:0.0316 exploreP:0.1619\n",
      "Episode:980 meanR:16.1100 R:17.0 loss:0.0322 exploreP:0.1617\n",
      "Episode:981 meanR:16.1200 R:18.0 loss:0.0300 exploreP:0.1614\n",
      "Episode:982 meanR:16.0900 R:13.0 loss:0.0306 exploreP:0.1612\n",
      "Episode:983 meanR:16.0000 R:8.0 loss:0.0399 exploreP:0.1611\n",
      "Episode:984 meanR:15.9800 R:17.0 loss:0.0293 exploreP:0.1608\n",
      "Episode:985 meanR:16.0300 R:15.0 loss:0.0331 exploreP:0.1606\n",
      "Episode:986 meanR:16.1100 R:20.0 loss:0.0326 exploreP:0.1603\n",
      "Episode:987 meanR:16.0200 R:9.0 loss:0.0348 exploreP:0.1602\n",
      "Episode:988 meanR:16.0500 R:17.0 loss:0.0288 exploreP:0.1599\n",
      "Episode:989 meanR:16.0900 R:18.0 loss:0.0307 exploreP:0.1596\n",
      "Episode:990 meanR:16.0800 R:15.0 loss:0.0262 exploreP:0.1594\n",
      "Episode:991 meanR:16.0700 R:14.0 loss:0.0336 exploreP:0.1592\n",
      "Episode:992 meanR:15.9300 R:9.0 loss:0.0324 exploreP:0.1591\n",
      "Episode:993 meanR:15.9300 R:16.0 loss:0.0340 exploreP:0.1588\n",
      "Episode:994 meanR:15.9400 R:18.0 loss:0.0327 exploreP:0.1586\n",
      "Episode:995 meanR:15.9700 R:19.0 loss:0.0353 exploreP:0.1583\n",
      "Episode:996 meanR:16.0100 R:17.0 loss:0.0328 exploreP:0.1580\n",
      "Episode:997 meanR:15.9800 R:17.0 loss:0.0312 exploreP:0.1578\n",
      "Episode:998 meanR:15.9800 R:18.0 loss:0.0272 exploreP:0.1575\n",
      "Episode:999 meanR:15.9700 R:14.0 loss:0.0314 exploreP:0.1573\n",
      "Episode:1000 meanR:16.0000 R:16.0 loss:0.0252 exploreP:0.1571\n",
      "Episode:1001 meanR:16.0700 R:22.0 loss:0.0306 exploreP:0.1567\n",
      "Episode:1002 meanR:16.0600 R:15.0 loss:0.0346 exploreP:0.1565\n",
      "Episode:1003 meanR:16.0500 R:15.0 loss:0.0264 exploreP:0.1563\n",
      "Episode:1004 meanR:16.0700 R:19.0 loss:0.0351 exploreP:0.1560\n",
      "Episode:1005 meanR:16.0900 R:15.0 loss:0.0328 exploreP:0.1558\n",
      "Episode:1006 meanR:16.1500 R:19.0 loss:0.0353 exploreP:0.1555\n",
      "Episode:1007 meanR:16.2400 R:21.0 loss:0.0282 exploreP:0.1552\n",
      "Episode:1008 meanR:16.1700 R:10.0 loss:0.0307 exploreP:0.1551\n",
      "Episode:1009 meanR:16.1800 R:14.0 loss:0.0329 exploreP:0.1549\n",
      "Episode:1010 meanR:16.2000 R:17.0 loss:0.0270 exploreP:0.1546\n",
      "Episode:1011 meanR:16.1900 R:17.0 loss:0.0337 exploreP:0.1544\n",
      "Episode:1012 meanR:16.1900 R:14.0 loss:0.0330 exploreP:0.1542\n",
      "Episode:1013 meanR:16.1100 R:10.0 loss:0.0337 exploreP:0.1540\n",
      "Episode:1014 meanR:16.1200 R:18.0 loss:0.0308 exploreP:0.1538\n",
      "Episode:1015 meanR:15.8700 R:14.0 loss:0.0249 exploreP:0.1536\n",
      "Episode:1016 meanR:15.9000 R:18.0 loss:0.0324 exploreP:0.1533\n",
      "Episode:1017 meanR:15.8800 R:16.0 loss:0.0281 exploreP:0.1531\n",
      "Episode:1018 meanR:15.8900 R:17.0 loss:0.0329 exploreP:0.1529\n",
      "Episode:1019 meanR:15.8800 R:17.0 loss:0.0303 exploreP:0.1526\n",
      "Episode:1020 meanR:15.8200 R:9.0 loss:0.0375 exploreP:0.1525\n",
      "Episode:1021 meanR:15.7500 R:9.0 loss:0.0299 exploreP:0.1524\n",
      "Episode:1022 meanR:15.7200 R:15.0 loss:0.0337 exploreP:0.1521\n",
      "Episode:1023 meanR:15.7100 R:16.0 loss:0.0306 exploreP:0.1519\n",
      "Episode:1024 meanR:15.7200 R:18.0 loss:0.0271 exploreP:0.1517\n",
      "Episode:1025 meanR:15.7400 R:19.0 loss:0.0305 exploreP:0.1514\n",
      "Episode:1026 meanR:15.6600 R:11.0 loss:0.0297 exploreP:0.1512\n",
      "Episode:1027 meanR:15.6600 R:15.0 loss:0.0355 exploreP:0.1510\n",
      "Episode:1028 meanR:15.7600 R:20.0 loss:0.0337 exploreP:0.1507\n",
      "Episode:1029 meanR:15.8000 R:14.0 loss:0.0264 exploreP:0.1505\n",
      "Episode:1030 meanR:15.7600 R:11.0 loss:0.0344 exploreP:0.1504\n",
      "Episode:1031 meanR:15.7800 R:21.0 loss:0.0312 exploreP:0.1501\n",
      "Episode:1032 meanR:15.7100 R:12.0 loss:0.0311 exploreP:0.1499\n",
      "Episode:1033 meanR:15.6700 R:15.0 loss:0.0264 exploreP:0.1497\n",
      "Episode:1034 meanR:15.6100 R:13.0 loss:0.0286 exploreP:0.1495\n",
      "Episode:1035 meanR:15.5900 R:9.0 loss:0.0226 exploreP:0.1494\n",
      "Episode:1036 meanR:15.5500 R:13.0 loss:0.0289 exploreP:0.1492\n",
      "Episode:1037 meanR:15.5700 R:15.0 loss:0.0279 exploreP:0.1490\n",
      "Episode:1038 meanR:15.5800 R:16.0 loss:0.0247 exploreP:0.1488\n",
      "Episode:1039 meanR:15.5600 R:13.0 loss:0.0253 exploreP:0.1486\n",
      "Episode:1040 meanR:15.5500 R:15.0 loss:0.0375 exploreP:0.1484\n",
      "Episode:1041 meanR:15.5400 R:18.0 loss:0.0307 exploreP:0.1482\n",
      "Episode:1042 meanR:15.5400 R:19.0 loss:0.0279 exploreP:0.1479\n",
      "Episode:1043 meanR:15.5700 R:17.0 loss:0.0334 exploreP:0.1477\n",
      "Episode:1044 meanR:15.6100 R:17.0 loss:0.0302 exploreP:0.1474\n",
      "Episode:1045 meanR:15.6100 R:18.0 loss:0.0249 exploreP:0.1472\n",
      "Episode:1046 meanR:15.6000 R:17.0 loss:0.0286 exploreP:0.1469\n",
      "Episode:1047 meanR:15.6100 R:14.0 loss:0.0336 exploreP:0.1468\n",
      "Episode:1048 meanR:15.5500 R:10.0 loss:0.0232 exploreP:0.1466\n",
      "Episode:1049 meanR:15.5000 R:9.0 loss:0.0299 exploreP:0.1465\n",
      "Episode:1050 meanR:15.4900 R:17.0 loss:0.0269 exploreP:0.1463\n",
      "Episode:1051 meanR:15.4500 R:16.0 loss:0.0274 exploreP:0.1460\n",
      "Episode:1052 meanR:15.3100 R:11.0 loss:0.0252 exploreP:0.1459\n",
      "Episode:1053 meanR:15.2200 R:12.0 loss:0.0278 exploreP:0.1457\n",
      "Episode:1054 meanR:15.1700 R:10.0 loss:0.0309 exploreP:0.1456\n",
      "Episode:1055 meanR:15.2300 R:15.0 loss:0.0315 exploreP:0.1454\n",
      "Episode:1056 meanR:15.1900 R:10.0 loss:0.0323 exploreP:0.1453\n",
      "Episode:1057 meanR:15.2400 R:14.0 loss:0.0286 exploreP:0.1451\n",
      "Episode:1058 meanR:15.2100 R:15.0 loss:0.0328 exploreP:0.1449\n",
      "Episode:1059 meanR:15.3000 R:22.0 loss:0.0311 exploreP:0.1446\n",
      "Episode:1060 meanR:15.3500 R:18.0 loss:0.0309 exploreP:0.1443\n",
      "Episode:1061 meanR:15.3400 R:16.0 loss:0.0351 exploreP:0.1441\n",
      "Episode:1062 meanR:15.3200 R:16.0 loss:0.0291 exploreP:0.1439\n",
      "Episode:1063 meanR:15.3300 R:17.0 loss:0.0308 exploreP:0.1437\n",
      "Episode:1064 meanR:15.3300 R:15.0 loss:0.0304 exploreP:0.1435\n",
      "Episode:1065 meanR:15.3900 R:20.0 loss:0.0257 exploreP:0.1432\n",
      "Episode:1066 meanR:15.3800 R:16.0 loss:0.0316 exploreP:0.1430\n",
      "Episode:1067 meanR:15.3500 R:16.0 loss:0.0290 exploreP:0.1428\n",
      "Episode:1068 meanR:15.3900 R:17.0 loss:0.0279 exploreP:0.1426\n",
      "Episode:1069 meanR:15.3100 R:9.0 loss:0.0237 exploreP:0.1424\n",
      "Episode:1070 meanR:15.3300 R:17.0 loss:0.0242 exploreP:0.1422\n",
      "Episode:1071 meanR:15.3000 R:16.0 loss:0.0297 exploreP:0.1420\n",
      "Episode:1072 meanR:15.2500 R:13.0 loss:0.0220 exploreP:0.1418\n",
      "Episode:1073 meanR:15.2500 R:13.0 loss:0.0289 exploreP:0.1417\n",
      "Episode:1074 meanR:15.2500 R:15.0 loss:0.0259 exploreP:0.1415\n",
      "Episode:1075 meanR:15.3100 R:17.0 loss:0.0278 exploreP:0.1412\n",
      "Episode:1076 meanR:15.2500 R:13.0 loss:0.0300 exploreP:0.1411\n",
      "Episode:1077 meanR:15.2400 R:17.0 loss:0.0292 exploreP:0.1408\n",
      "Episode:1078 meanR:15.2700 R:16.0 loss:0.0320 exploreP:0.1406\n",
      "Episode:1079 meanR:15.2500 R:15.0 loss:0.0293 exploreP:0.1404\n",
      "Episode:1080 meanR:15.2600 R:18.0 loss:0.0300 exploreP:0.1402\n",
      "Episode:1081 meanR:15.1700 R:9.0 loss:0.0286 exploreP:0.1401\n",
      "Episode:1082 meanR:15.1900 R:15.0 loss:0.0317 exploreP:0.1399\n",
      "Episode:1083 meanR:15.2600 R:15.0 loss:0.0275 exploreP:0.1397\n",
      "Episode:1084 meanR:15.2200 R:13.0 loss:0.0254 exploreP:0.1395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1085 meanR:15.3200 R:25.0 loss:0.0285 exploreP:0.1392\n",
      "Episode:1086 meanR:15.3100 R:19.0 loss:0.0278 exploreP:0.1390\n",
      "Episode:1087 meanR:15.3700 R:15.0 loss:0.0337 exploreP:0.1388\n",
      "Episode:1088 meanR:15.3700 R:17.0 loss:0.0350 exploreP:0.1385\n",
      "Episode:1089 meanR:15.3700 R:18.0 loss:0.0304 exploreP:0.1383\n",
      "Episode:1090 meanR:15.3700 R:15.0 loss:0.0292 exploreP:0.1381\n",
      "Episode:1091 meanR:15.4000 R:17.0 loss:0.0271 exploreP:0.1379\n",
      "Episode:1092 meanR:15.5000 R:19.0 loss:0.0281 exploreP:0.1377\n",
      "Episode:1093 meanR:15.5300 R:19.0 loss:0.0289 exploreP:0.1374\n",
      "Episode:1094 meanR:15.4600 R:11.0 loss:0.0340 exploreP:0.1373\n",
      "Episode:1095 meanR:15.4200 R:15.0 loss:0.0303 exploreP:0.1371\n",
      "Episode:1096 meanR:15.3900 R:14.0 loss:0.0317 exploreP:0.1369\n",
      "Episode:1097 meanR:15.4000 R:18.0 loss:0.0367 exploreP:0.1367\n",
      "Episode:1098 meanR:15.3700 R:15.0 loss:0.0317 exploreP:0.1365\n",
      "Episode:1099 meanR:15.4000 R:17.0 loss:0.0306 exploreP:0.1363\n",
      "Episode:1100 meanR:15.4500 R:21.0 loss:0.0292 exploreP:0.1360\n",
      "Episode:1101 meanR:15.4100 R:18.0 loss:0.0275 exploreP:0.1358\n",
      "Episode:1102 meanR:15.4500 R:19.0 loss:0.0282 exploreP:0.1356\n",
      "Episode:1103 meanR:15.4600 R:16.0 loss:0.0325 exploreP:0.1353\n",
      "Episode:1104 meanR:15.3900 R:12.0 loss:0.0306 exploreP:0.1352\n",
      "Episode:1105 meanR:15.3900 R:15.0 loss:0.0262 exploreP:0.1350\n",
      "Episode:1106 meanR:15.2800 R:8.0 loss:0.0307 exploreP:0.1349\n",
      "Episode:1107 meanR:15.2500 R:18.0 loss:0.0330 exploreP:0.1347\n",
      "Episode:1108 meanR:15.3300 R:18.0 loss:0.0283 exploreP:0.1345\n",
      "Episode:1109 meanR:15.3400 R:15.0 loss:0.0330 exploreP:0.1343\n",
      "Episode:1110 meanR:15.3200 R:15.0 loss:0.0334 exploreP:0.1341\n",
      "Episode:1111 meanR:15.2700 R:12.0 loss:0.0243 exploreP:0.1339\n",
      "Episode:1112 meanR:15.2900 R:16.0 loss:0.0288 exploreP:0.1337\n",
      "Episode:1113 meanR:15.3200 R:13.0 loss:0.0274 exploreP:0.1336\n",
      "Episode:1114 meanR:15.2300 R:9.0 loss:0.0253 exploreP:0.1335\n",
      "Episode:1115 meanR:15.2300 R:14.0 loss:0.0338 exploreP:0.1333\n",
      "Episode:1116 meanR:15.1600 R:11.0 loss:0.0269 exploreP:0.1332\n",
      "Episode:1117 meanR:15.1800 R:18.0 loss:0.0320 exploreP:0.1329\n",
      "Episode:1118 meanR:15.1500 R:14.0 loss:0.0310 exploreP:0.1328\n",
      "Episode:1119 meanR:15.1200 R:14.0 loss:0.0281 exploreP:0.1326\n",
      "Episode:1120 meanR:15.2000 R:17.0 loss:0.0292 exploreP:0.1324\n",
      "Episode:1121 meanR:15.3000 R:19.0 loss:0.0323 exploreP:0.1322\n",
      "Episode:1122 meanR:15.2400 R:9.0 loss:0.0330 exploreP:0.1320\n",
      "Episode:1123 meanR:15.1800 R:10.0 loss:0.0312 exploreP:0.1319\n",
      "Episode:1124 meanR:15.1400 R:14.0 loss:0.0291 exploreP:0.1318\n",
      "Episode:1125 meanR:15.0700 R:12.0 loss:0.0296 exploreP:0.1316\n",
      "Episode:1126 meanR:15.0900 R:13.0 loss:0.0250 exploreP:0.1315\n",
      "Episode:1127 meanR:15.1000 R:16.0 loss:0.0294 exploreP:0.1313\n",
      "Episode:1128 meanR:15.0600 R:16.0 loss:0.0282 exploreP:0.1311\n",
      "Episode:1129 meanR:15.0500 R:13.0 loss:0.0247 exploreP:0.1309\n",
      "Episode:1130 meanR:15.1000 R:16.0 loss:0.0274 exploreP:0.1307\n",
      "Episode:1131 meanR:15.0200 R:13.0 loss:0.0293 exploreP:0.1306\n",
      "Episode:1132 meanR:15.0500 R:15.0 loss:0.0285 exploreP:0.1304\n",
      "Episode:1133 meanR:15.0600 R:16.0 loss:0.0302 exploreP:0.1302\n",
      "Episode:1134 meanR:15.1100 R:18.0 loss:0.0317 exploreP:0.1300\n",
      "Episode:1135 meanR:15.2100 R:19.0 loss:0.0274 exploreP:0.1297\n",
      "Episode:1136 meanR:15.2700 R:19.0 loss:0.0295 exploreP:0.1295\n",
      "Episode:1137 meanR:15.2300 R:11.0 loss:0.0252 exploreP:0.1294\n",
      "Episode:1138 meanR:15.1800 R:11.0 loss:0.0340 exploreP:0.1292\n",
      "Episode:1139 meanR:15.2200 R:17.0 loss:0.0303 exploreP:0.1290\n",
      "Episode:1140 meanR:15.2300 R:16.0 loss:0.0296 exploreP:0.1289\n",
      "Episode:1141 meanR:15.2400 R:19.0 loss:0.0335 exploreP:0.1286\n",
      "Episode:1142 meanR:15.2000 R:15.0 loss:0.0321 exploreP:0.1285\n",
      "Episode:1143 meanR:15.1800 R:15.0 loss:0.0289 exploreP:0.1283\n",
      "Episode:1144 meanR:15.1800 R:17.0 loss:0.0295 exploreP:0.1281\n",
      "Episode:1145 meanR:15.1500 R:15.0 loss:0.0284 exploreP:0.1279\n",
      "Episode:1146 meanR:15.1700 R:19.0 loss:0.0300 exploreP:0.1277\n",
      "Episode:1147 meanR:15.1300 R:10.0 loss:0.0308 exploreP:0.1276\n",
      "Episode:1148 meanR:15.1900 R:16.0 loss:0.0279 exploreP:0.1274\n",
      "Episode:1149 meanR:15.2700 R:17.0 loss:0.0274 exploreP:0.1272\n",
      "Episode:1150 meanR:15.2500 R:15.0 loss:0.0239 exploreP:0.1270\n",
      "Episode:1151 meanR:15.2900 R:20.0 loss:0.0286 exploreP:0.1268\n",
      "Episode:1152 meanR:15.3300 R:15.0 loss:0.0237 exploreP:0.1266\n",
      "Episode:1153 meanR:15.3800 R:17.0 loss:0.0259 exploreP:0.1264\n",
      "Episode:1154 meanR:15.4200 R:14.0 loss:0.0298 exploreP:0.1262\n",
      "Episode:1155 meanR:15.4600 R:19.0 loss:0.0270 exploreP:0.1260\n",
      "Episode:1156 meanR:15.5500 R:19.0 loss:0.0338 exploreP:0.1258\n",
      "Episode:1157 meanR:15.5000 R:9.0 loss:0.0310 exploreP:0.1257\n",
      "Episode:1158 meanR:15.5000 R:15.0 loss:0.0283 exploreP:0.1255\n",
      "Episode:1159 meanR:15.4300 R:15.0 loss:0.0262 exploreP:0.1253\n",
      "Episode:1160 meanR:15.3800 R:13.0 loss:0.0298 exploreP:0.1252\n",
      "Episode:1161 meanR:15.3100 R:9.0 loss:0.0238 exploreP:0.1251\n",
      "Episode:1162 meanR:15.2300 R:8.0 loss:0.0259 exploreP:0.1250\n",
      "Episode:1163 meanR:15.1600 R:10.0 loss:0.0275 exploreP:0.1249\n",
      "Episode:1164 meanR:15.1800 R:17.0 loss:0.0257 exploreP:0.1247\n",
      "Episode:1165 meanR:15.1700 R:19.0 loss:0.0291 exploreP:0.1245\n",
      "Episode:1166 meanR:15.1600 R:15.0 loss:0.0291 exploreP:0.1243\n",
      "Episode:1167 meanR:15.1400 R:14.0 loss:0.0272 exploreP:0.1241\n",
      "Episode:1168 meanR:15.1000 R:13.0 loss:0.0299 exploreP:0.1240\n",
      "Episode:1169 meanR:15.1000 R:9.0 loss:0.0302 exploreP:0.1239\n",
      "Episode:1170 meanR:15.0400 R:11.0 loss:0.0292 exploreP:0.1238\n",
      "Episode:1171 meanR:15.0600 R:18.0 loss:0.0285 exploreP:0.1235\n",
      "Episode:1172 meanR:15.1100 R:18.0 loss:0.0269 exploreP:0.1233\n",
      "Episode:1173 meanR:15.1100 R:13.0 loss:0.0256 exploreP:0.1232\n",
      "Episode:1174 meanR:15.0900 R:13.0 loss:0.0304 exploreP:0.1230\n",
      "Episode:1175 meanR:15.0600 R:14.0 loss:0.0297 exploreP:0.1229\n",
      "Episode:1176 meanR:15.0200 R:9.0 loss:0.0270 exploreP:0.1228\n",
      "Episode:1177 meanR:14.9900 R:14.0 loss:0.0252 exploreP:0.1226\n",
      "Episode:1178 meanR:14.9300 R:10.0 loss:0.0283 exploreP:0.1225\n",
      "Episode:1179 meanR:14.9200 R:14.0 loss:0.0279 exploreP:0.1224\n",
      "Episode:1180 meanR:14.8200 R:8.0 loss:0.0264 exploreP:0.1223\n",
      "Episode:1181 meanR:14.8400 R:11.0 loss:0.0277 exploreP:0.1221\n",
      "Episode:1182 meanR:14.8200 R:13.0 loss:0.0259 exploreP:0.1220\n",
      "Episode:1183 meanR:14.8300 R:16.0 loss:0.0234 exploreP:0.1218\n",
      "Episode:1184 meanR:14.9100 R:21.0 loss:0.0300 exploreP:0.1216\n",
      "Episode:1185 meanR:14.8100 R:15.0 loss:0.0252 exploreP:0.1214\n",
      "Episode:1186 meanR:14.7200 R:10.0 loss:0.0244 exploreP:0.1213\n",
      "Episode:1187 meanR:14.7500 R:18.0 loss:0.0298 exploreP:0.1211\n",
      "Episode:1188 meanR:14.7500 R:17.0 loss:0.0254 exploreP:0.1209\n",
      "Episode:1189 meanR:14.7200 R:15.0 loss:0.0285 exploreP:0.1208\n",
      "Episode:1190 meanR:14.7500 R:18.0 loss:0.0308 exploreP:0.1206\n",
      "Episode:1191 meanR:14.7200 R:14.0 loss:0.0284 exploreP:0.1204\n",
      "Episode:1192 meanR:14.6400 R:11.0 loss:0.0236 exploreP:0.1203\n",
      "Episode:1193 meanR:14.6200 R:17.0 loss:0.0273 exploreP:0.1201\n",
      "Episode:1194 meanR:14.6000 R:9.0 loss:0.0260 exploreP:0.1200\n",
      "Episode:1195 meanR:14.6400 R:19.0 loss:0.0331 exploreP:0.1198\n",
      "Episode:1196 meanR:14.6800 R:18.0 loss:0.0327 exploreP:0.1196\n",
      "Episode:1197 meanR:14.6600 R:16.0 loss:0.0270 exploreP:0.1194\n",
      "Episode:1198 meanR:14.6100 R:10.0 loss:0.0261 exploreP:0.1193\n",
      "Episode:1199 meanR:14.5400 R:10.0 loss:0.0266 exploreP:0.1192\n",
      "Episode:1200 meanR:14.4900 R:16.0 loss:0.0273 exploreP:0.1190\n",
      "Episode:1201 meanR:14.4400 R:13.0 loss:0.0231 exploreP:0.1189\n",
      "Episode:1202 meanR:14.3400 R:9.0 loss:0.0262 exploreP:0.1188\n",
      "Episode:1203 meanR:14.3200 R:14.0 loss:0.0238 exploreP:0.1186\n",
      "Episode:1204 meanR:14.3900 R:19.0 loss:0.0255 exploreP:0.1184\n",
      "Episode:1205 meanR:14.3800 R:14.0 loss:0.0238 exploreP:0.1183\n",
      "Episode:1206 meanR:14.4100 R:11.0 loss:0.0291 exploreP:0.1181\n",
      "Episode:1207 meanR:14.3300 R:10.0 loss:0.0288 exploreP:0.1180\n",
      "Episode:1208 meanR:14.2600 R:11.0 loss:0.0275 exploreP:0.1179\n",
      "Episode:1209 meanR:14.2300 R:12.0 loss:0.0235 exploreP:0.1178\n",
      "Episode:1210 meanR:14.1700 R:9.0 loss:0.0280 exploreP:0.1177\n",
      "Episode:1211 meanR:14.2000 R:15.0 loss:0.0306 exploreP:0.1175\n",
      "Episode:1212 meanR:14.2100 R:17.0 loss:0.0239 exploreP:0.1174\n",
      "Episode:1213 meanR:14.2100 R:13.0 loss:0.0301 exploreP:0.1172\n",
      "Episode:1214 meanR:14.2300 R:11.0 loss:0.0232 exploreP:0.1171\n",
      "Episode:1215 meanR:14.1700 R:8.0 loss:0.0323 exploreP:0.1170\n",
      "Episode:1216 meanR:14.2000 R:14.0 loss:0.0278 exploreP:0.1169\n",
      "Episode:1217 meanR:14.1500 R:13.0 loss:0.0249 exploreP:0.1167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1218 meanR:14.1700 R:16.0 loss:0.0265 exploreP:0.1165\n",
      "Episode:1219 meanR:14.2100 R:18.0 loss:0.0258 exploreP:0.1164\n",
      "Episode:1220 meanR:14.1900 R:15.0 loss:0.0253 exploreP:0.1162\n",
      "Episode:1221 meanR:14.1500 R:15.0 loss:0.0274 exploreP:0.1160\n",
      "Episode:1222 meanR:14.2200 R:16.0 loss:0.0246 exploreP:0.1159\n",
      "Episode:1223 meanR:14.2900 R:17.0 loss:0.0283 exploreP:0.1157\n",
      "Episode:1224 meanR:14.3000 R:15.0 loss:0.0298 exploreP:0.1155\n",
      "Episode:1225 meanR:14.3100 R:13.0 loss:0.0317 exploreP:0.1154\n",
      "Episode:1226 meanR:14.3500 R:17.0 loss:0.0316 exploreP:0.1152\n",
      "Episode:1227 meanR:14.3300 R:14.0 loss:0.0281 exploreP:0.1151\n",
      "Episode:1228 meanR:14.2900 R:12.0 loss:0.0277 exploreP:0.1149\n",
      "Episode:1229 meanR:14.2500 R:9.0 loss:0.0239 exploreP:0.1148\n",
      "Episode:1230 meanR:14.2200 R:13.0 loss:0.0273 exploreP:0.1147\n",
      "Episode:1231 meanR:14.2600 R:17.0 loss:0.0292 exploreP:0.1145\n",
      "Episode:1232 meanR:14.2100 R:10.0 loss:0.0192 exploreP:0.1144\n",
      "Episode:1233 meanR:14.1700 R:12.0 loss:0.0234 exploreP:0.1143\n",
      "Episode:1234 meanR:14.0800 R:9.0 loss:0.0238 exploreP:0.1142\n",
      "Episode:1235 meanR:14.0100 R:12.0 loss:0.0299 exploreP:0.1141\n",
      "Episode:1236 meanR:13.9200 R:10.0 loss:0.0253 exploreP:0.1140\n",
      "Episode:1237 meanR:13.9900 R:18.0 loss:0.0263 exploreP:0.1138\n",
      "Episode:1238 meanR:14.0200 R:14.0 loss:0.0263 exploreP:0.1136\n",
      "Episode:1239 meanR:13.9500 R:10.0 loss:0.0251 exploreP:0.1135\n",
      "Episode:1240 meanR:13.9800 R:19.0 loss:0.0267 exploreP:0.1133\n",
      "Episode:1241 meanR:13.9100 R:12.0 loss:0.0285 exploreP:0.1132\n",
      "Episode:1242 meanR:13.9200 R:16.0 loss:0.0290 exploreP:0.1131\n",
      "Episode:1243 meanR:13.9400 R:17.0 loss:0.0247 exploreP:0.1129\n",
      "Episode:1244 meanR:13.9300 R:16.0 loss:0.0275 exploreP:0.1127\n",
      "Episode:1245 meanR:13.9100 R:13.0 loss:0.0279 exploreP:0.1126\n",
      "Episode:1246 meanR:13.8600 R:14.0 loss:0.0295 exploreP:0.1124\n",
      "Episode:1247 meanR:13.9400 R:18.0 loss:0.0241 exploreP:0.1123\n",
      "Episode:1248 meanR:13.8900 R:11.0 loss:0.0236 exploreP:0.1121\n",
      "Episode:1249 meanR:13.9400 R:22.0 loss:0.0237 exploreP:0.1119\n",
      "Episode:1250 meanR:13.9700 R:18.0 loss:0.0268 exploreP:0.1117\n",
      "Episode:1251 meanR:13.9200 R:15.0 loss:0.0278 exploreP:0.1116\n",
      "Episode:1252 meanR:13.9200 R:15.0 loss:0.0286 exploreP:0.1114\n",
      "Episode:1253 meanR:13.8400 R:9.0 loss:0.0244 exploreP:0.1113\n",
      "Episode:1254 meanR:13.8600 R:16.0 loss:0.0276 exploreP:0.1112\n",
      "Episode:1255 meanR:13.8100 R:14.0 loss:0.0271 exploreP:0.1110\n",
      "Episode:1256 meanR:13.7600 R:14.0 loss:0.0270 exploreP:0.1109\n",
      "Episode:1257 meanR:13.7800 R:11.0 loss:0.0252 exploreP:0.1108\n",
      "Episode:1258 meanR:13.7100 R:8.0 loss:0.0249 exploreP:0.1107\n",
      "Episode:1259 meanR:13.7200 R:16.0 loss:0.0240 exploreP:0.1105\n",
      "Episode:1260 meanR:13.7300 R:14.0 loss:0.0270 exploreP:0.1104\n",
      "Episode:1261 meanR:13.7500 R:11.0 loss:0.0249 exploreP:0.1103\n",
      "Episode:1262 meanR:13.8600 R:19.0 loss:0.0295 exploreP:0.1101\n",
      "Episode:1263 meanR:13.9200 R:16.0 loss:0.0271 exploreP:0.1099\n",
      "Episode:1264 meanR:13.8700 R:12.0 loss:0.0277 exploreP:0.1098\n",
      "Episode:1265 meanR:13.7700 R:9.0 loss:0.0270 exploreP:0.1097\n",
      "Episode:1266 meanR:13.7100 R:9.0 loss:0.0263 exploreP:0.1096\n",
      "Episode:1267 meanR:13.6700 R:10.0 loss:0.0332 exploreP:0.1095\n",
      "Episode:1268 meanR:13.6400 R:10.0 loss:0.0231 exploreP:0.1094\n",
      "Episode:1269 meanR:13.6600 R:11.0 loss:0.0295 exploreP:0.1093\n",
      "Episode:1270 meanR:13.6900 R:14.0 loss:0.0278 exploreP:0.1092\n",
      "Episode:1271 meanR:13.6100 R:10.0 loss:0.0271 exploreP:0.1091\n",
      "Episode:1272 meanR:13.6200 R:19.0 loss:0.0308 exploreP:0.1089\n",
      "Episode:1273 meanR:13.6200 R:13.0 loss:0.0277 exploreP:0.1088\n",
      "Episode:1274 meanR:13.5900 R:10.0 loss:0.0288 exploreP:0.1087\n",
      "Episode:1275 meanR:13.5400 R:9.0 loss:0.0312 exploreP:0.1086\n",
      "Episode:1276 meanR:13.6200 R:17.0 loss:0.0262 exploreP:0.1084\n",
      "Episode:1277 meanR:13.6300 R:15.0 loss:0.0256 exploreP:0.1083\n",
      "Episode:1278 meanR:13.6900 R:16.0 loss:0.0273 exploreP:0.1081\n",
      "Episode:1279 meanR:13.7400 R:19.0 loss:0.0290 exploreP:0.1079\n",
      "Episode:1280 meanR:13.7800 R:12.0 loss:0.0224 exploreP:0.1078\n",
      "Episode:1281 meanR:13.8000 R:13.0 loss:0.0280 exploreP:0.1077\n",
      "Episode:1282 meanR:13.8300 R:16.0 loss:0.0286 exploreP:0.1075\n",
      "Episode:1283 meanR:13.7600 R:9.0 loss:0.0234 exploreP:0.1074\n",
      "Episode:1284 meanR:13.7400 R:19.0 loss:0.0244 exploreP:0.1073\n",
      "Episode:1285 meanR:13.7500 R:16.0 loss:0.0275 exploreP:0.1071\n",
      "Episode:1286 meanR:13.7300 R:8.0 loss:0.0283 exploreP:0.1070\n",
      "Episode:1287 meanR:13.7000 R:15.0 loss:0.0312 exploreP:0.1069\n",
      "Episode:1288 meanR:13.6300 R:10.0 loss:0.0269 exploreP:0.1068\n",
      "Episode:1289 meanR:13.6500 R:17.0 loss:0.0227 exploreP:0.1066\n",
      "Episode:1290 meanR:13.5800 R:11.0 loss:0.0242 exploreP:0.1065\n",
      "Episode:1291 meanR:13.5300 R:9.0 loss:0.0242 exploreP:0.1064\n",
      "Episode:1292 meanR:13.5400 R:12.0 loss:0.0247 exploreP:0.1063\n",
      "Episode:1293 meanR:13.4700 R:10.0 loss:0.0277 exploreP:0.1062\n",
      "Episode:1294 meanR:13.5200 R:14.0 loss:0.0299 exploreP:0.1061\n",
      "Episode:1295 meanR:13.4900 R:16.0 loss:0.0281 exploreP:0.1059\n",
      "Episode:1296 meanR:13.4000 R:9.0 loss:0.0220 exploreP:0.1058\n",
      "Episode:1297 meanR:13.4100 R:17.0 loss:0.0289 exploreP:0.1057\n",
      "Episode:1298 meanR:13.4000 R:9.0 loss:0.0214 exploreP:0.1056\n",
      "Episode:1299 meanR:13.4100 R:11.0 loss:0.0288 exploreP:0.1055\n",
      "Episode:1300 meanR:13.3500 R:10.0 loss:0.0280 exploreP:0.1054\n",
      "Episode:1301 meanR:13.3800 R:16.0 loss:0.0225 exploreP:0.1052\n",
      "Episode:1302 meanR:13.4400 R:15.0 loss:0.0252 exploreP:0.1051\n",
      "Episode:1303 meanR:13.4200 R:12.0 loss:0.0245 exploreP:0.1050\n",
      "Episode:1304 meanR:13.3400 R:11.0 loss:0.0226 exploreP:0.1049\n",
      "Episode:1305 meanR:13.3100 R:11.0 loss:0.0252 exploreP:0.1048\n",
      "Episode:1306 meanR:13.2900 R:9.0 loss:0.0263 exploreP:0.1047\n",
      "Episode:1307 meanR:13.3100 R:12.0 loss:0.0278 exploreP:0.1046\n",
      "Episode:1308 meanR:13.3200 R:12.0 loss:0.0277 exploreP:0.1045\n",
      "Episode:1309 meanR:13.4200 R:22.0 loss:0.0255 exploreP:0.1043\n",
      "Episode:1310 meanR:13.5100 R:18.0 loss:0.0255 exploreP:0.1041\n",
      "Episode:1311 meanR:13.4900 R:13.0 loss:0.0249 exploreP:0.1040\n",
      "Episode:1312 meanR:13.4900 R:17.0 loss:0.0287 exploreP:0.1038\n",
      "Episode:1313 meanR:13.4800 R:12.0 loss:0.0297 exploreP:0.1037\n",
      "Episode:1314 meanR:13.4700 R:10.0 loss:0.0284 exploreP:0.1036\n",
      "Episode:1315 meanR:13.4800 R:9.0 loss:0.0270 exploreP:0.1035\n",
      "Episode:1316 meanR:13.4300 R:9.0 loss:0.0263 exploreP:0.1034\n",
      "Episode:1317 meanR:13.4200 R:12.0 loss:0.0286 exploreP:0.1033\n",
      "Episode:1318 meanR:13.3600 R:10.0 loss:0.0265 exploreP:0.1032\n",
      "Episode:1319 meanR:13.2800 R:10.0 loss:0.0251 exploreP:0.1031\n",
      "Episode:1320 meanR:13.2500 R:12.0 loss:0.0277 exploreP:0.1030\n",
      "Episode:1321 meanR:13.2700 R:17.0 loss:0.0286 exploreP:0.1029\n",
      "Episode:1322 meanR:13.2300 R:12.0 loss:0.0306 exploreP:0.1027\n",
      "Episode:1323 meanR:13.1600 R:10.0 loss:0.0266 exploreP:0.1027\n",
      "Episode:1324 meanR:13.1100 R:10.0 loss:0.0303 exploreP:0.1026\n",
      "Episode:1325 meanR:13.0800 R:10.0 loss:0.0281 exploreP:0.1025\n",
      "Episode:1326 meanR:13.0800 R:17.0 loss:0.0237 exploreP:0.1023\n",
      "Episode:1327 meanR:13.0500 R:11.0 loss:0.0282 exploreP:0.1022\n",
      "Episode:1328 meanR:13.0300 R:10.0 loss:0.0255 exploreP:0.1021\n",
      "Episode:1329 meanR:13.1100 R:17.0 loss:0.0236 exploreP:0.1020\n",
      "Episode:1330 meanR:13.1000 R:12.0 loss:0.0248 exploreP:0.1019\n",
      "Episode:1331 meanR:13.1000 R:17.0 loss:0.0270 exploreP:0.1017\n",
      "Episode:1332 meanR:13.1000 R:10.0 loss:0.0291 exploreP:0.1016\n",
      "Episode:1333 meanR:13.0700 R:9.0 loss:0.0262 exploreP:0.1015\n",
      "Episode:1334 meanR:13.0700 R:9.0 loss:0.0304 exploreP:0.1014\n",
      "Episode:1335 meanR:13.1300 R:18.0 loss:0.0307 exploreP:0.1013\n",
      "Episode:1336 meanR:13.1400 R:11.0 loss:0.0251 exploreP:0.1012\n",
      "Episode:1337 meanR:13.1400 R:18.0 loss:0.0292 exploreP:0.1010\n",
      "Episode:1338 meanR:13.1800 R:18.0 loss:0.0286 exploreP:0.1008\n",
      "Episode:1339 meanR:13.1800 R:10.0 loss:0.0240 exploreP:0.1008\n",
      "Episode:1340 meanR:13.1400 R:15.0 loss:0.0247 exploreP:0.1006\n",
      "Episode:1341 meanR:13.1100 R:9.0 loss:0.0247 exploreP:0.1005\n",
      "Episode:1342 meanR:13.0600 R:11.0 loss:0.0277 exploreP:0.1004\n",
      "Episode:1343 meanR:13.0200 R:13.0 loss:0.0266 exploreP:0.1003\n",
      "Episode:1344 meanR:12.9600 R:10.0 loss:0.0276 exploreP:0.1002\n",
      "Episode:1345 meanR:12.9700 R:14.0 loss:0.0248 exploreP:0.1001\n",
      "Episode:1346 meanR:12.9500 R:12.0 loss:0.0244 exploreP:0.1000\n",
      "Episode:1347 meanR:12.8800 R:11.0 loss:0.0280 exploreP:0.0999\n",
      "Episode:1348 meanR:12.8600 R:9.0 loss:0.0313 exploreP:0.0998\n",
      "Episode:1349 meanR:12.8100 R:17.0 loss:0.0274 exploreP:0.0997\n",
      "Episode:1350 meanR:12.8000 R:17.0 loss:0.0279 exploreP:0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1351 meanR:12.7500 R:10.0 loss:0.0245 exploreP:0.0994\n",
      "Episode:1352 meanR:12.7100 R:11.0 loss:0.0261 exploreP:0.0993\n",
      "Episode:1353 meanR:12.7700 R:15.0 loss:0.0293 exploreP:0.0992\n",
      "Episode:1354 meanR:12.8000 R:19.0 loss:0.0287 exploreP:0.0990\n",
      "Episode:1355 meanR:12.7900 R:13.0 loss:0.0262 exploreP:0.0989\n",
      "Episode:1356 meanR:12.8300 R:18.0 loss:0.0253 exploreP:0.0987\n",
      "Episode:1357 meanR:12.8800 R:16.0 loss:0.0303 exploreP:0.0986\n",
      "Episode:1358 meanR:12.9100 R:11.0 loss:0.0261 exploreP:0.0985\n",
      "Episode:1359 meanR:12.8900 R:14.0 loss:0.0242 exploreP:0.0984\n",
      "Episode:1360 meanR:12.8700 R:12.0 loss:0.0279 exploreP:0.0983\n",
      "Episode:1361 meanR:12.8600 R:10.0 loss:0.0298 exploreP:0.0982\n",
      "Episode:1362 meanR:12.8100 R:14.0 loss:0.0279 exploreP:0.0981\n",
      "Episode:1363 meanR:12.7400 R:9.0 loss:0.0258 exploreP:0.0980\n",
      "Episode:1364 meanR:12.7300 R:11.0 loss:0.0288 exploreP:0.0979\n",
      "Episode:1365 meanR:12.8100 R:17.0 loss:0.0264 exploreP:0.0977\n",
      "Episode:1366 meanR:12.8200 R:10.0 loss:0.0280 exploreP:0.0977\n",
      "Episode:1367 meanR:12.8100 R:9.0 loss:0.0342 exploreP:0.0976\n",
      "Episode:1368 meanR:12.8000 R:9.0 loss:0.0284 exploreP:0.0975\n",
      "Episode:1369 meanR:12.8800 R:19.0 loss:0.0257 exploreP:0.0973\n",
      "Episode:1370 meanR:12.9000 R:16.0 loss:0.0259 exploreP:0.0972\n",
      "Episode:1371 meanR:12.8900 R:9.0 loss:0.0268 exploreP:0.0971\n",
      "Episode:1372 meanR:12.8700 R:17.0 loss:0.0267 exploreP:0.0970\n",
      "Episode:1373 meanR:12.8500 R:11.0 loss:0.0303 exploreP:0.0969\n",
      "Episode:1374 meanR:12.9100 R:16.0 loss:0.0295 exploreP:0.0967\n",
      "Episode:1375 meanR:12.9900 R:17.0 loss:0.0249 exploreP:0.0966\n",
      "Episode:1376 meanR:12.9000 R:8.0 loss:0.0279 exploreP:0.0965\n",
      "Episode:1377 meanR:12.8600 R:11.0 loss:0.0281 exploreP:0.0964\n",
      "Episode:1378 meanR:12.7800 R:8.0 loss:0.0254 exploreP:0.0963\n",
      "Episode:1379 meanR:12.7400 R:15.0 loss:0.0299 exploreP:0.0962\n",
      "Episode:1380 meanR:12.7600 R:14.0 loss:0.0261 exploreP:0.0961\n",
      "Episode:1381 meanR:12.7900 R:16.0 loss:0.0300 exploreP:0.0960\n",
      "Episode:1382 meanR:12.7700 R:14.0 loss:0.0280 exploreP:0.0958\n",
      "Episode:1383 meanR:12.8000 R:12.0 loss:0.0260 exploreP:0.0957\n",
      "Episode:1384 meanR:12.7100 R:10.0 loss:0.0287 exploreP:0.0957\n",
      "Episode:1385 meanR:12.6900 R:14.0 loss:0.0283 exploreP:0.0955\n",
      "Episode:1386 meanR:12.7700 R:16.0 loss:0.0273 exploreP:0.0954\n",
      "Episode:1387 meanR:12.7800 R:16.0 loss:0.0297 exploreP:0.0953\n",
      "Episode:1388 meanR:12.7700 R:9.0 loss:0.0328 exploreP:0.0952\n",
      "Episode:1389 meanR:12.6800 R:8.0 loss:0.0275 exploreP:0.0951\n",
      "Episode:1390 meanR:12.6600 R:9.0 loss:0.0283 exploreP:0.0950\n",
      "Episode:1391 meanR:12.7300 R:16.0 loss:0.0288 exploreP:0.0949\n",
      "Episode:1392 meanR:12.7800 R:17.0 loss:0.0245 exploreP:0.0948\n",
      "Episode:1393 meanR:12.7700 R:9.0 loss:0.0265 exploreP:0.0947\n",
      "Episode:1394 meanR:12.7500 R:12.0 loss:0.0272 exploreP:0.0946\n",
      "Episode:1395 meanR:12.7200 R:13.0 loss:0.0277 exploreP:0.0945\n",
      "Episode:1396 meanR:12.8000 R:17.0 loss:0.0271 exploreP:0.0943\n",
      "Episode:1397 meanR:12.7200 R:9.0 loss:0.0230 exploreP:0.0943\n",
      "Episode:1398 meanR:12.7700 R:14.0 loss:0.0296 exploreP:0.0941\n",
      "Episode:1399 meanR:12.7700 R:11.0 loss:0.0294 exploreP:0.0940\n",
      "Episode:1400 meanR:12.7800 R:11.0 loss:0.0321 exploreP:0.0939\n",
      "Episode:1401 meanR:12.7100 R:9.0 loss:0.0320 exploreP:0.0939\n",
      "Episode:1402 meanR:12.6600 R:10.0 loss:0.0266 exploreP:0.0938\n",
      "Episode:1403 meanR:12.7200 R:18.0 loss:0.0276 exploreP:0.0936\n",
      "Episode:1404 meanR:12.7500 R:14.0 loss:0.0306 exploreP:0.0935\n",
      "Episode:1405 meanR:12.8000 R:16.0 loss:0.0296 exploreP:0.0934\n",
      "Episode:1406 meanR:12.8000 R:9.0 loss:0.0297 exploreP:0.0933\n",
      "Episode:1407 meanR:12.7700 R:9.0 loss:0.0281 exploreP:0.0932\n",
      "Episode:1408 meanR:12.7400 R:9.0 loss:0.0243 exploreP:0.0932\n",
      "Episode:1409 meanR:12.6700 R:15.0 loss:0.0352 exploreP:0.0930\n",
      "Episode:1410 meanR:12.5700 R:8.0 loss:0.0281 exploreP:0.0930\n",
      "Episode:1411 meanR:12.5900 R:15.0 loss:0.0257 exploreP:0.0928\n",
      "Episode:1412 meanR:12.5100 R:9.0 loss:0.0281 exploreP:0.0928\n",
      "Episode:1413 meanR:12.5300 R:14.0 loss:0.0316 exploreP:0.0927\n",
      "Episode:1414 meanR:12.5800 R:15.0 loss:0.0286 exploreP:0.0925\n",
      "Episode:1415 meanR:12.6700 R:18.0 loss:0.0293 exploreP:0.0924\n",
      "Episode:1416 meanR:12.7600 R:18.0 loss:0.0291 exploreP:0.0922\n",
      "Episode:1417 meanR:12.7500 R:11.0 loss:0.0245 exploreP:0.0921\n",
      "Episode:1418 meanR:12.7400 R:9.0 loss:0.0286 exploreP:0.0921\n",
      "Episode:1419 meanR:12.7500 R:11.0 loss:0.0283 exploreP:0.0920\n",
      "Episode:1420 meanR:12.7200 R:9.0 loss:0.0251 exploreP:0.0919\n",
      "Episode:1421 meanR:12.6400 R:9.0 loss:0.0248 exploreP:0.0918\n",
      "Episode:1422 meanR:12.6100 R:9.0 loss:0.0290 exploreP:0.0918\n",
      "Episode:1423 meanR:12.6100 R:10.0 loss:0.0263 exploreP:0.0917\n",
      "Episode:1424 meanR:12.6000 R:9.0 loss:0.0287 exploreP:0.0916\n",
      "Episode:1425 meanR:12.6000 R:10.0 loss:0.0362 exploreP:0.0915\n",
      "Episode:1426 meanR:12.6000 R:17.0 loss:0.0282 exploreP:0.0914\n",
      "Episode:1427 meanR:12.7000 R:21.0 loss:0.0284 exploreP:0.0912\n",
      "Episode:1428 meanR:12.7500 R:15.0 loss:0.0307 exploreP:0.0911\n",
      "Episode:1429 meanR:12.6900 R:11.0 loss:0.0302 exploreP:0.0910\n",
      "Episode:1430 meanR:12.6500 R:8.0 loss:0.0292 exploreP:0.0909\n",
      "Episode:1431 meanR:12.6100 R:13.0 loss:0.0318 exploreP:0.0908\n",
      "Episode:1432 meanR:12.6100 R:10.0 loss:0.0270 exploreP:0.0908\n",
      "Episode:1433 meanR:12.6900 R:17.0 loss:0.0318 exploreP:0.0906\n",
      "Episode:1434 meanR:12.7600 R:16.0 loss:0.0300 exploreP:0.0905\n",
      "Episode:1435 meanR:12.7100 R:13.0 loss:0.0238 exploreP:0.0904\n",
      "Episode:1436 meanR:12.7400 R:14.0 loss:0.0332 exploreP:0.0903\n",
      "Episode:1437 meanR:12.6700 R:11.0 loss:0.0283 exploreP:0.0902\n",
      "Episode:1438 meanR:12.6000 R:11.0 loss:0.0270 exploreP:0.0901\n",
      "Episode:1439 meanR:12.6500 R:15.0 loss:0.0283 exploreP:0.0900\n",
      "Episode:1440 meanR:12.6600 R:16.0 loss:0.0289 exploreP:0.0898\n",
      "Episode:1441 meanR:12.6600 R:9.0 loss:0.0290 exploreP:0.0898\n",
      "Episode:1442 meanR:12.6800 R:13.0 loss:0.0283 exploreP:0.0897\n",
      "Episode:1443 meanR:12.6900 R:14.0 loss:0.0281 exploreP:0.0896\n",
      "Episode:1444 meanR:12.6800 R:9.0 loss:0.0282 exploreP:0.0895\n",
      "Episode:1445 meanR:12.7000 R:16.0 loss:0.0280 exploreP:0.0894\n",
      "Episode:1446 meanR:12.7100 R:13.0 loss:0.0274 exploreP:0.0893\n",
      "Episode:1447 meanR:12.7700 R:17.0 loss:0.0312 exploreP:0.0891\n",
      "Episode:1448 meanR:12.8000 R:12.0 loss:0.0252 exploreP:0.0890\n",
      "Episode:1449 meanR:12.7100 R:8.0 loss:0.0297 exploreP:0.0890\n",
      "Episode:1450 meanR:12.6400 R:10.0 loss:0.0233 exploreP:0.0889\n",
      "Episode:1451 meanR:12.6300 R:9.0 loss:0.0247 exploreP:0.0888\n",
      "Episode:1452 meanR:12.6900 R:17.0 loss:0.0267 exploreP:0.0887\n",
      "Episode:1453 meanR:12.6900 R:15.0 loss:0.0284 exploreP:0.0886\n",
      "Episode:1454 meanR:12.5800 R:8.0 loss:0.0245 exploreP:0.0885\n",
      "Episode:1455 meanR:12.5800 R:13.0 loss:0.0261 exploreP:0.0884\n",
      "Episode:1456 meanR:12.5100 R:11.0 loss:0.0289 exploreP:0.0883\n",
      "Episode:1457 meanR:12.4500 R:10.0 loss:0.0277 exploreP:0.0882\n",
      "Episode:1458 meanR:12.4500 R:11.0 loss:0.0344 exploreP:0.0881\n",
      "Episode:1459 meanR:12.4900 R:18.0 loss:0.0262 exploreP:0.0880\n",
      "Episode:1460 meanR:12.4900 R:12.0 loss:0.0258 exploreP:0.0879\n",
      "Episode:1461 meanR:12.5500 R:16.0 loss:0.0358 exploreP:0.0878\n",
      "Episode:1462 meanR:12.5000 R:9.0 loss:0.0345 exploreP:0.0877\n",
      "Episode:1463 meanR:12.5700 R:16.0 loss:0.0267 exploreP:0.0876\n",
      "Episode:1464 meanR:12.5700 R:11.0 loss:0.0274 exploreP:0.0875\n",
      "Episode:1465 meanR:12.5400 R:14.0 loss:0.0342 exploreP:0.0874\n",
      "Episode:1466 meanR:12.5400 R:10.0 loss:0.0259 exploreP:0.0873\n",
      "Episode:1467 meanR:12.6200 R:17.0 loss:0.0268 exploreP:0.0872\n",
      "Episode:1468 meanR:12.6200 R:9.0 loss:0.0262 exploreP:0.0871\n",
      "Episode:1469 meanR:12.5200 R:9.0 loss:0.0319 exploreP:0.0871\n",
      "Episode:1470 meanR:12.4500 R:9.0 loss:0.0270 exploreP:0.0870\n",
      "Episode:1471 meanR:12.5600 R:20.0 loss:0.0296 exploreP:0.0868\n",
      "Episode:1472 meanR:12.4900 R:10.0 loss:0.0336 exploreP:0.0868\n",
      "Episode:1473 meanR:12.5200 R:14.0 loss:0.0280 exploreP:0.0866\n",
      "Episode:1474 meanR:12.4500 R:9.0 loss:0.0292 exploreP:0.0866\n",
      "Episode:1475 meanR:12.4200 R:14.0 loss:0.0261 exploreP:0.0865\n",
      "Episode:1476 meanR:12.5100 R:17.0 loss:0.0307 exploreP:0.0863\n",
      "Episode:1477 meanR:12.5500 R:15.0 loss:0.0269 exploreP:0.0862\n",
      "Episode:1478 meanR:12.6200 R:15.0 loss:0.0295 exploreP:0.0861\n",
      "Episode:1479 meanR:12.5800 R:11.0 loss:0.0340 exploreP:0.0860\n",
      "Episode:1480 meanR:12.5400 R:10.0 loss:0.0276 exploreP:0.0860\n",
      "Episode:1481 meanR:12.5500 R:17.0 loss:0.0285 exploreP:0.0858\n",
      "Episode:1482 meanR:12.5100 R:10.0 loss:0.0263 exploreP:0.0857\n",
      "Episode:1483 meanR:12.5600 R:17.0 loss:0.0293 exploreP:0.0856\n",
      "Episode:1484 meanR:12.6400 R:18.0 loss:0.0283 exploreP:0.0855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1485 meanR:12.6700 R:17.0 loss:0.0310 exploreP:0.0854\n",
      "Episode:1486 meanR:12.6800 R:17.0 loss:0.0288 exploreP:0.0852\n",
      "Episode:1487 meanR:12.6700 R:15.0 loss:0.0320 exploreP:0.0851\n",
      "Episode:1488 meanR:12.7400 R:16.0 loss:0.0279 exploreP:0.0850\n",
      "Episode:1489 meanR:12.8100 R:15.0 loss:0.0307 exploreP:0.0849\n",
      "Episode:1490 meanR:12.8800 R:16.0 loss:0.0280 exploreP:0.0848\n",
      "Episode:1491 meanR:12.8900 R:17.0 loss:0.0315 exploreP:0.0846\n",
      "Episode:1492 meanR:12.8800 R:16.0 loss:0.0270 exploreP:0.0845\n",
      "Episode:1493 meanR:12.9400 R:15.0 loss:0.0313 exploreP:0.0844\n",
      "Episode:1494 meanR:12.9300 R:11.0 loss:0.0248 exploreP:0.0843\n",
      "Episode:1495 meanR:12.9700 R:17.0 loss:0.0281 exploreP:0.0842\n",
      "Episode:1496 meanR:12.9100 R:11.0 loss:0.0254 exploreP:0.0841\n",
      "Episode:1497 meanR:12.9600 R:14.0 loss:0.0263 exploreP:0.0840\n",
      "Episode:1498 meanR:12.9900 R:17.0 loss:0.0290 exploreP:0.0839\n",
      "Episode:1499 meanR:13.0500 R:17.0 loss:0.0267 exploreP:0.0838\n",
      "Episode:1500 meanR:13.1100 R:17.0 loss:0.0280 exploreP:0.0836\n",
      "Episode:1501 meanR:13.1700 R:15.0 loss:0.0285 exploreP:0.0835\n",
      "Episode:1502 meanR:13.2100 R:14.0 loss:0.0285 exploreP:0.0834\n",
      "Episode:1503 meanR:13.1200 R:9.0 loss:0.0343 exploreP:0.0834\n",
      "Episode:1504 meanR:13.0900 R:11.0 loss:0.0347 exploreP:0.0833\n",
      "Episode:1505 meanR:13.0900 R:16.0 loss:0.0285 exploreP:0.0832\n",
      "Episode:1506 meanR:13.1500 R:15.0 loss:0.0278 exploreP:0.0830\n",
      "Episode:1507 meanR:13.1500 R:9.0 loss:0.0288 exploreP:0.0830\n",
      "Episode:1508 meanR:13.2000 R:14.0 loss:0.0307 exploreP:0.0829\n",
      "Episode:1509 meanR:13.1400 R:9.0 loss:0.0253 exploreP:0.0828\n",
      "Episode:1510 meanR:13.1600 R:10.0 loss:0.0331 exploreP:0.0827\n",
      "Episode:1511 meanR:13.1100 R:10.0 loss:0.0267 exploreP:0.0827\n",
      "Episode:1512 meanR:13.2000 R:18.0 loss:0.0321 exploreP:0.0825\n",
      "Episode:1513 meanR:13.1500 R:9.0 loss:0.0279 exploreP:0.0825\n",
      "Episode:1514 meanR:13.1700 R:17.0 loss:0.0268 exploreP:0.0823\n",
      "Episode:1515 meanR:13.0900 R:10.0 loss:0.0296 exploreP:0.0823\n",
      "Episode:1516 meanR:13.0100 R:10.0 loss:0.0312 exploreP:0.0822\n",
      "Episode:1517 meanR:13.0100 R:11.0 loss:0.0232 exploreP:0.0821\n",
      "Episode:1518 meanR:13.0100 R:9.0 loss:0.0326 exploreP:0.0821\n",
      "Episode:1519 meanR:12.9900 R:9.0 loss:0.0269 exploreP:0.0820\n",
      "Episode:1520 meanR:13.0700 R:17.0 loss:0.0295 exploreP:0.0819\n",
      "Episode:1521 meanR:13.0700 R:9.0 loss:0.0242 exploreP:0.0818\n",
      "Episode:1522 meanR:13.1400 R:16.0 loss:0.0275 exploreP:0.0817\n",
      "Episode:1523 meanR:13.2200 R:18.0 loss:0.0338 exploreP:0.0816\n",
      "Episode:1524 meanR:13.2800 R:15.0 loss:0.0270 exploreP:0.0815\n",
      "Episode:1525 meanR:13.2600 R:8.0 loss:0.0329 exploreP:0.0814\n",
      "Episode:1526 meanR:13.2500 R:16.0 loss:0.0294 exploreP:0.0813\n",
      "Episode:1527 meanR:13.1400 R:10.0 loss:0.0258 exploreP:0.0812\n",
      "Episode:1528 meanR:13.1700 R:18.0 loss:0.0272 exploreP:0.0811\n",
      "Episode:1529 meanR:13.2000 R:14.0 loss:0.0280 exploreP:0.0810\n",
      "Episode:1530 meanR:13.2700 R:15.0 loss:0.0248 exploreP:0.0809\n",
      "Episode:1531 meanR:13.2900 R:15.0 loss:0.0314 exploreP:0.0808\n",
      "Episode:1532 meanR:13.3300 R:14.0 loss:0.0262 exploreP:0.0807\n",
      "Episode:1533 meanR:13.3400 R:18.0 loss:0.0275 exploreP:0.0805\n",
      "Episode:1534 meanR:13.2900 R:11.0 loss:0.0262 exploreP:0.0805\n",
      "Episode:1535 meanR:13.3300 R:17.0 loss:0.0291 exploreP:0.0804\n",
      "Episode:1536 meanR:13.2900 R:10.0 loss:0.0296 exploreP:0.0803\n",
      "Episode:1537 meanR:13.2900 R:11.0 loss:0.0333 exploreP:0.0802\n",
      "Episode:1538 meanR:13.2700 R:9.0 loss:0.0288 exploreP:0.0801\n",
      "Episode:1539 meanR:13.2200 R:10.0 loss:0.0221 exploreP:0.0801\n",
      "Episode:1540 meanR:13.1800 R:12.0 loss:0.0308 exploreP:0.0800\n",
      "Episode:1541 meanR:13.2000 R:11.0 loss:0.0284 exploreP:0.0799\n",
      "Episode:1542 meanR:13.2300 R:16.0 loss:0.0265 exploreP:0.0798\n",
      "Episode:1543 meanR:13.2600 R:17.0 loss:0.0258 exploreP:0.0797\n",
      "Episode:1544 meanR:13.3400 R:17.0 loss:0.0275 exploreP:0.0796\n",
      "Episode:1545 meanR:13.3300 R:15.0 loss:0.0255 exploreP:0.0795\n",
      "Episode:1546 meanR:13.3200 R:12.0 loss:0.0301 exploreP:0.0794\n",
      "Episode:1547 meanR:13.2600 R:11.0 loss:0.0316 exploreP:0.0793\n",
      "Episode:1548 meanR:13.2700 R:13.0 loss:0.0296 exploreP:0.0792\n",
      "Episode:1549 meanR:13.3300 R:14.0 loss:0.0286 exploreP:0.0791\n",
      "Episode:1550 meanR:13.4200 R:19.0 loss:0.0297 exploreP:0.0790\n",
      "Episode:1551 meanR:13.4200 R:9.0 loss:0.0260 exploreP:0.0789\n",
      "Episode:1552 meanR:13.4300 R:18.0 loss:0.0302 exploreP:0.0788\n",
      "Episode:1553 meanR:13.4200 R:14.0 loss:0.0273 exploreP:0.0787\n",
      "Episode:1554 meanR:13.4700 R:13.0 loss:0.0285 exploreP:0.0786\n",
      "Episode:1555 meanR:13.5000 R:16.0 loss:0.0294 exploreP:0.0785\n",
      "Episode:1556 meanR:13.5000 R:11.0 loss:0.0325 exploreP:0.0784\n",
      "Episode:1557 meanR:13.5000 R:10.0 loss:0.0271 exploreP:0.0784\n",
      "Episode:1558 meanR:13.4900 R:10.0 loss:0.0282 exploreP:0.0783\n",
      "Episode:1559 meanR:13.4800 R:17.0 loss:0.0281 exploreP:0.0782\n",
      "Episode:1560 meanR:13.4700 R:11.0 loss:0.0286 exploreP:0.0781\n",
      "Episode:1561 meanR:13.5200 R:21.0 loss:0.0309 exploreP:0.0780\n",
      "Episode:1562 meanR:13.5200 R:9.0 loss:0.0272 exploreP:0.0779\n",
      "Episode:1563 meanR:13.5300 R:17.0 loss:0.0297 exploreP:0.0778\n",
      "Episode:1564 meanR:13.5100 R:9.0 loss:0.0284 exploreP:0.0777\n",
      "Episode:1565 meanR:13.5000 R:13.0 loss:0.0277 exploreP:0.0776\n",
      "Episode:1566 meanR:13.5600 R:16.0 loss:0.0276 exploreP:0.0775\n",
      "Episode:1567 meanR:13.5400 R:15.0 loss:0.0305 exploreP:0.0774\n",
      "Episode:1568 meanR:13.6100 R:16.0 loss:0.0332 exploreP:0.0773\n",
      "Episode:1569 meanR:13.6400 R:12.0 loss:0.0320 exploreP:0.0772\n",
      "Episode:1570 meanR:13.7000 R:15.0 loss:0.0266 exploreP:0.0771\n",
      "Episode:1571 meanR:13.6500 R:15.0 loss:0.0251 exploreP:0.0770\n",
      "Episode:1572 meanR:13.6700 R:12.0 loss:0.0217 exploreP:0.0769\n",
      "Episode:1573 meanR:13.6900 R:16.0 loss:0.0347 exploreP:0.0768\n",
      "Episode:1574 meanR:13.7500 R:15.0 loss:0.0312 exploreP:0.0767\n",
      "Episode:1575 meanR:13.7800 R:17.0 loss:0.0316 exploreP:0.0766\n",
      "Episode:1576 meanR:13.7000 R:9.0 loss:0.0339 exploreP:0.0766\n",
      "Episode:1577 meanR:13.6900 R:14.0 loss:0.0322 exploreP:0.0765\n",
      "Episode:1578 meanR:13.6500 R:11.0 loss:0.0294 exploreP:0.0764\n",
      "Episode:1579 meanR:13.6500 R:11.0 loss:0.0223 exploreP:0.0763\n",
      "Episode:1580 meanR:13.6500 R:10.0 loss:0.0328 exploreP:0.0763\n",
      "Episode:1581 meanR:13.6400 R:16.0 loss:0.0341 exploreP:0.0762\n",
      "Episode:1582 meanR:13.6900 R:15.0 loss:0.0286 exploreP:0.0761\n",
      "Episode:1583 meanR:13.6600 R:14.0 loss:0.0315 exploreP:0.0760\n",
      "Episode:1584 meanR:13.6200 R:14.0 loss:0.0297 exploreP:0.0759\n",
      "Episode:1585 meanR:13.5700 R:12.0 loss:0.0287 exploreP:0.0758\n",
      "Episode:1586 meanR:13.5400 R:14.0 loss:0.0270 exploreP:0.0757\n",
      "Episode:1587 meanR:13.4900 R:10.0 loss:0.0285 exploreP:0.0756\n",
      "Episode:1588 meanR:13.4200 R:9.0 loss:0.0268 exploreP:0.0756\n",
      "Episode:1589 meanR:13.3800 R:11.0 loss:0.0242 exploreP:0.0755\n",
      "Episode:1590 meanR:13.3900 R:17.0 loss:0.0297 exploreP:0.0754\n",
      "Episode:1591 meanR:13.3300 R:11.0 loss:0.0276 exploreP:0.0753\n",
      "Episode:1592 meanR:13.3000 R:13.0 loss:0.0260 exploreP:0.0752\n",
      "Episode:1593 meanR:13.2800 R:13.0 loss:0.0312 exploreP:0.0752\n",
      "Episode:1594 meanR:13.2800 R:11.0 loss:0.0312 exploreP:0.0751\n",
      "Episode:1595 meanR:13.2000 R:9.0 loss:0.0287 exploreP:0.0750\n",
      "Episode:1596 meanR:13.2400 R:15.0 loss:0.0331 exploreP:0.0749\n",
      "Episode:1597 meanR:13.2400 R:14.0 loss:0.0281 exploreP:0.0748\n",
      "Episode:1598 meanR:13.2400 R:17.0 loss:0.0321 exploreP:0.0747\n",
      "Episode:1599 meanR:13.2200 R:15.0 loss:0.0295 exploreP:0.0746\n",
      "Episode:1600 meanR:13.1700 R:12.0 loss:0.0296 exploreP:0.0745\n",
      "Episode:1601 meanR:13.1400 R:12.0 loss:0.0317 exploreP:0.0745\n",
      "Episode:1602 meanR:13.1400 R:14.0 loss:0.0278 exploreP:0.0744\n",
      "Episode:1603 meanR:13.1400 R:9.0 loss:0.0261 exploreP:0.0743\n",
      "Episode:1604 meanR:13.1900 R:16.0 loss:0.0291 exploreP:0.0742\n",
      "Episode:1605 meanR:13.1800 R:15.0 loss:0.0328 exploreP:0.0741\n",
      "Episode:1606 meanR:13.2100 R:18.0 loss:0.0295 exploreP:0.0740\n",
      "Episode:1607 meanR:13.2400 R:12.0 loss:0.0309 exploreP:0.0739\n",
      "Episode:1608 meanR:13.2700 R:17.0 loss:0.0275 exploreP:0.0738\n",
      "Episode:1609 meanR:13.2900 R:11.0 loss:0.0319 exploreP:0.0738\n",
      "Episode:1610 meanR:13.3200 R:13.0 loss:0.0289 exploreP:0.0737\n",
      "Episode:1611 meanR:13.3600 R:14.0 loss:0.0285 exploreP:0.0736\n",
      "Episode:1612 meanR:13.3300 R:15.0 loss:0.0321 exploreP:0.0735\n",
      "Episode:1613 meanR:13.3500 R:11.0 loss:0.0267 exploreP:0.0734\n",
      "Episode:1614 meanR:13.2800 R:10.0 loss:0.0313 exploreP:0.0734\n",
      "Episode:1615 meanR:13.3000 R:12.0 loss:0.0321 exploreP:0.0733\n",
      "Episode:1616 meanR:13.3500 R:15.0 loss:0.0283 exploreP:0.0732\n",
      "Episode:1617 meanR:13.3400 R:10.0 loss:0.0309 exploreP:0.0731\n",
      "Episode:1618 meanR:13.3500 R:10.0 loss:0.0304 exploreP:0.0731\n",
      "Episode:1619 meanR:13.3500 R:9.0 loss:0.0309 exploreP:0.0730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1620 meanR:13.3100 R:13.0 loss:0.0275 exploreP:0.0729\n",
      "Episode:1621 meanR:13.3800 R:16.0 loss:0.0295 exploreP:0.0728\n",
      "Episode:1622 meanR:13.3200 R:10.0 loss:0.0309 exploreP:0.0728\n",
      "Episode:1623 meanR:13.2700 R:13.0 loss:0.0277 exploreP:0.0727\n",
      "Episode:1624 meanR:13.2100 R:9.0 loss:0.0306 exploreP:0.0726\n",
      "Episode:1625 meanR:13.2600 R:13.0 loss:0.0264 exploreP:0.0725\n",
      "Episode:1626 meanR:13.2300 R:13.0 loss:0.0296 exploreP:0.0725\n",
      "Episode:1627 meanR:13.2800 R:15.0 loss:0.0314 exploreP:0.0724\n",
      "Episode:1628 meanR:13.2500 R:15.0 loss:0.0254 exploreP:0.0723\n",
      "Episode:1629 meanR:13.2400 R:13.0 loss:0.0255 exploreP:0.0722\n",
      "Episode:1630 meanR:13.2500 R:16.0 loss:0.0275 exploreP:0.0721\n",
      "Episode:1631 meanR:13.2200 R:12.0 loss:0.0301 exploreP:0.0720\n",
      "Episode:1632 meanR:13.2000 R:12.0 loss:0.0277 exploreP:0.0719\n",
      "Episode:1633 meanR:13.1500 R:13.0 loss:0.0316 exploreP:0.0719\n",
      "Episode:1634 meanR:13.1400 R:10.0 loss:0.0299 exploreP:0.0718\n",
      "Episode:1635 meanR:13.0600 R:9.0 loss:0.0365 exploreP:0.0717\n",
      "Episode:1636 meanR:13.1000 R:14.0 loss:0.0307 exploreP:0.0717\n",
      "Episode:1637 meanR:13.1700 R:18.0 loss:0.0299 exploreP:0.0715\n",
      "Episode:1638 meanR:13.2100 R:13.0 loss:0.0300 exploreP:0.0715\n",
      "Episode:1639 meanR:13.2000 R:9.0 loss:0.0369 exploreP:0.0714\n",
      "Episode:1640 meanR:13.1800 R:10.0 loss:0.0328 exploreP:0.0713\n",
      "Episode:1641 meanR:13.2000 R:13.0 loss:0.0280 exploreP:0.0713\n",
      "Episode:1642 meanR:13.1500 R:11.0 loss:0.0303 exploreP:0.0712\n",
      "Episode:1643 meanR:13.1600 R:18.0 loss:0.0293 exploreP:0.0711\n",
      "Episode:1644 meanR:13.1500 R:16.0 loss:0.0298 exploreP:0.0710\n",
      "Episode:1645 meanR:13.1100 R:11.0 loss:0.0247 exploreP:0.0709\n",
      "Episode:1646 meanR:13.1000 R:11.0 loss:0.0379 exploreP:0.0709\n",
      "Episode:1647 meanR:13.1600 R:17.0 loss:0.0323 exploreP:0.0708\n",
      "Episode:1648 meanR:13.1100 R:8.0 loss:0.0337 exploreP:0.0707\n",
      "Episode:1649 meanR:13.1400 R:17.0 loss:0.0260 exploreP:0.0706\n",
      "Episode:1650 meanR:13.0800 R:13.0 loss:0.0280 exploreP:0.0705\n",
      "Episode:1651 meanR:13.1000 R:11.0 loss:0.0297 exploreP:0.0705\n",
      "Episode:1652 meanR:13.0500 R:13.0 loss:0.0350 exploreP:0.0704\n",
      "Episode:1653 meanR:13.0800 R:17.0 loss:0.0357 exploreP:0.0703\n",
      "Episode:1654 meanR:13.0600 R:11.0 loss:0.0298 exploreP:0.0702\n",
      "Episode:1655 meanR:13.0300 R:13.0 loss:0.0299 exploreP:0.0701\n",
      "Episode:1656 meanR:13.1100 R:19.0 loss:0.0341 exploreP:0.0700\n",
      "Episode:1657 meanR:13.1200 R:11.0 loss:0.0302 exploreP:0.0699\n",
      "Episode:1658 meanR:13.1900 R:17.0 loss:0.0271 exploreP:0.0698\n",
      "Episode:1659 meanR:13.1300 R:11.0 loss:0.0327 exploreP:0.0698\n",
      "Episode:1660 meanR:13.1100 R:9.0 loss:0.0315 exploreP:0.0697\n",
      "Episode:1661 meanR:13.0100 R:11.0 loss:0.0223 exploreP:0.0697\n",
      "Episode:1662 meanR:13.0400 R:12.0 loss:0.0316 exploreP:0.0696\n",
      "Episode:1663 meanR:12.9800 R:11.0 loss:0.0261 exploreP:0.0695\n",
      "Episode:1664 meanR:13.0200 R:13.0 loss:0.0266 exploreP:0.0694\n",
      "Episode:1665 meanR:13.0300 R:14.0 loss:0.0288 exploreP:0.0694\n",
      "Episode:1666 meanR:13.0200 R:15.0 loss:0.0313 exploreP:0.0693\n",
      "Episode:1667 meanR:13.0000 R:13.0 loss:0.0309 exploreP:0.0692\n",
      "Episode:1668 meanR:12.9900 R:15.0 loss:0.0310 exploreP:0.0691\n",
      "Episode:1669 meanR:13.0100 R:14.0 loss:0.0287 exploreP:0.0690\n",
      "Episode:1670 meanR:13.0400 R:18.0 loss:0.0262 exploreP:0.0689\n",
      "Episode:1671 meanR:13.0500 R:16.0 loss:0.0296 exploreP:0.0688\n",
      "Episode:1672 meanR:13.1100 R:18.0 loss:0.0321 exploreP:0.0687\n",
      "Episode:1673 meanR:13.1100 R:16.0 loss:0.0315 exploreP:0.0686\n",
      "Episode:1674 meanR:13.1200 R:16.0 loss:0.0294 exploreP:0.0685\n",
      "Episode:1675 meanR:13.0500 R:10.0 loss:0.0348 exploreP:0.0685\n",
      "Episode:1676 meanR:13.0500 R:9.0 loss:0.0296 exploreP:0.0684\n",
      "Episode:1677 meanR:13.0200 R:11.0 loss:0.0331 exploreP:0.0684\n",
      "Episode:1678 meanR:13.0600 R:15.0 loss:0.0350 exploreP:0.0683\n",
      "Episode:1679 meanR:13.1000 R:15.0 loss:0.0300 exploreP:0.0682\n",
      "Episode:1680 meanR:13.1400 R:14.0 loss:0.0308 exploreP:0.0681\n",
      "Episode:1681 meanR:13.1300 R:15.0 loss:0.0324 exploreP:0.0680\n",
      "Episode:1682 meanR:13.0900 R:11.0 loss:0.0286 exploreP:0.0680\n",
      "Episode:1683 meanR:13.0800 R:13.0 loss:0.0315 exploreP:0.0679\n",
      "Episode:1684 meanR:13.0200 R:8.0 loss:0.0277 exploreP:0.0678\n",
      "Episode:1685 meanR:12.9900 R:9.0 loss:0.0352 exploreP:0.0678\n",
      "Episode:1686 meanR:12.9600 R:11.0 loss:0.0357 exploreP:0.0677\n",
      "Episode:1687 meanR:13.0200 R:16.0 loss:0.0295 exploreP:0.0676\n",
      "Episode:1688 meanR:13.0900 R:16.0 loss:0.0305 exploreP:0.0675\n",
      "Episode:1689 meanR:13.1200 R:14.0 loss:0.0339 exploreP:0.0674\n",
      "Episode:1690 meanR:13.0800 R:13.0 loss:0.0323 exploreP:0.0674\n",
      "Episode:1691 meanR:13.0900 R:12.0 loss:0.0348 exploreP:0.0673\n",
      "Episode:1692 meanR:13.1300 R:17.0 loss:0.0322 exploreP:0.0672\n",
      "Episode:1693 meanR:13.1500 R:15.0 loss:0.0303 exploreP:0.0671\n",
      "Episode:1694 meanR:13.1700 R:13.0 loss:0.0324 exploreP:0.0670\n",
      "Episode:1695 meanR:13.2300 R:15.0 loss:0.0279 exploreP:0.0670\n",
      "Episode:1696 meanR:13.1700 R:9.0 loss:0.0304 exploreP:0.0669\n",
      "Episode:1697 meanR:13.2000 R:17.0 loss:0.0335 exploreP:0.0668\n",
      "Episode:1698 meanR:13.1300 R:10.0 loss:0.0319 exploreP:0.0668\n",
      "Episode:1699 meanR:13.1000 R:12.0 loss:0.0356 exploreP:0.0667\n",
      "Episode:1700 meanR:13.1300 R:15.0 loss:0.0293 exploreP:0.0666\n",
      "Episode:1701 meanR:13.1000 R:9.0 loss:0.0354 exploreP:0.0666\n",
      "Episode:1702 meanR:13.1000 R:14.0 loss:0.0293 exploreP:0.0665\n",
      "Episode:1703 meanR:13.1200 R:11.0 loss:0.0338 exploreP:0.0664\n",
      "Episode:1704 meanR:13.1100 R:15.0 loss:0.0285 exploreP:0.0663\n",
      "Episode:1705 meanR:13.1200 R:16.0 loss:0.0304 exploreP:0.0662\n",
      "Episode:1706 meanR:13.0500 R:11.0 loss:0.0333 exploreP:0.0662\n",
      "Episode:1707 meanR:13.0500 R:12.0 loss:0.0340 exploreP:0.0661\n",
      "Episode:1708 meanR:13.0200 R:14.0 loss:0.0327 exploreP:0.0660\n",
      "Episode:1709 meanR:13.0400 R:13.0 loss:0.0283 exploreP:0.0660\n",
      "Episode:1710 meanR:13.0600 R:15.0 loss:0.0401 exploreP:0.0659\n",
      "Episode:1711 meanR:13.0500 R:13.0 loss:0.0270 exploreP:0.0658\n",
      "Episode:1712 meanR:13.0200 R:12.0 loss:0.0272 exploreP:0.0657\n",
      "Episode:1713 meanR:13.0400 R:13.0 loss:0.0309 exploreP:0.0657\n",
      "Episode:1714 meanR:13.0600 R:12.0 loss:0.0377 exploreP:0.0656\n",
      "Episode:1715 meanR:13.0900 R:15.0 loss:0.0295 exploreP:0.0655\n",
      "Episode:1716 meanR:13.0900 R:15.0 loss:0.0306 exploreP:0.0654\n",
      "Episode:1717 meanR:13.1400 R:15.0 loss:0.0295 exploreP:0.0653\n",
      "Episode:1718 meanR:13.1300 R:9.0 loss:0.0384 exploreP:0.0653\n",
      "Episode:1719 meanR:13.1700 R:13.0 loss:0.0298 exploreP:0.0652\n",
      "Episode:1720 meanR:13.2000 R:16.0 loss:0.0308 exploreP:0.0651\n",
      "Episode:1721 meanR:13.1600 R:12.0 loss:0.0352 exploreP:0.0651\n",
      "Episode:1722 meanR:13.2000 R:14.0 loss:0.0303 exploreP:0.0650\n",
      "Episode:1723 meanR:13.2000 R:13.0 loss:0.0322 exploreP:0.0649\n",
      "Episode:1724 meanR:13.2000 R:9.0 loss:0.0307 exploreP:0.0649\n",
      "Episode:1725 meanR:13.2200 R:15.0 loss:0.0318 exploreP:0.0648\n",
      "Episode:1726 meanR:13.1800 R:9.0 loss:0.0299 exploreP:0.0647\n",
      "Episode:1727 meanR:13.1700 R:14.0 loss:0.0322 exploreP:0.0647\n",
      "Episode:1728 meanR:13.1700 R:15.0 loss:0.0288 exploreP:0.0646\n",
      "Episode:1729 meanR:13.1300 R:9.0 loss:0.0310 exploreP:0.0645\n",
      "Episode:1730 meanR:13.1400 R:17.0 loss:0.0283 exploreP:0.0644\n",
      "Episode:1731 meanR:13.1900 R:17.0 loss:0.0307 exploreP:0.0643\n",
      "Episode:1732 meanR:13.2100 R:14.0 loss:0.0267 exploreP:0.0643\n",
      "Episode:1733 meanR:13.1800 R:10.0 loss:0.0404 exploreP:0.0642\n",
      "Episode:1734 meanR:13.2300 R:15.0 loss:0.0394 exploreP:0.0641\n",
      "Episode:1735 meanR:13.2700 R:13.0 loss:0.0309 exploreP:0.0641\n",
      "Episode:1736 meanR:13.2400 R:11.0 loss:0.0351 exploreP:0.0640\n",
      "Episode:1737 meanR:13.1600 R:10.0 loss:0.0288 exploreP:0.0640\n",
      "Episode:1738 meanR:13.1500 R:12.0 loss:0.0332 exploreP:0.0639\n",
      "Episode:1739 meanR:13.1900 R:13.0 loss:0.0267 exploreP:0.0638\n",
      "Episode:1740 meanR:13.2600 R:17.0 loss:0.0283 exploreP:0.0637\n",
      "Episode:1741 meanR:13.2400 R:11.0 loss:0.0364 exploreP:0.0637\n",
      "Episode:1742 meanR:13.2800 R:15.0 loss:0.0321 exploreP:0.0636\n",
      "Episode:1743 meanR:13.1900 R:9.0 loss:0.0319 exploreP:0.0635\n",
      "Episode:1744 meanR:13.1400 R:11.0 loss:0.0324 exploreP:0.0635\n",
      "Episode:1745 meanR:13.1400 R:11.0 loss:0.0271 exploreP:0.0634\n",
      "Episode:1746 meanR:13.1900 R:16.0 loss:0.0256 exploreP:0.0633\n",
      "Episode:1747 meanR:13.1500 R:13.0 loss:0.0300 exploreP:0.0633\n",
      "Episode:1748 meanR:13.2200 R:15.0 loss:0.0313 exploreP:0.0632\n",
      "Episode:1749 meanR:13.1600 R:11.0 loss:0.0359 exploreP:0.0631\n",
      "Episode:1750 meanR:13.1500 R:12.0 loss:0.0338 exploreP:0.0631\n",
      "Episode:1751 meanR:13.1700 R:13.0 loss:0.0354 exploreP:0.0630\n",
      "Episode:1752 meanR:13.1900 R:15.0 loss:0.0264 exploreP:0.0629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1753 meanR:13.1100 R:9.0 loss:0.0309 exploreP:0.0629\n",
      "Episode:1754 meanR:13.1300 R:13.0 loss:0.0312 exploreP:0.0628\n",
      "Episode:1755 meanR:13.1200 R:12.0 loss:0.0338 exploreP:0.0627\n",
      "Episode:1756 meanR:13.0400 R:11.0 loss:0.0321 exploreP:0.0627\n",
      "Episode:1757 meanR:13.0700 R:14.0 loss:0.0334 exploreP:0.0626\n",
      "Episode:1758 meanR:12.9900 R:9.0 loss:0.0309 exploreP:0.0626\n",
      "Episode:1759 meanR:13.0000 R:12.0 loss:0.0344 exploreP:0.0625\n",
      "Episode:1760 meanR:13.0400 R:13.0 loss:0.0342 exploreP:0.0624\n",
      "Episode:1761 meanR:13.0500 R:12.0 loss:0.0294 exploreP:0.0624\n",
      "Episode:1762 meanR:13.0400 R:11.0 loss:0.0284 exploreP:0.0623\n",
      "Episode:1763 meanR:13.0400 R:11.0 loss:0.0331 exploreP:0.0622\n",
      "Episode:1764 meanR:13.0100 R:10.0 loss:0.0309 exploreP:0.0622\n",
      "Episode:1765 meanR:13.0400 R:17.0 loss:0.0330 exploreP:0.0621\n",
      "Episode:1766 meanR:13.0000 R:11.0 loss:0.0324 exploreP:0.0621\n",
      "Episode:1767 meanR:13.0200 R:15.0 loss:0.0343 exploreP:0.0620\n",
      "Episode:1768 meanR:13.0200 R:15.0 loss:0.0261 exploreP:0.0619\n",
      "Episode:1769 meanR:13.0000 R:12.0 loss:0.0358 exploreP:0.0618\n",
      "Episode:1770 meanR:12.9500 R:13.0 loss:0.0293 exploreP:0.0618\n",
      "Episode:1771 meanR:12.9600 R:17.0 loss:0.0304 exploreP:0.0617\n",
      "Episode:1772 meanR:12.9100 R:13.0 loss:0.0271 exploreP:0.0616\n",
      "Episode:1773 meanR:12.8400 R:9.0 loss:0.0310 exploreP:0.0616\n",
      "Episode:1774 meanR:12.8100 R:13.0 loss:0.0328 exploreP:0.0615\n",
      "Episode:1775 meanR:12.8300 R:12.0 loss:0.0372 exploreP:0.0614\n",
      "Episode:1776 meanR:12.8900 R:15.0 loss:0.0338 exploreP:0.0614\n",
      "Episode:1777 meanR:12.9000 R:12.0 loss:0.0292 exploreP:0.0613\n",
      "Episode:1778 meanR:12.8900 R:14.0 loss:0.0318 exploreP:0.0612\n",
      "Episode:1779 meanR:12.9000 R:16.0 loss:0.0296 exploreP:0.0611\n",
      "Episode:1780 meanR:12.9000 R:14.0 loss:0.0318 exploreP:0.0611\n",
      "Episode:1781 meanR:12.9000 R:15.0 loss:0.0297 exploreP:0.0610\n",
      "Episode:1782 meanR:12.9000 R:11.0 loss:0.0357 exploreP:0.0609\n",
      "Episode:1783 meanR:12.9400 R:17.0 loss:0.0349 exploreP:0.0609\n",
      "Episode:1784 meanR:13.0000 R:14.0 loss:0.0357 exploreP:0.0608\n",
      "Episode:1785 meanR:13.0800 R:17.0 loss:0.0294 exploreP:0.0607\n",
      "Episode:1786 meanR:13.0800 R:11.0 loss:0.0281 exploreP:0.0606\n",
      "Episode:1787 meanR:13.0300 R:11.0 loss:0.0299 exploreP:0.0606\n",
      "Episode:1788 meanR:13.0100 R:14.0 loss:0.0348 exploreP:0.0605\n",
      "Episode:1789 meanR:12.9600 R:9.0 loss:0.0344 exploreP:0.0605\n",
      "Episode:1790 meanR:12.9700 R:14.0 loss:0.0295 exploreP:0.0604\n",
      "Episode:1791 meanR:12.9700 R:12.0 loss:0.0388 exploreP:0.0603\n",
      "Episode:1792 meanR:12.9100 R:11.0 loss:0.0309 exploreP:0.0603\n",
      "Episode:1793 meanR:12.9100 R:15.0 loss:0.0294 exploreP:0.0602\n",
      "Episode:1794 meanR:12.9100 R:13.0 loss:0.0366 exploreP:0.0601\n",
      "Episode:1795 meanR:12.8800 R:12.0 loss:0.0288 exploreP:0.0601\n",
      "Episode:1796 meanR:12.9600 R:17.0 loss:0.0346 exploreP:0.0600\n",
      "Episode:1797 meanR:12.9000 R:11.0 loss:0.0378 exploreP:0.0599\n",
      "Episode:1798 meanR:12.9800 R:18.0 loss:0.0327 exploreP:0.0598\n",
      "Episode:1799 meanR:12.9600 R:10.0 loss:0.0303 exploreP:0.0598\n",
      "Episode:1800 meanR:12.9600 R:15.0 loss:0.0314 exploreP:0.0597\n",
      "Episode:1801 meanR:12.9900 R:12.0 loss:0.0308 exploreP:0.0597\n",
      "Episode:1802 meanR:12.9700 R:12.0 loss:0.0396 exploreP:0.0596\n",
      "Episode:1803 meanR:12.9900 R:13.0 loss:0.0321 exploreP:0.0595\n",
      "Episode:1804 meanR:13.0200 R:18.0 loss:0.0330 exploreP:0.0595\n",
      "Episode:1805 meanR:12.9700 R:11.0 loss:0.0252 exploreP:0.0594\n",
      "Episode:1806 meanR:13.0200 R:16.0 loss:0.0332 exploreP:0.0593\n",
      "Episode:1807 meanR:13.0300 R:13.0 loss:0.0299 exploreP:0.0593\n",
      "Episode:1808 meanR:13.0500 R:16.0 loss:0.0363 exploreP:0.0592\n",
      "Episode:1809 meanR:13.0500 R:13.0 loss:0.0337 exploreP:0.0591\n",
      "Episode:1810 meanR:13.0800 R:18.0 loss:0.0336 exploreP:0.0590\n",
      "Episode:1811 meanR:13.1400 R:19.0 loss:0.0320 exploreP:0.0589\n",
      "Episode:1812 meanR:13.1700 R:15.0 loss:0.0354 exploreP:0.0589\n",
      "Episode:1813 meanR:13.1500 R:11.0 loss:0.0307 exploreP:0.0588\n",
      "Episode:1814 meanR:13.1600 R:13.0 loss:0.0347 exploreP:0.0587\n",
      "Episode:1815 meanR:13.1000 R:9.0 loss:0.0269 exploreP:0.0587\n",
      "Episode:1816 meanR:13.0900 R:14.0 loss:0.0295 exploreP:0.0586\n",
      "Episode:1817 meanR:13.0700 R:13.0 loss:0.0311 exploreP:0.0586\n",
      "Episode:1818 meanR:13.1300 R:15.0 loss:0.0283 exploreP:0.0585\n",
      "Episode:1819 meanR:13.1200 R:12.0 loss:0.0316 exploreP:0.0584\n",
      "Episode:1820 meanR:13.0800 R:12.0 loss:0.0252 exploreP:0.0584\n",
      "Episode:1821 meanR:13.0900 R:13.0 loss:0.0294 exploreP:0.0583\n",
      "Episode:1822 meanR:13.1000 R:15.0 loss:0.0345 exploreP:0.0582\n",
      "Episode:1823 meanR:13.1200 R:15.0 loss:0.0343 exploreP:0.0582\n",
      "Episode:1824 meanR:13.1200 R:9.0 loss:0.0296 exploreP:0.0581\n",
      "Episode:1825 meanR:13.1000 R:13.0 loss:0.0293 exploreP:0.0581\n",
      "Episode:1826 meanR:13.1100 R:10.0 loss:0.0342 exploreP:0.0580\n",
      "Episode:1827 meanR:13.0700 R:10.0 loss:0.0317 exploreP:0.0580\n",
      "Episode:1828 meanR:13.0800 R:16.0 loss:0.0322 exploreP:0.0579\n",
      "Episode:1829 meanR:13.1500 R:16.0 loss:0.0286 exploreP:0.0578\n",
      "Episode:1830 meanR:13.1200 R:14.0 loss:0.0318 exploreP:0.0577\n",
      "Episode:1831 meanR:13.0400 R:9.0 loss:0.0321 exploreP:0.0577\n",
      "Episode:1832 meanR:13.0000 R:10.0 loss:0.0434 exploreP:0.0577\n",
      "Episode:1833 meanR:13.0400 R:14.0 loss:0.0309 exploreP:0.0576\n",
      "Episode:1834 meanR:13.0400 R:15.0 loss:0.0332 exploreP:0.0575\n",
      "Episode:1835 meanR:13.0400 R:13.0 loss:0.0318 exploreP:0.0575\n",
      "Episode:1836 meanR:13.0800 R:15.0 loss:0.0344 exploreP:0.0574\n",
      "Episode:1837 meanR:13.1400 R:16.0 loss:0.0275 exploreP:0.0573\n",
      "Episode:1838 meanR:13.1600 R:14.0 loss:0.0303 exploreP:0.0572\n",
      "Episode:1839 meanR:13.1700 R:14.0 loss:0.0330 exploreP:0.0572\n",
      "Episode:1840 meanR:13.1900 R:19.0 loss:0.0355 exploreP:0.0571\n",
      "Episode:1841 meanR:13.2300 R:15.0 loss:0.0290 exploreP:0.0570\n",
      "Episode:1842 meanR:13.2000 R:12.0 loss:0.0284 exploreP:0.0570\n",
      "Episode:1843 meanR:13.2400 R:13.0 loss:0.0270 exploreP:0.0569\n",
      "Episode:1844 meanR:13.2300 R:10.0 loss:0.0298 exploreP:0.0569\n",
      "Episode:1845 meanR:13.2700 R:15.0 loss:0.0334 exploreP:0.0568\n",
      "Episode:1846 meanR:13.2000 R:9.0 loss:0.0297 exploreP:0.0567\n",
      "Episode:1847 meanR:13.1900 R:12.0 loss:0.0373 exploreP:0.0567\n",
      "Episode:1848 meanR:13.1600 R:12.0 loss:0.0313 exploreP:0.0566\n",
      "Episode:1849 meanR:13.1700 R:12.0 loss:0.0321 exploreP:0.0566\n",
      "Episode:1850 meanR:13.1900 R:14.0 loss:0.0330 exploreP:0.0565\n",
      "Episode:1851 meanR:13.2100 R:15.0 loss:0.0365 exploreP:0.0564\n",
      "Episode:1852 meanR:13.2100 R:15.0 loss:0.0294 exploreP:0.0564\n",
      "Episode:1853 meanR:13.2500 R:13.0 loss:0.0277 exploreP:0.0563\n",
      "Episode:1854 meanR:13.3000 R:18.0 loss:0.0310 exploreP:0.0562\n",
      "Episode:1855 meanR:13.2900 R:11.0 loss:0.0364 exploreP:0.0562\n",
      "Episode:1856 meanR:13.3200 R:14.0 loss:0.0320 exploreP:0.0561\n",
      "Episode:1857 meanR:13.3200 R:14.0 loss:0.0332 exploreP:0.0560\n",
      "Episode:1858 meanR:13.3700 R:14.0 loss:0.0330 exploreP:0.0560\n",
      "Episode:1859 meanR:13.4000 R:15.0 loss:0.0307 exploreP:0.0559\n",
      "Episode:1860 meanR:13.4100 R:14.0 loss:0.0333 exploreP:0.0558\n",
      "Episode:1861 meanR:13.4600 R:17.0 loss:0.0367 exploreP:0.0558\n",
      "Episode:1862 meanR:13.4900 R:14.0 loss:0.0294 exploreP:0.0557\n",
      "Episode:1863 meanR:13.5000 R:12.0 loss:0.0315 exploreP:0.0557\n",
      "Episode:1864 meanR:13.5300 R:13.0 loss:0.0369 exploreP:0.0556\n",
      "Episode:1865 meanR:13.5100 R:15.0 loss:0.0376 exploreP:0.0555\n",
      "Episode:1866 meanR:13.5200 R:12.0 loss:0.0374 exploreP:0.0555\n",
      "Episode:1867 meanR:13.5300 R:16.0 loss:0.0306 exploreP:0.0554\n",
      "Episode:1868 meanR:13.4700 R:9.0 loss:0.0333 exploreP:0.0554\n",
      "Episode:1869 meanR:13.4500 R:10.0 loss:0.0327 exploreP:0.0553\n",
      "Episode:1870 meanR:13.4400 R:12.0 loss:0.0341 exploreP:0.0553\n",
      "Episode:1871 meanR:13.4000 R:13.0 loss:0.0323 exploreP:0.0552\n",
      "Episode:1872 meanR:13.4100 R:14.0 loss:0.0347 exploreP:0.0551\n",
      "Episode:1873 meanR:13.4900 R:17.0 loss:0.0328 exploreP:0.0551\n",
      "Episode:1874 meanR:13.4600 R:10.0 loss:0.0364 exploreP:0.0550\n",
      "Episode:1875 meanR:13.4700 R:13.0 loss:0.0324 exploreP:0.0550\n",
      "Episode:1876 meanR:13.4500 R:13.0 loss:0.0317 exploreP:0.0549\n",
      "Episode:1877 meanR:13.4700 R:14.0 loss:0.0317 exploreP:0.0548\n",
      "Episode:1878 meanR:13.5100 R:18.0 loss:0.0354 exploreP:0.0548\n",
      "Episode:1879 meanR:13.4600 R:11.0 loss:0.0399 exploreP:0.0547\n",
      "Episode:1880 meanR:13.4500 R:13.0 loss:0.0287 exploreP:0.0546\n",
      "Episode:1881 meanR:13.4200 R:12.0 loss:0.0270 exploreP:0.0546\n",
      "Episode:1882 meanR:13.4200 R:11.0 loss:0.0269 exploreP:0.0545\n",
      "Episode:1883 meanR:13.3300 R:8.0 loss:0.0361 exploreP:0.0545\n",
      "Episode:1884 meanR:13.3200 R:13.0 loss:0.0297 exploreP:0.0544\n",
      "Episode:1885 meanR:13.2500 R:10.0 loss:0.0348 exploreP:0.0544\n",
      "Episode:1886 meanR:13.2400 R:10.0 loss:0.0252 exploreP:0.0544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1887 meanR:13.2700 R:14.0 loss:0.0307 exploreP:0.0543\n",
      "Episode:1888 meanR:13.2600 R:13.0 loss:0.0341 exploreP:0.0542\n",
      "Episode:1889 meanR:13.3200 R:15.0 loss:0.0361 exploreP:0.0542\n",
      "Episode:1890 meanR:13.3000 R:12.0 loss:0.0319 exploreP:0.0541\n",
      "Episode:1891 meanR:13.2900 R:11.0 loss:0.0341 exploreP:0.0541\n",
      "Episode:1892 meanR:13.3300 R:15.0 loss:0.0362 exploreP:0.0540\n",
      "Episode:1893 meanR:13.3500 R:17.0 loss:0.0311 exploreP:0.0539\n",
      "Episode:1894 meanR:13.3300 R:11.0 loss:0.0299 exploreP:0.0539\n",
      "Episode:1895 meanR:13.3300 R:12.0 loss:0.0333 exploreP:0.0538\n",
      "Episode:1896 meanR:13.2800 R:12.0 loss:0.0390 exploreP:0.0538\n",
      "Episode:1897 meanR:13.3000 R:13.0 loss:0.0337 exploreP:0.0537\n",
      "Episode:1898 meanR:13.2400 R:12.0 loss:0.0268 exploreP:0.0537\n",
      "Episode:1899 meanR:13.2800 R:14.0 loss:0.0303 exploreP:0.0536\n",
      "Episode:1900 meanR:13.2800 R:15.0 loss:0.0323 exploreP:0.0535\n",
      "Episode:1901 meanR:13.3000 R:14.0 loss:0.0324 exploreP:0.0535\n",
      "Episode:1902 meanR:13.3200 R:14.0 loss:0.0360 exploreP:0.0534\n",
      "Episode:1903 meanR:13.3100 R:12.0 loss:0.0332 exploreP:0.0534\n",
      "Episode:1904 meanR:13.2600 R:13.0 loss:0.0305 exploreP:0.0533\n",
      "Episode:1905 meanR:13.2800 R:13.0 loss:0.0325 exploreP:0.0533\n",
      "Episode:1906 meanR:13.2100 R:9.0 loss:0.0252 exploreP:0.0532\n",
      "Episode:1907 meanR:13.1900 R:11.0 loss:0.0308 exploreP:0.0532\n",
      "Episode:1908 meanR:13.1500 R:12.0 loss:0.0343 exploreP:0.0531\n",
      "Episode:1909 meanR:13.1100 R:9.0 loss:0.0344 exploreP:0.0531\n",
      "Episode:1910 meanR:13.0600 R:13.0 loss:0.0312 exploreP:0.0530\n",
      "Episode:1911 meanR:13.0200 R:15.0 loss:0.0326 exploreP:0.0530\n",
      "Episode:1912 meanR:13.0200 R:15.0 loss:0.0398 exploreP:0.0529\n",
      "Episode:1913 meanR:13.0300 R:12.0 loss:0.0335 exploreP:0.0528\n",
      "Episode:1914 meanR:13.0200 R:12.0 loss:0.0290 exploreP:0.0528\n",
      "Episode:1915 meanR:13.0600 R:13.0 loss:0.0332 exploreP:0.0527\n",
      "Episode:1916 meanR:13.0500 R:13.0 loss:0.0368 exploreP:0.0527\n",
      "Episode:1917 meanR:13.0600 R:14.0 loss:0.0328 exploreP:0.0526\n",
      "Episode:1918 meanR:13.0000 R:9.0 loss:0.0278 exploreP:0.0526\n",
      "Episode:1919 meanR:13.0200 R:14.0 loss:0.0315 exploreP:0.0525\n",
      "Episode:1920 meanR:13.0800 R:18.0 loss:0.0339 exploreP:0.0524\n",
      "Episode:1921 meanR:13.0800 R:13.0 loss:0.0281 exploreP:0.0524\n",
      "Episode:1922 meanR:13.0700 R:14.0 loss:0.0260 exploreP:0.0523\n",
      "Episode:1923 meanR:13.0500 R:13.0 loss:0.0316 exploreP:0.0523\n",
      "Episode:1924 meanR:13.0900 R:13.0 loss:0.0314 exploreP:0.0522\n",
      "Episode:1925 meanR:13.0900 R:13.0 loss:0.0353 exploreP:0.0522\n",
      "Episode:1926 meanR:13.0900 R:10.0 loss:0.0279 exploreP:0.0521\n",
      "Episode:1927 meanR:13.1100 R:12.0 loss:0.0294 exploreP:0.0521\n",
      "Episode:1928 meanR:13.0400 R:9.0 loss:0.0336 exploreP:0.0520\n",
      "Episode:1929 meanR:13.0400 R:16.0 loss:0.0283 exploreP:0.0520\n",
      "Episode:1930 meanR:13.0400 R:14.0 loss:0.0316 exploreP:0.0519\n",
      "Episode:1931 meanR:13.0900 R:14.0 loss:0.0385 exploreP:0.0519\n",
      "Episode:1932 meanR:13.1400 R:15.0 loss:0.0335 exploreP:0.0518\n",
      "Episode:1933 meanR:13.1500 R:15.0 loss:0.0304 exploreP:0.0517\n",
      "Episode:1934 meanR:13.1700 R:17.0 loss:0.0318 exploreP:0.0517\n",
      "Episode:1935 meanR:13.1600 R:12.0 loss:0.0306 exploreP:0.0516\n",
      "Episode:1936 meanR:13.1800 R:17.0 loss:0.0339 exploreP:0.0515\n",
      "Episode:1937 meanR:13.1400 R:12.0 loss:0.0312 exploreP:0.0515\n",
      "Episode:1938 meanR:13.1500 R:15.0 loss:0.0311 exploreP:0.0514\n",
      "Episode:1939 meanR:13.1100 R:10.0 loss:0.0299 exploreP:0.0514\n",
      "Episode:1940 meanR:13.0900 R:17.0 loss:0.0338 exploreP:0.0513\n",
      "Episode:1941 meanR:13.1000 R:16.0 loss:0.0327 exploreP:0.0512\n",
      "Episode:1942 meanR:13.1300 R:15.0 loss:0.0309 exploreP:0.0512\n",
      "Episode:1943 meanR:13.1400 R:14.0 loss:0.0286 exploreP:0.0511\n",
      "Episode:1944 meanR:13.1600 R:12.0 loss:0.0407 exploreP:0.0511\n",
      "Episode:1945 meanR:13.1100 R:10.0 loss:0.0308 exploreP:0.0510\n",
      "Episode:1946 meanR:13.1300 R:11.0 loss:0.0331 exploreP:0.0510\n",
      "Episode:1947 meanR:13.1600 R:15.0 loss:0.0280 exploreP:0.0509\n",
      "Episode:1948 meanR:13.1600 R:12.0 loss:0.0345 exploreP:0.0509\n",
      "Episode:1949 meanR:13.1600 R:12.0 loss:0.0391 exploreP:0.0508\n",
      "Episode:1950 meanR:13.1600 R:14.0 loss:0.0259 exploreP:0.0508\n",
      "Episode:1951 meanR:13.1100 R:10.0 loss:0.0300 exploreP:0.0507\n",
      "Episode:1952 meanR:13.0500 R:9.0 loss:0.0295 exploreP:0.0507\n",
      "Episode:1953 meanR:13.0500 R:13.0 loss:0.0351 exploreP:0.0506\n",
      "Episode:1954 meanR:12.9500 R:8.0 loss:0.0396 exploreP:0.0506\n",
      "Episode:1955 meanR:12.9300 R:9.0 loss:0.0258 exploreP:0.0506\n",
      "Episode:1956 meanR:12.9500 R:16.0 loss:0.0263 exploreP:0.0505\n",
      "Episode:1957 meanR:12.9400 R:13.0 loss:0.0300 exploreP:0.0505\n",
      "Episode:1958 meanR:12.8900 R:9.0 loss:0.0261 exploreP:0.0504\n",
      "Episode:1959 meanR:12.8600 R:12.0 loss:0.0259 exploreP:0.0504\n",
      "Episode:1960 meanR:12.8900 R:17.0 loss:0.0325 exploreP:0.0503\n",
      "Episode:1961 meanR:12.8400 R:12.0 loss:0.0306 exploreP:0.0503\n",
      "Episode:1962 meanR:12.8300 R:13.0 loss:0.0305 exploreP:0.0502\n",
      "Episode:1963 meanR:12.8400 R:13.0 loss:0.0333 exploreP:0.0501\n",
      "Episode:1964 meanR:12.8200 R:11.0 loss:0.0285 exploreP:0.0501\n",
      "Episode:1965 meanR:12.8500 R:18.0 loss:0.0340 exploreP:0.0500\n",
      "Episode:1966 meanR:12.9000 R:17.0 loss:0.0276 exploreP:0.0500\n",
      "Episode:1967 meanR:12.8600 R:12.0 loss:0.0314 exploreP:0.0499\n",
      "Episode:1968 meanR:12.9000 R:13.0 loss:0.0346 exploreP:0.0499\n",
      "Episode:1969 meanR:12.9500 R:15.0 loss:0.0311 exploreP:0.0498\n",
      "Episode:1970 meanR:12.9200 R:9.0 loss:0.0297 exploreP:0.0498\n",
      "Episode:1971 meanR:12.9400 R:15.0 loss:0.0317 exploreP:0.0497\n",
      "Episode:1972 meanR:12.9500 R:15.0 loss:0.0294 exploreP:0.0497\n",
      "Episode:1973 meanR:12.9500 R:17.0 loss:0.0326 exploreP:0.0496\n",
      "Episode:1974 meanR:12.9900 R:14.0 loss:0.0315 exploreP:0.0495\n",
      "Episode:1975 meanR:13.0000 R:14.0 loss:0.0300 exploreP:0.0495\n",
      "Episode:1976 meanR:12.9800 R:11.0 loss:0.0394 exploreP:0.0494\n",
      "Episode:1977 meanR:12.9700 R:13.0 loss:0.0308 exploreP:0.0494\n",
      "Episode:1978 meanR:12.9400 R:15.0 loss:0.0285 exploreP:0.0493\n",
      "Episode:1979 meanR:12.9500 R:12.0 loss:0.0324 exploreP:0.0493\n",
      "Episode:1980 meanR:12.9800 R:16.0 loss:0.0300 exploreP:0.0492\n",
      "Episode:1981 meanR:13.0000 R:14.0 loss:0.0294 exploreP:0.0492\n",
      "Episode:1982 meanR:13.0100 R:12.0 loss:0.0268 exploreP:0.0491\n",
      "Episode:1983 meanR:13.0200 R:9.0 loss:0.0328 exploreP:0.0491\n",
      "Episode:1984 meanR:13.0000 R:11.0 loss:0.0291 exploreP:0.0490\n",
      "Episode:1985 meanR:13.0200 R:12.0 loss:0.0282 exploreP:0.0490\n",
      "Episode:1986 meanR:13.0400 R:12.0 loss:0.0307 exploreP:0.0489\n",
      "Episode:1987 meanR:13.0200 R:12.0 loss:0.0428 exploreP:0.0489\n",
      "Episode:1988 meanR:13.0000 R:11.0 loss:0.0393 exploreP:0.0488\n",
      "Episode:1989 meanR:12.9600 R:11.0 loss:0.0309 exploreP:0.0488\n",
      "Episode:1990 meanR:12.9900 R:15.0 loss:0.0301 exploreP:0.0487\n",
      "Episode:1991 meanR:12.9800 R:10.0 loss:0.0322 exploreP:0.0487\n",
      "Episode:1992 meanR:12.9500 R:12.0 loss:0.0316 exploreP:0.0487\n",
      "Episode:1993 meanR:12.8900 R:11.0 loss:0.0378 exploreP:0.0486\n",
      "Episode:1994 meanR:12.8800 R:10.0 loss:0.0262 exploreP:0.0486\n",
      "Episode:1995 meanR:12.9100 R:15.0 loss:0.0321 exploreP:0.0485\n",
      "Episode:1996 meanR:12.9000 R:11.0 loss:0.0307 exploreP:0.0485\n",
      "Episode:1997 meanR:12.9200 R:15.0 loss:0.0341 exploreP:0.0484\n",
      "Episode:1998 meanR:12.9600 R:16.0 loss:0.0294 exploreP:0.0484\n",
      "Episode:1999 meanR:12.9800 R:16.0 loss:0.0345 exploreP:0.0483\n",
      "Episode:2000 meanR:12.9600 R:13.0 loss:0.0291 exploreP:0.0482\n",
      "Episode:2001 meanR:12.9800 R:16.0 loss:0.0329 exploreP:0.0482\n",
      "Episode:2002 meanR:12.9300 R:9.0 loss:0.0311 exploreP:0.0482\n",
      "Episode:2003 meanR:12.9100 R:10.0 loss:0.0345 exploreP:0.0481\n",
      "Episode:2004 meanR:12.9200 R:14.0 loss:0.0263 exploreP:0.0481\n",
      "Episode:2005 meanR:12.9300 R:14.0 loss:0.0328 exploreP:0.0480\n",
      "Episode:2006 meanR:12.9900 R:15.0 loss:0.0270 exploreP:0.0480\n",
      "Episode:2007 meanR:13.0100 R:13.0 loss:0.0263 exploreP:0.0479\n",
      "Episode:2008 meanR:13.0500 R:16.0 loss:0.0353 exploreP:0.0478\n",
      "Episode:2009 meanR:13.1200 R:16.0 loss:0.0319 exploreP:0.0478\n",
      "Episode:2010 meanR:13.1300 R:14.0 loss:0.0284 exploreP:0.0477\n",
      "Episode:2011 meanR:13.1300 R:15.0 loss:0.0300 exploreP:0.0477\n",
      "Episode:2012 meanR:13.1300 R:15.0 loss:0.0324 exploreP:0.0476\n",
      "Episode:2013 meanR:13.1300 R:12.0 loss:0.0297 exploreP:0.0476\n",
      "Episode:2014 meanR:13.1700 R:16.0 loss:0.0280 exploreP:0.0475\n",
      "Episode:2015 meanR:13.1800 R:14.0 loss:0.0301 exploreP:0.0475\n",
      "Episode:2016 meanR:13.2000 R:15.0 loss:0.0309 exploreP:0.0474\n",
      "Episode:2017 meanR:13.1800 R:12.0 loss:0.0340 exploreP:0.0474\n",
      "Episode:2018 meanR:13.2200 R:13.0 loss:0.0356 exploreP:0.0473\n",
      "Episode:2019 meanR:13.2000 R:12.0 loss:0.0386 exploreP:0.0473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2020 meanR:13.1100 R:9.0 loss:0.0349 exploreP:0.0472\n",
      "Episode:2021 meanR:13.1400 R:16.0 loss:0.0289 exploreP:0.0472\n",
      "Episode:2022 meanR:13.1100 R:11.0 loss:0.0277 exploreP:0.0471\n",
      "Episode:2023 meanR:13.1400 R:16.0 loss:0.0328 exploreP:0.0471\n",
      "Episode:2024 meanR:13.1300 R:12.0 loss:0.0308 exploreP:0.0470\n",
      "Episode:2025 meanR:13.1400 R:14.0 loss:0.0260 exploreP:0.0470\n",
      "Episode:2026 meanR:13.2000 R:16.0 loss:0.0327 exploreP:0.0469\n",
      "Episode:2027 meanR:13.2300 R:15.0 loss:0.0271 exploreP:0.0469\n",
      "Episode:2028 meanR:13.2600 R:12.0 loss:0.0350 exploreP:0.0468\n",
      "Episode:2029 meanR:13.2500 R:15.0 loss:0.0306 exploreP:0.0468\n",
      "Episode:2030 meanR:13.2800 R:17.0 loss:0.0305 exploreP:0.0467\n",
      "Episode:2031 meanR:13.2600 R:12.0 loss:0.0334 exploreP:0.0467\n",
      "Episode:2032 meanR:13.2400 R:13.0 loss:0.0263 exploreP:0.0466\n",
      "Episode:2033 meanR:13.2500 R:16.0 loss:0.0301 exploreP:0.0465\n",
      "Episode:2034 meanR:13.2300 R:15.0 loss:0.0350 exploreP:0.0465\n",
      "Episode:2035 meanR:13.2800 R:17.0 loss:0.0328 exploreP:0.0464\n",
      "Episode:2036 meanR:13.2600 R:15.0 loss:0.0312 exploreP:0.0464\n",
      "Episode:2037 meanR:13.2500 R:11.0 loss:0.0321 exploreP:0.0463\n",
      "Episode:2038 meanR:13.2400 R:14.0 loss:0.0298 exploreP:0.0463\n",
      "Episode:2039 meanR:13.2700 R:13.0 loss:0.0318 exploreP:0.0462\n",
      "Episode:2040 meanR:13.2700 R:17.0 loss:0.0327 exploreP:0.0462\n",
      "Episode:2041 meanR:13.2000 R:9.0 loss:0.0289 exploreP:0.0461\n",
      "Episode:2042 meanR:13.2000 R:15.0 loss:0.0340 exploreP:0.0461\n",
      "Episode:2043 meanR:13.2000 R:14.0 loss:0.0273 exploreP:0.0460\n",
      "Episode:2044 meanR:13.1900 R:11.0 loss:0.0285 exploreP:0.0460\n",
      "Episode:2045 meanR:13.2000 R:11.0 loss:0.0319 exploreP:0.0460\n",
      "Episode:2046 meanR:13.2000 R:11.0 loss:0.0305 exploreP:0.0459\n",
      "Episode:2047 meanR:13.1600 R:11.0 loss:0.0317 exploreP:0.0459\n",
      "Episode:2048 meanR:13.1400 R:10.0 loss:0.0300 exploreP:0.0458\n",
      "Episode:2049 meanR:13.1400 R:12.0 loss:0.0347 exploreP:0.0458\n",
      "Episode:2050 meanR:13.1100 R:11.0 loss:0.0310 exploreP:0.0458\n",
      "Episode:2051 meanR:13.1600 R:15.0 loss:0.0313 exploreP:0.0457\n",
      "Episode:2052 meanR:13.1800 R:11.0 loss:0.0283 exploreP:0.0457\n",
      "Episode:2053 meanR:13.1800 R:13.0 loss:0.0289 exploreP:0.0456\n",
      "Episode:2054 meanR:13.2600 R:16.0 loss:0.0315 exploreP:0.0456\n",
      "Episode:2055 meanR:13.2800 R:11.0 loss:0.0242 exploreP:0.0455\n",
      "Episode:2056 meanR:13.2500 R:13.0 loss:0.0325 exploreP:0.0455\n",
      "Episode:2057 meanR:13.3000 R:18.0 loss:0.0311 exploreP:0.0454\n",
      "Episode:2058 meanR:13.3700 R:16.0 loss:0.0277 exploreP:0.0454\n",
      "Episode:2059 meanR:13.4000 R:15.0 loss:0.0291 exploreP:0.0453\n",
      "Episode:2060 meanR:13.3400 R:11.0 loss:0.0326 exploreP:0.0453\n",
      "Episode:2061 meanR:13.3800 R:16.0 loss:0.0318 exploreP:0.0452\n",
      "Episode:2062 meanR:13.3900 R:14.0 loss:0.0309 exploreP:0.0452\n",
      "Episode:2063 meanR:13.4400 R:18.0 loss:0.0294 exploreP:0.0451\n",
      "Episode:2064 meanR:13.4500 R:12.0 loss:0.0349 exploreP:0.0451\n",
      "Episode:2065 meanR:13.3800 R:11.0 loss:0.0342 exploreP:0.0450\n",
      "Episode:2066 meanR:13.3300 R:12.0 loss:0.0272 exploreP:0.0450\n",
      "Episode:2067 meanR:13.3200 R:11.0 loss:0.0324 exploreP:0.0449\n",
      "Episode:2068 meanR:13.3300 R:14.0 loss:0.0278 exploreP:0.0449\n",
      "Episode:2069 meanR:13.3100 R:13.0 loss:0.0330 exploreP:0.0448\n",
      "Episode:2070 meanR:13.3400 R:12.0 loss:0.0307 exploreP:0.0448\n",
      "Episode:2071 meanR:13.3300 R:14.0 loss:0.0317 exploreP:0.0448\n",
      "Episode:2072 meanR:13.3200 R:14.0 loss:0.0320 exploreP:0.0447\n",
      "Episode:2073 meanR:13.3000 R:15.0 loss:0.0281 exploreP:0.0447\n",
      "Episode:2074 meanR:13.3200 R:16.0 loss:0.0302 exploreP:0.0446\n",
      "Episode:2075 meanR:13.2800 R:10.0 loss:0.0259 exploreP:0.0446\n",
      "Episode:2076 meanR:13.3000 R:13.0 loss:0.0269 exploreP:0.0445\n",
      "Episode:2077 meanR:13.3000 R:13.0 loss:0.0302 exploreP:0.0445\n",
      "Episode:2078 meanR:13.3200 R:17.0 loss:0.0296 exploreP:0.0444\n",
      "Episode:2079 meanR:13.3700 R:17.0 loss:0.0306 exploreP:0.0444\n",
      "Episode:2080 meanR:13.3600 R:15.0 loss:0.0320 exploreP:0.0443\n",
      "Episode:2081 meanR:13.3800 R:16.0 loss:0.0329 exploreP:0.0443\n",
      "Episode:2082 meanR:13.4100 R:15.0 loss:0.0278 exploreP:0.0442\n",
      "Episode:2083 meanR:13.4800 R:16.0 loss:0.0311 exploreP:0.0441\n",
      "Episode:2084 meanR:13.5300 R:16.0 loss:0.0271 exploreP:0.0441\n",
      "Episode:2085 meanR:13.5400 R:13.0 loss:0.0260 exploreP:0.0440\n",
      "Episode:2086 meanR:13.5800 R:16.0 loss:0.0301 exploreP:0.0440\n",
      "Episode:2087 meanR:13.5600 R:10.0 loss:0.0257 exploreP:0.0440\n",
      "Episode:2088 meanR:13.5600 R:11.0 loss:0.0379 exploreP:0.0439\n",
      "Episode:2089 meanR:13.5500 R:10.0 loss:0.0339 exploreP:0.0439\n",
      "Episode:2090 meanR:13.5500 R:15.0 loss:0.0284 exploreP:0.0438\n",
      "Episode:2091 meanR:13.5800 R:13.0 loss:0.0298 exploreP:0.0438\n",
      "Episode:2092 meanR:13.5700 R:11.0 loss:0.0223 exploreP:0.0438\n",
      "Episode:2093 meanR:13.5800 R:12.0 loss:0.0291 exploreP:0.0437\n",
      "Episode:2094 meanR:13.6200 R:14.0 loss:0.0260 exploreP:0.0437\n",
      "Episode:2095 meanR:13.6300 R:16.0 loss:0.0253 exploreP:0.0436\n",
      "Episode:2096 meanR:13.6900 R:17.0 loss:0.0307 exploreP:0.0436\n",
      "Episode:2097 meanR:13.6600 R:12.0 loss:0.0330 exploreP:0.0435\n",
      "Episode:2098 meanR:13.6300 R:13.0 loss:0.0309 exploreP:0.0435\n",
      "Episode:2099 meanR:13.5800 R:11.0 loss:0.0325 exploreP:0.0434\n",
      "Episode:2100 meanR:13.6100 R:16.0 loss:0.0292 exploreP:0.0434\n",
      "Episode:2101 meanR:13.5800 R:13.0 loss:0.0351 exploreP:0.0433\n",
      "Episode:2102 meanR:13.6300 R:14.0 loss:0.0288 exploreP:0.0433\n",
      "Episode:2103 meanR:13.7000 R:17.0 loss:0.0255 exploreP:0.0432\n",
      "Episode:2104 meanR:13.7000 R:14.0 loss:0.0302 exploreP:0.0432\n",
      "Episode:2105 meanR:13.6700 R:11.0 loss:0.0297 exploreP:0.0432\n",
      "Episode:2106 meanR:13.6400 R:12.0 loss:0.0286 exploreP:0.0431\n",
      "Episode:2107 meanR:13.6400 R:13.0 loss:0.0309 exploreP:0.0431\n",
      "Episode:2108 meanR:13.6100 R:13.0 loss:0.0288 exploreP:0.0430\n",
      "Episode:2109 meanR:13.5900 R:14.0 loss:0.0291 exploreP:0.0430\n",
      "Episode:2110 meanR:13.6000 R:15.0 loss:0.0262 exploreP:0.0429\n",
      "Episode:2111 meanR:13.5400 R:9.0 loss:0.0355 exploreP:0.0429\n",
      "Episode:2112 meanR:13.5500 R:16.0 loss:0.0291 exploreP:0.0428\n",
      "Episode:2113 meanR:13.5800 R:15.0 loss:0.0318 exploreP:0.0428\n",
      "Episode:2114 meanR:13.5700 R:15.0 loss:0.0306 exploreP:0.0428\n",
      "Episode:2115 meanR:13.5900 R:16.0 loss:0.0305 exploreP:0.0427\n",
      "Episode:2116 meanR:13.6100 R:17.0 loss:0.0313 exploreP:0.0426\n",
      "Episode:2117 meanR:13.6700 R:18.0 loss:0.0331 exploreP:0.0426\n",
      "Episode:2118 meanR:13.6700 R:13.0 loss:0.0288 exploreP:0.0425\n",
      "Episode:2119 meanR:13.6900 R:14.0 loss:0.0330 exploreP:0.0425\n",
      "Episode:2120 meanR:13.7400 R:14.0 loss:0.0292 exploreP:0.0425\n",
      "Episode:2121 meanR:13.7600 R:18.0 loss:0.0298 exploreP:0.0424\n",
      "Episode:2122 meanR:13.7500 R:10.0 loss:0.0332 exploreP:0.0424\n",
      "Episode:2123 meanR:13.7400 R:15.0 loss:0.0294 exploreP:0.0423\n",
      "Episode:2124 meanR:13.7300 R:11.0 loss:0.0272 exploreP:0.0423\n",
      "Episode:2125 meanR:13.7500 R:16.0 loss:0.0320 exploreP:0.0422\n",
      "Episode:2126 meanR:13.7200 R:13.0 loss:0.0293 exploreP:0.0422\n",
      "Episode:2127 meanR:13.6900 R:12.0 loss:0.0326 exploreP:0.0421\n",
      "Episode:2128 meanR:13.6600 R:9.0 loss:0.0295 exploreP:0.0421\n",
      "Episode:2129 meanR:13.6400 R:13.0 loss:0.0257 exploreP:0.0421\n",
      "Episode:2130 meanR:13.5600 R:9.0 loss:0.0322 exploreP:0.0420\n",
      "Episode:2131 meanR:13.6000 R:16.0 loss:0.0323 exploreP:0.0420\n",
      "Episode:2132 meanR:13.6200 R:15.0 loss:0.0271 exploreP:0.0419\n",
      "Episode:2133 meanR:13.5500 R:9.0 loss:0.0272 exploreP:0.0419\n",
      "Episode:2134 meanR:13.5000 R:10.0 loss:0.0294 exploreP:0.0419\n",
      "Episode:2135 meanR:13.4800 R:15.0 loss:0.0296 exploreP:0.0418\n",
      "Episode:2136 meanR:13.4600 R:13.0 loss:0.0263 exploreP:0.0418\n",
      "Episode:2137 meanR:13.4700 R:12.0 loss:0.0247 exploreP:0.0418\n",
      "Episode:2138 meanR:13.5000 R:17.0 loss:0.0305 exploreP:0.0417\n",
      "Episode:2139 meanR:13.5000 R:13.0 loss:0.0259 exploreP:0.0417\n",
      "Episode:2140 meanR:13.4200 R:9.0 loss:0.0250 exploreP:0.0416\n",
      "Episode:2141 meanR:13.5100 R:18.0 loss:0.0355 exploreP:0.0416\n",
      "Episode:2142 meanR:13.5200 R:16.0 loss:0.0311 exploreP:0.0415\n",
      "Episode:2143 meanR:13.4900 R:11.0 loss:0.0277 exploreP:0.0415\n",
      "Episode:2144 meanR:13.5000 R:12.0 loss:0.0366 exploreP:0.0415\n",
      "Episode:2145 meanR:13.4900 R:10.0 loss:0.0259 exploreP:0.0414\n",
      "Episode:2146 meanR:13.5300 R:15.0 loss:0.0296 exploreP:0.0414\n",
      "Episode:2147 meanR:13.5400 R:12.0 loss:0.0303 exploreP:0.0413\n",
      "Episode:2148 meanR:13.5400 R:10.0 loss:0.0303 exploreP:0.0413\n",
      "Episode:2149 meanR:13.5700 R:15.0 loss:0.0266 exploreP:0.0413\n",
      "Episode:2150 meanR:13.6300 R:17.0 loss:0.0310 exploreP:0.0412\n",
      "Episode:2151 meanR:13.6100 R:13.0 loss:0.0269 exploreP:0.0412\n",
      "Episode:2152 meanR:13.6500 R:15.0 loss:0.0336 exploreP:0.0411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2153 meanR:13.6400 R:12.0 loss:0.0316 exploreP:0.0411\n",
      "Episode:2154 meanR:13.6100 R:13.0 loss:0.0285 exploreP:0.0410\n",
      "Episode:2155 meanR:13.6300 R:13.0 loss:0.0299 exploreP:0.0410\n",
      "Episode:2156 meanR:13.6100 R:11.0 loss:0.0302 exploreP:0.0410\n",
      "Episode:2157 meanR:13.5800 R:15.0 loss:0.0275 exploreP:0.0409\n",
      "Episode:2158 meanR:13.5400 R:12.0 loss:0.0245 exploreP:0.0409\n",
      "Episode:2159 meanR:13.5200 R:13.0 loss:0.0286 exploreP:0.0408\n",
      "Episode:2160 meanR:13.5700 R:16.0 loss:0.0308 exploreP:0.0408\n",
      "Episode:2161 meanR:13.5600 R:15.0 loss:0.0321 exploreP:0.0407\n",
      "Episode:2162 meanR:13.5300 R:11.0 loss:0.0284 exploreP:0.0407\n",
      "Episode:2163 meanR:13.4500 R:10.0 loss:0.0290 exploreP:0.0407\n",
      "Episode:2164 meanR:13.4400 R:11.0 loss:0.0299 exploreP:0.0406\n",
      "Episode:2165 meanR:13.4400 R:11.0 loss:0.0321 exploreP:0.0406\n",
      "Episode:2166 meanR:13.4100 R:9.0 loss:0.0345 exploreP:0.0406\n",
      "Episode:2167 meanR:13.4400 R:14.0 loss:0.0257 exploreP:0.0405\n",
      "Episode:2168 meanR:13.4100 R:11.0 loss:0.0311 exploreP:0.0405\n",
      "Episode:2169 meanR:13.4000 R:12.0 loss:0.0348 exploreP:0.0405\n",
      "Episode:2170 meanR:13.3800 R:10.0 loss:0.0242 exploreP:0.0404\n",
      "Episode:2171 meanR:13.3700 R:13.0 loss:0.0295 exploreP:0.0404\n",
      "Episode:2172 meanR:13.3800 R:15.0 loss:0.0272 exploreP:0.0404\n",
      "Episode:2173 meanR:13.3600 R:13.0 loss:0.0257 exploreP:0.0403\n",
      "Episode:2174 meanR:13.3100 R:11.0 loss:0.0271 exploreP:0.0403\n",
      "Episode:2175 meanR:13.3800 R:17.0 loss:0.0278 exploreP:0.0402\n",
      "Episode:2176 meanR:13.3800 R:13.0 loss:0.0299 exploreP:0.0402\n",
      "Episode:2177 meanR:13.4000 R:15.0 loss:0.0307 exploreP:0.0402\n",
      "Episode:2178 meanR:13.3800 R:15.0 loss:0.0317 exploreP:0.0401\n",
      "Episode:2179 meanR:13.3500 R:14.0 loss:0.0285 exploreP:0.0401\n",
      "Episode:2180 meanR:13.3200 R:12.0 loss:0.0282 exploreP:0.0400\n",
      "Episode:2181 meanR:13.3100 R:15.0 loss:0.0268 exploreP:0.0400\n",
      "Episode:2182 meanR:13.2500 R:9.0 loss:0.0347 exploreP:0.0400\n",
      "Episode:2183 meanR:13.1800 R:9.0 loss:0.0431 exploreP:0.0399\n",
      "Episode:2184 meanR:13.1000 R:8.0 loss:0.0275 exploreP:0.0399\n",
      "Episode:2185 meanR:13.1000 R:13.0 loss:0.0268 exploreP:0.0399\n",
      "Episode:2186 meanR:13.0500 R:11.0 loss:0.0262 exploreP:0.0398\n",
      "Episode:2187 meanR:13.0600 R:11.0 loss:0.0260 exploreP:0.0398\n",
      "Episode:2188 meanR:13.1000 R:15.0 loss:0.0268 exploreP:0.0398\n",
      "Episode:2189 meanR:13.0900 R:9.0 loss:0.0314 exploreP:0.0397\n",
      "Episode:2190 meanR:13.1000 R:16.0 loss:0.0289 exploreP:0.0397\n",
      "Episode:2191 meanR:13.0900 R:12.0 loss:0.0343 exploreP:0.0396\n",
      "Episode:2192 meanR:13.0800 R:10.0 loss:0.0308 exploreP:0.0396\n",
      "Episode:2193 meanR:13.0600 R:10.0 loss:0.0251 exploreP:0.0396\n",
      "Episode:2194 meanR:13.0000 R:8.0 loss:0.0245 exploreP:0.0396\n",
      "Episode:2195 meanR:12.9900 R:15.0 loss:0.0302 exploreP:0.0395\n",
      "Episode:2196 meanR:12.9300 R:11.0 loss:0.0298 exploreP:0.0395\n",
      "Episode:2197 meanR:12.9700 R:16.0 loss:0.0264 exploreP:0.0394\n",
      "Episode:2198 meanR:13.0000 R:16.0 loss:0.0314 exploreP:0.0394\n",
      "Episode:2199 meanR:13.0600 R:17.0 loss:0.0268 exploreP:0.0393\n",
      "Episode:2200 meanR:13.0400 R:14.0 loss:0.0316 exploreP:0.0393\n",
      "Episode:2201 meanR:13.0100 R:10.0 loss:0.0296 exploreP:0.0393\n",
      "Episode:2202 meanR:13.0200 R:15.0 loss:0.0287 exploreP:0.0392\n",
      "Episode:2203 meanR:12.9900 R:14.0 loss:0.0260 exploreP:0.0392\n",
      "Episode:2204 meanR:12.9800 R:13.0 loss:0.0275 exploreP:0.0391\n",
      "Episode:2205 meanR:13.0400 R:17.0 loss:0.0248 exploreP:0.0391\n",
      "Episode:2206 meanR:13.0100 R:9.0 loss:0.0279 exploreP:0.0391\n",
      "Episode:2207 meanR:13.0300 R:15.0 loss:0.0263 exploreP:0.0390\n",
      "Episode:2208 meanR:13.0300 R:13.0 loss:0.0309 exploreP:0.0390\n",
      "Episode:2209 meanR:12.9900 R:10.0 loss:0.0281 exploreP:0.0390\n",
      "Episode:2210 meanR:12.9700 R:13.0 loss:0.0336 exploreP:0.0389\n",
      "Episode:2211 meanR:13.0400 R:16.0 loss:0.0232 exploreP:0.0389\n",
      "Episode:2212 meanR:12.9900 R:11.0 loss:0.0323 exploreP:0.0388\n",
      "Episode:2213 meanR:12.9600 R:12.0 loss:0.0325 exploreP:0.0388\n",
      "Episode:2214 meanR:12.9500 R:14.0 loss:0.0315 exploreP:0.0388\n",
      "Episode:2215 meanR:12.9300 R:14.0 loss:0.0267 exploreP:0.0387\n",
      "Episode:2216 meanR:12.8700 R:11.0 loss:0.0270 exploreP:0.0387\n",
      "Episode:2217 meanR:12.8300 R:14.0 loss:0.0287 exploreP:0.0387\n",
      "Episode:2218 meanR:12.8400 R:14.0 loss:0.0275 exploreP:0.0386\n",
      "Episode:2219 meanR:12.8200 R:12.0 loss:0.0275 exploreP:0.0386\n",
      "Episode:2220 meanR:12.7700 R:9.0 loss:0.0308 exploreP:0.0386\n",
      "Episode:2221 meanR:12.7400 R:15.0 loss:0.0294 exploreP:0.0385\n",
      "Episode:2222 meanR:12.7900 R:15.0 loss:0.0294 exploreP:0.0385\n",
      "Episode:2223 meanR:12.7300 R:9.0 loss:0.0295 exploreP:0.0384\n",
      "Episode:2224 meanR:12.7700 R:15.0 loss:0.0258 exploreP:0.0384\n",
      "Episode:2225 meanR:12.7200 R:11.0 loss:0.0292 exploreP:0.0384\n",
      "Episode:2226 meanR:12.7200 R:13.0 loss:0.0249 exploreP:0.0383\n",
      "Episode:2227 meanR:12.7600 R:16.0 loss:0.0276 exploreP:0.0383\n",
      "Episode:2228 meanR:12.8200 R:15.0 loss:0.0246 exploreP:0.0383\n",
      "Episode:2229 meanR:12.8100 R:12.0 loss:0.0268 exploreP:0.0382\n",
      "Episode:2230 meanR:12.8600 R:14.0 loss:0.0247 exploreP:0.0382\n",
      "Episode:2231 meanR:12.8400 R:14.0 loss:0.0268 exploreP:0.0381\n",
      "Episode:2232 meanR:12.8200 R:13.0 loss:0.0344 exploreP:0.0381\n",
      "Episode:2233 meanR:12.9000 R:17.0 loss:0.0266 exploreP:0.0381\n",
      "Episode:2234 meanR:12.9100 R:11.0 loss:0.0286 exploreP:0.0380\n",
      "Episode:2235 meanR:12.8700 R:11.0 loss:0.0294 exploreP:0.0380\n",
      "Episode:2236 meanR:12.9000 R:16.0 loss:0.0270 exploreP:0.0379\n",
      "Episode:2237 meanR:12.9500 R:17.0 loss:0.0306 exploreP:0.0379\n",
      "Episode:2238 meanR:12.9200 R:14.0 loss:0.0268 exploreP:0.0379\n",
      "Episode:2239 meanR:12.9100 R:12.0 loss:0.0311 exploreP:0.0378\n",
      "Episode:2240 meanR:12.9300 R:11.0 loss:0.0320 exploreP:0.0378\n",
      "Episode:2241 meanR:12.8400 R:9.0 loss:0.0319 exploreP:0.0378\n",
      "Episode:2242 meanR:12.8300 R:15.0 loss:0.0288 exploreP:0.0377\n",
      "Episode:2243 meanR:12.8800 R:16.0 loss:0.0293 exploreP:0.0377\n",
      "Episode:2244 meanR:12.9500 R:19.0 loss:0.0280 exploreP:0.0376\n",
      "Episode:2245 meanR:12.9800 R:13.0 loss:0.0259 exploreP:0.0376\n",
      "Episode:2246 meanR:12.9800 R:15.0 loss:0.0266 exploreP:0.0376\n",
      "Episode:2247 meanR:12.9700 R:11.0 loss:0.0288 exploreP:0.0375\n",
      "Episode:2248 meanR:13.0300 R:16.0 loss:0.0245 exploreP:0.0375\n",
      "Episode:2249 meanR:13.0500 R:17.0 loss:0.0280 exploreP:0.0374\n",
      "Episode:2250 meanR:13.0400 R:16.0 loss:0.0349 exploreP:0.0374\n",
      "Episode:2251 meanR:13.0600 R:15.0 loss:0.0245 exploreP:0.0373\n",
      "Episode:2252 meanR:13.0400 R:13.0 loss:0.0289 exploreP:0.0373\n",
      "Episode:2253 meanR:13.0600 R:14.0 loss:0.0282 exploreP:0.0373\n",
      "Episode:2254 meanR:13.0300 R:10.0 loss:0.0221 exploreP:0.0372\n",
      "Episode:2255 meanR:13.0200 R:12.0 loss:0.0217 exploreP:0.0372\n",
      "Episode:2256 meanR:13.0600 R:15.0 loss:0.0384 exploreP:0.0372\n",
      "Episode:2257 meanR:12.9900 R:8.0 loss:0.0319 exploreP:0.0372\n",
      "Episode:2258 meanR:13.0000 R:13.0 loss:0.0298 exploreP:0.0371\n",
      "Episode:2259 meanR:12.9800 R:11.0 loss:0.0306 exploreP:0.0371\n",
      "Episode:2260 meanR:12.9600 R:14.0 loss:0.0231 exploreP:0.0371\n",
      "Episode:2261 meanR:12.9000 R:9.0 loss:0.0323 exploreP:0.0370\n",
      "Episode:2262 meanR:12.9400 R:15.0 loss:0.0279 exploreP:0.0370\n",
      "Episode:2263 meanR:12.9700 R:13.0 loss:0.0308 exploreP:0.0370\n",
      "Episode:2264 meanR:13.0100 R:15.0 loss:0.0311 exploreP:0.0369\n",
      "Episode:2265 meanR:13.0300 R:13.0 loss:0.0341 exploreP:0.0369\n",
      "Episode:2266 meanR:13.0900 R:15.0 loss:0.0316 exploreP:0.0368\n",
      "Episode:2267 meanR:13.0800 R:13.0 loss:0.0316 exploreP:0.0368\n",
      "Episode:2268 meanR:13.0800 R:11.0 loss:0.0278 exploreP:0.0368\n",
      "Episode:2269 meanR:13.1000 R:14.0 loss:0.0277 exploreP:0.0367\n",
      "Episode:2270 meanR:13.1300 R:13.0 loss:0.0295 exploreP:0.0367\n",
      "Episode:2271 meanR:13.1200 R:12.0 loss:0.0279 exploreP:0.0367\n",
      "Episode:2272 meanR:13.1300 R:16.0 loss:0.0267 exploreP:0.0366\n",
      "Episode:2273 meanR:13.1300 R:13.0 loss:0.0251 exploreP:0.0366\n",
      "Episode:2274 meanR:13.1400 R:12.0 loss:0.0302 exploreP:0.0366\n",
      "Episode:2275 meanR:13.0900 R:12.0 loss:0.0300 exploreP:0.0365\n",
      "Episode:2276 meanR:13.0800 R:12.0 loss:0.0320 exploreP:0.0365\n",
      "Episode:2277 meanR:13.0600 R:13.0 loss:0.0353 exploreP:0.0365\n",
      "Episode:2278 meanR:13.0800 R:17.0 loss:0.0238 exploreP:0.0364\n",
      "Episode:2279 meanR:13.0700 R:13.0 loss:0.0305 exploreP:0.0364\n",
      "Episode:2280 meanR:13.1100 R:16.0 loss:0.0320 exploreP:0.0363\n",
      "Episode:2281 meanR:13.0700 R:11.0 loss:0.0205 exploreP:0.0363\n",
      "Episode:2282 meanR:13.0700 R:9.0 loss:0.0348 exploreP:0.0363\n",
      "Episode:2283 meanR:13.1400 R:16.0 loss:0.0255 exploreP:0.0362\n",
      "Episode:2284 meanR:13.2200 R:16.0 loss:0.0242 exploreP:0.0362\n",
      "Episode:2285 meanR:13.2700 R:18.0 loss:0.0292 exploreP:0.0362\n",
      "Episode:2286 meanR:13.3400 R:18.0 loss:0.0303 exploreP:0.0361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2287 meanR:13.3700 R:14.0 loss:0.0280 exploreP:0.0361\n",
      "Episode:2288 meanR:13.3700 R:15.0 loss:0.0261 exploreP:0.0360\n",
      "Episode:2289 meanR:13.4400 R:16.0 loss:0.0258 exploreP:0.0360\n",
      "Episode:2290 meanR:13.4300 R:15.0 loss:0.0311 exploreP:0.0360\n",
      "Episode:2291 meanR:13.4600 R:15.0 loss:0.0289 exploreP:0.0359\n",
      "Episode:2292 meanR:13.5000 R:14.0 loss:0.0217 exploreP:0.0359\n",
      "Episode:2293 meanR:13.5400 R:14.0 loss:0.0268 exploreP:0.0358\n",
      "Episode:2294 meanR:13.6000 R:14.0 loss:0.0303 exploreP:0.0358\n",
      "Episode:2295 meanR:13.5300 R:8.0 loss:0.0259 exploreP:0.0358\n",
      "Episode:2296 meanR:13.5900 R:17.0 loss:0.0283 exploreP:0.0357\n",
      "Episode:2297 meanR:13.5600 R:13.0 loss:0.0285 exploreP:0.0357\n",
      "Episode:2298 meanR:13.5000 R:10.0 loss:0.0289 exploreP:0.0357\n",
      "Episode:2299 meanR:13.4600 R:13.0 loss:0.0334 exploreP:0.0356\n",
      "Episode:2300 meanR:13.4600 R:14.0 loss:0.0234 exploreP:0.0356\n",
      "Episode:2301 meanR:13.4900 R:13.0 loss:0.0229 exploreP:0.0356\n",
      "Episode:2302 meanR:13.4300 R:9.0 loss:0.0265 exploreP:0.0356\n",
      "Episode:2303 meanR:13.4400 R:15.0 loss:0.0304 exploreP:0.0355\n",
      "Episode:2304 meanR:13.4100 R:10.0 loss:0.0254 exploreP:0.0355\n",
      "Episode:2305 meanR:13.3700 R:13.0 loss:0.0238 exploreP:0.0355\n",
      "Episode:2306 meanR:13.4100 R:13.0 loss:0.0255 exploreP:0.0354\n",
      "Episode:2307 meanR:13.3500 R:9.0 loss:0.0281 exploreP:0.0354\n",
      "Episode:2308 meanR:13.3600 R:14.0 loss:0.0249 exploreP:0.0354\n",
      "Episode:2309 meanR:13.3500 R:9.0 loss:0.0298 exploreP:0.0353\n",
      "Episode:2310 meanR:13.3200 R:10.0 loss:0.0199 exploreP:0.0353\n",
      "Episode:2311 meanR:13.2800 R:12.0 loss:0.0238 exploreP:0.0353\n",
      "Episode:2312 meanR:13.2900 R:12.0 loss:0.0242 exploreP:0.0353\n",
      "Episode:2313 meanR:13.3100 R:14.0 loss:0.0290 exploreP:0.0352\n",
      "Episode:2314 meanR:13.3200 R:15.0 loss:0.0286 exploreP:0.0352\n",
      "Episode:2315 meanR:13.2700 R:9.0 loss:0.0319 exploreP:0.0352\n",
      "Episode:2316 meanR:13.3000 R:14.0 loss:0.0303 exploreP:0.0351\n",
      "Episode:2317 meanR:13.2900 R:13.0 loss:0.0246 exploreP:0.0351\n",
      "Episode:2318 meanR:13.2500 R:10.0 loss:0.0279 exploreP:0.0351\n",
      "Episode:2319 meanR:13.2300 R:10.0 loss:0.0256 exploreP:0.0350\n",
      "Episode:2320 meanR:13.2900 R:15.0 loss:0.0267 exploreP:0.0350\n",
      "Episode:2321 meanR:13.2300 R:9.0 loss:0.0309 exploreP:0.0350\n",
      "Episode:2322 meanR:13.2300 R:15.0 loss:0.0292 exploreP:0.0349\n",
      "Episode:2323 meanR:13.3000 R:16.0 loss:0.0270 exploreP:0.0349\n",
      "Episode:2324 meanR:13.2400 R:9.0 loss:0.0261 exploreP:0.0349\n",
      "Episode:2325 meanR:13.2900 R:16.0 loss:0.0260 exploreP:0.0348\n",
      "Episode:2326 meanR:13.2600 R:10.0 loss:0.0308 exploreP:0.0348\n",
      "Episode:2327 meanR:13.2000 R:10.0 loss:0.0279 exploreP:0.0348\n",
      "Episode:2328 meanR:13.1800 R:13.0 loss:0.0287 exploreP:0.0348\n",
      "Episode:2329 meanR:13.1600 R:10.0 loss:0.0226 exploreP:0.0347\n",
      "Episode:2330 meanR:13.1100 R:9.0 loss:0.0223 exploreP:0.0347\n",
      "Episode:2331 meanR:13.1300 R:16.0 loss:0.0293 exploreP:0.0347\n",
      "Episode:2332 meanR:13.0900 R:9.0 loss:0.0304 exploreP:0.0347\n",
      "Episode:2333 meanR:13.0500 R:13.0 loss:0.0252 exploreP:0.0346\n",
      "Episode:2334 meanR:13.1000 R:16.0 loss:0.0231 exploreP:0.0346\n",
      "Episode:2335 meanR:13.1100 R:12.0 loss:0.0197 exploreP:0.0346\n",
      "Episode:2336 meanR:13.0400 R:9.0 loss:0.0339 exploreP:0.0345\n",
      "Episode:2337 meanR:13.0200 R:15.0 loss:0.0270 exploreP:0.0345\n",
      "Episode:2338 meanR:12.9900 R:11.0 loss:0.0273 exploreP:0.0345\n",
      "Episode:2339 meanR:12.9500 R:8.0 loss:0.0229 exploreP:0.0344\n",
      "Episode:2340 meanR:12.9500 R:11.0 loss:0.0263 exploreP:0.0344\n",
      "Episode:2341 meanR:13.0100 R:15.0 loss:0.0324 exploreP:0.0344\n",
      "Episode:2342 meanR:13.0100 R:15.0 loss:0.0304 exploreP:0.0343\n",
      "Episode:2343 meanR:13.0000 R:15.0 loss:0.0286 exploreP:0.0343\n",
      "Episode:2344 meanR:12.9500 R:14.0 loss:0.0246 exploreP:0.0343\n",
      "Episode:2345 meanR:12.9800 R:16.0 loss:0.0275 exploreP:0.0342\n",
      "Episode:2346 meanR:12.9500 R:12.0 loss:0.0266 exploreP:0.0342\n",
      "Episode:2347 meanR:12.9900 R:15.0 loss:0.0293 exploreP:0.0342\n",
      "Episode:2348 meanR:12.9600 R:13.0 loss:0.0327 exploreP:0.0341\n",
      "Episode:2349 meanR:12.9100 R:12.0 loss:0.0253 exploreP:0.0341\n",
      "Episode:2350 meanR:12.8400 R:9.0 loss:0.0302 exploreP:0.0341\n",
      "Episode:2351 meanR:12.7800 R:9.0 loss:0.0266 exploreP:0.0341\n",
      "Episode:2352 meanR:12.7700 R:12.0 loss:0.0295 exploreP:0.0340\n",
      "Episode:2353 meanR:12.7300 R:10.0 loss:0.0233 exploreP:0.0340\n",
      "Episode:2354 meanR:12.7900 R:16.0 loss:0.0287 exploreP:0.0340\n",
      "Episode:2355 meanR:12.8200 R:15.0 loss:0.0278 exploreP:0.0339\n",
      "Episode:2356 meanR:12.8300 R:16.0 loss:0.0288 exploreP:0.0339\n",
      "Episode:2357 meanR:12.8900 R:14.0 loss:0.0293 exploreP:0.0339\n",
      "Episode:2358 meanR:12.8600 R:10.0 loss:0.0259 exploreP:0.0338\n",
      "Episode:2359 meanR:12.9100 R:16.0 loss:0.0289 exploreP:0.0338\n",
      "Episode:2360 meanR:12.9200 R:15.0 loss:0.0248 exploreP:0.0338\n",
      "Episode:2361 meanR:12.9600 R:13.0 loss:0.0283 exploreP:0.0337\n",
      "Episode:2362 meanR:12.9700 R:16.0 loss:0.0263 exploreP:0.0337\n",
      "Episode:2363 meanR:12.9700 R:13.0 loss:0.0261 exploreP:0.0337\n",
      "Episode:2364 meanR:12.9400 R:12.0 loss:0.0271 exploreP:0.0336\n",
      "Episode:2365 meanR:13.0000 R:19.0 loss:0.0248 exploreP:0.0336\n",
      "Episode:2366 meanR:12.9300 R:8.0 loss:0.0241 exploreP:0.0336\n",
      "Episode:2367 meanR:12.9200 R:12.0 loss:0.0224 exploreP:0.0336\n",
      "Episode:2368 meanR:12.9600 R:15.0 loss:0.0275 exploreP:0.0335\n",
      "Episode:2369 meanR:12.9200 R:10.0 loss:0.0305 exploreP:0.0335\n",
      "Episode:2370 meanR:12.9300 R:14.0 loss:0.0305 exploreP:0.0335\n",
      "Episode:2371 meanR:12.9700 R:16.0 loss:0.0248 exploreP:0.0334\n",
      "Episode:2372 meanR:12.9600 R:15.0 loss:0.0294 exploreP:0.0334\n",
      "Episode:2373 meanR:12.9700 R:14.0 loss:0.0276 exploreP:0.0334\n",
      "Episode:2374 meanR:13.0200 R:17.0 loss:0.0285 exploreP:0.0333\n",
      "Episode:2375 meanR:13.0100 R:11.0 loss:0.0284 exploreP:0.0333\n",
      "Episode:2376 meanR:13.0400 R:15.0 loss:0.0254 exploreP:0.0333\n",
      "Episode:2377 meanR:13.0200 R:11.0 loss:0.0258 exploreP:0.0332\n",
      "Episode:2378 meanR:13.0200 R:17.0 loss:0.0250 exploreP:0.0332\n",
      "Episode:2379 meanR:13.0000 R:11.0 loss:0.0238 exploreP:0.0332\n",
      "Episode:2380 meanR:12.9900 R:15.0 loss:0.0270 exploreP:0.0331\n",
      "Episode:2381 meanR:12.9900 R:11.0 loss:0.0285 exploreP:0.0331\n",
      "Episode:2382 meanR:13.0700 R:17.0 loss:0.0250 exploreP:0.0331\n",
      "Episode:2383 meanR:13.0300 R:12.0 loss:0.0281 exploreP:0.0330\n",
      "Episode:2384 meanR:13.0200 R:15.0 loss:0.0291 exploreP:0.0330\n",
      "Episode:2385 meanR:12.9400 R:10.0 loss:0.0297 exploreP:0.0330\n",
      "Episode:2386 meanR:12.9100 R:15.0 loss:0.0260 exploreP:0.0329\n",
      "Episode:2387 meanR:12.8500 R:8.0 loss:0.0304 exploreP:0.0329\n",
      "Episode:2388 meanR:12.7900 R:9.0 loss:0.0320 exploreP:0.0329\n",
      "Episode:2389 meanR:12.7800 R:15.0 loss:0.0265 exploreP:0.0329\n",
      "Episode:2390 meanR:12.7300 R:10.0 loss:0.0348 exploreP:0.0328\n",
      "Episode:2391 meanR:12.7200 R:14.0 loss:0.0305 exploreP:0.0328\n",
      "Episode:2392 meanR:12.7400 R:16.0 loss:0.0218 exploreP:0.0328\n",
      "Episode:2393 meanR:12.7400 R:14.0 loss:0.0256 exploreP:0.0327\n",
      "Episode:2394 meanR:12.7700 R:17.0 loss:0.0224 exploreP:0.0327\n",
      "Episode:2395 meanR:12.8500 R:16.0 loss:0.0289 exploreP:0.0327\n",
      "Episode:2396 meanR:12.8400 R:16.0 loss:0.0277 exploreP:0.0326\n",
      "Episode:2397 meanR:12.8300 R:12.0 loss:0.0289 exploreP:0.0326\n",
      "Episode:2398 meanR:12.8700 R:14.0 loss:0.0259 exploreP:0.0326\n",
      "Episode:2399 meanR:12.8800 R:14.0 loss:0.0313 exploreP:0.0325\n",
      "Episode:2400 meanR:12.8400 R:10.0 loss:0.0279 exploreP:0.0325\n",
      "Episode:2401 meanR:12.8100 R:10.0 loss:0.0257 exploreP:0.0325\n",
      "Episode:2402 meanR:12.8900 R:17.0 loss:0.0282 exploreP:0.0325\n",
      "Episode:2403 meanR:12.8300 R:9.0 loss:0.0296 exploreP:0.0324\n",
      "Episode:2404 meanR:12.8500 R:12.0 loss:0.0263 exploreP:0.0324\n",
      "Episode:2405 meanR:12.8100 R:9.0 loss:0.0277 exploreP:0.0324\n",
      "Episode:2406 meanR:12.7800 R:10.0 loss:0.0343 exploreP:0.0324\n",
      "Episode:2407 meanR:12.7800 R:9.0 loss:0.0267 exploreP:0.0324\n",
      "Episode:2408 meanR:12.7300 R:9.0 loss:0.0218 exploreP:0.0323\n",
      "Episode:2409 meanR:12.7700 R:13.0 loss:0.0276 exploreP:0.0323\n",
      "Episode:2410 meanR:12.8100 R:14.0 loss:0.0273 exploreP:0.0323\n",
      "Episode:2411 meanR:12.7900 R:10.0 loss:0.0301 exploreP:0.0323\n",
      "Episode:2412 meanR:12.7800 R:11.0 loss:0.0293 exploreP:0.0322\n",
      "Episode:2413 meanR:12.7300 R:9.0 loss:0.0290 exploreP:0.0322\n",
      "Episode:2414 meanR:12.7100 R:13.0 loss:0.0286 exploreP:0.0322\n",
      "Episode:2415 meanR:12.7500 R:13.0 loss:0.0258 exploreP:0.0321\n",
      "Episode:2416 meanR:12.7200 R:11.0 loss:0.0209 exploreP:0.0321\n",
      "Episode:2417 meanR:12.7100 R:12.0 loss:0.0266 exploreP:0.0321\n",
      "Episode:2418 meanR:12.7500 R:14.0 loss:0.0261 exploreP:0.0321\n",
      "Episode:2419 meanR:12.8000 R:15.0 loss:0.0242 exploreP:0.0320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2420 meanR:12.7400 R:9.0 loss:0.0289 exploreP:0.0320\n",
      "Episode:2421 meanR:12.7800 R:13.0 loss:0.0308 exploreP:0.0320\n",
      "Episode:2422 meanR:12.7200 R:9.0 loss:0.0298 exploreP:0.0320\n",
      "Episode:2423 meanR:12.6700 R:11.0 loss:0.0247 exploreP:0.0319\n",
      "Episode:2424 meanR:12.7100 R:13.0 loss:0.0298 exploreP:0.0319\n",
      "Episode:2425 meanR:12.6300 R:8.0 loss:0.0329 exploreP:0.0319\n",
      "Episode:2426 meanR:12.6300 R:10.0 loss:0.0235 exploreP:0.0319\n",
      "Episode:2427 meanR:12.6300 R:10.0 loss:0.0278 exploreP:0.0319\n",
      "Episode:2428 meanR:12.6000 R:10.0 loss:0.0252 exploreP:0.0318\n",
      "Episode:2429 meanR:12.6300 R:13.0 loss:0.0283 exploreP:0.0318\n",
      "Episode:2430 meanR:12.7000 R:16.0 loss:0.0338 exploreP:0.0318\n",
      "Episode:2431 meanR:12.6500 R:11.0 loss:0.0271 exploreP:0.0317\n",
      "Episode:2432 meanR:12.6500 R:9.0 loss:0.0253 exploreP:0.0317\n",
      "Episode:2433 meanR:12.6200 R:10.0 loss:0.0215 exploreP:0.0317\n",
      "Episode:2434 meanR:12.6200 R:16.0 loss:0.0272 exploreP:0.0317\n",
      "Episode:2435 meanR:12.6300 R:13.0 loss:0.0265 exploreP:0.0316\n",
      "Episode:2436 meanR:12.6400 R:10.0 loss:0.0278 exploreP:0.0316\n",
      "Episode:2437 meanR:12.6100 R:12.0 loss:0.0313 exploreP:0.0316\n",
      "Episode:2438 meanR:12.6900 R:19.0 loss:0.0296 exploreP:0.0316\n",
      "Episode:2439 meanR:12.7400 R:13.0 loss:0.0257 exploreP:0.0315\n",
      "Episode:2440 meanR:12.8000 R:17.0 loss:0.0260 exploreP:0.0315\n",
      "Episode:2441 meanR:12.7900 R:14.0 loss:0.0269 exploreP:0.0315\n",
      "Episode:2442 meanR:12.7800 R:14.0 loss:0.0228 exploreP:0.0314\n",
      "Episode:2443 meanR:12.7400 R:11.0 loss:0.0275 exploreP:0.0314\n",
      "Episode:2444 meanR:12.7400 R:14.0 loss:0.0221 exploreP:0.0314\n",
      "Episode:2445 meanR:12.7200 R:14.0 loss:0.0225 exploreP:0.0313\n",
      "Episode:2446 meanR:12.7400 R:14.0 loss:0.0268 exploreP:0.0313\n",
      "Episode:2447 meanR:12.7400 R:15.0 loss:0.0272 exploreP:0.0313\n",
      "Episode:2448 meanR:12.7200 R:11.0 loss:0.0295 exploreP:0.0313\n",
      "Episode:2449 meanR:12.7600 R:16.0 loss:0.0248 exploreP:0.0312\n",
      "Episode:2450 meanR:12.8200 R:15.0 loss:0.0271 exploreP:0.0312\n",
      "Episode:2451 meanR:12.8900 R:16.0 loss:0.0318 exploreP:0.0312\n",
      "Episode:2452 meanR:12.9100 R:14.0 loss:0.0224 exploreP:0.0311\n",
      "Episode:2453 meanR:12.9100 R:10.0 loss:0.0256 exploreP:0.0311\n",
      "Episode:2454 meanR:12.8700 R:12.0 loss:0.0265 exploreP:0.0311\n",
      "Episode:2455 meanR:12.8400 R:12.0 loss:0.0322 exploreP:0.0311\n",
      "Episode:2456 meanR:12.8000 R:12.0 loss:0.0261 exploreP:0.0310\n",
      "Episode:2457 meanR:12.7600 R:10.0 loss:0.0277 exploreP:0.0310\n",
      "Episode:2458 meanR:12.7800 R:12.0 loss:0.0295 exploreP:0.0310\n",
      "Episode:2459 meanR:12.7800 R:16.0 loss:0.0271 exploreP:0.0310\n",
      "Episode:2460 meanR:12.7800 R:15.0 loss:0.0264 exploreP:0.0309\n",
      "Episode:2461 meanR:12.8100 R:16.0 loss:0.0288 exploreP:0.0309\n",
      "Episode:2462 meanR:12.8200 R:17.0 loss:0.0236 exploreP:0.0309\n",
      "Episode:2463 meanR:12.7800 R:9.0 loss:0.0220 exploreP:0.0308\n",
      "Episode:2464 meanR:12.7600 R:10.0 loss:0.0318 exploreP:0.0308\n",
      "Episode:2465 meanR:12.7200 R:15.0 loss:0.0287 exploreP:0.0308\n",
      "Episode:2466 meanR:12.7500 R:11.0 loss:0.0289 exploreP:0.0308\n",
      "Episode:2467 meanR:12.7400 R:11.0 loss:0.0241 exploreP:0.0307\n",
      "Episode:2468 meanR:12.6800 R:9.0 loss:0.0275 exploreP:0.0307\n",
      "Episode:2469 meanR:12.7400 R:16.0 loss:0.0267 exploreP:0.0307\n",
      "Episode:2470 meanR:12.6900 R:9.0 loss:0.0290 exploreP:0.0307\n",
      "Episode:2471 meanR:12.6300 R:10.0 loss:0.0225 exploreP:0.0306\n",
      "Episode:2472 meanR:12.6200 R:14.0 loss:0.0242 exploreP:0.0306\n",
      "Episode:2473 meanR:12.5700 R:9.0 loss:0.0303 exploreP:0.0306\n",
      "Episode:2474 meanR:12.5000 R:10.0 loss:0.0254 exploreP:0.0306\n",
      "Episode:2475 meanR:12.4900 R:10.0 loss:0.0277 exploreP:0.0306\n",
      "Episode:2476 meanR:12.5100 R:17.0 loss:0.0261 exploreP:0.0305\n",
      "Episode:2477 meanR:12.5100 R:11.0 loss:0.0289 exploreP:0.0305\n",
      "Episode:2478 meanR:12.4900 R:15.0 loss:0.0299 exploreP:0.0305\n",
      "Episode:2479 meanR:12.4700 R:9.0 loss:0.0312 exploreP:0.0304\n",
      "Episode:2480 meanR:12.4600 R:14.0 loss:0.0264 exploreP:0.0304\n",
      "Episode:2481 meanR:12.4800 R:13.0 loss:0.0293 exploreP:0.0304\n",
      "Episode:2482 meanR:12.4200 R:11.0 loss:0.0307 exploreP:0.0304\n",
      "Episode:2483 meanR:12.4600 R:16.0 loss:0.0304 exploreP:0.0303\n",
      "Episode:2484 meanR:12.4800 R:17.0 loss:0.0223 exploreP:0.0303\n",
      "Episode:2485 meanR:12.4800 R:10.0 loss:0.0314 exploreP:0.0303\n",
      "Episode:2486 meanR:12.4200 R:9.0 loss:0.0314 exploreP:0.0303\n",
      "Episode:2487 meanR:12.4900 R:15.0 loss:0.0284 exploreP:0.0302\n",
      "Episode:2488 meanR:12.5100 R:11.0 loss:0.0268 exploreP:0.0302\n",
      "Episode:2489 meanR:12.4800 R:12.0 loss:0.0334 exploreP:0.0302\n",
      "Episode:2490 meanR:12.4600 R:8.0 loss:0.0258 exploreP:0.0302\n",
      "Episode:2491 meanR:12.4500 R:13.0 loss:0.0312 exploreP:0.0301\n",
      "Episode:2492 meanR:12.4000 R:11.0 loss:0.0260 exploreP:0.0301\n",
      "Episode:2493 meanR:12.3800 R:12.0 loss:0.0264 exploreP:0.0301\n",
      "Episode:2494 meanR:12.3600 R:15.0 loss:0.0281 exploreP:0.0301\n",
      "Episode:2495 meanR:12.3700 R:17.0 loss:0.0245 exploreP:0.0300\n",
      "Episode:2496 meanR:12.3300 R:12.0 loss:0.0284 exploreP:0.0300\n",
      "Episode:2497 meanR:12.3500 R:14.0 loss:0.0333 exploreP:0.0300\n",
      "Episode:2498 meanR:12.3600 R:15.0 loss:0.0276 exploreP:0.0300\n",
      "Episode:2499 meanR:12.3700 R:15.0 loss:0.0275 exploreP:0.0299\n",
      "Episode:2500 meanR:12.4200 R:15.0 loss:0.0253 exploreP:0.0299\n",
      "Episode:2501 meanR:12.4600 R:14.0 loss:0.0291 exploreP:0.0299\n",
      "Episode:2502 meanR:12.3900 R:10.0 loss:0.0274 exploreP:0.0298\n",
      "Episode:2503 meanR:12.4400 R:14.0 loss:0.0274 exploreP:0.0298\n",
      "Episode:2504 meanR:12.4600 R:14.0 loss:0.0272 exploreP:0.0298\n",
      "Episode:2505 meanR:12.5200 R:15.0 loss:0.0227 exploreP:0.0298\n",
      "Episode:2506 meanR:12.5100 R:9.0 loss:0.0239 exploreP:0.0297\n",
      "Episode:2507 meanR:12.5700 R:15.0 loss:0.0316 exploreP:0.0297\n",
      "Episode:2508 meanR:12.6500 R:17.0 loss:0.0232 exploreP:0.0297\n",
      "Episode:2509 meanR:12.6900 R:17.0 loss:0.0232 exploreP:0.0296\n",
      "Episode:2510 meanR:12.6400 R:9.0 loss:0.0311 exploreP:0.0296\n",
      "Episode:2511 meanR:12.6900 R:15.0 loss:0.0268 exploreP:0.0296\n",
      "Episode:2512 meanR:12.7200 R:14.0 loss:0.0308 exploreP:0.0296\n",
      "Episode:2513 meanR:12.7800 R:15.0 loss:0.0289 exploreP:0.0295\n",
      "Episode:2514 meanR:12.7500 R:10.0 loss:0.0281 exploreP:0.0295\n",
      "Episode:2515 meanR:12.7400 R:12.0 loss:0.0274 exploreP:0.0295\n",
      "Episode:2516 meanR:12.7500 R:12.0 loss:0.0280 exploreP:0.0295\n",
      "Episode:2517 meanR:12.7700 R:14.0 loss:0.0265 exploreP:0.0294\n",
      "Episode:2518 meanR:12.7700 R:14.0 loss:0.0245 exploreP:0.0294\n",
      "Episode:2519 meanR:12.7700 R:15.0 loss:0.0280 exploreP:0.0294\n",
      "Episode:2520 meanR:12.7800 R:10.0 loss:0.0264 exploreP:0.0294\n",
      "Episode:2521 meanR:12.7800 R:13.0 loss:0.0290 exploreP:0.0293\n",
      "Episode:2522 meanR:12.7900 R:10.0 loss:0.0319 exploreP:0.0293\n",
      "Episode:2523 meanR:12.8300 R:15.0 loss:0.0249 exploreP:0.0293\n",
      "Episode:2524 meanR:12.8400 R:14.0 loss:0.0263 exploreP:0.0293\n",
      "Episode:2525 meanR:12.8700 R:11.0 loss:0.0278 exploreP:0.0293\n",
      "Episode:2526 meanR:12.9200 R:15.0 loss:0.0258 exploreP:0.0292\n",
      "Episode:2527 meanR:12.9100 R:9.0 loss:0.0258 exploreP:0.0292\n",
      "Episode:2528 meanR:12.9500 R:14.0 loss:0.0253 exploreP:0.0292\n",
      "Episode:2529 meanR:12.9800 R:16.0 loss:0.0285 exploreP:0.0291\n",
      "Episode:2530 meanR:12.9000 R:8.0 loss:0.0251 exploreP:0.0291\n",
      "Episode:2531 meanR:12.9000 R:11.0 loss:0.0256 exploreP:0.0291\n",
      "Episode:2532 meanR:12.9200 R:11.0 loss:0.0274 exploreP:0.0291\n",
      "Episode:2533 meanR:12.9200 R:10.0 loss:0.0255 exploreP:0.0291\n",
      "Episode:2534 meanR:12.9200 R:16.0 loss:0.0267 exploreP:0.0290\n",
      "Episode:2535 meanR:12.9200 R:13.0 loss:0.0254 exploreP:0.0290\n",
      "Episode:2536 meanR:12.9400 R:12.0 loss:0.0306 exploreP:0.0290\n",
      "Episode:2537 meanR:12.9500 R:13.0 loss:0.0260 exploreP:0.0290\n",
      "Episode:2538 meanR:12.9000 R:14.0 loss:0.0278 exploreP:0.0289\n",
      "Episode:2539 meanR:12.8800 R:11.0 loss:0.0245 exploreP:0.0289\n",
      "Episode:2540 meanR:12.8700 R:16.0 loss:0.0219 exploreP:0.0289\n",
      "Episode:2541 meanR:12.8600 R:13.0 loss:0.0296 exploreP:0.0289\n",
      "Episode:2542 meanR:12.8600 R:14.0 loss:0.0322 exploreP:0.0288\n",
      "Episode:2543 meanR:12.8700 R:12.0 loss:0.0239 exploreP:0.0288\n",
      "Episode:2544 meanR:12.8900 R:16.0 loss:0.0273 exploreP:0.0288\n",
      "Episode:2545 meanR:12.8800 R:13.0 loss:0.0292 exploreP:0.0288\n",
      "Episode:2546 meanR:12.8500 R:11.0 loss:0.0252 exploreP:0.0287\n",
      "Episode:2547 meanR:12.8100 R:11.0 loss:0.0258 exploreP:0.0287\n",
      "Episode:2548 meanR:12.8600 R:16.0 loss:0.0330 exploreP:0.0287\n",
      "Episode:2549 meanR:12.8400 R:14.0 loss:0.0268 exploreP:0.0287\n",
      "Episode:2550 meanR:12.8500 R:16.0 loss:0.0258 exploreP:0.0286\n",
      "Episode:2551 meanR:12.8100 R:12.0 loss:0.0292 exploreP:0.0286\n",
      "Episode:2552 meanR:12.7900 R:12.0 loss:0.0258 exploreP:0.0286\n",
      "Episode:2553 meanR:12.8000 R:11.0 loss:0.0297 exploreP:0.0286\n",
      "Episode:2554 meanR:12.7700 R:9.0 loss:0.0282 exploreP:0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2555 meanR:12.7400 R:9.0 loss:0.0279 exploreP:0.0285\n",
      "Episode:2556 meanR:12.7500 R:13.0 loss:0.0238 exploreP:0.0285\n",
      "Episode:2557 meanR:12.8000 R:15.0 loss:0.0253 exploreP:0.0285\n",
      "Episode:2558 meanR:12.8000 R:12.0 loss:0.0267 exploreP:0.0285\n",
      "Episode:2559 meanR:12.8000 R:16.0 loss:0.0242 exploreP:0.0284\n",
      "Episode:2560 meanR:12.7600 R:11.0 loss:0.0270 exploreP:0.0284\n",
      "Episode:2561 meanR:12.7100 R:11.0 loss:0.0299 exploreP:0.0284\n",
      "Episode:2562 meanR:12.6900 R:15.0 loss:0.0295 exploreP:0.0284\n",
      "Episode:2563 meanR:12.7000 R:10.0 loss:0.0252 exploreP:0.0283\n",
      "Episode:2564 meanR:12.7100 R:11.0 loss:0.0309 exploreP:0.0283\n",
      "Episode:2565 meanR:12.6700 R:11.0 loss:0.0285 exploreP:0.0283\n",
      "Episode:2566 meanR:12.6600 R:10.0 loss:0.0312 exploreP:0.0283\n",
      "Episode:2567 meanR:12.6800 R:13.0 loss:0.0232 exploreP:0.0283\n",
      "Episode:2568 meanR:12.6900 R:10.0 loss:0.0287 exploreP:0.0282\n",
      "Episode:2569 meanR:12.7000 R:17.0 loss:0.0259 exploreP:0.0282\n",
      "Episode:2570 meanR:12.7200 R:11.0 loss:0.0280 exploreP:0.0282\n",
      "Episode:2571 meanR:12.7300 R:11.0 loss:0.0314 exploreP:0.0282\n",
      "Episode:2572 meanR:12.6900 R:10.0 loss:0.0223 exploreP:0.0282\n",
      "Episode:2573 meanR:12.7200 R:12.0 loss:0.0272 exploreP:0.0281\n",
      "Episode:2574 meanR:12.7400 R:12.0 loss:0.0366 exploreP:0.0281\n",
      "Episode:2575 meanR:12.8100 R:17.0 loss:0.0265 exploreP:0.0281\n",
      "Episode:2576 meanR:12.7600 R:12.0 loss:0.0264 exploreP:0.0281\n",
      "Episode:2577 meanR:12.7900 R:14.0 loss:0.0301 exploreP:0.0280\n",
      "Episode:2578 meanR:12.7400 R:10.0 loss:0.0286 exploreP:0.0280\n",
      "Episode:2579 meanR:12.7600 R:11.0 loss:0.0225 exploreP:0.0280\n",
      "Episode:2580 meanR:12.7800 R:16.0 loss:0.0255 exploreP:0.0280\n",
      "Episode:2581 meanR:12.7900 R:14.0 loss:0.0219 exploreP:0.0279\n",
      "Episode:2582 meanR:12.8400 R:16.0 loss:0.0244 exploreP:0.0279\n",
      "Episode:2583 meanR:12.8000 R:12.0 loss:0.0291 exploreP:0.0279\n",
      "Episode:2584 meanR:12.7700 R:14.0 loss:0.0250 exploreP:0.0279\n",
      "Episode:2585 meanR:12.7900 R:12.0 loss:0.0286 exploreP:0.0278\n",
      "Episode:2586 meanR:12.8000 R:10.0 loss:0.0228 exploreP:0.0278\n",
      "Episode:2587 meanR:12.7800 R:13.0 loss:0.0282 exploreP:0.0278\n",
      "Episode:2588 meanR:12.7900 R:12.0 loss:0.0308 exploreP:0.0278\n",
      "Episode:2589 meanR:12.7600 R:9.0 loss:0.0253 exploreP:0.0278\n",
      "Episode:2590 meanR:12.8400 R:16.0 loss:0.0283 exploreP:0.0277\n",
      "Episode:2591 meanR:12.8300 R:12.0 loss:0.0242 exploreP:0.0277\n",
      "Episode:2592 meanR:12.8100 R:9.0 loss:0.0335 exploreP:0.0277\n",
      "Episode:2593 meanR:12.8200 R:13.0 loss:0.0274 exploreP:0.0277\n",
      "Episode:2594 meanR:12.8000 R:13.0 loss:0.0245 exploreP:0.0277\n",
      "Episode:2595 meanR:12.7800 R:15.0 loss:0.0266 exploreP:0.0276\n",
      "Episode:2596 meanR:12.7500 R:9.0 loss:0.0262 exploreP:0.0276\n",
      "Episode:2597 meanR:12.7200 R:11.0 loss:0.0204 exploreP:0.0276\n",
      "Episode:2598 meanR:12.7400 R:17.0 loss:0.0253 exploreP:0.0276\n",
      "Episode:2599 meanR:12.7600 R:17.0 loss:0.0252 exploreP:0.0275\n",
      "Episode:2600 meanR:12.7600 R:15.0 loss:0.0236 exploreP:0.0275\n",
      "Episode:2601 meanR:12.7800 R:16.0 loss:0.0242 exploreP:0.0275\n",
      "Episode:2602 meanR:12.8400 R:16.0 loss:0.0224 exploreP:0.0275\n",
      "Episode:2603 meanR:12.8000 R:10.0 loss:0.0251 exploreP:0.0274\n",
      "Episode:2604 meanR:12.7700 R:11.0 loss:0.0239 exploreP:0.0274\n",
      "Episode:2605 meanR:12.7900 R:17.0 loss:0.0244 exploreP:0.0274\n",
      "Episode:2606 meanR:12.7900 R:9.0 loss:0.0309 exploreP:0.0274\n",
      "Episode:2607 meanR:12.8000 R:16.0 loss:0.0341 exploreP:0.0273\n",
      "Episode:2608 meanR:12.7700 R:14.0 loss:0.0280 exploreP:0.0273\n",
      "Episode:2609 meanR:12.7000 R:10.0 loss:0.0210 exploreP:0.0273\n",
      "Episode:2610 meanR:12.7700 R:16.0 loss:0.0237 exploreP:0.0273\n",
      "Episode:2611 meanR:12.7100 R:9.0 loss:0.0251 exploreP:0.0273\n",
      "Episode:2612 meanR:12.6900 R:12.0 loss:0.0288 exploreP:0.0272\n",
      "Episode:2613 meanR:12.6800 R:14.0 loss:0.0257 exploreP:0.0272\n",
      "Episode:2614 meanR:12.7400 R:16.0 loss:0.0235 exploreP:0.0272\n",
      "Episode:2615 meanR:12.7200 R:10.0 loss:0.0261 exploreP:0.0272\n",
      "Episode:2616 meanR:12.7600 R:16.0 loss:0.0303 exploreP:0.0271\n",
      "Episode:2617 meanR:12.7100 R:9.0 loss:0.0297 exploreP:0.0271\n",
      "Episode:2618 meanR:12.7200 R:15.0 loss:0.0256 exploreP:0.0271\n",
      "Episode:2619 meanR:12.6600 R:9.0 loss:0.0303 exploreP:0.0271\n",
      "Episode:2620 meanR:12.7000 R:14.0 loss:0.0266 exploreP:0.0271\n",
      "Episode:2621 meanR:12.6500 R:8.0 loss:0.0256 exploreP:0.0270\n",
      "Episode:2622 meanR:12.6400 R:9.0 loss:0.0273 exploreP:0.0270\n",
      "Episode:2623 meanR:12.5800 R:9.0 loss:0.0244 exploreP:0.0270\n",
      "Episode:2624 meanR:12.5900 R:15.0 loss:0.0277 exploreP:0.0270\n",
      "Episode:2625 meanR:12.5800 R:10.0 loss:0.0252 exploreP:0.0270\n",
      "Episode:2626 meanR:12.5900 R:16.0 loss:0.0265 exploreP:0.0269\n",
      "Episode:2627 meanR:12.6500 R:15.0 loss:0.0281 exploreP:0.0269\n",
      "Episode:2628 meanR:12.6500 R:14.0 loss:0.0247 exploreP:0.0269\n",
      "Episode:2629 meanR:12.6300 R:14.0 loss:0.0252 exploreP:0.0269\n",
      "Episode:2630 meanR:12.6400 R:9.0 loss:0.0227 exploreP:0.0269\n",
      "Episode:2631 meanR:12.6800 R:15.0 loss:0.0270 exploreP:0.0268\n",
      "Episode:2632 meanR:12.7300 R:16.0 loss:0.0265 exploreP:0.0268\n",
      "Episode:2633 meanR:12.7600 R:13.0 loss:0.0279 exploreP:0.0268\n",
      "Episode:2634 meanR:12.7200 R:12.0 loss:0.0267 exploreP:0.0268\n",
      "Episode:2635 meanR:12.7400 R:15.0 loss:0.0229 exploreP:0.0267\n",
      "Episode:2636 meanR:12.7600 R:14.0 loss:0.0263 exploreP:0.0267\n",
      "Episode:2637 meanR:12.7900 R:16.0 loss:0.0250 exploreP:0.0267\n",
      "Episode:2638 meanR:12.7600 R:11.0 loss:0.0312 exploreP:0.0267\n",
      "Episode:2639 meanR:12.7500 R:10.0 loss:0.0234 exploreP:0.0267\n",
      "Episode:2640 meanR:12.7100 R:12.0 loss:0.0213 exploreP:0.0266\n",
      "Episode:2641 meanR:12.7400 R:16.0 loss:0.0268 exploreP:0.0266\n",
      "Episode:2642 meanR:12.7000 R:10.0 loss:0.0246 exploreP:0.0266\n",
      "Episode:2643 meanR:12.6900 R:11.0 loss:0.0289 exploreP:0.0266\n",
      "Episode:2644 meanR:12.6600 R:13.0 loss:0.0252 exploreP:0.0266\n",
      "Episode:2645 meanR:12.6400 R:11.0 loss:0.0226 exploreP:0.0265\n",
      "Episode:2646 meanR:12.6200 R:9.0 loss:0.0259 exploreP:0.0265\n",
      "Episode:2647 meanR:12.6200 R:11.0 loss:0.0271 exploreP:0.0265\n",
      "Episode:2648 meanR:12.5500 R:9.0 loss:0.0254 exploreP:0.0265\n",
      "Episode:2649 meanR:12.5700 R:16.0 loss:0.0262 exploreP:0.0265\n",
      "Episode:2650 meanR:12.5300 R:12.0 loss:0.0305 exploreP:0.0264\n",
      "Episode:2651 meanR:12.5500 R:14.0 loss:0.0249 exploreP:0.0264\n",
      "Episode:2652 meanR:12.5400 R:11.0 loss:0.0300 exploreP:0.0264\n",
      "Episode:2653 meanR:12.5500 R:12.0 loss:0.0248 exploreP:0.0264\n",
      "Episode:2654 meanR:12.5700 R:11.0 loss:0.0251 exploreP:0.0264\n",
      "Episode:2655 meanR:12.6000 R:12.0 loss:0.0310 exploreP:0.0263\n",
      "Episode:2656 meanR:12.6300 R:16.0 loss:0.0277 exploreP:0.0263\n",
      "Episode:2657 meanR:12.5700 R:9.0 loss:0.0271 exploreP:0.0263\n",
      "Episode:2658 meanR:12.5400 R:9.0 loss:0.0261 exploreP:0.0263\n",
      "Episode:2659 meanR:12.4900 R:11.0 loss:0.0289 exploreP:0.0263\n",
      "Episode:2660 meanR:12.5500 R:17.0 loss:0.0274 exploreP:0.0262\n",
      "Episode:2661 meanR:12.5700 R:13.0 loss:0.0236 exploreP:0.0262\n",
      "Episode:2662 meanR:12.5400 R:12.0 loss:0.0316 exploreP:0.0262\n",
      "Episode:2663 meanR:12.6100 R:17.0 loss:0.0262 exploreP:0.0262\n",
      "Episode:2664 meanR:12.5900 R:9.0 loss:0.0248 exploreP:0.0262\n",
      "Episode:2665 meanR:12.5800 R:10.0 loss:0.0218 exploreP:0.0261\n",
      "Episode:2666 meanR:12.6300 R:15.0 loss:0.0242 exploreP:0.0261\n",
      "Episode:2667 meanR:12.6400 R:14.0 loss:0.0286 exploreP:0.0261\n",
      "Episode:2668 meanR:12.6300 R:9.0 loss:0.0237 exploreP:0.0261\n",
      "Episode:2669 meanR:12.5500 R:9.0 loss:0.0293 exploreP:0.0261\n",
      "Episode:2670 meanR:12.5600 R:12.0 loss:0.0249 exploreP:0.0260\n",
      "Episode:2671 meanR:12.5600 R:11.0 loss:0.0306 exploreP:0.0260\n",
      "Episode:2672 meanR:12.5800 R:12.0 loss:0.0244 exploreP:0.0260\n",
      "Episode:2673 meanR:12.6200 R:16.0 loss:0.0273 exploreP:0.0260\n",
      "Episode:2674 meanR:12.6400 R:14.0 loss:0.0319 exploreP:0.0260\n",
      "Episode:2675 meanR:12.5900 R:12.0 loss:0.0260 exploreP:0.0259\n",
      "Episode:2676 meanR:12.6100 R:14.0 loss:0.0284 exploreP:0.0259\n",
      "Episode:2677 meanR:12.6200 R:15.0 loss:0.0277 exploreP:0.0259\n",
      "Episode:2678 meanR:12.6800 R:16.0 loss:0.0311 exploreP:0.0259\n",
      "Episode:2679 meanR:12.7000 R:13.0 loss:0.0362 exploreP:0.0259\n",
      "Episode:2680 meanR:12.6500 R:11.0 loss:0.0281 exploreP:0.0258\n",
      "Episode:2681 meanR:12.6500 R:14.0 loss:0.0306 exploreP:0.0258\n",
      "Episode:2682 meanR:12.6400 R:15.0 loss:0.0309 exploreP:0.0258\n",
      "Episode:2683 meanR:12.6800 R:16.0 loss:0.0282 exploreP:0.0258\n",
      "Episode:2684 meanR:12.6400 R:10.0 loss:0.0316 exploreP:0.0257\n",
      "Episode:2685 meanR:12.6400 R:12.0 loss:0.0262 exploreP:0.0257\n",
      "Episode:2686 meanR:12.6600 R:12.0 loss:0.0270 exploreP:0.0257\n",
      "Episode:2687 meanR:12.6700 R:14.0 loss:0.0316 exploreP:0.0257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2688 meanR:12.6800 R:13.0 loss:0.0291 exploreP:0.0257\n",
      "Episode:2689 meanR:12.7400 R:15.0 loss:0.0257 exploreP:0.0256\n",
      "Episode:2690 meanR:12.7200 R:14.0 loss:0.0294 exploreP:0.0256\n",
      "Episode:2691 meanR:12.7400 R:14.0 loss:0.0250 exploreP:0.0256\n",
      "Episode:2692 meanR:12.7800 R:13.0 loss:0.0278 exploreP:0.0256\n",
      "Episode:2693 meanR:12.7400 R:9.0 loss:0.0220 exploreP:0.0256\n",
      "Episode:2694 meanR:12.7300 R:12.0 loss:0.0253 exploreP:0.0255\n",
      "Episode:2695 meanR:12.7700 R:19.0 loss:0.0285 exploreP:0.0255\n",
      "Episode:2696 meanR:12.8100 R:13.0 loss:0.0240 exploreP:0.0255\n",
      "Episode:2697 meanR:12.8300 R:13.0 loss:0.0278 exploreP:0.0255\n",
      "Episode:2698 meanR:12.7700 R:11.0 loss:0.0336 exploreP:0.0255\n",
      "Episode:2699 meanR:12.7100 R:11.0 loss:0.0302 exploreP:0.0254\n",
      "Episode:2700 meanR:12.6800 R:12.0 loss:0.0248 exploreP:0.0254\n",
      "Episode:2701 meanR:12.6500 R:13.0 loss:0.0267 exploreP:0.0254\n",
      "Episode:2702 meanR:12.6300 R:14.0 loss:0.0261 exploreP:0.0254\n",
      "Episode:2703 meanR:12.6300 R:10.0 loss:0.0222 exploreP:0.0254\n",
      "Episode:2704 meanR:12.6200 R:10.0 loss:0.0248 exploreP:0.0254\n",
      "Episode:2705 meanR:12.6000 R:15.0 loss:0.0260 exploreP:0.0253\n",
      "Episode:2706 meanR:12.6300 R:12.0 loss:0.0248 exploreP:0.0253\n",
      "Episode:2707 meanR:12.5700 R:10.0 loss:0.0308 exploreP:0.0253\n",
      "Episode:2708 meanR:12.5200 R:9.0 loss:0.0281 exploreP:0.0253\n",
      "Episode:2709 meanR:12.5500 R:13.0 loss:0.0291 exploreP:0.0253\n",
      "Episode:2710 meanR:12.5000 R:11.0 loss:0.0332 exploreP:0.0252\n",
      "Episode:2711 meanR:12.5500 R:14.0 loss:0.0259 exploreP:0.0252\n",
      "Episode:2712 meanR:12.5600 R:13.0 loss:0.0240 exploreP:0.0252\n",
      "Episode:2713 meanR:12.5400 R:12.0 loss:0.0270 exploreP:0.0252\n",
      "Episode:2714 meanR:12.5200 R:14.0 loss:0.0307 exploreP:0.0252\n",
      "Episode:2715 meanR:12.5700 R:15.0 loss:0.0263 exploreP:0.0251\n",
      "Episode:2716 meanR:12.4900 R:8.0 loss:0.0280 exploreP:0.0251\n",
      "Episode:2717 meanR:12.4900 R:9.0 loss:0.0219 exploreP:0.0251\n",
      "Episode:2718 meanR:12.4400 R:10.0 loss:0.0298 exploreP:0.0251\n",
      "Episode:2719 meanR:12.5000 R:15.0 loss:0.0261 exploreP:0.0251\n",
      "Episode:2720 meanR:12.4500 R:9.0 loss:0.0284 exploreP:0.0251\n",
      "Episode:2721 meanR:12.4900 R:12.0 loss:0.0298 exploreP:0.0250\n",
      "Episode:2722 meanR:12.5100 R:11.0 loss:0.0341 exploreP:0.0250\n",
      "Episode:2723 meanR:12.5200 R:10.0 loss:0.0321 exploreP:0.0250\n",
      "Episode:2724 meanR:12.4900 R:12.0 loss:0.0311 exploreP:0.0250\n",
      "Episode:2725 meanR:12.4900 R:10.0 loss:0.0289 exploreP:0.0250\n",
      "Episode:2726 meanR:12.4900 R:16.0 loss:0.0272 exploreP:0.0250\n",
      "Episode:2727 meanR:12.4400 R:10.0 loss:0.0278 exploreP:0.0249\n",
      "Episode:2728 meanR:12.4100 R:11.0 loss:0.0296 exploreP:0.0249\n",
      "Episode:2729 meanR:12.3500 R:8.0 loss:0.0219 exploreP:0.0249\n",
      "Episode:2730 meanR:12.3800 R:12.0 loss:0.0297 exploreP:0.0249\n",
      "Episode:2731 meanR:12.3700 R:14.0 loss:0.0270 exploreP:0.0249\n",
      "Episode:2732 meanR:12.3500 R:14.0 loss:0.0264 exploreP:0.0249\n",
      "Episode:2733 meanR:12.3300 R:11.0 loss:0.0264 exploreP:0.0248\n",
      "Episode:2734 meanR:12.3500 R:14.0 loss:0.0274 exploreP:0.0248\n",
      "Episode:2735 meanR:12.3200 R:12.0 loss:0.0280 exploreP:0.0248\n",
      "Episode:2736 meanR:12.2800 R:10.0 loss:0.0244 exploreP:0.0248\n",
      "Episode:2737 meanR:12.2800 R:16.0 loss:0.0280 exploreP:0.0248\n",
      "Episode:2738 meanR:12.3100 R:14.0 loss:0.0268 exploreP:0.0247\n",
      "Episode:2739 meanR:12.3000 R:9.0 loss:0.0218 exploreP:0.0247\n",
      "Episode:2740 meanR:12.3100 R:13.0 loss:0.0258 exploreP:0.0247\n",
      "Episode:2741 meanR:12.2900 R:14.0 loss:0.0296 exploreP:0.0247\n",
      "Episode:2742 meanR:12.2700 R:8.0 loss:0.0298 exploreP:0.0247\n",
      "Episode:2743 meanR:12.3000 R:14.0 loss:0.0237 exploreP:0.0247\n",
      "Episode:2744 meanR:12.2800 R:11.0 loss:0.0258 exploreP:0.0246\n",
      "Episode:2745 meanR:12.2500 R:8.0 loss:0.0247 exploreP:0.0246\n",
      "Episode:2746 meanR:12.3000 R:14.0 loss:0.0325 exploreP:0.0246\n",
      "Episode:2747 meanR:12.3400 R:15.0 loss:0.0268 exploreP:0.0246\n",
      "Episode:2748 meanR:12.3600 R:11.0 loss:0.0291 exploreP:0.0246\n",
      "Episode:2749 meanR:12.3600 R:16.0 loss:0.0307 exploreP:0.0245\n",
      "Episode:2750 meanR:12.3900 R:15.0 loss:0.0274 exploreP:0.0245\n",
      "Episode:2751 meanR:12.3400 R:9.0 loss:0.0321 exploreP:0.0245\n",
      "Episode:2752 meanR:12.4000 R:17.0 loss:0.0253 exploreP:0.0245\n",
      "Episode:2753 meanR:12.3900 R:11.0 loss:0.0278 exploreP:0.0245\n",
      "Episode:2754 meanR:12.4100 R:13.0 loss:0.0253 exploreP:0.0245\n",
      "Episode:2755 meanR:12.3800 R:9.0 loss:0.0297 exploreP:0.0244\n",
      "Episode:2756 meanR:12.3300 R:11.0 loss:0.0274 exploreP:0.0244\n",
      "Episode:2757 meanR:12.3600 R:12.0 loss:0.0247 exploreP:0.0244\n",
      "Episode:2758 meanR:12.4100 R:14.0 loss:0.0287 exploreP:0.0244\n",
      "Episode:2759 meanR:12.4100 R:11.0 loss:0.0249 exploreP:0.0244\n",
      "Episode:2760 meanR:12.3700 R:13.0 loss:0.0257 exploreP:0.0244\n",
      "Episode:2761 meanR:12.3800 R:14.0 loss:0.0313 exploreP:0.0243\n",
      "Episode:2762 meanR:12.4000 R:14.0 loss:0.0275 exploreP:0.0243\n",
      "Episode:2763 meanR:12.3600 R:13.0 loss:0.0300 exploreP:0.0243\n",
      "Episode:2764 meanR:12.3800 R:11.0 loss:0.0251 exploreP:0.0243\n",
      "Episode:2765 meanR:12.4400 R:16.0 loss:0.0225 exploreP:0.0243\n",
      "Episode:2766 meanR:12.3900 R:10.0 loss:0.0264 exploreP:0.0242\n",
      "Episode:2767 meanR:12.4000 R:15.0 loss:0.0291 exploreP:0.0242\n",
      "Episode:2768 meanR:12.4600 R:15.0 loss:0.0316 exploreP:0.0242\n",
      "Episode:2769 meanR:12.4900 R:12.0 loss:0.0300 exploreP:0.0242\n",
      "Episode:2770 meanR:12.4800 R:11.0 loss:0.0336 exploreP:0.0242\n",
      "Episode:2771 meanR:12.4900 R:12.0 loss:0.0258 exploreP:0.0241\n",
      "Episode:2772 meanR:12.4900 R:12.0 loss:0.0282 exploreP:0.0241\n",
      "Episode:2773 meanR:12.4300 R:10.0 loss:0.0267 exploreP:0.0241\n",
      "Episode:2774 meanR:12.4100 R:12.0 loss:0.0326 exploreP:0.0241\n",
      "Episode:2775 meanR:12.4300 R:14.0 loss:0.0355 exploreP:0.0241\n",
      "Episode:2776 meanR:12.3900 R:10.0 loss:0.0268 exploreP:0.0241\n",
      "Episode:2777 meanR:12.3600 R:12.0 loss:0.0237 exploreP:0.0240\n",
      "Episode:2778 meanR:12.3300 R:13.0 loss:0.0266 exploreP:0.0240\n",
      "Episode:2779 meanR:12.3000 R:10.0 loss:0.0265 exploreP:0.0240\n",
      "Episode:2780 meanR:12.3400 R:15.0 loss:0.0264 exploreP:0.0240\n",
      "Episode:2781 meanR:12.3200 R:12.0 loss:0.0272 exploreP:0.0240\n",
      "Episode:2782 meanR:12.3300 R:16.0 loss:0.0242 exploreP:0.0240\n",
      "Episode:2783 meanR:12.2600 R:9.0 loss:0.0293 exploreP:0.0239\n",
      "Episode:2784 meanR:12.2500 R:9.0 loss:0.0329 exploreP:0.0239\n",
      "Episode:2785 meanR:12.2400 R:11.0 loss:0.0213 exploreP:0.0239\n",
      "Episode:2786 meanR:12.2400 R:12.0 loss:0.0242 exploreP:0.0239\n",
      "Episode:2787 meanR:12.2200 R:12.0 loss:0.0243 exploreP:0.0239\n",
      "Episode:2788 meanR:12.1800 R:9.0 loss:0.0269 exploreP:0.0239\n",
      "Episode:2789 meanR:12.1200 R:9.0 loss:0.0256 exploreP:0.0239\n",
      "Episode:2790 meanR:12.0900 R:11.0 loss:0.0246 exploreP:0.0238\n",
      "Episode:2791 meanR:12.0900 R:14.0 loss:0.0278 exploreP:0.0238\n",
      "Episode:2792 meanR:12.0500 R:9.0 loss:0.0279 exploreP:0.0238\n",
      "Episode:2793 meanR:12.0700 R:11.0 loss:0.0290 exploreP:0.0238\n",
      "Episode:2794 meanR:12.0600 R:11.0 loss:0.0279 exploreP:0.0238\n",
      "Episode:2795 meanR:12.0400 R:17.0 loss:0.0281 exploreP:0.0238\n",
      "Episode:2796 meanR:12.0100 R:10.0 loss:0.0238 exploreP:0.0237\n",
      "Episode:2797 meanR:11.9900 R:11.0 loss:0.0244 exploreP:0.0237\n",
      "Episode:2798 meanR:11.9800 R:10.0 loss:0.0251 exploreP:0.0237\n",
      "Episode:2799 meanR:11.9900 R:12.0 loss:0.0246 exploreP:0.0237\n",
      "Episode:2800 meanR:11.9800 R:11.0 loss:0.0255 exploreP:0.0237\n",
      "Episode:2801 meanR:11.9900 R:14.0 loss:0.0260 exploreP:0.0237\n",
      "Episode:2802 meanR:11.9600 R:11.0 loss:0.0313 exploreP:0.0236\n",
      "Episode:2803 meanR:11.9800 R:12.0 loss:0.0273 exploreP:0.0236\n",
      "Episode:2804 meanR:12.0300 R:15.0 loss:0.0283 exploreP:0.0236\n",
      "Episode:2805 meanR:12.0100 R:13.0 loss:0.0265 exploreP:0.0236\n",
      "Episode:2806 meanR:12.0500 R:16.0 loss:0.0240 exploreP:0.0236\n",
      "Episode:2807 meanR:12.1200 R:17.0 loss:0.0279 exploreP:0.0236\n",
      "Episode:2808 meanR:12.1300 R:10.0 loss:0.0316 exploreP:0.0235\n",
      "Episode:2809 meanR:12.1000 R:10.0 loss:0.0222 exploreP:0.0235\n",
      "Episode:2810 meanR:12.1200 R:13.0 loss:0.0296 exploreP:0.0235\n",
      "Episode:2811 meanR:12.0800 R:10.0 loss:0.0284 exploreP:0.0235\n",
      "Episode:2812 meanR:12.0800 R:13.0 loss:0.0325 exploreP:0.0235\n",
      "Episode:2813 meanR:12.0600 R:10.0 loss:0.0271 exploreP:0.0235\n",
      "Episode:2814 meanR:12.0700 R:15.0 loss:0.0262 exploreP:0.0234\n",
      "Episode:2815 meanR:12.0200 R:10.0 loss:0.0285 exploreP:0.0234\n",
      "Episode:2816 meanR:12.0200 R:8.0 loss:0.0284 exploreP:0.0234\n",
      "Episode:2817 meanR:12.0600 R:13.0 loss:0.0247 exploreP:0.0234\n",
      "Episode:2818 meanR:12.0500 R:9.0 loss:0.0264 exploreP:0.0234\n",
      "Episode:2819 meanR:11.9900 R:9.0 loss:0.0273 exploreP:0.0234\n",
      "Episode:2820 meanR:12.0300 R:13.0 loss:0.0277 exploreP:0.0234\n",
      "Episode:2821 meanR:12.0600 R:15.0 loss:0.0277 exploreP:0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2822 meanR:12.1000 R:15.0 loss:0.0314 exploreP:0.0233\n",
      "Episode:2823 meanR:12.1000 R:10.0 loss:0.0229 exploreP:0.0233\n",
      "Episode:2824 meanR:12.0700 R:9.0 loss:0.0257 exploreP:0.0233\n",
      "Episode:2825 meanR:12.1300 R:16.0 loss:0.0283 exploreP:0.0233\n",
      "Episode:2826 meanR:12.0600 R:9.0 loss:0.0256 exploreP:0.0233\n",
      "Episode:2827 meanR:12.0600 R:10.0 loss:0.0330 exploreP:0.0232\n",
      "Episode:2828 meanR:12.0700 R:12.0 loss:0.0259 exploreP:0.0232\n",
      "Episode:2829 meanR:12.1500 R:16.0 loss:0.0265 exploreP:0.0232\n",
      "Episode:2830 meanR:12.1400 R:11.0 loss:0.0254 exploreP:0.0232\n",
      "Episode:2831 meanR:12.1600 R:16.0 loss:0.0284 exploreP:0.0232\n",
      "Episode:2832 meanR:12.1400 R:12.0 loss:0.0301 exploreP:0.0232\n",
      "Episode:2833 meanR:12.1600 R:13.0 loss:0.0308 exploreP:0.0231\n",
      "Episode:2834 meanR:12.1300 R:11.0 loss:0.0294 exploreP:0.0231\n",
      "Episode:2835 meanR:12.1000 R:9.0 loss:0.0192 exploreP:0.0231\n",
      "Episode:2836 meanR:12.0900 R:9.0 loss:0.0272 exploreP:0.0231\n",
      "Episode:2837 meanR:12.0200 R:9.0 loss:0.0281 exploreP:0.0231\n",
      "Episode:2838 meanR:12.0400 R:16.0 loss:0.0268 exploreP:0.0231\n",
      "Episode:2839 meanR:12.1000 R:15.0 loss:0.0269 exploreP:0.0231\n",
      "Episode:2840 meanR:12.1200 R:15.0 loss:0.0268 exploreP:0.0230\n",
      "Episode:2841 meanR:12.1300 R:15.0 loss:0.0298 exploreP:0.0230\n",
      "Episode:2842 meanR:12.1500 R:10.0 loss:0.0301 exploreP:0.0230\n",
      "Episode:2843 meanR:12.1600 R:15.0 loss:0.0286 exploreP:0.0230\n",
      "Episode:2844 meanR:12.1900 R:14.0 loss:0.0268 exploreP:0.0230\n",
      "Episode:2845 meanR:12.2500 R:14.0 loss:0.0324 exploreP:0.0229\n",
      "Episode:2846 meanR:12.2100 R:10.0 loss:0.0262 exploreP:0.0229\n",
      "Episode:2847 meanR:12.2100 R:15.0 loss:0.0260 exploreP:0.0229\n",
      "Episode:2848 meanR:12.2200 R:12.0 loss:0.0292 exploreP:0.0229\n",
      "Episode:2849 meanR:12.1500 R:9.0 loss:0.0266 exploreP:0.0229\n",
      "Episode:2850 meanR:12.1200 R:12.0 loss:0.0225 exploreP:0.0229\n",
      "Episode:2851 meanR:12.1800 R:15.0 loss:0.0255 exploreP:0.0228\n",
      "Episode:2852 meanR:12.1000 R:9.0 loss:0.0278 exploreP:0.0228\n",
      "Episode:2853 meanR:12.1400 R:15.0 loss:0.0253 exploreP:0.0228\n",
      "Episode:2854 meanR:12.0900 R:8.0 loss:0.0229 exploreP:0.0228\n",
      "Episode:2855 meanR:12.1200 R:12.0 loss:0.0204 exploreP:0.0228\n",
      "Episode:2856 meanR:12.0900 R:8.0 loss:0.0253 exploreP:0.0228\n",
      "Episode:2857 meanR:12.1000 R:13.0 loss:0.0295 exploreP:0.0228\n",
      "Episode:2858 meanR:12.0900 R:13.0 loss:0.0255 exploreP:0.0227\n",
      "Episode:2859 meanR:12.1400 R:16.0 loss:0.0256 exploreP:0.0227\n",
      "Episode:2860 meanR:12.1300 R:12.0 loss:0.0246 exploreP:0.0227\n",
      "Episode:2861 meanR:12.1400 R:15.0 loss:0.0288 exploreP:0.0227\n",
      "Episode:2862 meanR:12.1500 R:15.0 loss:0.0338 exploreP:0.0227\n",
      "Episode:2863 meanR:12.1800 R:16.0 loss:0.0300 exploreP:0.0227\n",
      "Episode:2864 meanR:12.2000 R:13.0 loss:0.0252 exploreP:0.0226\n",
      "Episode:2865 meanR:12.1900 R:15.0 loss:0.0297 exploreP:0.0226\n",
      "Episode:2866 meanR:12.2200 R:13.0 loss:0.0283 exploreP:0.0226\n",
      "Episode:2867 meanR:12.1900 R:12.0 loss:0.0299 exploreP:0.0226\n",
      "Episode:2868 meanR:12.1800 R:14.0 loss:0.0265 exploreP:0.0226\n",
      "Episode:2869 meanR:12.2200 R:16.0 loss:0.0251 exploreP:0.0225\n",
      "Episode:2870 meanR:12.2100 R:10.0 loss:0.0261 exploreP:0.0225\n",
      "Episode:2871 meanR:12.2100 R:12.0 loss:0.0239 exploreP:0.0225\n",
      "Episode:2872 meanR:12.2400 R:15.0 loss:0.0248 exploreP:0.0225\n",
      "Episode:2873 meanR:12.2700 R:13.0 loss:0.0273 exploreP:0.0225\n",
      "Episode:2874 meanR:12.2700 R:12.0 loss:0.0236 exploreP:0.0225\n",
      "Episode:2875 meanR:12.2400 R:11.0 loss:0.0278 exploreP:0.0225\n",
      "Episode:2876 meanR:12.2800 R:14.0 loss:0.0253 exploreP:0.0224\n",
      "Episode:2877 meanR:12.3000 R:14.0 loss:0.0256 exploreP:0.0224\n",
      "Episode:2878 meanR:12.3200 R:15.0 loss:0.0287 exploreP:0.0224\n",
      "Episode:2879 meanR:12.3600 R:14.0 loss:0.0247 exploreP:0.0224\n",
      "Episode:2880 meanR:12.3000 R:9.0 loss:0.0256 exploreP:0.0224\n",
      "Episode:2881 meanR:12.3300 R:15.0 loss:0.0219 exploreP:0.0224\n",
      "Episode:2882 meanR:12.3300 R:16.0 loss:0.0280 exploreP:0.0223\n",
      "Episode:2883 meanR:12.3500 R:11.0 loss:0.0362 exploreP:0.0223\n",
      "Episode:2884 meanR:12.4100 R:15.0 loss:0.0257 exploreP:0.0223\n",
      "Episode:2885 meanR:12.4400 R:14.0 loss:0.0277 exploreP:0.0223\n",
      "Episode:2886 meanR:12.4900 R:17.0 loss:0.0317 exploreP:0.0223\n",
      "Episode:2887 meanR:12.4700 R:10.0 loss:0.0274 exploreP:0.0223\n",
      "Episode:2888 meanR:12.4800 R:10.0 loss:0.0234 exploreP:0.0222\n",
      "Episode:2889 meanR:12.4900 R:10.0 loss:0.0286 exploreP:0.0222\n",
      "Episode:2890 meanR:12.5200 R:14.0 loss:0.0317 exploreP:0.0222\n",
      "Episode:2891 meanR:12.5200 R:14.0 loss:0.0250 exploreP:0.0222\n",
      "Episode:2892 meanR:12.5400 R:11.0 loss:0.0261 exploreP:0.0222\n",
      "Episode:2893 meanR:12.5900 R:16.0 loss:0.0252 exploreP:0.0222\n",
      "Episode:2894 meanR:12.6000 R:12.0 loss:0.0246 exploreP:0.0221\n",
      "Episode:2895 meanR:12.5700 R:14.0 loss:0.0257 exploreP:0.0221\n",
      "Episode:2896 meanR:12.5900 R:12.0 loss:0.0290 exploreP:0.0221\n",
      "Episode:2897 meanR:12.6000 R:12.0 loss:0.0315 exploreP:0.0221\n",
      "Episode:2898 meanR:12.6200 R:12.0 loss:0.0286 exploreP:0.0221\n",
      "Episode:2899 meanR:12.6100 R:11.0 loss:0.0288 exploreP:0.0221\n",
      "Episode:2900 meanR:12.6500 R:15.0 loss:0.0257 exploreP:0.0221\n",
      "Episode:2901 meanR:12.6300 R:12.0 loss:0.0257 exploreP:0.0220\n",
      "Episode:2902 meanR:12.6700 R:15.0 loss:0.0261 exploreP:0.0220\n",
      "Episode:2903 meanR:12.7000 R:15.0 loss:0.0279 exploreP:0.0220\n",
      "Episode:2904 meanR:12.6800 R:13.0 loss:0.0254 exploreP:0.0220\n",
      "Episode:2905 meanR:12.6900 R:14.0 loss:0.0307 exploreP:0.0220\n",
      "Episode:2906 meanR:12.6900 R:16.0 loss:0.0273 exploreP:0.0220\n",
      "Episode:2907 meanR:12.6600 R:14.0 loss:0.0339 exploreP:0.0219\n",
      "Episode:2908 meanR:12.7100 R:15.0 loss:0.0279 exploreP:0.0219\n",
      "Episode:2909 meanR:12.7300 R:12.0 loss:0.0311 exploreP:0.0219\n",
      "Episode:2910 meanR:12.7200 R:12.0 loss:0.0281 exploreP:0.0219\n",
      "Episode:2911 meanR:12.7500 R:13.0 loss:0.0307 exploreP:0.0219\n",
      "Episode:2912 meanR:12.7500 R:13.0 loss:0.0282 exploreP:0.0219\n",
      "Episode:2913 meanR:12.7600 R:11.0 loss:0.0235 exploreP:0.0218\n",
      "Episode:2914 meanR:12.7100 R:10.0 loss:0.0233 exploreP:0.0218\n",
      "Episode:2915 meanR:12.7700 R:16.0 loss:0.0209 exploreP:0.0218\n",
      "Episode:2916 meanR:12.7900 R:10.0 loss:0.0241 exploreP:0.0218\n",
      "Episode:2917 meanR:12.8300 R:17.0 loss:0.0206 exploreP:0.0218\n",
      "Episode:2918 meanR:12.8300 R:9.0 loss:0.0365 exploreP:0.0218\n",
      "Episode:2919 meanR:12.8500 R:11.0 loss:0.0291 exploreP:0.0218\n",
      "Episode:2920 meanR:12.8400 R:12.0 loss:0.0285 exploreP:0.0217\n",
      "Episode:2921 meanR:12.8500 R:16.0 loss:0.0309 exploreP:0.0217\n",
      "Episode:2922 meanR:12.7900 R:9.0 loss:0.0299 exploreP:0.0217\n",
      "Episode:2923 meanR:12.8100 R:12.0 loss:0.0359 exploreP:0.0217\n",
      "Episode:2924 meanR:12.8800 R:16.0 loss:0.0259 exploreP:0.0217\n",
      "Episode:2925 meanR:12.8400 R:12.0 loss:0.0302 exploreP:0.0217\n",
      "Episode:2926 meanR:12.8900 R:14.0 loss:0.0251 exploreP:0.0217\n",
      "Episode:2927 meanR:12.9300 R:14.0 loss:0.0287 exploreP:0.0216\n",
      "Episode:2928 meanR:12.9600 R:15.0 loss:0.0271 exploreP:0.0216\n",
      "Episode:2929 meanR:12.9100 R:11.0 loss:0.0277 exploreP:0.0216\n",
      "Episode:2930 meanR:12.9600 R:16.0 loss:0.0228 exploreP:0.0216\n",
      "Episode:2931 meanR:12.9400 R:14.0 loss:0.0266 exploreP:0.0216\n",
      "Episode:2932 meanR:12.9500 R:13.0 loss:0.0225 exploreP:0.0216\n",
      "Episode:2933 meanR:12.9300 R:11.0 loss:0.0231 exploreP:0.0215\n",
      "Episode:2934 meanR:12.9800 R:16.0 loss:0.0237 exploreP:0.0215\n",
      "Episode:2935 meanR:13.0100 R:12.0 loss:0.0241 exploreP:0.0215\n",
      "Episode:2936 meanR:13.0400 R:12.0 loss:0.0223 exploreP:0.0215\n",
      "Episode:2937 meanR:13.0900 R:14.0 loss:0.0257 exploreP:0.0215\n",
      "Episode:2938 meanR:13.0200 R:9.0 loss:0.0239 exploreP:0.0215\n",
      "Episode:2939 meanR:12.9600 R:9.0 loss:0.0266 exploreP:0.0215\n",
      "Episode:2940 meanR:12.9000 R:9.0 loss:0.0238 exploreP:0.0215\n",
      "Episode:2941 meanR:12.8900 R:14.0 loss:0.0308 exploreP:0.0214\n",
      "Episode:2942 meanR:12.9400 R:15.0 loss:0.0260 exploreP:0.0214\n",
      "Episode:2943 meanR:12.9500 R:16.0 loss:0.0303 exploreP:0.0214\n",
      "Episode:2944 meanR:12.9600 R:15.0 loss:0.0243 exploreP:0.0214\n",
      "Episode:2945 meanR:12.9100 R:9.0 loss:0.0250 exploreP:0.0214\n",
      "Episode:2946 meanR:12.9200 R:11.0 loss:0.0282 exploreP:0.0214\n",
      "Episode:2947 meanR:12.9300 R:16.0 loss:0.0300 exploreP:0.0213\n",
      "Episode:2948 meanR:12.9600 R:15.0 loss:0.0261 exploreP:0.0213\n",
      "Episode:2949 meanR:13.0200 R:15.0 loss:0.0268 exploreP:0.0213\n",
      "Episode:2950 meanR:13.0600 R:16.0 loss:0.0278 exploreP:0.0213\n",
      "Episode:2951 meanR:13.0500 R:14.0 loss:0.0243 exploreP:0.0213\n",
      "Episode:2952 meanR:13.1200 R:16.0 loss:0.0232 exploreP:0.0213\n",
      "Episode:2953 meanR:13.0700 R:10.0 loss:0.0283 exploreP:0.0212\n",
      "Episode:2954 meanR:13.1200 R:13.0 loss:0.0290 exploreP:0.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2955 meanR:13.1400 R:14.0 loss:0.0318 exploreP:0.0212\n",
      "Episode:2956 meanR:13.1900 R:13.0 loss:0.0259 exploreP:0.0212\n",
      "Episode:2957 meanR:13.2100 R:15.0 loss:0.0279 exploreP:0.0212\n",
      "Episode:2958 meanR:13.2200 R:14.0 loss:0.0274 exploreP:0.0212\n",
      "Episode:2959 meanR:13.1600 R:10.0 loss:0.0277 exploreP:0.0212\n",
      "Episode:2960 meanR:13.1500 R:11.0 loss:0.0236 exploreP:0.0211\n",
      "Episode:2961 meanR:13.1500 R:15.0 loss:0.0226 exploreP:0.0211\n",
      "Episode:2962 meanR:13.1200 R:12.0 loss:0.0241 exploreP:0.0211\n",
      "Episode:2963 meanR:13.0700 R:11.0 loss:0.0250 exploreP:0.0211\n",
      "Episode:2964 meanR:13.0800 R:14.0 loss:0.0255 exploreP:0.0211\n",
      "Episode:2965 meanR:13.0500 R:12.0 loss:0.0241 exploreP:0.0211\n",
      "Episode:2966 meanR:13.0200 R:10.0 loss:0.0355 exploreP:0.0211\n",
      "Episode:2967 meanR:13.0300 R:13.0 loss:0.0285 exploreP:0.0210\n",
      "Episode:2968 meanR:12.9900 R:10.0 loss:0.0289 exploreP:0.0210\n",
      "Episode:2969 meanR:12.9400 R:11.0 loss:0.0253 exploreP:0.0210\n",
      "Episode:2970 meanR:12.9900 R:15.0 loss:0.0233 exploreP:0.0210\n",
      "Episode:2971 meanR:13.0200 R:15.0 loss:0.0302 exploreP:0.0210\n",
      "Episode:2972 meanR:13.0100 R:14.0 loss:0.0302 exploreP:0.0210\n",
      "Episode:2973 meanR:13.0000 R:12.0 loss:0.0232 exploreP:0.0210\n",
      "Episode:2974 meanR:12.9700 R:9.0 loss:0.0275 exploreP:0.0210\n",
      "Episode:2975 meanR:12.9600 R:10.0 loss:0.0207 exploreP:0.0209\n",
      "Episode:2976 meanR:12.9100 R:9.0 loss:0.0320 exploreP:0.0209\n",
      "Episode:2977 meanR:12.8900 R:12.0 loss:0.0237 exploreP:0.0209\n",
      "Episode:2978 meanR:12.8300 R:9.0 loss:0.0254 exploreP:0.0209\n",
      "Episode:2979 meanR:12.8300 R:14.0 loss:0.0255 exploreP:0.0209\n",
      "Episode:2980 meanR:12.8600 R:12.0 loss:0.0299 exploreP:0.0209\n",
      "Episode:2981 meanR:12.8500 R:14.0 loss:0.0240 exploreP:0.0209\n",
      "Episode:2982 meanR:12.7900 R:10.0 loss:0.0263 exploreP:0.0209\n",
      "Episode:2983 meanR:12.8000 R:12.0 loss:0.0281 exploreP:0.0208\n",
      "Episode:2984 meanR:12.8100 R:16.0 loss:0.0322 exploreP:0.0208\n",
      "Episode:2985 meanR:12.8100 R:14.0 loss:0.0283 exploreP:0.0208\n",
      "Episode:2986 meanR:12.7900 R:15.0 loss:0.0261 exploreP:0.0208\n",
      "Episode:2987 meanR:12.7900 R:10.0 loss:0.0313 exploreP:0.0208\n",
      "Episode:2988 meanR:12.8300 R:14.0 loss:0.0230 exploreP:0.0208\n",
      "Episode:2989 meanR:12.8400 R:11.0 loss:0.0264 exploreP:0.0208\n",
      "Episode:2990 meanR:12.8400 R:14.0 loss:0.0302 exploreP:0.0207\n",
      "Episode:2991 meanR:12.8600 R:16.0 loss:0.0306 exploreP:0.0207\n",
      "Episode:2992 meanR:12.9100 R:16.0 loss:0.0272 exploreP:0.0207\n",
      "Episode:2993 meanR:12.8400 R:9.0 loss:0.0316 exploreP:0.0207\n",
      "Episode:2994 meanR:12.8300 R:11.0 loss:0.0270 exploreP:0.0207\n",
      "Episode:2995 meanR:12.8000 R:11.0 loss:0.0277 exploreP:0.0207\n",
      "Episode:2996 meanR:12.8000 R:12.0 loss:0.0275 exploreP:0.0207\n",
      "Episode:2997 meanR:12.8100 R:13.0 loss:0.0308 exploreP:0.0206\n",
      "Episode:2998 meanR:12.8100 R:12.0 loss:0.0295 exploreP:0.0206\n",
      "Episode:2999 meanR:12.8600 R:16.0 loss:0.0294 exploreP:0.0206\n",
      "Episode:3000 meanR:12.8700 R:16.0 loss:0.0254 exploreP:0.0206\n",
      "Episode:3001 meanR:12.9000 R:15.0 loss:0.0264 exploreP:0.0206\n",
      "Episode:3002 meanR:12.8900 R:14.0 loss:0.0306 exploreP:0.0206\n",
      "Episode:3003 meanR:12.8600 R:12.0 loss:0.0250 exploreP:0.0206\n",
      "Episode:3004 meanR:12.8500 R:12.0 loss:0.0299 exploreP:0.0205\n",
      "Episode:3005 meanR:12.8500 R:14.0 loss:0.0241 exploreP:0.0205\n",
      "Episode:3006 meanR:12.8500 R:16.0 loss:0.0326 exploreP:0.0205\n",
      "Episode:3007 meanR:12.8200 R:11.0 loss:0.0202 exploreP:0.0205\n",
      "Episode:3008 meanR:12.7900 R:12.0 loss:0.0240 exploreP:0.0205\n",
      "Episode:3009 meanR:12.7800 R:11.0 loss:0.0266 exploreP:0.0205\n",
      "Episode:3010 meanR:12.7700 R:11.0 loss:0.0242 exploreP:0.0205\n",
      "Episode:3011 meanR:12.7600 R:12.0 loss:0.0275 exploreP:0.0205\n",
      "Episode:3012 meanR:12.7700 R:14.0 loss:0.0221 exploreP:0.0204\n",
      "Episode:3013 meanR:12.7900 R:13.0 loss:0.0261 exploreP:0.0204\n",
      "Episode:3014 meanR:12.8400 R:15.0 loss:0.0305 exploreP:0.0204\n",
      "Episode:3015 meanR:12.8000 R:12.0 loss:0.0264 exploreP:0.0204\n",
      "Episode:3016 meanR:12.8200 R:12.0 loss:0.0238 exploreP:0.0204\n",
      "Episode:3017 meanR:12.7300 R:8.0 loss:0.0375 exploreP:0.0204\n",
      "Episode:3018 meanR:12.7900 R:15.0 loss:0.0297 exploreP:0.0204\n",
      "Episode:3019 meanR:12.8400 R:16.0 loss:0.0262 exploreP:0.0203\n",
      "Episode:3020 meanR:12.8700 R:15.0 loss:0.0245 exploreP:0.0203\n",
      "Episode:3021 meanR:12.8000 R:9.0 loss:0.0295 exploreP:0.0203\n",
      "Episode:3022 meanR:12.8100 R:10.0 loss:0.0225 exploreP:0.0203\n",
      "Episode:3023 meanR:12.8400 R:15.0 loss:0.0262 exploreP:0.0203\n",
      "Episode:3024 meanR:12.7900 R:11.0 loss:0.0262 exploreP:0.0203\n",
      "Episode:3025 meanR:12.8100 R:14.0 loss:0.0280 exploreP:0.0203\n",
      "Episode:3026 meanR:12.7900 R:12.0 loss:0.0253 exploreP:0.0203\n",
      "Episode:3027 meanR:12.7500 R:10.0 loss:0.0219 exploreP:0.0202\n",
      "Episode:3028 meanR:12.7500 R:15.0 loss:0.0267 exploreP:0.0202\n",
      "Episode:3029 meanR:12.7500 R:11.0 loss:0.0249 exploreP:0.0202\n",
      "Episode:3030 meanR:12.7500 R:16.0 loss:0.0225 exploreP:0.0202\n",
      "Episode:3031 meanR:12.7200 R:11.0 loss:0.0282 exploreP:0.0202\n",
      "Episode:3032 meanR:12.7500 R:16.0 loss:0.0285 exploreP:0.0202\n",
      "Episode:3033 meanR:12.7600 R:12.0 loss:0.0232 exploreP:0.0202\n",
      "Episode:3034 meanR:12.6900 R:9.0 loss:0.0246 exploreP:0.0202\n",
      "Episode:3035 meanR:12.7200 R:15.0 loss:0.0243 exploreP:0.0201\n",
      "Episode:3036 meanR:12.7300 R:13.0 loss:0.0236 exploreP:0.0201\n",
      "Episode:3037 meanR:12.7100 R:12.0 loss:0.0232 exploreP:0.0201\n",
      "Episode:3038 meanR:12.7500 R:13.0 loss:0.0252 exploreP:0.0201\n",
      "Episode:3039 meanR:12.7700 R:11.0 loss:0.0242 exploreP:0.0201\n",
      "Episode:3040 meanR:12.7900 R:11.0 loss:0.0293 exploreP:0.0201\n",
      "Episode:3041 meanR:12.7900 R:14.0 loss:0.0242 exploreP:0.0201\n",
      "Episode:3042 meanR:12.7600 R:12.0 loss:0.0246 exploreP:0.0201\n",
      "Episode:3043 meanR:12.7400 R:14.0 loss:0.0259 exploreP:0.0200\n",
      "Episode:3044 meanR:12.7200 R:13.0 loss:0.0282 exploreP:0.0200\n",
      "Episode:3045 meanR:12.7600 R:13.0 loss:0.0289 exploreP:0.0200\n",
      "Episode:3046 meanR:12.7300 R:8.0 loss:0.0258 exploreP:0.0200\n",
      "Episode:3047 meanR:12.6800 R:11.0 loss:0.0229 exploreP:0.0200\n",
      "Episode:3048 meanR:12.6600 R:13.0 loss:0.0263 exploreP:0.0200\n",
      "Episode:3049 meanR:12.6500 R:14.0 loss:0.0305 exploreP:0.0200\n",
      "Episode:3050 meanR:12.6500 R:16.0 loss:0.0281 exploreP:0.0200\n",
      "Episode:3051 meanR:12.6700 R:16.0 loss:0.0270 exploreP:0.0199\n",
      "Episode:3052 meanR:12.6400 R:13.0 loss:0.0308 exploreP:0.0199\n",
      "Episode:3053 meanR:12.6700 R:13.0 loss:0.0278 exploreP:0.0199\n",
      "Episode:3054 meanR:12.6400 R:10.0 loss:0.0257 exploreP:0.0199\n",
      "Episode:3055 meanR:12.6400 R:14.0 loss:0.0316 exploreP:0.0199\n",
      "Episode:3056 meanR:12.6700 R:16.0 loss:0.0254 exploreP:0.0199\n",
      "Episode:3057 meanR:12.6800 R:16.0 loss:0.0232 exploreP:0.0199\n",
      "Episode:3058 meanR:12.6500 R:11.0 loss:0.0254 exploreP:0.0198\n",
      "Episode:3059 meanR:12.6800 R:13.0 loss:0.0257 exploreP:0.0198\n",
      "Episode:3060 meanR:12.7100 R:14.0 loss:0.0329 exploreP:0.0198\n",
      "Episode:3061 meanR:12.7000 R:14.0 loss:0.0282 exploreP:0.0198\n",
      "Episode:3062 meanR:12.7400 R:16.0 loss:0.0253 exploreP:0.0198\n",
      "Episode:3063 meanR:12.7700 R:14.0 loss:0.0297 exploreP:0.0198\n",
      "Episode:3064 meanR:12.7600 R:13.0 loss:0.0247 exploreP:0.0198\n",
      "Episode:3065 meanR:12.7500 R:11.0 loss:0.0277 exploreP:0.0197\n",
      "Episode:3066 meanR:12.7800 R:13.0 loss:0.0272 exploreP:0.0197\n",
      "Episode:3067 meanR:12.7800 R:13.0 loss:0.0216 exploreP:0.0197\n",
      "Episode:3068 meanR:12.7800 R:10.0 loss:0.0352 exploreP:0.0197\n",
      "Episode:3069 meanR:12.8100 R:14.0 loss:0.0258 exploreP:0.0197\n",
      "Episode:3070 meanR:12.8200 R:16.0 loss:0.0284 exploreP:0.0197\n",
      "Episode:3071 meanR:12.7600 R:9.0 loss:0.0214 exploreP:0.0197\n",
      "Episode:3072 meanR:12.7400 R:12.0 loss:0.0281 exploreP:0.0197\n",
      "Episode:3073 meanR:12.7300 R:11.0 loss:0.0286 exploreP:0.0197\n",
      "Episode:3074 meanR:12.7800 R:14.0 loss:0.0321 exploreP:0.0196\n",
      "Episode:3075 meanR:12.8200 R:14.0 loss:0.0261 exploreP:0.0196\n",
      "Episode:3076 meanR:12.8300 R:10.0 loss:0.0226 exploreP:0.0196\n",
      "Episode:3077 meanR:12.8200 R:11.0 loss:0.0254 exploreP:0.0196\n",
      "Episode:3078 meanR:12.8800 R:15.0 loss:0.0272 exploreP:0.0196\n",
      "Episode:3079 meanR:12.8900 R:15.0 loss:0.0283 exploreP:0.0196\n",
      "Episode:3080 meanR:12.9200 R:15.0 loss:0.0240 exploreP:0.0196\n",
      "Episode:3081 meanR:12.9100 R:13.0 loss:0.0306 exploreP:0.0196\n",
      "Episode:3082 meanR:12.9500 R:14.0 loss:0.0241 exploreP:0.0195\n",
      "Episode:3083 meanR:12.9600 R:13.0 loss:0.0257 exploreP:0.0195\n",
      "Episode:3084 meanR:12.9200 R:12.0 loss:0.0297 exploreP:0.0195\n",
      "Episode:3085 meanR:12.9000 R:12.0 loss:0.0253 exploreP:0.0195\n",
      "Episode:3086 meanR:12.9000 R:15.0 loss:0.0243 exploreP:0.0195\n",
      "Episode:3087 meanR:12.9200 R:12.0 loss:0.0285 exploreP:0.0195\n",
      "Episode:3088 meanR:12.9400 R:16.0 loss:0.0270 exploreP:0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:3089 meanR:12.9200 R:9.0 loss:0.0272 exploreP:0.0195\n",
      "Episode:3090 meanR:12.9400 R:16.0 loss:0.0204 exploreP:0.0194\n",
      "Episode:3091 meanR:12.9300 R:15.0 loss:0.0234 exploreP:0.0194\n",
      "Episode:3092 meanR:12.9000 R:13.0 loss:0.0272 exploreP:0.0194\n",
      "Episode:3093 meanR:12.9700 R:16.0 loss:0.0261 exploreP:0.0194\n",
      "Episode:3094 meanR:13.0000 R:14.0 loss:0.0310 exploreP:0.0194\n",
      "Episode:3095 meanR:13.0400 R:15.0 loss:0.0264 exploreP:0.0194\n",
      "Episode:3096 meanR:13.0600 R:14.0 loss:0.0285 exploreP:0.0194\n",
      "Episode:3097 meanR:13.0700 R:14.0 loss:0.0285 exploreP:0.0193\n",
      "Episode:3098 meanR:13.1100 R:16.0 loss:0.0268 exploreP:0.0193\n",
      "Episode:3099 meanR:13.0600 R:11.0 loss:0.0217 exploreP:0.0193\n",
      "Episode:3100 meanR:13.0600 R:16.0 loss:0.0289 exploreP:0.0193\n",
      "Episode:3101 meanR:13.0300 R:12.0 loss:0.0242 exploreP:0.0193\n",
      "Episode:3102 meanR:13.0600 R:17.0 loss:0.0272 exploreP:0.0193\n",
      "Episode:3103 meanR:13.0900 R:15.0 loss:0.0243 exploreP:0.0193\n",
      "Episode:3104 meanR:13.1000 R:13.0 loss:0.0237 exploreP:0.0193\n",
      "Episode:3105 meanR:13.1200 R:16.0 loss:0.0259 exploreP:0.0192\n",
      "Episode:3106 meanR:13.0800 R:12.0 loss:0.0228 exploreP:0.0192\n",
      "Episode:3107 meanR:13.0800 R:11.0 loss:0.0259 exploreP:0.0192\n",
      "Episode:3108 meanR:13.0800 R:12.0 loss:0.0271 exploreP:0.0192\n",
      "Episode:3109 meanR:13.0800 R:11.0 loss:0.0204 exploreP:0.0192\n",
      "Episode:3110 meanR:13.1200 R:15.0 loss:0.0271 exploreP:0.0192\n",
      "Episode:3111 meanR:13.1000 R:10.0 loss:0.0294 exploreP:0.0192\n",
      "Episode:3112 meanR:13.0500 R:9.0 loss:0.0271 exploreP:0.0192\n",
      "Episode:3113 meanR:13.0600 R:14.0 loss:0.0245 exploreP:0.0191\n",
      "Episode:3114 meanR:13.0600 R:15.0 loss:0.0257 exploreP:0.0191\n",
      "Episode:3115 meanR:13.0400 R:10.0 loss:0.0302 exploreP:0.0191\n",
      "Episode:3116 meanR:13.0300 R:11.0 loss:0.0239 exploreP:0.0191\n",
      "Episode:3117 meanR:13.0500 R:10.0 loss:0.0289 exploreP:0.0191\n",
      "Episode:3118 meanR:13.0000 R:10.0 loss:0.0233 exploreP:0.0191\n",
      "Episode:3119 meanR:12.9300 R:9.0 loss:0.0259 exploreP:0.0191\n",
      "Episode:3120 meanR:12.8900 R:11.0 loss:0.0268 exploreP:0.0191\n",
      "Episode:3121 meanR:12.9100 R:11.0 loss:0.0214 exploreP:0.0191\n",
      "Episode:3122 meanR:12.9500 R:14.0 loss:0.0276 exploreP:0.0191\n",
      "Episode:3123 meanR:12.9400 R:14.0 loss:0.0280 exploreP:0.0190\n",
      "Episode:3124 meanR:13.0000 R:17.0 loss:0.0269 exploreP:0.0190\n",
      "Episode:3125 meanR:12.9800 R:12.0 loss:0.0271 exploreP:0.0190\n",
      "Episode:3126 meanR:12.9700 R:11.0 loss:0.0263 exploreP:0.0190\n",
      "Episode:3127 meanR:13.0200 R:15.0 loss:0.0253 exploreP:0.0190\n",
      "Episode:3128 meanR:13.0100 R:14.0 loss:0.0281 exploreP:0.0190\n",
      "Episode:3129 meanR:13.0300 R:13.0 loss:0.0232 exploreP:0.0190\n",
      "Episode:3130 meanR:13.0100 R:14.0 loss:0.0310 exploreP:0.0190\n",
      "Episode:3131 meanR:13.0500 R:15.0 loss:0.0297 exploreP:0.0189\n",
      "Episode:3132 meanR:13.0600 R:17.0 loss:0.0264 exploreP:0.0189\n",
      "Episode:3133 meanR:13.0700 R:13.0 loss:0.0277 exploreP:0.0189\n",
      "Episode:3134 meanR:13.1400 R:16.0 loss:0.0236 exploreP:0.0189\n",
      "Episode:3135 meanR:13.0800 R:9.0 loss:0.0328 exploreP:0.0189\n",
      "Episode:3136 meanR:13.1000 R:15.0 loss:0.0247 exploreP:0.0189\n",
      "Episode:3137 meanR:13.0900 R:11.0 loss:0.0289 exploreP:0.0189\n",
      "Episode:3138 meanR:13.1200 R:16.0 loss:0.0252 exploreP:0.0189\n",
      "Episode:3139 meanR:13.1700 R:16.0 loss:0.0227 exploreP:0.0188\n",
      "Episode:3140 meanR:13.1600 R:10.0 loss:0.0235 exploreP:0.0188\n",
      "Episode:3141 meanR:13.1600 R:14.0 loss:0.0286 exploreP:0.0188\n",
      "Episode:3142 meanR:13.2000 R:16.0 loss:0.0257 exploreP:0.0188\n",
      "Episode:3143 meanR:13.1900 R:13.0 loss:0.0256 exploreP:0.0188\n",
      "Episode:3144 meanR:13.1900 R:13.0 loss:0.0249 exploreP:0.0188\n",
      "Episode:3145 meanR:13.1900 R:13.0 loss:0.0255 exploreP:0.0188\n",
      "Episode:3146 meanR:13.2700 R:16.0 loss:0.0242 exploreP:0.0188\n",
      "Episode:3147 meanR:13.3000 R:14.0 loss:0.0287 exploreP:0.0187\n",
      "Episode:3148 meanR:13.2900 R:12.0 loss:0.0220 exploreP:0.0187\n",
      "Episode:3149 meanR:13.3000 R:15.0 loss:0.0232 exploreP:0.0187\n",
      "Episode:3150 meanR:13.2600 R:12.0 loss:0.0243 exploreP:0.0187\n",
      "Episode:3151 meanR:13.1900 R:9.0 loss:0.0246 exploreP:0.0187\n",
      "Episode:3152 meanR:13.1800 R:12.0 loss:0.0305 exploreP:0.0187\n",
      "Episode:3153 meanR:13.1600 R:11.0 loss:0.0217 exploreP:0.0187\n",
      "Episode:3154 meanR:13.2000 R:14.0 loss:0.0224 exploreP:0.0187\n",
      "Episode:3155 meanR:13.2200 R:16.0 loss:0.0265 exploreP:0.0187\n",
      "Episode:3156 meanR:13.2100 R:15.0 loss:0.0215 exploreP:0.0186\n",
      "Episode:3157 meanR:13.1900 R:14.0 loss:0.0267 exploreP:0.0186\n",
      "Episode:3158 meanR:13.1900 R:11.0 loss:0.0270 exploreP:0.0186\n",
      "Episode:3159 meanR:13.1800 R:12.0 loss:0.0205 exploreP:0.0186\n",
      "Episode:3160 meanR:13.1800 R:14.0 loss:0.0270 exploreP:0.0186\n",
      "Episode:3161 meanR:13.2000 R:16.0 loss:0.0265 exploreP:0.0186\n",
      "Episode:3162 meanR:13.1600 R:12.0 loss:0.0276 exploreP:0.0186\n",
      "Episode:3163 meanR:13.1900 R:17.0 loss:0.0231 exploreP:0.0186\n",
      "Episode:3164 meanR:13.2100 R:15.0 loss:0.0271 exploreP:0.0186\n",
      "Episode:3165 meanR:13.2400 R:14.0 loss:0.0286 exploreP:0.0185\n",
      "Episode:3166 meanR:13.2500 R:14.0 loss:0.0274 exploreP:0.0185\n",
      "Episode:3167 meanR:13.2300 R:11.0 loss:0.0261 exploreP:0.0185\n",
      "Episode:3168 meanR:13.2800 R:15.0 loss:0.0257 exploreP:0.0185\n",
      "Episode:3169 meanR:13.2600 R:12.0 loss:0.0247 exploreP:0.0185\n",
      "Episode:3170 meanR:13.2100 R:11.0 loss:0.0251 exploreP:0.0185\n",
      "Episode:3171 meanR:13.2200 R:10.0 loss:0.0240 exploreP:0.0185\n",
      "Episode:3172 meanR:13.2600 R:16.0 loss:0.0247 exploreP:0.0185\n",
      "Episode:3173 meanR:13.2900 R:14.0 loss:0.0286 exploreP:0.0185\n",
      "Episode:3174 meanR:13.2600 R:11.0 loss:0.0289 exploreP:0.0184\n",
      "Episode:3175 meanR:13.2500 R:13.0 loss:0.0260 exploreP:0.0184\n",
      "Episode:3176 meanR:13.2800 R:13.0 loss:0.0233 exploreP:0.0184\n",
      "Episode:3177 meanR:13.3000 R:13.0 loss:0.0235 exploreP:0.0184\n",
      "Episode:3178 meanR:13.3100 R:16.0 loss:0.0255 exploreP:0.0184\n",
      "Episode:3179 meanR:13.2800 R:12.0 loss:0.0216 exploreP:0.0184\n",
      "Episode:3180 meanR:13.2500 R:12.0 loss:0.0211 exploreP:0.0184\n",
      "Episode:3181 meanR:13.2500 R:13.0 loss:0.0241 exploreP:0.0184\n",
      "Episode:3182 meanR:13.2500 R:14.0 loss:0.0217 exploreP:0.0184\n",
      "Episode:3183 meanR:13.2500 R:13.0 loss:0.0241 exploreP:0.0183\n",
      "Episode:3184 meanR:13.2800 R:15.0 loss:0.0234 exploreP:0.0183\n",
      "Episode:3185 meanR:13.2800 R:12.0 loss:0.0287 exploreP:0.0183\n",
      "Episode:3186 meanR:13.2800 R:15.0 loss:0.0239 exploreP:0.0183\n",
      "Episode:3187 meanR:13.2800 R:12.0 loss:0.0259 exploreP:0.0183\n",
      "Episode:3188 meanR:13.2700 R:15.0 loss:0.0252 exploreP:0.0183\n",
      "Episode:3189 meanR:13.3100 R:13.0 loss:0.0230 exploreP:0.0183\n",
      "Episode:3190 meanR:13.2600 R:11.0 loss:0.0224 exploreP:0.0183\n",
      "Episode:3191 meanR:13.2300 R:12.0 loss:0.0257 exploreP:0.0183\n",
      "Episode:3192 meanR:13.2100 R:11.0 loss:0.0270 exploreP:0.0182\n",
      "Episode:3193 meanR:13.2100 R:16.0 loss:0.0203 exploreP:0.0182\n",
      "Episode:3194 meanR:13.1900 R:12.0 loss:0.0203 exploreP:0.0182\n",
      "Episode:3195 meanR:13.1900 R:15.0 loss:0.0235 exploreP:0.0182\n",
      "Episode:3196 meanR:13.1600 R:11.0 loss:0.0257 exploreP:0.0182\n",
      "Episode:3197 meanR:13.1400 R:12.0 loss:0.0235 exploreP:0.0182\n",
      "Episode:3198 meanR:13.0900 R:11.0 loss:0.0279 exploreP:0.0182\n",
      "Episode:3199 meanR:13.1400 R:16.0 loss:0.0236 exploreP:0.0182\n",
      "Episode:3200 meanR:13.1100 R:13.0 loss:0.0283 exploreP:0.0182\n",
      "Episode:3201 meanR:13.1300 R:14.0 loss:0.0264 exploreP:0.0181\n",
      "Episode:3202 meanR:13.0700 R:11.0 loss:0.0205 exploreP:0.0181\n",
      "Episode:3203 meanR:13.0400 R:12.0 loss:0.0197 exploreP:0.0181\n",
      "Episode:3204 meanR:13.0500 R:14.0 loss:0.0209 exploreP:0.0181\n",
      "Episode:3205 meanR:13.0400 R:15.0 loss:0.0315 exploreP:0.0181\n",
      "Episode:3206 meanR:13.0200 R:10.0 loss:0.0236 exploreP:0.0181\n",
      "Episode:3207 meanR:13.0200 R:11.0 loss:0.0269 exploreP:0.0181\n",
      "Episode:3208 meanR:13.0000 R:10.0 loss:0.0227 exploreP:0.0181\n",
      "Episode:3209 meanR:12.9800 R:9.0 loss:0.0251 exploreP:0.0181\n",
      "Episode:3210 meanR:12.9200 R:9.0 loss:0.0259 exploreP:0.0181\n",
      "Episode:3211 meanR:12.9300 R:11.0 loss:0.0285 exploreP:0.0181\n",
      "Episode:3212 meanR:12.9500 R:11.0 loss:0.0206 exploreP:0.0180\n",
      "Episode:3213 meanR:12.9200 R:11.0 loss:0.0192 exploreP:0.0180\n",
      "Episode:3214 meanR:12.8700 R:10.0 loss:0.0238 exploreP:0.0180\n",
      "Episode:3215 meanR:12.9100 R:14.0 loss:0.0251 exploreP:0.0180\n",
      "Episode:3216 meanR:12.9000 R:10.0 loss:0.0234 exploreP:0.0180\n",
      "Episode:3217 meanR:12.9400 R:14.0 loss:0.0233 exploreP:0.0180\n",
      "Episode:3218 meanR:12.9800 R:14.0 loss:0.0221 exploreP:0.0180\n",
      "Episode:3219 meanR:13.0200 R:13.0 loss:0.0218 exploreP:0.0180\n",
      "Episode:3220 meanR:13.0300 R:12.0 loss:0.0232 exploreP:0.0180\n",
      "Episode:3221 meanR:13.0500 R:13.0 loss:0.0218 exploreP:0.0180\n",
      "Episode:3222 meanR:13.0700 R:16.0 loss:0.0216 exploreP:0.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:3223 meanR:13.0500 R:12.0 loss:0.0303 exploreP:0.0179\n",
      "Episode:3224 meanR:13.0200 R:14.0 loss:0.0277 exploreP:0.0179\n",
      "Episode:3225 meanR:13.0200 R:12.0 loss:0.0203 exploreP:0.0179\n",
      "Episode:3226 meanR:13.0700 R:16.0 loss:0.0228 exploreP:0.0179\n",
      "Episode:3227 meanR:13.0600 R:14.0 loss:0.0231 exploreP:0.0179\n",
      "Episode:3228 meanR:13.0500 R:13.0 loss:0.0233 exploreP:0.0179\n",
      "Episode:3229 meanR:13.0600 R:14.0 loss:0.0243 exploreP:0.0179\n",
      "Episode:3230 meanR:13.0800 R:16.0 loss:0.0246 exploreP:0.0179\n",
      "Episode:3231 meanR:13.0600 R:13.0 loss:0.0236 exploreP:0.0178\n",
      "Episode:3232 meanR:13.0400 R:15.0 loss:0.0232 exploreP:0.0178\n",
      "Episode:3233 meanR:13.0200 R:11.0 loss:0.0244 exploreP:0.0178\n",
      "Episode:3234 meanR:12.9500 R:9.0 loss:0.0216 exploreP:0.0178\n",
      "Episode:3235 meanR:12.9400 R:8.0 loss:0.0213 exploreP:0.0178\n",
      "Episode:3236 meanR:12.9200 R:13.0 loss:0.0269 exploreP:0.0178\n",
      "Episode:3237 meanR:12.8900 R:8.0 loss:0.0195 exploreP:0.0178\n",
      "Episode:3238 meanR:12.8400 R:11.0 loss:0.0201 exploreP:0.0178\n",
      "Episode:3239 meanR:12.7800 R:10.0 loss:0.0246 exploreP:0.0178\n",
      "Episode:3240 meanR:12.8000 R:12.0 loss:0.0269 exploreP:0.0178\n",
      "Episode:3241 meanR:12.7700 R:11.0 loss:0.0281 exploreP:0.0178\n",
      "Episode:3242 meanR:12.7500 R:14.0 loss:0.0221 exploreP:0.0178\n",
      "Episode:3243 meanR:12.7600 R:14.0 loss:0.0221 exploreP:0.0177\n",
      "Episode:3244 meanR:12.7200 R:9.0 loss:0.0237 exploreP:0.0177\n",
      "Episode:3245 meanR:12.7300 R:14.0 loss:0.0263 exploreP:0.0177\n",
      "Episode:3246 meanR:12.6600 R:9.0 loss:0.0199 exploreP:0.0177\n",
      "Episode:3247 meanR:12.6300 R:11.0 loss:0.0207 exploreP:0.0177\n",
      "Episode:3248 meanR:12.6400 R:13.0 loss:0.0243 exploreP:0.0177\n",
      "Episode:3249 meanR:12.5900 R:10.0 loss:0.0224 exploreP:0.0177\n",
      "Episode:3250 meanR:12.5900 R:12.0 loss:0.0236 exploreP:0.0177\n",
      "Episode:3251 meanR:12.6600 R:16.0 loss:0.0257 exploreP:0.0177\n",
      "Episode:3252 meanR:12.6600 R:12.0 loss:0.0243 exploreP:0.0177\n",
      "Episode:3253 meanR:12.7100 R:16.0 loss:0.0282 exploreP:0.0176\n",
      "Episode:3254 meanR:12.7000 R:13.0 loss:0.0241 exploreP:0.0176\n",
      "Episode:3255 meanR:12.6600 R:12.0 loss:0.0232 exploreP:0.0176\n",
      "Episode:3256 meanR:12.6500 R:14.0 loss:0.0242 exploreP:0.0176\n",
      "Episode:3257 meanR:12.6200 R:11.0 loss:0.0207 exploreP:0.0176\n",
      "Episode:3258 meanR:12.6200 R:11.0 loss:0.0216 exploreP:0.0176\n",
      "Episode:3259 meanR:12.6500 R:15.0 loss:0.0317 exploreP:0.0176\n",
      "Episode:3260 meanR:12.6000 R:9.0 loss:0.0285 exploreP:0.0176\n",
      "Episode:3261 meanR:12.5300 R:9.0 loss:0.0240 exploreP:0.0176\n",
      "Episode:3262 meanR:12.5000 R:9.0 loss:0.0265 exploreP:0.0176\n",
      "Episode:3263 meanR:12.4200 R:9.0 loss:0.0296 exploreP:0.0176\n",
      "Episode:3264 meanR:12.3900 R:12.0 loss:0.0227 exploreP:0.0176\n",
      "Episode:3265 meanR:12.3800 R:13.0 loss:0.0320 exploreP:0.0175\n",
      "Episode:3266 meanR:12.3700 R:13.0 loss:0.0251 exploreP:0.0175\n",
      "Episode:3267 meanR:12.4100 R:15.0 loss:0.0211 exploreP:0.0175\n",
      "Episode:3268 meanR:12.3600 R:10.0 loss:0.0231 exploreP:0.0175\n",
      "Episode:3269 meanR:12.3600 R:12.0 loss:0.0294 exploreP:0.0175\n",
      "Episode:3270 meanR:12.4000 R:15.0 loss:0.0283 exploreP:0.0175\n",
      "Episode:3271 meanR:12.4000 R:10.0 loss:0.0263 exploreP:0.0175\n",
      "Episode:3272 meanR:12.3400 R:10.0 loss:0.0237 exploreP:0.0175\n",
      "Episode:3273 meanR:12.2900 R:9.0 loss:0.0265 exploreP:0.0175\n",
      "Episode:3274 meanR:12.3300 R:15.0 loss:0.0214 exploreP:0.0175\n",
      "Episode:3275 meanR:12.3200 R:12.0 loss:0.0267 exploreP:0.0175\n",
      "Episode:3276 meanR:12.3300 R:14.0 loss:0.0227 exploreP:0.0174\n",
      "Episode:3277 meanR:12.3300 R:13.0 loss:0.0193 exploreP:0.0174\n",
      "Episode:3278 meanR:12.2900 R:12.0 loss:0.0202 exploreP:0.0174\n",
      "Episode:3279 meanR:12.2600 R:9.0 loss:0.0265 exploreP:0.0174\n",
      "Episode:3280 meanR:12.3000 R:16.0 loss:0.0253 exploreP:0.0174\n",
      "Episode:3281 meanR:12.3200 R:15.0 loss:0.0224 exploreP:0.0174\n",
      "Episode:3282 meanR:12.3400 R:16.0 loss:0.0268 exploreP:0.0174\n",
      "Episode:3283 meanR:12.3200 R:11.0 loss:0.0283 exploreP:0.0174\n",
      "Episode:3284 meanR:12.2800 R:11.0 loss:0.0259 exploreP:0.0174\n",
      "Episode:3285 meanR:12.3200 R:16.0 loss:0.0252 exploreP:0.0174\n",
      "Episode:3286 meanR:12.3300 R:16.0 loss:0.0191 exploreP:0.0173\n",
      "Episode:3287 meanR:12.3300 R:12.0 loss:0.0230 exploreP:0.0173\n",
      "Episode:3288 meanR:12.3300 R:15.0 loss:0.0334 exploreP:0.0173\n",
      "Episode:3289 meanR:12.3200 R:12.0 loss:0.0224 exploreP:0.0173\n",
      "Episode:3290 meanR:12.3400 R:13.0 loss:0.0251 exploreP:0.0173\n",
      "Episode:3291 meanR:12.3300 R:11.0 loss:0.0195 exploreP:0.0173\n",
      "Episode:3292 meanR:12.3100 R:9.0 loss:0.0245 exploreP:0.0173\n",
      "Episode:3293 meanR:12.3000 R:15.0 loss:0.0251 exploreP:0.0173\n",
      "Episode:3294 meanR:12.2800 R:10.0 loss:0.0242 exploreP:0.0173\n",
      "Episode:3295 meanR:12.2100 R:8.0 loss:0.0312 exploreP:0.0173\n",
      "Episode:3296 meanR:12.2300 R:13.0 loss:0.0184 exploreP:0.0173\n",
      "Episode:3297 meanR:12.2700 R:16.0 loss:0.0245 exploreP:0.0172\n",
      "Episode:3298 meanR:12.3200 R:16.0 loss:0.0233 exploreP:0.0172\n",
      "Episode:3299 meanR:12.2400 R:8.0 loss:0.0262 exploreP:0.0172\n",
      "Episode:3300 meanR:12.2500 R:14.0 loss:0.0236 exploreP:0.0172\n",
      "Episode:3301 meanR:12.2200 R:11.0 loss:0.0225 exploreP:0.0172\n",
      "Episode:3302 meanR:12.2500 R:14.0 loss:0.0220 exploreP:0.0172\n",
      "Episode:3303 meanR:12.2700 R:14.0 loss:0.0274 exploreP:0.0172\n",
      "Episode:3304 meanR:12.2400 R:11.0 loss:0.0228 exploreP:0.0172\n",
      "Episode:3305 meanR:12.1900 R:10.0 loss:0.0264 exploreP:0.0172\n",
      "Episode:3306 meanR:12.2100 R:12.0 loss:0.0260 exploreP:0.0172\n",
      "Episode:3307 meanR:12.2400 R:14.0 loss:0.0281 exploreP:0.0172\n",
      "Episode:3308 meanR:12.2300 R:9.0 loss:0.0209 exploreP:0.0172\n",
      "Episode:3309 meanR:12.2300 R:9.0 loss:0.0219 exploreP:0.0171\n",
      "Episode:3310 meanR:12.2700 R:13.0 loss:0.0187 exploreP:0.0171\n",
      "Episode:3311 meanR:12.3100 R:15.0 loss:0.0177 exploreP:0.0171\n",
      "Episode:3312 meanR:12.3000 R:10.0 loss:0.0218 exploreP:0.0171\n",
      "Episode:3313 meanR:12.3400 R:15.0 loss:0.0212 exploreP:0.0171\n",
      "Episode:3314 meanR:12.3500 R:11.0 loss:0.0282 exploreP:0.0171\n",
      "Episode:3315 meanR:12.3000 R:9.0 loss:0.0293 exploreP:0.0171\n",
      "Episode:3316 meanR:12.3600 R:16.0 loss:0.0247 exploreP:0.0171\n",
      "Episode:3317 meanR:12.3700 R:15.0 loss:0.0226 exploreP:0.0171\n",
      "Episode:3318 meanR:12.3500 R:12.0 loss:0.0225 exploreP:0.0171\n",
      "Episode:3319 meanR:12.3700 R:15.0 loss:0.0229 exploreP:0.0171\n",
      "Episode:3320 meanR:12.3400 R:9.0 loss:0.0229 exploreP:0.0170\n",
      "Episode:3321 meanR:12.3400 R:13.0 loss:0.0255 exploreP:0.0170\n",
      "Episode:3322 meanR:12.2900 R:11.0 loss:0.0182 exploreP:0.0170\n",
      "Episode:3323 meanR:12.2900 R:12.0 loss:0.0198 exploreP:0.0170\n",
      "Episode:3324 meanR:12.2700 R:12.0 loss:0.0266 exploreP:0.0170\n",
      "Episode:3325 meanR:12.2800 R:13.0 loss:0.0271 exploreP:0.0170\n",
      "Episode:3326 meanR:12.2700 R:15.0 loss:0.0238 exploreP:0.0170\n",
      "Episode:3327 meanR:12.2100 R:8.0 loss:0.0197 exploreP:0.0170\n",
      "Episode:3328 meanR:12.1800 R:10.0 loss:0.0220 exploreP:0.0170\n",
      "Episode:3329 meanR:12.1700 R:13.0 loss:0.0196 exploreP:0.0170\n",
      "Episode:3330 meanR:12.1800 R:17.0 loss:0.0246 exploreP:0.0170\n",
      "Episode:3331 meanR:12.1600 R:11.0 loss:0.0202 exploreP:0.0170\n",
      "Episode:3332 meanR:12.1300 R:12.0 loss:0.0214 exploreP:0.0169\n",
      "Episode:3333 meanR:12.1700 R:15.0 loss:0.0209 exploreP:0.0169\n",
      "Episode:3334 meanR:12.2300 R:15.0 loss:0.0264 exploreP:0.0169\n",
      "Episode:3335 meanR:12.2600 R:11.0 loss:0.0168 exploreP:0.0169\n",
      "Episode:3336 meanR:12.2800 R:15.0 loss:0.0244 exploreP:0.0169\n",
      "Episode:3337 meanR:12.3000 R:10.0 loss:0.0278 exploreP:0.0169\n",
      "Episode:3338 meanR:12.3300 R:14.0 loss:0.0213 exploreP:0.0169\n",
      "Episode:3339 meanR:12.3900 R:16.0 loss:0.0245 exploreP:0.0169\n",
      "Episode:3340 meanR:12.4100 R:14.0 loss:0.0236 exploreP:0.0169\n",
      "Episode:3341 meanR:12.4500 R:15.0 loss:0.0237 exploreP:0.0169\n",
      "Episode:3342 meanR:12.4700 R:16.0 loss:0.0221 exploreP:0.0168\n",
      "Episode:3343 meanR:12.4400 R:11.0 loss:0.0255 exploreP:0.0168\n",
      "Episode:3344 meanR:12.5000 R:15.0 loss:0.0229 exploreP:0.0168\n",
      "Episode:3345 meanR:12.5000 R:14.0 loss:0.0263 exploreP:0.0168\n",
      "Episode:3346 meanR:12.5700 R:16.0 loss:0.0196 exploreP:0.0168\n",
      "Episode:3347 meanR:12.6000 R:14.0 loss:0.0214 exploreP:0.0168\n",
      "Episode:3348 meanR:12.6200 R:15.0 loss:0.0273 exploreP:0.0168\n",
      "Episode:3349 meanR:12.6800 R:16.0 loss:0.0231 exploreP:0.0168\n",
      "Episode:3350 meanR:12.6900 R:13.0 loss:0.0222 exploreP:0.0168\n",
      "Episode:3351 meanR:12.6600 R:13.0 loss:0.0267 exploreP:0.0168\n",
      "Episode:3352 meanR:12.6900 R:15.0 loss:0.0246 exploreP:0.0167\n",
      "Episode:3353 meanR:12.6900 R:16.0 loss:0.0210 exploreP:0.0167\n",
      "Episode:3354 meanR:12.6500 R:9.0 loss:0.0202 exploreP:0.0167\n",
      "Episode:3355 meanR:12.6200 R:9.0 loss:0.0291 exploreP:0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:3356 meanR:12.6300 R:15.0 loss:0.0222 exploreP:0.0167\n",
      "Episode:3357 meanR:12.6800 R:16.0 loss:0.0244 exploreP:0.0167\n",
      "Episode:3358 meanR:12.7300 R:16.0 loss:0.0260 exploreP:0.0167\n",
      "Episode:3359 meanR:12.6800 R:10.0 loss:0.0303 exploreP:0.0167\n",
      "Episode:3360 meanR:12.7500 R:16.0 loss:0.0222 exploreP:0.0167\n",
      "Episode:3361 meanR:12.7800 R:12.0 loss:0.0239 exploreP:0.0167\n",
      "Episode:3362 meanR:12.8000 R:11.0 loss:0.0250 exploreP:0.0167\n",
      "Episode:3363 meanR:12.8400 R:13.0 loss:0.0279 exploreP:0.0167\n",
      "Episode:3364 meanR:12.8100 R:9.0 loss:0.0260 exploreP:0.0166\n",
      "Episode:3365 meanR:12.8200 R:14.0 loss:0.0241 exploreP:0.0166\n",
      "Episode:3366 meanR:12.8100 R:12.0 loss:0.0236 exploreP:0.0166\n",
      "Episode:3367 meanR:12.7800 R:12.0 loss:0.0198 exploreP:0.0166\n",
      "Episode:3368 meanR:12.7900 R:11.0 loss:0.0189 exploreP:0.0166\n",
      "Episode:3369 meanR:12.8100 R:14.0 loss:0.0282 exploreP:0.0166\n",
      "Episode:3370 meanR:12.8000 R:14.0 loss:0.0211 exploreP:0.0166\n",
      "Episode:3371 meanR:12.8100 R:11.0 loss:0.0245 exploreP:0.0166\n",
      "Episode:3372 meanR:12.8200 R:11.0 loss:0.0238 exploreP:0.0166\n",
      "Episode:3373 meanR:12.8500 R:12.0 loss:0.0288 exploreP:0.0166\n",
      "Episode:3374 meanR:12.8100 R:11.0 loss:0.0234 exploreP:0.0166\n",
      "Episode:3375 meanR:12.7800 R:9.0 loss:0.0265 exploreP:0.0166\n",
      "Episode:3376 meanR:12.8100 R:17.0 loss:0.0253 exploreP:0.0165\n",
      "Episode:3377 meanR:12.8500 R:17.0 loss:0.0273 exploreP:0.0165\n",
      "Episode:3378 meanR:12.8500 R:12.0 loss:0.0270 exploreP:0.0165\n",
      "Episode:3379 meanR:12.9000 R:14.0 loss:0.0245 exploreP:0.0165\n",
      "Episode:3380 meanR:12.8900 R:15.0 loss:0.0223 exploreP:0.0165\n",
      "Episode:3381 meanR:12.8300 R:9.0 loss:0.0201 exploreP:0.0165\n",
      "Episode:3382 meanR:12.8200 R:15.0 loss:0.0240 exploreP:0.0165\n",
      "Episode:3383 meanR:12.8000 R:9.0 loss:0.0245 exploreP:0.0165\n",
      "Episode:3384 meanR:12.8000 R:11.0 loss:0.0203 exploreP:0.0165\n",
      "Episode:3385 meanR:12.7600 R:12.0 loss:0.0227 exploreP:0.0165\n",
      "Episode:3386 meanR:12.7200 R:12.0 loss:0.0258 exploreP:0.0165\n",
      "Episode:3387 meanR:12.7300 R:13.0 loss:0.0194 exploreP:0.0165\n",
      "Episode:3388 meanR:12.7100 R:13.0 loss:0.0263 exploreP:0.0165\n",
      "Episode:3389 meanR:12.7000 R:11.0 loss:0.0243 exploreP:0.0164\n",
      "Episode:3390 meanR:12.6800 R:11.0 loss:0.0271 exploreP:0.0164\n",
      "Episode:3391 meanR:12.6600 R:9.0 loss:0.0249 exploreP:0.0164\n",
      "Episode:3392 meanR:12.7200 R:15.0 loss:0.0204 exploreP:0.0164\n",
      "Episode:3393 meanR:12.7000 R:13.0 loss:0.0208 exploreP:0.0164\n",
      "Episode:3394 meanR:12.7300 R:13.0 loss:0.0288 exploreP:0.0164\n",
      "Episode:3395 meanR:12.8000 R:15.0 loss:0.0285 exploreP:0.0164\n",
      "Episode:3396 meanR:12.7600 R:9.0 loss:0.0264 exploreP:0.0164\n",
      "Episode:3397 meanR:12.7600 R:16.0 loss:0.0213 exploreP:0.0164\n",
      "Episode:3398 meanR:12.6900 R:9.0 loss:0.0214 exploreP:0.0164\n",
      "Episode:3399 meanR:12.7400 R:13.0 loss:0.0246 exploreP:0.0164\n",
      "Episode:3400 meanR:12.7500 R:15.0 loss:0.0246 exploreP:0.0164\n",
      "Episode:3401 meanR:12.8000 R:16.0 loss:0.0227 exploreP:0.0163\n",
      "Episode:3402 meanR:12.8200 R:16.0 loss:0.0220 exploreP:0.0163\n",
      "Episode:3403 meanR:12.8300 R:15.0 loss:0.0240 exploreP:0.0163\n",
      "Episode:3404 meanR:12.8100 R:9.0 loss:0.0223 exploreP:0.0163\n",
      "Episode:3405 meanR:12.8400 R:13.0 loss:0.0240 exploreP:0.0163\n",
      "Episode:3406 meanR:12.8200 R:10.0 loss:0.0275 exploreP:0.0163\n",
      "Episode:3407 meanR:12.7700 R:9.0 loss:0.0215 exploreP:0.0163\n",
      "Episode:3408 meanR:12.8200 R:14.0 loss:0.0192 exploreP:0.0163\n",
      "Episode:3409 meanR:12.8900 R:16.0 loss:0.0236 exploreP:0.0163\n",
      "Episode:3410 meanR:12.8600 R:10.0 loss:0.0236 exploreP:0.0163\n",
      "Episode:3411 meanR:12.8300 R:12.0 loss:0.0249 exploreP:0.0163\n",
      "Episode:3412 meanR:12.8400 R:11.0 loss:0.0280 exploreP:0.0163\n",
      "Episode:3413 meanR:12.7800 R:9.0 loss:0.0224 exploreP:0.0163\n",
      "Episode:3414 meanR:12.8300 R:16.0 loss:0.0255 exploreP:0.0162\n",
      "Episode:3415 meanR:12.8700 R:13.0 loss:0.0215 exploreP:0.0162\n",
      "Episode:3416 meanR:12.8300 R:12.0 loss:0.0285 exploreP:0.0162\n",
      "Episode:3417 meanR:12.8100 R:13.0 loss:0.0254 exploreP:0.0162\n",
      "Episode:3418 meanR:12.8200 R:13.0 loss:0.0189 exploreP:0.0162\n",
      "Episode:3419 meanR:12.8100 R:14.0 loss:0.0236 exploreP:0.0162\n",
      "Episode:3420 meanR:12.8700 R:15.0 loss:0.0225 exploreP:0.0162\n",
      "Episode:3421 meanR:12.8400 R:10.0 loss:0.0237 exploreP:0.0162\n",
      "Episode:3422 meanR:12.8700 R:14.0 loss:0.0213 exploreP:0.0162\n",
      "Episode:3423 meanR:12.9100 R:16.0 loss:0.0221 exploreP:0.0162\n",
      "Episode:3424 meanR:12.9500 R:16.0 loss:0.0224 exploreP:0.0162\n",
      "Episode:3425 meanR:12.9500 R:13.0 loss:0.0214 exploreP:0.0162\n",
      "Episode:3426 meanR:12.9500 R:15.0 loss:0.0235 exploreP:0.0161\n",
      "Episode:3427 meanR:13.0200 R:15.0 loss:0.0182 exploreP:0.0161\n",
      "Episode:3428 meanR:13.0200 R:10.0 loss:0.0220 exploreP:0.0161\n",
      "Episode:3429 meanR:13.0200 R:13.0 loss:0.0226 exploreP:0.0161\n",
      "Episode:3430 meanR:13.0200 R:17.0 loss:0.0228 exploreP:0.0161\n",
      "Episode:3431 meanR:12.9900 R:8.0 loss:0.0195 exploreP:0.0161\n",
      "Episode:3432 meanR:13.0300 R:16.0 loss:0.0228 exploreP:0.0161\n",
      "Episode:3433 meanR:13.0400 R:16.0 loss:0.0210 exploreP:0.0161\n",
      "Episode:3434 meanR:13.0000 R:11.0 loss:0.0221 exploreP:0.0161\n",
      "Episode:3435 meanR:13.0000 R:11.0 loss:0.0161 exploreP:0.0161\n",
      "Episode:3436 meanR:12.9300 R:8.0 loss:0.0275 exploreP:0.0161\n",
      "Episode:3437 meanR:12.9600 R:13.0 loss:0.0219 exploreP:0.0161\n",
      "Episode:3438 meanR:12.9700 R:15.0 loss:0.0240 exploreP:0.0160\n",
      "Episode:3439 meanR:12.9100 R:10.0 loss:0.0230 exploreP:0.0160\n",
      "Episode:3440 meanR:12.9000 R:13.0 loss:0.0246 exploreP:0.0160\n",
      "Episode:3441 meanR:12.8800 R:13.0 loss:0.0237 exploreP:0.0160\n",
      "Episode:3442 meanR:12.8500 R:13.0 loss:0.0227 exploreP:0.0160\n",
      "Episode:3443 meanR:12.8400 R:10.0 loss:0.0203 exploreP:0.0160\n",
      "Episode:3444 meanR:12.8500 R:16.0 loss:0.0229 exploreP:0.0160\n",
      "Episode:3445 meanR:12.8400 R:13.0 loss:0.0223 exploreP:0.0160\n",
      "Episode:3446 meanR:12.8400 R:16.0 loss:0.0227 exploreP:0.0160\n",
      "Episode:3447 meanR:12.8600 R:16.0 loss:0.0210 exploreP:0.0160\n",
      "Episode:3448 meanR:12.8600 R:15.0 loss:0.0205 exploreP:0.0160\n",
      "Episode:3449 meanR:12.8300 R:13.0 loss:0.0202 exploreP:0.0160\n",
      "Episode:3450 meanR:12.7900 R:9.0 loss:0.0237 exploreP:0.0160\n",
      "Episode:3451 meanR:12.7500 R:9.0 loss:0.0264 exploreP:0.0160\n",
      "Episode:3452 meanR:12.8000 R:20.0 loss:0.0246 exploreP:0.0159\n",
      "Episode:3453 meanR:12.7600 R:12.0 loss:0.0227 exploreP:0.0159\n",
      "Episode:3454 meanR:12.7900 R:12.0 loss:0.0263 exploreP:0.0159\n",
      "Episode:3455 meanR:12.8100 R:11.0 loss:0.0195 exploreP:0.0159\n",
      "Episode:3456 meanR:12.7800 R:12.0 loss:0.0225 exploreP:0.0159\n",
      "Episode:3457 meanR:12.7500 R:13.0 loss:0.0227 exploreP:0.0159\n",
      "Episode:3458 meanR:12.7000 R:11.0 loss:0.0239 exploreP:0.0159\n",
      "Episode:3459 meanR:12.7200 R:12.0 loss:0.0211 exploreP:0.0159\n",
      "Episode:3460 meanR:12.6800 R:12.0 loss:0.0249 exploreP:0.0159\n",
      "Episode:3461 meanR:12.6700 R:11.0 loss:0.0192 exploreP:0.0159\n",
      "Episode:3462 meanR:12.6700 R:11.0 loss:0.0363 exploreP:0.0159\n",
      "Episode:3463 meanR:12.6400 R:10.0 loss:0.0255 exploreP:0.0159\n",
      "Episode:3464 meanR:12.6600 R:11.0 loss:0.0245 exploreP:0.0159\n",
      "Episode:3465 meanR:12.6800 R:16.0 loss:0.0207 exploreP:0.0158\n",
      "Episode:3466 meanR:12.6700 R:11.0 loss:0.0250 exploreP:0.0158\n",
      "Episode:3467 meanR:12.7100 R:16.0 loss:0.0201 exploreP:0.0158\n",
      "Episode:3468 meanR:12.7400 R:14.0 loss:0.0219 exploreP:0.0158\n",
      "Episode:3469 meanR:12.6900 R:9.0 loss:0.0185 exploreP:0.0158\n",
      "Episode:3470 meanR:12.7100 R:16.0 loss:0.0228 exploreP:0.0158\n",
      "Episode:3471 meanR:12.7200 R:12.0 loss:0.0239 exploreP:0.0158\n",
      "Episode:3472 meanR:12.7400 R:13.0 loss:0.0215 exploreP:0.0158\n",
      "Episode:3473 meanR:12.7600 R:14.0 loss:0.0289 exploreP:0.0158\n",
      "Episode:3474 meanR:12.7700 R:12.0 loss:0.0229 exploreP:0.0158\n",
      "Episode:3475 meanR:12.7700 R:9.0 loss:0.0202 exploreP:0.0158\n",
      "Episode:3476 meanR:12.7600 R:16.0 loss:0.0258 exploreP:0.0158\n",
      "Episode:3477 meanR:12.7300 R:14.0 loss:0.0247 exploreP:0.0158\n",
      "Episode:3478 meanR:12.7300 R:12.0 loss:0.0236 exploreP:0.0158\n",
      "Episode:3479 meanR:12.7000 R:11.0 loss:0.0209 exploreP:0.0157\n",
      "Episode:3480 meanR:12.6700 R:12.0 loss:0.0227 exploreP:0.0157\n",
      "Episode:3481 meanR:12.6900 R:11.0 loss:0.0214 exploreP:0.0157\n",
      "Episode:3482 meanR:12.6800 R:14.0 loss:0.0258 exploreP:0.0157\n",
      "Episode:3483 meanR:12.6700 R:8.0 loss:0.0181 exploreP:0.0157\n",
      "Episode:3484 meanR:12.7100 R:15.0 loss:0.0222 exploreP:0.0157\n",
      "Episode:3485 meanR:12.6900 R:10.0 loss:0.0220 exploreP:0.0157\n",
      "Episode:3486 meanR:12.6600 R:9.0 loss:0.0294 exploreP:0.0157\n",
      "Episode:3487 meanR:12.6300 R:10.0 loss:0.0279 exploreP:0.0157\n",
      "Episode:3488 meanR:12.6600 R:16.0 loss:0.0272 exploreP:0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:3489 meanR:12.6500 R:10.0 loss:0.0190 exploreP:0.0157\n",
      "Episode:3490 meanR:12.6800 R:14.0 loss:0.0210 exploreP:0.0157\n",
      "Episode:3491 meanR:12.7500 R:16.0 loss:0.0234 exploreP:0.0157\n",
      "Episode:3492 meanR:12.7600 R:16.0 loss:0.0170 exploreP:0.0157\n",
      "Episode:3493 meanR:12.7200 R:9.0 loss:0.0211 exploreP:0.0156\n",
      "Episode:3494 meanR:12.6800 R:9.0 loss:0.0227 exploreP:0.0156\n",
      "Episode:3495 meanR:12.6400 R:11.0 loss:0.0168 exploreP:0.0156\n",
      "Episode:3496 meanR:12.6700 R:12.0 loss:0.0213 exploreP:0.0156\n",
      "Episode:3497 meanR:12.6000 R:9.0 loss:0.0276 exploreP:0.0156\n",
      "Episode:3498 meanR:12.6200 R:11.0 loss:0.0236 exploreP:0.0156\n",
      "Episode:3499 meanR:12.6400 R:15.0 loss:0.0230 exploreP:0.0156\n",
      "Episode:3500 meanR:12.6500 R:16.0 loss:0.0216 exploreP:0.0156\n",
      "Episode:3501 meanR:12.6100 R:12.0 loss:0.0245 exploreP:0.0156\n",
      "Episode:3502 meanR:12.5700 R:12.0 loss:0.0260 exploreP:0.0156\n",
      "Episode:3503 meanR:12.5300 R:11.0 loss:0.0231 exploreP:0.0156\n",
      "Episode:3504 meanR:12.5600 R:12.0 loss:0.0268 exploreP:0.0156\n",
      "Episode:3505 meanR:12.6000 R:17.0 loss:0.0255 exploreP:0.0156\n",
      "Episode:3506 meanR:12.6100 R:11.0 loss:0.0269 exploreP:0.0156\n",
      "Episode:3507 meanR:12.6500 R:13.0 loss:0.0244 exploreP:0.0156\n",
      "Episode:3508 meanR:12.6200 R:11.0 loss:0.0309 exploreP:0.0155\n",
      "Episode:3509 meanR:12.6200 R:16.0 loss:0.0241 exploreP:0.0155\n",
      "Episode:3510 meanR:12.6400 R:12.0 loss:0.0242 exploreP:0.0155\n",
      "Episode:3511 meanR:12.6300 R:11.0 loss:0.0206 exploreP:0.0155\n",
      "Episode:3512 meanR:12.6200 R:10.0 loss:0.0343 exploreP:0.0155\n",
      "Episode:3513 meanR:12.6700 R:14.0 loss:0.0203 exploreP:0.0155\n",
      "Episode:3514 meanR:12.6500 R:14.0 loss:0.0207 exploreP:0.0155\n",
      "Episode:3515 meanR:12.6900 R:17.0 loss:0.0272 exploreP:0.0155\n",
      "Episode:3516 meanR:12.6800 R:11.0 loss:0.0207 exploreP:0.0155\n",
      "Episode:3517 meanR:12.7000 R:15.0 loss:0.0211 exploreP:0.0155\n",
      "Episode:3518 meanR:12.7100 R:14.0 loss:0.0223 exploreP:0.0155\n",
      "Episode:3519 meanR:12.6900 R:12.0 loss:0.0196 exploreP:0.0155\n",
      "Episode:3520 meanR:12.6500 R:11.0 loss:0.0230 exploreP:0.0155\n",
      "Episode:3521 meanR:12.6400 R:9.0 loss:0.0294 exploreP:0.0155\n",
      "Episode:3522 meanR:12.6500 R:15.0 loss:0.0192 exploreP:0.0154\n",
      "Episode:3523 meanR:12.5800 R:9.0 loss:0.0198 exploreP:0.0154\n",
      "Episode:3524 meanR:12.5800 R:16.0 loss:0.0203 exploreP:0.0154\n",
      "Episode:3525 meanR:12.5800 R:13.0 loss:0.0236 exploreP:0.0154\n",
      "Episode:3526 meanR:12.5500 R:12.0 loss:0.0213 exploreP:0.0154\n",
      "Episode:3527 meanR:12.5600 R:16.0 loss:0.0181 exploreP:0.0154\n",
      "Episode:3528 meanR:12.5900 R:13.0 loss:0.0278 exploreP:0.0154\n",
      "Episode:3529 meanR:12.6100 R:15.0 loss:0.0256 exploreP:0.0154\n",
      "Episode:3530 meanR:12.6000 R:16.0 loss:0.0256 exploreP:0.0154\n",
      "Episode:3531 meanR:12.6700 R:15.0 loss:0.0257 exploreP:0.0154\n",
      "Episode:3532 meanR:12.6600 R:15.0 loss:0.0238 exploreP:0.0154\n",
      "Episode:3533 meanR:12.6500 R:15.0 loss:0.0231 exploreP:0.0154\n",
      "Episode:3534 meanR:12.7100 R:17.0 loss:0.0246 exploreP:0.0154\n",
      "Episode:3535 meanR:12.7100 R:11.0 loss:0.0245 exploreP:0.0153\n",
      "Episode:3536 meanR:12.7600 R:13.0 loss:0.0232 exploreP:0.0153\n",
      "Episode:3537 meanR:12.7300 R:10.0 loss:0.0252 exploreP:0.0153\n",
      "Episode:3538 meanR:12.7300 R:15.0 loss:0.0214 exploreP:0.0153\n",
      "Episode:3539 meanR:12.7400 R:11.0 loss:0.0196 exploreP:0.0153\n",
      "Episode:3540 meanR:12.7100 R:10.0 loss:0.0236 exploreP:0.0153\n",
      "Episode:3541 meanR:12.6800 R:10.0 loss:0.0199 exploreP:0.0153\n",
      "Episode:3542 meanR:12.6600 R:11.0 loss:0.0201 exploreP:0.0153\n",
      "Episode:3543 meanR:12.7200 R:16.0 loss:0.0193 exploreP:0.0153\n",
      "Episode:3544 meanR:12.7000 R:14.0 loss:0.0242 exploreP:0.0153\n",
      "Episode:3545 meanR:12.6600 R:9.0 loss:0.0260 exploreP:0.0153\n",
      "Episode:3546 meanR:12.5900 R:9.0 loss:0.0243 exploreP:0.0153\n",
      "Episode:3547 meanR:12.5900 R:16.0 loss:0.0244 exploreP:0.0153\n",
      "Episode:3548 meanR:12.5900 R:15.0 loss:0.0226 exploreP:0.0153\n",
      "Episode:3549 meanR:12.5600 R:10.0 loss:0.0228 exploreP:0.0153\n",
      "Episode:3550 meanR:12.6300 R:16.0 loss:0.0270 exploreP:0.0152\n",
      "Episode:3551 meanR:12.6500 R:11.0 loss:0.0257 exploreP:0.0152\n",
      "Episode:3552 meanR:12.5800 R:13.0 loss:0.0245 exploreP:0.0152\n",
      "Episode:3553 meanR:12.5800 R:12.0 loss:0.0196 exploreP:0.0152\n",
      "Episode:3554 meanR:12.5600 R:10.0 loss:0.0228 exploreP:0.0152\n",
      "Episode:3555 meanR:12.5600 R:11.0 loss:0.0205 exploreP:0.0152\n",
      "Episode:3556 meanR:12.5800 R:14.0 loss:0.0200 exploreP:0.0152\n",
      "Episode:3557 meanR:12.6100 R:16.0 loss:0.0224 exploreP:0.0152\n",
      "Episode:3558 meanR:12.6200 R:12.0 loss:0.0198 exploreP:0.0152\n",
      "Episode:3559 meanR:12.6400 R:14.0 loss:0.0244 exploreP:0.0152\n",
      "Episode:3560 meanR:12.6300 R:11.0 loss:0.0192 exploreP:0.0152\n",
      "Episode:3561 meanR:12.6200 R:10.0 loss:0.0208 exploreP:0.0152\n",
      "Episode:3562 meanR:12.6200 R:11.0 loss:0.0270 exploreP:0.0152\n",
      "Episode:3563 meanR:12.6300 R:11.0 loss:0.0217 exploreP:0.0152\n",
      "Episode:3564 meanR:12.6600 R:14.0 loss:0.0244 exploreP:0.0152\n",
      "Episode:3565 meanR:12.5800 R:8.0 loss:0.0295 exploreP:0.0152\n",
      "Episode:3566 meanR:12.6300 R:16.0 loss:0.0234 exploreP:0.0151\n",
      "Episode:3567 meanR:12.5700 R:10.0 loss:0.0189 exploreP:0.0151\n",
      "Episode:3568 meanR:12.5200 R:9.0 loss:0.0220 exploreP:0.0151\n",
      "Episode:3569 meanR:12.5300 R:10.0 loss:0.0213 exploreP:0.0151\n",
      "Episode:3570 meanR:12.4600 R:9.0 loss:0.0170 exploreP:0.0151\n",
      "Episode:3571 meanR:12.5000 R:16.0 loss:0.0224 exploreP:0.0151\n",
      "Episode:3572 meanR:12.4900 R:12.0 loss:0.0221 exploreP:0.0151\n",
      "Episode:3573 meanR:12.4500 R:10.0 loss:0.0237 exploreP:0.0151\n",
      "Episode:3574 meanR:12.4500 R:12.0 loss:0.0246 exploreP:0.0151\n",
      "Episode:3575 meanR:12.4700 R:11.0 loss:0.0238 exploreP:0.0151\n",
      "Episode:3576 meanR:12.4300 R:12.0 loss:0.0242 exploreP:0.0151\n",
      "Episode:3577 meanR:12.4000 R:11.0 loss:0.0257 exploreP:0.0151\n",
      "Episode:3578 meanR:12.4200 R:14.0 loss:0.0263 exploreP:0.0151\n",
      "Episode:3579 meanR:12.4100 R:10.0 loss:0.0282 exploreP:0.0151\n",
      "Episode:3580 meanR:12.4300 R:14.0 loss:0.0177 exploreP:0.0151\n",
      "Episode:3581 meanR:12.4800 R:16.0 loss:0.0228 exploreP:0.0151\n"
     ]
    }
   ],
   "source": [
    "# Save/load the model and save for plotting\n",
    "saver = tf.train.Saver()\n",
    "episode_rewards_list, rewards_list, loss_list = [], [], []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    total_step = 0 # Explore or exploit parameter\n",
    "    episode_reward = deque(maxlen=100) # 100 episodes average/running average/running mean/window\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    for ep in range(11111):\n",
    "        total_reward = 0\n",
    "        loss_batch = []\n",
    "        state = env.reset()\n",
    "\n",
    "        # Training steps/batches\n",
    "        while True:\n",
    "            # Explore (Env) or Exploit (Model)\n",
    "            total_step += 1\n",
    "            explore_p = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * total_step) \n",
    "            if explore_p > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = act(sess, state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            memory.buffer.append([state, action, next_state, reward, float(done)])\n",
    "            \n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Training\n",
    "            loss = learn(sess, memory, batch_size)\n",
    "            loss_batch.append(loss)\n",
    "            \n",
    "            if done is True:\n",
    "                break\n",
    "                \n",
    "        episode_reward.append(total_reward)\n",
    "        print('Episode:{}'.format(ep),\n",
    "              'meanR:{:.4f}'.format(np.mean(episode_reward)),\n",
    "              'R:{}'.format(total_reward),\n",
    "              'loss:{:.4f}'.format(np.mean(loss_batch)),\n",
    "              'exploreP:{:.4f}'.format(explore_p))\n",
    "        # Ploting out\n",
    "        episode_rewards_list.append([ep, np.mean(episode_reward)])\n",
    "        rewards_list.append([ep, total_reward])\n",
    "        loss_list.append([ep, np.mean(loss_batch)])\n",
    "        # Break episode/epoch loop\n",
    "        if np.mean(episode_reward) >= 500:\n",
    "            break\n",
    "            \n",
    "    # At the end of all training episodes/epochs\n",
    "    saver.save(sess, 'checkpoints/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcZGV97/HPr6p6n6Vn3xeGmWETGGBEUIICbiwCrkCMYMIVjdzcGGNu0Nxo9N7kmntjNCZGRfEGEqPihqi4IIsKyMCwDAwgzMLMdE/vS3V17dvv/lGnoR16emqGqa7qru/79epXnfPUqapv9dTUr5/nnPMcc3dEREQOFKp2ABERqU0qECIiMiEVCBERmZAKhIiITEgFQkREJqQCISIiE1KBEBGRCalAiIjIhFQgRERkQpFqB3g5Fi5c6GvXrq12DBGRaeWRRx4ZcPdFh9puWheItWvXsnXr1mrHEBGZVsxsbznbaYhJREQmpAIhIiITUoEQEZEJqUCIiMiEVCBERGRCFS0QZrbHzJ40s8fNbGvQNt/M7jSzHcHtvKDdzOzzZrbTzJ4ws9MrmU1ERCY3FT2I89x9k7tvDtZvAO5y9w3AXcE6wIXAhuDnOuCLU5BNREQOohrnQVwGvC5Yvhm4F/jLoP0WL10D9UEzazezZe7eXYWMIiJTKp/Pk0wmAYilcjzVNUIslSOTL5AvFCkWnULRKbhTKBR5zQkr2LR2cUUzVbpAOPBzM3Pgy+5+I7Bk7Evf3bvNbOwdrgA6xj22M2j7nQJhZtdR6mGwevXqCscXEam8TCZDZ2cn3cMJfvpUD/fvHCBf8Ekf09LcOO0LxGvcvSsoAnea2W8n2dYmaHvJbygoMjcCbN68efLfoIhIjXJ3CoUC8XicHfv2c/u2br7zTBIsxGWbjufiU5azaHYTLY0RGkJGOBwibEY4bDSEwzQ3hCuesaIFwt27gts+M/s+cCbQOzZ0ZGbLgL5g805g1biHrwS6KplPRKQaMpkM+/btI5cv8KNtXfzk6V6687N416vWcf1561kyp7naEYEKFggzawNC7j4aLL8R+BRwO3AN8Ong9gfBQ24H/quZfRN4FTCi/Q8iMtMkk0k6OzvJFYr846+6ue/5GG865Ti+9sbjOGZhW7Xj/Y5K9iCWAN83s7HX+U93/6mZPQzcambXAvuAdwbb3wFcBOwEksAfVjCbiMiUKxQKdHV1YWb8+xOj3PV8kr976+n8/qtqc39qxQqEu+8GTp2gfRC4YIJ2B66vVB4RkWqLRqMUCgU6sq1887E+3v/adTVbHEBnUouITIliscjw8DDW0MzHf/Qc6xfP4s9ev7HasSY1ra8HISIyXYz1Hr79VJzuWJrv/fGrp+RIpJdDPQgRkQob6z3EciFufqiLd56xktNWz6t2rENSD0JEpML6+/vJ5/P826PDREIh/vyNx1U7UlnUgxARqaBUKkU0GqUrGeLHTw/ygdceWzPnORyKCoSISIW4Oz09PYTDEf7p/h6WzGnifeceU+1YZVOBEBGpkKGhIbLZLI/0FXm8M8ZfvOl4Whunz8i+CoSISAW4O8PDw4Qam/mHe/ayaVU7bzttRbVjHZbpU8pERKaR0dFRCoUC3316lP7RDF+9ejOh0ERzktYu9SBERI6yXC5Hb28vA8kC/29LF+/avJJTV7VXO9ZhU4EQETnKuru7yeYK/PP9PTRHIvzFm46vdqQjoiEmEZGjKJFIkEwm+Y8nojzYmeKfrzqNRbObqh3riKhAiIgcBYVCgWQyydDQEL/cOcQ3Hh/ig69bz1tOXV7taEdMBUJE5CgYGBggGo3y255RvvBAHxccv4KPTJMzpg9G+yBERF6mTCZDNBolG2rkU/cOsGhBO5+9ctO0O2rpQOpBiIi8DOl0mr179+LufPquTlIFuPXqzcxpbqh2tJdNPQgRkZdhaGiIcDjM7nQL9++J8VcXn8Cxi2ZVO9ZRoQIhInKECoUC8XicOXPm8IVf7WPNglau2Lyq2rGOGhUIEZEjFIvFcHce68nwVFeMPzl/A5HwzPlanTnvRERkisViMZqbm7l5y36Wz23msk3T95DWiahAiIgcgUwmQzqdpj8T4oFdg7zn7LU0zKDeA6hAiIgckZGREcyMbz8+SHNDiKvOnDn7HsaoQIiIHCZ3Z3R0lHyoke8/0c1bT1tJe2tjtWMddToPQkTkMCUSCfL5PHfsjJPNF7n2nLXVjlQR6kGIiBymkZERYukCNz3YxYWvWMr6xbOrHakiVCBERA5DKpViJDbK5+/vouDw0QtPqHakitEQk4jIIYwdsZTL5Xjouf18Y8se7usN85l3bWL1gtZqx6sYFQgRkYMoFosMDQ0xODjIQDzDF+7Zxb6hJLTM5V9+/wwuPmVZtSNWlAqEiMhB9PX1MTIyQjEU4a/u3MtQuoWPXn4Gl21aTmvjzP/6nPnvUETkCBQKBWKxGO3t7Xzu/j72jeT49gfO5ow186sdbcpoJ7WIyATi8XjpfIdiA7du7eA9Z62pq+IAU1AgzCxsZo+Z2Y+C9WPMbIuZ7TCzb5lZY9DeFKzvDO5fW+lsIiIHMzo6SmNjI197cD9hM/74deurHWnKTUUP4k+BZ8at/z3wWXffAAwD1wbt1wLD7r4e+GywnYjIlMvn8ySTSQrhZr6ztZN3bF7J0rnN1Y415SpaIMxsJXAx8NVg3YDzge8Em9wMXB4sXxasE9x/QbC9iMiUGh0dxd359Z442UKRq89eU+1IVVHpHsTngP8OFIP1BUDU3fPBeiewIlheAXQABPePBNuLiEyp0dFRmpqauO3JPk5YNofjl86pdqSqqFiBMLNLgD53f2R88wSbehn3jX/e68xsq5lt7e/vPwpJRURelMvlSKVSRPNhtnVEefvpKw79oBmqkj2I1wCXmtke4JuUhpY+B7Sb2djhtSuBrmC5E1gFENw/Fxg68End/UZ33+zumxctWlTB+CJSj2KxGAB37RwlZHDpqTPrIkCHo2IFwt0/6u4r3X0tcCVwt7u/G7gHeEew2TXAD4Ll24N1gvvvdveX9CBERCpp7CpxP36qj1cds4DFc+pv5/SYapwH8ZfAh81sJ6V9DDcF7TcBC4L2DwM3VCGbiNSxTCZDNpulPxNmd39ixk+lcShTcia1u98L3Bss7wbOnGCbNPDOqcgjIjKRWCyGmXH3rhHCIePCVyytdqSq0pnUIiK8eJW4lpYWfry9j1cfu4AFs5qqHauqVCBEROCF6by7kyH2Dia5+OT6Hl4CFQgREaA0vBQKhfjFriiRkPHmOh9eAhUIEZEXhpfa2tq448leztmwkPbWxmrHqjoVCBGpe8lkkkKhwN5Ykc7hFJecUr/nPoynAiEidS8WixEOh7lzxwiN4RBvOHFJtSPVBBUIEalr7k4ikaC1tY2fbO/h3I0LmdvSUO1YNUEFQkTq2tjw0u6RPN0jaQ0vjaMCISJ1LR6Pl45eem6ExkiI12t46QUqECJSt9ydeDxOc0srd2zv4bzjFjGraUommJgW9JsQkbqVTqfJ5/N0pPL0jWY0vHQA9SBEpG7F43HMjF/siNLcEOKCExZXO1JNUYEQkboVj8dpamrmJ9v7uOD4JbQ2alBlPP02RKQujU3t3ZFqYDCR5ZI6n9p7IupBiEhdisfjAPz02ShtjWHOO17DSwdSgRCRuhSPxymGG/jx9j4u3bSc5oZwtSPVHA0xiUjdyWazpNNptnRlSeUKXPHK1dWOVJPUgxCRuhONRjEzvr99iOOXzubUlXOrHakmqUCISF0Zm9q7N+Vs2x/nileuwsyqHasmqUCISF1JpVLk83l+sSNGYyTEW09bUe1INUsFQkTqRiaToauri4Ib398+yJtPWqoLA03ikAXCzN5mZrOD5RvM7FYz21T5aCIiR1d/fz+FQoFH+iGWLnDVmdo5PZlyehB/4+6jZvZq4C3At4AvVTaWiMjRVSgUSCaTtM+bz9e2dHHKyrmctW5+tWPVtHIKRCG4vQT4V3f/LtBUuUgiIkdfIpHA3Xm4M8HzAwnef+6x2jl9COWcB9FtZl8A3gxsNrNGtO9CRKaZeDxOOBzmKw90snp+K29+xdJqR6p55XzRvwv4JXCxuw8DC4EbKppKROQoGrus6PPRAts6R3jfuesIh9R7OJSD9iDMbM641Z+Oa4sD91c4l4jIUROLxSgWi3xrWz8L2hp55xkrqx1pWphsiOkpwAEDlgOjwfIsYD+g3f8iUvNyuRx9fX3sj+X4xY4RPvyGjZp3qUwHHWJy91Xuvhr4IfBWd29397nA5ZSOZBIRqWnuTkdHB5lcnn+9v4uFsxq55uy11Y41bZSzD+JMd799bMXdfwicV7lIIiIvn7uTyWRIZ7J88cF+tvbk+J+XvYK5rQ3VjjZtlHMU05CZ3QD8B6Uhpz8AhiuaSkTkZejt7SUajVIoOl/59fPcsTvPxy95BReerIsCHY5yCsTvA58EfkKpQPwKuKqSoUREjlQ8HicajdIVTXHj/ft4sj/PX128iT8655hqR5t2Ji0QZhYGPuLu1x/uE5tZM6Vi0hS8znfc/RNmdgzwTWA+8CjwHnfPmlkTcAtwBjAIXOHuew73dUWkPhWLRTKZDL29vdz73ACf2TLC7KYW/uHdJ+uchyM0aYFw94KZnXmEz50Bznf3uJk1APeZ2U+ADwOfdfdvmtmXgGuBLwa3w+6+3syuBP4euOIIX1tE6khPTw8jIyN0RVP8cFsX9zyf4NUb1/AP7zyVhbM08cORKmeI6VEz+x7wbSAx1jh+x/VE3N0pnTMB0BD8OHA+pWErgJuBv6FUIC4LlgG+A/yLmVnwPCIiv6NYLJJMJkmn0/x2Xw/feaSTLR0JUuE2rj3/FP70go2EdDLcy1JOgVhCqTBcNK7NgUkLBLwwRPUIsB74ArALiLp7PtikExibjH0F0AHg7nkzGwEWAANlZBSROlIoFOjo6KBvOM4vftvLz5/pYzTczu+/bhPvffVaFqjXcFQcskC4+3uO9MndvQBsMrN24PvACRNtFtxOVOpf0nsws+uA6wBWr9a5eiL1Ip/PMzIyQj6fp7t/iNse28/tvx0lXTTOP3EdH7/sVBbPaa52zBnlkAUi2Hn8XuAk4IXfvrtfV+6LuHvUzO4FzgLazSwS9CJWAl3BZp3AKqDTzCLAXGBogue6EbgRYPPmzRp+EqkD7s6ePXsoFAo81zPKV+/bzc54A2/ZfCwfeO2xrF3YVu2IM1I5J8rdAqylNN33FuBYIH2oB5nZoqDngJm1AK8HngHuAd4RbHYN8INg+fZgneD+u7X/QUQARkdHKRQKbO3J81c/6yDZOI+vf/A8Pv32U1QcKqicfRAb3f0KM7vY3W8ys1uAn5XxuGXAzcF+iBBwq7v/yMyeBr5pZv8LeAy4Kdj+JuDfzWwnpZ7DlYf9bkRkxonFYvT19TGcLvLJO/ey+ZhlfPk9ZzC7WWdEV1o5BSIX3EbN7ASgF1hzqAe5+xPAaRO07wZecuisu6eBd5aRR0TqRCqVoru7m+bmZm56dIBIKMRnr9ik4jBFyhliusnM5gGfoNRzeA74TEVTiYhQOivazNibbubOZwf5r+evZ4l2RE+Zco5i+nKweA+a4ltEplA8Hqe5uZnP/HAnK9pbuFbTZUypco5ieg74DfBr4Ffu/lzFU4lI3ctms2SzWXaNhtjWEeXTbzuZpoiu4zCVyhli2kTpjOcVlM5u3mVm365sLBGpZ+7OwMAA7s6XHtjP6vmtvF1XgZty5RSIDKWrySWAFKUzm2OVDCUi9S0ajTI6OsqzUXiiK8F/u2ADDeFyvq7kaCrnKKYRSpcf/RzwPnfvq2wkEal38XichoZGvvJwJ2sWtHL5puXVjlSXyinJ1wAPAB8EbjGzvzaz11Y2lojUq3w+TyqV4u5dMbbvj/Gh128got5DVZRzFNN3ge+a2XrgYkrTdf8PStd5EBE5qvr7++kfzfD5X3dy7sZFXL5pxaEfJBVxyLJsZt8ysx3Al4F5wB8FtyIiR42709XVxXB0hH95oAe3CP/7bSdjpim7q6WcfRCfAx4eN0W3iMhRVSwW6e7uJh6P85Nno/xmf4Z/uvI0VrS3VDtaXStnYO9x4CNm9kUAM1tvZhdWNpaI1JOBgQHi8ThDhWb+9aEhLtu0gss0tFR15RSIrwXb/V6w3gX8XcUSiUhdyefzRKNR5s6dyz/d18W81kY+dekrqh1LKK9AbHD3vyOYtM/dk0x8cR8RkcM2PDwMwO4YPLh7iOvPO5a5rZqMrxaUUyCyZtZMcHU3MzsGyFY0lYjUhWKxSDQaZfbs2Xz94S7mtTZw1Zma8q1WlLOT+lPAT4GVZnYz8Frg2oqmEpG6kEwmKRaLFMLN/PzpHq4+ey3NDZpvqVZMWiCsdHzZNkrXaXg1paGlv9DZ1CJyNCSTSUKhEHfvjJIrOO/avKrakWScSQuEu7uZ/cjdz+DFS4OKiBwViUSClpYW7nxmP+sWtXHc0tnVjiTjlLMP4iEzO73iSUSkruRyObLZLMVwI7/ZNcgbT1xa7UhygHL2QZwDvM/MdlGa0dUodS5UNETkiCUSCQAe7kyQLzpvPGlJlRPJgcopEJdXPIWI1J1kMkkkEuGu54ZYNLuJTSvbqx1JDlDOZH27piKIiNQPdyeZTNLY3Mq9z+7g8tNWEArp9Kpaozl0RWTKpdNpCoUCT/enSWYLvPFEDS/VIhUIEZlyiUQCM+OenTFmN0V49bELqx1JJqACISJTLh6P09jYxC9+289rj1tEY0RfRbXooPsgzGyYYHqNA++idBTT/IqlEpEZK5vNkslk2D0aYjCR5ZJTdDnRWjXZTmr1+UTkqBsaGiIUCvHzHTHmNEc47/hF1Y4kB3HQAuHuhfHrZjYfaB7X1FWpUCIycyWTSfKhRu54qo+3n7GSpojmXqpV5Vxy9GIzew7oBLYEt3dXOpiIzDzZbJZcLsedzw2TyRe55uy11Y4kkyhnz9DfAq8BnnX3VcCbgHsrGUpEZqZEIkE8k+ffHurm3I2LNPdSjSunQOTdvR8ImZm5+52AptkQkcOSSqUYGBjg9if7iaaLfOyi46sdSQ6hnKk2RsysDbgPuMXM+oBiZWOJyEySTqfZv38/9+8e5uvbR3n3q47h+KVzqh1LDqGcHsTlQBr4EKWhpf3AJRXMJCIzSCKRoKOjg1/vHORv7+3hrGMX87GLTqh2LClDOQXio+5ecPecu9/k7v8IfPhQDzKzVWZ2j5k9Y2ZPmdmfBu3zzexOM9sR3M4L2s3MPm9mO83sCU0xLjL9jY6Osn//fu7bNcz/+mUfZ61fwlev2UxLo45cmg7KKRBvnqDt4jIelwf+3N1PAM4CrjezE4EbgLvcfQNwV7AOcCGwIfi5DvhiGa8hIjUqHo/T3d3Nfc+P8Kl7e3nNhiV85erNuqToNDLZmdTvBz4AbDSzR8fdNRvYeqgndvduoDtYHjWzZ4AVwGXA64LNbqY0bPWXQfst7u7Ag2bWbmbLgucRkWkkkUiwf/9+fvHsEP/wwADnblzCl99zhorDNDPZTupbKf2F/7958a98gNHDvSa1ma0FTqN0HsWSsS99d+82s8XBZiuAjnEP6wzaVCBEppFYLEbH/i5u2bKfb/82yZtOWs7nrtyk4jANTXYm9TAwDLzTzF5B6cpyAL8Gyi4QZjYL+C7wIXePmR10zveJ7njJXFBmdh2lIShWr15dbgwRqbB0Os3AwADdg1H++Zf7+HVXkT+54Dg+dMEGXethmirnTOrrKfUmVgc/t5rZB8t5cjNroFQcvu7u3wuae81sWXD/Ml4sNp3AqnEPX8kE03m4+43uvtndNy9apDlcRGpBOp1m37599EVH+fhP9/JQH3z+qtP58Bs2qjhMY+XspH4/cKa7f8zdPwa8itK+iUlZqatwE/BMcOTTmNuBa4Lla4AfjGu/Ojia6SxgRPsfRGrf6OgonZ2dFDE+/eshdo+G+Pr7zuItp2qW1umunBPlDMiNW88x8XDQgV4DvAd40sweD9o+BnyaUi/kWmAf8M7gvjuAi4CdQBL4wzJeQ0SqyN3p7e0lHA7zlUeGeWhvlM9fdRpnrNHVAGaCyY5iirh7Hvh3SkcVfTe4662Ujj6alLvfx8ELyQUTbO/A9YdMLCI1I5PJUCgUuHtPhm891s2fnL+eS9VzmDEm60E8BJzu7v/HzO4Bfo/SF/4H3P3hKUknIjUrnU7T0dFB90iK/3t3J286aSl/9vqN1Y4lR9FkBeKFv/6DgqCiICJAqeewb98+3J1vbBumuaGBv3vrydohPcNMViAWmdlBp9Q4YMeziNSRnp4ezIxen8PPdu3khguPZ8GspmrHkqNssgIRBmZR3g5pEakT2WyWdDrNwoWL+NDXn2JFewvvffXaaseSCpisQHS7+6emLImITAupVAqAx7pSPNUV47NXnKqzpGeoyc6DUM9BRF4imUwSiUS47cle5rU2cPHJOmppppqsQLzkUFQRqW+pVIrR0VE80sidT/dyySnLaYyUc76tTEcH/Zd196GpDCIitW9wcJBwOMwjvQUy+SJvPX1FtSNJBan0i0hZ3J1kMsns2bO57fEejlnYxmmr2qsdSypIBUJEypJOp3F3YjnjwecHuXzTCiaZnVlmABUIESlLMpkE4GfPDuEOl5+mndMznQqEiJQllUrR2NjIbY/3cMaaeaxZ0FbtSFJhKhAickjFYpFUKkVXvMiOvjhvPU07p+tBOdN9i0idGx4eplgscteuBA1h45JTllU7kkwB9SBE5JASiQQNjU3cvn2A845bTHtrY7UjyRRQD0JEJjU4OEgqlWL3aIiBeIa36dyHuqEehIgclLszNDRES0sLP9sxytyWBs47fnG1Y8kUUYEQkYPKZrMUi0UaW2bxs6f7uPiUZTRFNDFfvVCBEJGDSiQSAPxm3yipXIHLdDnRuqICISIHlUgkaGpq4sfb+1g2t5lXrp1f7UgyhVQgRGRChUKBVCqFh5v45XP9XHLKMl1StM6oQIjIhJLJJO7Ob/bFyRWct2h4qe6oQIjIhOLxOOFwmDueHmTNglZOXjG32pFkiqlAiMhLuDuJRIIsDTywe5BLT12umVvrkE6UE5GXSKfTFAoF7uvIUHS4VMNLdUk9CBF5iUQigZlx+1MDnLxiLhuWzK52JKkCFQgR+R35fJ5oNEpvssD27rim1qhjKhAi8juGh4cpFArctStJJGQaXqpjKhAi8gJ3Z2RkhJQ38J+P9XH5aStYMKup2rGkSrSTWkReEI/HKRQK/OfjQ+DwZ2/YWO1IUkXqQYjIC4aHh+mL5/jOtj7ec/YaVrS3VDuSVJEKhIgAMDAwQCqV4htPDNPa2MD1562vdiSpsooVCDP7mpn1mdn2cW3zzexOM9sR3M4L2s3MPm9mO83sCTM7vVK5ROSlUqkUg4ODdMTy3PHsCNedu475bbpqXL2rZA/i34A3H9B2A3CXu28A7grWAS4ENgQ/1wFfrGAuERmnWCzS19dHOBzmq4+OsHBWE9eec0y1Y0kNqFiBcPdfAUMHNF8G3Bws3wxcPq79Fi95EGg3M10VXWQKDA8Pk06neT4R4cHnh/mT8zfQ1qTjV2Tq90EscfdugOB27NqFK4COcdt1Bm0vYWbXmdlWM9va399f0bAiM527E41GaW1t5Z9+1cHKeS1cdebqaseSGlErO6knmgXMJ9rQ3W90983uvnnRokUVjiUysyWTSfL5PA91Z9m+P8afv3EjjZFa+VqQapvqT0Lv2NBRcNsXtHcCq8ZttxLomuJsInUnkUiQKzif+cXznLR8Dpeeqmk15EVTXSBuB64Jlq8BfjCu/ergaKazgJGxoSgRqYxkMkk0GuUnz0bpimX4xFtOIqwrxsk4FdsTZWbfAF4HLDSzTuATwKeBW83sWmAf8M5g8zuAi4CdQBL4w0rlEpHS5UR7enqIpovc9Mggbzl1OWceo+tNy++qWIFw96sOctcFE2zrwPWVyiIiL3J3enp6yGSzfGFLP1iIGy48vtqxpAbpWDaROjM8PEw8Hud7z4zyy10xPv22kzWlhkxIhyuI1JFMJsPg4CD37orxlS19XH32Gq7UYa1yEOpBiNSJaDRKX18fD+we5v/+upc3nricj19yYrVjSQ1TgRCpA7FYjP1dPXx7Wx//vi3KmesW8/mrTiMS1iCCHJwKhMgMlk6nGRgY4KEd3dz6WC9b+uC9rzmWj154gk6Ik0NSgRCZgXK5HENDQ2z5bQfff7ybx3oytM1u5wvvPomLTtY0Z1IeFQiRGSSbzTIwMMDju3u47bFOtnZlaGyby4cvPZkrXrmKpki42hFlGlGBEJkBMpkMfX19PNMxwPcf388DHWmaWmbxwYtewR+ctYbmBhUGOXwqECLTWDKZZGRkhKf39XLbY938cm+SSHMr73/TJq45e62m7ZaXRZ8ekWlobOfzzq4BfrCtm/ufj5FpmMO1F5zCH52zltnNDdWOKDOACoTINFIsFhkYGODZfT388Ikefr5zlFyklfe+9lTe93vraG/VZULl6FGBEJkG0uk0Q0NDbN3ZzS+e7uH+fUmS4Vbec86JvP/cdSyY1VTtiDIDqUCI1Kixq70NDw/zyJ4Bbt/WzVN9WSLNbbzr3JP5w1evZfGc5mrHlBlMBUKkBqVSKfr6+ugdGuWrD+7nwX1x5s5t5yOXb+Btp6/QUUkyJVQgRGpMPB5n//79PNoR458f6GUoF+aGS07n3WetoUFTY8gUUoEQqRHFYpH+gUEe2dHJbdt6uHNfgZNWzOWWKzaxfvHsaseTOqQCITKFstks2VyeaDLLQCzFnr4onf0jdA/H6Ykm2DuYJJoLkWuczV9fchJXn71GE+pJ1ahAiBxl6XSaWCJJ13CK3V39dA3G6Ivn6ImlGYilGExkKRYdAAeyRGhpamTp/FmcffJyTj92GW84aSmzdJKbVJk+gSJHwN0pFAoMjcR4ak8fO3tH2D+coieaoGckyWAiCw55QmQ8QltTmOXtLaxavpSzFsxiQVsT82c1s2bxXNYtmqXzF6QmqUCIHIK7k81mSafTPN87wva9vezsibK7P0HHUJJU0ch7iOaGMMvmtbEBzei3AAALvklEQVR25TJ+b/E81sxv4Zgl7axbOIv21gbMrNpvReSwqECITKBYLJJMJukbHOLhHd1s64iyrXOEWCpHljBEmli/dC5veOVaNq1bwikr57KivUVFQGYUFQipa+5OLpcjlkjSOZSgazhJ50CMrv5hdvfHeX4wRbwYIdLYzKvWr+Ws9Ys4fc0CNi6ZpZ3HMuOpQEhdyOfzpWsljKbZ2RPl+d4ROgdH6BocpWckxVAi98K2RYxCuJljli3gknM2cs6Gxbxy7XxdgU3qjgqEzBjuTj6fJ51Os39wlOe6h9nbO0z3cIKukTTdIymSmQIABYxwpIGl82azbvUCzl88l9ULZ7Fy/izWLpzFwlmNGi6SuqcCIdNWoVAgl8vR0TvEU/v62NU7wvP9cfYMJBhJ5XAg5Q3Mamli1YI2zjhhOesWzWbd0rkct6ydZXOaCYVUBEQORgVCpoWxI4m6BmM8uaePHV2D7BkYZe9gguFEjgxhch5m6fzZnHDsWk5atYCTV7azYfFs5rXpEFKRI6ECQekC7x0dHUQaGtk5nGdX9xCjmSJzZ7WysL2N5kiIpnCIhpCTyeUZTeeJjiaJJVPEEimGE1mG0wXyboARDkEoFCEUDhE2I2RGOAxhK90XNgiHwoRCRiQUImROJBSiIRKiIRymIRKmIRKiMRKmMRKiqSFSuo2EaIpEaGoM09wQpqWxkebGCC1NEVoawrQ2RgjPgL+Ii8UiiUSCvX1RdvXG2Nk7yu7eYToGRhlOlnoGGSIsmjeHjWtWcdLKBZy8egEnLZ+jC+WIHEV1WSAymQzxeJz29nb279/P9n393LdjgMc6osTT+bKewymdBGWhCO1tTcxvDdNgYDiFAuSKabzoFNwpFosU3Sk6FIpQcCgUHfcixaK/sJ4vFktPfASKGA6Ew2GaImEaGyI0N4RLBaQxMu62gaZImKZIiOaGEI2REGZGsVCg6EXcoQjghrtTtBDhUIiGsBHCaQiXxu7BKRY9yF96bz72HseWi8F7f+H9O14s3RaKY9sXKBYKpDI54ukcyUyWVCZHLJ0nmS1QIIRjLG1v5dg1Kzlh5QJOWb2AV6xs15nGIhVWl//DEokEAwMDDAwMALCjP8Udz+c494SNvGHjPDatbmfx3Db6o3H6R1Nk8062UCRbgMaGCHNbGpg/u4V5bU20NoYn3Znp7mXfXywWyRWKZHJ5srkC6XyBbK5IJp8nnSuSzhXI5AtkcgUy2TyZXK60nMuTzuVJZ/Oks4VxyznSuQLpTIrR0dJzZgpFcvkimcLvFiN/4bZUCI4mMwiZYRYsY5gZFir1uCwUoqmhgdbmBtpa2pg/r5ETZrWxfvl8Tlw+lxOWzVExEKkCcz+6XwZTafPmzb5169YjemwikSAWi9Hc3ExD62wiIauLOfbz+Rd7SNlCkXSuCEAkXOophMwAf+FL3YtFcoUC2VwBQmGy+SK5fD74wjciISMU/BilYTRwwiGjIRwO7iv1UnRUkEhtMLNH3H3zobar2z/L2traaGtrq3aMKReJRMYtQ+shr1QZpokGaKloLBGpQTrzR0REJlRTBcLM3mxmz5rZTjO7odp5RETqWc0UCDMLA18ALgROBK4ysxOrm0pEpH7VTIEAzgR2uvtud88C3wQuq3ImEZG6VUsFYgXQMW69M2j7HWZ2nZltNbOt/f39UxZORKTe1FKBmOgYyJccg+vuN7r7ZnffvGjRoimIJSJSn2qpQHQCq8atrwS6qpRFRKTu1VKBeBjYYGbHmFkjcCVwe5UziYjUrZo6k9rMLgI+B4SBr7n73x5i+35g7xG+3EJg4AgfWw3KW1nKW1nKW1mHm3eNux9yjL6mCsRUMrOt5ZxqXiuUt7KUt7KUt7IqlbeWhphERKSGqECIiMiE6rlA3FjtAIdJeStLeStLeSurInnrdh+EiIhMrp57ECIiMom6LBC1OGusmX3NzPrMbPu4tvlmdqeZ7Qhu5wXtZmafD/I/YWanVyHvKjO7x8yeMbOnzOxPazmzmTWb2UNmti3I+8mg/Rgz2xLk/VZwDg5m1hSs7wzuXzuVeYMMYTN7zMx+VOtZgxx7zOxJM3vczLYGbTX5eQgytJvZd8zst8Hn+OxazWtmxwW/17GfmJl9qOJ53b2ufiidY7ELWAc0AtuAE2sg17nA6cD2cW3/B7ghWL4B+Ptg+SLgJ5SmJzkL2FKFvMuA04Pl2cBzlGbhrcnMwevOCpYbgC1BjluBK4P2LwF/HCx/EPhSsHwl8K0q/I4/DPwn8KNgvWazBq+9B1h4QFtNfh6CDDcD/yVYbgTaaznvuNxhoAdYU+m8VXmD1fwBzgZ+Nm79o8BHq50ryLL2gALxLLAsWF4GPBssfxm4aqLtqpj9B8AbpkNmoBV4FHgVpZOLIgd+NoCfAWcHy5FgO5vCjCuBu4DzgR8F/9FrMuu4zBMViJr8PABzgOcP/D3Vat4DMr4RuH8q8tbjEFNZs8bWiCXu3g0Q3C4O2mvqPQRDGqdR+qu8ZjMHQzaPA33AnZR6klF3H7tQ9/hML+QN7h8BFkxh3M8B/x0oBusLqN2sYxz4uZk9YmbXBW21+nlYB/QD/y8YxvuqmbXVcN7xrgS+ESxXNG89FoiyZo2tcTXzHsxsFvBd4EPuHpts0wnapjSzuxfcfROlv87PBE6YJFPV8prZJUCfuz8yvnmSPFX/3QZe4+6nU7ro1/Vmdu4k21Y7c4TSkO4X3f00IEFpiOZgqp23FKK03+lS4NuH2nSCtsPOW48FYjrNGttrZssAgtu+oL0m3oOZNVAqDl939+8FzTWdGcDdo8C9lMZm280sMkGmF/IG988FhqYo4muAS81sD6ULZ51PqUdRi1lf4O5dwW0f8H1KRbhWPw+dQKe7bwnWv0OpYNRq3jEXAo+6e2+wXtG89VggptOssbcD1wTL11Aa5x9rvzo4UuEsYGSsmzlVzMyAm4Bn3P0fx91Vk5nNbJGZtQfLLcDrgWeAe4B3HCTv2Pt4B3C3B4O5lebuH3X3le6+ltLn8253f3ctZh1jZm1mNntsmdI4+XZq9PPg7j1Ah5kdFzRdADxdq3nHuYoXh5fGclUubzV2slT7h9Ie/ucojUH/VbXzBJm+AXQDOUrV/1pK48h3ATuC2/nBtkbp+t27gCeBzVXIew6lLusTwOPBz0W1mhk4BXgsyLsd+HjQvg54CNhJqdveFLQ3B+s7g/vXVelz8TpePIqpZrMG2bYFP0+N/b+q1c9DkGETsDX4TNwGzKvxvK3AIDB3XFtF8+pMahERmVA9DjGJiEgZVCBERGRCKhAiIjIhFQgREZmQCoSIiExIBUJkHDMrHDBr5qSz/ZrZB8zs6qPwunvMbOHLfR6Ro0mHuYqMY2Zxd59VhdfdQ+lY9YGpfm2Rg1EPQqQMwV/4f2+la0o8ZGbrg/a/MbOPBMv/zcyeDubf/2bQNt/MbgvaHjSzU4L2BWb282CiuC8zbu4cM/uD4DUeN7Mvm1m4Cm9ZRAVC5AAtBwwxXTHuvpi7nwn8C6W5kQ50A3Cau58CfCBo+yTwWND2MeCWoP0TwH1emijudmA1gJmdAFxBaeK7TUABePfRfYsi5YkcehORupIKvpgn8o1xt5+d4P4ngK+b2W2Upm6A0pQkbwdw97uDnsNcSheIelvQ/mMzGw62vwA4A3i4NN0VLbw4AZvIlFKBECmfH2R5zMWUvvgvBf7azE5i8mmXJ3oOA25294++nKAiR4OGmETKd8W429+Mv8PMQsAqd7+H0oV+2oFZwK8IhojM7HXAgJeumzG+/UJKE8VBacK1d5jZ4uC++Wa2poLvSeSg1IMQ+V0twVXnxvzU3ccOdW0ysy2U/rC66oDHhYH/CIaPDPisu0fN7G8oXbXsCSDJi1MzfxL4hpk9CvwS2Afg7k+b2f+gdGW2EKXZfa8H9h7tNypyKDrMVaQMOgxV6pGGmEREZELqQYiIyITUgxARkQmpQIiIyIRUIEREZEIqECIiMiEVCBERmZAKhIiITOj/AwEoTB246kS/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(episode_rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Total rewards')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model-qn.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n",
      "total_reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "# Creating a gym env\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# A training graph session\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, 'checkpoints/model-qn.ckpt')    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Episodes/epochs\n",
    "    for _ in range(10):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        # Steps/batches\n",
    "        while True:\n",
    "            env.render()\n",
    "            action_logits = sess.run(model.actions_logits, feed_dict={model.states: np.reshape(state, [1, -1])})\n",
    "            action = np.argmax(action_logits)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        # Closing the env\n",
    "        print('total_reward: {}'.format(total_reward))\n",
    "# Close the env at the end\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

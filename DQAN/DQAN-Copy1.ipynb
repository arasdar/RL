{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQAN (Deep Q-Adverserial Nets): DQN (Deep Q-Nets) + GAN (Gen. Adv. Nets)\n",
    "\n",
    "In this notebook, we'll combine a DQN (deep Q-net) with GAN (generative adverserial net) that can learn to play games through reinforcement learning without any reward function. We'll call this network DQAN (deep Q adverserial net). \n",
    "Adverserial nets learn to maximize the current reward based the past rewards.\n",
    "Q-net learns to maximize the future rewards based on the current reward.\n",
    "Given a task and known when the task is done or failed, we should be able to learn the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN\n",
    "More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info\n",
      "[-6.10042299e-03 -1.71261127e-01 -1.11377864e-04  2.65194181e-01] 0 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00952565  0.02386241  0.00519251 -0.02752387] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.0090484   0.21890952  0.00464203 -0.31856399] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00467021  0.02372176 -0.00172925 -0.02442076] 0 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00419577  0.21886847 -0.00221767 -0.31764879] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 1.81597700e-04  4.14021936e-01 -8.57064259e-03 -6.11030261e-01] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.00846204  0.60926263 -0.02079125 -0.90640028] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.02064729  0.80465982 -0.03891925 -1.20554492] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.03674049  1.00026253 -0.06303015 -1.51016617] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.05674574  1.19608904 -0.09323348 -1.82184123] 1 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "rewards, states, actions, dones = [], [], [], []\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    states.append(state)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    dones.append(done)\n",
    "    print('state, action, reward, done, info')\n",
    "    print(state, action, reward, done, info)\n",
    "    if done:\n",
    "        print('state, action, reward, done, info')\n",
    "        print(state, action, reward, done, info)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        dones.append(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(10,) (10, 4) (10,) (10,)\n",
      "float64 float64 int64 bool\n",
      "1 0\n",
      "2\n",
      "1.0 1.0\n",
      "1.1960890396872554 -1.8218412331768141\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    # Given data\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    \n",
    "    # Actions as output\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # Target Q values for training\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    return states, next_states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.layers.dense(\n",
    "#     inputs, ????????????????????????\n",
    "#     units, ??????????????????????\n",
    "#     activation=None,\n",
    "#     use_bias=True, OOOOOOOOOOOOOOOOOOOOOOOK\n",
    "#     kernel_initializer=None,\n",
    "#     bias_initializer=tf.zeros_initializer(), OOOOOOOOOOOOOOOK\n",
    "#     kernel_regularizer=None,\n",
    "#     bias_regularizer=None,\n",
    "#     activity_regularizer=None,\n",
    "#     kernel_constraint=None,\n",
    "#     bias_constraint=None,\n",
    "#     trainable=True, ??????????????????\n",
    "#     name=None,\n",
    "#     reuse=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q function\n",
    "def generator(states, state_size, action_size, hidden_size, reuse=False, alpha=0.1): #training=True ~ batchnorm\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        #bn1 = tf.layers.batch_normalization(h1, training=training) #training=True ~ batchnorm\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        #bn2 = tf.layers.batch_normalization(h2, training=training) #training=True ~ batchnorm\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits_actions = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits_actions)\n",
    "\n",
    "        # Output layer\n",
    "        logits_next_states = tf.layers.dense(inputs=nl2, units=state_size, trainable=False)        \n",
    "        #predictions = tf.nn.softmax(logits_next_states)\n",
    "\n",
    "        # # Output layer\n",
    "        # logits = tf.layers.dense(inputs=nl2, units=(state_size + action_size))\n",
    "\n",
    "        # # Split the states and actions (opposite of fusion)\n",
    "        # logits_next_states, logits_actions = tf.split(value=logits, axis=1, num_or_size_splits=[state_size, action_size])\n",
    "\n",
    "        return logits_actions, logits_next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a reward function: Rt(St+1, at) or Rt(~St+1, ~at)\n",
    "def discriminator(next_states, actions, hidden_size, reuse=False, alpha=0.1): #training=True ~ batchnorm\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Stack/concatenate/fuse actions and states or \n",
    "        # predicted/reconstructed actions and states\n",
    "        x_fused = tf.concat(values=(next_states, actions), axis=1)\n",
    "        \n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=x_fused, units=hidden_size)\n",
    "        #bn1 = tf.layers.batch_normalization(h1, training=True)\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        #bn2 = tf.layers.batch_normalization(h2, training=True)\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)   \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # logits for loss and reward/prob/out\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qt(St, At) = Rt(St+1, At) + max(alpha*Qt+1(St+1))\n",
    "def model_loss(states, next_states, state_size, actions, action_size, hidden_size, targetQs, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param states: real current input states or observations given\n",
    "    :param actions: real actions given\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    # The fake/generated actions\n",
    "    actions_logits, next_states_logits = generator(states=states, state_size=state_size, hidden_size=hidden_size, \n",
    "                                              action_size=action_size)\n",
    "    #print(actions_logits.shape, next_states_logits.shape)\n",
    "    actions_fake = tf.nn.softmax(actions_logits)\n",
    "    next_states_fake = tf.sigmoid(x=next_states_logits)\n",
    "    d_logits_fake = discriminator(next_states=next_states_fake, actions=actions_fake, hidden_size=hidden_size, reuse=False)\n",
    "\n",
    "    # The real onehot encoded actions\n",
    "    actions_real = tf.one_hot(actions, action_size)\n",
    "    next_states_real = tf.sigmoid(x=next_states) \n",
    "    d_logits_real = discriminator(next_states=next_states_real, actions=actions_real, hidden_size=hidden_size, reuse=True)\n",
    "\n",
    "    # Training the rewarding function\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # Train the generate to maximize the current reward 0-1\n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "\n",
    "    # Train the generator to maximize the future rewards: Bellman equations: loss (targetQ - Q)^2\n",
    "    Qs = tf.reduce_sum(tf.multiply(actions_logits, actions_real), axis=1)\n",
    "    q_loss = tf.reduce_mean(tf.square(targetQs - Qs))\n",
    "\n",
    "    # The generated rewards for Bellman equation\n",
    "    rewards_fake = tf.sigmoid(d_logits_fake)\n",
    "    rewards_real = tf.sigmoid(d_logits_real)\n",
    "\n",
    "    return d_loss, g_loss, q_loss, actions_logits, Qs, rewards_fake, rewards_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, q_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator/Reward loss Tensor for reward function\n",
    "    :param g_loss: Generator/Q-value loss Tensor for action & next state predicton\n",
    "    :param q_loss: Value loss Tensor\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        q_opt = tf.train.AdamOptimizer(learning_rate).minimize(q_loss, var_list=g_vars)\n",
    "\n",
    "    return d_opt, g_opt, q_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQAN:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.next_states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "        #print(self.states, self.next_states, self.actions, self.targetQs)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.d_loss, self.g_loss, self.q_loss, self.actions_logits, self.Qs, self.rewards_fake, self.rewards_real = model_loss(\n",
    "            state_size=state_size, action_size=action_size, actions=self.actions, \n",
    "            states=self.states, next_states=self.next_states, \n",
    "            hidden_size=hidden_size, targetQs=self.targetQs)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.d_opt, self.g_opt, self.q_opt = model_opt(d_loss=self.d_loss, g_loss=self.g_loss, \n",
    "                                                       q_loss=self.q_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 200               # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64              # number of units in each Q-network hidden layer -- simulation\n",
    "state_size = 4                # number of units for the input state/observation -- simulation\n",
    "action_size = 2               # number of units for the output actions -- simulation\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 10                # experience mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = DQAN(action_size=action_size, hidden_size=hidden_size, state_size=state_size, \n",
    "                 learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 0 Total reward: 10.0 Average reward fake: 0.48005765676498413 Training d_loss: 1.3099 Training g_loss: 0.7401 Training q_loss: 0.4127 Explore P: 0.9990\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 1 Total reward: 18.0 Average reward fake: 0.4778939187526703 Training d_loss: 1.2042 Training g_loss: 0.7468 Training q_loss: 0.4495 Explore P: 0.9972\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 2 Total reward: 11.0 Average reward fake: 0.49697789549827576 Training d_loss: 1.3116 Training g_loss: 0.7172 Training q_loss: 1.7709 Explore P: 0.9961\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 3 Total reward: 22.0 Average reward fake: 0.4399871230125427 Training d_loss: 1.1919 Training g_loss: 0.8386 Training q_loss: 3.0942 Explore P: 0.9940\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 4 Total reward: 39.0 Average reward fake: 0.4332939088344574 Training d_loss: 1.3056 Training g_loss: 0.9097 Training q_loss: 53.9300 Explore P: 0.9901\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 5 Total reward: 9.0 Average reward fake: 0.39627689123153687 Training d_loss: 1.0148 Training g_loss: 0.9814 Training q_loss: 10.7686 Explore P: 0.9893\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 6 Total reward: 25.0 Average reward fake: 0.41913795471191406 Training d_loss: 1.2923 Training g_loss: 0.9490 Training q_loss: 19.3390 Explore P: 0.9868\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 7 Total reward: 11.0 Average reward fake: 0.394930362701416 Training d_loss: 1.2803 Training g_loss: 0.9477 Training q_loss: 30.5104 Explore P: 0.9857\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 8 Total reward: 20.0 Average reward fake: 0.4219962954521179 Training d_loss: 1.2375 Training g_loss: 0.9242 Training q_loss: 24.0388 Explore P: 0.9838\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 9 Total reward: 9.0 Average reward fake: 0.6143600344657898 Training d_loss: 1.6497 Training g_loss: 0.5499 Training q_loss: 66.3036 Explore P: 0.9829\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 10 Total reward: 13.0 Average reward fake: 0.42293763160705566 Training d_loss: 1.4420 Training g_loss: 0.8795 Training q_loss: 58.8784 Explore P: 0.9817\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 11 Total reward: 47.0 Average reward fake: 0.19943849742412567 Training d_loss: 0.5531 Training g_loss: 1.6911 Training q_loss: 153.7111 Explore P: 0.9771\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 12 Total reward: 36.0 Average reward fake: 0.19302907586097717 Training d_loss: 0.6156 Training g_loss: 1.8530 Training q_loss: 280.2135 Explore P: 0.9736\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 13 Total reward: 25.0 Average reward fake: 0.25636231899261475 Training d_loss: 0.6316 Training g_loss: 1.6541 Training q_loss: 918.8625 Explore P: 0.9712\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 14 Total reward: 33.0 Average reward fake: 0.12375567108392715 Training d_loss: 0.4714 Training g_loss: 3.1912 Training q_loss: 1487.0267 Explore P: 0.9681\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 15 Total reward: 51.0 Average reward fake: 0.18865251541137695 Training d_loss: 0.5550 Training g_loss: 4.1125 Training q_loss: 1474.5076 Explore P: 0.9632\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 16 Total reward: 23.0 Average reward fake: 0.09871076792478561 Training d_loss: 0.4522 Training g_loss: 5.6256 Training q_loss: 1738.4125 Explore P: 0.9610\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 17 Total reward: 9.0 Average reward fake: 0.117152139544487 Training d_loss: 0.3620 Training g_loss: 3.2477 Training q_loss: 2415.0894 Explore P: 0.9601\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 18 Total reward: 19.0 Average reward fake: 0.08140845596790314 Training d_loss: 0.2155 Training g_loss: 4.5016 Training q_loss: 2458.0950 Explore P: 0.9583\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 19 Total reward: 11.0 Average reward fake: 0.09953830391168594 Training d_loss: 0.3984 Training g_loss: 4.8573 Training q_loss: 3162.4424 Explore P: 0.9573\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 20 Total reward: 11.0 Average reward fake: 0.1756286323070526 Training d_loss: 0.5155 Training g_loss: 4.6181 Training q_loss: 3520.8960 Explore P: 0.9562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 21 Total reward: 14.0 Average reward fake: 0.1254643052816391 Training d_loss: 0.4114 Training g_loss: 4.8311 Training q_loss: 5058.1299 Explore P: 0.9549\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 22 Total reward: 23.0 Average reward fake: 0.044020310044288635 Training d_loss: 0.1672 Training g_loss: 6.2657 Training q_loss: 43458.6328 Explore P: 0.9528\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 23 Total reward: 30.0 Average reward fake: 0.07139793783426285 Training d_loss: 0.2057 Training g_loss: 6.9963 Training q_loss: 12295.9346 Explore P: 0.9499\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 24 Total reward: 46.0 Average reward fake: 0.044072020798921585 Training d_loss: 0.0853 Training g_loss: 6.1537 Training q_loss: 11020.7754 Explore P: 0.9456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 25 Total reward: 15.0 Average reward fake: 0.05179304629564285 Training d_loss: 0.1156 Training g_loss: 5.3909 Training q_loss: 7679.9219 Explore P: 0.9442\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 26 Total reward: 20.0 Average reward fake: 0.032715048640966415 Training d_loss: 0.0934 Training g_loss: 5.3382 Training q_loss: 18815.4727 Explore P: 0.9423\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 27 Total reward: 10.0 Average reward fake: 0.034544918686151505 Training d_loss: 0.0856 Training g_loss: 3.4841 Training q_loss: 17557.1973 Explore P: 0.9414\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 28 Total reward: 22.0 Average reward fake: 0.012021704576909542 Training d_loss: 0.0269 Training g_loss: 4.4737 Training q_loss: 143545.2812 Explore P: 0.9394\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 29 Total reward: 18.0 Average reward fake: 0.013034487143158913 Training d_loss: 0.0458 Training g_loss: 4.3628 Training q_loss: 19991.9492 Explore P: 0.9377\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 30 Total reward: 33.0 Average reward fake: 0.006668332032859325 Training d_loss: 0.0113 Training g_loss: 5.0219 Training q_loss: 45775.9180 Explore P: 0.9346\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 31 Total reward: 14.0 Average reward fake: 0.004337894730269909 Training d_loss: 0.0082 Training g_loss: 5.4824 Training q_loss: 42134.9180 Explore P: 0.9333\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 32 Total reward: 30.0 Average reward fake: 0.003140825778245926 Training d_loss: 0.0116 Training g_loss: 5.7517 Training q_loss: 52547.9492 Explore P: 0.9306\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 33 Total reward: 20.0 Average reward fake: 0.0024303558748215437 Training d_loss: 0.0044 Training g_loss: 6.0423 Training q_loss: 24771.3164 Explore P: 0.9287\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 34 Total reward: 12.0 Average reward fake: 0.002135917078703642 Training d_loss: 0.0055 Training g_loss: 6.1786 Training q_loss: 68130.7812 Explore P: 0.9276\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 35 Total reward: 15.0 Average reward fake: 0.0015875985845923424 Training d_loss: 0.0038 Training g_loss: 6.4474 Training q_loss: 65596.6406 Explore P: 0.9263\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 36 Total reward: 13.0 Average reward fake: 0.0019942820072174072 Training d_loss: 0.0031 Training g_loss: 6.2267 Training q_loss: 483118.3125 Explore P: 0.9251\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 37 Total reward: 16.0 Average reward fake: 0.0015905685722827911 Training d_loss: 0.0032 Training g_loss: 6.4531 Training q_loss: 109839.4531 Explore P: 0.9236\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 38 Total reward: 9.0 Average reward fake: 0.0015229893615469337 Training d_loss: 0.0048 Training g_loss: 6.4908 Training q_loss: 62100.9297 Explore P: 0.9228\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 39 Total reward: 13.0 Average reward fake: 0.0013774038525298238 Training d_loss: 0.0025 Training g_loss: 6.5995 Training q_loss: 796337.0000 Explore P: 0.9216\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 40 Total reward: 25.0 Average reward fake: 0.0015387911116704345 Training d_loss: 0.0030 Training g_loss: 6.5127 Training q_loss: 74780.2969 Explore P: 0.9193\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 41 Total reward: 25.0 Average reward fake: 0.002588269766420126 Training d_loss: 0.0046 Training g_loss: 5.9817 Training q_loss: 1760717.6250 Explore P: 0.9171\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 42 Total reward: 19.0 Average reward fake: 0.0016300417482852936 Training d_loss: 0.0037 Training g_loss: 6.4409 Training q_loss: 89774.9531 Explore P: 0.9153\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 43 Total reward: 29.0 Average reward fake: 0.0021965946070849895 Training d_loss: 0.0033 Training g_loss: 6.1091 Training q_loss: 104954.3125 Explore P: 0.9127\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 44 Total reward: 10.0 Average reward fake: 0.00199209526181221 Training d_loss: 0.0028 Training g_loss: 6.2474 Training q_loss: 129979.9844 Explore P: 0.9118\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 45 Total reward: 16.0 Average reward fake: 0.0013924210797995329 Training d_loss: 0.0023 Training g_loss: 6.5841 Training q_loss: 144550.3281 Explore P: 0.9104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 46 Total reward: 16.0 Average reward fake: 0.0011372400913387537 Training d_loss: 0.0017 Training g_loss: 6.7673 Training q_loss: 900339.3750 Explore P: 0.9089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 47 Total reward: 11.0 Average reward fake: 0.0013228629250079393 Training d_loss: 0.0021 Training g_loss: 6.6319 Training q_loss: 118175.3984 Explore P: 0.9079\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 48 Total reward: 21.0 Average reward fake: 0.0011037448421120644 Training d_loss: 0.0020 Training g_loss: 6.8287 Training q_loss: 258327.0938 Explore P: 0.9061\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 49 Total reward: 24.0 Average reward fake: 0.0007974323816597462 Training d_loss: 0.0127 Training g_loss: 7.1156 Training q_loss: 1570178.0000 Explore P: 0.9039\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 50 Total reward: 15.0 Average reward fake: 0.0009191660210490227 Training d_loss: 0.0016 Training g_loss: 6.9852 Training q_loss: 9446266.0000 Explore P: 0.9026\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 51 Total reward: 23.0 Average reward fake: 0.0007540752412751317 Training d_loss: 0.0018 Training g_loss: 7.1965 Training q_loss: 180196.0938 Explore P: 0.9005\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 52 Total reward: 18.0 Average reward fake: 0.0006361400010064244 Training d_loss: 0.0013 Training g_loss: 7.3719 Training q_loss: 115112.0469 Explore P: 0.8989\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 53 Total reward: 23.0 Average reward fake: 0.0006066871574148536 Training d_loss: 0.0011 Training g_loss: 7.4031 Training q_loss: 158798.9688 Explore P: 0.8969\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 54 Total reward: 14.0 Average reward fake: 0.0006130716647021472 Training d_loss: 0.0010 Training g_loss: 7.4059 Training q_loss: 1336757.8750 Explore P: 0.8956\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 55 Total reward: 16.0 Average reward fake: 0.0005211628740653396 Training d_loss: 0.0009 Training g_loss: 7.5712 Training q_loss: 230280.5938 Explore P: 0.8942\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 56 Total reward: 11.0 Average reward fake: 0.0004693219962064177 Training d_loss: 0.0009 Training g_loss: 7.6739 Training q_loss: 235131.8438 Explore P: 0.8932\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 57 Total reward: 37.0 Average reward fake: 0.0006143749924376607 Training d_loss: 0.0009 Training g_loss: 7.4094 Training q_loss: 513879.9375 Explore P: 0.8900\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 58 Total reward: 26.0 Average reward fake: 0.0004665933665819466 Training d_loss: 0.0010 Training g_loss: 7.6771 Training q_loss: 5733242.5000 Explore P: 0.8877\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 59 Total reward: 26.0 Average reward fake: 0.00036535499384626746 Training d_loss: 0.0006 Training g_loss: 7.9215 Training q_loss: 292863.1250 Explore P: 0.8854\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 60 Total reward: 12.0 Average reward fake: 0.000354286574292928 Training d_loss: 0.0007 Training g_loss: 7.9494 Training q_loss: 170917.1094 Explore P: 0.8844\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 61 Total reward: 47.0 Average reward fake: 0.00035407074028626084 Training d_loss: 0.0010 Training g_loss: 7.9541 Training q_loss: 2817238.5000 Explore P: 0.8803\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 62 Total reward: 29.0 Average reward fake: 0.00029793244902975857 Training d_loss: 0.0005 Training g_loss: 8.1229 Training q_loss: 181861.0938 Explore P: 0.8778\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 63 Total reward: 17.0 Average reward fake: 0.0004797196888830513 Training d_loss: 0.0007 Training g_loss: 7.6367 Training q_loss: 152211.4219 Explore P: 0.8763\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 64 Total reward: 30.0 Average reward fake: 0.00036326824920251966 Training d_loss: 0.0013 Training g_loss: 7.9277 Training q_loss: 4092427.2500 Explore P: 0.8737\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 65 Total reward: 22.0 Average reward fake: 0.00032272207317873836 Training d_loss: 0.0005 Training g_loss: 8.0457 Training q_loss: 226556.0781 Explore P: 0.8718\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 66 Total reward: 22.0 Average reward fake: 0.0002787872508633882 Training d_loss: 0.0007 Training g_loss: 8.1923 Training q_loss: 4243229.0000 Explore P: 0.8699\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 67 Total reward: 10.0 Average reward fake: 0.0002898280508816242 Training d_loss: 0.0005 Training g_loss: 8.1087 Training q_loss: 175501.3906 Explore P: 0.8690\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 68 Total reward: 23.0 Average reward fake: 0.0004127916763536632 Training d_loss: 0.0006 Training g_loss: 7.7750 Training q_loss: 5413821.0000 Explore P: 0.8671\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 69 Total reward: 63.0 Average reward fake: 0.0003314934147056192 Training d_loss: 0.0005 Training g_loss: 8.0191 Training q_loss: 100630.0625 Explore P: 0.8617\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 70 Total reward: 61.0 Average reward fake: 0.00028426924836821854 Training d_loss: 0.0004 Training g_loss: 8.1758 Training q_loss: 113848.3281 Explore P: 0.8565\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 71 Total reward: 31.0 Average reward fake: 0.00021442133584059775 Training d_loss: 0.0003 Training g_loss: 8.4570 Training q_loss: 114847.3594 Explore P: 0.8539\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 72 Total reward: 19.0 Average reward fake: 0.00018255450413562357 Training d_loss: 0.0003 Training g_loss: 8.6163 Training q_loss: 11407422.0000 Explore P: 0.8523\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 73 Total reward: 14.0 Average reward fake: 0.00018630245176609606 Training d_loss: 0.0004 Training g_loss: 8.5825 Training q_loss: 93163.7109 Explore P: 0.8511\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 74 Total reward: 17.0 Average reward fake: 0.0001816776639316231 Training d_loss: 0.0003 Training g_loss: 8.6197 Training q_loss: 1851880.6250 Explore P: 0.8497\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 75 Total reward: 16.0 Average reward fake: 0.00017732536070980132 Training d_loss: 0.0003 Training g_loss: 8.5869 Training q_loss: 4466384.0000 Explore P: 0.8483\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 76 Total reward: 13.0 Average reward fake: 0.00027170396060682833 Training d_loss: 0.0003 Training g_loss: 8.2031 Training q_loss: 123053.7109 Explore P: 0.8472\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 77 Total reward: 19.0 Average reward fake: 0.00024866656167432666 Training d_loss: 0.0004 Training g_loss: 8.3108 Training q_loss: 85648.0781 Explore P: 0.8456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 78 Total reward: 45.0 Average reward fake: 0.0003285272396169603 Training d_loss: 0.0004 Training g_loss: 8.0332 Training q_loss: 6979693.5000 Explore P: 0.8419\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 79 Total reward: 19.0 Average reward fake: 0.0002398686483502388 Training d_loss: 0.0003 Training g_loss: 8.3504 Training q_loss: 62977.6484 Explore P: 0.8403\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 80 Total reward: 32.0 Average reward fake: 0.0001666890166234225 Training d_loss: 0.0002 Training g_loss: 8.7094 Training q_loss: 68090.1953 Explore P: 0.8377\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 81 Total reward: 20.0 Average reward fake: 0.00021210114937275648 Training d_loss: 0.0003 Training g_loss: 8.4473 Training q_loss: 30648.7930 Explore P: 0.8360\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 82 Total reward: 9.0 Average reward fake: 0.0002244631468784064 Training d_loss: 0.0003 Training g_loss: 8.4047 Training q_loss: 52735.1484 Explore P: 0.8353\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 83 Total reward: 33.0 Average reward fake: 0.00019856281869579107 Training d_loss: 0.0003 Training g_loss: 8.5355 Training q_loss: 19716.1992 Explore P: 0.8325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 84 Total reward: 41.0 Average reward fake: 0.00014820022624917328 Training d_loss: 0.0002 Training g_loss: 8.8276 Training q_loss: 2799317.2500 Explore P: 0.8292\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 85 Total reward: 12.0 Average reward fake: 0.00013324691099114716 Training d_loss: 0.0002 Training g_loss: 8.9301 Training q_loss: 37504.3164 Explore P: 0.8282\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 86 Total reward: 59.0 Average reward fake: 0.0001576855720486492 Training d_loss: 0.0003 Training g_loss: 8.7597 Training q_loss: 15210.2637 Explore P: 0.8234\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 87 Total reward: 29.0 Average reward fake: 0.00015038037963677198 Training d_loss: 0.0002 Training g_loss: 8.8112 Training q_loss: 2076452.7500 Explore P: 0.8210\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 88 Total reward: 16.0 Average reward fake: 0.00012964544293936342 Training d_loss: 0.0009 Training g_loss: 8.9533 Training q_loss: 2730950.2500 Explore P: 0.8197\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 89 Total reward: 19.0 Average reward fake: 0.00012185259402031079 Training d_loss: 0.0002 Training g_loss: 9.0196 Training q_loss: 2019602.6250 Explore P: 0.8182\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 90 Total reward: 23.0 Average reward fake: 0.00011521080887177959 Training d_loss: 0.0002 Training g_loss: 9.0618 Training q_loss: 2167932.7500 Explore P: 0.8163\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 91 Total reward: 24.0 Average reward fake: 0.00011241992615396157 Training d_loss: 0.0001 Training g_loss: 9.0927 Training q_loss: 2533566.5000 Explore P: 0.8144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 92 Total reward: 27.0 Average reward fake: 0.00010537625348661095 Training d_loss: 0.0001 Training g_loss: 9.1640 Training q_loss: 2163139.5000 Explore P: 0.8122\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 93 Total reward: 14.0 Average reward fake: 0.00010560762893874198 Training d_loss: 0.0002 Training g_loss: 9.1154 Training q_loss: 2067997.7500 Explore P: 0.8111\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 94 Total reward: 40.0 Average reward fake: 0.00016898738977033645 Training d_loss: 0.0002 Training g_loss: 8.7011 Training q_loss: 13809.4561 Explore P: 0.8079\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 95 Total reward: 12.0 Average reward fake: 0.00014049370656721294 Training d_loss: 0.0002 Training g_loss: 8.8850 Training q_loss: 8870.8096 Explore P: 0.8070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 96 Total reward: 10.0 Average reward fake: 0.00011882609396707267 Training d_loss: 0.0002 Training g_loss: 9.0511 Training q_loss: 1850792.6250 Explore P: 0.8062\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 97 Total reward: 21.0 Average reward fake: 0.00013289839262142777 Training d_loss: 0.0002 Training g_loss: 8.9245 Training q_loss: 6158.4180 Explore P: 0.8045\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 98 Total reward: 35.0 Average reward fake: 0.00010925203969236463 Training d_loss: 0.0002 Training g_loss: 9.1299 Training q_loss: 11220.7275 Explore P: 0.8017\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 99 Total reward: 24.0 Average reward fake: 9.255595796275884e-05 Training d_loss: 0.0002 Training g_loss: 9.2942 Training q_loss: 7031.7900 Explore P: 0.7998\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 100 Total reward: 35.0 Average reward fake: 9.012246300699189e-05 Training d_loss: 0.0001 Training g_loss: 9.3220 Training q_loss: 2962.7466 Explore P: 0.7971\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 101 Total reward: 16.0 Average reward fake: 8.474201604258269e-05 Training d_loss: 0.0001 Training g_loss: 9.3774 Training q_loss: 3428898.5000 Explore P: 0.7958\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 102 Total reward: 33.0 Average reward fake: 7.030439155641943e-05 Training d_loss: 0.0001 Training g_loss: 9.5672 Training q_loss: 1436.3698 Explore P: 0.7932\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 103 Total reward: 20.0 Average reward fake: 7.201531116152182e-05 Training d_loss: 0.0001 Training g_loss: 9.5358 Training q_loss: 1354581.7500 Explore P: 0.7916\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 104 Total reward: 13.0 Average reward fake: 6.992997805355117e-05 Training d_loss: 0.0001 Training g_loss: 9.5704 Training q_loss: 4997111.0000 Explore P: 0.7906\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 105 Total reward: 21.0 Average reward fake: 9.805082663660869e-05 Training d_loss: 0.0001 Training g_loss: 9.2141 Training q_loss: 1819.9375 Explore P: 0.7890\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 106 Total reward: 9.0 Average reward fake: 0.00010414615826448426 Training d_loss: 0.0001 Training g_loss: 9.1708 Training q_loss: 2992.2222 Explore P: 0.7883\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 107 Total reward: 33.0 Average reward fake: 7.79314068495296e-05 Training d_loss: 0.0001 Training g_loss: 9.4674 Training q_loss: 1272107.0000 Explore P: 0.7857\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 108 Total reward: 23.0 Average reward fake: 6.98727963026613e-05 Training d_loss: 0.0001 Training g_loss: 9.5750 Training q_loss: 3538.4751 Explore P: 0.7839\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 109 Total reward: 13.0 Average reward fake: 6.470481457654387e-05 Training d_loss: 0.0001 Training g_loss: 9.6509 Training q_loss: 1794.2076 Explore P: 0.7829\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 110 Total reward: 18.0 Average reward fake: 6.517775182146579e-05 Training d_loss: 0.0001 Training g_loss: 9.6399 Training q_loss: 2182.4507 Explore P: 0.7816\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 111 Total reward: 40.0 Average reward fake: 0.00012195452291052788 Training d_loss: 0.0001 Training g_loss: 8.9924 Training q_loss: 3862.1926 Explore P: 0.7785\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 112 Total reward: 28.0 Average reward fake: 0.0001086460761143826 Training d_loss: 0.0001 Training g_loss: 9.1408 Training q_loss: 3078.1262 Explore P: 0.7763\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 113 Total reward: 9.0 Average reward fake: 9.372133354190737e-05 Training d_loss: 0.0001 Training g_loss: 9.2870 Training q_loss: 3300.5469 Explore P: 0.7756\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 114 Total reward: 9.0 Average reward fake: 8.543975127395242e-05 Training d_loss: 0.0001 Training g_loss: 9.3788 Training q_loss: 1008210.5000 Explore P: 0.7749\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 115 Total reward: 12.0 Average reward fake: 8.103382424451411e-05 Training d_loss: 0.0001 Training g_loss: 9.4269 Training q_loss: 2504.4458 Explore P: 0.7740\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 116 Total reward: 9.0 Average reward fake: 9.213019802700728e-05 Training d_loss: 0.0001 Training g_loss: 9.2789 Training q_loss: 2503.7480 Explore P: 0.7733\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 117 Total reward: 21.0 Average reward fake: 8.504423021804541e-05 Training d_loss: 0.0001 Training g_loss: 9.3800 Training q_loss: 892137.1250 Explore P: 0.7717\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 118 Total reward: 13.0 Average reward fake: 7.96407475718297e-05 Training d_loss: 0.0001 Training g_loss: 9.4485 Training q_loss: 873454.3750 Explore P: 0.7708\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 119 Total reward: 32.0 Average reward fake: 6.262955139391124e-05 Training d_loss: 0.0001 Training g_loss: 9.6849 Training q_loss: 3330.0591 Explore P: 0.7683\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 120 Total reward: 12.0 Average reward fake: 5.90644012845587e-05 Training d_loss: 0.0001 Training g_loss: 9.7407 Training q_loss: 766215.0625 Explore P: 0.7674\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 121 Total reward: 14.0 Average reward fake: 5.4412055760622025e-05 Training d_loss: 0.0001 Training g_loss: 9.8244 Training q_loss: 746771.1875 Explore P: 0.7664\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 122 Total reward: 12.0 Average reward fake: 5.215513374423608e-05 Training d_loss: 0.0001 Training g_loss: 9.8661 Training q_loss: 1596.7898 Explore P: 0.7654\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 123 Total reward: 14.0 Average reward fake: 4.847965465160087e-05 Training d_loss: 0.0001 Training g_loss: 9.9382 Training q_loss: 665918.3125 Explore P: 0.7644\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 124 Total reward: 19.0 Average reward fake: 1.5459827409358695e-06 Training d_loss: 0.2044 Training g_loss: 13.2645 Training q_loss: 1352029.2500 Explore P: 0.7630\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 125 Total reward: 14.0 Average reward fake: 1.0067141374747735e-05 Training d_loss: 0.0036 Training g_loss: 11.4284 Training q_loss: 8967.7842 Explore P: 0.7619\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 126 Total reward: 9.0 Average reward fake: 1.670744313742034e-05 Training d_loss: 0.0005 Training g_loss: 10.9655 Training q_loss: 676488.8750 Explore P: 0.7612\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 127 Total reward: 10.0 Average reward fake: 2.1240724890958518e-05 Training d_loss: 0.0023 Training g_loss: 10.7453 Training q_loss: 664887.0000 Explore P: 0.7605\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 128 Total reward: 16.0 Average reward fake: 2.4526534616597928e-05 Training d_loss: 0.0015 Training g_loss: 10.6084 Training q_loss: 4636.3179 Explore P: 0.7593\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 129 Total reward: 33.0 Average reward fake: 3.5410696000326425e-05 Training d_loss: 0.0002 Training g_loss: 10.2398 Training q_loss: 1198.1124 Explore P: 0.7568\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 130 Total reward: 28.0 Average reward fake: 3.953780105803162e-05 Training d_loss: 0.0000 Training g_loss: 10.1372 Training q_loss: 1902.0732 Explore P: 0.7547\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 131 Total reward: 21.0 Average reward fake: 4.000489934696816e-05 Training d_loss: 0.0008 Training g_loss: 10.1262 Training q_loss: 1243.9797 Explore P: 0.7532\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 132 Total reward: 21.0 Average reward fake: 4.130239176447503e-05 Training d_loss: 0.0006 Training g_loss: 10.0931 Training q_loss: 415297.8438 Explore P: 0.7516\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 133 Total reward: 22.0 Average reward fake: 4.591931792674586e-05 Training d_loss: 0.0001 Training g_loss: 9.9869 Training q_loss: 972.1017 Explore P: 0.7500\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 134 Total reward: 10.0 Average reward fake: 4.6531204134225845e-05 Training d_loss: 0.0001 Training g_loss: 9.9745 Training q_loss: 824.5890 Explore P: 0.7492\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 135 Total reward: 10.0 Average reward fake: 4.6958313760114834e-05 Training d_loss: 0.0002 Training g_loss: 9.9618 Training q_loss: 1018423.0000 Explore P: 0.7485\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 136 Total reward: 9.0 Average reward fake: 4.852856363868341e-05 Training d_loss: 0.0001 Training g_loss: 9.9313 Training q_loss: 1334.0887 Explore P: 0.7478\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 137 Total reward: 17.0 Average reward fake: 4.899699706584215e-05 Training d_loss: 0.0005 Training g_loss: 9.9236 Training q_loss: 1149776.6250 Explore P: 0.7466\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 138 Total reward: 22.0 Average reward fake: 4.941398583468981e-05 Training d_loss: 0.0004 Training g_loss: 9.9152 Training q_loss: 755.8197 Explore P: 0.7450\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 139 Total reward: 21.0 Average reward fake: 4.993587572243996e-05 Training d_loss: 0.0005 Training g_loss: 9.9046 Training q_loss: 512653.1875 Explore P: 0.7434\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 140 Total reward: 36.0 Average reward fake: 5.1233044359833e-05 Training d_loss: 0.0002 Training g_loss: 9.8781 Training q_loss: 957.5565 Explore P: 0.7408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 141 Total reward: 14.0 Average reward fake: 5.04097442899365e-05 Training d_loss: 0.0004 Training g_loss: 9.8977 Training q_loss: 3315.3137 Explore P: 0.7398\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 142 Total reward: 12.0 Average reward fake: 5.152641097083688e-05 Training d_loss: 0.0002 Training g_loss: 9.8737 Training q_loss: 1031.7040 Explore P: 0.7389\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 143 Total reward: 13.0 Average reward fake: 5.1398383220657706e-05 Training d_loss: 0.0001 Training g_loss: 9.8763 Training q_loss: 890859.0000 Explore P: 0.7379\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 144 Total reward: 10.0 Average reward fake: 5.332934597390704e-05 Training d_loss: 0.0001 Training g_loss: 9.8367 Training q_loss: 246187.5000 Explore P: 0.7372\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 145 Total reward: 32.0 Average reward fake: 5.4204894695430994e-05 Training d_loss: 0.0001 Training g_loss: 9.8231 Training q_loss: 1780.2574 Explore P: 0.7349\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 146 Total reward: 17.0 Average reward fake: 5.404842158895917e-05 Training d_loss: 0.0001 Training g_loss: 9.8237 Training q_loss: 905.3538 Explore P: 0.7336\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 147 Total reward: 13.0 Average reward fake: 5.456405779113993e-05 Training d_loss: 0.0002 Training g_loss: 9.8162 Training q_loss: 430238.8125 Explore P: 0.7327\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 148 Total reward: 14.0 Average reward fake: 0.0017659884179010987 Training d_loss: 0.0018 Training g_loss: 9.1821 Training q_loss: 4364.4019 Explore P: 0.7317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 149 Total reward: 16.0 Average reward fake: 5.8172365243081003e-05 Training d_loss: 0.0001 Training g_loss: 9.7517 Training q_loss: 2021.7305 Explore P: 0.7305\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 150 Total reward: 11.0 Average reward fake: 5.842769314767793e-05 Training d_loss: 0.0001 Training g_loss: 9.7479 Training q_loss: 2439.0415 Explore P: 0.7298\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 151 Total reward: 16.0 Average reward fake: 5.812627568957396e-05 Training d_loss: 0.0004 Training g_loss: 9.7532 Training q_loss: 277276.6875 Explore P: 0.7286\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 152 Total reward: 18.0 Average reward fake: 5.8945781347574666e-05 Training d_loss: 0.0002 Training g_loss: 9.7384 Training q_loss: 1379.9617 Explore P: 0.7273\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 153 Total reward: 12.0 Average reward fake: 5.9088524722028524e-05 Training d_loss: 0.0002 Training g_loss: 9.7359 Training q_loss: 1111136.0000 Explore P: 0.7264\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 154 Total reward: 14.0 Average reward fake: 5.910253821639344e-05 Training d_loss: 0.0001 Training g_loss: 9.7365 Training q_loss: 1896.8802 Explore P: 0.7254\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 155 Total reward: 21.0 Average reward fake: 5.853482798556797e-05 Training d_loss: 0.0001 Training g_loss: 9.7466 Training q_loss: 1215.9594 Explore P: 0.7239\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 156 Total reward: 11.0 Average reward fake: 5.79532643314451e-05 Training d_loss: 0.0002 Training g_loss: 9.7569 Training q_loss: 2443.6821 Explore P: 0.7232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 157 Total reward: 28.0 Average reward fake: 5.2853509259875864e-05 Training d_loss: 0.0001 Training g_loss: 9.8520 Training q_loss: 3854.2312 Explore P: 0.7212\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 158 Total reward: 9.0 Average reward fake: 4.958756471751258e-05 Training d_loss: 0.0001 Training g_loss: 9.9181 Training q_loss: 1102654.5000 Explore P: 0.7205\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 159 Total reward: 16.0 Average reward fake: 4.676559183280915e-05 Training d_loss: 0.0003 Training g_loss: 9.9721 Training q_loss: 3011.4429 Explore P: 0.7194\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 160 Total reward: 26.0 Average reward fake: 3.934705091523938e-05 Training d_loss: 0.0002 Training g_loss: 10.1528 Training q_loss: 3393.2332 Explore P: 0.7175\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 161 Total reward: 11.0 Average reward fake: 3.6654804716818035e-05 Training d_loss: 0.0001 Training g_loss: 10.2176 Training q_loss: 4243.1094 Explore P: 0.7168\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 162 Total reward: 20.0 Average reward fake: 0.0008860150119289756 Training d_loss: 0.0009 Training g_loss: 9.7268 Training q_loss: 9664.5371 Explore P: 0.7154\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 163 Total reward: 11.0 Average reward fake: 3.369493060745299e-05 Training d_loss: 0.0001 Training g_loss: 10.2997 Training q_loss: 4675.1138 Explore P: 0.7146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 164 Total reward: 22.0 Average reward fake: 0.10002560913562775 Training d_loss: 1.0515 Training g_loss: 9.3975 Training q_loss: 12643.4473 Explore P: 0.7130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 165 Total reward: 18.0 Average reward fake: 1.680731656961143e-05 Training d_loss: 0.0002 Training g_loss: 11.0023 Training q_loss: 11939.8223 Explore P: 0.7118\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 166 Total reward: 10.0 Average reward fake: 1.5904170140856877e-05 Training d_loss: 0.0002 Training g_loss: 11.0515 Training q_loss: 5701.1772 Explore P: 0.7111\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 167 Total reward: 13.0 Average reward fake: 1.5636753232683986e-05 Training d_loss: 0.0004 Training g_loss: 11.0658 Training q_loss: 10432.8408 Explore P: 0.7102\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 168 Total reward: 16.0 Average reward fake: 1.1932793313462753e-05 Training d_loss: 0.0011 Training g_loss: 11.3458 Training q_loss: 13321.8066 Explore P: 0.7090\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 169 Total reward: 16.0 Average reward fake: 7.965845725266263e-05 Training d_loss: 0.0008 Training g_loss: 10.9117 Training q_loss: 11607.0898 Explore P: 0.7079\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 170 Total reward: 44.0 Average reward fake: 0.09999996423721313 Training d_loss: 0.9476 Training g_loss: 10.5270 Training q_loss: 913822.8125 Explore P: 0.7049\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 171 Total reward: 9.0 Average reward fake: 1.2502493518695701e-05 Training d_loss: 0.0115 Training g_loss: 11.8979 Training q_loss: 9911.5332 Explore P: 0.7042\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 172 Total reward: 10.0 Average reward fake: 0.10000340640544891 Training d_loss: 1.5630 Training g_loss: 11.2642 Training q_loss: 1599865.5000 Explore P: 0.7035\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 173 Total reward: 10.0 Average reward fake: 5.2329824029584415e-06 Training d_loss: 0.0168 Training g_loss: 12.0862 Training q_loss: 1108904.2500 Explore P: 0.7028\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 174 Total reward: 19.0 Average reward fake: 0.09930630028247833 Training d_loss: 0.5858 Training g_loss: 9.6380 Training q_loss: 22722.6992 Explore P: 0.7015\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 175 Total reward: 19.0 Average reward fake: 0.09822160750627518 Training d_loss: 0.4207 Training g_loss: 9.3656 Training q_loss: 1326277.8750 Explore P: 0.7002\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 176 Total reward: 12.0 Average reward fake: 3.248210850870237e-05 Training d_loss: 0.0247 Training g_loss: 10.3291 Training q_loss: 18593.6445 Explore P: 0.6994\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 177 Total reward: 11.0 Average reward fake: 4.6595814637839794e-05 Training d_loss: 0.0121 Training g_loss: 9.9859 Training q_loss: 1167765.0000 Explore P: 0.6986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 178 Total reward: 15.0 Average reward fake: 0.07201595604419708 Training d_loss: 0.1926 Training g_loss: 9.3549 Training q_loss: 19721.3496 Explore P: 0.6976\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 179 Total reward: 9.0 Average reward fake: 0.17044799029827118 Training d_loss: 0.3856 Training g_loss: 7.4824 Training q_loss: 25489.1992 Explore P: 0.6970\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 180 Total reward: 24.0 Average reward fake: 0.00010674933582777157 Training d_loss: 0.0276 Training g_loss: 9.0696 Training q_loss: 22277.0254 Explore P: 0.6953\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 181 Total reward: 14.0 Average reward fake: 0.00017139238480012864 Training d_loss: 0.0782 Training g_loss: 8.9771 Training q_loss: 36203.5195 Explore P: 0.6944\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 182 Total reward: 16.0 Average reward fake: 0.05844586342573166 Training d_loss: 0.0855 Training g_loss: 6.2110 Training q_loss: 1503156.5000 Explore P: 0.6933\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 183 Total reward: 21.0 Average reward fake: 0.002444095443934202 Training d_loss: 0.0313 Training g_loss: 7.5318 Training q_loss: 35630.4883 Explore P: 0.6918\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 184 Total reward: 9.0 Average reward fake: 0.000942157581448555 Training d_loss: 0.0219 Training g_loss: 6.9303 Training q_loss: 21303.0254 Explore P: 0.6912\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 185 Total reward: 13.0 Average reward fake: 0.06985291838645935 Training d_loss: 0.1364 Training g_loss: 6.7142 Training q_loss: 51322.5625 Explore P: 0.6903\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 186 Total reward: 12.0 Average reward fake: 0.0009387337486259639 Training d_loss: 0.0337 Training g_loss: 6.9495 Training q_loss: 27173.8555 Explore P: 0.6895\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 187 Total reward: 26.0 Average reward fake: 0.001739071449264884 Training d_loss: 0.0682 Training g_loss: 6.3757 Training q_loss: 719998.1250 Explore P: 0.6878\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 188 Total reward: 15.0 Average reward fake: 0.09165067225694656 Training d_loss: 0.2229 Training g_loss: 4.7539 Training q_loss: 27075.1094 Explore P: 0.6868\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 189 Total reward: 8.0 Average reward fake: 0.0033498373813927174 Training d_loss: 0.0377 Training g_loss: 5.7521 Training q_loss: 25326.5039 Explore P: 0.6862\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 190 Total reward: 11.0 Average reward fake: 0.0018023947486653924 Training d_loss: 0.0366 Training g_loss: 6.7169 Training q_loss: 96081.2344 Explore P: 0.6855\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 191 Total reward: 26.0 Average reward fake: 0.0014668602962046862 Training d_loss: 0.0130 Training g_loss: 6.5446 Training q_loss: 40009.1797 Explore P: 0.6837\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 192 Total reward: 15.0 Average reward fake: 0.006818657275289297 Training d_loss: 0.0290 Training g_loss: 6.0003 Training q_loss: 35485.1484 Explore P: 0.6827\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 193 Total reward: 15.0 Average reward fake: 0.001583373756147921 Training d_loss: 0.0082 Training g_loss: 6.4607 Training q_loss: 928680.8125 Explore P: 0.6817\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 194 Total reward: 27.0 Average reward fake: 0.0007188314339146018 Training d_loss: 0.0170 Training g_loss: 7.2839 Training q_loss: 110242.4375 Explore P: 0.6799\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 195 Total reward: 10.0 Average reward fake: 0.053680598735809326 Training d_loss: 0.0840 Training g_loss: 6.7644 Training q_loss: 36812.8516 Explore P: 0.6792\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 196 Total reward: 15.0 Average reward fake: 0.005345392040908337 Training d_loss: 0.0137 Training g_loss: 6.6647 Training q_loss: 41718.8633 Explore P: 0.6782\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 197 Total reward: 24.0 Average reward fake: 0.0004896777682006359 Training d_loss: 0.0258 Training g_loss: 8.5217 Training q_loss: 43078.8047 Explore P: 0.6766\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 198 Total reward: 13.0 Average reward fake: 0.0002611482050269842 Training d_loss: 0.0069 Training g_loss: 8.2018 Training q_loss: 47380.4609 Explore P: 0.6757\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 199 Total reward: 8.0 Average reward fake: 0.00358828017488122 Training d_loss: 0.0091 Training g_loss: 7.3609 Training q_loss: 1029730.0000 Explore P: 0.6752\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 200 Total reward: 9.0 Average reward fake: 0.0001931466395035386 Training d_loss: 0.0223 Training g_loss: 8.6887 Training q_loss: 50265.3477 Explore P: 0.6746\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 201 Total reward: 13.0 Average reward fake: 0.008055253885686398 Training d_loss: 0.0156 Training g_loss: 7.7731 Training q_loss: 1912908.0000 Explore P: 0.6737\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 202 Total reward: 22.0 Average reward fake: 0.00016952489386312664 Training d_loss: 0.0032 Training g_loss: 8.8695 Training q_loss: 46900.4609 Explore P: 0.6723\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 203 Total reward: 10.0 Average reward fake: 0.0833156555891037 Training d_loss: 0.1788 Training g_loss: 8.3684 Training q_loss: 47625.0547 Explore P: 0.6716\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 204 Total reward: 10.0 Average reward fake: 0.0006900394218973815 Training d_loss: 0.0250 Training g_loss: 9.0822 Training q_loss: 58497.5703 Explore P: 0.6710\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 205 Total reward: 20.0 Average reward fake: 0.003104089293628931 Training d_loss: 0.0109 Training g_loss: 9.7451 Training q_loss: 38496.0430 Explore P: 0.6696\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 206 Total reward: 24.0 Average reward fake: 2.3405522370012477e-05 Training d_loss: 0.0016 Training g_loss: 10.6443 Training q_loss: 58222.1797 Explore P: 0.6681\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 207 Total reward: 35.0 Average reward fake: 2.4321168893948197e-05 Training d_loss: 0.0038 Training g_loss: 10.6431 Training q_loss: 44536.5078 Explore P: 0.6658\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 208 Total reward: 15.0 Average reward fake: 0.0023481224197894335 Training d_loss: 0.0067 Training g_loss: 8.9708 Training q_loss: 67557.4375 Explore P: 0.6648\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 209 Total reward: 11.0 Average reward fake: 2.207741272286512e-05 Training d_loss: 0.0020 Training g_loss: 10.7233 Training q_loss: 749088.5000 Explore P: 0.6641\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 210 Total reward: 11.0 Average reward fake: 0.002232200698927045 Training d_loss: 0.0035 Training g_loss: 9.4444 Training q_loss: 37830.5703 Explore P: 0.6633\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 211 Total reward: 21.0 Average reward fake: 0.0006167615647427738 Training d_loss: 0.0047 Training g_loss: 10.5152 Training q_loss: 33471.7422 Explore P: 0.6620\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 212 Total reward: 16.0 Average reward fake: 0.00014295305300038308 Training d_loss: 0.0175 Training g_loss: 11.0199 Training q_loss: 156045.5312 Explore P: 0.6609\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 213 Total reward: 12.0 Average reward fake: 0.00018862912838812917 Training d_loss: 0.0055 Training g_loss: 10.5915 Training q_loss: 1539321.2500 Explore P: 0.6602\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 214 Total reward: 22.0 Average reward fake: 4.051413634442724e-05 Training d_loss: 0.0551 Training g_loss: 11.2466 Training q_loss: 1025552.3750 Explore P: 0.6587\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 215 Total reward: 18.0 Average reward fake: 0.00019733332737814635 Training d_loss: 0.0004 Training g_loss: 10.9040 Training q_loss: 27216.5977 Explore P: 0.6576\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 216 Total reward: 17.0 Average reward fake: 0.00012594935833476484 Training d_loss: 0.0070 Training g_loss: 11.0235 Training q_loss: 900204.0000 Explore P: 0.6565\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 217 Total reward: 14.0 Average reward fake: 7.752313831588253e-05 Training d_loss: 0.0042 Training g_loss: 10.3620 Training q_loss: 36379.1719 Explore P: 0.6556\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 218 Total reward: 14.0 Average reward fake: 0.000263014662778005 Training d_loss: 0.0020 Training g_loss: 9.2558 Training q_loss: 1064758.7500 Explore P: 0.6546\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 219 Total reward: 45.0 Average reward fake: 0.0010225645964965224 Training d_loss: 0.0112 Training g_loss: 9.4752 Training q_loss: 34988.1172 Explore P: 0.6518\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 220 Total reward: 15.0 Average reward fake: 6.6107910242863e-05 Training d_loss: 0.0014 Training g_loss: 10.1183 Training q_loss: 24816.1094 Explore P: 0.6508\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 221 Total reward: 17.0 Average reward fake: 0.00014224827464204282 Training d_loss: 0.0152 Training g_loss: 9.5884 Training q_loss: 33678.1953 Explore P: 0.6497\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 222 Total reward: 62.0 Average reward fake: 0.0012422322761267424 Training d_loss: 0.0019 Training g_loss: 7.5186 Training q_loss: 1283228.1250 Explore P: 0.6457\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 223 Total reward: 8.0 Average reward fake: 0.0003364177537150681 Training d_loss: 0.0022 Training g_loss: 8.1681 Training q_loss: 41077.7266 Explore P: 0.6452\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 224 Total reward: 31.0 Average reward fake: 0.0010004689684137702 Training d_loss: 0.0019 Training g_loss: 7.9810 Training q_loss: 48646.1445 Explore P: 0.6433\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 225 Total reward: 11.0 Average reward fake: 0.002628398360684514 Training d_loss: 0.0039 Training g_loss: 7.4146 Training q_loss: 902139.3125 Explore P: 0.6426\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 226 Total reward: 22.0 Average reward fake: 0.0002056458470178768 Training d_loss: 0.0033 Training g_loss: 8.4825 Training q_loss: 43120.6484 Explore P: 0.6412\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 227 Total reward: 26.0 Average reward fake: 0.0006842563161626458 Training d_loss: 0.0044 Training g_loss: 7.7660 Training q_loss: 37012.1016 Explore P: 0.6395\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 228 Total reward: 7.0 Average reward fake: 0.0005108076147735119 Training d_loss: 0.0009 Training g_loss: 7.7917 Training q_loss: 1027973.1250 Explore P: 0.6391\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 229 Total reward: 17.0 Average reward fake: 0.018447181209921837 Training d_loss: 0.0220 Training g_loss: 7.3531 Training q_loss: 25335.1211 Explore P: 0.6380\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 230 Total reward: 9.0 Average reward fake: 0.0002527112956158817 Training d_loss: 0.0023 Training g_loss: 8.4351 Training q_loss: 696162.1250 Explore P: 0.6375\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 231 Total reward: 15.0 Average reward fake: 0.000209760430152528 Training d_loss: 0.0005 Training g_loss: 8.5648 Training q_loss: 20552.4785 Explore P: 0.6365\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 232 Total reward: 49.0 Average reward fake: 0.0004072635492775589 Training d_loss: 0.0010 Training g_loss: 8.0089 Training q_loss: 26988.9492 Explore P: 0.6335\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 233 Total reward: 19.0 Average reward fake: 0.00016760840662755072 Training d_loss: 0.0008 Training g_loss: 8.8981 Training q_loss: 41134.8047 Explore P: 0.6323\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 234 Total reward: 16.0 Average reward fake: 0.00017128426406998187 Training d_loss: 0.0010 Training g_loss: 8.6821 Training q_loss: 676547.6250 Explore P: 0.6313\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 235 Total reward: 14.0 Average reward fake: 0.000316526711685583 Training d_loss: 0.0005 Training g_loss: 8.1852 Training q_loss: 44661.6719 Explore P: 0.6304\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 236 Total reward: 11.0 Average reward fake: 0.000313140160869807 Training d_loss: 0.0006 Training g_loss: 8.2395 Training q_loss: 886476.5000 Explore P: 0.6297\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 237 Total reward: 18.0 Average reward fake: 0.0001429024268873036 Training d_loss: 0.0008 Training g_loss: 8.8979 Training q_loss: 31569.4785 Explore P: 0.6286\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 238 Total reward: 12.0 Average reward fake: 0.00015637859178241342 Training d_loss: 0.0006 Training g_loss: 8.8503 Training q_loss: 27580.4629 Explore P: 0.6279\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 239 Total reward: 17.0 Average reward fake: 0.00014870746235828847 Training d_loss: 0.0003 Training g_loss: 8.8360 Training q_loss: 28737.0000 Explore P: 0.6268\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 240 Total reward: 17.0 Average reward fake: 0.00029602713766507804 Training d_loss: 0.0007 Training g_loss: 8.3615 Training q_loss: 39742.9648 Explore P: 0.6258\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 241 Total reward: 14.0 Average reward fake: 0.0009970079408958554 Training d_loss: 0.0013 Training g_loss: 7.7667 Training q_loss: 78082.7031 Explore P: 0.6249\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 242 Total reward: 8.0 Average reward fake: 0.0004126247076783329 Training d_loss: 0.0009 Training g_loss: 8.1996 Training q_loss: 19341.4648 Explore P: 0.6244\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 243 Total reward: 11.0 Average reward fake: 0.00017999227566178888 Training d_loss: 0.0007 Training g_loss: 8.9779 Training q_loss: 820220.0625 Explore P: 0.6238\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 244 Total reward: 11.0 Average reward fake: 0.011533801443874836 Training d_loss: 0.0165 Training g_loss: 8.3744 Training q_loss: 22133.1777 Explore P: 0.6231\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 245 Total reward: 19.0 Average reward fake: 0.0004301596782170236 Training d_loss: 0.0020 Training g_loss: 8.7152 Training q_loss: 33743.8828 Explore P: 0.6219\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 246 Total reward: 11.0 Average reward fake: 0.00010323544120183215 Training d_loss: 0.0032 Training g_loss: 9.3130 Training q_loss: 21599.6348 Explore P: 0.6212\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 247 Total reward: 9.0 Average reward fake: 0.00024519432918168604 Training d_loss: 0.0009 Training g_loss: 9.0568 Training q_loss: 737587.5000 Explore P: 0.6207\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 248 Total reward: 10.0 Average reward fake: 9.184017835650593e-05 Training d_loss: 0.0110 Training g_loss: 9.5438 Training q_loss: 20997.3848 Explore P: 0.6201\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 249 Total reward: 11.0 Average reward fake: 0.02280215360224247 Training d_loss: 0.0265 Training g_loss: 8.0858 Training q_loss: 23163.9805 Explore P: 0.6194\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 250 Total reward: 15.0 Average reward fake: 0.015042705461382866 Training d_loss: 0.0173 Training g_loss: 8.6949 Training q_loss: 1431817.2500 Explore P: 0.6185\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 251 Total reward: 9.0 Average reward fake: 0.00011682893091347069 Training d_loss: 0.0027 Training g_loss: 9.4117 Training q_loss: 23087.7910 Explore P: 0.6180\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 252 Total reward: 16.0 Average reward fake: 0.0003123377973679453 Training d_loss: 0.0005 Training g_loss: 8.4031 Training q_loss: 29882.0430 Explore P: 0.6170\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 253 Total reward: 24.0 Average reward fake: 6.333254714263603e-05 Training d_loss: 0.0009 Training g_loss: 9.8436 Training q_loss: 22305.6719 Explore P: 0.6155\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 254 Total reward: 19.0 Average reward fake: 0.0007194889476522803 Training d_loss: 0.0013 Training g_loss: 8.6393 Training q_loss: 21178.7715 Explore P: 0.6144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 255 Total reward: 28.0 Average reward fake: 4.409821849549189e-05 Training d_loss: 0.0081 Training g_loss: 10.1162 Training q_loss: 26329.8027 Explore P: 0.6127\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 256 Total reward: 10.0 Average reward fake: 0.00012882045120932162 Training d_loss: 0.0012 Training g_loss: 9.5356 Training q_loss: 1045620.6250 Explore P: 0.6121\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 257 Total reward: 31.0 Average reward fake: 6.693496106890962e-05 Training d_loss: 0.0013 Training g_loss: 9.8843 Training q_loss: 77274.3594 Explore P: 0.6102\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 258 Total reward: 15.0 Average reward fake: 6.782172567909583e-05 Training d_loss: 0.0137 Training g_loss: 10.0154 Training q_loss: 18136.9648 Explore P: 0.6093\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 259 Total reward: 19.0 Average reward fake: 0.0001291989319724962 Training d_loss: 0.0060 Training g_loss: 9.0385 Training q_loss: 712402.9375 Explore P: 0.6082\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 260 Total reward: 11.0 Average reward fake: 0.02468978799879551 Training d_loss: 0.0291 Training g_loss: 8.5307 Training q_loss: 869851.0000 Explore P: 0.6075\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 261 Total reward: 18.0 Average reward fake: 5.9965841501252726e-05 Training d_loss: 0.0093 Training g_loss: 9.6252 Training q_loss: 19340.5781 Explore P: 0.6065\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 262 Total reward: 9.0 Average reward fake: 0.08634669333696365 Training d_loss: 0.1986 Training g_loss: 8.8973 Training q_loss: 23515.3359 Explore P: 0.6059\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 263 Total reward: 13.0 Average reward fake: 0.0001568302686791867 Training d_loss: 0.0030 Training g_loss: 9.0329 Training q_loss: 34878.1484 Explore P: 0.6051\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 264 Total reward: 12.0 Average reward fake: 0.009082021191716194 Training d_loss: 0.0107 Training g_loss: 9.1835 Training q_loss: 21993.5469 Explore P: 0.6044\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 265 Total reward: 9.0 Average reward fake: 0.00014597261906601489 Training d_loss: 0.0006 Training g_loss: 8.8240 Training q_loss: 17955.0508 Explore P: 0.6039\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 266 Total reward: 19.0 Average reward fake: 0.0001930849248310551 Training d_loss: 0.0005 Training g_loss: 9.2264 Training q_loss: 37329.4922 Explore P: 0.6028\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 267 Total reward: 11.0 Average reward fake: 0.00018043050658889115 Training d_loss: 0.0008 Training g_loss: 8.6517 Training q_loss: 10695.2012 Explore P: 0.6021\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 268 Total reward: 10.0 Average reward fake: 9.814271470531821e-05 Training d_loss: 0.0042 Training g_loss: 9.9870 Training q_loss: 17109.2754 Explore P: 0.6015\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 269 Total reward: 12.0 Average reward fake: 0.00011511382035678253 Training d_loss: 0.0007 Training g_loss: 9.1445 Training q_loss: 16768.6660 Explore P: 0.6008\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 270 Total reward: 9.0 Average reward fake: 0.00010044191731140018 Training d_loss: 0.0011 Training g_loss: 9.9852 Training q_loss: 17516.3516 Explore P: 0.6003\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 271 Total reward: 17.0 Average reward fake: 0.00013364889309741557 Training d_loss: 0.0010 Training g_loss: 9.6719 Training q_loss: 21489.3027 Explore P: 0.5993\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 272 Total reward: 11.0 Average reward fake: 0.0001603825658094138 Training d_loss: 0.0005 Training g_loss: 8.9387 Training q_loss: 25242.1289 Explore P: 0.5986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 273 Total reward: 8.0 Average reward fake: 0.03499375656247139 Training d_loss: 0.0440 Training g_loss: 8.3025 Training q_loss: 974519.6250 Explore P: 0.5982\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 274 Total reward: 14.0 Average reward fake: 4.8024667194113135e-05 Training d_loss: 0.0003 Training g_loss: 10.6683 Training q_loss: 12390.3809 Explore P: 0.5973\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 275 Total reward: 18.0 Average reward fake: 5.964497177046724e-05 Training d_loss: 0.0006 Training g_loss: 10.1211 Training q_loss: 12693.0186 Explore P: 0.5963\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 276 Total reward: 23.0 Average reward fake: 7.092216401360929e-05 Training d_loss: 0.0040 Training g_loss: 9.9435 Training q_loss: 23836.4316 Explore P: 0.5949\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 277 Total reward: 21.0 Average reward fake: 0.00010309647768735886 Training d_loss: 0.0016 Training g_loss: 9.1806 Training q_loss: 1174189.0000 Explore P: 0.5937\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 278 Total reward: 10.0 Average reward fake: 0.00013145888806320727 Training d_loss: 0.0011 Training g_loss: 8.9203 Training q_loss: 16258.5205 Explore P: 0.5931\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 279 Total reward: 21.0 Average reward fake: 0.0001848223473643884 Training d_loss: 0.0011 Training g_loss: 8.5952 Training q_loss: 11952.1484 Explore P: 0.5919\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 280 Total reward: 21.0 Average reward fake: 4.3404841562733054e-05 Training d_loss: 0.0252 Training g_loss: 10.0395 Training q_loss: 10139.1533 Explore P: 0.5907\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 281 Total reward: 10.0 Average reward fake: 4.7756311687408015e-05 Training d_loss: 0.0011 Training g_loss: 9.9671 Training q_loss: 483542.2500 Explore P: 0.5901\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 282 Total reward: 12.0 Average reward fake: 6.784018478356302e-05 Training d_loss: 0.0002 Training g_loss: 10.3092 Training q_loss: 21994.9727 Explore P: 0.5894\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 283 Total reward: 19.0 Average reward fake: 2.5328738047392108e-05 Training d_loss: 0.0004 Training g_loss: 11.7986 Training q_loss: 11214.8379 Explore P: 0.5883\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 284 Total reward: 20.0 Average reward fake: 9.608473192201927e-05 Training d_loss: 0.0026 Training g_loss: 9.4011 Training q_loss: 9901.1494 Explore P: 0.5872\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 285 Total reward: 9.0 Average reward fake: 7.980779628269374e-05 Training d_loss: 0.0021 Training g_loss: 9.9857 Training q_loss: 9509.0801 Explore P: 0.5866\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 286 Total reward: 10.0 Average reward fake: 4.620054824044928e-05 Training d_loss: 0.0020 Training g_loss: 10.8396 Training q_loss: 41062.3828 Explore P: 0.5861\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 287 Total reward: 11.0 Average reward fake: 3.752324846573174e-05 Training d_loss: 0.0115 Training g_loss: 10.2076 Training q_loss: 20335.6152 Explore P: 0.5854\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 288 Total reward: 10.0 Average reward fake: 6.540428148582578e-05 Training d_loss: 0.0038 Training g_loss: 10.2201 Training q_loss: 653886.1250 Explore P: 0.5848\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 289 Total reward: 13.0 Average reward fake: 7.188846211647615e-05 Training d_loss: 0.0005 Training g_loss: 10.8552 Training q_loss: 12497.4053 Explore P: 0.5841\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 290 Total reward: 15.0 Average reward fake: 0.00011921381519641727 Training d_loss: 0.0006 Training g_loss: 9.2949 Training q_loss: 7904.5361 Explore P: 0.5832\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 291 Total reward: 8.0 Average reward fake: 0.00011598742275964469 Training d_loss: 0.0003 Training g_loss: 9.3745 Training q_loss: 667490.1250 Explore P: 0.5828\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 292 Total reward: 8.0 Average reward fake: 0.00014500028919428587 Training d_loss: 0.0021 Training g_loss: 8.9055 Training q_loss: 614499.4375 Explore P: 0.5823\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 293 Total reward: 12.0 Average reward fake: 0.00012700891238637269 Training d_loss: 0.0027 Training g_loss: 8.9786 Training q_loss: 10421.6318 Explore P: 0.5816\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 294 Total reward: 11.0 Average reward fake: 0.00015113093832042068 Training d_loss: 0.0003 Training g_loss: 8.7948 Training q_loss: 642817.0000 Explore P: 0.5810\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 295 Total reward: 17.0 Average reward fake: 3.491273309919052e-05 Training d_loss: 0.0049 Training g_loss: 10.2323 Training q_loss: 7708.9365 Explore P: 0.5800\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 296 Total reward: 12.0 Average reward fake: 0.00014799566997680813 Training d_loss: 0.0008 Training g_loss: 9.2940 Training q_loss: 8714.7002 Explore P: 0.5794\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 297 Total reward: 8.0 Average reward fake: 0.0001435855810996145 Training d_loss: 0.0003 Training g_loss: 9.6775 Training q_loss: 753088.3750 Explore P: 0.5789\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 298 Total reward: 11.0 Average reward fake: 0.00014882185496389866 Training d_loss: 0.0006 Training g_loss: 8.8059 Training q_loss: 7372.6650 Explore P: 0.5783\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 299 Total reward: 23.0 Average reward fake: 0.00022258346143644303 Training d_loss: 0.0022 Training g_loss: 10.2105 Training q_loss: 452660.5000 Explore P: 0.5770\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 300 Total reward: 22.0 Average reward fake: 0.0001678664266364649 Training d_loss: 0.0003 Training g_loss: 8.6454 Training q_loss: 8836.4980 Explore P: 0.5757\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 301 Total reward: 18.0 Average reward fake: 0.015300306491553783 Training d_loss: 0.0169 Training g_loss: 8.9875 Training q_loss: 75732.8906 Explore P: 0.5747\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 302 Total reward: 12.0 Average reward fake: 0.0011025568237528205 Training d_loss: 0.0047 Training g_loss: 9.0464 Training q_loss: 11174.3545 Explore P: 0.5740\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 303 Total reward: 18.0 Average reward fake: 1.3774336366623174e-05 Training d_loss: 0.0010 Training g_loss: 11.2891 Training q_loss: 4593.3052 Explore P: 0.5730\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 304 Total reward: 13.0 Average reward fake: 0.18641258776187897 Training d_loss: 0.5857 Training g_loss: 11.0415 Training q_loss: 4861.4092 Explore P: 0.5723\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 305 Total reward: 13.0 Average reward fake: 1.2924949714943068e-06 Training d_loss: 0.0238 Training g_loss: 13.4916 Training q_loss: 4710.2979 Explore P: 0.5716\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 306 Total reward: 22.0 Average reward fake: 0.00020022012176923454 Training d_loss: 0.0006 Training g_loss: 8.7862 Training q_loss: 53930.9297 Explore P: 0.5703\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 307 Total reward: 12.0 Average reward fake: 1.0886525160458405e-05 Training d_loss: 0.0011 Training g_loss: 12.3994 Training q_loss: 449241.4375 Explore P: 0.5696\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 308 Total reward: 14.0 Average reward fake: 0.0018778098747134209 Training d_loss: 0.0655 Training g_loss: 11.4311 Training q_loss: 4118.8369 Explore P: 0.5689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 309 Total reward: 14.0 Average reward fake: 0.010074261575937271 Training d_loss: 0.0369 Training g_loss: 7.5553 Training q_loss: 316927.4375 Explore P: 0.5681\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 310 Total reward: 19.0 Average reward fake: 0.005419914610683918 Training d_loss: 0.0083 Training g_loss: 5.5545 Training q_loss: 366630.9688 Explore P: 0.5670\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 311 Total reward: 11.0 Average reward fake: 0.0016610829625278711 Training d_loss: 0.0041 Training g_loss: 7.0830 Training q_loss: 4304.7358 Explore P: 0.5664\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 312 Total reward: 9.0 Average reward fake: 0.00134180742315948 Training d_loss: 0.0045 Training g_loss: 7.6402 Training q_loss: 68473.1328 Explore P: 0.5659\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 313 Total reward: 11.0 Average reward fake: 0.0022991816513240337 Training d_loss: 0.0051 Training g_loss: 7.0861 Training q_loss: 2948.9807 Explore P: 0.5653\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 314 Total reward: 28.0 Average reward fake: 0.0008052792400121689 Training d_loss: 0.0023 Training g_loss: 7.2440 Training q_loss: 4595.6860 Explore P: 0.5637\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 315 Total reward: 24.0 Average reward fake: 0.0009012478403747082 Training d_loss: 0.0017 Training g_loss: 7.6123 Training q_loss: 639121.9375 Explore P: 0.5624\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 316 Total reward: 10.0 Average reward fake: 0.0005697261658497155 Training d_loss: 0.0021 Training g_loss: 7.8934 Training q_loss: 328938.5938 Explore P: 0.5619\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 317 Total reward: 10.0 Average reward fake: 0.0005028685554862022 Training d_loss: 0.0021 Training g_loss: 7.7450 Training q_loss: 318647.1562 Explore P: 0.5613\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 318 Total reward: 13.0 Average reward fake: 0.0027870198246091604 Training d_loss: 0.0103 Training g_loss: 8.1507 Training q_loss: 3130.2693 Explore P: 0.5606\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 319 Total reward: 14.0 Average reward fake: 0.0002885764406528324 Training d_loss: 0.0011 Training g_loss: 8.1834 Training q_loss: 1935.8018 Explore P: 0.5598\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 320 Total reward: 18.0 Average reward fake: 0.0057344818487763405 Training d_loss: 0.0068 Training g_loss: 7.4454 Training q_loss: 384689.7188 Explore P: 0.5588\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 321 Total reward: 12.0 Average reward fake: 0.00041298818541690707 Training d_loss: 0.0020 Training g_loss: 8.0086 Training q_loss: 332638.3438 Explore P: 0.5582\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 322 Total reward: 16.0 Average reward fake: 0.0006034880643710494 Training d_loss: 0.0013 Training g_loss: 7.7617 Training q_loss: 3740.4590 Explore P: 0.5573\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 323 Total reward: 11.0 Average reward fake: 0.00048087452887557447 Training d_loss: 0.0010 Training g_loss: 7.6609 Training q_loss: 2418.7095 Explore P: 0.5567\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 324 Total reward: 17.0 Average reward fake: 0.00033058892586268485 Training d_loss: 0.0011 Training g_loss: 8.0260 Training q_loss: 2266.4629 Explore P: 0.5558\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 325 Total reward: 14.0 Average reward fake: 0.00031544858939014375 Training d_loss: 0.0008 Training g_loss: 8.1202 Training q_loss: 226674.1562 Explore P: 0.5550\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 326 Total reward: 16.0 Average reward fake: 4.3940213799942285e-05 Training d_loss: 0.0015 Training g_loss: 10.1151 Training q_loss: 1677.5898 Explore P: 0.5541\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 327 Total reward: 11.0 Average reward fake: 3.976443986175582e-05 Training d_loss: 0.0015 Training g_loss: 10.0946 Training q_loss: 2399.8286 Explore P: 0.5535\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 328 Total reward: 12.0 Average reward fake: 0.004832625854760408 Training d_loss: 0.0061 Training g_loss: 8.5612 Training q_loss: 244205.2031 Explore P: 0.5529\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 329 Total reward: 8.0 Average reward fake: 0.002204853342846036 Training d_loss: 0.0028 Training g_loss: 8.3806 Training q_loss: 2205.1558 Explore P: 0.5525\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 330 Total reward: 10.0 Average reward fake: 0.00010430944530526176 Training d_loss: 0.0024 Training g_loss: 9.4831 Training q_loss: 1690.3326 Explore P: 0.5519\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 331 Total reward: 16.0 Average reward fake: 0.0005045233992859721 Training d_loss: 0.0142 Training g_loss: 12.4550 Training q_loss: 2843.3972 Explore P: 0.5510\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 332 Total reward: 11.0 Average reward fake: 0.02186797931790352 Training d_loss: 0.0248 Training g_loss: 7.9678 Training q_loss: 574227.2500 Explore P: 0.5505\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 333 Total reward: 10.0 Average reward fake: 3.8587058952543885e-05 Training d_loss: 0.0001 Training g_loss: 10.5959 Training q_loss: 3565.4453 Explore P: 0.5499\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 334 Total reward: 8.0 Average reward fake: 8.733932190807536e-05 Training d_loss: 0.0012 Training g_loss: 11.8630 Training q_loss: 3029.0984 Explore P: 0.5495\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 335 Total reward: 47.0 Average reward fake: 1.788716144801583e-05 Training d_loss: 0.0022 Training g_loss: 11.1054 Training q_loss: 2685.0603 Explore P: 0.5469\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 336 Total reward: 9.0 Average reward fake: 0.00017735108849592507 Training d_loss: 0.0050 Training g_loss: 12.3147 Training q_loss: 215919.1719 Explore P: 0.5465\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 337 Total reward: 16.0 Average reward fake: 0.00016071998106781393 Training d_loss: 0.0020 Training g_loss: 10.7964 Training q_loss: 181810.2812 Explore P: 0.5456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 338 Total reward: 11.0 Average reward fake: 1.906137549667619e-05 Training d_loss: 0.0008 Training g_loss: 12.3860 Training q_loss: 202980.9062 Explore P: 0.5450\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 339 Total reward: 10.0 Average reward fake: 0.042649924755096436 Training d_loss: 0.0519 Training g_loss: 11.0067 Training q_loss: 1243.5731 Explore P: 0.5445\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 340 Total reward: 8.0 Average reward fake: 0.010830206796526909 Training d_loss: 0.0228 Training g_loss: 12.1573 Training q_loss: 982.6281 Explore P: 0.5441\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 341 Total reward: 11.0 Average reward fake: 0.022054161876440048 Training d_loss: 0.0301 Training g_loss: 11.2748 Training q_loss: 200603.6406 Explore P: 0.5435\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 342 Total reward: 13.0 Average reward fake: 4.474678917176789e-06 Training d_loss: 0.0062 Training g_loss: 13.2776 Training q_loss: 350061.8125 Explore P: 0.5428\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 343 Total reward: 20.0 Average reward fake: 0.06257238984107971 Training d_loss: 0.1613 Training g_loss: 11.9772 Training q_loss: 1092.1165 Explore P: 0.5417\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 344 Total reward: 17.0 Average reward fake: 0.09342534840106964 Training d_loss: 0.1427 Training g_loss: 10.8549 Training q_loss: 180356.5938 Explore P: 0.5408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 345 Total reward: 17.0 Average reward fake: 0.13135401904582977 Training d_loss: 0.2564 Training g_loss: 11.0745 Training q_loss: 63755.3320 Explore P: 0.5399\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 346 Total reward: 24.0 Average reward fake: 0.031173091381788254 Training d_loss: 0.0919 Training g_loss: 9.9189 Training q_loss: 910.4902 Explore P: 0.5386\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 347 Total reward: 8.0 Average reward fake: 0.006022837944328785 Training d_loss: 0.2016 Training g_loss: 11.3990 Training q_loss: 318770.7500 Explore P: 0.5382\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 348 Total reward: 39.0 Average reward fake: 0.1578161120414734 Training d_loss: 0.3189 Training g_loss: 7.1265 Training q_loss: 232382.9688 Explore P: 0.5362\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 349 Total reward: 18.0 Average reward fake: 0.11598291248083115 Training d_loss: 0.1459 Training g_loss: 3.6553 Training q_loss: 642.0088 Explore P: 0.5352\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 350 Total reward: 19.0 Average reward fake: 0.313740074634552 Training d_loss: 0.5945 Training g_loss: 2.6638 Training q_loss: 156672.2188 Explore P: 0.5342\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 351 Total reward: 12.0 Average reward fake: 0.2655244469642639 Training d_loss: 0.4882 Training g_loss: 4.0118 Training q_loss: 590.1979 Explore P: 0.5336\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 352 Total reward: 19.0 Average reward fake: 0.05868156999349594 Training d_loss: 0.3204 Training g_loss: 3.6463 Training q_loss: 482.2115 Explore P: 0.5326\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 353 Total reward: 15.0 Average reward fake: 0.05327000468969345 Training d_loss: 0.0843 Training g_loss: 3.1732 Training q_loss: 342.9780 Explore P: 0.5318\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 354 Total reward: 13.0 Average reward fake: 0.2990983724594116 Training d_loss: 0.7619 Training g_loss: 1.9875 Training q_loss: 829.0621 Explore P: 0.5311\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 355 Total reward: 26.0 Average reward fake: 0.41024574637413025 Training d_loss: 0.9196 Training g_loss: 4.4734 Training q_loss: 118754.6016 Explore P: 0.5298\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 356 Total reward: 20.0 Average reward fake: 0.34011512994766235 Training d_loss: 0.7350 Training g_loss: 2.6764 Training q_loss: 117048.7969 Explore P: 0.5287\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 357 Total reward: 20.0 Average reward fake: 0.21806152164936066 Training d_loss: 0.5657 Training g_loss: 4.2600 Training q_loss: 116292.0391 Explore P: 0.5277\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 358 Total reward: 15.0 Average reward fake: 0.010236925445497036 Training d_loss: 1.5133 Training g_loss: 5.2714 Training q_loss: 29931.3965 Explore P: 0.5269\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 359 Total reward: 15.0 Average reward fake: 0.11096713691949844 Training d_loss: 0.8238 Training g_loss: 5.5543 Training q_loss: 6936.5850 Explore P: 0.5262\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 360 Total reward: 12.0 Average reward fake: 0.3241109251976013 Training d_loss: 1.0596 Training g_loss: 1.5927 Training q_loss: 4139.5400 Explore P: 0.5255\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 361 Total reward: 12.0 Average reward fake: 0.3979934751987457 Training d_loss: 0.7787 Training g_loss: 1.3246 Training q_loss: 41001.6641 Explore P: 0.5249\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 362 Total reward: 9.0 Average reward fake: 0.21812379360198975 Training d_loss: 1.0861 Training g_loss: 1.8971 Training q_loss: 190883.5312 Explore P: 0.5245\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 363 Total reward: 33.0 Average reward fake: 0.28830671310424805 Training d_loss: 0.9735 Training g_loss: 2.1143 Training q_loss: 661.1543 Explore P: 0.5228\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 364 Total reward: 8.0 Average reward fake: 0.1855684369802475 Training d_loss: 0.9099 Training g_loss: 2.9701 Training q_loss: 1317.1595 Explore P: 0.5223\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 365 Total reward: 11.0 Average reward fake: 0.3933306932449341 Training d_loss: 1.1310 Training g_loss: 1.4839 Training q_loss: 1283.7494 Explore P: 0.5218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 366 Total reward: 14.0 Average reward fake: 0.42142120003700256 Training d_loss: 0.8432 Training g_loss: 0.8985 Training q_loss: 2094.3081 Explore P: 0.5211\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 367 Total reward: 15.0 Average reward fake: 0.37139734625816345 Training d_loss: 0.8880 Training g_loss: 1.2450 Training q_loss: 2034.3500 Explore P: 0.5203\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 368 Total reward: 10.0 Average reward fake: 0.3633456826210022 Training d_loss: 1.2265 Training g_loss: 1.7825 Training q_loss: 1694.0247 Explore P: 0.5198\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 369 Total reward: 14.0 Average reward fake: 0.3410020172595978 Training d_loss: 1.2116 Training g_loss: 1.8130 Training q_loss: 179692.8750 Explore P: 0.5191\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 370 Total reward: 21.0 Average reward fake: 0.3878391981124878 Training d_loss: 1.1761 Training g_loss: 0.9436 Training q_loss: 85335.5547 Explore P: 0.5180\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 371 Total reward: 11.0 Average reward fake: 0.31710296869277954 Training d_loss: 0.9625 Training g_loss: 2.2031 Training q_loss: 70187.6875 Explore P: 0.5175\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 372 Total reward: 11.0 Average reward fake: 0.4106266498565674 Training d_loss: 0.9451 Training g_loss: 0.8910 Training q_loss: 164722.6875 Explore P: 0.5169\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 373 Total reward: 23.0 Average reward fake: 0.46183866262435913 Training d_loss: 1.2490 Training g_loss: 0.8333 Training q_loss: 78289.2031 Explore P: 0.5157\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 374 Total reward: 18.0 Average reward fake: 0.6642769575119019 Training d_loss: 2.3178 Training g_loss: 0.5231 Training q_loss: 80928.1406 Explore P: 0.5148\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 375 Total reward: 13.0 Average reward fake: 0.2152564972639084 Training d_loss: 1.8357 Training g_loss: 1.7009 Training q_loss: 64520.0742 Explore P: 0.5142\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 376 Total reward: 14.0 Average reward fake: 0.24158163368701935 Training d_loss: 1.1692 Training g_loss: 2.2955 Training q_loss: 162232.9062 Explore P: 0.5135\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 377 Total reward: 46.0 Average reward fake: 0.6037982702255249 Training d_loss: 1.3180 Training g_loss: 0.8662 Training q_loss: 49356.4336 Explore P: 0.5111\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 378 Total reward: 15.0 Average reward fake: 0.5653695464134216 Training d_loss: 1.1875 Training g_loss: 0.5841 Training q_loss: 1674.7998 Explore P: 0.5104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 379 Total reward: 23.0 Average reward fake: 0.34370511770248413 Training d_loss: 0.7413 Training g_loss: 2.1410 Training q_loss: 2172.2139 Explore P: 0.5092\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 380 Total reward: 20.0 Average reward fake: 0.38712361454963684 Training d_loss: 1.0975 Training g_loss: 0.9773 Training q_loss: 56434.8828 Explore P: 0.5083\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 381 Total reward: 15.0 Average reward fake: 0.3901436924934387 Training d_loss: 0.8064 Training g_loss: 1.6174 Training q_loss: 1475.8070 Explore P: 0.5075\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 382 Total reward: 10.0 Average reward fake: 0.4499177932739258 Training d_loss: 1.1526 Training g_loss: 0.8170 Training q_loss: 125590.2500 Explore P: 0.5070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 383 Total reward: 16.0 Average reward fake: 0.5513480305671692 Training d_loss: 1.5712 Training g_loss: 0.7119 Training q_loss: 436.4599 Explore P: 0.5062\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 384 Total reward: 18.0 Average reward fake: 0.2702758312225342 Training d_loss: 1.0885 Training g_loss: 1.2716 Training q_loss: 740.6758 Explore P: 0.5053\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 385 Total reward: 13.0 Average reward fake: 0.3897702991962433 Training d_loss: 1.3663 Training g_loss: 1.0894 Training q_loss: 51768.7266 Explore P: 0.5047\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 386 Total reward: 33.0 Average reward fake: 0.399177610874176 Training d_loss: 1.0000 Training g_loss: 1.9046 Training q_loss: 62785.4258 Explore P: 0.5030\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 387 Total reward: 9.0 Average reward fake: 0.4051072597503662 Training d_loss: 0.9914 Training g_loss: 1.0794 Training q_loss: 869.6356 Explore P: 0.5026\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 388 Total reward: 21.0 Average reward fake: 0.3345349431037903 Training d_loss: 1.2825 Training g_loss: 1.6230 Training q_loss: 39539.1602 Explore P: 0.5016\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 389 Total reward: 9.0 Average reward fake: 0.526038646697998 Training d_loss: 1.3889 Training g_loss: 0.8139 Training q_loss: 39351.0742 Explore P: 0.5011\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 390 Total reward: 15.0 Average reward fake: 0.257419615983963 Training d_loss: 0.8292 Training g_loss: 1.3845 Training q_loss: 83392.2656 Explore P: 0.5004\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 391 Total reward: 10.0 Average reward fake: 0.21860606968402863 Training d_loss: 0.5583 Training g_loss: 1.9328 Training q_loss: 43907.4141 Explore P: 0.4999\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 392 Total reward: 18.0 Average reward fake: 0.317278653383255 Training d_loss: 0.9568 Training g_loss: 1.1775 Training q_loss: 45038.0352 Explore P: 0.4990\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 393 Total reward: 17.0 Average reward fake: 0.5313671231269836 Training d_loss: 1.3773 Training g_loss: 0.7544 Training q_loss: 513.5435 Explore P: 0.4982\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 394 Total reward: 15.0 Average reward fake: 0.5340149402618408 Training d_loss: 1.1781 Training g_loss: 0.6681 Training q_loss: 1723.4919 Explore P: 0.4975\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 395 Total reward: 12.0 Average reward fake: 0.23671993613243103 Training d_loss: 0.6031 Training g_loss: 1.9782 Training q_loss: 135707.7969 Explore P: 0.4969\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 396 Total reward: 20.0 Average reward fake: 0.7456110119819641 Training d_loss: 1.5672 Training g_loss: 0.3153 Training q_loss: 1825.3684 Explore P: 0.4959\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 397 Total reward: 14.0 Average reward fake: 0.5128880143165588 Training d_loss: 1.3766 Training g_loss: 0.7509 Training q_loss: 1095.1971 Explore P: 0.4952\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 398 Total reward: 18.0 Average reward fake: 0.2823684811592102 Training d_loss: 1.1348 Training g_loss: 1.9433 Training q_loss: 75901.6484 Explore P: 0.4943\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 399 Total reward: 14.0 Average reward fake: 0.5941718816757202 Training d_loss: 1.9264 Training g_loss: 0.6229 Training q_loss: 118296.7109 Explore P: 0.4937\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 400 Total reward: 83.0 Average reward fake: 0.37970083951950073 Training d_loss: 1.2125 Training g_loss: 1.4157 Training q_loss: 3161.8386 Explore P: 0.4897\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 401 Total reward: 16.0 Average reward fake: 0.6446272730827332 Training d_loss: 1.4926 Training g_loss: 0.4488 Training q_loss: 1224.5352 Explore P: 0.4889\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 402 Total reward: 19.0 Average reward fake: 0.4535563886165619 Training d_loss: 1.0531 Training g_loss: 1.1173 Training q_loss: 56777.9375 Explore P: 0.4880\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 403 Total reward: 15.0 Average reward fake: 0.437922865152359 Training d_loss: 1.1358 Training g_loss: 1.0244 Training q_loss: 38660.6016 Explore P: 0.4873\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 404 Total reward: 22.0 Average reward fake: 0.45592230558395386 Training d_loss: 1.3205 Training g_loss: 0.7970 Training q_loss: 1190.2256 Explore P: 0.4862\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 405 Total reward: 18.0 Average reward fake: 0.5021408796310425 Training d_loss: 1.4412 Training g_loss: 0.7840 Training q_loss: 27989.6816 Explore P: 0.4854\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 406 Total reward: 14.0 Average reward fake: 0.5237618684768677 Training d_loss: 1.3383 Training g_loss: 0.6518 Training q_loss: 1206.7850 Explore P: 0.4847\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 407 Total reward: 17.0 Average reward fake: 0.49536237120628357 Training d_loss: 1.2881 Training g_loss: 0.7058 Training q_loss: 1044.3076 Explore P: 0.4839\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 408 Total reward: 22.0 Average reward fake: 0.5111860036849976 Training d_loss: 1.4030 Training g_loss: 0.6896 Training q_loss: 1120.2375 Explore P: 0.4829\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 409 Total reward: 40.0 Average reward fake: 0.308171808719635 Training d_loss: 1.1605 Training g_loss: 1.1783 Training q_loss: 831.1389 Explore P: 0.4810\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 410 Total reward: 29.0 Average reward fake: 0.48435330390930176 Training d_loss: 1.1671 Training g_loss: 0.8150 Training q_loss: 26617.3086 Explore P: 0.4796\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 411 Total reward: 15.0 Average reward fake: 0.5071293115615845 Training d_loss: 1.2725 Training g_loss: 0.7421 Training q_loss: 1120.2213 Explore P: 0.4789\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 412 Total reward: 20.0 Average reward fake: 0.45959338545799255 Training d_loss: 1.2849 Training g_loss: 0.8364 Training q_loss: 1192.8555 Explore P: 0.4780\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 413 Total reward: 13.0 Average reward fake: 0.5219707489013672 Training d_loss: 1.3283 Training g_loss: 0.6688 Training q_loss: 51601.2656 Explore P: 0.4774\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 414 Total reward: 15.0 Average reward fake: 0.47735652327537537 Training d_loss: 1.3305 Training g_loss: 0.7644 Training q_loss: 1046.2418 Explore P: 0.4767\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 415 Total reward: 15.0 Average reward fake: 0.48194393515586853 Training d_loss: 1.3027 Training g_loss: 0.8058 Training q_loss: 1226.9880 Explore P: 0.4760\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 416 Total reward: 14.0 Average reward fake: 0.5179945826530457 Training d_loss: 1.3498 Training g_loss: 0.6684 Training q_loss: 1522.5133 Explore P: 0.4753\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 417 Total reward: 14.0 Average reward fake: 0.4683988690376282 Training d_loss: 1.2774 Training g_loss: 0.7642 Training q_loss: 23881.2832 Explore P: 0.4747\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 418 Total reward: 23.0 Average reward fake: 0.49930834770202637 Training d_loss: 1.3685 Training g_loss: 0.7039 Training q_loss: 1457.5408 Explore P: 0.4736\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 419 Total reward: 13.0 Average reward fake: 0.41898012161254883 Training d_loss: 1.0534 Training g_loss: 0.9743 Training q_loss: 2200.6746 Explore P: 0.4730\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 420 Total reward: 17.0 Average reward fake: 0.4782997965812683 Training d_loss: 1.3317 Training g_loss: 0.7892 Training q_loss: 1189.9401 Explore P: 0.4722\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 421 Total reward: 24.0 Average reward fake: 0.5332969427108765 Training d_loss: 1.3938 Training g_loss: 0.6505 Training q_loss: 35560.6328 Explore P: 0.4711\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 422 Total reward: 17.0 Average reward fake: 0.4284683167934418 Training d_loss: 1.3076 Training g_loss: 0.9041 Training q_loss: 1068.3512 Explore P: 0.4703\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 423 Total reward: 18.0 Average reward fake: 0.47264695167541504 Training d_loss: 1.3453 Training g_loss: 0.7746 Training q_loss: 15507.4199 Explore P: 0.4695\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 424 Total reward: 18.0 Average reward fake: 0.5348646640777588 Training d_loss: 1.4038 Training g_loss: 0.6301 Training q_loss: 1285.4938 Explore P: 0.4687\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 425 Total reward: 11.0 Average reward fake: 0.5090295672416687 Training d_loss: 1.2947 Training g_loss: 0.6994 Training q_loss: 1465.1184 Explore P: 0.4682\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 426 Total reward: 29.0 Average reward fake: 0.4926074147224426 Training d_loss: 1.3151 Training g_loss: 0.7451 Training q_loss: 1107.3995 Explore P: 0.4668\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 427 Total reward: 12.0 Average reward fake: 0.4211302399635315 Training d_loss: 1.3541 Training g_loss: 0.9588 Training q_loss: 14590.2715 Explore P: 0.4663\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 428 Total reward: 24.0 Average reward fake: 0.3179008364677429 Training d_loss: 1.1294 Training g_loss: 1.1960 Training q_loss: 360.9287 Explore P: 0.4652\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 429 Total reward: 9.0 Average reward fake: 0.3235514163970947 Training d_loss: 1.0480 Training g_loss: 1.1280 Training q_loss: 28989.1055 Explore P: 0.4648\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 430 Total reward: 10.0 Average reward fake: 0.40113529562950134 Training d_loss: 1.1056 Training g_loss: 0.9332 Training q_loss: 396.5132 Explore P: 0.4643\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 431 Total reward: 11.0 Average reward fake: 0.28473228216171265 Training d_loss: 0.7093 Training g_loss: 1.3202 Training q_loss: 126.1506 Explore P: 0.4638\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 432 Total reward: 13.0 Average reward fake: 0.3788524270057678 Training d_loss: 0.9051 Training g_loss: 1.0107 Training q_loss: 22756.8477 Explore P: 0.4632\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 433 Total reward: 28.0 Average reward fake: 0.3404468297958374 Training d_loss: 0.9809 Training g_loss: 1.1057 Training q_loss: 12852.3584 Explore P: 0.4620\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 434 Total reward: 17.0 Average reward fake: 0.4078013300895691 Training d_loss: 1.2052 Training g_loss: 1.0104 Training q_loss: 11258.9053 Explore P: 0.4612\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 435 Total reward: 92.0 Average reward fake: 0.49930277466773987 Training d_loss: 1.2862 Training g_loss: 0.7396 Training q_loss: 12487.6660 Explore P: 0.4571\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 436 Total reward: 33.0 Average reward fake: 0.4283158779144287 Training d_loss: 1.1811 Training g_loss: 0.8994 Training q_loss: 696.4448 Explore P: 0.4556\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 437 Total reward: 45.0 Average reward fake: 0.3954484462738037 Training d_loss: 1.3624 Training g_loss: 1.1454 Training q_loss: 11418.4941 Explore P: 0.4536\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 438 Total reward: 14.0 Average reward fake: 0.5187297463417053 Training d_loss: 1.2544 Training g_loss: 0.6701 Training q_loss: 905.7623 Explore P: 0.4530\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 439 Total reward: 17.0 Average reward fake: 0.3976368308067322 Training d_loss: 1.0242 Training g_loss: 1.0215 Training q_loss: 1688.2002 Explore P: 0.4522\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 440 Total reward: 18.0 Average reward fake: 0.4726964831352234 Training d_loss: 1.4848 Training g_loss: 0.8127 Training q_loss: 1161.7598 Explore P: 0.4514\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 441 Total reward: 19.0 Average reward fake: 0.4033343195915222 Training d_loss: 1.3703 Training g_loss: 1.5113 Training q_loss: 937.6010 Explore P: 0.4506\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 442 Total reward: 23.0 Average reward fake: 0.4903998374938965 Training d_loss: 1.5087 Training g_loss: 0.9014 Training q_loss: 1180.0426 Explore P: 0.4496\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 443 Total reward: 19.0 Average reward fake: 0.4602566361427307 Training d_loss: 1.2669 Training g_loss: 0.7903 Training q_loss: 1594.3354 Explore P: 0.4487\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 444 Total reward: 15.0 Average reward fake: 0.4837045669555664 Training d_loss: 1.2473 Training g_loss: 0.7848 Training q_loss: 1341.7335 Explore P: 0.4481\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 445 Total reward: 21.0 Average reward fake: 0.4929542541503906 Training d_loss: 1.3471 Training g_loss: 0.7197 Training q_loss: 18363.7324 Explore P: 0.4472\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 446 Total reward: 17.0 Average reward fake: 0.5335776805877686 Training d_loss: 1.4287 Training g_loss: 0.6690 Training q_loss: 1151.9917 Explore P: 0.4464\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 447 Total reward: 16.0 Average reward fake: 0.5184555053710938 Training d_loss: 1.2872 Training g_loss: 0.7641 Training q_loss: 1646.4236 Explore P: 0.4457\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 448 Total reward: 15.0 Average reward fake: 0.4585673213005066 Training d_loss: 1.1452 Training g_loss: 0.8326 Training q_loss: 2436.8813 Explore P: 0.4451\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 449 Total reward: 9.0 Average reward fake: 0.3824484944343567 Training d_loss: 1.1410 Training g_loss: 1.2797 Training q_loss: 3087.9116 Explore P: 0.4447\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 450 Total reward: 11.0 Average reward fake: 0.4682648777961731 Training d_loss: 1.3924 Training g_loss: 0.8482 Training q_loss: 1646.4330 Explore P: 0.4442\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 451 Total reward: 11.0 Average reward fake: 0.4459124207496643 Training d_loss: 1.3312 Training g_loss: 0.8372 Training q_loss: 2096.3232 Explore P: 0.4437\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 452 Total reward: 13.0 Average reward fake: 0.47761163115501404 Training d_loss: 1.2685 Training g_loss: 0.8532 Training q_loss: 18865.3711 Explore P: 0.4432\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 453 Total reward: 20.0 Average reward fake: 0.39692163467407227 Training d_loss: 1.2219 Training g_loss: 1.0168 Training q_loss: 2169.0093 Explore P: 0.4423\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 454 Total reward: 11.0 Average reward fake: 0.4601285457611084 Training d_loss: 1.3759 Training g_loss: 0.8573 Training q_loss: 7906.3799 Explore P: 0.4418\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 455 Total reward: 10.0 Average reward fake: 0.41148871183395386 Training d_loss: 1.1134 Training g_loss: 1.0433 Training q_loss: 18005.5098 Explore P: 0.4414\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 456 Total reward: 16.0 Average reward fake: 0.4095500111579895 Training d_loss: 1.1749 Training g_loss: 0.9256 Training q_loss: 30200.6211 Explore P: 0.4407\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 457 Total reward: 14.0 Average reward fake: 0.4878053069114685 Training d_loss: 1.2939 Training g_loss: 0.7411 Training q_loss: 1276.5715 Explore P: 0.4401\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 458 Total reward: 48.0 Average reward fake: 0.5210574865341187 Training d_loss: 1.4175 Training g_loss: 0.6543 Training q_loss: 1394.6726 Explore P: 0.4380\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 459 Total reward: 18.0 Average reward fake: 0.525520920753479 Training d_loss: 1.3451 Training g_loss: 0.7084 Training q_loss: 1739.4500 Explore P: 0.4373\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 460 Total reward: 11.0 Average reward fake: 0.4810510575771332 Training d_loss: 1.3709 Training g_loss: 0.7726 Training q_loss: 17590.5742 Explore P: 0.4368\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 461 Total reward: 14.0 Average reward fake: 0.43170732259750366 Training d_loss: 1.1346 Training g_loss: 0.8840 Training q_loss: 12259.9395 Explore P: 0.4362\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 462 Total reward: 12.0 Average reward fake: 0.4435803294181824 Training d_loss: 1.1780 Training g_loss: 0.9896 Training q_loss: 2014.8379 Explore P: 0.4357\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 463 Total reward: 14.0 Average reward fake: 0.4370744228363037 Training d_loss: 1.3786 Training g_loss: 1.0412 Training q_loss: 1696.9519 Explore P: 0.4351\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 464 Total reward: 12.0 Average reward fake: 0.5022176504135132 Training d_loss: 1.3244 Training g_loss: 0.7717 Training q_loss: 1916.0986 Explore P: 0.4346\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 465 Total reward: 14.0 Average reward fake: 0.4567226469516754 Training d_loss: 1.2161 Training g_loss: 1.0130 Training q_loss: 1940.6381 Explore P: 0.4340\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 466 Total reward: 11.0 Average reward fake: 0.4183564782142639 Training d_loss: 1.3138 Training g_loss: 0.9657 Training q_loss: 6396.9644 Explore P: 0.4335\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 467 Total reward: 13.0 Average reward fake: 0.5148334503173828 Training d_loss: 1.3867 Training g_loss: 0.7453 Training q_loss: 10962.8379 Explore P: 0.4330\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 468 Total reward: 34.0 Average reward fake: 0.355426549911499 Training d_loss: 1.0067 Training g_loss: 1.0944 Training q_loss: 1876.0277 Explore P: 0.4315\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 469 Total reward: 29.0 Average reward fake: 0.5635289549827576 Training d_loss: 1.4559 Training g_loss: 0.6016 Training q_loss: 1267.7227 Explore P: 0.4303\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 470 Total reward: 32.0 Average reward fake: 0.5035711526870728 Training d_loss: 1.2114 Training g_loss: 0.8144 Training q_loss: 1332.4880 Explore P: 0.4290\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 471 Total reward: 41.0 Average reward fake: 0.4868217408657074 Training d_loss: 1.3362 Training g_loss: 0.7478 Training q_loss: 1197.0629 Explore P: 0.4273\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 472 Total reward: 36.0 Average reward fake: 0.5701754093170166 Training d_loss: 1.3806 Training g_loss: 0.5666 Training q_loss: 6777.4727 Explore P: 0.4258\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 473 Total reward: 25.0 Average reward fake: 0.46382004022598267 Training d_loss: 1.4442 Training g_loss: 0.9530 Training q_loss: 9497.2637 Explore P: 0.4247\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 474 Total reward: 19.0 Average reward fake: 0.2989194393157959 Training d_loss: 0.9850 Training g_loss: 1.4962 Training q_loss: 1552.3933 Explore P: 0.4239\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 475 Total reward: 18.0 Average reward fake: 0.4170457720756531 Training d_loss: 1.2799 Training g_loss: 1.2647 Training q_loss: 1761.9875 Explore P: 0.4232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 476 Total reward: 21.0 Average reward fake: 0.5284793972969055 Training d_loss: 1.3363 Training g_loss: 0.6781 Training q_loss: 1201.2709 Explore P: 0.4223\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 477 Total reward: 12.0 Average reward fake: 0.4473581314086914 Training d_loss: 1.3201 Training g_loss: 0.8852 Training q_loss: 1459.5603 Explore P: 0.4218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 478 Total reward: 13.0 Average reward fake: 0.4597746431827545 Training d_loss: 1.2777 Training g_loss: 0.8525 Training q_loss: 5808.1279 Explore P: 0.4213\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 479 Total reward: 19.0 Average reward fake: 0.5133448243141174 Training d_loss: 1.4130 Training g_loss: 0.6885 Training q_loss: 1502.6627 Explore P: 0.4205\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 480 Total reward: 14.0 Average reward fake: 0.4100568890571594 Training d_loss: 1.1981 Training g_loss: 1.1027 Training q_loss: 1894.3070 Explore P: 0.4199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 481 Total reward: 32.0 Average reward fake: 0.42111292481422424 Training d_loss: 1.3066 Training g_loss: 1.1798 Training q_loss: 23663.4160 Explore P: 0.4186\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 482 Total reward: 41.0 Average reward fake: 0.5007866024971008 Training d_loss: 1.3333 Training g_loss: 0.7041 Training q_loss: 1323.7869 Explore P: 0.4170\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 483 Total reward: 15.0 Average reward fake: 0.4330296516418457 Training d_loss: 1.2371 Training g_loss: 0.9535 Training q_loss: 9984.4258 Explore P: 0.4163\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 484 Total reward: 20.0 Average reward fake: 0.48098254203796387 Training d_loss: 1.3086 Training g_loss: 0.7428 Training q_loss: 1457.4244 Explore P: 0.4155\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 485 Total reward: 12.0 Average reward fake: 0.43600574135780334 Training d_loss: 1.3238 Training g_loss: 0.9721 Training q_loss: 1501.5940 Explore P: 0.4150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 486 Total reward: 27.0 Average reward fake: 0.4935113489627838 Training d_loss: 1.3369 Training g_loss: 0.7165 Training q_loss: 3735.9563 Explore P: 0.4140\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 487 Total reward: 20.0 Average reward fake: 0.4694024622440338 Training d_loss: 1.2859 Training g_loss: 0.8415 Training q_loss: 14901.0234 Explore P: 0.4131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 488 Total reward: 18.0 Average reward fake: 0.4333224296569824 Training d_loss: 1.2127 Training g_loss: 0.9005 Training q_loss: 12680.3340 Explore P: 0.4124\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 489 Total reward: 26.0 Average reward fake: 0.5439260601997375 Training d_loss: 1.4058 Training g_loss: 0.6031 Training q_loss: 550.6160 Explore P: 0.4114\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 490 Total reward: 25.0 Average reward fake: 0.5010302662849426 Training d_loss: 1.2914 Training g_loss: 0.7257 Training q_loss: 1731.0374 Explore P: 0.4104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 491 Total reward: 13.0 Average reward fake: 0.4163520336151123 Training d_loss: 1.3378 Training g_loss: 0.8991 Training q_loss: 1714.3242 Explore P: 0.4099\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 492 Total reward: 19.0 Average reward fake: 0.5056757926940918 Training d_loss: 1.2796 Training g_loss: 0.7881 Training q_loss: 1486.6511 Explore P: 0.4091\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 493 Total reward: 13.0 Average reward fake: 0.494668573141098 Training d_loss: 1.5225 Training g_loss: 0.7349 Training q_loss: 737.5647 Explore P: 0.4086\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 494 Total reward: 16.0 Average reward fake: 0.410390704870224 Training d_loss: 1.1319 Training g_loss: 0.9953 Training q_loss: 8337.3066 Explore P: 0.4079\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 495 Total reward: 14.0 Average reward fake: 0.4505350589752197 Training d_loss: 1.3525 Training g_loss: 0.8595 Training q_loss: 1652.8098 Explore P: 0.4074\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 496 Total reward: 11.0 Average reward fake: 0.43409377336502075 Training d_loss: 1.2993 Training g_loss: 0.9375 Training q_loss: 1607.3113 Explore P: 0.4069\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 497 Total reward: 53.0 Average reward fake: 0.4741083085536957 Training d_loss: 1.3487 Training g_loss: 0.7962 Training q_loss: 4968.8311 Explore P: 0.4048\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 498 Total reward: 18.0 Average reward fake: 0.5036285519599915 Training d_loss: 1.2621 Training g_loss: 0.7011 Training q_loss: 1390.8142 Explore P: 0.4041\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 499 Total reward: 17.0 Average reward fake: 0.5201224088668823 Training d_loss: 1.4672 Training g_loss: 0.6656 Training q_loss: 11792.7158 Explore P: 0.4035\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 500 Total reward: 56.0 Average reward fake: 0.47496646642684937 Training d_loss: 1.3426 Training g_loss: 0.9375 Training q_loss: 891.6646 Explore P: 0.4013\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 501 Total reward: 35.0 Average reward fake: 0.48176127672195435 Training d_loss: 1.3607 Training g_loss: 0.8083 Training q_loss: 1473.3123 Explore P: 0.3999\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 502 Total reward: 103.0 Average reward fake: 0.5114068984985352 Training d_loss: 1.4632 Training g_loss: 0.7098 Training q_loss: 2909.6936 Explore P: 0.3959\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 503 Total reward: 24.0 Average reward fake: 0.44690459966659546 Training d_loss: 1.2458 Training g_loss: 0.8451 Training q_loss: 4158.3276 Explore P: 0.3950\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 504 Total reward: 35.0 Average reward fake: 0.4260168969631195 Training d_loss: 1.1395 Training g_loss: 0.8913 Training q_loss: 7524.2588 Explore P: 0.3936\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 505 Total reward: 20.0 Average reward fake: 0.519483745098114 Training d_loss: 1.4109 Training g_loss: 0.7632 Training q_loss: 479.6938 Explore P: 0.3929\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 506 Total reward: 62.0 Average reward fake: 0.44192394614219666 Training d_loss: 1.2891 Training g_loss: 0.8353 Training q_loss: 883.9069 Explore P: 0.3905\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 507 Total reward: 52.0 Average reward fake: 0.5177776217460632 Training d_loss: 1.5264 Training g_loss: 0.7972 Training q_loss: 2704.3723 Explore P: 0.3885\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 508 Total reward: 58.0 Average reward fake: 0.4792671203613281 Training d_loss: 1.2964 Training g_loss: 0.7793 Training q_loss: 736.2723 Explore P: 0.3863\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 509 Total reward: 95.0 Average reward fake: 0.5082980990409851 Training d_loss: 1.3063 Training g_loss: 0.7590 Training q_loss: 983.7295 Explore P: 0.3828\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 510 Total reward: 37.0 Average reward fake: 0.5285951495170593 Training d_loss: 1.4457 Training g_loss: 0.6591 Training q_loss: 673.3333 Explore P: 0.3814\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 511 Total reward: 26.0 Average reward fake: 0.4088977873325348 Training d_loss: 1.2318 Training g_loss: 0.9603 Training q_loss: 552.0179 Explore P: 0.3804\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 512 Total reward: 17.0 Average reward fake: 0.44694119691848755 Training d_loss: 1.2758 Training g_loss: 0.8512 Training q_loss: 4552.4131 Explore P: 0.3798\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 513 Total reward: 74.0 Average reward fake: 0.4778851568698883 Training d_loss: 1.3718 Training g_loss: 0.7510 Training q_loss: 5506.9746 Explore P: 0.3771\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 514 Total reward: 43.0 Average reward fake: 0.4908694326877594 Training d_loss: 1.3119 Training g_loss: 0.7351 Training q_loss: 356.0963 Explore P: 0.3755\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 515 Total reward: 100.0 Average reward fake: 0.4253755509853363 Training d_loss: 1.3018 Training g_loss: 0.9608 Training q_loss: 268.0242 Explore P: 0.3719\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 516 Total reward: 27.0 Average reward fake: 0.49244871735572815 Training d_loss: 1.2643 Training g_loss: 0.8721 Training q_loss: 2261.4321 Explore P: 0.3709\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 517 Total reward: 57.0 Average reward fake: 0.5161703824996948 Training d_loss: 1.3753 Training g_loss: 0.6845 Training q_loss: 420.6105 Explore P: 0.3689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 518 Total reward: 45.0 Average reward fake: 0.4668753147125244 Training d_loss: 1.3197 Training g_loss: 0.7909 Training q_loss: 3007.9170 Explore P: 0.3672\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 519 Total reward: 47.0 Average reward fake: 0.48687201738357544 Training d_loss: 1.3509 Training g_loss: 0.7475 Training q_loss: 476.2525 Explore P: 0.3656\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 520 Total reward: 42.0 Average reward fake: 0.5116093754768372 Training d_loss: 1.4882 Training g_loss: 0.6796 Training q_loss: 555.8577 Explore P: 0.3641\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 521 Total reward: 40.0 Average reward fake: 0.4635889530181885 Training d_loss: 1.3366 Training g_loss: 0.7781 Training q_loss: 565.5175 Explore P: 0.3627\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 522 Total reward: 102.0 Average reward fake: 0.6159616112709045 Training d_loss: 1.5585 Training g_loss: 0.4978 Training q_loss: 217.0848 Explore P: 0.3591\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 523 Total reward: 38.0 Average reward fake: 0.3654036223888397 Training d_loss: 1.1775 Training g_loss: 1.0294 Training q_loss: 1498.8425 Explore P: 0.3578\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 524 Total reward: 33.0 Average reward fake: 0.5331598520278931 Training d_loss: 1.6222 Training g_loss: 0.7066 Training q_loss: 340.7789 Explore P: 0.3566\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 525 Total reward: 42.0 Average reward fake: 0.39302605390548706 Training d_loss: 1.2416 Training g_loss: 1.0126 Training q_loss: 432.5926 Explore P: 0.3552\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 526 Total reward: 43.0 Average reward fake: 0.4539991319179535 Training d_loss: 1.3023 Training g_loss: 0.8284 Training q_loss: 703.5104 Explore P: 0.3537\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 527 Total reward: 14.0 Average reward fake: 0.529501736164093 Training d_loss: 1.3740 Training g_loss: 0.6580 Training q_loss: 610.6065 Explore P: 0.3532\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 528 Total reward: 30.0 Average reward fake: 0.49434465169906616 Training d_loss: 1.3566 Training g_loss: 0.8078 Training q_loss: 1470.1371 Explore P: 0.3522\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 529 Total reward: 27.0 Average reward fake: 0.4656490385532379 Training d_loss: 1.4183 Training g_loss: 0.7837 Training q_loss: 435.7267 Explore P: 0.3512\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 530 Total reward: 50.0 Average reward fake: 0.4843088686466217 Training d_loss: 1.3359 Training g_loss: 0.7393 Training q_loss: 381.4394 Explore P: 0.3495\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 531 Total reward: 41.0 Average reward fake: 0.4976831078529358 Training d_loss: 1.2639 Training g_loss: 0.7036 Training q_loss: 729.0287 Explore P: 0.3482\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 532 Total reward: 30.0 Average reward fake: 0.4810510575771332 Training d_loss: 1.2626 Training g_loss: 0.7625 Training q_loss: 135.6755 Explore P: 0.3471\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 533 Total reward: 50.0 Average reward fake: 0.46360722184181213 Training d_loss: 1.3605 Training g_loss: 0.8211 Training q_loss: 585.5588 Explore P: 0.3455\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 534 Total reward: 49.0 Average reward fake: 0.4244089722633362 Training d_loss: 1.3106 Training g_loss: 0.8890 Training q_loss: 228.2965 Explore P: 0.3438\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 535 Total reward: 34.0 Average reward fake: 0.4366191029548645 Training d_loss: 1.2655 Training g_loss: 0.8505 Training q_loss: 712.8586 Explore P: 0.3427\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 536 Total reward: 74.0 Average reward fake: 0.536406934261322 Training d_loss: 1.4821 Training g_loss: 0.6551 Training q_loss: 201.4947 Explore P: 0.3402\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 537 Total reward: 37.0 Average reward fake: 0.5502848625183105 Training d_loss: 1.4738 Training g_loss: 0.6059 Training q_loss: 255.1585 Explore P: 0.3390\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 538 Total reward: 34.0 Average reward fake: 0.4210471510887146 Training d_loss: 1.2704 Training g_loss: 0.9268 Training q_loss: 715.5829 Explore P: 0.3379\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 539 Total reward: 41.0 Average reward fake: 0.4573098123073578 Training d_loss: 1.3260 Training g_loss: 0.8853 Training q_loss: 2958.7524 Explore P: 0.3366\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 540 Total reward: 54.0 Average reward fake: 0.49125128984451294 Training d_loss: 1.3252 Training g_loss: 0.7526 Training q_loss: 149.3026 Explore P: 0.3348\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 541 Total reward: 20.0 Average reward fake: 0.49949756264686584 Training d_loss: 1.3513 Training g_loss: 0.7557 Training q_loss: 3257.8872 Explore P: 0.3341\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 542 Total reward: 39.0 Average reward fake: 0.4780092239379883 Training d_loss: 1.3327 Training g_loss: 0.8550 Training q_loss: 357.4999 Explore P: 0.3329\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 543 Total reward: 37.0 Average reward fake: 0.5016921758651733 Training d_loss: 1.3589 Training g_loss: 0.7144 Training q_loss: 197.6875 Explore P: 0.3317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 544 Total reward: 45.0 Average reward fake: 0.4625415802001953 Training d_loss: 1.3837 Training g_loss: 0.8044 Training q_loss: 1836.1283 Explore P: 0.3303\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 545 Total reward: 31.0 Average reward fake: 0.5598512887954712 Training d_loss: 1.4221 Training g_loss: 0.5945 Training q_loss: 1026.4567 Explore P: 0.3293\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 546 Total reward: 40.0 Average reward fake: 0.522093653678894 Training d_loss: 1.3153 Training g_loss: 0.6690 Training q_loss: 259.1938 Explore P: 0.3280\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 547 Total reward: 32.0 Average reward fake: 0.4437738060951233 Training d_loss: 1.3041 Training g_loss: 0.9436 Training q_loss: 2654.6021 Explore P: 0.3270\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 548 Total reward: 57.0 Average reward fake: 0.43079766631126404 Training d_loss: 1.4001 Training g_loss: 0.8960 Training q_loss: 234.9579 Explore P: 0.3252\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 549 Total reward: 16.0 Average reward fake: 0.5437114834785461 Training d_loss: 1.3731 Training g_loss: 0.6228 Training q_loss: 203.8847 Explore P: 0.3247\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 550 Total reward: 34.0 Average reward fake: 0.4697893559932709 Training d_loss: 1.3047 Training g_loss: 0.7869 Training q_loss: 6954.3721 Explore P: 0.3236\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 551 Total reward: 68.0 Average reward fake: 0.5583606958389282 Training d_loss: 1.4682 Training g_loss: 0.5850 Training q_loss: 391.0042 Explore P: 0.3215\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 552 Total reward: 53.0 Average reward fake: 0.5034593343734741 Training d_loss: 1.3412 Training g_loss: 0.7054 Training q_loss: 193.5956 Explore P: 0.3198\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 553 Total reward: 32.0 Average reward fake: 0.5068283081054688 Training d_loss: 1.4877 Training g_loss: 0.6977 Training q_loss: 108.5646 Explore P: 0.3188\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 554 Total reward: 36.0 Average reward fake: 0.41471201181411743 Training d_loss: 1.1713 Training g_loss: 0.9114 Training q_loss: 139.7280 Explore P: 0.3177\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 555 Total reward: 45.0 Average reward fake: 0.5341122150421143 Training d_loss: 1.5394 Training g_loss: 0.6350 Training q_loss: 336.6983 Explore P: 0.3163\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 556 Total reward: 39.0 Average reward fake: 0.5593283772468567 Training d_loss: 1.4203 Training g_loss: 0.6314 Training q_loss: 159.0442 Explore P: 0.3152\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 557 Total reward: 28.0 Average reward fake: 0.478149950504303 Training d_loss: 1.4652 Training g_loss: 0.7959 Training q_loss: 1771.5945 Explore P: 0.3143\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 558 Total reward: 28.0 Average reward fake: 0.5136814713478088 Training d_loss: 1.4637 Training g_loss: 0.6656 Training q_loss: 149.6767 Explore P: 0.3134\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 559 Total reward: 29.0 Average reward fake: 0.38643553853034973 Training d_loss: 1.2448 Training g_loss: 0.9697 Training q_loss: 2984.8582 Explore P: 0.3126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 560 Total reward: 44.0 Average reward fake: 0.4550396502017975 Training d_loss: 1.4045 Training g_loss: 0.7908 Training q_loss: 121.3460 Explore P: 0.3112\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 561 Total reward: 67.0 Average reward fake: 0.4706662595272064 Training d_loss: 1.2616 Training g_loss: 0.7961 Training q_loss: 137.3870 Explore P: 0.3092\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 562 Total reward: 66.0 Average reward fake: 0.5411723256111145 Training d_loss: 1.5197 Training g_loss: 0.6403 Training q_loss: 122.9117 Explore P: 0.3073\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 563 Total reward: 72.0 Average reward fake: 0.5034571886062622 Training d_loss: 1.3846 Training g_loss: 0.6960 Training q_loss: 102.0954 Explore P: 0.3051\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 564 Total reward: 21.0 Average reward fake: 0.46899837255477905 Training d_loss: 1.2763 Training g_loss: 0.7684 Training q_loss: 483.5860 Explore P: 0.3045\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 565 Total reward: 37.0 Average reward fake: 0.516659140586853 Training d_loss: 1.3175 Training g_loss: 0.6908 Training q_loss: 85.4771 Explore P: 0.3034\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 566 Total reward: 35.0 Average reward fake: 0.4889511168003082 Training d_loss: 1.3857 Training g_loss: 0.7342 Training q_loss: 77.7137 Explore P: 0.3024\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 567 Total reward: 52.0 Average reward fake: 0.5383445024490356 Training d_loss: 1.4699 Training g_loss: 0.6388 Training q_loss: 323.7597 Explore P: 0.3009\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 568 Total reward: 37.0 Average reward fake: 0.5211420059204102 Training d_loss: 1.4131 Training g_loss: 0.6659 Training q_loss: 85.6407 Explore P: 0.2998\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 569 Total reward: 42.0 Average reward fake: 0.5445209741592407 Training d_loss: 1.3265 Training g_loss: 0.6259 Training q_loss: 144.4407 Explore P: 0.2986\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 570 Total reward: 26.0 Average reward fake: 0.43798819184303284 Training d_loss: 1.2396 Training g_loss: 0.8381 Training q_loss: 153.3609 Explore P: 0.2978\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 571 Total reward: 35.0 Average reward fake: 0.40251627564430237 Training d_loss: 1.2083 Training g_loss: 1.0506 Training q_loss: 1111.5193 Explore P: 0.2968\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 572 Total reward: 44.0 Average reward fake: 0.5505610108375549 Training d_loss: 1.2989 Training g_loss: 0.6626 Training q_loss: 545.6210 Explore P: 0.2956\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 573 Total reward: 63.0 Average reward fake: 0.2836069166660309 Training d_loss: 1.1194 Training g_loss: 1.5414 Training q_loss: 2442.0784 Explore P: 0.2938\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 574 Total reward: 28.0 Average reward fake: 0.6425580382347107 Training d_loss: 1.8639 Training g_loss: 0.5061 Training q_loss: 208.7567 Explore P: 0.2930\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 575 Total reward: 44.0 Average reward fake: 0.5039047002792358 Training d_loss: 1.3119 Training g_loss: 0.7179 Training q_loss: 268.8693 Explore P: 0.2917\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 576 Total reward: 61.0 Average reward fake: 0.44763270020484924 Training d_loss: 1.3768 Training g_loss: 0.8444 Training q_loss: 227.4609 Explore P: 0.2900\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 577 Total reward: 97.0 Average reward fake: 0.49980583786964417 Training d_loss: 1.3646 Training g_loss: 0.7486 Training q_loss: 177.8256 Explore P: 0.2873\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 578 Total reward: 36.0 Average reward fake: 0.49670252203941345 Training d_loss: 1.3123 Training g_loss: 0.7342 Training q_loss: 759.6906 Explore P: 0.2863\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 579 Total reward: 58.0 Average reward fake: 0.49078765511512756 Training d_loss: 1.3682 Training g_loss: 0.7350 Training q_loss: 48.6809 Explore P: 0.2847\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 580 Total reward: 36.0 Average reward fake: 0.438441663980484 Training d_loss: 1.3657 Training g_loss: 0.8728 Training q_loss: 68.9580 Explore P: 0.2837\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 581 Total reward: 44.0 Average reward fake: 0.46855664253234863 Training d_loss: 1.3925 Training g_loss: 0.7733 Training q_loss: 118.0841 Explore P: 0.2825\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 582 Total reward: 61.0 Average reward fake: 0.5366647839546204 Training d_loss: 1.3619 Training g_loss: 0.7234 Training q_loss: 56.3090 Explore P: 0.2809\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 583 Total reward: 78.0 Average reward fake: 0.4194067120552063 Training d_loss: 1.1582 Training g_loss: 0.9308 Training q_loss: 118.5200 Explore P: 0.2788\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 584 Total reward: 59.0 Average reward fake: 0.44181403517723083 Training d_loss: 1.2467 Training g_loss: 0.8641 Training q_loss: 2270.4917 Explore P: 0.2772\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 585 Total reward: 40.0 Average reward fake: 0.45209425687789917 Training d_loss: 1.2253 Training g_loss: 0.8336 Training q_loss: 102.6142 Explore P: 0.2761\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 586 Total reward: 32.0 Average reward fake: 0.48494529724121094 Training d_loss: 1.1883 Training g_loss: 0.7443 Training q_loss: 129.2861 Explore P: 0.2753\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 587 Total reward: 52.0 Average reward fake: 0.45873379707336426 Training d_loss: 1.2180 Training g_loss: 0.9225 Training q_loss: 46.1034 Explore P: 0.2739\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 588 Total reward: 34.0 Average reward fake: 0.48063230514526367 Training d_loss: 1.2839 Training g_loss: 0.7502 Training q_loss: 498.8763 Explore P: 0.2730\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 589 Total reward: 38.0 Average reward fake: 0.41326767206192017 Training d_loss: 1.0728 Training g_loss: 0.9272 Training q_loss: 169.0261 Explore P: 0.2720\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 590 Total reward: 40.0 Average reward fake: 0.4960927963256836 Training d_loss: 1.5671 Training g_loss: 0.7204 Training q_loss: 569.5490 Explore P: 0.2710\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 591 Total reward: 35.0 Average reward fake: 0.48149237036705017 Training d_loss: 1.3129 Training g_loss: 0.7439 Training q_loss: 141.6773 Explore P: 0.2701\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 592 Total reward: 46.0 Average reward fake: 0.4821224808692932 Training d_loss: 1.4794 Training g_loss: 0.8332 Training q_loss: 98.3875 Explore P: 0.2689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 593 Total reward: 32.0 Average reward fake: 0.4941227436065674 Training d_loss: 1.3103 Training g_loss: 0.7147 Training q_loss: 2093.0825 Explore P: 0.2680\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 594 Total reward: 69.0 Average reward fake: 0.4916040897369385 Training d_loss: 1.3784 Training g_loss: 0.8183 Training q_loss: 99.3972 Explore P: 0.2663\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 595 Total reward: 48.0 Average reward fake: 0.4534975588321686 Training d_loss: 1.4681 Training g_loss: 0.8950 Training q_loss: 52.0705 Explore P: 0.2650\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 596 Total reward: 53.0 Average reward fake: 0.5149523019790649 Training d_loss: 1.3309 Training g_loss: 0.7107 Training q_loss: 200.2793 Explore P: 0.2637\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 597 Total reward: 52.0 Average reward fake: 0.3717849850654602 Training d_loss: 1.0191 Training g_loss: 1.0505 Training q_loss: 1871.4746 Explore P: 0.2624\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 598 Total reward: 62.0 Average reward fake: 0.5270645022392273 Training d_loss: 1.4694 Training g_loss: 0.6602 Training q_loss: 68.0383 Explore P: 0.2608\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 599 Total reward: 37.0 Average reward fake: 0.5587324500083923 Training d_loss: 1.5771 Training g_loss: 0.6134 Training q_loss: 148.2043 Explore P: 0.2599\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 600 Total reward: 34.0 Average reward fake: 0.38382598757743835 Training d_loss: 1.2703 Training g_loss: 0.9780 Training q_loss: 51.4281 Explore P: 0.2590\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 601 Total reward: 37.0 Average reward fake: 0.5112641453742981 Training d_loss: 1.4196 Training g_loss: 0.6912 Training q_loss: 94.7605 Explore P: 0.2581\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 602 Total reward: 79.0 Average reward fake: 0.38095059990882874 Training d_loss: 1.3114 Training g_loss: 1.0255 Training q_loss: 1246.0437 Explore P: 0.2562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 603 Total reward: 41.0 Average reward fake: 0.49321651458740234 Training d_loss: 1.4919 Training g_loss: 0.7269 Training q_loss: 38.8076 Explore P: 0.2552\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 604 Total reward: 40.0 Average reward fake: 0.4925629496574402 Training d_loss: 1.3610 Training g_loss: 0.7173 Training q_loss: 74.5223 Explore P: 0.2542\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 605 Total reward: 157.0 Average reward fake: 0.5382567644119263 Training d_loss: 1.4521 Training g_loss: 0.6333 Training q_loss: 41.3290 Explore P: 0.2504\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 606 Total reward: 43.0 Average reward fake: 0.4021177291870117 Training d_loss: 1.3606 Training g_loss: 0.9760 Training q_loss: 77.1510 Explore P: 0.2493\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 607 Total reward: 64.0 Average reward fake: 0.3923420310020447 Training d_loss: 1.2982 Training g_loss: 1.0078 Training q_loss: 49.3925 Explore P: 0.2478\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 608 Total reward: 47.0 Average reward fake: 0.41364583373069763 Training d_loss: 1.2554 Training g_loss: 0.9119 Training q_loss: 239.7379 Explore P: 0.2467\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 609 Total reward: 199.0 Average reward fake: 0.33543825149536133 Training d_loss: 0.8940 Training g_loss: 1.2444 Training q_loss: 100.4518 Explore P: 0.2420\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 610 Total reward: 126.0 Average reward fake: 0.4156920909881592 Training d_loss: 1.1325 Training g_loss: 0.9290 Training q_loss: 38.6801 Explore P: 0.2391\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 611 Total reward: 161.0 Average reward fake: 0.4719092845916748 Training d_loss: 1.2841 Training g_loss: 0.7678 Training q_loss: 94.8352 Explore P: 0.2355\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 612 Total reward: 81.0 Average reward fake: 0.5560188293457031 Training d_loss: 1.3874 Training g_loss: 0.6056 Training q_loss: 1973.3918 Explore P: 0.2337\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 613 Total reward: 87.0 Average reward fake: 0.49348679184913635 Training d_loss: 1.2987 Training g_loss: 0.7400 Training q_loss: 108.0391 Explore P: 0.2317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 614 Total reward: 95.0 Average reward fake: 0.46008744835853577 Training d_loss: 1.2753 Training g_loss: 0.8412 Training q_loss: 55.7342 Explore P: 0.2296\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 615 Total reward: 93.0 Average reward fake: 0.48948922753334045 Training d_loss: 1.2669 Training g_loss: 0.9424 Training q_loss: 28.0439 Explore P: 0.2276\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 616 Total reward: 100.0 Average reward fake: 0.4474087655544281 Training d_loss: 1.2714 Training g_loss: 0.8675 Training q_loss: 32.5592 Explore P: 0.2254\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 617 Total reward: 104.0 Average reward fake: 0.4611400067806244 Training d_loss: 1.2492 Training g_loss: 0.9210 Training q_loss: 1198.5868 Explore P: 0.2232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 618 Total reward: 151.0 Average reward fake: 0.43542981147766113 Training d_loss: 1.4813 Training g_loss: 0.9035 Training q_loss: 2140.6772 Explore P: 0.2200\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 619 Total reward: 91.0 Average reward fake: 0.40076160430908203 Training d_loss: 1.2423 Training g_loss: 0.9689 Training q_loss: 98.3524 Explore P: 0.2181\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 620 Total reward: 149.0 Average reward fake: 0.418834388256073 Training d_loss: 1.2037 Training g_loss: 1.0818 Training q_loss: 172.3769 Explore P: 0.2150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 621 Total reward: 69.0 Average reward fake: 0.47007375955581665 Training d_loss: 1.4710 Training g_loss: 0.9399 Training q_loss: 119.0095 Explore P: 0.2136\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 622 Total reward: 178.0 Average reward fake: 0.4065268933773041 Training d_loss: 1.3187 Training g_loss: 1.1286 Training q_loss: 62.6212 Explore P: 0.2100\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 623 Total reward: 136.0 Average reward fake: 0.4451788067817688 Training d_loss: 1.3074 Training g_loss: 1.2295 Training q_loss: 74.4317 Explore P: 0.2073\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 624 Total reward: 89.0 Average reward fake: 0.32360461354255676 Training d_loss: 1.2228 Training g_loss: 1.1773 Training q_loss: 132.1618 Explore P: 0.2056\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 625 Total reward: 7.0 Average reward fake: 0.24401481449604034 Training d_loss: 1.2168 Training g_loss: 1.4458 Training q_loss: 75.0088 Explore P: 0.2054\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 626 Total reward: 15.0 Average reward fake: 0.4054776132106781 Training d_loss: 1.0229 Training g_loss: 0.9096 Training q_loss: 1093.4999 Explore P: 0.2051\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 627 Total reward: 14.0 Average reward fake: 0.2803230285644531 Training d_loss: 0.8879 Training g_loss: 1.2684 Training q_loss: 2164.2212 Explore P: 0.2049\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 628 Total reward: 9.0 Average reward fake: 0.3717852532863617 Training d_loss: 1.2000 Training g_loss: 0.9505 Training q_loss: 68.5448 Explore P: 0.2047\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 629 Total reward: 10.0 Average reward fake: 0.3935273289680481 Training d_loss: 0.8328 Training g_loss: 0.9825 Training q_loss: 614.6068 Explore P: 0.2045\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 630 Total reward: 12.0 Average reward fake: 0.2981390058994293 Training d_loss: 0.9368 Training g_loss: 1.1794 Training q_loss: 5445.4502 Explore P: 0.2043\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 631 Total reward: 10.0 Average reward fake: 0.35718265175819397 Training d_loss: 1.1777 Training g_loss: 1.0477 Training q_loss: 1828.4166 Explore P: 0.2041\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 632 Total reward: 9.0 Average reward fake: 0.3468802273273468 Training d_loss: 0.7736 Training g_loss: 1.0688 Training q_loss: 884.4959 Explore P: 0.2039\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 633 Total reward: 14.0 Average reward fake: 0.428043931722641 Training d_loss: 1.4948 Training g_loss: 0.9559 Training q_loss: 1883.6471 Explore P: 0.2036\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 634 Total reward: 20.0 Average reward fake: 0.374071329832077 Training d_loss: 1.0874 Training g_loss: 1.0285 Training q_loss: 23.7944 Explore P: 0.2032\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 635 Total reward: 10.0 Average reward fake: 0.2742139399051666 Training d_loss: 1.0837 Training g_loss: 1.3199 Training q_loss: 30.5563 Explore P: 0.2030\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 636 Total reward: 14.0 Average reward fake: 0.2725489139556885 Training d_loss: 0.9428 Training g_loss: 1.3051 Training q_loss: 40.2213 Explore P: 0.2028\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 637 Total reward: 7.0 Average reward fake: 0.27656805515289307 Training d_loss: 0.7142 Training g_loss: 1.4651 Training q_loss: 21.3687 Explore P: 0.2026\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 638 Total reward: 10.0 Average reward fake: 0.39092200994491577 Training d_loss: 1.1384 Training g_loss: 1.0186 Training q_loss: 142.8802 Explore P: 0.2024\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 639 Total reward: 12.0 Average reward fake: 0.32149502635002136 Training d_loss: 1.1999 Training g_loss: 1.1780 Training q_loss: 34.0786 Explore P: 0.2022\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 640 Total reward: 7.0 Average reward fake: 0.2742525637149811 Training d_loss: 1.0156 Training g_loss: 1.3171 Training q_loss: 1012.6899 Explore P: 0.2021\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 641 Total reward: 13.0 Average reward fake: 0.26066941022872925 Training d_loss: 0.8869 Training g_loss: 1.3797 Training q_loss: 1818.2654 Explore P: 0.2018\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 642 Total reward: 10.0 Average reward fake: 0.22180095314979553 Training d_loss: 0.7993 Training g_loss: 1.5709 Training q_loss: 819.3994 Explore P: 0.2016\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 643 Total reward: 11.0 Average reward fake: 0.42449140548706055 Training d_loss: 0.9647 Training g_loss: 0.9298 Training q_loss: 73.7325 Explore P: 0.2014\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 644 Total reward: 11.0 Average reward fake: 0.33750152587890625 Training d_loss: 1.3729 Training g_loss: 1.2063 Training q_loss: 2681.6309 Explore P: 0.2012\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 645 Total reward: 8.0 Average reward fake: 0.26271504163742065 Training d_loss: 1.0720 Training g_loss: 1.3135 Training q_loss: 1619.9719 Explore P: 0.2011\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 646 Total reward: 9.0 Average reward fake: 0.29377302527427673 Training d_loss: 0.4785 Training g_loss: 1.3070 Training q_loss: 1044.0765 Explore P: 0.2009\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 647 Total reward: 12.0 Average reward fake: 0.2257126122713089 Training d_loss: 0.5143 Training g_loss: 1.5094 Training q_loss: 768.5098 Explore P: 0.2007\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 648 Total reward: 8.0 Average reward fake: 0.27580443024635315 Training d_loss: 0.8398 Training g_loss: 1.3130 Training q_loss: 30.8421 Explore P: 0.2005\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 649 Total reward: 8.0 Average reward fake: 0.36736616492271423 Training d_loss: 0.8250 Training g_loss: 1.1051 Training q_loss: 128.3047 Explore P: 0.2004\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 650 Total reward: 9.0 Average reward fake: 0.1953439563512802 Training d_loss: 0.7352 Training g_loss: 1.6948 Training q_loss: 29.5655 Explore P: 0.2002\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 651 Total reward: 11.0 Average reward fake: 0.2849505543708801 Training d_loss: 1.2929 Training g_loss: 1.4882 Training q_loss: 114.2814 Explore P: 0.2000\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 652 Total reward: 11.0 Average reward fake: 0.26656389236450195 Training d_loss: 0.4669 Training g_loss: 1.4732 Training q_loss: 25.0771 Explore P: 0.1998\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 653 Total reward: 8.0 Average reward fake: 0.43057721853256226 Training d_loss: 1.0377 Training g_loss: 0.9695 Training q_loss: 18.4857 Explore P: 0.1996\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 654 Total reward: 11.0 Average reward fake: 0.2764113247394562 Training d_loss: 1.3358 Training g_loss: 1.3195 Training q_loss: 60.2842 Explore P: 0.1994\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 655 Total reward: 9.0 Average reward fake: 0.27797573804855347 Training d_loss: 0.4871 Training g_loss: 1.3542 Training q_loss: 156.8251 Explore P: 0.1992\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 656 Total reward: 8.0 Average reward fake: 0.3260307013988495 Training d_loss: 0.8757 Training g_loss: 1.2572 Training q_loss: 118.7812 Explore P: 0.1991\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 657 Total reward: 12.0 Average reward fake: 0.27530720829963684 Training d_loss: 1.1046 Training g_loss: 1.3334 Training q_loss: 81.7440 Explore P: 0.1989\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 658 Total reward: 10.0 Average reward fake: 0.34898993372917175 Training d_loss: 0.9529 Training g_loss: 1.1484 Training q_loss: 60.6287 Explore P: 0.1987\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 659 Total reward: 11.0 Average reward fake: 0.305206835269928 Training d_loss: 0.8209 Training g_loss: 1.2892 Training q_loss: 97.5112 Explore P: 0.1985\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 660 Total reward: 9.0 Average reward fake: 0.421292245388031 Training d_loss: 0.8100 Training g_loss: 0.9128 Training q_loss: 50.0925 Explore P: 0.1983\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 661 Total reward: 14.0 Average reward fake: 0.2752987742424011 Training d_loss: 1.1507 Training g_loss: 1.2830 Training q_loss: 21.2560 Explore P: 0.1980\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 662 Total reward: 10.0 Average reward fake: 0.4494221806526184 Training d_loss: 1.6820 Training g_loss: 0.8939 Training q_loss: 120.2038 Explore P: 0.1978\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 663 Total reward: 12.0 Average reward fake: 0.30625101923942566 Training d_loss: 1.1005 Training g_loss: 1.1984 Training q_loss: 33.4142 Explore P: 0.1976\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 664 Total reward: 11.0 Average reward fake: 0.3469715714454651 Training d_loss: 1.1734 Training g_loss: 1.2539 Training q_loss: 245.3040 Explore P: 0.1974\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 665 Total reward: 10.0 Average reward fake: 0.5041259527206421 Training d_loss: 1.7991 Training g_loss: 0.7818 Training q_loss: 1048.1997 Explore P: 0.1972\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 666 Total reward: 10.0 Average reward fake: 0.3555315136909485 Training d_loss: 1.2116 Training g_loss: 1.0518 Training q_loss: 221.7718 Explore P: 0.1970\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 667 Total reward: 14.0 Average reward fake: 0.34418967366218567 Training d_loss: 1.0568 Training g_loss: 1.2590 Training q_loss: 961.2278 Explore P: 0.1968\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 668 Total reward: 9.0 Average reward fake: 0.3220803141593933 Training d_loss: 1.1153 Training g_loss: 1.1679 Training q_loss: 40.5834 Explore P: 0.1966\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 669 Total reward: 8.0 Average reward fake: 0.3015212416648865 Training d_loss: 0.8754 Training g_loss: 1.1896 Training q_loss: 1149.7380 Explore P: 0.1965\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 670 Total reward: 13.0 Average reward fake: 0.37716078758239746 Training d_loss: 1.0410 Training g_loss: 0.9943 Training q_loss: 21.0568 Explore P: 0.1962\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 671 Total reward: 15.0 Average reward fake: 0.36228710412979126 Training d_loss: 1.0067 Training g_loss: 1.0195 Training q_loss: 278.2755 Explore P: 0.1959\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 672 Total reward: 8.0 Average reward fake: 0.38816267251968384 Training d_loss: 1.0718 Training g_loss: 0.9606 Training q_loss: 153.3479 Explore P: 0.1958\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 673 Total reward: 12.0 Average reward fake: 0.3395083546638489 Training d_loss: 0.7118 Training g_loss: 1.1147 Training q_loss: 67.0847 Explore P: 0.1956\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 674 Total reward: 11.0 Average reward fake: 0.37906262278556824 Training d_loss: 0.7679 Training g_loss: 1.0493 Training q_loss: 1494.5161 Explore P: 0.1954\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 675 Total reward: 9.0 Average reward fake: 0.36146417260169983 Training d_loss: 1.3442 Training g_loss: 1.1732 Training q_loss: 345.2677 Explore P: 0.1952\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 676 Total reward: 12.0 Average reward fake: 0.37057942152023315 Training d_loss: 0.8643 Training g_loss: 1.1942 Training q_loss: 447.8980 Explore P: 0.1950\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 677 Total reward: 10.0 Average reward fake: 0.31851696968078613 Training d_loss: 0.9779 Training g_loss: 1.1682 Training q_loss: 276.0629 Explore P: 0.1948\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 678 Total reward: 10.0 Average reward fake: 0.32682275772094727 Training d_loss: 0.7388 Training g_loss: 1.1376 Training q_loss: 701.7331 Explore P: 0.1946\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 679 Total reward: 10.0 Average reward fake: 0.27000507712364197 Training d_loss: 0.9826 Training g_loss: 1.5597 Training q_loss: 1395.8516 Explore P: 0.1944\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 680 Total reward: 7.0 Average reward fake: 0.4388992190361023 Training d_loss: 1.1168 Training g_loss: 0.8823 Training q_loss: 100.8901 Explore P: 0.1943\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 681 Total reward: 9.0 Average reward fake: 0.329508513212204 Training d_loss: 0.9466 Training g_loss: 1.1634 Training q_loss: 259.2739 Explore P: 0.1941\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 682 Total reward: 9.0 Average reward fake: 0.3342529237270355 Training d_loss: 1.1692 Training g_loss: 1.0871 Training q_loss: 153.7547 Explore P: 0.1940\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 683 Total reward: 8.0 Average reward fake: 0.4337400794029236 Training d_loss: 1.3952 Training g_loss: 0.8622 Training q_loss: 743.7005 Explore P: 0.1938\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 684 Total reward: 10.0 Average reward fake: 0.3263736367225647 Training d_loss: 1.0034 Training g_loss: 1.1713 Training q_loss: 137.3888 Explore P: 0.1936\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 685 Total reward: 10.0 Average reward fake: 0.32174190878868103 Training d_loss: 0.9680 Training g_loss: 1.1776 Training q_loss: 133.1745 Explore P: 0.1934\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 686 Total reward: 7.0 Average reward fake: 0.434946209192276 Training d_loss: 1.1986 Training g_loss: 0.9763 Training q_loss: 363.4270 Explore P: 0.1933\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 687 Total reward: 10.0 Average reward fake: 0.32267430424690247 Training d_loss: 0.9850 Training g_loss: 1.1137 Training q_loss: 987.8391 Explore P: 0.1931\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 688 Total reward: 9.0 Average reward fake: 0.362467497587204 Training d_loss: 1.0384 Training g_loss: 1.2274 Training q_loss: 181.4583 Explore P: 0.1930\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 689 Total reward: 11.0 Average reward fake: 0.38031303882598877 Training d_loss: 0.8156 Training g_loss: 0.9963 Training q_loss: 301.1479 Explore P: 0.1928\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 690 Total reward: 11.0 Average reward fake: 0.2996337413787842 Training d_loss: 1.0072 Training g_loss: 1.2816 Training q_loss: 69.4157 Explore P: 0.1926\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 691 Total reward: 8.0 Average reward fake: 0.3968256711959839 Training d_loss: 1.1690 Training g_loss: 0.9417 Training q_loss: 567.9365 Explore P: 0.1924\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 692 Total reward: 10.0 Average reward fake: 0.3000580668449402 Training d_loss: 1.0294 Training g_loss: 1.2632 Training q_loss: 254.3055 Explore P: 0.1922\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 693 Total reward: 9.0 Average reward fake: 0.39791345596313477 Training d_loss: 0.8181 Training g_loss: 0.9394 Training q_loss: 86.5266 Explore P: 0.1921\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 694 Total reward: 9.0 Average reward fake: 0.4001924395561218 Training d_loss: 1.3449 Training g_loss: 0.9713 Training q_loss: 70.2372 Explore P: 0.1919\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 695 Total reward: 11.0 Average reward fake: 0.3254556953907013 Training d_loss: 1.0059 Training g_loss: 1.1317 Training q_loss: 202.6317 Explore P: 0.1917\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 696 Total reward: 9.0 Average reward fake: 0.3620433509349823 Training d_loss: 1.1368 Training g_loss: 1.1721 Training q_loss: 263.2017 Explore P: 0.1915\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 697 Total reward: 11.0 Average reward fake: 0.4009353518486023 Training d_loss: 1.2428 Training g_loss: 1.0035 Training q_loss: 362.7210 Explore P: 0.1913\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 698 Total reward: 12.0 Average reward fake: 0.37546706199645996 Training d_loss: 1.0025 Training g_loss: 1.0210 Training q_loss: 237.2756 Explore P: 0.1911\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 699 Total reward: 15.0 Average reward fake: 0.4120561480522156 Training d_loss: 0.9757 Training g_loss: 0.9586 Training q_loss: 154.4800 Explore P: 0.1909\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 700 Total reward: 8.0 Average reward fake: 0.39476269483566284 Training d_loss: 0.7909 Training g_loss: 0.9627 Training q_loss: 63.0281 Explore P: 0.1907\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 701 Total reward: 11.0 Average reward fake: 0.38084137439727783 Training d_loss: 1.1348 Training g_loss: 1.0076 Training q_loss: 319.2570 Explore P: 0.1905\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 702 Total reward: 9.0 Average reward fake: 0.24689695239067078 Training d_loss: 0.7302 Training g_loss: 1.4654 Training q_loss: 64.7629 Explore P: 0.1904\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 703 Total reward: 10.0 Average reward fake: 0.31882551312446594 Training d_loss: 0.7497 Training g_loss: 1.1866 Training q_loss: 140.0647 Explore P: 0.1902\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 704 Total reward: 10.0 Average reward fake: 0.3625241816043854 Training d_loss: 1.1486 Training g_loss: 1.0195 Training q_loss: 47.5726 Explore P: 0.1900\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 705 Total reward: 8.0 Average reward fake: 0.3578888773918152 Training d_loss: 1.2344 Training g_loss: 1.1929 Training q_loss: 15.9558 Explore P: 0.1898\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 706 Total reward: 11.0 Average reward fake: 0.30522552132606506 Training d_loss: 0.9537 Training g_loss: 1.1635 Training q_loss: 149.1634 Explore P: 0.1896\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 707 Total reward: 10.0 Average reward fake: 0.45973652601242065 Training d_loss: 1.2080 Training g_loss: 0.8340 Training q_loss: 200.3468 Explore P: 0.1895\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 708 Total reward: 8.0 Average reward fake: 0.33635538816452026 Training d_loss: 0.6994 Training g_loss: 1.1783 Training q_loss: 263.8950 Explore P: 0.1893\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 709 Total reward: 10.0 Average reward fake: 0.27994921803474426 Training d_loss: 1.3276 Training g_loss: 1.3768 Training q_loss: 60.0560 Explore P: 0.1891\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 710 Total reward: 14.0 Average reward fake: 0.39017254114151 Training d_loss: 1.1356 Training g_loss: 0.9820 Training q_loss: 44.7255 Explore P: 0.1889\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 711 Total reward: 10.0 Average reward fake: 0.42628249526023865 Training d_loss: 1.1905 Training g_loss: 0.8958 Training q_loss: 36.4543 Explore P: 0.1887\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 712 Total reward: 7.0 Average reward fake: 0.38610172271728516 Training d_loss: 0.8693 Training g_loss: 0.9759 Training q_loss: 35.0919 Explore P: 0.1886\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 713 Total reward: 7.0 Average reward fake: 0.2981538474559784 Training d_loss: 1.1133 Training g_loss: 1.2587 Training q_loss: 181.9845 Explore P: 0.1885\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 714 Total reward: 8.0 Average reward fake: 0.35381263494491577 Training d_loss: 0.8988 Training g_loss: 1.0685 Training q_loss: 167.5167 Explore P: 0.1883\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 715 Total reward: 11.0 Average reward fake: 0.3249293863773346 Training d_loss: 0.7751 Training g_loss: 1.1513 Training q_loss: 67.1357 Explore P: 0.1881\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 716 Total reward: 11.0 Average reward fake: 0.3150312602519989 Training d_loss: 0.9374 Training g_loss: 1.1464 Training q_loss: 495.9278 Explore P: 0.1879\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 717 Total reward: 12.0 Average reward fake: 0.3891768753528595 Training d_loss: 0.9594 Training g_loss: 0.9778 Training q_loss: 113.3747 Explore P: 0.1877\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 718 Total reward: 8.0 Average reward fake: 0.3760000169277191 Training d_loss: 1.1904 Training g_loss: 0.9813 Training q_loss: 147.2513 Explore P: 0.1876\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 719 Total reward: 8.0 Average reward fake: 0.4240763187408447 Training d_loss: 1.1493 Training g_loss: 1.0012 Training q_loss: 5705.0688 Explore P: 0.1874\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 720 Total reward: 18.0 Average reward fake: 0.39781877398490906 Training d_loss: 1.0928 Training g_loss: 0.9018 Training q_loss: 56.6141 Explore P: 0.1871\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 721 Total reward: 8.0 Average reward fake: 0.4398845136165619 Training d_loss: 1.1822 Training g_loss: 0.8804 Training q_loss: 137.6435 Explore P: 0.1870\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 722 Total reward: 9.0 Average reward fake: 0.3295774459838867 Training d_loss: 0.9335 Training g_loss: 1.1451 Training q_loss: 84.3388 Explore P: 0.1868\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 723 Total reward: 14.0 Average reward fake: 0.38259124755859375 Training d_loss: 1.0916 Training g_loss: 0.9395 Training q_loss: 110.1650 Explore P: 0.1866\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 724 Total reward: 15.0 Average reward fake: 0.3160279095172882 Training d_loss: 1.1668 Training g_loss: 1.2024 Training q_loss: 348.7103 Explore P: 0.1863\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 725 Total reward: 12.0 Average reward fake: 0.43614286184310913 Training d_loss: 1.0034 Training g_loss: 0.8459 Training q_loss: 148.7028 Explore P: 0.1861\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 726 Total reward: 12.0 Average reward fake: 0.4201596677303314 Training d_loss: 1.2330 Training g_loss: 0.9231 Training q_loss: 84.1242 Explore P: 0.1859\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 727 Total reward: 9.0 Average reward fake: 0.3873506188392639 Training d_loss: 0.8925 Training g_loss: 1.0412 Training q_loss: 112.4668 Explore P: 0.1857\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 728 Total reward: 7.0 Average reward fake: 0.2950991988182068 Training d_loss: 1.1154 Training g_loss: 1.1923 Training q_loss: 272.1245 Explore P: 0.1856\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 729 Total reward: 10.0 Average reward fake: 0.3452548086643219 Training d_loss: 0.7938 Training g_loss: 1.0798 Training q_loss: 164.8221 Explore P: 0.1854\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 730 Total reward: 9.0 Average reward fake: 0.38307151198387146 Training d_loss: 0.9959 Training g_loss: 0.9778 Training q_loss: 18.1082 Explore P: 0.1853\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 731 Total reward: 12.0 Average reward fake: 0.42872437834739685 Training d_loss: 1.1854 Training g_loss: 0.8963 Training q_loss: 113.4102 Explore P: 0.1851\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 732 Total reward: 7.0 Average reward fake: 0.3807135820388794 Training d_loss: 1.2982 Training g_loss: 0.9363 Training q_loss: 390.0625 Explore P: 0.1849\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 733 Total reward: 9.0 Average reward fake: 0.47138676047325134 Training d_loss: 1.0662 Training g_loss: 0.7905 Training q_loss: 51.3125 Explore P: 0.1848\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 734 Total reward: 9.0 Average reward fake: 0.35835835337638855 Training d_loss: 1.0077 Training g_loss: 1.0656 Training q_loss: 375.4874 Explore P: 0.1846\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 735 Total reward: 7.0 Average reward fake: 0.34568339586257935 Training d_loss: 1.1853 Training g_loss: 1.0562 Training q_loss: 149.6138 Explore P: 0.1845\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 736 Total reward: 9.0 Average reward fake: 0.4198969900608063 Training d_loss: 1.0691 Training g_loss: 0.8814 Training q_loss: 126.2588 Explore P: 0.1843\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 737 Total reward: 9.0 Average reward fake: 0.365640252828598 Training d_loss: 1.1967 Training g_loss: 1.0168 Training q_loss: 264.0412 Explore P: 0.1842\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 738 Total reward: 11.0 Average reward fake: 0.4086636006832123 Training d_loss: 1.2278 Training g_loss: 0.8929 Training q_loss: 657.0999 Explore P: 0.1840\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 739 Total reward: 10.0 Average reward fake: 0.391602098941803 Training d_loss: 1.1184 Training g_loss: 0.9505 Training q_loss: 124.0149 Explore P: 0.1838\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 740 Total reward: 12.0 Average reward fake: 0.42179805040359497 Training d_loss: 0.9976 Training g_loss: 0.8616 Training q_loss: 851.8747 Explore P: 0.1836\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 741 Total reward: 12.0 Average reward fake: 0.3559667468070984 Training d_loss: 1.0642 Training g_loss: 1.0776 Training q_loss: 650.0703 Explore P: 0.1834\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 742 Total reward: 11.0 Average reward fake: 0.479776531457901 Training d_loss: 1.3172 Training g_loss: 0.8235 Training q_loss: 129.5244 Explore P: 0.1832\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 743 Total reward: 7.0 Average reward fake: 0.2950991690158844 Training d_loss: 0.9619 Training g_loss: 1.2291 Training q_loss: 1228.1992 Explore P: 0.1831\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 744 Total reward: 12.0 Average reward fake: 0.3920961618423462 Training d_loss: 0.8019 Training g_loss: 0.9492 Training q_loss: 121.9221 Explore P: 0.1829\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 745 Total reward: 9.0 Average reward fake: 0.3149159252643585 Training d_loss: 0.9834 Training g_loss: 1.1751 Training q_loss: 506.1216 Explore P: 0.1827\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 746 Total reward: 9.0 Average reward fake: 0.4197250306606293 Training d_loss: 1.4300 Training g_loss: 0.9377 Training q_loss: 173.5560 Explore P: 0.1826\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 747 Total reward: 13.0 Average reward fake: 0.3786075711250305 Training d_loss: 0.8879 Training g_loss: 0.9637 Training q_loss: 103.9884 Explore P: 0.1823\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 748 Total reward: 8.0 Average reward fake: 0.36999475955963135 Training d_loss: 0.9703 Training g_loss: 1.0185 Training q_loss: 31.3534 Explore P: 0.1822\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 749 Total reward: 12.0 Average reward fake: 0.3488907217979431 Training d_loss: 1.2669 Training g_loss: 1.0465 Training q_loss: 164.9686 Explore P: 0.1820\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 750 Total reward: 9.0 Average reward fake: 0.35807669162750244 Training d_loss: 0.9784 Training g_loss: 1.1906 Training q_loss: 360.7654 Explore P: 0.1818\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 751 Total reward: 11.0 Average reward fake: 0.3659173846244812 Training d_loss: 1.0287 Training g_loss: 1.0326 Training q_loss: 67.6239 Explore P: 0.1817\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 752 Total reward: 8.0 Average reward fake: 0.3515436053276062 Training d_loss: 0.9691 Training g_loss: 1.0663 Training q_loss: 135.9062 Explore P: 0.1815\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 753 Total reward: 9.0 Average reward fake: 0.3960866630077362 Training d_loss: 1.1350 Training g_loss: 0.9336 Training q_loss: 927.1234 Explore P: 0.1814\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 754 Total reward: 8.0 Average reward fake: 0.25499647855758667 Training d_loss: 1.0009 Training g_loss: 1.6788 Training q_loss: 266.6006 Explore P: 0.1812\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 755 Total reward: 12.0 Average reward fake: 0.3325757384300232 Training d_loss: 0.7284 Training g_loss: 1.1312 Training q_loss: 246.4991 Explore P: 0.1810\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 756 Total reward: 14.0 Average reward fake: 0.41811758279800415 Training d_loss: 1.0942 Training g_loss: 0.8634 Training q_loss: 217.9375 Explore P: 0.1808\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 757 Total reward: 8.0 Average reward fake: 0.31438547372817993 Training d_loss: 0.9055 Training g_loss: 1.3635 Training q_loss: 172.6733 Explore P: 0.1806\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 758 Total reward: 7.0 Average reward fake: 0.3384767770767212 Training d_loss: 1.1823 Training g_loss: 1.0583 Training q_loss: 115.4913 Explore P: 0.1805\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 759 Total reward: 10.0 Average reward fake: 0.43249455094337463 Training d_loss: 1.1651 Training g_loss: 1.0535 Training q_loss: 953.1670 Explore P: 0.1804\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 760 Total reward: 11.0 Average reward fake: 0.25969693064689636 Training d_loss: 0.9049 Training g_loss: 1.4485 Training q_loss: 240.2718 Explore P: 0.1802\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 761 Total reward: 11.0 Average reward fake: 0.3643729090690613 Training d_loss: 1.2391 Training g_loss: 1.0766 Training q_loss: 271.9414 Explore P: 0.1800\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 762 Total reward: 13.0 Average reward fake: 0.4042930603027344 Training d_loss: 1.1231 Training g_loss: 0.9255 Training q_loss: 245.2156 Explore P: 0.1798\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 763 Total reward: 13.0 Average reward fake: 0.3826456665992737 Training d_loss: 1.0875 Training g_loss: 0.9791 Training q_loss: 180.3884 Explore P: 0.1795\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 764 Total reward: 13.0 Average reward fake: 0.3563048243522644 Training d_loss: 0.8304 Training g_loss: 1.4366 Training q_loss: 109.9658 Explore P: 0.1793\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 765 Total reward: 7.0 Average reward fake: 0.401658833026886 Training d_loss: 1.4217 Training g_loss: 0.9914 Training q_loss: 181.5017 Explore P: 0.1792\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 766 Total reward: 13.0 Average reward fake: 0.35518112778663635 Training d_loss: 1.1052 Training g_loss: 1.0475 Training q_loss: 96.7611 Explore P: 0.1790\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 767 Total reward: 12.0 Average reward fake: 0.3947604298591614 Training d_loss: 1.2723 Training g_loss: 0.9403 Training q_loss: 53.8747 Explore P: 0.1788\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 768 Total reward: 10.0 Average reward fake: 0.3902173638343811 Training d_loss: 1.3159 Training g_loss: 0.9418 Training q_loss: 238.5439 Explore P: 0.1786\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 769 Total reward: 13.0 Average reward fake: 0.305586576461792 Training d_loss: 1.1215 Training g_loss: 1.2284 Training q_loss: 243.5758 Explore P: 0.1784\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 770 Total reward: 13.0 Average reward fake: 0.3187909722328186 Training d_loss: 0.8967 Training g_loss: 1.1633 Training q_loss: 132.4011 Explore P: 0.1782\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 771 Total reward: 8.0 Average reward fake: 0.3739158511161804 Training d_loss: 1.1223 Training g_loss: 1.2599 Training q_loss: 202.0910 Explore P: 0.1780\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 772 Total reward: 9.0 Average reward fake: 0.30607691407203674 Training d_loss: 1.0628 Training g_loss: 1.1750 Training q_loss: 154.6602 Explore P: 0.1779\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 773 Total reward: 9.0 Average reward fake: 0.35959893465042114 Training d_loss: 1.1518 Training g_loss: 0.9992 Training q_loss: 201.5665 Explore P: 0.1777\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 774 Total reward: 9.0 Average reward fake: 0.44066935777664185 Training d_loss: 0.8829 Training g_loss: 0.8553 Training q_loss: 197.5318 Explore P: 0.1776\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 775 Total reward: 8.0 Average reward fake: 0.38180530071258545 Training d_loss: 1.0121 Training g_loss: 0.9977 Training q_loss: 117.4620 Explore P: 0.1775\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 776 Total reward: 15.0 Average reward fake: 0.45059776306152344 Training d_loss: 1.3099 Training g_loss: 0.8509 Training q_loss: 339.0054 Explore P: 0.1772\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 777 Total reward: 12.0 Average reward fake: 0.46727699041366577 Training d_loss: 1.3152 Training g_loss: 0.8308 Training q_loss: 120.6851 Explore P: 0.1770\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 778 Total reward: 11.0 Average reward fake: 0.37001094222068787 Training d_loss: 1.1320 Training g_loss: 0.9791 Training q_loss: 113.1201 Explore P: 0.1768\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 779 Total reward: 10.0 Average reward fake: 0.414259135723114 Training d_loss: 0.9796 Training g_loss: 0.9248 Training q_loss: 540.4958 Explore P: 0.1767\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 780 Total reward: 8.0 Average reward fake: 0.3901030719280243 Training d_loss: 1.1732 Training g_loss: 0.9952 Training q_loss: 255.6882 Explore P: 0.1765\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 781 Total reward: 11.0 Average reward fake: 0.3870900273323059 Training d_loss: 1.0189 Training g_loss: 0.9733 Training q_loss: 142.4910 Explore P: 0.1763\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 782 Total reward: 11.0 Average reward fake: 0.4258165955543518 Training d_loss: 0.9397 Training g_loss: 0.8490 Training q_loss: 239.0785 Explore P: 0.1762\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 783 Total reward: 10.0 Average reward fake: 0.43752679228782654 Training d_loss: 1.5891 Training g_loss: 0.9334 Training q_loss: 198.7520 Explore P: 0.1760\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 784 Total reward: 12.0 Average reward fake: 0.2506035566329956 Training d_loss: 1.3296 Training g_loss: 1.5477 Training q_loss: 438.9589 Explore P: 0.1758\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 785 Total reward: 12.0 Average reward fake: 0.3008389472961426 Training d_loss: 0.7577 Training g_loss: 1.3541 Training q_loss: 460.4852 Explore P: 0.1756\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 786 Total reward: 10.0 Average reward fake: 0.2964968979358673 Training d_loss: 0.8910 Training g_loss: 1.7535 Training q_loss: 524.1132 Explore P: 0.1754\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 787 Total reward: 9.0 Average reward fake: 0.3760828375816345 Training d_loss: 1.1634 Training g_loss: 1.0443 Training q_loss: 270.0949 Explore P: 0.1753\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 788 Total reward: 10.0 Average reward fake: 0.3065893054008484 Training d_loss: 1.1691 Training g_loss: 1.2406 Training q_loss: 286.6028 Explore P: 0.1751\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 789 Total reward: 12.0 Average reward fake: 0.53353351354599 Training d_loss: 1.1851 Training g_loss: 0.6689 Training q_loss: 88.8556 Explore P: 0.1749\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 790 Total reward: 9.0 Average reward fake: 0.32128143310546875 Training d_loss: 1.2887 Training g_loss: 1.4090 Training q_loss: 540.6455 Explore P: 0.1748\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 791 Total reward: 12.0 Average reward fake: 0.27999022603034973 Training d_loss: 0.7275 Training g_loss: 1.3376 Training q_loss: 702.1683 Explore P: 0.1746\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 792 Total reward: 7.0 Average reward fake: 0.37221604585647583 Training d_loss: 0.9295 Training g_loss: 1.0068 Training q_loss: 185.9862 Explore P: 0.1744\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 793 Total reward: 8.0 Average reward fake: 0.4041967988014221 Training d_loss: 1.2270 Training g_loss: 0.9296 Training q_loss: 328.1776 Explore P: 0.1743\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 794 Total reward: 8.0 Average reward fake: 0.403878390789032 Training d_loss: 0.8513 Training g_loss: 0.9613 Training q_loss: 327.8006 Explore P: 0.1742\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 795 Total reward: 12.0 Average reward fake: 0.3762935996055603 Training d_loss: 1.3720 Training g_loss: 1.1154 Training q_loss: 225.7691 Explore P: 0.1740\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 796 Total reward: 10.0 Average reward fake: 0.4071308970451355 Training d_loss: 1.2093 Training g_loss: 0.9307 Training q_loss: 147.2820 Explore P: 0.1738\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 797 Total reward: 8.0 Average reward fake: 0.3477240800857544 Training d_loss: 0.9234 Training g_loss: 1.0973 Training q_loss: 195.2785 Explore P: 0.1737\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 798 Total reward: 10.0 Average reward fake: 0.3715549111366272 Training d_loss: 1.0890 Training g_loss: 0.9966 Training q_loss: 36.6737 Explore P: 0.1735\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 799 Total reward: 15.0 Average reward fake: 0.33209553360939026 Training d_loss: 0.6230 Training g_loss: 1.1502 Training q_loss: 121.8679 Explore P: 0.1733\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 800 Total reward: 7.0 Average reward fake: 0.32973402738571167 Training d_loss: 0.7306 Training g_loss: 1.1095 Training q_loss: 49.7164 Explore P: 0.1732\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 801 Total reward: 9.0 Average reward fake: 0.30380409955978394 Training d_loss: 1.0042 Training g_loss: 1.2150 Training q_loss: 220.0208 Explore P: 0.1730\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 802 Total reward: 12.0 Average reward fake: 0.4413045048713684 Training d_loss: 1.2439 Training g_loss: 0.8136 Training q_loss: 183.8045 Explore P: 0.1728\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 803 Total reward: 9.0 Average reward fake: 0.43089038133621216 Training d_loss: 1.1479 Training g_loss: 0.8821 Training q_loss: 187.9279 Explore P: 0.1727\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 804 Total reward: 9.0 Average reward fake: 0.4268004298210144 Training d_loss: 1.0281 Training g_loss: 0.8583 Training q_loss: 182.6941 Explore P: 0.1725\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 805 Total reward: 15.0 Average reward fake: 0.3114832043647766 Training d_loss: 1.3694 Training g_loss: 1.1925 Training q_loss: 128.6039 Explore P: 0.1723\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 806 Total reward: 12.0 Average reward fake: 0.34893110394477844 Training d_loss: 0.9282 Training g_loss: 1.2196 Training q_loss: 128.2073 Explore P: 0.1721\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 807 Total reward: 12.0 Average reward fake: 0.34172773361206055 Training d_loss: 0.9856 Training g_loss: 1.0895 Training q_loss: 109.7150 Explore P: 0.1719\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 808 Total reward: 7.0 Average reward fake: 0.352973073720932 Training d_loss: 0.9534 Training g_loss: 1.2329 Training q_loss: 112.0613 Explore P: 0.1718\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 809 Total reward: 16.0 Average reward fake: 0.340918630361557 Training d_loss: 1.0489 Training g_loss: 1.1039 Training q_loss: 153.5074 Explore P: 0.1715\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 810 Total reward: 8.0 Average reward fake: 0.3964061737060547 Training d_loss: 1.0671 Training g_loss: 0.9462 Training q_loss: 201.8456 Explore P: 0.1714\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 811 Total reward: 11.0 Average reward fake: 0.3061451315879822 Training d_loss: 0.7959 Training g_loss: 1.2312 Training q_loss: 312.6192 Explore P: 0.1712\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 812 Total reward: 10.0 Average reward fake: 0.3062437176704407 Training d_loss: 1.2403 Training g_loss: 1.1610 Training q_loss: 177.4429 Explore P: 0.1711\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 813 Total reward: 7.0 Average reward fake: 0.409921258687973 Training d_loss: 0.9410 Training g_loss: 0.9003 Training q_loss: 353.7936 Explore P: 0.1710\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 814 Total reward: 8.0 Average reward fake: 0.4582608640193939 Training d_loss: 1.2560 Training g_loss: 0.8481 Training q_loss: 252.6019 Explore P: 0.1708\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 815 Total reward: 9.0 Average reward fake: 0.37326693534851074 Training d_loss: 0.9885 Training g_loss: 0.9985 Training q_loss: 123.7024 Explore P: 0.1707\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 816 Total reward: 11.0 Average reward fake: 0.364228755235672 Training d_loss: 1.2008 Training g_loss: 1.0070 Training q_loss: 143.2871 Explore P: 0.1705\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 817 Total reward: 11.0 Average reward fake: 0.404259592294693 Training d_loss: 0.9209 Training g_loss: 0.9367 Training q_loss: 79.8190 Explore P: 0.1703\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 818 Total reward: 9.0 Average reward fake: 0.3413078188896179 Training d_loss: 1.0253 Training g_loss: 1.1003 Training q_loss: 179.3187 Explore P: 0.1702\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 819 Total reward: 7.0 Average reward fake: 0.40919047594070435 Training d_loss: 0.8986 Training g_loss: 0.9036 Training q_loss: 93.7912 Explore P: 0.1701\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 820 Total reward: 12.0 Average reward fake: 0.35594943165779114 Training d_loss: 1.3251 Training g_loss: 1.3086 Training q_loss: 101.9974 Explore P: 0.1699\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 821 Total reward: 12.0 Average reward fake: 0.40397268533706665 Training d_loss: 0.9517 Training g_loss: 0.9594 Training q_loss: 47.9751 Explore P: 0.1697\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 822 Total reward: 11.0 Average reward fake: 0.374253511428833 Training d_loss: 0.9690 Training g_loss: 0.9878 Training q_loss: 253.5039 Explore P: 0.1695\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 823 Total reward: 9.0 Average reward fake: 0.3591734766960144 Training d_loss: 1.0040 Training g_loss: 1.0649 Training q_loss: 167.9962 Explore P: 0.1694\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 824 Total reward: 9.0 Average reward fake: 0.41444841027259827 Training d_loss: 1.4182 Training g_loss: 1.0401 Training q_loss: 48.4146 Explore P: 0.1692\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 825 Total reward: 8.0 Average reward fake: 0.3580625653266907 Training d_loss: 0.7891 Training g_loss: 1.2430 Training q_loss: 267.2228 Explore P: 0.1691\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 826 Total reward: 12.0 Average reward fake: 0.3022643029689789 Training d_loss: 1.1101 Training g_loss: 1.3314 Training q_loss: 219.6290 Explore P: 0.1689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 827 Total reward: 11.0 Average reward fake: 0.3456938564777374 Training d_loss: 1.2251 Training g_loss: 1.0778 Training q_loss: 436.3334 Explore P: 0.1687\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 828 Total reward: 9.0 Average reward fake: 0.3770100772380829 Training d_loss: 0.9780 Training g_loss: 1.1842 Training q_loss: 224.2885 Explore P: 0.1686\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 829 Total reward: 10.0 Average reward fake: 0.38486048579216003 Training d_loss: 1.1677 Training g_loss: 1.0864 Training q_loss: 259.2510 Explore P: 0.1684\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 830 Total reward: 17.0 Average reward fake: 0.35526323318481445 Training d_loss: 0.8435 Training g_loss: 1.1549 Training q_loss: 94.3854 Explore P: 0.1682\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 831 Total reward: 9.0 Average reward fake: 0.3144136667251587 Training d_loss: 0.9780 Training g_loss: 1.3743 Training q_loss: 153.5233 Explore P: 0.1680\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 832 Total reward: 12.0 Average reward fake: 0.4189840853214264 Training d_loss: 1.1828 Training g_loss: 0.8896 Training q_loss: 198.8152 Explore P: 0.1678\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 833 Total reward: 53.0 Average reward fake: 0.39956560730934143 Training d_loss: 1.1536 Training g_loss: 1.1301 Training q_loss: 239.9620 Explore P: 0.1670\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 834 Total reward: 19.0 Average reward fake: 0.3951355516910553 Training d_loss: 1.0283 Training g_loss: 0.9837 Training q_loss: 187.9921 Explore P: 0.1667\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 835 Total reward: 24.0 Average reward fake: 0.474093496799469 Training d_loss: 1.3241 Training g_loss: 0.9931 Training q_loss: 71.3203 Explore P: 0.1663\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 836 Total reward: 18.0 Average reward fake: 0.4314369559288025 Training d_loss: 1.1840 Training g_loss: 1.2065 Training q_loss: 80.2937 Explore P: 0.1660\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 837 Total reward: 19.0 Average reward fake: 0.39945098757743835 Training d_loss: 1.2270 Training g_loss: 1.2745 Training q_loss: 106.2702 Explore P: 0.1657\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 838 Total reward: 27.0 Average reward fake: 0.43726855516433716 Training d_loss: 1.1788 Training g_loss: 1.0134 Training q_loss: 90.8952 Explore P: 0.1653\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 839 Total reward: 41.0 Average reward fake: 0.4675937294960022 Training d_loss: 1.2720 Training g_loss: 0.7742 Training q_loss: 43.6090 Explore P: 0.1647\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 840 Total reward: 28.0 Average reward fake: 0.5559958219528198 Training d_loss: 1.3782 Training g_loss: 0.6188 Training q_loss: 42.7905 Explore P: 0.1643\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 841 Total reward: 38.0 Average reward fake: 0.4327620565891266 Training d_loss: 1.2497 Training g_loss: 1.0365 Training q_loss: 102.6310 Explore P: 0.1637\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 842 Total reward: 67.0 Average reward fake: 0.44593220949172974 Training d_loss: 1.2663 Training g_loss: 1.0532 Training q_loss: 19.2707 Explore P: 0.1626\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 843 Total reward: 25.0 Average reward fake: 0.4375278353691101 Training d_loss: 1.2913 Training g_loss: 1.0570 Training q_loss: 365.7063 Explore P: 0.1623\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 844 Total reward: 18.0 Average reward fake: 0.46710020303726196 Training d_loss: 1.0976 Training g_loss: 0.7842 Training q_loss: 42.9188 Explore P: 0.1620\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 845 Total reward: 21.0 Average reward fake: 0.46945780515670776 Training d_loss: 1.2446 Training g_loss: 0.9581 Training q_loss: 363.1159 Explore P: 0.1617\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 846 Total reward: 20.0 Average reward fake: 0.3921763300895691 Training d_loss: 1.0398 Training g_loss: 1.0493 Training q_loss: 1125.6907 Explore P: 0.1614\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 847 Total reward: 92.0 Average reward fake: 0.47507014870643616 Training d_loss: 1.3651 Training g_loss: 1.1452 Training q_loss: 1058.8810 Explore P: 0.1600\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 848 Total reward: 62.0 Average reward fake: 0.45049986243247986 Training d_loss: 1.2864 Training g_loss: 0.9803 Training q_loss: 79.3417 Explore P: 0.1591\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 849 Total reward: 22.0 Average reward fake: 0.45215123891830444 Training d_loss: 1.1968 Training g_loss: 1.0405 Training q_loss: 147.5226 Explore P: 0.1587\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 850 Total reward: 40.0 Average reward fake: 0.5051954388618469 Training d_loss: 1.3790 Training g_loss: 0.9357 Training q_loss: 347.1062 Explore P: 0.1581\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 851 Total reward: 68.0 Average reward fake: 0.5071180462837219 Training d_loss: 1.4144 Training g_loss: 0.6770 Training q_loss: 710.6000 Explore P: 0.1571\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 852 Total reward: 67.0 Average reward fake: 0.5190539956092834 Training d_loss: 1.4880 Training g_loss: 0.6954 Training q_loss: 429.2795 Explore P: 0.1561\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 853 Total reward: 24.0 Average reward fake: 0.44751447439193726 Training d_loss: 1.0993 Training g_loss: 0.8414 Training q_loss: 262.3504 Explore P: 0.1558\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 854 Total reward: 65.0 Average reward fake: 0.4418451189994812 Training d_loss: 1.3998 Training g_loss: 0.7844 Training q_loss: 147.8980 Explore P: 0.1549\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 855 Total reward: 47.0 Average reward fake: 0.4568885862827301 Training d_loss: 1.2934 Training g_loss: 0.9992 Training q_loss: 98.0324 Explore P: 0.1542\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 856 Total reward: 53.0 Average reward fake: 0.5018851161003113 Training d_loss: 1.2538 Training g_loss: 0.7313 Training q_loss: 69.7046 Explore P: 0.1534\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 857 Total reward: 143.0 Average reward fake: 0.4735003113746643 Training d_loss: 1.2660 Training g_loss: 0.8006 Training q_loss: 49.9427 Explore P: 0.1514\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 858 Total reward: 74.0 Average reward fake: 0.488527774810791 Training d_loss: 1.4972 Training g_loss: 0.7606 Training q_loss: 29.7473 Explore P: 0.1503\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 859 Total reward: 169.0 Average reward fake: 0.5084898471832275 Training d_loss: 1.3262 Training g_loss: 0.7361 Training q_loss: 1124.9768 Explore P: 0.1480\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 860 Total reward: 101.0 Average reward fake: 0.4729616045951843 Training d_loss: 1.4450 Training g_loss: 0.7782 Training q_loss: 44.6600 Explore P: 0.1466\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 861 Total reward: 162.0 Average reward fake: 0.47523683309555054 Training d_loss: 1.3613 Training g_loss: 0.8331 Training q_loss: 57.3682 Explore P: 0.1444\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 862 Total reward: 199.0 Average reward fake: 0.4698219299316406 Training d_loss: 1.2773 Training g_loss: 1.0329 Training q_loss: 26.5284 Explore P: 0.1417\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 863 Total reward: 119.0 Average reward fake: 0.4476141333580017 Training d_loss: 1.1831 Training g_loss: 1.0798 Training q_loss: 8.1687 Explore P: 0.1402\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 864 Total reward: 85.0 Average reward fake: 0.5152420997619629 Training d_loss: 1.4456 Training g_loss: 0.6685 Training q_loss: 65.1069 Explore P: 0.1391\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 865 Total reward: 124.0 Average reward fake: 0.35383084416389465 Training d_loss: 1.1011 Training g_loss: 1.4894 Training q_loss: 300.2415 Explore P: 0.1375\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 866 Total reward: 128.0 Average reward fake: 0.5854285955429077 Training d_loss: 1.3927 Training g_loss: 0.5682 Training q_loss: 12.4695 Explore P: 0.1359\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 867 Total reward: 151.0 Average reward fake: 0.5339025259017944 Training d_loss: 1.4749 Training g_loss: 0.6460 Training q_loss: 1819.4838 Explore P: 0.1340\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 868 Total reward: 173.0 Average reward fake: 0.5127017498016357 Training d_loss: 1.3650 Training g_loss: 0.9349 Training q_loss: 61.4193 Explore P: 0.1319\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 869 Total reward: 199.0 Average reward fake: 0.37684378027915955 Training d_loss: 1.1034 Training g_loss: 1.2341 Training q_loss: 2535.3433 Explore P: 0.1295\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 870 Total reward: 140.0 Average reward fake: 0.508309006690979 Training d_loss: 1.4877 Training g_loss: 0.7422 Training q_loss: 39.8820 Explore P: 0.1278\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 871 Total reward: 199.0 Average reward fake: 0.44705334305763245 Training d_loss: 1.2782 Training g_loss: 0.8405 Training q_loss: 30.3587 Explore P: 0.1255\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 872 Total reward: 199.0 Average reward fake: 0.4534967541694641 Training d_loss: 1.2163 Training g_loss: 0.8529 Training q_loss: 31.9315 Explore P: 0.1232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 873 Total reward: 199.0 Average reward fake: 0.4642842710018158 Training d_loss: 1.2305 Training g_loss: 1.0677 Training q_loss: 42.6676 Explore P: 0.1210\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 874 Total reward: 199.0 Average reward fake: 0.3638117015361786 Training d_loss: 1.0921 Training g_loss: 1.4189 Training q_loss: 41.6622 Explore P: 0.1188\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 875 Total reward: 199.0 Average reward fake: 0.5473641157150269 Training d_loss: 1.3148 Training g_loss: 0.6508 Training q_loss: 48.5022 Explore P: 0.1166\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 876 Total reward: 199.0 Average reward fake: 0.45902523398399353 Training d_loss: 1.3513 Training g_loss: 0.7871 Training q_loss: 35.7015 Explore P: 0.1145\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 877 Total reward: 152.0 Average reward fake: 0.5612236261367798 Training d_loss: 1.5203 Training g_loss: 0.6180 Training q_loss: 78.8758 Explore P: 0.1130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 878 Total reward: 199.0 Average reward fake: 0.5072553753852844 Training d_loss: 1.4585 Training g_loss: 0.7184 Training q_loss: 29.2919 Explore P: 0.1109\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 879 Total reward: 199.0 Average reward fake: 0.375542551279068 Training d_loss: 1.1649 Training g_loss: 1.0239 Training q_loss: 51.3536 Explore P: 0.1089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 880 Total reward: 199.0 Average reward fake: 0.47939038276672363 Training d_loss: 1.5553 Training g_loss: 0.7810 Training q_loss: 178.8434 Explore P: 0.1070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 881 Total reward: 199.0 Average reward fake: 0.4919620454311371 Training d_loss: 1.2975 Training g_loss: 0.7475 Training q_loss: 88.4349 Explore P: 0.1051\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 882 Total reward: 199.0 Average reward fake: 0.48956552147865295 Training d_loss: 1.3383 Training g_loss: 0.7141 Training q_loss: 87.6940 Explore P: 0.1032\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 883 Total reward: 199.0 Average reward fake: 0.4105874001979828 Training d_loss: 1.1676 Training g_loss: 0.9954 Training q_loss: 62.7693 Explore P: 0.1014\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 884 Total reward: 199.0 Average reward fake: 0.5536087155342102 Training d_loss: 1.4255 Training g_loss: 0.6197 Training q_loss: 38.8094 Explore P: 0.0996\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 885 Total reward: 199.0 Average reward fake: 0.3477306365966797 Training d_loss: 1.0598 Training g_loss: 1.2722 Training q_loss: 44.8746 Explore P: 0.0978\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 886 Total reward: 199.0 Average reward fake: 0.44769659638404846 Training d_loss: 1.3500 Training g_loss: 0.9968 Training q_loss: 76.2871 Explore P: 0.0961\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 887 Total reward: 199.0 Average reward fake: 0.5523737668991089 Training d_loss: 1.5490 Training g_loss: 0.6219 Training q_loss: 37.0859 Explore P: 0.0944\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 888 Total reward: 199.0 Average reward fake: 0.4753243327140808 Training d_loss: 1.2832 Training g_loss: 0.7851 Training q_loss: 185.5042 Explore P: 0.0927\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 889 Total reward: 199.0 Average reward fake: 0.4356812536716461 Training d_loss: 1.2793 Training g_loss: 1.0801 Training q_loss: 65.2625 Explore P: 0.0911\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 890 Total reward: 169.0 Average reward fake: 0.44980573654174805 Training d_loss: 1.2610 Training g_loss: 0.8796 Training q_loss: 37.6070 Explore P: 0.0897\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 891 Total reward: 199.0 Average reward fake: 0.35082465410232544 Training d_loss: 0.8449 Training g_loss: 1.4569 Training q_loss: 5.3135 Explore P: 0.0882\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 892 Total reward: 199.0 Average reward fake: 0.39913782477378845 Training d_loss: 1.3099 Training g_loss: 1.2214 Training q_loss: 50.7515 Explore P: 0.0866\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 893 Total reward: 199.0 Average reward fake: 0.40335211157798767 Training d_loss: 1.1841 Training g_loss: 0.9786 Training q_loss: 32.8331 Explore P: 0.0851\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 894 Total reward: 199.0 Average reward fake: 0.4293193221092224 Training d_loss: 1.2939 Training g_loss: 1.1411 Training q_loss: 22.3571 Explore P: 0.0836\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 895 Total reward: 199.0 Average reward fake: 0.449729859828949 Training d_loss: 1.2110 Training g_loss: 0.8514 Training q_loss: 39.7867 Explore P: 0.0822\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 896 Total reward: 199.0 Average reward fake: 0.4711282253265381 Training d_loss: 1.2973 Training g_loss: 0.8000 Training q_loss: 16.9027 Explore P: 0.0808\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 897 Total reward: 196.0 Average reward fake: 0.44401177763938904 Training d_loss: 1.2037 Training g_loss: 1.1835 Training q_loss: 25.6792 Explore P: 0.0794\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 898 Total reward: 199.0 Average reward fake: 0.535315990447998 Training d_loss: 1.4914 Training g_loss: 0.6584 Training q_loss: 26.0280 Explore P: 0.0780\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 899 Total reward: 199.0 Average reward fake: 0.36456194519996643 Training d_loss: 1.2992 Training g_loss: 1.0325 Training q_loss: 21.6504 Explore P: 0.0767\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 900 Total reward: 166.0 Average reward fake: 0.49646997451782227 Training d_loss: 1.3290 Training g_loss: 1.0406 Training q_loss: 12.6549 Explore P: 0.0756\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 901 Total reward: 193.0 Average reward fake: 0.5068396329879761 Training d_loss: 1.3908 Training g_loss: 0.7009 Training q_loss: 14.4760 Explore P: 0.0743\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 902 Total reward: 199.0 Average reward fake: 0.441992849111557 Training d_loss: 1.2191 Training g_loss: 0.8621 Training q_loss: 16.0935 Explore P: 0.0731\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 903 Total reward: 199.0 Average reward fake: 0.41791409254074097 Training d_loss: 1.4070 Training g_loss: 1.6281 Training q_loss: 10.1170 Explore P: 0.0718\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 904 Total reward: 199.0 Average reward fake: 0.4348544180393219 Training d_loss: 1.2781 Training g_loss: 1.1553 Training q_loss: 11.0291 Explore P: 0.0706\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 905 Total reward: 199.0 Average reward fake: 0.4794686734676361 Training d_loss: 1.2441 Training g_loss: 0.7696 Training q_loss: 10.6258 Explore P: 0.0694\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 906 Total reward: 199.0 Average reward fake: 0.5593735575675964 Training d_loss: 1.5071 Training g_loss: 0.5888 Training q_loss: 15.4357 Explore P: 0.0682\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 907 Total reward: 199.0 Average reward fake: 0.43765538930892944 Training d_loss: 1.2522 Training g_loss: 0.8481 Training q_loss: 38.3433 Explore P: 0.0671\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 908 Total reward: 199.0 Average reward fake: 0.3398706912994385 Training d_loss: 1.1047 Training g_loss: 1.7818 Training q_loss: 9.4200 Explore P: 0.0660\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 909 Total reward: 199.0 Average reward fake: 0.46875977516174316 Training d_loss: 1.3025 Training g_loss: 1.0558 Training q_loss: 10.1916 Explore P: 0.0649\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 910 Total reward: 161.0 Average reward fake: 0.47036677598953247 Training d_loss: 1.3524 Training g_loss: 0.7683 Training q_loss: 24.0352 Explore P: 0.0640\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 911 Total reward: 199.0 Average reward fake: 0.5879033803939819 Training d_loss: 1.5839 Training g_loss: 0.5531 Training q_loss: 63.6536 Explore P: 0.0629\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 912 Total reward: 178.0 Average reward fake: 0.3204672038555145 Training d_loss: 0.8286 Training g_loss: 1.6429 Training q_loss: 11.2184 Explore P: 0.0620\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 913 Total reward: 194.0 Average reward fake: 0.4852510094642639 Training d_loss: 1.4555 Training g_loss: 0.7650 Training q_loss: 2.7165 Explore P: 0.0610\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 914 Total reward: 159.0 Average reward fake: 0.3646809756755829 Training d_loss: 1.2484 Training g_loss: 1.2230 Training q_loss: 10.4018 Explore P: 0.0602\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 915 Total reward: 130.0 Average reward fake: 0.529194712638855 Training d_loss: 1.6200 Training g_loss: 0.6364 Training q_loss: 10.8294 Explore P: 0.0595\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 916 Total reward: 199.0 Average reward fake: 0.2898865342140198 Training d_loss: 0.5281 Training g_loss: 1.2919 Training q_loss: 10.5544 Explore P: 0.0586\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 917 Total reward: 142.0 Average reward fake: 0.5153576731681824 Training d_loss: 1.2700 Training g_loss: 0.7510 Training q_loss: 12.7342 Explore P: 0.0579\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 918 Total reward: 199.0 Average reward fake: 0.5529966354370117 Training d_loss: 1.5324 Training g_loss: 0.6128 Training q_loss: 19.4321 Explore P: 0.0569\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 919 Total reward: 180.0 Average reward fake: 0.43651285767555237 Training d_loss: 1.2685 Training g_loss: 1.1090 Training q_loss: 6.8587 Explore P: 0.0561\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 920 Total reward: 199.0 Average reward fake: 0.44836002588272095 Training d_loss: 1.1731 Training g_loss: 0.8218 Training q_loss: 5.9798 Explore P: 0.0552\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 921 Total reward: 199.0 Average reward fake: 0.5039076209068298 Training d_loss: 1.1956 Training g_loss: 1.0932 Training q_loss: 5.6916 Explore P: 0.0543\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 922 Total reward: 137.0 Average reward fake: 0.4444900453090668 Training d_loss: 1.2494 Training g_loss: 1.3800 Training q_loss: 7.5918 Explore P: 0.0537\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 923 Total reward: 199.0 Average reward fake: 0.6226497292518616 Training d_loss: 2.2049 Training g_loss: 0.5684 Training q_loss: 9.0571 Explore P: 0.0528\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 924 Total reward: 199.0 Average reward fake: 0.2609116733074188 Training d_loss: 1.0262 Training g_loss: 2.6214 Training q_loss: 6.4940 Explore P: 0.0520\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 925 Total reward: 173.0 Average reward fake: 0.43401700258255005 Training d_loss: 1.2030 Training g_loss: 0.9802 Training q_loss: 16.4628 Explore P: 0.0513\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 926 Total reward: 199.0 Average reward fake: 0.43960151076316833 Training d_loss: 1.2505 Training g_loss: 1.1044 Training q_loss: 11.6548 Explore P: 0.0505\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 927 Total reward: 165.0 Average reward fake: 0.3893303871154785 Training d_loss: 1.6814 Training g_loss: 1.0284 Training q_loss: 22.0272 Explore P: 0.0498\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 928 Total reward: 183.0 Average reward fake: 0.4361134469509125 Training d_loss: 1.7284 Training g_loss: 0.9669 Training q_loss: 11.5785 Explore P: 0.0491\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 929 Total reward: 199.0 Average reward fake: 0.5055744051933289 Training d_loss: 1.3057 Training g_loss: 0.8014 Training q_loss: 2.2479 Explore P: 0.0483\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 930 Total reward: 166.0 Average reward fake: 0.4596797525882721 Training d_loss: 1.2028 Training g_loss: 1.2292 Training q_loss: 10.7940 Explore P: 0.0477\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 931 Total reward: 141.0 Average reward fake: 0.36112263798713684 Training d_loss: 1.1670 Training g_loss: 1.3289 Training q_loss: 40.1710 Explore P: 0.0471\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 932 Total reward: 167.0 Average reward fake: 0.3952156603336334 Training d_loss: 1.3421 Training g_loss: 1.7630 Training q_loss: 9.9427 Explore P: 0.0465\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 933 Total reward: 137.0 Average reward fake: 0.3140743374824524 Training d_loss: 0.9450 Training g_loss: 2.0446 Training q_loss: 6.2165 Explore P: 0.0460\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 934 Total reward: 137.0 Average reward fake: 0.5290267467498779 Training d_loss: 1.3616 Training g_loss: 0.6579 Training q_loss: 19.7961 Explore P: 0.0455\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 935 Total reward: 126.0 Average reward fake: 0.33093076944351196 Training d_loss: 1.4715 Training g_loss: 2.3639 Training q_loss: 11.0813 Explore P: 0.0451\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 936 Total reward: 146.0 Average reward fake: 0.5124090313911438 Training d_loss: 1.4336 Training g_loss: 0.6785 Training q_loss: 3.1490 Explore P: 0.0446\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 937 Total reward: 126.0 Average reward fake: 0.34436744451522827 Training d_loss: 1.0248 Training g_loss: 1.6256 Training q_loss: 4.7729 Explore P: 0.0442\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 938 Total reward: 143.0 Average reward fake: 0.40459179878234863 Training d_loss: 1.3403 Training g_loss: 1.7567 Training q_loss: 7.3268 Explore P: 0.0437\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 939 Total reward: 143.0 Average reward fake: 0.4596478343009949 Training d_loss: 1.2835 Training g_loss: 1.7803 Training q_loss: 18.5300 Explore P: 0.0432\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 940 Total reward: 129.0 Average reward fake: 0.4122973382472992 Training d_loss: 1.1907 Training g_loss: 1.4762 Training q_loss: 13.6099 Explore P: 0.0428\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 941 Total reward: 143.0 Average reward fake: 0.3821001946926117 Training d_loss: 1.0429 Training g_loss: 1.4081 Training q_loss: 8.4962 Explore P: 0.0423\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 942 Total reward: 122.0 Average reward fake: 0.4387410283088684 Training d_loss: 1.4219 Training g_loss: 1.7071 Training q_loss: 2.8447 Explore P: 0.0419\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 943 Total reward: 199.0 Average reward fake: 0.49183645844459534 Training d_loss: 1.2439 Training g_loss: 0.7160 Training q_loss: 4.0498 Explore P: 0.0413\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 944 Total reward: 160.0 Average reward fake: 0.2769284248352051 Training d_loss: 0.6421 Training g_loss: 1.8773 Training q_loss: 2.2148 Explore P: 0.0408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 945 Total reward: 146.0 Average reward fake: 0.3789866864681244 Training d_loss: 1.0753 Training g_loss: 1.8029 Training q_loss: 9.4740 Explore P: 0.0403\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 946 Total reward: 169.0 Average reward fake: 0.39973288774490356 Training d_loss: 0.9915 Training g_loss: 1.3490 Training q_loss: 6.7313 Explore P: 0.0398\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 947 Total reward: 128.0 Average reward fake: 0.4564303457736969 Training d_loss: 1.5465 Training g_loss: 1.0363 Training q_loss: 5.4767 Explore P: 0.0395\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 948 Total reward: 118.0 Average reward fake: 0.6078076362609863 Training d_loss: 1.6840 Training g_loss: 0.5567 Training q_loss: 3.7742 Explore P: 0.0391\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 949 Total reward: 118.0 Average reward fake: 0.33433228731155396 Training d_loss: 1.2949 Training g_loss: 1.7651 Training q_loss: 13.8506 Explore P: 0.0388\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 950 Total reward: 113.0 Average reward fake: 0.6126774549484253 Training d_loss: 1.5295 Training g_loss: 0.5478 Training q_loss: 4.6984 Explore P: 0.0384\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 951 Total reward: 160.0 Average reward fake: 0.43940114974975586 Training d_loss: 1.4730 Training g_loss: 0.8435 Training q_loss: 1151.2211 Explore P: 0.0380\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 952 Total reward: 118.0 Average reward fake: 0.3870985805988312 Training d_loss: 1.0969 Training g_loss: 1.4379 Training q_loss: 17.5345 Explore P: 0.0377\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 953 Total reward: 133.0 Average reward fake: 0.48511162400245667 Training d_loss: 1.4608 Training g_loss: 1.2053 Training q_loss: 2.2712 Explore P: 0.0373\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 954 Total reward: 120.0 Average reward fake: 0.48276257514953613 Training d_loss: 1.3176 Training g_loss: 0.8062 Training q_loss: 3.6758 Explore P: 0.0370\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 955 Total reward: 135.0 Average reward fake: 0.3909475803375244 Training d_loss: 1.0852 Training g_loss: 1.4368 Training q_loss: 38.5891 Explore P: 0.0366\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 956 Total reward: 120.0 Average reward fake: 0.44846266508102417 Training d_loss: 1.2215 Training g_loss: 1.2620 Training q_loss: 11.3219 Explore P: 0.0363\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 957 Total reward: 136.0 Average reward fake: 0.42516836524009705 Training d_loss: 1.1782 Training g_loss: 1.4417 Training q_loss: 4.1317 Explore P: 0.0359\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 958 Total reward: 161.0 Average reward fake: 0.3844979703426361 Training d_loss: 0.9274 Training g_loss: 1.0498 Training q_loss: 15.6009 Explore P: 0.0355\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 959 Total reward: 121.0 Average reward fake: 0.4230178892612457 Training d_loss: 1.6237 Training g_loss: 1.7148 Training q_loss: 32.0457 Explore P: 0.0352\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 960 Total reward: 116.0 Average reward fake: 0.39752301573753357 Training d_loss: 0.9866 Training g_loss: 0.9935 Training q_loss: 32.2130 Explore P: 0.0349\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 961 Total reward: 115.0 Average reward fake: 0.4685294032096863 Training d_loss: 1.4242 Training g_loss: 0.9289 Training q_loss: 13.0327 Explore P: 0.0346\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 962 Total reward: 117.0 Average reward fake: 0.4256224036216736 Training d_loss: 1.3252 Training g_loss: 1.3491 Training q_loss: 19.2789 Explore P: 0.0344\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 963 Total reward: 102.0 Average reward fake: 0.3575606942176819 Training d_loss: 0.9166 Training g_loss: 1.4531 Training q_loss: 8.4409 Explore P: 0.0341\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 964 Total reward: 104.0 Average reward fake: 0.3600820302963257 Training d_loss: 1.0719 Training g_loss: 1.0409 Training q_loss: 4.3901 Explore P: 0.0339\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 965 Total reward: 109.0 Average reward fake: 0.3593119978904724 Training d_loss: 1.2194 Training g_loss: 1.4846 Training q_loss: 4.2005 Explore P: 0.0336\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 966 Total reward: 111.0 Average reward fake: 0.4623439908027649 Training d_loss: 1.3784 Training g_loss: 0.8317 Training q_loss: 5.3666 Explore P: 0.0333\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 967 Total reward: 126.0 Average reward fake: 0.41604098677635193 Training d_loss: 1.0840 Training g_loss: 1.2021 Training q_loss: 5.6361 Explore P: 0.0330\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 968 Total reward: 132.0 Average reward fake: 0.3614177107810974 Training d_loss: 1.3145 Training g_loss: 1.9210 Training q_loss: 31.3666 Explore P: 0.0327\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 969 Total reward: 96.0 Average reward fake: 0.5061797499656677 Training d_loss: 1.3176 Training g_loss: 0.7471 Training q_loss: 11.4228 Explore P: 0.0325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 970 Total reward: 98.0 Average reward fake: 0.3799974024295807 Training d_loss: 1.4401 Training g_loss: 1.0536 Training q_loss: 23.8372 Explore P: 0.0323\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 971 Total reward: 105.0 Average reward fake: 0.3670755624771118 Training d_loss: 0.8102 Training g_loss: 1.5807 Training q_loss: 19.1138 Explore P: 0.0321\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 972 Total reward: 107.0 Average reward fake: 0.45502233505249023 Training d_loss: 1.3788 Training g_loss: 0.8000 Training q_loss: 159.0483 Explore P: 0.0318\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 973 Total reward: 101.0 Average reward fake: 0.5051623582839966 Training d_loss: 1.5582 Training g_loss: 1.6410 Training q_loss: 34.9650 Explore P: 0.0316\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 974 Total reward: 93.0 Average reward fake: 0.5235683917999268 Training d_loss: 1.3733 Training g_loss: 0.7771 Training q_loss: 20.9144 Explore P: 0.0314\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 975 Total reward: 122.0 Average reward fake: 0.4669479429721832 Training d_loss: 1.2119 Training g_loss: 0.8236 Training q_loss: 6.1216 Explore P: 0.0312\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 976 Total reward: 135.0 Average reward fake: 0.3901039958000183 Training d_loss: 1.1248 Training g_loss: 1.3306 Training q_loss: 4.1049 Explore P: 0.0309\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 977 Total reward: 109.0 Average reward fake: 0.39630991220474243 Training d_loss: 1.0180 Training g_loss: 1.2974 Training q_loss: 4.1085 Explore P: 0.0306\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 978 Total reward: 116.0 Average reward fake: 0.4737418591976166 Training d_loss: 1.3639 Training g_loss: 0.7894 Training q_loss: 3.2621 Explore P: 0.0304\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 979 Total reward: 110.0 Average reward fake: 0.44453492760658264 Training d_loss: 1.1419 Training g_loss: 0.8668 Training q_loss: 12.2823 Explore P: 0.0302\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 980 Total reward: 95.0 Average reward fake: 0.3052758574485779 Training d_loss: 0.9708 Training g_loss: 1.4624 Training q_loss: 6.4741 Explore P: 0.0300\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 981 Total reward: 112.0 Average reward fake: 0.2616782486438751 Training d_loss: 1.2026 Training g_loss: 2.1485 Training q_loss: 4.8180 Explore P: 0.0298\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 982 Total reward: 127.0 Average reward fake: 0.3614761233329773 Training d_loss: 1.0548 Training g_loss: 1.4527 Training q_loss: 6.8029 Explore P: 0.0295\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 983 Total reward: 126.0 Average reward fake: 0.4600169062614441 Training d_loss: 1.3414 Training g_loss: 1.3042 Training q_loss: 19.8251 Explore P: 0.0293\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 984 Total reward: 120.0 Average reward fake: 0.4398157000541687 Training d_loss: 1.2057 Training g_loss: 1.2750 Training q_loss: 87.1249 Explore P: 0.0290\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 985 Total reward: 149.0 Average reward fake: 0.3505440950393677 Training d_loss: 1.1956 Training g_loss: 1.5064 Training q_loss: 49.8386 Explore P: 0.0288\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 986 Total reward: 135.0 Average reward fake: 0.39247798919677734 Training d_loss: 1.1988 Training g_loss: 1.0027 Training q_loss: 4.8125 Explore P: 0.0285\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 987 Total reward: 144.0 Average reward fake: 0.4656151235103607 Training d_loss: 1.1775 Training g_loss: 0.8267 Training q_loss: 5.7717 Explore P: 0.0283\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 988 Total reward: 115.0 Average reward fake: 0.43218526244163513 Training d_loss: 1.2707 Training g_loss: 0.9102 Training q_loss: 4.4825 Explore P: 0.0280\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 989 Total reward: 118.0 Average reward fake: 0.5062875747680664 Training d_loss: 1.3388 Training g_loss: 0.6983 Training q_loss: 7.3767 Explore P: 0.0278\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 990 Total reward: 105.0 Average reward fake: 0.33046528697013855 Training d_loss: 0.9974 Training g_loss: 2.3732 Training q_loss: 583.0866 Explore P: 0.0276\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 991 Total reward: 106.0 Average reward fake: 0.3292748034000397 Training d_loss: 1.2928 Training g_loss: 1.6888 Training q_loss: 9.1768 Explore P: 0.0275\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 992 Total reward: 97.0 Average reward fake: 0.4842756390571594 Training d_loss: 1.3876 Training g_loss: 1.1678 Training q_loss: 11.4064 Explore P: 0.0273\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 993 Total reward: 96.0 Average reward fake: 0.5463812351226807 Training d_loss: 1.5254 Training g_loss: 0.7073 Training q_loss: 13.9624 Explore P: 0.0271\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 994 Total reward: 104.0 Average reward fake: 0.3185381293296814 Training d_loss: 0.9054 Training g_loss: 2.1038 Training q_loss: 3.8188 Explore P: 0.0269\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 995 Total reward: 77.0 Average reward fake: 0.3948049545288086 Training d_loss: 1.1873 Training g_loss: 1.3880 Training q_loss: 23.3144 Explore P: 0.0268\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 996 Total reward: 66.0 Average reward fake: 0.35569867491722107 Training d_loss: 0.8427 Training g_loss: 1.1743 Training q_loss: 5.4672 Explore P: 0.0267\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 997 Total reward: 89.0 Average reward fake: 0.4174526631832123 Training d_loss: 1.0986 Training g_loss: 1.3390 Training q_loss: 13.4862 Explore P: 0.0266\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 998 Total reward: 72.0 Average reward fake: 0.4503025412559509 Training d_loss: 1.0170 Training g_loss: 1.3212 Training q_loss: 9.6206 Explore P: 0.0264\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 999 Total reward: 79.0 Average reward fake: 0.4164664149284363 Training d_loss: 1.2709 Training g_loss: 1.0140 Training q_loss: 5.5582 Explore P: 0.0263\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards and losses list for plotting\n",
    "rewards_list = []\n",
    "d_loss_list, g_loss_list, q_loss_list = [], [], [] \n",
    "rewards_fake_list = []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        \n",
    "        # Env/agent steps/batches/minibatches\n",
    "        total_reward = 0\n",
    "        d_loss, g_loss, q_loss = 0, 0, 0\n",
    "        rewards_fake_mean = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from model\n",
    "                feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "                actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "                action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Episode/epoch training is done/failed!\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Average reward fake: {}'.format(rewards_fake_mean),\n",
    "                      'Training d_loss: {:.4f}'.format(d_loss),\n",
    "                      'Training g_loss: {:.4f}'.format(g_loss),\n",
    "                      'Training q_loss: {:.4f}'.format(q_loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                \n",
    "                # total rewards and losses for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                rewards_fake_list.append((ep, rewards_fake_mean))\n",
    "                d_loss_list.append((ep, d_loss))\n",
    "                g_loss_list.append((ep, g_loss))\n",
    "                q_loss_list.append((ep, q_loss))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            #rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train the model\n",
    "            # feed_dict={model.states: next_states}\n",
    "            # next_actions_logits, next_rewards_fake = sess.run([model.actions_logits, model.rewards_fake], feed_dict)\n",
    "            feed_dict = {model.states: states}\n",
    "            rewards_fake = sess.run(model.rewards_fake, feed_dict)\n",
    "            feed_dict={model.states: next_states}\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "\n",
    "            # Mean/average fake rewards or rewarded generated actions\n",
    "            rewards_fake_mean = np.mean(rewards_fake.reshape(-1))\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            next_actions_logits[episode_ends] = (0, 0)\n",
    "\n",
    "            # Bellman equation: Qt = Rt + max(Qt+1)\n",
    "            targetQs = rewards_fake.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "            # print('DEBUGGING', targetQs.shape, next_rewards_fake.shape, next_actions_logits.shape, np.max(next_actions_logits, axis=1).shape)\n",
    "\n",
    "            # Updating the model\n",
    "            # print(states.shape, next_states.shape, targetQs.shape, actions.shape)\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions, model.targetQs: targetQs}\n",
    "            #states, next_states, actions, Qs = sess.run([model.states, model.next_states, model.actions, model.Qs], feed_dict)\n",
    "            #print(states.shape, next_states.shape, actions.shape, Qs.shape)\n",
    "            #rewards_real = sess.run(model.rewards_real, feed_dict)\n",
    "            #d_loss = sess.run(model.d_loss, feed_dict)\n",
    "            d_loss, _ = sess.run([model.d_loss, model.d_opt], feed_dict)\n",
    "            g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict)\n",
    "            q_loss, _ = sess.run([model.q_loss, model.q_opt], feed_dict)\n",
    "            \n",
    "    # Save the trained model \n",
    "    saver.save(sess, 'checkpoints/DQAN-cartpole.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total rewards')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'D losses')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'G losses')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsvXl4Y9lZ5/85utol2/JuV7nKdq29pddK0h2ydBICITSdhRAISwJk6AEGCMwMmWTYMjD8hpkBMqyBTAJkmBDIZCErpJNOJySk00n1WtVdXVXtqvJSLu+L9uVK5/fH1ZUlW7ZVtqVrW+/nefzYurrLubrW+Z53Oe9RWmsEQRCE5sXldAMEQRAEZxEhEARBaHJECARBEJocEQJBEIQmR4RAEAShyREhEARBaHJECARBEJocEQJBEIQmp25CoJT6K6XUjFLqbJX3/qNSSiuluup1fUEQBKE23HU8998Afwr8n/KNSqlDwGuAsVpP1NXVpYeGhnaybYIgCPuexx57bE5r3b3ZfnUTAq31vyilhqq89T7gXcCnaz3X0NAQp0+f3qGWCYIgNAdKqdFa9mtojEApdT9wVWv9VCOvKwiCIKxPPV1DFSilgsCvAd9T4/4PAA8AHD58uI4tEwRBaG4aaREcBYaBp5RSV4AB4HGlVF+1nbXWH9Ban9Jan+ru3tTFJQiCIGyRhlkEWuszQI/9uigGp7TWc41qgyAIgrCWeqaPfhR4BDiplJpQSr2jXtcSBEEQtk49s4beusn7Q/W6tiAIglA7MrNYEAShyREhEHaUTCZDKpVyuhmCIFwHIgTCjnLlyhXGxmqeNC4Iwi5AhEAQBKHJESEQHENrTTabdboZgtD0iBA4wMWLF7ly5YrTzXCcubk5Ll++LGIgCA4jQuAAhUKBTCbjdDMcxw4q5/N5h1siCM2NCIEgCEKTI0IgOI7W2ukmCEJTI0IgOIZSyukmCIKACIEgCELTI0IgOI64hgTBWUQIBMcQ15Ag7A5ECARBEJocEQJBEIQmR4RAcByJEQiCs4gQCI4hMQJB2B2IEAgNZXJykqtXrzrdDEEQyhAhEOrC3Nxc1e2xWIx4PM78/DzxeBwQ15AgOI0IgVAXlpaWNny/XChECATBWUQIBEEQmpy6CYFS6q+UUjNKqbNl2/6nUuo5pdTTSqlPKaUi9bq+4CzXM8oXi0AQnKWeFsHfAK9dte1LwC1a61uBC8B76nj9fUk6nSaXyzndjE0RIRCEvUPdhEBr/S/AwqptD2qtzeLLbwED9br+fmV0dJRLly453QxBEPYRTsYIfhr4JwevL9QRsQgEYe/giBAopX4NMIGPbLDPA0qp00qp07Ozs41r3C5mL7iEtoIIgSA4S8OFQCn1duA+4Mf0Bj2A1voDWutTWutT3d3djWvgLmZ8fNzpJpTYqc57ZDZOJidrFguCkzRUCJRSrwX+E3C/1jrZyGvvB3bLIu/Ly8tcuHBh2xbKYjLLf/vCc/zBg+d3qGWCIGyFeqaPfhR4BDiplJpQSr0D+FOgBfiSUupJpdRf1Ov6Qv2IxWIAZLPZbZ1nejkNwIPPTlMoiHtIEJzCXa8Ta63fWmXzh+p1PaFx7JRbaC5uCYlCs5TK0RHy7sh5BUG4PmRmseAYGXPF1TUXzzjYEkFobkQIhC2z3TLSWXPFsnjbh7693eYIgrBFRAj2EPstzTKbLwCggKlo2tnGCEITU7cYgbA5WuuaR9Va630pBF63iw6yvPhAi9PNEYSmRYTAQQqFAoZh1LTvbppUt54gXa9QpXN5PIbiQCRIPisWgSA4hbiGHOR6Os5kcmvTLjKZDBMTE3WxJlZbM8vLyzUfq7Xma+dnSWTyeN2uiniBIAiNRYTAQQqFQs37lnfkwWCw5uOmp6dJJBKkUqnrattWuJ77SeVW9vUaLrJm7ccKgrCziBA4yFaEIJnNM7FYu3Xgcrkqjq8ntbq5AOJps/S3z+0qBY4FQWg8IgQNprxDrrVz1lqXyjn86v97inf+/ZM1H5tOpyt+15PrEoKMdT8/d+9RvG4XGbEIBMExRAgcpFaLwI4PaK2LHaYmmjI3Pqi4v12faL3F5LfCTlgX8YzV/vagB4/hIidCIAiOIULgILUWkbMFI1bmThlb2Nw9VG930HbOn8xa9x70ufEYLszrcJMJgrCziBA4yPVWE51PrBR5+86VhQ32tCjvqLc7C7ga4+PjjIyMVL3eZqRsIfAauF2KXGH/zZMQhL2CCIGDLCXSfOgbl5mNbVxnx+4g5+MrQvDk+NKm5y93PXm99SnoZpqbu6iqkcyaaKCnI4LhUqAhLxVIBcERZEJZgykf9f7Xz57lodEshYLmZ15+ZNNj5xOWYNzc38pzU9FN9y9f23gnRtuFQqGUhVSN67IIlJ8FI0KktQWPYZ0zmy/gNmRsIgiNRr51DnFpNs6Z8XkAllMbL/CyYhFkCHgNBjuDXFveOAtofn6+4vX1pKpWwzRNLl68yMLCwo6ISiyraAn4ACyLAMjJpDJBcAQRAod45NI8Ibc1mSqarm2lr/l4ls6Ql0jQQyxtksyu75ZZnSW03c7bjmdEo2stkdXnLmhNYZPrxbImrX4PQMkKyOySFdgEodkQIXCIicU0gx0B+tr8RGuwCLJmgQszcQ5EAnQELX//dLS2Gv6ffnKSt//VtxmvIdNoPexg80aCYr/3nk+e4T994ukNzxfPmLQGikJQ/C/M5cUiEAQnECFoMHZnObmc5kCbn1a/UZEWuh5Xl1KMpf286GgPIa81cWszAQGrw/3YkzMoNC/7Hw9vud0bCcHqbfPxLIuJjdsWS5u0+q0QVSlGIHMJBMERRAgcIJ4xWU7n6Y/46Qp7N/X3a62ZXEqRxeBIbxuBohDUIiATi0k0imI3zrXlrdUcsjv78k5/OprhW5fm1ztkQ2LpFYugFCOQMhOC4AgiBA4wHU1TQNHb6udoV5BLc/ENF29fXl5mcjmNx+2iry2AVxWIqBSxGmIL09EMGsWtA20o4PmZ+LbaXr4uwvu/+jwf/PplporisnrNhPXcSLl8gdlYhu6wD6UU7qIQiEUgCM4gQuAAi4kcBa3oDHk50hkknStwdan6SD2fz5PJZJhcTDLcGcJtuAh4DVpUpiaLYDmVQyt4wx0HAVhK1haYXo/yzt7u57/89DixWIxcLldRPG69MhjjC0kyZoEXDncAK8FiKTwnCM5QNyFQSv2VUmpGKXW2bFuHUupLSqmLxd/t9br+bkVrzUIyQx4X7UEvQx1W4PfCdKzq/leuXAGsmMKJ3lYAgl7Lt15LttFyKker30ur34NCb5qqulG77d92KmrYb7mozj5/hcnJSRYWFiqqii4ks2tPxEqdoZ4WK33UU0ofFSEQBCeop0XwN8BrV217N/CQ1vo48FDxddOxlMih3G7Cfg+d7hweA75zZbHqvqZpksnlmY9nOdYTRmtNwOPC53YxsVjdiih3yURTOdpDPkI+g15XvCYhmJycZGmp+szlciGwzzVTtt5wPLOSArpQVhLDNE3Gx8cBu86QIlLMfjLEIhAER6mbEGit/wVYXRDn9cCHi39/GHhDva6/m1lIZulpCdDd3Y0qmNw10MLXL65ditLu0K8VO9rjvWHAyuDpafUzOp+oev61QuDFY7gIGLVZBLFYjOnp6XVrIWmtyRc0szGro58rK33xT2evrdxnmRBkMplSFVXbImgrpY9KsFgQnKTRMYJerfU1gOLvngZff1ewmMzR1eIjFAoB8MqhIM9MRvn0k1cr9rM7YtttdKKvtdTJRwLuig64nHIhWE7n6AhZLpiQz81Sora5BwDXrlmd+oULF0ouKrA67C89O02+oGkNeEhkzdI1T5dZNouJ6u1LZvNoKKWPSrBYEJxl1waLlVIPKKVOK6VO76aF27dLoVAgkckRCXjxer1EIhFeNhTmlX0mv/vxb/HHXz5POmcJQDKZZCmZ42PfmQBgsGNlicqQz8NSamMh0NqyANqLQhD0Giyvc0w1MplMxflsPv3kJB9/zGrTzf2tmHldmgw23BUq7VceIyg/RzJjEvYZuA0XLperLFgsE8oEwQkaLQTTSql+gOLvmfV21Fp/QGt9Smt9qru7u2ENrDfxeJx0rkAwEACgt7eXA/19/OKrjvGSwwH+9itP8p6PPwFAIpHg7x4dA2CgPYDbcJU61JDPWDcDyN4naxbImZqOkLd4jJvlTbKGytc2drur1yS0VxcDOFZ0V9nunqxZ4I7DETxuVeEaKieRydNSLC8RCoVwuxRZDLEIBMEhGi0EnwHeXvz77cCnG3x9x4nFYkRzilDQX9oWiUS47eYbePf9d/Ka4xGeOneBLzx+macuT/H4+CKvONnNe++/ueI8Qa+bWNrErOJXt4UgWszgiZQsAjfRTSyCsbGx0t/rVRq1J4K94GBryc//macst1YyZxL0GrT43OsKQTK7MplMKUU4FEQjMQJBcIq6laFWSn0UuBfoUkpNAL8F/B7wMaXUO4Ax4Ifqdf3diGmapFJplnIuwr7K9X0Nw6Cvr4/7bpvj8nyS//bxb1pvePz84J0Dpf1KFkHZ7OL2UOVaA/Y+9oSzjrAXyBLyGUQXa08fXU8ITFNjuBQ//8pj5IoT4b5xcZ6ffMkwyUyegMdNW8BbMYu53DUUz+ZLBeegbB6BWASC4Ah1EwKt9VvXeevV9brmbiSdTjM9PU1/fz+ZTIaMmSdVcBP2V//ou8Jefu11N/DlkTifPbfEa14wQNC7tkP2FSu1pXJ5Vk/GKC1tWVoX2Ac6S8jrJnYdi9gnEomqmUOpXJ4Wv7XEpMeAV5zs5hsX58jk8mTMAi0BN72tPr45V73IXTJr0t2xIgR2rSGxCATBGWRhmjqRyWQYHx/H7XaTyWSIx+MopYhnTExchH2edY/1GC7+7Xffwi//gBVHOH/+/Jp9vB4XoEtr/5azYhEUhSDkRcctKyKVzZM1C3jda8Ull8utOc/VqyuZTNeWU/zGPz5Da8BTYdEc7Q7ztfOznJ20SlS3+t1kwl6ujaTQWq9ZJjORyXO0TAjdhvV+RiwCQXCEXZs1tNeZm5srlYeYi2fI5wvk83kuTMcpFGv/bMR6awzb7hqv4UKhS2v/llMSgmKJh86yYPF6s4sLhULFimY22eyKn//rF601DqKpHF1hX2m7fS/fLq6j3Brw4HMbFPRK516eyZTMmKVgMYDHJRaBIDiJCEGdsDvykdk47/7EGd734LMsLS1x9lqMzpCPm/pbazp+NYZhjcR9bgMFVRenKQlBJofHrQgWrY9gcRRfLYW0WoG4xWSWxbJ5BxenVwrW9bWtBLvDPsvV9Xzx/Va/Z8V1tUqocnmNWdC0BVbiGi6Xwq2UxAgEwSHENVQn7EXdP/m4lW//9WfGeerSFLOpAi+79SQuV/WO3ma9QK293edxWUKQW98imFpO0xnylkTFrlG0nkVQzsRikvd+5lk08Fs/cBOH2gNMLafxul0cag/wqht6MAyjFEM40ObnQkkI3CUhSBZjGHabEkXhKg8WgzWpTCwCQXAGsQjqQC6XI51Oc3YyyvmpON9zcy+dIS/RVI6DHWHe8dLNF6ovtwiOHj3K4OAgYKWaghUs3sw1dHkuwZGDvaXXYZ8bRfUKpMvLyxWvP/j1y1Y7gK9dmGUplSOVy/OmOw/yntfdyO03HKWnZ2Vi+K0DkdLftmsIrMlj5STs8hLBFSFQSuF2u2SFMkFwCLEI6kAsFqNQKPCRR8fobvHx/S/o5013DGC4YGBggHA4vOk5yoXA7XaXJnd5vV76+/uZjV0B1rpeYKVUdDKbJxL0lIRgI4ugfLH7rFlgOprmSHeIS7MJzkws8bXz1uzu3lbLJeT3+yvcSaeG2kuzjT2GC5+naBGsal+yWJSudVXWlNulJFgsCA4hQrCDZDIZ0uk0pmmykDS5Gs3x9hcdIOSzPuaBgYFSfaH1cLlc5PP5dV1DYImE11hxvaxGa6vkQ76gCfncBINB2traiGfm17UIynl6YplcXvOmOwd4bHSBh59bKfHR0+IvtcEwDHw+H5lMhq6wj595+XDJ5VNyDRWFYI1rKFDpGvIa4hoSBKcQIdhBJiYmME0Tn8/HZ85MsUSIu08cBKzOL1AsK7ERhw8fJpFIrBsstvF6XLjQpNYJFtuWQqhoBbS3t7NYLC29WQXSR0bm8HsMjveEWU5lS0LwjpcO09vqq9i3XLBePNxZ+tt2DaVyle2z1ysoDxaDZRFIsFgQnEFiBDtENpstBYhPX5rh4fNz/PTLj3PnTUdL+2w0yrfxer20t2+8Xo9SCp/bRa8rvu48gmSxAw6V5fu7lCLsNzYUgoLWPDMZ5e4jHRguxcneVg53BLn/9gPcc3Slo7eFaj3Bsi2CRKbSIjg7GcVtKLrCq4TAcIlFIAgOIRbBDhGNRolnTP7koYuMzCYYjPh556uP1+16LqVwG2pNMBasTncxYXX2kVUj71a/e40QJBIr6xrMxDKYBc3hYqXTSNDDb/7ATeu2Y701C9ZLH11MZjnR04LfuzZGIBaBIDiDCMEOMD4+TjKZ5NEry4zMJugMefmN19+O32ONxu2Mn53CHoX73C7SubVCkM/neX42ThY399w0WHFMa8DDUjJbWihGa015me9vPj+HUnCir6WmNtilqlfjK9776nkOmVxhjTgppfAYSlYoEwSHECHYAeyVt74zHudAxM9/uf9mjh1d6fz9fv96h24Ln9u1xjVUKBRYXFwkmsqR9bfTFqq8tm0RlC80Y5MvaE5fWWS4K0Rfa21t7u7uptp6EeXzCGDFNZQ286X3yjFcLlJiEQiCI0iMYJvYHVw8Y/LEZJzbDkWKefH111iv27VmxG23J5nNl0pEl9Pq96wbI5haTjMTy3DPkc6q71fDntewGrdL4VIr6aI2WbNQSi0tR7KGBME5RAi2QaFQKBVl+9qFWWJ5z3V1olulfKawXVjOxi4cl8iaFUJgH9NSJUYAVpD4dz7/LACDnSsroW0258HlcjEwMEBXVxdgZUYppXC5XAS97jXpo2kzX3KZlWMYLnENCYJDiGtoC5imSTwet5adLAZan5iFk/0Rbjjcu+lcgZ0i5DWYWDUnYHR0FLBG4m0R75pjqgWLAZ4aX8IszuztbllJEa0l0ykUCpVKVHg8HgKBAIuLiwS8RkX6aEFrcqZeU/lUKYXbBTlTZhYLghOIEGyB8fHxiqqcWbPAk1ejvOXuY/T399f9+vboPuTzsDy//ipg/VUsgla/h1y+QCaXx+cxuDgTJ5kx+doFy8//2lv6aPF78Hg85HI52tra8Hq9LCwsrKlHVE44HKa9vZ3Ozk4WF60F7INeo5Q+CisZRP4qriGPWASC4BgiBFtgdYf4+NgiGVPz6ht71jmiPoR8Bktlo3u7AwZIZPO0BdY+3vaAizaVZiGZo7/N4E++crHkx7/nSCdvvstaDS0UCrG0tIRhGHR2drK0tEShUODw4cNV26KUqqg9BKxxDdmWSCTgXTP/wJCic4LgGCIEW8D2dy8nc/z510YYmYnT397H3cP1jw9AuUXgJp5OY+YLuA0XMzMzpfatFyxuc2VoVRlmYml6WnwVwdybD66Uxu7p6SEcDuPz+Squ6Xa78XjWX1SnnOAq19BC0haCtcd7RAgEwTFECK4TrXVpEtWXzk0zMmOVXv71H7hl09LSO03QawCaaNqko2zd4rRZoFDQVYPF3cUFZeZiGWZi1hyA193ax419rdxQNndAKVUR67CPr7ZuQTW01gS9BvGyCW/fuDiLy6XoqZKaKhaBIDiHCMF1YovAZ5+6xj+fneKeo52890fvJRioz1yBjQgXi9ktJbN0FNcdsFcAy+GqahG0+N0YLsViMsfkkrW4/F2HOyoyhY4ePbrmuOsVAoCAx2AmaolNoVDgybElXn68i0iwsl1WsFiRk3kEguAIkj56nZimSS5f4J/PXqM/4udt9ww2XARKriGvtb6A7Xu3M3wS2TxLhcCawm72sZGAh6Vkjq9ftALEfW2+itF/tTkQvb29BINBvN6151y3fT53qeZRLG2SK2j6ItUzqtwuF7kNgtGCINSP6xICpZRLKbXxGou1nedXlFLPKKXOKqU+qpRq/HB6CywvLzM6OsrIbIKYqXjzXQN4DOe01F560g4Y2x2wPcmsmmsIIBLyMrmU4uxVa7F5n9vYdKQfCAQ4dOjQplVRy+lt9bGwFGPk8igLiTQaRVuwupAYLmRhGkFwiE17MaXU3ymlWpVSIeBZ4LxS6le3ekGl1EHgl4BTWutbAAP4ka2er1FMTU0xNTUFwPmpGAs6yPGejevx1IvyETdYQevy7XYAuJprCKA96GFswSqL8YMvOVm3dt56sI0O4oxcW2A+mi62qbo30jAU+YKmUBAxEIRGU8tw9iatdRR4A/AF4DDwE9u8rhsIKKXcQBCY3Ob56o69lKPWmsdGF7hloKMYrHWO8hgBrAiBvfjL6uUgbdqLo/KAx+BtLz1eet/n82EYO3dP9vVTuTzzyzFMXLT6q1sE7qJbS9xDgtB4agkWe5RSHiwh+FOtdU4pteVhm9b6qlLq94ExIAU8qLV+cKvnawS220RrzWefvsbkUppfeOVhIhFfQ2oKrUfAU+kasokWy050rOOGsbN22luDeN0rHf/Q0NCOts8Wqkwuz3IyQ04btBYtgtUuJncx4yqX1/gkhUEQGkotFsFfAleAEPAvSqlBILrVCyql2oHXA8PAASCklPrxKvs9oJQ6rZQ6Xa26ZSNZWFgArEVVPvPkJLccbOUNdxykt7eXzs7GzB0ox+5EDZeixW+Ulp60ty8msrQF3ATWsViO94QooHjLvbfXtZ2h4gzitJm3xEkpjg0O4Pf7KwRUKYVhC4FkDglCw9lUCLTWf6y1Pqi1fp22GAVeuY1rfjdwWWs9q7XOAZ8EXlLluh/QWp/SWp/q7u7exuW2j11z/5GReUI+g1945fHSUoxO0+LzEE1XWgSLiWxpkXmb8hH4QHuQ9//EKX7wrsNV398u9rnyqRgA6VyBy3MJ+iNBWsIhBgcHN7AIRAgEodHUEizuVUp9SCn1T8XXNwFv38Y1x4C7lVJBZfUGrwbObeN8dSefz5PM5XlibJEXDXXgNho7cWw15Z1oa8BDNGVWbF9O5+gK+6oea+Nz1T8oa5ebnotneG4qxktPrF+CoyQEEiwWhIZTi2vob4AvYrlxAC4Av7zVC2qtHwU+DjwOnCm24QNbPV+90VqTyWR4+Nw0ubzmFTcPcPDgQaebVaLFZ6yxCGIpk0jrxuWjbQKBAF6vt1RGeicJ+Tyg4J/OTlEoaF5+fH03mriGBME5ahGCLq31x4ACgNbaBKovVFsjWuvf0lrfoLW+RWv9E1rr6usd7gImJyfJ5/M8cmmeE71h7r5xcNMa/Y0k7POU1iSwZxZHMzm6WmqbmmEYBsPDw6WaQjvJwsICfrcBGoa6gtzQV30KSkWMQFxDgtBwahGChFKqE9AASqm7geW6tmoXEY/HWU7lGF3Oc/uRPoLB4OYHNZCWgEG0LGsoaxbImbqi9lCjKXdd2R37i4c76ejoWPeY8qwhQRAaSy2Jev8e+AxwVCn1r0A38Oa6tmqXcWE6RlYbvPS2EzsaVN0JWs1lommrs1VKlVJHOx0UgnLyRZ9/byS84Wdnx13EIhCExrOpEGitH1dKvQI4CSjgfDHbZ99jzx+4MBUj4HFxy8E2h1tkUb5qWNBjEM9kSzNy7XhBtWDxegvNN4LNgteGEiEQBKeoJWvoh4CA1voZrEll/6CUurPuLdsFzM3NAXB+OsbJgU5H6wqV43K5SgHrgM9Aa4gXZxPHbYsgvNYiaG9vb0j7KlxDuIhqHzcfH9rwGKMobrJKmSA0nlp6tt/QWseUUi8Fvhf4MPD++jZrd5BMJslqg8cWPLzw+O7JFIIVqyDoKZaZSGRIpVIsJHMsaT89VYLFSimOHz+Oy+UiEAg0pJ33nuyhq6uLnnWqjtrtsqdlmBIjEISGU0uMwM4Q+n7g/VrrTyul3lu/Ju0eTNPk+fkMJgYvGl4/0Okk9uzhsfGrdAdgPq3JuIL0tFR3xbhcLo4fP96w9v3cvcf4vcHBTfcT15AgOEctFsFVpdRfAm8BvqCU8tV43J7GXons3HQcj6F4wS6JD6zGLny3FEsAMBtNc7A90PDV0sopdw2VxzM2QmYWC4Jz1PItfQvWhLLXaq2XgA5gy2Wo9woLCwtorTl7Lc4tB9vwe3ZHSQkbu7MNei2jLpmzDLfZWJqB9sa4fWqh1qJ8K1lD4hoShEZTixD0A5/XWl9USt0L/BDw7bq2ahcwNzdHLl/g7LUEpwYbE2TdCnYF0lTWFoIMA+3OznWoKIHRWts6RjKhTBCcoxYh+ASQV0odAz6EVTX07+raqgYwNTXF+fPnN9xncilNxixw+6HdKwRBn4GLAslsnkwuTyyd41DH7rAI/H5/xRKY66GUkhiBIDhILUJQKJaVeBPwv7TWv4JlJexp7IVm1sPtdjOxmCSDmxv6nVmJrBYCHoNeV5xEtsB8IotCO24RbAVDXEOC4Bi1CEFOKfVW4G3A54rbqq+BuM+4mlD43AZDnZuPahtNxZoEXkU8k2MxmUMB/W3OLgG9ldnXbrEIBMExahGCnwLuAX5Xa31ZKTUM/N/6NstZ0uk0pmlyeSHFid6Wkv96t9LicxNNmySzJgpNq3/v6bTECATBOWpZmOZZ4D8CZ5RStwATWuvfq3vLGoRdRqKc0dFRAC7OpjjZt3vdQjYtAQ+xZJpUNo8CWvzOrvW4FYvAkKJzguAYm/YYxUyhD2MtV6mAQ0qpt2ut/6W+TWsMWutSx1UuCrF0jqVkhht2qRCUt7XV72Y2liGVy5NHOS4ENrUKglKqOI9Ai0UgCA5QS4/xB8D3aK3PAyilTgAfBe6qZ8MaRXmHOjExQTabRSnFxGKKpPbuDYvA72FkNkEqV2BGtxDy7g4huB5sMRAhEITGU0uP4bFFAEBrfUEptfec0OtQLgTJZBKwZsM+PpXFcLu59WDEqabVTIvfTTxjkshqgj6vo7OKYevrH7sNJa4hQXCAWoTgtFLqQ8DfFl//GPBY/ZrUWGwhGBsbK22bXk4YtwxQAAAgAElEQVTx4LMz3PeCYdqCu1/zWvxuCgXN+eko3S27X7jWw2O4xCIQBAeoJWvo54BngF8C3gk8C/xsPRvVSGwhSKVSAMQzJh/+5hU0il96deOKs10v5ZaMvU7C2EIKr3t3lcK4HrwuEQJBcIJaFqbJAH9Y/Nl3aK0pFFY6nz9+6CKXZhO8/RW3MNS1++YPVKOvdWXeQIvP+fjA9bqG7P3dhiJnimtIEBrNur2GUuoMxXWKq6G1vrUuLWowdpVRgKlomkuzCd581wA/fs+wwy27Pn7x1ccYX8ryw6+6zemmbBlxDQmCM2w0fLyvXhdVSkWADwK3YInNT2utH6nX9TaiXAjOTUYBODXUXnPVTKdY3b7bBiK88Ih3T5aXsPEaLnIFsQgEodGs29tprUfreN0/Av5Za/1mpZQXcKz3KheCJYIYLkVnyIvXuzsWf18Pr9fL0aNHWVhYYHFx0enm7AgeQ5EzxSIQhEbT8GGvUqoVeDnwkwBa6yyQbXQ7bLTWZLPW5WcSeSJBj5XTvsstAqi91r9TXG+swEofFSEQhEbjxEpjR4BZ4K+VUk8opT6olHIsKqu1xjRNDMNgOpqlPeht2Hq+O0F5Z+v3O1tsbqvY9+AR15AgOIITQuAG7sRa//gOIAG8e/VOSqkHlFKnlVKnZ2dn69YY2zXkcrmYjJu0Rtrp7997Vbb9fj+9vb1ON2NbeA2XuIYEwQHWFQKl1OuVUv+u7PWjSqlLxZ83b+OaE1iF6x4tvv44ljBUoLX+gNb6lNb6VHd39zYutzHlQnBtOUVPdxcez+6fRGZTWrIyGKx5feDdittQZMU1JAgNZ6Oe413AZ8pe+4AXAvdiTTLbElrrKWBcKXWyuOnVWJPUHMEWgkwe0rkC3S0+p5qyLbZa1mE34XVL+qggOMFG0Uav1nq87PU3tNbzwPwO+PR/EfhIMWPoEtaaB45gTyhLZC3fdEdobwnBfhAAG5/bRSYnQiAIjWYjIahYqFdr/QtlL7flq9FaPwmc2s45tkomk6mYSWxbBNFi3lJnaHenja6m2noKTnO9bbLFzGu4xDUkCA6wkWvoUaXUz6zeqJT6t8C369ek+nLlypWKAnMlIUhbcwk69pgQ2OwHy8CyCPLE4/FdKXCCsF/ZyCL4FeAflVI/Cjxe3HYXVqzgDfVuWKMwTRNgzwvBbsLns9xrbW1t13Wc1+3CZaa4evUqPT09tLe3b36QIAjbZqOZxTPAS5RSrwJuLm7+vNb6Kw1pWYMozSpOW4LQGd5bQrAbR85ut5uTJ09uvuMqfG4X+bz1HOznIghC/aml+uhXgH3V+ZdjWwRLyRw+t4uAZ2+Wcd7LrqHShDK3C9O0BMAw9uZzEIS9yO6uUdAA4okEX3p2mguz0N3i29Md6l7HZ7jI5wtorff8nAhB2Es0tRD87ufPcXkuAcBMIcy9Nx90uEXXz250DW0Vn9uFiwJmQYRAEBpJ037b4hmzJAJg1cK+7dDeXeZxP1gyXrf172hKvSFBaChNKwRTy2kAXntLHzf1t6JR3H2k0+FWNTdetwsFMrtYEBpM07qGllM5NPDi4Q5+8M6D/Ne+AbojYaeb1ZSUTygDMPNiEQhCI2laiyCZsbKFgj43Sinaw3uzhPP+ihEoUJATIRCEhtK0QpDI5tEowl4rTXGv+9j3evsBPIaBAkxxDQlCQ2liITBxKVUKUO7VjnR/WQQuQGMW9L66L0HY7TStEKSyefxed0kA9nq64l4VsnI8xRiBBIsFobHs7d5vG2TNAl6PFSvfyyLQ0tIC7N1lKsvxuZW4hgTBAZo2ayibL5QWf9/Lo+lQKLSluj67iVLWkNu2CMQtJAiNZO8OhbdJzizg8ex9IdhPeIv1hcQ1JAiNpWmFIKaC+NxWx7OXXUP7Ca9bYVAgVyhIsFgQGkjT9oAps4DfY91+Npt1uDUCQDK6iIGWCWWC0GCaVgjSuULJJy04i+2ay2essh8SIxCExtK0PWHW1MW8dWG34DYsQZCsIUFoLE3bEyZzJv6iEPT29jrcGgFW5hFI9VFBaCyOCYFSylBKPaGU+pwT109k8gQka2hXYVsEkjUkCI3FSYvgncC5Rl7QzkTRWpPMFgj6ZDnE3YRLKQyXkqwhQWgwjgiBUmoA+H7gg05cP20W0EDQ07SesV1FuUXmdilMU0RAEBqJUz3h/wLeBTTUB2CPMtM567L2QvXiGto9eAzLIhAEoXE0XAiUUvcBM1rrxzbZ7wGl1Gml1OnZ2dkdufaKEJiWReBr2gobuxa34ZJ5BILQYJywCL4LuF8pdQX4e+BVSqn/u3onrfUHtNantNanuru7d+TCthCksnkAAuIa2nV4DBe5vJShFoRG0vCeUGv9Hq31gNZ6CPgR4Cta6x9v0LWBFddQUFxDu46C1nzr0jzLyZzTTRGEpqGphsQrQpAHFH5vU93+nmA+bpX7+MDXLzncEkFoHhx1kmutvwp8tdHXTZu2ReAGTLEIHKba5z8dTTvQEkFoTppqSLwSI7CCxRIj2H1I2Q9BaDxN9a0ruYaKFkHAKxPKdgPlFsF7XncDAMms6VRzBKHpaEohSGXzeAxFR6QNAJ/P52Szmp5yIRhoD/Ki4Q4WE1IaXBAaRVMl0pcHi0NeN21tbbS2tkqMwGFWf/5tAQ/zibhDrRGE5qMpLYJ0rlCaTCYi4Dyrn0Gr30M6lyeREfeQIDSCphSCVC5PSGYV71paA9azeXpi2eGWCEJz0FRCYJPIGwQDfqebIRRZbRG0B70o4K3/+1vONEgQmoymEgLbIlgo+MUi2EWsFoJDHQGHWiIIzUlTCkEikycsQrBrWC0ELX6PQy0RhOakqYTAJp4xRQh2OT/1on6CZIvlQARBqCdNKQSJrAjBbqJa5lbAKNDpShJNSfE5Qag3TSUEWmsKxWUqJUawe6gmBG1+6/nMxDKNbo4gNB1NJQSwUoK6xS9CsFuoJgTtIS8Ak0upRjdHEJqOphICrTXpXB4NYhHscjqKQjAlVUgFoe40pRAAEiPY5YS81vORBWqE3U4ikaCwx9fZbiohAGtWsUaEYLdx+PDhitduQ+F1u4imRQiE3YtpmkxMTHDt2jWnm7ItmkoILIugACjCEiPYVQQCK5PI7JhB0GsQTUm9IWH3Ys9NymT2dlJDUwkBIK6hPUTQa4hFIAgNoKmEQGstrqE9RMDrFiEQ9hSpVIpkMrmtcywsLJBONzZJoqmEACBZLG3cGpAyBrudoMdVcg1Fo1FMU9xEwu5mbGyM8fHxbZ1jdnaW0dHRHWpRbTSVEGitiaZNvIZBq8QIdi2lGIHPTTSVxTRNrl27xsTEhMMtE4T9ScOFQCl1SCn1sFLqnFLqGaXUOxt5/WjKpDPslQVp9gBBj4ErtcTIyAhgBeTs4Jwg7CdM0ySXc84N6oRFYAL/QWt9I3A38O+UUjc14sJaa2KZHJ1hbyMuJ2yTgM+gkEtXdP4LCwsOtkgQKtmpgcnIyAiXLl2qOF883rjlWhsuBFrra1rrx4t/x4BzwMFGXT+dK5QmKwm7E/vLEPS4KRQ0WXNlsk4ikXCqWYKwITs9or969eqOnm8jHI0RKKWGgDuARxtxPa01GbNA0Gs04nLCFrGFIFB8TnZ9qNXk83kmJycbnmEhCNWYmZlxuglbxrGhsVIqDHwC+GWtdbTK+w8AD8DaWafbIW0WiIhFsCs5dOgQQCnrwu+xxikpM08bVpaX1rqUXheLxQCIxWIMDg7i98vyo0JjKXflrHYT5XI53G531Xjk7Ows2WyWgwcrnSFOxcAcsQiUUh4sEfiI1vqT1fbRWn9Aa31Ka32qu7t7R667uLhIzjRLI01hdxEMBgkGg6XXAY/1nFLZysVpZmdnSyJgk81m699AQVgHrfWaekOXLl1aN5V0YWGhoTGAzXAia0gBHwLOaa3/sFHXLU0FF9fQnsHvsSy38kllkjXUPOzGYm7Xrl2rGISU/z+Wt9WuPZRKpVheXq75/M1kEXwX8BPAq5RSTxZ/Xlfvi9qBnGyuIBbBHiFQdA39yUPPl74gIgTbJ5fLOToaNU2TfH7jJUgzmQwTExPMzs42qFW1EY1GmZycrPpe+f9mNLri7Z6amiKfz5NOp5mYmNiV/8MNd5Zrrb8BNDyJP5/Pky9ozIKWrKE9QneLr/T3QjJHZ8i7rgtI5oXUzujoKPl8nhMnTjjyuY2MjGAYBseOHVt3H1sodovLzzRNUqmVRZKWl5dpa2ur2Gcj60VrzdTUFJlMpuKepqen6ezsrNjPCZpmZnGhUCCZNYlpn8wq3iP4PQYvPtIBwNXF7dVv2WuYprnjncLCwgKZTKbUyW7UcWUymYqOb6fZzCKwLfjdIvBXr16tsASmpqaA6sFirTVPjC3yxNgiz02tyYOpYGlpienp6dJrp1xhTSMEAMlsgaT20BaUOkN7hR+7exCA8cWd65QKhQKTk5ObdkZgfVEb/eXUWjMyMlLqbHaCQqHA7OwsV65cKW3bKO/9ypUrjI2N7dj1rxf73uspBIlEoqb/AaCmOlf2/8m/jszzZw+P8GcPj/D7X7zAyGylG271NcvFxClXWNMIgdaaZNZEo2j1ixDsFYIeg9aAh6+cmyG2QSXS65nMs7S0RCwWY35+fsP9EokE09PTjn05V2dG1YotdPZnMjs7y8WLF9fst9U4wejoKM8///yWji3n6tWrTE9PbzhJMJ/P10WI8/k8ExMTTE5OorVe04Z8Ps+FCxeuawKj3aGfvVoZHH52MsrVq1dLaxasziRabzZx1izwG586w3QDlmttMiGwSlC3SeXRPYWhYDmV47c/9+ya9+wv0fV01tc7ymx0DZjtuoTi8TixWIy5uTlgbVmOgtaMLSR55LlxLs9EyReu73rpdJp8Pk8ikShdY6vtXFpa2rCYYCqVqrBiNiObzTIzM7PpZ2i/n81mWVxcZGJioqLTz2azaK1L97fe/8zS0lLp77GFJO/55BmeGFsi5FtJSPnKczMbutnstuTyBWZjGUbnkySzef75mSk+8uiVNRZFPWgaZ7nWmnjG+kJHxDW0p0gU5xEsJnJ87qlJZuMZnhxfojPkY2whya99/40Md4U2PEc2m2V8fHzN5ETTNFFKYRhrM8nsL78TrqGdOr687Vprri6l+KMvX2TRXgv6C8/ykluG+b233rNuZ6e1JpPJrJmwZ3fgXV1dW2pbrWwmxHaGTvlyka2trbjdbtzuzbs4e6Ruu2zy+fyaZ1/ts0kkEhXZQZ9+8iqzMetcP/zCw9w1GOGv//UKp68sMh3L0NdqfX6ZXJ7R+SQF4HhPuCQSn3hsgi+fq5yd/LrBNl5ytPbPd6s0lRBEU5ZrqCvs2/wAwTGGh4dZWlpicXERgMMdQZ6fsUZF//jkSsAukbECyM9di20qBMvLy5imSTQaxeVaMYTtyqYnT55cc4zdCexmIdBaMzMzQ1tbW6mjtt0L0WiUjg4r2J4vaP7r588xvmB9ZjcdaOXlx7v5i6+N8M2zl/nWEy10hLwcPXp0Tec5OjpKJpNBKcWJEyfWtOH8+fOl4wqFAkqpio5Ta101y2b1OQKBQEmovV4rQ2w5leOr52f5wY6DDHcGMU2TdDpNIpEgGAzS1tZWdb3g8fFxCoVC1edqtwmsgYBtCdhtfv7550sDg42EoNySMU2TTFlNrDsGO/G54fW3H+D0lUV+/VNned8P38ZT48t8+JErlD/iP3jLbYzNJ9eIAMB9tx5Aa133oHlzCUE6h9tQ4hra5Xi9XsLhcEkIfvK7hri6mGJ0PsEXzqwNoH7i8QlO9IU5edKq9xIOhytmKOdyuZJ7RGtdc0pieRbItWvXiEQiFWsr14vrEYJ8Pl+KedjpmOV+5slrU2it+fyZa4wvJHnRcAffd0sfhzqsz+c3Wm7idz73LO/6+NP87htfgHt0lFAoRC5fYGQ2ztmpJznZ7cNjuNBaV8RVCloztZymv83P4uIiHR0dpdhBa2sr/f39gBXrmJ6eZnp6utShZcw8Xz43Q6GgeeFwB32tflKpFIVCAZfLRaFQYDqa4dc+dQaAC6lz/Oo9rRX3Ho1GK54zQCqX5/TlBQ51BhnsCKK1RmtNPp/H41n53pd/xrYlUN7Z2ttM0+TKlSubBpU/f+Yaz12zYjo9LT7agpaQ2VYAwLs+8TQ5c+2z/Q8fe8r6THDz2hvaAXj4uVneeMcBhrtC5PP5miyb7dBUQrCUzNER9O2alDRhfcpH7X2tfvpa/dw12M6b7hzg4kyc89eivPR4N3/4pfNMLqX522+N8cq7bmJxcZHFxcWKkWB5x79ZgNgmFouVjstms2SzWXK53I7WvVoPu5Oq5f90tbVit/mZySifemKCK3Mrabd3H+nkHS8dqjjvYGeQ772ljy+eneJ9Xz5PT4sfn9vFE2NLrOZod4gj3WHuPdnDE2OLfOHsNZKZPN0tPm4baOOVN/TQW+z4otFoSQjKXTtaax58doqPfWdlNP3pJycJeA06Q15+/r5WXnZjP+lsnvd+9iwAhktx/sIFPubp5b5bD+BzuxhbSDI6n+TsItwcsUbMT08s8ccPrQSxI0EPf/6zByG1RDKZrJg3sV4WUDURXr0wfTSVo6BXXMx/9OULnLlquYjuv/0ALzveXbqOUor/9qYX8J5PniFnarxuF//jzbcyHU0zMhPnG8/PMblkBYPvv+MwP3SrZcG98Y6B0oTKRlikTSUE4wtJTvY3rOK1sA026gSP94Q53hMG4D+/7kb+979c4qmJZd736Ud40+0H1hxrj+a01nz1/CzPXovywMuPVHzpr169Snt7O0opFhcXq2bsXM+ozC6O19raWjESrQXbElqPhYUFTNPE7/eviW1cvnyZa8tp/uShiwR9Boc7g4zNJ3nZ8S5+/O5BlFJ0dHRUBJB/6K4BDkYCfOHMJM9Orvi8D0YC3HywlQefsfLcR2YTjMwm+NKz0xXXnI1l+PK5Gb58bgav28UvvuoYi8kc15af5mB7oNSRZcw8f/jgBUZmLVfMj989SH+bn//5xfOksnkmsike+PCj/PxrbuaQESVnal73gj5edryb93zyDA8+M803Ls7hMVwsp2xxGcXndnHboQiPjy2iFLzseDeJjMljo4v89kcf5pdedRy3oZieW6S3y3rG1WoApVKpimccz5j8xddGyBc0R7vDvPGOg3zqiav881nLKu2P+Pnp7xouicCv33cjQ51rXZTdLT7eeMcBvnBmil+/70bCPjfh7jBHu8O87EQ3f/m1Ec5ejfL6OwYgbwl3eRmcWlNct4PajdOdV3Pq1Cl9+vTpLR2rtWZycpLleJKf/T/f5g2vOMW//57qfkNh95DNZrl8+XJN+37twix/+4i1xuvP3XuUuwbbOXnyJAsLC/j9fjKZDDMzM3z+6Uk+9cRKjOEnX3kzLz28uatHa83ff2ecmWia3/2xV9DWGubixYt0d3fT1tZW6ozt2jiGYZDNZksThar5qXO5HIZhlNwg8/PzdHZ24nK5OH/+PGBZRcePH19zrP1+OYZhMDg4yKVLl/jg1y/z6OV5fucNt9Db4uPSXIKhzhCGS5XaU+0cAFPRNBemYtx70wEKZjH9NJZhMZFlsDPIhZk4n31qkvtu7WeoM0TAa5DM5BlbTPIXXx2p8JNb96A41h3i0mwCsyw76Tfuu4nBTsutky9oJhZTLKWy/MO3x5kpBlw9bsUfvOV2gh6Dh5+b4SvnZ8jk8iynTO44HOHG/laml9M8WBSm7hYff/Jvvpv4gvX67789xpfPzZTWJzcUvPf+mxk+dKCiZPR8PMNHvzPOT79kmGBZts9vfvpsabS+Gf/+NSe46cCK68rv99dcHj1f0GgNB/p7K9qllEJrzcDAAKHQxjGw9VBKPaa1PrXZfvveIkilUsTjcUamYmgNtx+OON0kYYf5rqNdTC6leOjcDO//6gh//KN3ACsppeFwmNH5JJ96cpKbDrRyoifMPz45yZ9+5SIfDxS4/VAbHsPF46NL/OKrjzHYEeSr52fJ5gs8emmBsYUV98r7/+k7fP8dQ/iVdf7Z2VkikQidnZ0VwcPyirla61LxsUwmw9DQEJcuXcLr9RKJRFhaWiKbzeJ2u2lvb6+4t3w+X5Gzf+DAgTX3/+jleWIpk9yTV+lr8/GdKwu85sbekn/65kNdHD58mAsXLpSO6e3tJZPJEI1GK1wPfa1+bh4+SCKRIF0UgkPdbXS3WJ3a7Yc7uGOwk7a2tpKbrS3o4gXBNv7sx+7k8lyCrzw3w6nBdr5zZYFz12JcmLZiFncebueVNx/kxp7K7CPDpRjqCqF1kBccbOP9Xx3hibElXnyki2CxAu0rb+jhlTf0FMvEFPC5VzrsOwfbubaU4v6X3UFbwE28aOzcf8dBPG4XT4wtMrVsicu7P3GGd74my7HuIE+MLfKJxydK7/3S2BP86vee5GRfC3PxTEkE3njnQT71+MoiMXcf6STsMyqCuwcjW48d2QK92nL0eDwcOHDgui3KrbDvLYLZ2Vnm5+f5m29e4V+fn+dT//nNkjW0B9Bac/ny5Yqg8UbkC5pf/OgTpdXM/u87v4/U4gxKKXL5Ar//4AUenynwwR86TlvQQzqX50+/Ps5z47XlwQ+0B1hMZklkLDP93pPd+D0GWTNPT6ufm/pbiaYtv7PhUgz2d+PNW2mBhw8f5pkLI4R97mJbwW2sdX11dHTQ3d3N+fPnOXN1mUyuwONji7T43bxouIMnxpYIeg0GO0P4PS6WkzliGbNkDdnMFMJ87N/cxXBPK62tK6PUbDZLoVCoSAPNZDIVefq29bKwsFAS0hMnTpDL5dBa4/NZ353l5eXS7N++vj5CoVApA2v1c3lsdJEDET/33HqSYDDI5OQksViM7u5u3G43fr8fpRSXLl0CIJnJ88Vnp3jFjQfo8Cu8Xm8p+8m+5vHjx0uT5LxeL319fQQCgZJwdnd3l9qfL2iWc3BmdI6/e3SMFr+bI11hHh+z/q+UgtXdoMdQ5Aqa/+8NL6Cn1cdz16KgrBTmFw13YLgUF6bjmPkCg51BQr7KMXUgEKg6d2BwcJD5+fmqk/mGhoYqnoXP52NoaGjNftdDrRbBvhaCfD5fLHDl5rc/8zQ9LX7+5795bR1aKNST9dwYq5lcSvGbn36m9NrndjHcFSKaznFlKcfPv+4Ud3ev+FszuTxPjC9xenSRoY4gXS0+Hrk0T1fYR4vPzXIqx+W5BO/6vhsIuF0sp0zOXYvyoW/U5rICONEbZjGZYzaWoTPstTqlVA6tYaAjyFvuGsDncZHJFZiJZeju7aWlEOe3P7t28tx65FHcM9zOid4WZlUbLzvZxytO1L6Gh9a6ZC2Uu7FyuRzZbLaqWyKfzzM2NsaBAwdK4pDP50kmkxQKBUzTZG5uju7ubpaXl8lms6Vza62Jx+OEw+GKeE4ikSjFasCKyczMzBCJROjt7SWVSjE2NlbKSEomk2QymTVW1Op7Amhra2N5eZnR+SS/UzYx8S0vHODVN/RiuBSLyRz/55uXOXM1SneLj5/57ls40rq1xJJqQmB37Ou5PU+cOFHRZq/Xy/Dw8JaubyNCgDXBxE4xm1uOEXC7uOGGG+rQQqGeVBOCY8eOVS1zoLXmqYllnp5YZj6RYTaaYSaW4a5j/fz+215eddR69OhRkslk1Xz0ajw3FeXpiWVuG4gQ9BqYBc2Zq8vMRDOEfQa9bQGemVzmybElhrtC5AqaiYUkAa/B8Z4wZl7z7LWNi5EBvOJkN2+84yC//o9nOdod4g23HySRNVlI5HhybIn+iJ9YOsdLbzjIkXbPtjqOxcVFgsFgqVPfLuVzB7aapWcXZLOFACyxqTb5rxr2/013dzcul6sUs3lsdJFLcwnecPsBPEZlcYW5eIY/f3iEn7v3KDcfPUQoFKopVjUwMIDL5SrVZwqFQhUzlZVSHDt2rJQNZ9+bz+cjHA7j9/sJh8NMT0+XZiu73W6OHj1a072uh8QIsExtpRSRSIRksrmqV+5X2tvbCYfDGIaB2+1ekwaolOL2QxFuP7QSC9Ja09fXh9vt5sCBA0xOTlZkztjuCVgZhVUTHzsAeENfK6+684ZSNcru7m7uucVgamqKcDhMPB7n3hNd5PJWuiCsjBDtiVK5fIGMWeCx0UXm4xmuLqX4vlv6ubqU4pGReU4NtvPqG3vo6+vjI7/QT0tLC8lkkng8Tjwe5yVHV0oXt7S0EIvFtpUWXW1UvR3s7912sH3jXq+3tK1WESino6Oj1ClHIhF+4MABEolEacGYw4cPlzrwrrCP3/yBmwArWF+rf97lclWIaG9vL0tLS6X/MZ/PV5ESHYlEaGlpWXM/7e3txGIx/H7/dc3Y3i77Wgh8Ph99fX1ON0PYQdrb20tfzqGhoQqroL29nZaWFtxudyn4Oj09TT6fp6WlBbA6zcHBQXw+H5FIpJRC6vV66enpIRwOr7nmsWPHSl/Yy5cvk81maWlp4ejRo+RyOQKBQOk8ra2taK25ePEiXreiv7+/NOlpZGSEQCBgdQjpNB7DxStOWKPV9vZ2stksLzDNCrdOeWfa1tZGW1tbya/f3t5OMpkkEokQi8W2nFmyWwmFQhw+fHjLa1EHAoFS5k4wGGR4eLgkKuFwuCQEfr8fn89HJpOhv7+/ZBkGg0GUUhw8eBC/38+lS5fWneyntcblctHf34/P58Pj8dDd3V0SgnIRsKkmal6vd8N1GurFvhaC1cji5nub7u7uihHa6i9Sa2tr6Rnb+1WbALZ6H5vyUfGRI0eYnp5ek6t/+PDhUl53eS0bpVSphEL5yLw8WDs8PIzb7Safz5cmfmmtq4rPRnERn89XcjPY1xoaGqoYOe8XtjOT+9ChQ6W/lVIVn49Siu7u7lJdoaGhodKs5vJnBpSez9DQEOl0mmvXrtHV1UUkEimlCdv/U6uPtdOD7YHIbqVphKBajRRhbzA0NIRpmkebRqMAAAfhSURBVJuOeHdyxrjH42FgYGDNdsMwanJP9Pb2rlmr1u6IanE59PX1bTiRaHUbdsq3v5/Y7P/BzkSyqTZqL8fr9eL1eis6+0AgsGFmz/Hjx68rruEUTSMEUlZi7+Lz+Tbt6Do7O3dVZxiJRLblI9+oQJuwt9jtIgBNtB6BsL9pZGBNEPYbTWMRCPuT3t5eif0IwjZxxCJQSr1WKXVeKfW8UurdTrRB2B9EIhERAkHYJg0XAqWUAfwZ8H3ATcBblVI3NbodgiAIgoUTFsGLgOe11pe01lng74HXO9AOQRAEAWeE4CBQXgx8orhNEARBcAAnhKBaHuea6XpKqQeUUqeVUqftKoKCIAjCzuOEEEwAh8peDwCTq3fSWn9Aa31Ka32qvLa7IAiCsLM4IQTfAY4rpYaVUl7gR4DPONAOQRAEAQfmEWitTaXULwBfBAzgr7TWz2xymCAIglAnHJlQprX+AvAFJ64tCIIgVLInFqZRSs0Co5vuWJ0uoLb1CPcPcs/Ngdxzc7Cdex7UWm8aZN0TQrAdlFKna1mhZz8h99wcyD03B424Zyk6JwiC0OSIEAiCIDQ5zSAEH3C6AQ4g99wcyD03B3W/530fIxAEQRA2phksAkEQBGED9rUQ7Md1D5RSh5RSDyulzimlnlFKvbO4vUMp9SWl1MXi7/bidqWU+uPiZ/C0UupOZ+9g6yilDKXUE0qpzxVfDyulHi3e8z8UZ6qjlPIVXz9ffH/IyXZvFaVURCn1caXUc8Xnfc9+f85KqV8p/l+fVUp9VCnl32/PWSn1V0qpGaXU2bJt1/1clVJvL+5/USn19u20ad8KwT5e98AE/oPW+kbgbuDfFe/r3cBDWuvjwEPF12Dd//HizwPA+xvf5B3jncC5stf/HXhf8Z4XgXcUt78DWNRaHwPeV9xvL/JHwD9rrW8AbsO69337nJVSB4FfAk5prW/BqjzwI+y/5/w3wGtXbbuu56qU6gB+C3gxVmn/37LFY0torfflD3AP8MWy1+8B3uN0u+pwn58GXgOcB/qL2/qB88W//xJ4a9n+pf320g9WccKHgFcBn8OqYjsHuFc/b6zyJfcU/3YX91NO38N13m8rcHl1u/fzc2alRH1H8bl9Dvje/ficgSHg7FafK/BW4C/Ltlfsd70/+9YioAnWPSiawncAjwK9WutrAMXfPcXd9svn8L+AdwGF4utOYElrbRZfl99X6Z6L7y8X999LHAFmgb8uusM+qJQKsY+fs9b6KvD7wBhwDeu5Pcb+fs421/tcd/R572chqGndg72KUioMfAL4Za11dKNdq2zbU5+DUuo+YEZr/Vj55iq76hre2yu4gTuB92ut7wASrLgLqrHn77no2ng9MAwcAEJYrpHV7KfnvBnr3eOO3vt+FoKa1j3YiyilPFgi8BGt9SeLm6eVUv3F9/uBmeL2/fA5fBdwv1LqCtbSpq/CshAiSim7cGL5fZXuufh+G7DQyAbvABPAhNb60eLrj2MJw35+zt8NXNZaz2qtc8AngZewv5+zzfU+1x193vtZCPblugdKKQV8CDintf7Dsrc+A9iZA2/Hih3Y299WzD64G1i2TdC9gtb6PVrrAa31ENZz/IrW+seAh4E3F3dbfc/2Z/Hm4v57aqSotZ4CxpVSJ4ubXg08yz5+zlguobuVUsHi/7l9z/v2OZdxvc/1i8D3KKXai5bU9xS3bQ2ngyZ1Dsi8DrgAjAC/5nR7duieXoplAj4NPFn8eR2Wb/Qh4GLxd0dxf4WVPTUCnMHKyHD8PrZx//cCnyv+fQT4NvA88P8AX3G7v/j6+eL7R5xu9xbv9XbgdPFZ/yPQvt+fM/BfgOeAs8DfAr799pyBj2LFQHJYI/t3bOW5Aj9dvPfngZ/aTptkZrEgCEKTs59dQ4IgCEINiBAIgiA0OSIEgiAITY4IgSAIQpMjQiAIgtDkiBAITYlSKq+UerLsZ8PqtEqpn1VKvW0HrntFKdW13fMIwk4i6aNCU6KUimutww5c9wpWLvhco68tCOshFoEglFEcsf93pdS3iz/Hitvf+/+3d/8uVYVxHMffnwriQpAotJVzBJIILYIETRE0lHAJ+wOCwKmhwij/AhcXx8SwUYIgHIpE0AhSHNzbg8Khhohvw/MVD9drBt0cfD6v5Zz7Pef+OMv53ufh8HkkPcj9SUnbmQ//Mmv9kpayti5pKOsDkpYzOG6ORkaMpLv5HZuS5jI63ezIuRFYrVodU0PtxrGdiLgCzFIyjTo9BIYjYgi4l7VpYCNrj4H5rD8FVqMEx70CLgBIugi0gdGIuAz8AiZ6e4lmf+fU4aeYHUs/8gbczWJjO9Pl+BbwQtISJfoBSvTHbYCIeJsjgbPAGHAr668lfc3zrwEjwMcSq0OLvaAxsyPlRmC2Xxywv+sG5QZ/E3gi6RJ/jgXu9hkCnkfEo3/5oWa94Kkhs/3aje1a84CkE8D5iHhHWSinDzgDrJBTO5KuAl+irBPRrF+nBMdBCRYbl3Quj/VLGvyP12R2II8IrFYtSZuN128iYvcR0tOSPlD+KN3peN9JYCGnfURZS/ebpGeU1cS2gO/sRQpPA4uSPgHvKVHLRMS2pClgOZvLT+A+8LnXF2p2GD8+atbgxzutRp4aMjOrnEcEZmaV84jAzKxybgRmZpVzIzAzq5wbgZlZ5dwIzMwq50ZgZla5313b8mN4CK64AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Q losses')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(q_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Q losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/DQAN-cartpole.ckpt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-e50c306690e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtest_max_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Get action from DQAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.6/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcarbon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarbonConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;31m# XXX remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"
     ]
    }
   ],
   "source": [
    "test_episodes = 10\n",
    "test_max_steps = 1000\n",
    "env.reset()\n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    # Save the trained model \n",
    "    saver.restore(sess, 'checkpoints/DQAN-cartpole.ckpt')\n",
    "    \n",
    "    # iterations\n",
    "    for ep in range(test_episodes):\n",
    "        \n",
    "        # number of env/rob steps\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            env.render() \n",
    "            \n",
    "            # Get action from DQAN\n",
    "            feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "            actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # The task is done or not;\n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this to Deep Convolutional QAN\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

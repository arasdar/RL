{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-GAN: (Q-Net) + GAN (G-Net and D-Net)\n",
    "\n",
    "In this notebook, we'll combine a DQN (deep Q-net) with GAN (generative adverserial net) that can learn to play games through reinforcement learning without any reward function. We'll call this network DQAN (deep Q adverserial net). \n",
    "Adverserial nets learn to maximize the current reward based the past rewards.\n",
    "Q-net learns to maximize the future rewards based on the current reward.\n",
    "Given a task and known when the task is done or failed, we should be able to learn the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN\n",
    "More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info\n",
      "[-0.00090499 -0.1928352  -0.03145304  0.32617311] 0 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.0047617   0.00272012 -0.02492958  0.02373954] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00470729  0.19819055 -0.02445479 -0.27670353] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00074348  0.00342587 -0.02998886  0.00816714] 0 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00067497  0.19896478 -0.02982552 -0.29382475] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.00330433  0.39449898 -0.03570201 -0.59576301] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.01119431  0.59010192 -0.04761727 -0.89947461] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.02299635  0.78583572 -0.06560676 -1.20673671] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.03871306  0.98174112 -0.0897415  -1.51923717] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.05834789  1.17782615 -0.12012624 -1.83852972] 1 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "rewards, states, actions, dones = [], [], [], []\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    states.append(state)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    dones.append(done)\n",
    "    print('state, action, reward, done, info')\n",
    "    print(state, action, reward, done, info)\n",
    "    if done:\n",
    "        print('state, action, reward, done, info')\n",
    "        print(state, action, reward, done, info)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        dones.append(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(10,) (10, 4) (10,) (10,)\n",
      "float64 float64 int64 bool\n",
      "1 0\n",
      "2\n",
      "1.0 1.0\n",
      "1.177826153139452 -1.838529723915487\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    # Given data\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    \n",
    "    # Actions as output\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # Target Q values for training\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    return states, next_states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: qfunction/encoder\n",
    "def qfunction(states, action_size, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('qfunction', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits_actions)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: generator/ decoder: actions can be given actions, generated actions\n",
    "def generator(actions, state_size, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=actions, units=hidden_size)\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=state_size)        \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return next_states_logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D: descriminator/reward function\n",
    "def discriminator(states, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)   \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return reward logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, action_size, hidden_size, actions, targetQs, state_size, next_states, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param states: real current input states or observations given\n",
    "    :param actions: real actions given\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    # Q-learning: Bellman equations: loss (targetQ - Q)^2\n",
    "    actions_logits = qfunction(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_real = tf.one_hot(actions, action_size)\n",
    "    Qs = tf.reduce_sum(tf.multiply(actions_logits, actions_real), axis=1)\n",
    "    q_loss = tf.reduce_mean(tf.square(targetQs - Qs))\n",
    "\n",
    "    # GAN: Generate next states\n",
    "    actions_fake = tf.nn.softmax(actions_logits)\n",
    "    next_states_logits = generator(actions=actions_fake, state_size=state_size, hidden_size=hidden_size)\n",
    "    \n",
    "    # GAN: Discriminate between fake and real\n",
    "    next_states_fake = tf.sigmoid(x=next_states_logits)\n",
    "    d_logits_fake = discriminator(states=next_states_fake, hidden_size=hidden_size, reuse=False)\n",
    "    next_states_real = tf.sigmoid(x=next_states) \n",
    "    d_logits_real = discriminator(states=next_states_real, hidden_size=hidden_size, reuse=True)\n",
    "\n",
    "    # GAN: Adverserial training - D-learning\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # GAN: Adverserial training - G-learning\n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "\n",
    "    # Rewards fake/real\n",
    "    rewards_fake = tf.sigmoid(d_logits_fake)\n",
    "    rewards_real = tf.sigmoid(d_logits_real)\n",
    "\n",
    "    return actions_logits, q_loss, d_loss, g_loss, rewards_fake, rewards_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, q_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator/Reward loss Tensor for current reward function\n",
    "    :param g_loss: Generator/Decoder loss Tensor for next state prediction\n",
    "    :param q_loss: Qfunction/Value loss Tensor for next action prediction\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    q_vars = [var for var in t_vars if var.name.startswith('qfunction')] # Q: action At/at\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')] # G: next state St/st\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        q_opt = tf.train.AdamOptimizer(learning_rate).minimize(q_loss, var_list=q_vars)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return q_opt, g_opt, d_opt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQAN:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.next_states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.q_loss, self.d_loss, self.g_loss, self.rewards_fake, self.rewards_real = model_loss(\n",
    "            state_size=state_size, action_size=action_size, actions=self.actions, states=self.states, \n",
    "            next_states=self.next_states, hidden_size=hidden_size, targetQs=self.targetQs)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.q_opt, self.g_opt, self.d_opt = model_opt(d_loss=self.d_loss, g_loss=self.g_loss, \n",
    "                                                       q_loss=self.q_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 2000               # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64              # number of units in each Q-network hidden layer -- simulation\n",
    "state_size = 4                # number of units for the input state/observation -- simulation\n",
    "action_size = 2               # number of units for the output actions -- simulation\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 10                # experience mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = DQAN(action_size=action_size, hidden_size=hidden_size, state_size=state_size, \n",
    "                 learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 0 Total reward: 3.0 Average reward fake: 0.5075462460517883 Average reward real: 0.5098732709884644 Training d_loss: 1.3820 Training g_loss: 0.6783 Training q_loss: 0.3934 Explore P: 0.9997\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 1 Total reward: 16.0 Average reward fake: 0.4952053427696228 Average reward real: 0.489777147769928 Training d_loss: 1.3983 Training g_loss: 0.7068 Training q_loss: 0.3203 Explore P: 0.9981\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 2 Total reward: 11.0 Average reward fake: 0.4877958297729492 Average reward real: 0.49072346091270447 Training d_loss: 1.3810 Training g_loss: 0.7213 Training q_loss: 0.2446 Explore P: 0.9970\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 3 Total reward: 27.0 Average reward fake: 0.46171092987060547 Average reward real: 0.5315499305725098 Training d_loss: 1.2563 Training g_loss: 0.7815 Training q_loss: 0.3817 Explore P: 0.9944\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 4 Total reward: 11.0 Average reward fake: 0.4698796272277832 Average reward real: 0.5184186697006226 Training d_loss: 1.2997 Training g_loss: 0.7636 Training q_loss: 1.9648 Explore P: 0.9933\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 5 Total reward: 20.0 Average reward fake: 0.5067384243011475 Average reward real: 0.4558272957801819 Training d_loss: 1.5201 Training g_loss: 0.7017 Training q_loss: 4.8710 Explore P: 0.9913\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 6 Total reward: 25.0 Average reward fake: 0.4986640512943268 Average reward real: 0.4757203459739685 Training d_loss: 1.4339 Training g_loss: 0.7040 Training q_loss: 1.8724 Explore P: 0.9889\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 7 Total reward: 19.0 Average reward fake: 0.4999375343322754 Average reward real: 0.5456620454788208 Training d_loss: 1.2998 Training g_loss: 0.7041 Training q_loss: 5.6905 Explore P: 0.9870\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 8 Total reward: 20.0 Average reward fake: 0.42280906438827515 Average reward real: 0.6891927123069763 Training d_loss: 0.9242 Training g_loss: 0.8812 Training q_loss: 83.7140 Explore P: 0.9851\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 9 Total reward: 14.0 Average reward fake: 0.3453397750854492 Average reward real: 0.6732240915298462 Training d_loss: 0.8360 Training g_loss: 1.1064 Training q_loss: 159.3795 Explore P: 0.9837\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 10 Total reward: 14.0 Average reward fake: 0.46581631898880005 Average reward real: 0.6539368629455566 Training d_loss: 1.1049 Training g_loss: 0.8445 Training q_loss: 15.5429 Explore P: 0.9823\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 11 Total reward: 12.0 Average reward fake: 0.4640544056892395 Average reward real: 0.4773259162902832 Training d_loss: 1.4990 Training g_loss: 0.8376 Training q_loss: 17.3854 Explore P: 0.9812\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 12 Total reward: 16.0 Average reward fake: 0.5487098097801208 Average reward real: 0.4310271143913269 Training d_loss: 1.6696 Training g_loss: 0.6354 Training q_loss: 60.9374 Explore P: 0.9796\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 13 Total reward: 16.0 Average reward fake: 0.5850109457969666 Average reward real: 0.3487083315849304 Training d_loss: 1.9359 Training g_loss: 0.5987 Training q_loss: 54.8245 Explore P: 0.9781\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 14 Total reward: 47.0 Average reward fake: 0.40790629386901855 Average reward real: 0.6499353647232056 Training d_loss: 0.9892 Training g_loss: 0.9485 Training q_loss: 384.7792 Explore P: 0.9735\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 15 Total reward: 11.0 Average reward fake: 0.5244015455245972 Average reward real: 0.593265175819397 Training d_loss: 1.3105 Training g_loss: 0.7214 Training q_loss: 99.1789 Explore P: 0.9725\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 16 Total reward: 8.0 Average reward fake: 0.4558540880680084 Average reward real: 0.49047064781188965 Training d_loss: 1.3565 Training g_loss: 0.8666 Training q_loss: 739.3341 Explore P: 0.9717\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 17 Total reward: 14.0 Average reward fake: 0.3533034026622772 Average reward real: 0.4946940541267395 Training d_loss: 1.1734 Training g_loss: 1.0668 Training q_loss: 3787.9805 Explore P: 0.9704\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 18 Total reward: 17.0 Average reward fake: 0.5401115417480469 Average reward real: 0.5767245888710022 Training d_loss: 1.3290 Training g_loss: 0.7305 Training q_loss: 90.1616 Explore P: 0.9687\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 19 Total reward: 13.0 Average reward fake: 0.4430743157863617 Average reward real: 0.39372479915618896 Training d_loss: 1.5271 Training g_loss: 0.8813 Training q_loss: 66.2973 Explore P: 0.9675\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 20 Total reward: 17.0 Average reward fake: 0.2909243702888489 Average reward real: 0.528006911277771 Training d_loss: 1.0208 Training g_loss: 1.2646 Training q_loss: 1525.6887 Explore P: 0.9659\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 21 Total reward: 12.0 Average reward fake: 0.2170293778181076 Average reward real: 0.7449947595596313 Training d_loss: 0.5567 Training g_loss: 1.5790 Training q_loss: 6.2938 Explore P: 0.9647\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 22 Total reward: 18.0 Average reward fake: 0.3788483440876007 Average reward real: 0.6363021731376648 Training d_loss: 0.9677 Training g_loss: 1.1263 Training q_loss: 10.2285 Explore P: 0.9630\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 23 Total reward: 22.0 Average reward fake: 0.5436132550239563 Average reward real: 0.5609828233718872 Training d_loss: 1.4273 Training g_loss: 0.6778 Training q_loss: 7.1357 Explore P: 0.9609\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 24 Total reward: 19.0 Average reward fake: 0.5668443441390991 Average reward real: 0.4019160270690918 Training d_loss: 1.7839 Training g_loss: 0.6101 Training q_loss: 2.5507 Explore P: 0.9591\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 25 Total reward: 9.0 Average reward fake: 0.4306960999965668 Average reward real: 0.4785185754299164 Training d_loss: 1.3033 Training g_loss: 0.8863 Training q_loss: 4.3457 Explore P: 0.9582\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 26 Total reward: 9.0 Average reward fake: 0.2929706871509552 Average reward real: 0.5580456852912903 Training d_loss: 0.9336 Training g_loss: 1.2783 Training q_loss: 472.4407 Explore P: 0.9574\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 27 Total reward: 17.0 Average reward fake: 0.3206610083580017 Average reward real: 0.7034006714820862 Training d_loss: 0.7607 Training g_loss: 1.1946 Training q_loss: 2.4504 Explore P: 0.9558\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 28 Total reward: 38.0 Average reward fake: 0.5130559206008911 Average reward real: 0.40665286779403687 Training d_loss: 1.6680 Training g_loss: 0.6972 Training q_loss: 1.7046 Explore P: 0.9522\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 29 Total reward: 23.0 Average reward fake: 0.4624517560005188 Average reward real: 0.5323482155799866 Training d_loss: 1.2679 Training g_loss: 0.7936 Training q_loss: 180.2702 Explore P: 0.9500\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 30 Total reward: 17.0 Average reward fake: 0.5085260272026062 Average reward real: 0.5572590231895447 Training d_loss: 1.3080 Training g_loss: 0.6857 Training q_loss: 2.9431 Explore P: 0.9484\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 31 Total reward: 18.0 Average reward fake: 0.5289517641067505 Average reward real: 0.5093077421188354 Training d_loss: 1.4412 Training g_loss: 0.6454 Training q_loss: 2.9541 Explore P: 0.9467\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 32 Total reward: 15.0 Average reward fake: 0.5358701944351196 Average reward real: 0.4906995892524719 Training d_loss: 1.4892 Training g_loss: 0.6266 Training q_loss: 154.9519 Explore P: 0.9453\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 33 Total reward: 21.0 Average reward fake: 0.5625723600387573 Average reward real: 0.5010421276092529 Training d_loss: 1.5200 Training g_loss: 0.5815 Training q_loss: 3.0161 Explore P: 0.9434\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 34 Total reward: 12.0 Average reward fake: 0.5449956059455872 Average reward real: 0.4855140745639801 Training d_loss: 1.5103 Training g_loss: 0.6132 Training q_loss: 128.4251 Explore P: 0.9423\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 35 Total reward: 17.0 Average reward fake: 0.5092687010765076 Average reward real: 0.5099461078643799 Training d_loss: 1.3859 Training g_loss: 0.6836 Training q_loss: 2.1500 Explore P: 0.9407\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 36 Total reward: 12.0 Average reward fake: 0.47567886114120483 Average reward real: 0.5235112905502319 Training d_loss: 1.2986 Training g_loss: 0.7530 Training q_loss: 2.2753 Explore P: 0.9396\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 37 Total reward: 10.0 Average reward fake: 0.4638034701347351 Average reward real: 0.5195318460464478 Training d_loss: 1.2884 Training g_loss: 0.7741 Training q_loss: 2.7853 Explore P: 0.9386\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 38 Total reward: 12.0 Average reward fake: 0.4654296934604645 Average reward real: 0.5888561010360718 Training d_loss: 1.1668 Training g_loss: 0.7741 Training q_loss: 4.0473 Explore P: 0.9375\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 39 Total reward: 24.0 Average reward fake: 0.4745856821537018 Average reward real: 0.54789799451828 Training d_loss: 1.2699 Training g_loss: 0.7511 Training q_loss: 88.3379 Explore P: 0.9353\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 40 Total reward: 21.0 Average reward fake: 0.48053842782974243 Average reward real: 0.5449432730674744 Training d_loss: 1.2705 Training g_loss: 0.7424 Training q_loss: 2.8483 Explore P: 0.9333\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 41 Total reward: 10.0 Average reward fake: 0.5017991065979004 Average reward real: 0.5075013041496277 Training d_loss: 1.3872 Training g_loss: 0.6937 Training q_loss: 2.8982 Explore P: 0.9324\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 42 Total reward: 15.0 Average reward fake: 0.549674391746521 Average reward real: 0.5019339323043823 Training d_loss: 1.4919 Training g_loss: 0.6089 Training q_loss: 2.4936 Explore P: 0.9310\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 43 Total reward: 9.0 Average reward fake: 0.5548855066299438 Average reward real: 0.44376903772354126 Training d_loss: 1.6227 Training g_loss: 0.5959 Training q_loss: 2.1941 Explore P: 0.9302\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 44 Total reward: 18.0 Average reward fake: 0.50071120262146 Average reward real: 0.51701420545578 Training d_loss: 1.3557 Training g_loss: 0.7033 Training q_loss: 3.4710 Explore P: 0.9286\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 45 Total reward: 15.0 Average reward fake: 0.4541109502315521 Average reward real: 0.5410007238388062 Training d_loss: 1.2267 Training g_loss: 0.7951 Training q_loss: 4.4358 Explore P: 0.9272\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 46 Total reward: 25.0 Average reward fake: 0.46265727281570435 Average reward real: 0.5492198467254639 Training d_loss: 1.2408 Training g_loss: 0.7808 Training q_loss: 1.7422 Explore P: 0.9249\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 47 Total reward: 10.0 Average reward fake: 0.4608004689216614 Average reward real: 0.5248970985412598 Training d_loss: 1.2816 Training g_loss: 0.7820 Training q_loss: 4.1887 Explore P: 0.9240\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 48 Total reward: 16.0 Average reward fake: 0.5114399194717407 Average reward real: 0.5420728921890259 Training d_loss: 1.3418 Training g_loss: 0.6749 Training q_loss: 24.9609 Explore P: 0.9225\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 49 Total reward: 27.0 Average reward fake: 0.4999132752418518 Average reward real: 0.4971957206726074 Training d_loss: 1.3957 Training g_loss: 0.6983 Training q_loss: 3.3533 Explore P: 0.9201\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 50 Total reward: 33.0 Average reward fake: 0.48695802688598633 Average reward real: 0.4936605393886566 Training d_loss: 1.3800 Training g_loss: 0.7265 Training q_loss: 43.4300 Explore P: 0.9171\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 51 Total reward: 18.0 Average reward fake: 0.47506850957870483 Average reward real: 0.4996282458305359 Training d_loss: 1.3735 Training g_loss: 0.7755 Training q_loss: 22.8034 Explore P: 0.9154\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 52 Total reward: 34.0 Average reward fake: 0.46177929639816284 Average reward real: 0.45220357179641724 Training d_loss: 1.4218 Training g_loss: 0.8096 Training q_loss: 3.0546 Explore P: 0.9124\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 53 Total reward: 18.0 Average reward fake: 0.4472591280937195 Average reward real: 0.6375129818916321 Training d_loss: 1.0649 Training g_loss: 0.8345 Training q_loss: 3.6050 Explore P: 0.9107\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 54 Total reward: 30.0 Average reward fake: 0.4535748064517975 Average reward real: 0.4911019206047058 Training d_loss: 1.3804 Training g_loss: 0.8214 Training q_loss: 8.8333 Explore P: 0.9080\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 55 Total reward: 16.0 Average reward fake: 0.5513678193092346 Average reward real: 0.5085521936416626 Training d_loss: 1.5358 Training g_loss: 0.6159 Training q_loss: 42.3961 Explore P: 0.9066\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 56 Total reward: 45.0 Average reward fake: 0.5267537832260132 Average reward real: 0.4999713897705078 Training d_loss: 1.4451 Training g_loss: 0.6437 Training q_loss: 6.8488 Explore P: 0.9026\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 57 Total reward: 14.0 Average reward fake: 0.5059841275215149 Average reward real: 0.5198938846588135 Training d_loss: 1.3602 Training g_loss: 0.6898 Training q_loss: 77.2731 Explore P: 0.9013\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 58 Total reward: 18.0 Average reward fake: 0.4433358609676361 Average reward real: 0.5264477133750916 Training d_loss: 1.2362 Training g_loss: 0.8329 Training q_loss: 2.8031 Explore P: 0.8997\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 59 Total reward: 21.0 Average reward fake: 0.44410020112991333 Average reward real: 0.515873372554779 Training d_loss: 1.2819 Training g_loss: 0.8234 Training q_loss: 4.8416 Explore P: 0.8979\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 60 Total reward: 29.0 Average reward fake: 0.45968136191368103 Average reward real: 0.46480950713157654 Training d_loss: 1.4465 Training g_loss: 0.7944 Training q_loss: 36.7491 Explore P: 0.8953\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 61 Total reward: 15.0 Average reward fake: 0.509713888168335 Average reward real: 0.5024805665016174 Training d_loss: 1.4290 Training g_loss: 0.6887 Training q_loss: 1.4717 Explore P: 0.8940\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 62 Total reward: 22.0 Average reward fake: 0.5473809242248535 Average reward real: 0.509141206741333 Training d_loss: 1.4811 Training g_loss: 0.6163 Training q_loss: 33.7547 Explore P: 0.8920\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 63 Total reward: 15.0 Average reward fake: 0.5194061994552612 Average reward real: 0.48037999868392944 Training d_loss: 1.4667 Training g_loss: 0.6676 Training q_loss: 82.2443 Explore P: 0.8907\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 64 Total reward: 14.0 Average reward fake: 0.4154403805732727 Average reward real: 0.5169650912284851 Training d_loss: 1.2032 Training g_loss: 0.8976 Training q_loss: 40.8568 Explore P: 0.8895\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 65 Total reward: 28.0 Average reward fake: 0.4552479684352875 Average reward real: 0.5684057474136353 Training d_loss: 1.2157 Training g_loss: 0.7960 Training q_loss: 0.9643 Explore P: 0.8870\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 66 Total reward: 15.0 Average reward fake: 0.5056203603744507 Average reward real: 0.48646292090415955 Training d_loss: 1.4694 Training g_loss: 0.6967 Training q_loss: 34.5332 Explore P: 0.8857\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 67 Total reward: 17.0 Average reward fake: 0.509868860244751 Average reward real: 0.47668886184692383 Training d_loss: 1.5054 Training g_loss: 0.6806 Training q_loss: 3.3487 Explore P: 0.8842\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 68 Total reward: 19.0 Average reward fake: 0.5380724668502808 Average reward real: 0.5126553773880005 Training d_loss: 1.4674 Training g_loss: 0.6311 Training q_loss: 2.5696 Explore P: 0.8825\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 69 Total reward: 16.0 Average reward fake: 0.49061718583106995 Average reward real: 0.47039538621902466 Training d_loss: 1.4334 Training g_loss: 0.7205 Training q_loss: 16.4356 Explore P: 0.8811\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 70 Total reward: 30.0 Average reward fake: 0.4875944256782532 Average reward real: 0.5174214839935303 Training d_loss: 1.3282 Training g_loss: 0.7214 Training q_loss: 35.9657 Explore P: 0.8785\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 71 Total reward: 46.0 Average reward fake: 0.4603622853755951 Average reward real: 0.5122183561325073 Training d_loss: 1.3035 Training g_loss: 0.7829 Training q_loss: 32.2211 Explore P: 0.8745\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 72 Total reward: 66.0 Average reward fake: 0.4634663462638855 Average reward real: 0.49674588441848755 Training d_loss: 1.3554 Training g_loss: 0.7773 Training q_loss: 21.9912 Explore P: 0.8689\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 73 Total reward: 28.0 Average reward fake: 0.48343682289123535 Average reward real: 0.5128352642059326 Training d_loss: 1.3333 Training g_loss: 0.7323 Training q_loss: 18.7174 Explore P: 0.8665\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 74 Total reward: 68.0 Average reward fake: 0.5210146307945251 Average reward real: 0.4457215368747711 Training d_loss: 1.5695 Training g_loss: 0.6568 Training q_loss: 2.6288 Explore P: 0.8607\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 75 Total reward: 16.0 Average reward fake: 0.48649734258651733 Average reward real: 0.4878918528556824 Training d_loss: 1.4096 Training g_loss: 0.7364 Training q_loss: 1.9595 Explore P: 0.8593\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 76 Total reward: 17.0 Average reward fake: 0.45298337936401367 Average reward real: 0.506237804889679 Training d_loss: 1.2949 Training g_loss: 0.7960 Training q_loss: 1.1835 Explore P: 0.8579\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 77 Total reward: 20.0 Average reward fake: 0.4151034355163574 Average reward real: 0.6034284234046936 Training d_loss: 1.0543 Training g_loss: 0.8930 Training q_loss: 2.3180 Explore P: 0.8562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 78 Total reward: 24.0 Average reward fake: 0.4479575753211975 Average reward real: 0.5869371294975281 Training d_loss: 1.1764 Training g_loss: 0.8153 Training q_loss: 5.2836 Explore P: 0.8541\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 79 Total reward: 33.0 Average reward fake: 0.4623483121395111 Average reward real: 0.5718841552734375 Training d_loss: 1.2384 Training g_loss: 0.7911 Training q_loss: 0.9501 Explore P: 0.8513\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 80 Total reward: 88.0 Average reward fake: 0.3907202482223511 Average reward real: 0.6018367409706116 Training d_loss: 1.0155 Training g_loss: 0.9654 Training q_loss: 14.6612 Explore P: 0.8440\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 81 Total reward: 25.0 Average reward fake: 0.4377671778202057 Average reward real: 0.651684582233429 Training d_loss: 1.0635 Training g_loss: 0.9207 Training q_loss: 2.9546 Explore P: 0.8419\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 82 Total reward: 13.0 Average reward fake: 0.44957834482192993 Average reward real: 0.5088674426078796 Training d_loss: 1.3754 Training g_loss: 0.8242 Training q_loss: 2.9391 Explore P: 0.8408\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 83 Total reward: 49.0 Average reward fake: 0.5762022137641907 Average reward real: 0.47333043813705444 Training d_loss: 1.6115 Training g_loss: 0.5688 Training q_loss: 13.2034 Explore P: 0.8368\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 84 Total reward: 35.0 Average reward fake: 0.4848043918609619 Average reward real: 0.6708894968032837 Training d_loss: 1.0849 Training g_loss: 0.7517 Training q_loss: 3.3183 Explore P: 0.8339\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 85 Total reward: 16.0 Average reward fake: 0.5453301668167114 Average reward real: 0.5470648407936096 Training d_loss: 1.4547 Training g_loss: 0.6344 Training q_loss: 3.4242 Explore P: 0.8325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 86 Total reward: 24.0 Average reward fake: 0.5343902707099915 Average reward real: 0.5761639475822449 Training d_loss: 1.3328 Training g_loss: 0.6668 Training q_loss: 8.1396 Explore P: 0.8306\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 87 Total reward: 12.0 Average reward fake: 0.4420132040977478 Average reward real: 0.5007001757621765 Training d_loss: 1.2762 Training g_loss: 0.8315 Training q_loss: 27.9302 Explore P: 0.8296\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 88 Total reward: 40.0 Average reward fake: 0.5538844466209412 Average reward real: 0.5079801678657532 Training d_loss: 1.5224 Training g_loss: 0.6183 Training q_loss: 1.5847 Explore P: 0.8263\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 89 Total reward: 28.0 Average reward fake: 0.45022836327552795 Average reward real: 0.4289051592350006 Training d_loss: 1.4465 Training g_loss: 0.8010 Training q_loss: 1.1624 Explore P: 0.8240\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 90 Total reward: 24.0 Average reward fake: 0.5057294368743896 Average reward real: 0.46929579973220825 Training d_loss: 1.4699 Training g_loss: 0.6905 Training q_loss: 24.8547 Explore P: 0.8221\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 91 Total reward: 49.0 Average reward fake: 0.4415866732597351 Average reward real: 0.4876983165740967 Training d_loss: 1.3202 Training g_loss: 0.8381 Training q_loss: 50.3055 Explore P: 0.8181\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 92 Total reward: 44.0 Average reward fake: 0.4072880148887634 Average reward real: 0.49105969071388245 Training d_loss: 1.2476 Training g_loss: 0.9174 Training q_loss: 5.2514 Explore P: 0.8146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 93 Total reward: 66.0 Average reward fake: 0.5631589889526367 Average reward real: 0.49262523651123047 Training d_loss: 1.6096 Training g_loss: 0.5948 Training q_loss: 5.6165 Explore P: 0.8093\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 94 Total reward: 25.0 Average reward fake: 0.5648524761199951 Average reward real: 0.5596535801887512 Training d_loss: 1.4189 Training g_loss: 0.5850 Training q_loss: 2.4922 Explore P: 0.8073\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 95 Total reward: 32.0 Average reward fake: 0.561259925365448 Average reward real: 0.5860286355018616 Training d_loss: 1.3890 Training g_loss: 0.6021 Training q_loss: 2.3127 Explore P: 0.8047\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 96 Total reward: 34.0 Average reward fake: 0.4772149622440338 Average reward real: 0.4737885892391205 Training d_loss: 1.4221 Training g_loss: 0.8042 Training q_loss: 2.7164 Explore P: 0.8020\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 97 Total reward: 22.0 Average reward fake: 0.28150826692581177 Average reward real: 0.6169878244400024 Training d_loss: 0.8183 Training g_loss: 1.3504 Training q_loss: 14.5286 Explore P: 0.8003\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 98 Total reward: 19.0 Average reward fake: 0.3070385456085205 Average reward real: 0.5205233097076416 Training d_loss: 1.3160 Training g_loss: 1.4602 Training q_loss: 71.7661 Explore P: 0.7988\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 99 Total reward: 22.0 Average reward fake: 0.5976814031600952 Average reward real: 0.41035470366477966 Training d_loss: 2.1418 Training g_loss: 0.5237 Training q_loss: 3.0021 Explore P: 0.7971\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 100 Total reward: 36.0 Average reward fake: 0.5343033075332642 Average reward real: 0.4875965714454651 Training d_loss: 1.4858 Training g_loss: 0.6373 Training q_loss: 17.9350 Explore P: 0.7942\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 101 Total reward: 19.0 Average reward fake: 0.48433613777160645 Average reward real: 0.5077880620956421 Training d_loss: 1.3540 Training g_loss: 0.7467 Training q_loss: 82.2672 Explore P: 0.7927\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 102 Total reward: 22.0 Average reward fake: 0.42822304368019104 Average reward real: 0.5106856822967529 Training d_loss: 1.2704 Training g_loss: 0.8638 Training q_loss: 0.6500 Explore P: 0.7910\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 103 Total reward: 44.0 Average reward fake: 0.43232399225234985 Average reward real: 0.48665112257003784 Training d_loss: 1.3078 Training g_loss: 0.8718 Training q_loss: 62.5346 Explore P: 0.7876\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 104 Total reward: 22.0 Average reward fake: 0.31862783432006836 Average reward real: 0.48880448937416077 Training d_loss: 1.1010 Training g_loss: 1.1705 Training q_loss: 3.1933 Explore P: 0.7859\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 105 Total reward: 15.0 Average reward fake: 0.3229600787162781 Average reward real: 0.584833562374115 Training d_loss: 0.9385 Training g_loss: 1.1605 Training q_loss: 2.6347 Explore P: 0.7847\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 106 Total reward: 27.0 Average reward fake: 0.4904860854148865 Average reward real: 0.6091447472572327 Training d_loss: 1.2032 Training g_loss: 0.7443 Training q_loss: 49.7927 Explore P: 0.7826\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 107 Total reward: 10.0 Average reward fake: 0.5671337842941284 Average reward real: 0.45922261476516724 Training d_loss: 1.6398 Training g_loss: 0.5746 Training q_loss: 1.7536 Explore P: 0.7819\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 108 Total reward: 32.0 Average reward fake: 0.6681567430496216 Average reward real: 0.5061001181602478 Training d_loss: 1.7845 Training g_loss: 0.4153 Training q_loss: 3.7540 Explore P: 0.7794\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 109 Total reward: 30.0 Average reward fake: 0.4808040261268616 Average reward real: 0.5905645489692688 Training d_loss: 1.1877 Training g_loss: 0.7460 Training q_loss: 3.2897 Explore P: 0.7771\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 110 Total reward: 10.0 Average reward fake: 0.4805876314640045 Average reward real: 0.6074345707893372 Training d_loss: 1.1640 Training g_loss: 0.7467 Training q_loss: 4.0790 Explore P: 0.7763\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 111 Total reward: 65.0 Average reward fake: 0.44099053740501404 Average reward real: 0.5654643177986145 Training d_loss: 1.1542 Training g_loss: 0.8348 Training q_loss: 5.2215 Explore P: 0.7714\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 112 Total reward: 37.0 Average reward fake: 0.5223596692085266 Average reward real: 0.47402477264404297 Training d_loss: 1.4951 Training g_loss: 0.6535 Training q_loss: 2.5136 Explore P: 0.7685\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 113 Total reward: 23.0 Average reward fake: 0.5556254386901855 Average reward real: 0.4814903736114502 Training d_loss: 1.5562 Training g_loss: 0.5941 Training q_loss: 2.5690 Explore P: 0.7668\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 114 Total reward: 17.0 Average reward fake: 0.5060232877731323 Average reward real: 0.5025269985198975 Training d_loss: 1.4024 Training g_loss: 0.6799 Training q_loss: 34.5601 Explore P: 0.7655\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 115 Total reward: 65.0 Average reward fake: 0.52766352891922 Average reward real: 0.43797340989112854 Training d_loss: 1.5801 Training g_loss: 0.6674 Training q_loss: 3.9428 Explore P: 0.7606\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 116 Total reward: 18.0 Average reward fake: 0.42025095224380493 Average reward real: 0.4975675940513611 Training d_loss: 1.2628 Training g_loss: 0.9068 Training q_loss: 5.6436 Explore P: 0.7593\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 117 Total reward: 63.0 Average reward fake: 0.5037425756454468 Average reward real: 0.44829076528549194 Training d_loss: 1.5070 Training g_loss: 0.7028 Training q_loss: 5.0046 Explore P: 0.7546\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 118 Total reward: 19.0 Average reward fake: 0.3854878842830658 Average reward real: 0.5267564058303833 Training d_loss: 1.1502 Training g_loss: 0.9930 Training q_loss: 49.7958 Explore P: 0.7532\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 119 Total reward: 29.0 Average reward fake: 0.562842845916748 Average reward real: 0.5177631974220276 Training d_loss: 1.5023 Training g_loss: 0.5880 Training q_loss: 3.7133 Explore P: 0.7510\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 120 Total reward: 51.0 Average reward fake: 0.47928720712661743 Average reward real: 0.5224600434303284 Training d_loss: 1.3018 Training g_loss: 0.7387 Training q_loss: 2.6224 Explore P: 0.7472\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 121 Total reward: 44.0 Average reward fake: 0.48186206817626953 Average reward real: 0.5509284138679504 Training d_loss: 1.2564 Training g_loss: 0.7380 Training q_loss: 63.7904 Explore P: 0.7440\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 122 Total reward: 16.0 Average reward fake: 0.5226058959960938 Average reward real: 0.5113396644592285 Training d_loss: 1.4139 Training g_loss: 0.6526 Training q_loss: 1.8535 Explore P: 0.7428\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 123 Total reward: 65.0 Average reward fake: 0.5237872004508972 Average reward real: 0.4630652368068695 Training d_loss: 1.5145 Training g_loss: 0.6574 Training q_loss: 2.1182 Explore P: 0.7381\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 124 Total reward: 22.0 Average reward fake: 0.43998169898986816 Average reward real: 0.4913291037082672 Training d_loss: 1.2918 Training g_loss: 0.8349 Training q_loss: 1.3172 Explore P: 0.7365\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 125 Total reward: 18.0 Average reward fake: 0.471731036901474 Average reward real: 0.5170130729675293 Training d_loss: 1.3067 Training g_loss: 0.7681 Training q_loss: 5.3407 Explore P: 0.7352\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 126 Total reward: 27.0 Average reward fake: 0.48716744780540466 Average reward real: 0.4813947081565857 Training d_loss: 1.4168 Training g_loss: 0.7225 Training q_loss: 3.2984 Explore P: 0.7332\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 127 Total reward: 102.0 Average reward fake: 0.4418913722038269 Average reward real: 0.5690455436706543 Training d_loss: 1.1885 Training g_loss: 0.8545 Training q_loss: 73.9392 Explore P: 0.7259\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 128 Total reward: 15.0 Average reward fake: 0.5232558846473694 Average reward real: 0.5564731359481812 Training d_loss: 1.4121 Training g_loss: 0.6917 Training q_loss: 3.7674 Explore P: 0.7248\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 129 Total reward: 45.0 Average reward fake: 0.5271745324134827 Average reward real: 0.4197794497013092 Training d_loss: 1.6218 Training g_loss: 0.6620 Training q_loss: 4.3694 Explore P: 0.7216\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 130 Total reward: 70.0 Average reward fake: 0.5094336867332458 Average reward real: 0.5590265989303589 Training d_loss: 1.3726 Training g_loss: 0.7131 Training q_loss: 3.3855 Explore P: 0.7166\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 131 Total reward: 11.0 Average reward fake: 0.5710980892181396 Average reward real: 0.47616061568260193 Training d_loss: 1.6756 Training g_loss: 0.5746 Training q_loss: 4.2837 Explore P: 0.7159\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 132 Total reward: 31.0 Average reward fake: 0.5690445303916931 Average reward real: 0.5453413128852844 Training d_loss: 1.4512 Training g_loss: 0.5771 Training q_loss: 66.8377 Explore P: 0.7137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 133 Total reward: 46.0 Average reward fake: 0.4702112078666687 Average reward real: 0.5048040151596069 Training d_loss: 1.3388 Training g_loss: 0.7768 Training q_loss: 5.1465 Explore P: 0.7104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 134 Total reward: 48.0 Average reward fake: 0.3951827883720398 Average reward real: 0.47069066762924194 Training d_loss: 1.2682 Training g_loss: 0.9448 Training q_loss: 1.8922 Explore P: 0.7071\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 135 Total reward: 47.0 Average reward fake: 0.4219974875450134 Average reward real: 0.5864468812942505 Training d_loss: 1.0862 Training g_loss: 0.8797 Training q_loss: 2.0686 Explore P: 0.7038\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 136 Total reward: 15.0 Average reward fake: 0.46453553438186646 Average reward real: 0.5237237215042114 Training d_loss: 1.2964 Training g_loss: 0.7820 Training q_loss: 4.4124 Explore P: 0.7028\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 137 Total reward: 82.0 Average reward fake: 0.5242015719413757 Average reward real: 0.5083555579185486 Training d_loss: 1.4220 Training g_loss: 0.6479 Training q_loss: 6.6507 Explore P: 0.6971\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 138 Total reward: 75.0 Average reward fake: 0.49482256174087524 Average reward real: 0.600605845451355 Training d_loss: 1.1964 Training g_loss: 0.7105 Training q_loss: 4.3685 Explore P: 0.6920\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 139 Total reward: 20.0 Average reward fake: 0.441974937915802 Average reward real: 0.5665594935417175 Training d_loss: 1.1631 Training g_loss: 0.8315 Training q_loss: 2.2545 Explore P: 0.6906\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 140 Total reward: 37.0 Average reward fake: 0.44489049911499023 Average reward real: 0.5291858911514282 Training d_loss: 1.2378 Training g_loss: 0.8007 Training q_loss: 113.7272 Explore P: 0.6881\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 141 Total reward: 14.0 Average reward fake: 0.4466039538383484 Average reward real: 0.572528064250946 Training d_loss: 1.1574 Training g_loss: 0.8150 Training q_loss: 6.6072 Explore P: 0.6872\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 142 Total reward: 20.0 Average reward fake: 0.4689335227012634 Average reward real: 0.5703941583633423 Training d_loss: 1.2092 Training g_loss: 0.7676 Training q_loss: 7.8801 Explore P: 0.6858\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 143 Total reward: 84.0 Average reward fake: 0.5167196989059448 Average reward real: 0.5377113223075867 Training d_loss: 1.4282 Training g_loss: 0.7185 Training q_loss: 6.2306 Explore P: 0.6802\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 144 Total reward: 38.0 Average reward fake: 0.4910746216773987 Average reward real: 0.5264020562171936 Training d_loss: 1.3202 Training g_loss: 0.7113 Training q_loss: 157.5406 Explore P: 0.6776\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 145 Total reward: 103.0 Average reward fake: 0.4968436658382416 Average reward real: 0.4639247953891754 Training d_loss: 1.4588 Training g_loss: 0.6893 Training q_loss: 5.7883 Explore P: 0.6708\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 146 Total reward: 64.0 Average reward fake: 0.51125168800354 Average reward real: 0.3856808543205261 Training d_loss: 1.7110 Training g_loss: 0.6698 Training q_loss: 4.4003 Explore P: 0.6666\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 147 Total reward: 66.0 Average reward fake: 0.49820375442504883 Average reward real: 0.5156146287918091 Training d_loss: 1.3570 Training g_loss: 0.7037 Training q_loss: 6.2309 Explore P: 0.6622\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 148 Total reward: 33.0 Average reward fake: 0.4725703299045563 Average reward real: 0.5413480997085571 Training d_loss: 1.2599 Training g_loss: 0.7552 Training q_loss: 4.7128 Explore P: 0.6601\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 149 Total reward: 92.0 Average reward fake: 0.447326123714447 Average reward real: 0.38960331678390503 Training d_loss: 1.5601 Training g_loss: 0.8260 Training q_loss: 4.1327 Explore P: 0.6541\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 150 Total reward: 76.0 Average reward fake: 0.458423912525177 Average reward real: 0.591476321220398 Training d_loss: 1.1490 Training g_loss: 0.8049 Training q_loss: 4.0064 Explore P: 0.6493\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 151 Total reward: 167.0 Average reward fake: 0.47898024320602417 Average reward real: 0.395972341299057 Training d_loss: 1.6500 Training g_loss: 0.7586 Training q_loss: 4.0901 Explore P: 0.6387\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 152 Total reward: 76.0 Average reward fake: 0.4578797221183777 Average reward real: 0.5611639022827148 Training d_loss: 1.1918 Training g_loss: 0.7866 Training q_loss: 8.9557 Explore P: 0.6339\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 153 Total reward: 58.0 Average reward fake: 0.522998571395874 Average reward real: 0.48927822709083557 Training d_loss: 1.4643 Training g_loss: 0.6712 Training q_loss: 415.8405 Explore P: 0.6303\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 154 Total reward: 103.0 Average reward fake: 0.5021473169326782 Average reward real: 0.4539298415184021 Training d_loss: 1.5149 Training g_loss: 0.7071 Training q_loss: 7.3166 Explore P: 0.6239\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 155 Total reward: 22.0 Average reward fake: 0.4835086762905121 Average reward real: 0.5152308940887451 Training d_loss: 1.3337 Training g_loss: 0.7266 Training q_loss: 5.0446 Explore P: 0.6226\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 156 Total reward: 29.0 Average reward fake: 0.47803276777267456 Average reward real: 0.5419520139694214 Training d_loss: 1.2671 Training g_loss: 0.7465 Training q_loss: 8.1670 Explore P: 0.6208\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 157 Total reward: 17.0 Average reward fake: 0.49195265769958496 Average reward real: 0.5289364457130432 Training d_loss: 1.3165 Training g_loss: 0.7180 Training q_loss: 4.6685 Explore P: 0.6198\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 158 Total reward: 147.0 Average reward fake: 0.42957058548927307 Average reward real: 0.567907452583313 Training d_loss: 1.1392 Training g_loss: 0.8459 Training q_loss: 14.6405 Explore P: 0.6109\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 159 Total reward: 51.0 Average reward fake: 0.4923872947692871 Average reward real: 0.4739286005496979 Training d_loss: 1.4280 Training g_loss: 0.7010 Training q_loss: 4.8147 Explore P: 0.6078\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 160 Total reward: 15.0 Average reward fake: 0.5112699866294861 Average reward real: 0.5036092400550842 Training d_loss: 1.4158 Training g_loss: 0.6825 Training q_loss: 18.2254 Explore P: 0.6069\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 161 Total reward: 72.0 Average reward fake: 0.4261988699436188 Average reward real: 0.473207950592041 Training d_loss: 1.3437 Training g_loss: 0.9311 Training q_loss: 10.4884 Explore P: 0.6027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 162 Total reward: 165.0 Average reward fake: 0.44502711296081543 Average reward real: 0.5970150232315063 Training d_loss: 1.1535 Training g_loss: 0.8407 Training q_loss: 862.7224 Explore P: 0.5930\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 163 Total reward: 21.0 Average reward fake: 0.47253647446632385 Average reward real: 0.4282093644142151 Training d_loss: 1.5597 Training g_loss: 0.7420 Training q_loss: 112.7326 Explore P: 0.5917\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 164 Total reward: 74.0 Average reward fake: 0.5121086239814758 Average reward real: 0.4956692159175873 Training d_loss: 1.4288 Training g_loss: 0.6707 Training q_loss: 22.2597 Explore P: 0.5874\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 165 Total reward: 21.0 Average reward fake: 0.5029188394546509 Average reward real: 0.5093151330947876 Training d_loss: 1.3747 Training g_loss: 0.6875 Training q_loss: 8.7820 Explore P: 0.5862\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 166 Total reward: 138.0 Average reward fake: 0.4769342541694641 Average reward real: 0.5460297465324402 Training d_loss: 1.2651 Training g_loss: 0.8104 Training q_loss: 45.7342 Explore P: 0.5783\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 167 Total reward: 48.0 Average reward fake: 0.47547444701194763 Average reward real: 0.49145469069480896 Training d_loss: 1.3798 Training g_loss: 0.7556 Training q_loss: 10.5292 Explore P: 0.5756\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 168 Total reward: 156.0 Average reward fake: 0.549239993095398 Average reward real: 0.5386022925376892 Training d_loss: 1.4240 Training g_loss: 0.5992 Training q_loss: 21.3650 Explore P: 0.5669\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 169 Total reward: 20.0 Average reward fake: 0.5115240812301636 Average reward real: 0.5258992910385132 Training d_loss: 1.3634 Training g_loss: 0.6831 Training q_loss: 12.8725 Explore P: 0.5657\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 170 Total reward: 92.0 Average reward fake: 0.5332473516464233 Average reward real: 0.5002032518386841 Training d_loss: 1.4707 Training g_loss: 0.6612 Training q_loss: 691.9837 Explore P: 0.5607\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 171 Total reward: 96.0 Average reward fake: 0.5529931783676147 Average reward real: 0.4667319655418396 Training d_loss: 1.5930 Training g_loss: 0.6100 Training q_loss: 5.4675 Explore P: 0.5554\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 172 Total reward: 170.0 Average reward fake: 0.4806954264640808 Average reward real: 0.3766948878765106 Training d_loss: 1.6666 Training g_loss: 0.7676 Training q_loss: 23.8829 Explore P: 0.5462\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 173 Total reward: 55.0 Average reward fake: 0.3907133936882019 Average reward real: 0.608792245388031 Training d_loss: 0.9944 Training g_loss: 0.9965 Training q_loss: 23.0348 Explore P: 0.5433\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 174 Total reward: 38.0 Average reward fake: 0.6285675764083862 Average reward real: 0.40960603952407837 Training d_loss: 1.9567 Training g_loss: 0.4915 Training q_loss: 24.4256 Explore P: 0.5412\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 175 Total reward: 178.0 Average reward fake: 0.5158016085624695 Average reward real: 0.3999994695186615 Training d_loss: 1.6494 Training g_loss: 0.6762 Training q_loss: 27.4082 Explore P: 0.5319\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 176 Total reward: 72.0 Average reward fake: 0.49078044295310974 Average reward real: 0.36549997329711914 Training d_loss: 1.8426 Training g_loss: 0.7242 Training q_loss: 37.0282 Explore P: 0.5281\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 177 Total reward: 52.0 Average reward fake: 0.5715945959091187 Average reward real: 0.5422471761703491 Training d_loss: 1.4636 Training g_loss: 0.5774 Training q_loss: 75.4096 Explore P: 0.5254\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 178 Total reward: 138.0 Average reward fake: 0.5223649144172668 Average reward real: 0.4933384358882904 Training d_loss: 1.4470 Training g_loss: 0.6544 Training q_loss: 50.7597 Explore P: 0.5184\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 179 Total reward: 99.0 Average reward fake: 0.5095468759536743 Average reward real: 0.4658929407596588 Training d_loss: 1.5025 Training g_loss: 0.6756 Training q_loss: 6.5501 Explore P: 0.5134\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 180 Total reward: 122.0 Average reward fake: 0.4298607409000397 Average reward real: 0.5171598196029663 Training d_loss: 1.2261 Training g_loss: 0.8385 Training q_loss: 223.2468 Explore P: 0.5073\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 181 Total reward: 161.0 Average reward fake: 0.48590096831321716 Average reward real: 0.543528139591217 Training d_loss: 1.2796 Training g_loss: 0.7200 Training q_loss: 31.2757 Explore P: 0.4993\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 182 Total reward: 52.0 Average reward fake: 0.5236743688583374 Average reward real: 0.47987836599349976 Training d_loss: 1.4800 Training g_loss: 0.6536 Training q_loss: 49.2614 Explore P: 0.4968\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 183 Total reward: 75.0 Average reward fake: 0.47027188539505005 Average reward real: 0.550248384475708 Training d_loss: 1.2486 Training g_loss: 0.7648 Training q_loss: 1523.1927 Explore P: 0.4931\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 184 Total reward: 199.0 Average reward fake: 0.48718738555908203 Average reward real: 0.6039396524429321 Training d_loss: 1.3191 Training g_loss: 0.8807 Training q_loss: 44.1095 Explore P: 0.4836\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 185 Total reward: 185.0 Average reward fake: 0.4385625720024109 Average reward real: 0.5325339436531067 Training d_loss: 1.2206 Training g_loss: 0.8680 Training q_loss: 88.8581 Explore P: 0.4749\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 186 Total reward: 16.0 Average reward fake: 0.43672770261764526 Average reward real: 0.48595380783081055 Training d_loss: 1.3061 Training g_loss: 0.8477 Training q_loss: 10.7789 Explore P: 0.4742\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 187 Total reward: 154.0 Average reward fake: 0.5033859014511108 Average reward real: 0.5694661140441895 Training d_loss: 1.2723 Training g_loss: 0.6985 Training q_loss: 27.7557 Explore P: 0.4671\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 188 Total reward: 17.0 Average reward fake: 0.47843289375305176 Average reward real: 0.5032463073730469 Training d_loss: 1.3468 Training g_loss: 0.7462 Training q_loss: 729.8158 Explore P: 0.4663\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 189 Total reward: 199.0 Average reward fake: 0.4863644242286682 Average reward real: 0.47735515236854553 Training d_loss: 1.4268 Training g_loss: 0.7266 Training q_loss: 35.5006 Explore P: 0.4573\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 190 Total reward: 65.0 Average reward fake: 0.5115452408790588 Average reward real: 0.49518242478370667 Training d_loss: 1.4318 Training g_loss: 0.6769 Training q_loss: 98.3148 Explore P: 0.4544\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 191 Total reward: 199.0 Average reward fake: 0.4621833860874176 Average reward real: 0.5213952660560608 Training d_loss: 1.2736 Training g_loss: 0.7761 Training q_loss: 118.5408 Explore P: 0.4457\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 192 Total reward: 199.0 Average reward fake: 0.45790520310401917 Average reward real: 0.5593084692955017 Training d_loss: 1.1984 Training g_loss: 0.7899 Training q_loss: 8.9811 Explore P: 0.4371\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 193 Total reward: 180.0 Average reward fake: 0.421712726354599 Average reward real: 0.44950491189956665 Training d_loss: 1.3539 Training g_loss: 0.8766 Training q_loss: 29.9793 Explore P: 0.4295\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 194 Total reward: 199.0 Average reward fake: 0.47283926606178284 Average reward real: 0.4948022961616516 Training d_loss: 1.3469 Training g_loss: 0.7479 Training q_loss: 29.2436 Explore P: 0.4212\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 195 Total reward: 199.0 Average reward fake: 0.537057638168335 Average reward real: 0.540947437286377 Training d_loss: 1.3957 Training g_loss: 0.6649 Training q_loss: 225.7862 Explore P: 0.4131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 196 Total reward: 148.0 Average reward fake: 0.5026296377182007 Average reward real: 0.5517159104347229 Training d_loss: 1.2945 Training g_loss: 0.7039 Training q_loss: 122.4987 Explore P: 0.4072\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 197 Total reward: 181.0 Average reward fake: 0.4381450116634369 Average reward real: 0.4506418704986572 Training d_loss: 1.3957 Training g_loss: 0.8001 Training q_loss: 487.5938 Explore P: 0.4001\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 198 Total reward: 48.0 Average reward fake: 0.497182697057724 Average reward real: 0.44751936197280884 Training d_loss: 1.4998 Training g_loss: 0.7197 Training q_loss: 40.2939 Explore P: 0.3982\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 199 Total reward: 199.0 Average reward fake: 0.49913787841796875 Average reward real: 0.4337875247001648 Training d_loss: 1.5364 Training g_loss: 0.7291 Training q_loss: 32.5185 Explore P: 0.3905\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 200 Total reward: 97.0 Average reward fake: 0.4763607978820801 Average reward real: 0.4935847818851471 Training d_loss: 1.3542 Training g_loss: 0.7474 Training q_loss: 2165.4126 Explore P: 0.3869\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 201 Total reward: 190.0 Average reward fake: 0.45251813530921936 Average reward real: 0.5682864785194397 Training d_loss: 1.1726 Training g_loss: 0.8117 Training q_loss: 59.0146 Explore P: 0.3798\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 202 Total reward: 199.0 Average reward fake: 0.49133795499801636 Average reward real: 0.4933181405067444 Training d_loss: 1.3975 Training g_loss: 0.7135 Training q_loss: 21.5605 Explore P: 0.3725\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 203 Total reward: 178.0 Average reward fake: 0.5074685215950012 Average reward real: 0.47621458768844604 Training d_loss: 1.4530 Training g_loss: 0.6836 Training q_loss: 116.4291 Explore P: 0.3661\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 204 Total reward: 166.0 Average reward fake: 0.5212256908416748 Average reward real: 0.5632005333900452 Training d_loss: 1.3172 Training g_loss: 0.6597 Training q_loss: 97.9271 Explore P: 0.3602\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 205 Total reward: 199.0 Average reward fake: 0.5182390809059143 Average reward real: 0.5381057262420654 Training d_loss: 1.3539 Training g_loss: 0.6549 Training q_loss: 214.0844 Explore P: 0.3533\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 206 Total reward: 192.0 Average reward fake: 0.48320841789245605 Average reward real: 0.48751920461654663 Training d_loss: 1.3817 Training g_loss: 0.7338 Training q_loss: 66.2781 Explore P: 0.3468\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 207 Total reward: 199.0 Average reward fake: 0.5407321453094482 Average reward real: 0.49951180815696716 Training d_loss: 1.4954 Training g_loss: 0.6451 Training q_loss: 89.4391 Explore P: 0.3402\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 208 Total reward: 195.0 Average reward fake: 0.575671911239624 Average reward real: 0.5002851486206055 Training d_loss: 1.5719 Training g_loss: 0.5840 Training q_loss: 131.9282 Explore P: 0.3338\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 209 Total reward: 199.0 Average reward fake: 0.49126142263412476 Average reward real: 0.5026203393936157 Training d_loss: 1.3671 Training g_loss: 0.6975 Training q_loss: 61.6298 Explore P: 0.3274\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 210 Total reward: 182.0 Average reward fake: 0.4317895770072937 Average reward real: 0.5445783138275146 Training d_loss: 1.1841 Training g_loss: 0.8678 Training q_loss: 122.0789 Explore P: 0.3217\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 211 Total reward: 171.0 Average reward fake: 0.49183520674705505 Average reward real: 0.4891030192375183 Training d_loss: 1.3966 Training g_loss: 0.7165 Training q_loss: 64.1975 Explore P: 0.3164\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 212 Total reward: 195.0 Average reward fake: 0.5562946200370789 Average reward real: 0.5320450067520142 Training d_loss: 1.4497 Training g_loss: 0.6132 Training q_loss: 339.7006 Explore P: 0.3105\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 213 Total reward: 47.0 Average reward fake: 0.554375171661377 Average reward real: 0.5578139424324036 Training d_loss: 1.3931 Training g_loss: 0.5916 Training q_loss: 51.0532 Explore P: 0.3091\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 214 Total reward: 199.0 Average reward fake: 0.4994475841522217 Average reward real: 0.48398885130882263 Training d_loss: 1.4211 Training g_loss: 0.6852 Training q_loss: 159.9217 Explore P: 0.3032\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 215 Total reward: 199.0 Average reward fake: 0.4952738881111145 Average reward real: 0.5394571423530579 Training d_loss: 1.3093 Training g_loss: 0.7173 Training q_loss: 140.3493 Explore P: 0.2974\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 216 Total reward: 172.0 Average reward fake: 0.4726954996585846 Average reward real: 0.5340914130210876 Training d_loss: 1.2703 Training g_loss: 0.7551 Training q_loss: 99.2722 Explore P: 0.2925\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 217 Total reward: 181.0 Average reward fake: 0.503504753112793 Average reward real: 0.5075565576553345 Training d_loss: 1.3812 Training g_loss: 0.6889 Training q_loss: 65.2177 Explore P: 0.2874\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 218 Total reward: 194.0 Average reward fake: 0.48342499136924744 Average reward real: 0.5117071270942688 Training d_loss: 1.3361 Training g_loss: 0.7155 Training q_loss: 69.3427 Explore P: 0.2821\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 219 Total reward: 199.0 Average reward fake: 0.49102407693862915 Average reward real: 0.515713095664978 Training d_loss: 1.3443 Training g_loss: 0.7041 Training q_loss: 85.1515 Explore P: 0.2767\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 220 Total reward: 199.0 Average reward fake: 0.47214967012405396 Average reward real: 0.4799862504005432 Training d_loss: 1.3751 Training g_loss: 0.7447 Training q_loss: 28.3929 Explore P: 0.2715\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 221 Total reward: 199.0 Average reward fake: 0.6223286390304565 Average reward real: 0.4986100196838379 Training d_loss: 1.6868 Training g_loss: 0.4915 Training q_loss: 1750.3867 Explore P: 0.2663\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 222 Total reward: 199.0 Average reward fake: 0.5157618522644043 Average reward real: 0.431337833404541 Training d_loss: 1.5814 Training g_loss: 0.7328 Training q_loss: 40.7323 Explore P: 0.2613\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 223 Total reward: 199.0 Average reward fake: 0.39719265699386597 Average reward real: 0.5664493441581726 Training d_loss: 1.0771 Training g_loss: 0.9348 Training q_loss: 28.0862 Explore P: 0.2563\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 224 Total reward: 199.0 Average reward fake: 0.4971899390220642 Average reward real: 0.5330482721328735 Training d_loss: 1.3256 Training g_loss: 0.7274 Training q_loss: 9.1252 Explore P: 0.2515\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 225 Total reward: 199.0 Average reward fake: 0.506529688835144 Average reward real: 0.5466060638427734 Training d_loss: 1.3114 Training g_loss: 0.6876 Training q_loss: 32.1856 Explore P: 0.2467\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 226 Total reward: 199.0 Average reward fake: 0.45867133140563965 Average reward real: 0.4792085587978363 Training d_loss: 1.3496 Training g_loss: 0.7882 Training q_loss: 33.4426 Explore P: 0.2421\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 227 Total reward: 199.0 Average reward fake: 0.5084983110427856 Average reward real: 0.5229886770248413 Training d_loss: 1.3592 Training g_loss: 0.6821 Training q_loss: 14.8365 Explore P: 0.2375\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 228 Total reward: 199.0 Average reward fake: 0.5037803053855896 Average reward real: 0.5152658820152283 Training d_loss: 1.3723 Training g_loss: 0.6878 Training q_loss: 42.5638 Explore P: 0.2330\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 229 Total reward: 199.0 Average reward fake: 0.5083077549934387 Average reward real: 0.5006250143051147 Training d_loss: 1.4035 Training g_loss: 0.6930 Training q_loss: 26.8257 Explore P: 0.2286\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 230 Total reward: 199.0 Average reward fake: 0.42524003982543945 Average reward real: 0.5171224474906921 Training d_loss: 1.2245 Training g_loss: 0.8496 Training q_loss: 13.0246 Explore P: 0.2243\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 231 Total reward: 199.0 Average reward fake: 0.471426397562027 Average reward real: 0.5667468309402466 Training d_loss: 1.2073 Training g_loss: 0.7662 Training q_loss: 29.7605 Explore P: 0.2201\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 232 Total reward: 199.0 Average reward fake: 0.4653414189815521 Average reward real: 0.4863413870334625 Training d_loss: 1.3494 Training g_loss: 0.7694 Training q_loss: 419.6380 Explore P: 0.2159\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 233 Total reward: 199.0 Average reward fake: 0.48346996307373047 Average reward real: 0.5347434282302856 Training d_loss: 1.3006 Training g_loss: 0.7322 Training q_loss: 16.3952 Explore P: 0.2119\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 234 Total reward: 199.0 Average reward fake: 0.48777884244918823 Average reward real: 0.5146955251693726 Training d_loss: 1.3416 Training g_loss: 0.7276 Training q_loss: 51.4055 Explore P: 0.2079\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 235 Total reward: 199.0 Average reward fake: 0.5119046568870544 Average reward real: 0.4986460208892822 Training d_loss: 1.4143 Training g_loss: 0.6658 Training q_loss: 19.5015 Explore P: 0.2040\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 236 Total reward: 180.0 Average reward fake: 0.5311059355735779 Average reward real: 0.4310099184513092 Training d_loss: 1.6044 Training g_loss: 0.6523 Training q_loss: 13.3895 Explore P: 0.2005\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 237 Total reward: 199.0 Average reward fake: 0.4892582893371582 Average reward real: 0.5449902415275574 Training d_loss: 1.2836 Training g_loss: 0.7128 Training q_loss: 7.6131 Explore P: 0.1968\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 238 Total reward: 199.0 Average reward fake: 0.4749617576599121 Average reward real: 0.5380395650863647 Training d_loss: 1.2662 Training g_loss: 0.7713 Training q_loss: 36.7762 Explore P: 0.1931\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 239 Total reward: 199.0 Average reward fake: 0.45406174659729004 Average reward real: 0.4627777636051178 Training d_loss: 1.4193 Training g_loss: 0.8160 Training q_loss: 9.6636 Explore P: 0.1895\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 240 Total reward: 199.0 Average reward fake: 0.5155462026596069 Average reward real: 0.5204529762268066 Training d_loss: 1.3792 Training g_loss: 0.6697 Training q_loss: 4.6389 Explore P: 0.1860\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 241 Total reward: 199.0 Average reward fake: 0.47395166754722595 Average reward real: 0.49849772453308105 Training d_loss: 1.3386 Training g_loss: 0.7462 Training q_loss: 385.0717 Explore P: 0.1825\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 242 Total reward: 199.0 Average reward fake: 0.4754404127597809 Average reward real: 0.538528561592102 Training d_loss: 1.2668 Training g_loss: 0.7474 Training q_loss: 7.9611 Explore P: 0.1791\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 243 Total reward: 199.0 Average reward fake: 0.5172421336174011 Average reward real: 0.45894771814346313 Training d_loss: 1.5093 Training g_loss: 0.6621 Training q_loss: 13.3467 Explore P: 0.1758\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 244 Total reward: 199.0 Average reward fake: 0.5342408418655396 Average reward real: 0.5799914002418518 Training d_loss: 1.3105 Training g_loss: 0.6384 Training q_loss: 8.3273 Explore P: 0.1725\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 245 Total reward: 199.0 Average reward fake: 0.471856027841568 Average reward real: 0.48347902297973633 Training d_loss: 1.3695 Training g_loss: 0.7562 Training q_loss: 10.2275 Explore P: 0.1693\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 246 Total reward: 199.0 Average reward fake: 0.5110685229301453 Average reward real: 0.5074514150619507 Training d_loss: 1.3966 Training g_loss: 0.6772 Training q_loss: 5.2199 Explore P: 0.1662\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 247 Total reward: 199.0 Average reward fake: 0.5379027128219604 Average reward real: 0.5101209878921509 Training d_loss: 1.4453 Training g_loss: 0.6212 Training q_loss: 10.2584 Explore P: 0.1631\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 248 Total reward: 199.0 Average reward fake: 0.4920521378517151 Average reward real: 0.4356435239315033 Training d_loss: 1.5126 Training g_loss: 0.7226 Training q_loss: 10.4667 Explore P: 0.1601\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 249 Total reward: 199.0 Average reward fake: 0.48972344398498535 Average reward real: 0.5582342147827148 Training d_loss: 1.2758 Training g_loss: 0.7174 Training q_loss: 4.2434 Explore P: 0.1571\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 250 Total reward: 199.0 Average reward fake: 0.4845151901245117 Average reward real: 0.41187381744384766 Training d_loss: 1.5519 Training g_loss: 0.7344 Training q_loss: 4.7021 Explore P: 0.1542\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 251 Total reward: 199.0 Average reward fake: 0.5978191494941711 Average reward real: 0.4805842936038971 Training d_loss: 1.6602 Training g_loss: 0.5262 Training q_loss: 7.9992 Explore P: 0.1514\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 252 Total reward: 187.0 Average reward fake: 0.3898676335811615 Average reward real: 0.5159078240394592 Training d_loss: 1.1631 Training g_loss: 0.9450 Training q_loss: 7.7158 Explore P: 0.1488\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 253 Total reward: 199.0 Average reward fake: 0.499737411737442 Average reward real: 0.49107295274734497 Training d_loss: 1.4111 Training g_loss: 0.6904 Training q_loss: 2.2748 Explore P: 0.1460\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 254 Total reward: 199.0 Average reward fake: 0.4805217683315277 Average reward real: 0.4887158274650574 Training d_loss: 1.3713 Training g_loss: 0.7376 Training q_loss: 5.2408 Explore P: 0.1433\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 255 Total reward: 199.0 Average reward fake: 0.5185273289680481 Average reward real: 0.5147140026092529 Training d_loss: 1.3970 Training g_loss: 0.6639 Training q_loss: 2.2741 Explore P: 0.1407\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 256 Total reward: 199.0 Average reward fake: 0.48235392570495605 Average reward real: 0.4848858416080475 Training d_loss: 1.3829 Training g_loss: 0.7383 Training q_loss: 1.3400 Explore P: 0.1381\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 257 Total reward: 158.0 Average reward fake: 0.5159718990325928 Average reward real: 0.5188091993331909 Training d_loss: 1.3826 Training g_loss: 0.6614 Training q_loss: 3.7972 Explore P: 0.1361\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 258 Total reward: 199.0 Average reward fake: 0.4846929907798767 Average reward real: 0.4817281663417816 Training d_loss: 1.3939 Training g_loss: 0.7249 Training q_loss: 3.5147 Explore P: 0.1336\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 259 Total reward: 199.0 Average reward fake: 0.5006293058395386 Average reward real: 0.5174026489257812 Training d_loss: 1.3536 Training g_loss: 0.6959 Training q_loss: 4.5593 Explore P: 0.1312\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 260 Total reward: 199.0 Average reward fake: 0.5076476335525513 Average reward real: 0.493724524974823 Training d_loss: 1.4154 Training g_loss: 0.6782 Training q_loss: 3.4121 Explore P: 0.1288\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 261 Total reward: 199.0 Average reward fake: 0.5203791856765747 Average reward real: 0.5201929807662964 Training d_loss: 1.3884 Training g_loss: 0.6654 Training q_loss: 1.5408 Explore P: 0.1265\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 262 Total reward: 199.0 Average reward fake: 0.4837891161441803 Average reward real: 0.47557157278060913 Training d_loss: 1.4061 Training g_loss: 0.7173 Training q_loss: 3.4411 Explore P: 0.1242\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 263 Total reward: 199.0 Average reward fake: 0.4607722759246826 Average reward real: 0.45126160979270935 Training d_loss: 1.4219 Training g_loss: 0.8130 Training q_loss: 6.0661 Explore P: 0.1219\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 264 Total reward: 180.0 Average reward fake: 0.5068620443344116 Average reward real: 0.46816515922546387 Training d_loss: 1.4738 Training g_loss: 0.6785 Training q_loss: 2.8518 Explore P: 0.1199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 265 Total reward: 199.0 Average reward fake: 0.5265691876411438 Average reward real: 0.5311838984489441 Training d_loss: 1.3809 Training g_loss: 0.6474 Training q_loss: 19.4921 Explore P: 0.1178\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 266 Total reward: 36.0 Average reward fake: 0.4894508421421051 Average reward real: 0.5024110078811646 Training d_loss: 1.3621 Training g_loss: 0.7082 Training q_loss: 209.2878 Explore P: 0.1174\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 267 Total reward: 11.0 Average reward fake: 0.49108609557151794 Average reward real: 0.4890538156032562 Training d_loss: 1.3928 Training g_loss: 0.7147 Training q_loss: 961.8462 Explore P: 0.1173\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 268 Total reward: 13.0 Average reward fake: 0.4932493269443512 Average reward real: 0.49170637130737305 Training d_loss: 1.3923 Training g_loss: 0.7086 Training q_loss: 2619.4187 Explore P: 0.1171\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 269 Total reward: 10.0 Average reward fake: 0.5016671419143677 Average reward real: 0.4683294892311096 Training d_loss: 1.4606 Training g_loss: 0.6917 Training q_loss: 4981.3022 Explore P: 0.1170\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 270 Total reward: 11.0 Average reward fake: 0.5024110078811646 Average reward real: 0.4817278981208801 Training d_loss: 1.4317 Training g_loss: 0.6882 Training q_loss: 5796.7021 Explore P: 0.1169\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 271 Total reward: 10.0 Average reward fake: 0.5007144212722778 Average reward real: 0.46468624472618103 Training d_loss: 1.4613 Training g_loss: 0.6939 Training q_loss: 10490.3125 Explore P: 0.1168\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 272 Total reward: 12.0 Average reward fake: 0.5022628903388977 Average reward real: 0.4477185308933258 Training d_loss: 1.5033 Training g_loss: 0.6933 Training q_loss: 14215.9004 Explore P: 0.1167\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 273 Total reward: 10.0 Average reward fake: 0.5028152465820312 Average reward real: 0.46117687225341797 Training d_loss: 1.4739 Training g_loss: 0.6931 Training q_loss: 13062.2266 Explore P: 0.1166\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 274 Total reward: 11.0 Average reward fake: 0.4894380569458008 Average reward real: 0.4637354910373688 Training d_loss: 1.4409 Training g_loss: 0.7234 Training q_loss: 6955.0869 Explore P: 0.1164\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 275 Total reward: 8.0 Average reward fake: 0.4669927656650543 Average reward real: 0.46476539969444275 Training d_loss: 1.3956 Training g_loss: 0.7701 Training q_loss: 8674.4551 Explore P: 0.1164\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 276 Total reward: 8.0 Average reward fake: 0.462742418050766 Average reward real: 0.4690280854701996 Training d_loss: 1.3784 Training g_loss: 0.7782 Training q_loss: 6472.9731 Explore P: 0.1163\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 277 Total reward: 10.0 Average reward fake: 0.46855631470680237 Average reward real: 0.46763983368873596 Training d_loss: 1.3930 Training g_loss: 0.7646 Training q_loss: 13230.1514 Explore P: 0.1162\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 278 Total reward: 10.0 Average reward fake: 0.4491691589355469 Average reward real: 0.4810413420200348 Training d_loss: 1.3283 Training g_loss: 0.8033 Training q_loss: 11367.2012 Explore P: 0.1161\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 279 Total reward: 9.0 Average reward fake: 0.4274206757545471 Average reward real: 0.47859376668930054 Training d_loss: 1.2965 Training g_loss: 0.8439 Training q_loss: 9428.1025 Explore P: 0.1160\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 280 Total reward: 8.0 Average reward fake: 0.453524649143219 Average reward real: 0.4863601326942444 Training d_loss: 1.3330 Training g_loss: 0.8128 Training q_loss: 12366.5967 Explore P: 0.1159\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 281 Total reward: 9.0 Average reward fake: 0.4604232907295227 Average reward real: 0.4964601397514343 Training d_loss: 1.3207 Training g_loss: 0.7580 Training q_loss: 10920.8223 Explore P: 0.1158\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 282 Total reward: 11.0 Average reward fake: 0.465579092502594 Average reward real: 0.4744601249694824 Training d_loss: 1.3835 Training g_loss: 0.7472 Training q_loss: 3874494.5000 Explore P: 0.1157\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 283 Total reward: 9.0 Average reward fake: 0.4817584455013275 Average reward real: 0.5557069778442383 Training d_loss: 1.2592 Training g_loss: 0.7621 Training q_loss: 4504.3154 Explore P: 0.1156\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 284 Total reward: 12.0 Average reward fake: 0.48827439546585083 Average reward real: 0.4898911416530609 Training d_loss: 1.3894 Training g_loss: 0.7366 Training q_loss: 4288.5068 Explore P: 0.1154\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 285 Total reward: 11.0 Average reward fake: 0.4718826711177826 Average reward real: 0.5179444551467896 Training d_loss: 1.2980 Training g_loss: 0.7514 Training q_loss: 5559.9062 Explore P: 0.1153\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 286 Total reward: 8.0 Average reward fake: 0.4813062250614166 Average reward real: 0.49784860014915466 Training d_loss: 1.3645 Training g_loss: 0.7172 Training q_loss: 5416.6475 Explore P: 0.1152\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 287 Total reward: 11.0 Average reward fake: 0.5083435773849487 Average reward real: 0.4825640618801117 Training d_loss: 1.4581 Training g_loss: 0.6771 Training q_loss: 6935.5127 Explore P: 0.1151\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 288 Total reward: 9.0 Average reward fake: 0.584667980670929 Average reward real: 0.4670419692993164 Training d_loss: 1.6437 Training g_loss: 0.5748 Training q_loss: 5334.4268 Explore P: 0.1150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 289 Total reward: 10.0 Average reward fake: 0.6942683458328247 Average reward real: 0.5660728216171265 Training d_loss: 1.7548 Training g_loss: 0.3664 Training q_loss: 4299.8774 Explore P: 0.1149\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 290 Total reward: 10.0 Average reward fake: 0.6111582517623901 Average reward real: 0.6576863527297974 Training d_loss: 1.3638 Training g_loss: 0.5120 Training q_loss: 1632.7798 Explore P: 0.1148\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 291 Total reward: 12.0 Average reward fake: 0.527593731880188 Average reward real: 0.6919195652008057 Training d_loss: 1.1188 Training g_loss: 0.6588 Training q_loss: 2949.2251 Explore P: 0.1147\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 292 Total reward: 14.0 Average reward fake: 0.48547640442848206 Average reward real: 0.6013323664665222 Training d_loss: 1.1757 Training g_loss: 0.7477 Training q_loss: 3212.1108 Explore P: 0.1146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 293 Total reward: 9.0 Average reward fake: 0.47826260328292847 Average reward real: 0.5746487379074097 Training d_loss: 1.2099 Training g_loss: 0.7527 Training q_loss: 2191.2053 Explore P: 0.1145\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 294 Total reward: 8.0 Average reward fake: 0.4652804434299469 Average reward real: 0.5195827484130859 Training d_loss: 1.2880 Training g_loss: 0.7838 Training q_loss: 2998.5542 Explore P: 0.1144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 295 Total reward: 9.0 Average reward fake: 0.5000787973403931 Average reward real: 0.45645982027053833 Training d_loss: 1.4799 Training g_loss: 0.7069 Training q_loss: 1827.2961 Explore P: 0.1143\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 296 Total reward: 10.0 Average reward fake: 0.5444787740707397 Average reward real: 0.4618298411369324 Training d_loss: 1.5623 Training g_loss: 0.6309 Training q_loss: 3468.5933 Explore P: 0.1142\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 297 Total reward: 11.0 Average reward fake: 0.5117809176445007 Average reward real: 0.4002419114112854 Training d_loss: 1.6403 Training g_loss: 0.6930 Training q_loss: 4045.5286 Explore P: 0.1141\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 298 Total reward: 12.0 Average reward fake: 0.43225088715553284 Average reward real: 0.4111153483390808 Training d_loss: 1.4562 Training g_loss: 0.8584 Training q_loss: 940.3224 Explore P: 0.1139\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 299 Total reward: 13.0 Average reward fake: 0.3899877667427063 Average reward real: 0.42829975485801697 Training d_loss: 1.3466 Training g_loss: 0.9534 Training q_loss: 1741.9310 Explore P: 0.1138\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 300 Total reward: 11.0 Average reward fake: 0.4106937348842621 Average reward real: 0.5022231936454773 Training d_loss: 1.2233 Training g_loss: 0.9165 Training q_loss: 1507.7800 Explore P: 0.1137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 301 Total reward: 8.0 Average reward fake: 0.42322248220443726 Average reward real: 0.5204610228538513 Training d_loss: 1.2069 Training g_loss: 0.8881 Training q_loss: 1179.1135 Explore P: 0.1136\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 302 Total reward: 11.0 Average reward fake: 0.5239132642745972 Average reward real: 0.507365345954895 Training d_loss: 1.4519 Training g_loss: 0.6607 Training q_loss: 1357.3450 Explore P: 0.1135\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 303 Total reward: 11.0 Average reward fake: 0.5020383596420288 Average reward real: 0.4678545892238617 Training d_loss: 1.4792 Training g_loss: 0.6820 Training q_loss: 1647.0300 Explore P: 0.1134\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 304 Total reward: 11.0 Average reward fake: 0.5458940267562866 Average reward real: 0.5117923021316528 Training d_loss: 1.4606 Training g_loss: 0.6063 Training q_loss: 1678.9866 Explore P: 0.1133\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 305 Total reward: 9.0 Average reward fake: 0.5547767877578735 Average reward real: 0.500076174736023 Training d_loss: 1.5036 Training g_loss: 0.5962 Training q_loss: 3341.4595 Explore P: 0.1132\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 306 Total reward: 10.0 Average reward fake: 0.5421762466430664 Average reward real: 0.5161098837852478 Training d_loss: 1.4511 Training g_loss: 0.6140 Training q_loss: 443.1097 Explore P: 0.1131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 307 Total reward: 10.0 Average reward fake: 0.5497192144393921 Average reward real: 0.4808254837989807 Training d_loss: 1.5346 Training g_loss: 0.5970 Training q_loss: 595.0687 Explore P: 0.1130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 308 Total reward: 12.0 Average reward fake: 0.5588247179985046 Average reward real: 0.5016326308250427 Training d_loss: 1.5138 Training g_loss: 0.5896 Training q_loss: 363.5692 Explore P: 0.1128\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 309 Total reward: 11.0 Average reward fake: 0.5645285248756409 Average reward real: 0.5217869281768799 Training d_loss: 1.4832 Training g_loss: 0.5714 Training q_loss: 115.7373 Explore P: 0.1127\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 310 Total reward: 8.0 Average reward fake: 0.5660533905029297 Average reward real: 0.5261352062225342 Training d_loss: 1.4780 Training g_loss: 0.5748 Training q_loss: 160.9093 Explore P: 0.1126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 311 Total reward: 11.0 Average reward fake: 0.5439378023147583 Average reward real: 0.5691675543785095 Training d_loss: 1.3487 Training g_loss: 0.6071 Training q_loss: 57.9685 Explore P: 0.1125\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 312 Total reward: 12.0 Average reward fake: 0.5065275430679321 Average reward real: 0.5752305388450623 Training d_loss: 1.2599 Training g_loss: 0.6871 Training q_loss: 213.1928 Explore P: 0.1124\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 313 Total reward: 13.0 Average reward fake: 0.4986132085323334 Average reward real: 0.6020295023918152 Training d_loss: 1.1984 Training g_loss: 0.7071 Training q_loss: 119.5872 Explore P: 0.1123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 314 Total reward: 8.0 Average reward fake: 0.48461824655532837 Average reward real: 0.5600842237472534 Training d_loss: 1.2482 Training g_loss: 0.7324 Training q_loss: 636.0975 Explore P: 0.1122\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 315 Total reward: 11.0 Average reward fake: 0.49330392479896545 Average reward real: 0.5974491834640503 Training d_loss: 1.1984 Training g_loss: 0.7188 Training q_loss: 676.1245 Explore P: 0.1121\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 316 Total reward: 12.0 Average reward fake: 0.48575258255004883 Average reward real: 0.5215490460395813 Training d_loss: 1.3280 Training g_loss: 0.7221 Training q_loss: 2085.1953 Explore P: 0.1120\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 317 Total reward: 28.0 Average reward fake: 0.5374978184700012 Average reward real: 0.48291176557540894 Training d_loss: 1.5104 Training g_loss: 0.6286 Training q_loss: 1485641.7500 Explore P: 0.1117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 318 Total reward: 11.0 Average reward fake: 0.5283311605453491 Average reward real: 0.4057955741882324 Training d_loss: 1.6676 Training g_loss: 0.6423 Training q_loss: 965.7933 Explore P: 0.1116\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 319 Total reward: 12.0 Average reward fake: 0.5051537752151489 Average reward real: 0.3629092574119568 Training d_loss: 1.7206 Training g_loss: 0.6982 Training q_loss: 524.3091 Explore P: 0.1114\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 320 Total reward: 10.0 Average reward fake: 0.4747433066368103 Average reward real: 0.38323265314102173 Training d_loss: 1.6056 Training g_loss: 0.7652 Training q_loss: 957.8552 Explore P: 0.1113\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 321 Total reward: 10.0 Average reward fake: 0.42158907651901245 Average reward real: 0.3992372751235962 Training d_loss: 1.4665 Training g_loss: 0.8781 Training q_loss: 3761.3765 Explore P: 0.1112\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 322 Total reward: 15.0 Average reward fake: 0.4274655282497406 Average reward real: 0.45063668489456177 Training d_loss: 1.3564 Training g_loss: 0.8586 Training q_loss: 533.3578 Explore P: 0.1111\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 323 Total reward: 10.0 Average reward fake: 0.4031757712364197 Average reward real: 0.5148060917854309 Training d_loss: 1.1824 Training g_loss: 0.9246 Training q_loss: 489.7685 Explore P: 0.1110\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 324 Total reward: 12.0 Average reward fake: 0.35025906562805176 Average reward real: 0.5660988688468933 Training d_loss: 1.0057 Training g_loss: 1.0802 Training q_loss: 773.5524 Explore P: 0.1109\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 325 Total reward: 14.0 Average reward fake: 0.3364222049713135 Average reward real: 0.4678207337856293 Training d_loss: 1.1892 Training g_loss: 1.0782 Training q_loss: 642.8771 Explore P: 0.1107\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 326 Total reward: 10.0 Average reward fake: 0.4048634171485901 Average reward real: 0.5256363153457642 Training d_loss: 1.1869 Training g_loss: 0.9802 Training q_loss: 225.2742 Explore P: 0.1106\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 327 Total reward: 11.0 Average reward fake: 0.5605872869491577 Average reward real: 0.46457237005233765 Training d_loss: 1.6504 Training g_loss: 0.6156 Training q_loss: 417.1066 Explore P: 0.1105\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 328 Total reward: 12.0 Average reward fake: 0.5899305939674377 Average reward real: 0.4689321517944336 Training d_loss: 1.6593 Training g_loss: 0.5415 Training q_loss: 432.4881 Explore P: 0.1104\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 329 Total reward: 10.0 Average reward fake: 0.6351738572120667 Average reward real: 0.5505694150924683 Training d_loss: 1.6078 Training g_loss: 0.4855 Training q_loss: 597.4160 Explore P: 0.1103\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 330 Total reward: 8.0 Average reward fake: 0.5524862408638 Average reward real: 0.600016713142395 Training d_loss: 1.3152 Training g_loss: 0.5902 Training q_loss: 767.9075 Explore P: 0.1102\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 331 Total reward: 10.0 Average reward fake: 0.540132462978363 Average reward real: 0.6811464428901672 Training d_loss: 1.1622 Training g_loss: 0.6444 Training q_loss: 893.0206 Explore P: 0.1101\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 332 Total reward: 10.0 Average reward fake: 0.44755035638809204 Average reward real: 0.5906713008880615 Training d_loss: 1.1227 Training g_loss: 0.8177 Training q_loss: 3443.9675 Explore P: 0.1100\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 333 Total reward: 11.0 Average reward fake: 0.4980897903442383 Average reward real: 0.6058141589164734 Training d_loss: 1.1941 Training g_loss: 0.7323 Training q_loss: 2717.7588 Explore P: 0.1099\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 334 Total reward: 8.0 Average reward fake: 0.48924440145492554 Average reward real: 0.5283142328262329 Training d_loss: 1.3274 Training g_loss: 0.7326 Training q_loss: 2708.8350 Explore P: 0.1098\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 335 Total reward: 11.0 Average reward fake: 0.5422278046607971 Average reward real: 0.44015854597091675 Training d_loss: 1.6240 Training g_loss: 0.6147 Training q_loss: 1057.4828 Explore P: 0.1097\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 336 Total reward: 11.0 Average reward fake: 0.5420902371406555 Average reward real: 0.4615626335144043 Training d_loss: 1.5721 Training g_loss: 0.6251 Training q_loss: 1427.6252 Explore P: 0.1096\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 337 Total reward: 9.0 Average reward fake: 0.5525506734848022 Average reward real: 0.4451991021633148 Training d_loss: 1.6160 Training g_loss: 0.6166 Training q_loss: 1060608.8750 Explore P: 0.1095\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 338 Total reward: 11.0 Average reward fake: 0.5155784487724304 Average reward real: 0.43727660179138184 Training d_loss: 1.5569 Training g_loss: 0.6649 Training q_loss: 1301.7051 Explore P: 0.1094\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 339 Total reward: 10.0 Average reward fake: 0.4945589601993561 Average reward real: 0.4531564712524414 Training d_loss: 1.4748 Training g_loss: 0.7256 Training q_loss: 1393.0720 Explore P: 0.1093\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 340 Total reward: 10.0 Average reward fake: 0.4904419481754303 Average reward real: 0.42642730474472046 Training d_loss: 1.5326 Training g_loss: 0.7191 Training q_loss: 973.3245 Explore P: 0.1092\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 341 Total reward: 10.0 Average reward fake: 0.4548565447330475 Average reward real: 0.4651404321193695 Training d_loss: 1.3723 Training g_loss: 0.8050 Training q_loss: 1223346.3750 Explore P: 0.1091\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 342 Total reward: 10.0 Average reward fake: 0.43536195158958435 Average reward real: 0.4707302153110504 Training d_loss: 1.3251 Training g_loss: 0.8279 Training q_loss: 1482.2758 Explore P: 0.1090\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 343 Total reward: 9.0 Average reward fake: 0.4397026002407074 Average reward real: 0.4787430763244629 Training d_loss: 1.3181 Training g_loss: 0.8258 Training q_loss: 983.2455 Explore P: 0.1089\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 344 Total reward: 8.0 Average reward fake: 0.4465571343898773 Average reward real: 0.48361462354660034 Training d_loss: 1.3201 Training g_loss: 0.8009 Training q_loss: 1146.0837 Explore P: 0.1088\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 345 Total reward: 8.0 Average reward fake: 0.4497642517089844 Average reward real: 0.4910214841365814 Training d_loss: 1.3096 Training g_loss: 0.8067 Training q_loss: 615.8101 Explore P: 0.1088\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 346 Total reward: 8.0 Average reward fake: 0.4669567048549652 Average reward real: 0.4982174038887024 Training d_loss: 1.3286 Training g_loss: 0.7547 Training q_loss: 399.7961 Explore P: 0.1087\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 347 Total reward: 9.0 Average reward fake: 0.45732516050338745 Average reward real: 0.4987621307373047 Training d_loss: 1.3071 Training g_loss: 0.7921 Training q_loss: 366.5151 Explore P: 0.1086\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 348 Total reward: 9.0 Average reward fake: 0.4760797917842865 Average reward real: 0.4877474904060364 Training d_loss: 1.3680 Training g_loss: 0.7427 Training q_loss: 743.0965 Explore P: 0.1085\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 349 Total reward: 10.0 Average reward fake: 0.4970448911190033 Average reward real: 0.4963149130344391 Training d_loss: 1.3886 Training g_loss: 0.7064 Training q_loss: 1205.9973 Explore P: 0.1084\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 350 Total reward: 8.0 Average reward fake: 0.48135465383529663 Average reward real: 0.4804189205169678 Training d_loss: 1.3920 Training g_loss: 0.7327 Training q_loss: 2047.0186 Explore P: 0.1083\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 351 Total reward: 9.0 Average reward fake: 0.5045889616012573 Average reward real: 0.510482132434845 Training d_loss: 1.3768 Training g_loss: 0.6880 Training q_loss: 1551.8239 Explore P: 0.1082\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 352 Total reward: 10.0 Average reward fake: 0.5018292665481567 Average reward real: 0.4814876914024353 Training d_loss: 1.4333 Training g_loss: 0.6870 Training q_loss: 1073546.2500 Explore P: 0.1081\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 353 Total reward: 9.0 Average reward fake: 0.4964737892150879 Average reward real: 0.4955652356147766 Training d_loss: 1.3891 Training g_loss: 0.7060 Training q_loss: 1490.0422 Explore P: 0.1081\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 354 Total reward: 9.0 Average reward fake: 0.49838414788246155 Average reward real: 0.4870144724845886 Training d_loss: 1.4105 Training g_loss: 0.6921 Training q_loss: 1561.6051 Explore P: 0.1080\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 355 Total reward: 8.0 Average reward fake: 0.5170631408691406 Average reward real: 0.5160554051399231 Training d_loss: 1.3897 Training g_loss: 0.6642 Training q_loss: 626.1691 Explore P: 0.1079\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 356 Total reward: 11.0 Average reward fake: 0.5258320569992065 Average reward real: 0.49318069219589233 Training d_loss: 1.4551 Training g_loss: 0.6453 Training q_loss: 1348.0396 Explore P: 0.1078\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 357 Total reward: 9.0 Average reward fake: 0.5262426733970642 Average reward real: 0.48979559540748596 Training d_loss: 1.4613 Training g_loss: 0.6387 Training q_loss: 1015.3079 Explore P: 0.1077\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 358 Total reward: 10.0 Average reward fake: 0.5376819372177124 Average reward real: 0.5169948935508728 Training d_loss: 1.4313 Training g_loss: 0.6284 Training q_loss: 319.4501 Explore P: 0.1076\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 359 Total reward: 8.0 Average reward fake: 0.5172358751296997 Average reward real: 0.5042901039123535 Training d_loss: 1.4133 Training g_loss: 0.6613 Training q_loss: 397.3858 Explore P: 0.1075\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 360 Total reward: 11.0 Average reward fake: 0.5273608565330505 Average reward real: 0.5259119272232056 Training d_loss: 1.3925 Training g_loss: 0.6466 Training q_loss: 723.8336 Explore P: 0.1074\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 361 Total reward: 11.0 Average reward fake: 0.5323144197463989 Average reward real: 0.5231575965881348 Training d_loss: 1.4080 Training g_loss: 0.6284 Training q_loss: 590.0615 Explore P: 0.1073\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 362 Total reward: 9.0 Average reward fake: 0.540209174156189 Average reward real: 0.5166316032409668 Training d_loss: 1.4376 Training g_loss: 0.6214 Training q_loss: 551.9069 Explore P: 0.1072\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 363 Total reward: 9.0 Average reward fake: 0.5367909669876099 Average reward real: 0.5325230360031128 Training d_loss: 1.3998 Training g_loss: 0.6249 Training q_loss: 236.0329 Explore P: 0.1071\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 364 Total reward: 14.0 Average reward fake: 0.5162106156349182 Average reward real: 0.5324162244796753 Training d_loss: 1.3578 Training g_loss: 0.6699 Training q_loss: 1405.2423 Explore P: 0.1070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 365 Total reward: 11.0 Average reward fake: 0.5197634696960449 Average reward real: 0.5317336320877075 Training d_loss: 1.3655 Training g_loss: 0.6517 Training q_loss: 659.7889 Explore P: 0.1069\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 366 Total reward: 9.0 Average reward fake: 0.5050572752952576 Average reward real: 0.5215266346931458 Training d_loss: 1.3550 Training g_loss: 0.6874 Training q_loss: 147.3278 Explore P: 0.1068\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 367 Total reward: 10.0 Average reward fake: 0.5092705488204956 Average reward real: 0.5325756072998047 Training d_loss: 1.3427 Training g_loss: 0.6756 Training q_loss: 400.5669 Explore P: 0.1067\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 368 Total reward: 11.0 Average reward fake: 0.514445424079895 Average reward real: 0.5319850444793701 Training d_loss: 1.3576 Training g_loss: 0.6634 Training q_loss: 1262.9663 Explore P: 0.1066\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 369 Total reward: 11.0 Average reward fake: 0.5088344216346741 Average reward real: 0.4991297125816345 Training d_loss: 1.4074 Training g_loss: 0.6793 Training q_loss: 1071.3043 Explore P: 0.1065\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 370 Total reward: 8.0 Average reward fake: 0.5123868584632874 Average reward real: 0.5142837762832642 Training d_loss: 1.3842 Training g_loss: 0.6705 Training q_loss: 404.7772 Explore P: 0.1064\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 371 Total reward: 12.0 Average reward fake: 0.5166389346122742 Average reward real: 0.5087103247642517 Training d_loss: 1.4031 Training g_loss: 0.6695 Training q_loss: 256554.4531 Explore P: 0.1063\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 372 Total reward: 9.0 Average reward fake: 0.5149917006492615 Average reward real: 0.5128293037414551 Training d_loss: 1.3916 Training g_loss: 0.6624 Training q_loss: 777.6933 Explore P: 0.1062\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 373 Total reward: 13.0 Average reward fake: 0.4988802969455719 Average reward real: 0.5094989538192749 Training d_loss: 1.3655 Training g_loss: 0.6983 Training q_loss: 953.3159 Explore P: 0.1061\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 374 Total reward: 10.0 Average reward fake: 0.48695340752601624 Average reward real: 0.5159141421318054 Training d_loss: 1.3312 Training g_loss: 0.7305 Training q_loss: 367.2737 Explore P: 0.1060\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 375 Total reward: 10.0 Average reward fake: 0.48822730779647827 Average reward real: 0.5003302693367004 Training d_loss: 1.3631 Training g_loss: 0.7228 Training q_loss: 382.1745 Explore P: 0.1059\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 376 Total reward: 9.0 Average reward fake: 0.4883795380592346 Average reward real: 0.46627750992774963 Training d_loss: 1.4375 Training g_loss: 0.7208 Training q_loss: 774.9333 Explore P: 0.1058\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 377 Total reward: 8.0 Average reward fake: 0.4876226484775543 Average reward real: 0.48104017972946167 Training d_loss: 1.4057 Training g_loss: 0.7125 Training q_loss: 555564.8750 Explore P: 0.1057\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 378 Total reward: 10.0 Average reward fake: 0.4635067582130432 Average reward real: 0.47028249502182007 Training d_loss: 1.3784 Training g_loss: 0.7793 Training q_loss: 277.6199 Explore P: 0.1056\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 379 Total reward: 10.0 Average reward fake: 0.4836435914039612 Average reward real: 0.5047610998153687 Training d_loss: 1.3487 Training g_loss: 0.7336 Training q_loss: 1523.9218 Explore P: 0.1055\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 380 Total reward: 11.0 Average reward fake: 0.47366562485694885 Average reward real: 0.47469133138656616 Training d_loss: 1.3874 Training g_loss: 0.7423 Training q_loss: 511499.5938 Explore P: 0.1054\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 381 Total reward: 10.0 Average reward fake: 0.47777071595191956 Average reward real: 0.47804275155067444 Training d_loss: 1.3879 Training g_loss: 0.7412 Training q_loss: 333.1161 Explore P: 0.1053\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 382 Total reward: 12.0 Average reward fake: 0.4903936982154846 Average reward real: 0.4979321360588074 Training d_loss: 1.3720 Training g_loss: 0.7116 Training q_loss: 481.8106 Explore P: 0.1052\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 383 Total reward: 13.0 Average reward fake: 0.474402517080307 Average reward real: 0.4852816164493561 Training d_loss: 1.3663 Training g_loss: 0.7487 Training q_loss: 149.4031 Explore P: 0.1051\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 384 Total reward: 12.0 Average reward fake: 0.47308969497680664 Average reward real: 0.49536094069480896 Training d_loss: 1.3438 Training g_loss: 0.7543 Training q_loss: 1264.9119 Explore P: 0.1050\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 385 Total reward: 10.0 Average reward fake: 0.4667445719242096 Average reward real: 0.4966786801815033 Training d_loss: 1.3291 Training g_loss: 0.7627 Training q_loss: 320.8353 Explore P: 0.1049\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 386 Total reward: 14.0 Average reward fake: 0.46786874532699585 Average reward real: 0.4986419081687927 Training d_loss: 1.3273 Training g_loss: 0.7554 Training q_loss: 458.3035 Explore P: 0.1048\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 387 Total reward: 12.0 Average reward fake: 0.48167985677719116 Average reward real: 0.5123350024223328 Training d_loss: 1.3262 Training g_loss: 0.7289 Training q_loss: 34.1195 Explore P: 0.1046\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 388 Total reward: 13.0 Average reward fake: 0.48747366666793823 Average reward real: 0.5110746026039124 Training d_loss: 1.3403 Training g_loss: 0.7120 Training q_loss: 325.2272 Explore P: 0.1045\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 389 Total reward: 13.0 Average reward fake: 0.48150452971458435 Average reward real: 0.5111249685287476 Training d_loss: 1.3289 Training g_loss: 0.7315 Training q_loss: 359951.5625 Explore P: 0.1044\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 390 Total reward: 14.0 Average reward fake: 0.48128312826156616 Average reward real: 0.5066053867340088 Training d_loss: 1.3368 Training g_loss: 0.7333 Training q_loss: 1166.4430 Explore P: 0.1043\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 391 Total reward: 18.0 Average reward fake: 0.48936977982521057 Average reward real: 0.5122450590133667 Training d_loss: 1.3444 Training g_loss: 0.7201 Training q_loss: 432.3299 Explore P: 0.1041\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 392 Total reward: 20.0 Average reward fake: 0.47346797585487366 Average reward real: 0.4939757287502289 Training d_loss: 1.3488 Training g_loss: 0.7463 Training q_loss: 676.1523 Explore P: 0.1039\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 393 Total reward: 26.0 Average reward fake: 0.49778294563293457 Average reward real: 0.5313644409179688 Training d_loss: 1.3247 Training g_loss: 0.6999 Training q_loss: 3958.5054 Explore P: 0.1037\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 394 Total reward: 17.0 Average reward fake: 0.4902685284614563 Average reward real: 0.503437340259552 Training d_loss: 1.3608 Training g_loss: 0.7177 Training q_loss: 1577.6118 Explore P: 0.1035\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 395 Total reward: 65.0 Average reward fake: 0.5114818811416626 Average reward real: 0.5384165644645691 Training d_loss: 1.3385 Training g_loss: 0.6721 Training q_loss: 121282.5469 Explore P: 0.1029\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 396 Total reward: 69.0 Average reward fake: 0.48987069725990295 Average reward real: 0.5629863739013672 Training d_loss: 1.2592 Training g_loss: 0.7395 Training q_loss: 147825.6250 Explore P: 0.1023\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 397 Total reward: 36.0 Average reward fake: 0.4378621578216553 Average reward real: 0.479588121175766 Training d_loss: 1.3156 Training g_loss: 0.8336 Training q_loss: 59.2121 Explore P: 0.1019\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 398 Total reward: 113.0 Average reward fake: 0.5106974244117737 Average reward real: 0.5185275673866272 Training d_loss: 1.4086 Training g_loss: 0.6819 Training q_loss: 2836.8276 Explore P: 0.1009\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 399 Total reward: 173.0 Average reward fake: 0.4480856955051422 Average reward real: 0.5144031047821045 Training d_loss: 1.2766 Training g_loss: 0.8161 Training q_loss: 158.7320 Explore P: 0.0993\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 400 Total reward: 136.0 Average reward fake: 0.4347311854362488 Average reward real: 0.45556601881980896 Training d_loss: 1.3570 Training g_loss: 0.8402 Training q_loss: 6284.3760 Explore P: 0.0981\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 401 Total reward: 127.0 Average reward fake: 0.5635597705841064 Average reward real: 0.520919919013977 Training d_loss: 1.4830 Training g_loss: 0.5865 Training q_loss: 1262.6252 Explore P: 0.0970\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 402 Total reward: 112.0 Average reward fake: 0.5151032209396362 Average reward real: 0.4923720359802246 Training d_loss: 1.4416 Training g_loss: 0.6694 Training q_loss: 1714.7125 Explore P: 0.0960\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 403 Total reward: 98.0 Average reward fake: 0.497549831867218 Average reward real: 0.4372376799583435 Training d_loss: 1.5230 Training g_loss: 0.7072 Training q_loss: 274.6781 Explore P: 0.0952\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 404 Total reward: 199.0 Average reward fake: 0.47237342596054077 Average reward real: 0.43092337250709534 Training d_loss: 1.5341 Training g_loss: 0.7521 Training q_loss: 55.4413 Explore P: 0.0935\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 405 Total reward: 199.0 Average reward fake: 0.4760405123233795 Average reward real: 0.5056653022766113 Training d_loss: 1.3322 Training g_loss: 0.7417 Training q_loss: 1419.0824 Explore P: 0.0919\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 406 Total reward: 158.0 Average reward fake: 0.5012568235397339 Average reward real: 0.4963836669921875 Training d_loss: 1.3981 Training g_loss: 0.6950 Training q_loss: 1060.0806 Explore P: 0.0906\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 407 Total reward: 195.0 Average reward fake: 0.5027454495429993 Average reward real: 0.5299930572509766 Training d_loss: 1.3376 Training g_loss: 0.6977 Training q_loss: 1031.3376 Explore P: 0.0890\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 408 Total reward: 199.0 Average reward fake: 0.5044477581977844 Average reward real: 0.5145419239997864 Training d_loss: 1.3746 Training g_loss: 0.6856 Training q_loss: 824.6022 Explore P: 0.0875\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 409 Total reward: 172.0 Average reward fake: 0.48133546113967896 Average reward real: 0.5390876531600952 Training d_loss: 1.2771 Training g_loss: 0.7482 Training q_loss: 13677.2080 Explore P: 0.0862\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 410 Total reward: 174.0 Average reward fake: 0.4847453534603119 Average reward real: 0.48616495728492737 Training d_loss: 1.4283 Training g_loss: 0.7367 Training q_loss: 103.4641 Explore P: 0.0849\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 411 Total reward: 195.0 Average reward fake: 0.4451748728752136 Average reward real: 0.5123465061187744 Training d_loss: 1.2685 Training g_loss: 0.8259 Training q_loss: 33.7861 Explore P: 0.0834\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 412 Total reward: 199.0 Average reward fake: 0.4843454360961914 Average reward real: 0.43337708711624146 Training d_loss: 1.5019 Training g_loss: 0.7348 Training q_loss: 89.4796 Explore P: 0.0820\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 413 Total reward: 144.0 Average reward fake: 0.4647805690765381 Average reward real: 0.570787250995636 Training d_loss: 1.1866 Training g_loss: 0.7730 Training q_loss: 23.8495 Explore P: 0.0809\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 414 Total reward: 199.0 Average reward fake: 0.5059086680412292 Average reward real: 0.5031512975692749 Training d_loss: 1.3968 Training g_loss: 0.6712 Training q_loss: 18273.9102 Explore P: 0.0795\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 415 Total reward: 104.0 Average reward fake: 0.496337354183197 Average reward real: 0.4736470580101013 Training d_loss: 1.4338 Training g_loss: 0.7019 Training q_loss: 191.7003 Explore P: 0.0788\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 416 Total reward: 166.0 Average reward fake: 0.523528516292572 Average reward real: 0.4212793707847595 Training d_loss: 1.6078 Training g_loss: 0.6676 Training q_loss: 34424.7812 Explore P: 0.0777\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 417 Total reward: 157.0 Average reward fake: 0.49095749855041504 Average reward real: 0.6062934994697571 Training d_loss: 1.1766 Training g_loss: 0.7233 Training q_loss: 39.7852 Explore P: 0.0766\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 418 Total reward: 176.0 Average reward fake: 0.47427400946617126 Average reward real: 0.437716543674469 Training d_loss: 1.4693 Training g_loss: 0.7483 Training q_loss: 91.5824 Explore P: 0.0755\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 419 Total reward: 133.0 Average reward fake: 0.6017193794250488 Average reward real: 0.6306840777397156 Training d_loss: 1.3818 Training g_loss: 0.5195 Training q_loss: 142.0957 Explore P: 0.0746\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 420 Total reward: 114.0 Average reward fake: 0.4765738546848297 Average reward real: 0.4483048915863037 Training d_loss: 1.4502 Training g_loss: 0.7397 Training q_loss: 62.1904 Explore P: 0.0739\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 421 Total reward: 143.0 Average reward fake: 0.49537914991378784 Average reward real: 0.5111095905303955 Training d_loss: 1.3598 Training g_loss: 0.6993 Training q_loss: 724.9884 Explore P: 0.0730\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 422 Total reward: 120.0 Average reward fake: 0.5085767507553101 Average reward real: 0.5180079936981201 Training d_loss: 1.3700 Training g_loss: 0.6883 Training q_loss: 261.5355 Explore P: 0.0722\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 423 Total reward: 160.0 Average reward fake: 0.47249913215637207 Average reward real: 0.5035344362258911 Training d_loss: 1.3263 Training g_loss: 0.7487 Training q_loss: 101.0668 Explore P: 0.0712\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 424 Total reward: 146.0 Average reward fake: 0.5271214246749878 Average reward real: 0.5057844519615173 Training d_loss: 1.4312 Training g_loss: 0.6371 Training q_loss: 34.8890 Explore P: 0.0703\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 425 Total reward: 151.0 Average reward fake: 0.5085220336914062 Average reward real: 0.4695693850517273 Training d_loss: 1.4764 Training g_loss: 0.6831 Training q_loss: 126.0041 Explore P: 0.0694\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 426 Total reward: 199.0 Average reward fake: 0.47478312253952026 Average reward real: 0.485358864068985 Training d_loss: 1.3692 Training g_loss: 0.7386 Training q_loss: 138.3274 Explore P: 0.0683\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 427 Total reward: 151.0 Average reward fake: 0.5021457076072693 Average reward real: 0.5131552815437317 Training d_loss: 1.3649 Training g_loss: 0.6909 Training q_loss: 19.9356 Explore P: 0.0674\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 428 Total reward: 152.0 Average reward fake: 0.5052903890609741 Average reward real: 0.5478795766830444 Training d_loss: 1.3059 Training g_loss: 0.6890 Training q_loss: 50.6371 Explore P: 0.0665\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 429 Total reward: 132.0 Average reward fake: 0.4231685698032379 Average reward real: 0.49940961599349976 Training d_loss: 1.2452 Training g_loss: 0.8696 Training q_loss: 28.3790 Explore P: 0.0658\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 430 Total reward: 156.0 Average reward fake: 0.47953516244888306 Average reward real: 0.4728109836578369 Training d_loss: 1.4038 Training g_loss: 0.7462 Training q_loss: 208.8393 Explore P: 0.0649\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 431 Total reward: 182.0 Average reward fake: 0.524013340473175 Average reward real: 0.5342708230018616 Training d_loss: 1.3702 Training g_loss: 0.6455 Training q_loss: 16.7563 Explore P: 0.0639\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 432 Total reward: 151.0 Average reward fake: 0.49959295988082886 Average reward real: 0.5238596200942993 Training d_loss: 1.3405 Training g_loss: 0.6896 Training q_loss: 6.1387 Explore P: 0.0631\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 433 Total reward: 130.0 Average reward fake: 0.4739961624145508 Average reward real: 0.491058349609375 Training d_loss: 1.3564 Training g_loss: 0.7521 Training q_loss: 9.2097 Explore P: 0.0624\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 434 Total reward: 123.0 Average reward fake: 0.4927724003791809 Average reward real: 0.5266950726509094 Training d_loss: 1.3276 Training g_loss: 0.7041 Training q_loss: 45.9613 Explore P: 0.0618\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 435 Total reward: 117.0 Average reward fake: 0.6462634205818176 Average reward real: 0.3931732773780823 Training d_loss: 2.0488 Training g_loss: 0.5796 Training q_loss: 48.9284 Explore P: 0.0612\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 436 Total reward: 128.0 Average reward fake: 0.3349311649799347 Average reward real: 0.5923749208450317 Training d_loss: 0.9781 Training g_loss: 1.2137 Training q_loss: 234.2835 Explore P: 0.0605\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 437 Total reward: 199.0 Average reward fake: 0.5280517339706421 Average reward real: 0.5097582936286926 Training d_loss: 1.4282 Training g_loss: 0.6426 Training q_loss: 11.1281 Explore P: 0.0595\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 438 Total reward: 144.0 Average reward fake: 0.49909186363220215 Average reward real: 0.48946958780288696 Training d_loss: 1.4072 Training g_loss: 0.6974 Training q_loss: 20.9701 Explore P: 0.0588\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 439 Total reward: 128.0 Average reward fake: 0.4487817883491516 Average reward real: 0.4503510892391205 Training d_loss: 1.3935 Training g_loss: 0.7924 Training q_loss: 5.8633 Explore P: 0.0582\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 440 Total reward: 144.0 Average reward fake: 0.5032422542572021 Average reward real: 0.49507570266723633 Training d_loss: 1.4052 Training g_loss: 0.6802 Training q_loss: 4.6646 Explore P: 0.0575\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 441 Total reward: 163.0 Average reward fake: 0.5332292318344116 Average reward real: 0.554377019405365 Training d_loss: 1.3552 Training g_loss: 0.6386 Training q_loss: 43.5238 Explore P: 0.0568\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 442 Total reward: 199.0 Average reward fake: 0.5171521902084351 Average reward real: 0.5239952802658081 Training d_loss: 1.3780 Training g_loss: 0.6794 Training q_loss: 26.5007 Explore P: 0.0558\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 443 Total reward: 146.0 Average reward fake: 0.4969804883003235 Average reward real: 0.4894298017024994 Training d_loss: 1.4018 Training g_loss: 0.6958 Training q_loss: 2.9542 Explore P: 0.0552\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 444 Total reward: 184.0 Average reward fake: 0.47455650568008423 Average reward real: 0.5274932384490967 Training d_loss: 1.2875 Training g_loss: 0.7287 Training q_loss: 3.6832 Explore P: 0.0543\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 445 Total reward: 199.0 Average reward fake: 0.2413295954465866 Average reward real: 0.6895443201065063 Training d_loss: 0.6500 Training g_loss: 1.5653 Training q_loss: 1.7133 Explore P: 0.0535\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 446 Total reward: 124.0 Average reward fake: 0.5332861542701721 Average reward real: 0.6423189043998718 Training d_loss: 1.2082 Training g_loss: 0.6671 Training q_loss: 201.1143 Explore P: 0.0529\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 447 Total reward: 157.0 Average reward fake: 0.540851354598999 Average reward real: 0.5108440518379211 Training d_loss: 1.4975 Training g_loss: 0.6118 Training q_loss: 10.5277 Explore P: 0.0523\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 448 Total reward: 186.0 Average reward fake: 0.49556297063827515 Average reward real: 0.5667048096656799 Training d_loss: 1.2557 Training g_loss: 0.7140 Training q_loss: 6.3362 Explore P: 0.0515\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 449 Total reward: 183.0 Average reward fake: 0.5952722430229187 Average reward real: 0.5380462408065796 Training d_loss: 1.5574 Training g_loss: 0.5130 Training q_loss: 19.9773 Explore P: 0.0507\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 450 Total reward: 199.0 Average reward fake: 0.4936366081237793 Average reward real: 0.5597885847091675 Training d_loss: 1.2646 Training g_loss: 0.7116 Training q_loss: 7.2485 Explore P: 0.0499\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 451 Total reward: 161.0 Average reward fake: 0.3830316364765167 Average reward real: 0.4348958134651184 Training d_loss: 1.3166 Training g_loss: 0.9449 Training q_loss: 7.4960 Explore P: 0.0493\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 452 Total reward: 155.0 Average reward fake: 0.5461083650588989 Average reward real: 0.515063464641571 Training d_loss: 1.4581 Training g_loss: 0.6202 Training q_loss: 15.0048 Explore P: 0.0487\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 453 Total reward: 150.0 Average reward fake: 0.4687444269657135 Average reward real: 0.5576683878898621 Training d_loss: 1.2338 Training g_loss: 0.7813 Training q_loss: 3.6729 Explore P: 0.0481\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 454 Total reward: 189.0 Average reward fake: 0.47446292638778687 Average reward real: 0.5337475538253784 Training d_loss: 1.2742 Training g_loss: 0.7641 Training q_loss: 9.4143 Explore P: 0.0474\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 455 Total reward: 167.0 Average reward fake: 0.49243563413619995 Average reward real: 0.553670346736908 Training d_loss: 1.2856 Training g_loss: 0.7218 Training q_loss: 4.4929 Explore P: 0.0468\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 456 Total reward: 194.0 Average reward fake: 0.5106216669082642 Average reward real: 0.5237122774124146 Training d_loss: 1.3629 Training g_loss: 0.6877 Training q_loss: 28.4119 Explore P: 0.0461\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 457 Total reward: 69.0 Average reward fake: 0.48423299193382263 Average reward real: 0.6698276996612549 Training d_loss: 1.0700 Training g_loss: 0.7277 Training q_loss: 208.6613 Explore P: 0.0458\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 458 Total reward: 9.0 Average reward fake: 0.4244365096092224 Average reward real: 0.5126640796661377 Training d_loss: 1.2253 Training g_loss: 0.8334 Training q_loss: 412.9149 Explore P: 0.0458\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 459 Total reward: 8.0 Average reward fake: 0.47729507088661194 Average reward real: 0.5905236005783081 Training d_loss: 1.1806 Training g_loss: 0.7566 Training q_loss: 640.0353 Explore P: 0.0458\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 460 Total reward: 8.0 Average reward fake: 0.44831499457359314 Average reward real: 0.506773829460144 Training d_loss: 1.2837 Training g_loss: 0.7977 Training q_loss: 871.6141 Explore P: 0.0457\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 461 Total reward: 11.0 Average reward fake: 0.48432832956314087 Average reward real: 0.582513689994812 Training d_loss: 1.2305 Training g_loss: 0.7287 Training q_loss: 1191.7522 Explore P: 0.0457\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 462 Total reward: 9.0 Average reward fake: 0.4714587330818176 Average reward real: 0.5217331647872925 Training d_loss: 1.2975 Training g_loss: 0.7509 Training q_loss: 1451.0979 Explore P: 0.0457\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 463 Total reward: 11.0 Average reward fake: 0.40108761191368103 Average reward real: 0.5302869081497192 Training d_loss: 1.1628 Training g_loss: 0.9727 Training q_loss: 1127.2444 Explore P: 0.0456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 464 Total reward: 8.0 Average reward fake: 0.46510791778564453 Average reward real: 0.5233938097953796 Training d_loss: 1.2749 Training g_loss: 0.7483 Training q_loss: 1470.6438 Explore P: 0.0456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 465 Total reward: 7.0 Average reward fake: 0.4471966326236725 Average reward real: 0.5516940355300903 Training d_loss: 1.1939 Training g_loss: 0.8323 Training q_loss: 1436.0646 Explore P: 0.0456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 466 Total reward: 10.0 Average reward fake: 0.4466873109340668 Average reward real: 0.5335336923599243 Training d_loss: 1.2327 Training g_loss: 0.8026 Training q_loss: 1352.2971 Explore P: 0.0455\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 467 Total reward: 11.0 Average reward fake: 0.42495185136795044 Average reward real: 0.5218828916549683 Training d_loss: 1.2167 Training g_loss: 0.8467 Training q_loss: 1039.1082 Explore P: 0.0455\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 468 Total reward: 10.0 Average reward fake: 0.45097702741622925 Average reward real: 0.5628909468650818 Training d_loss: 1.1859 Training g_loss: 0.7813 Training q_loss: 517.3920 Explore P: 0.0455\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 469 Total reward: 10.0 Average reward fake: 0.44042688608169556 Average reward real: 0.5760383009910583 Training d_loss: 1.1370 Training g_loss: 0.8339 Training q_loss: 291.4450 Explore P: 0.0454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 470 Total reward: 9.0 Average reward fake: 0.41579586267471313 Average reward real: 0.548310399055481 Training d_loss: 1.1442 Training g_loss: 0.8795 Training q_loss: 40.7802 Explore P: 0.0454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 471 Total reward: 12.0 Average reward fake: 0.43686914443969727 Average reward real: 0.5696433782577515 Training d_loss: 1.1557 Training g_loss: 0.8233 Training q_loss: 162.7733 Explore P: 0.0454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 472 Total reward: 8.0 Average reward fake: 0.4341243803501129 Average reward real: 0.5336717367172241 Training d_loss: 1.2013 Training g_loss: 0.8336 Training q_loss: 106.4782 Explore P: 0.0453\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 473 Total reward: 9.0 Average reward fake: 0.4816473424434662 Average reward real: 0.5393393635749817 Training d_loss: 1.3023 Training g_loss: 0.7582 Training q_loss: 202834.9062 Explore P: 0.0453\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 474 Total reward: 13.0 Average reward fake: 0.4270555377006531 Average reward real: 0.5597929954528809 Training d_loss: 1.1498 Training g_loss: 0.8606 Training q_loss: 250.7835 Explore P: 0.0452\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 475 Total reward: 121.0 Average reward fake: 0.6681146621704102 Average reward real: 0.4096972346305847 Training d_loss: 2.0218 Training g_loss: 0.5082 Training q_loss: 180.8631 Explore P: 0.0448\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 476 Total reward: 136.0 Average reward fake: 0.5562211275100708 Average reward real: 0.5157670974731445 Training d_loss: 1.4994 Training g_loss: 0.6155 Training q_loss: 45.8171 Explore P: 0.0444\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 477 Total reward: 196.0 Average reward fake: 0.49897414445877075 Average reward real: 0.4989309310913086 Training d_loss: 1.3961 Training g_loss: 0.6937 Training q_loss: 1705.3015 Explore P: 0.0437\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 478 Total reward: 199.0 Average reward fake: 0.5623453855514526 Average reward real: 0.5435301065444946 Training d_loss: 1.4444 Training g_loss: 0.5851 Training q_loss: 77.6545 Explore P: 0.0430\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 479 Total reward: 199.0 Average reward fake: 0.48968735337257385 Average reward real: 0.4407350420951843 Training d_loss: 1.5023 Training g_loss: 0.7201 Training q_loss: 127.8681 Explore P: 0.0424\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 480 Total reward: 199.0 Average reward fake: 0.5414739847183228 Average reward real: 0.4911855161190033 Training d_loss: 1.5089 Training g_loss: 0.6323 Training q_loss: 168.8063 Explore P: 0.0417\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 481 Total reward: 199.0 Average reward fake: 0.49834948778152466 Average reward real: 0.5040051341056824 Training d_loss: 1.3795 Training g_loss: 0.6979 Training q_loss: 34.3069 Explore P: 0.0411\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 482 Total reward: 199.0 Average reward fake: 0.4725379943847656 Average reward real: 0.3950578272342682 Training d_loss: 1.5741 Training g_loss: 0.7519 Training q_loss: 23.3866 Explore P: 0.0405\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 483 Total reward: 182.0 Average reward fake: 0.45298367738723755 Average reward real: 0.5734552145004272 Training d_loss: 1.1657 Training g_loss: 0.8253 Training q_loss: 15.2818 Explore P: 0.0399\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 484 Total reward: 199.0 Average reward fake: 0.4174977242946625 Average reward real: 0.5018261671066284 Training d_loss: 1.2451 Training g_loss: 0.8680 Training q_loss: 12.8151 Explore P: 0.0394\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 485 Total reward: 163.0 Average reward fake: 0.4978354871273041 Average reward real: 0.5288176536560059 Training d_loss: 1.3372 Training g_loss: 0.6900 Training q_loss: 18.7888 Explore P: 0.0389\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 486 Total reward: 186.0 Average reward fake: 0.47413331270217896 Average reward real: 0.5170754790306091 Training d_loss: 1.3062 Training g_loss: 0.8208 Training q_loss: 14.6135 Explore P: 0.0383\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 487 Total reward: 192.0 Average reward fake: 0.48948630690574646 Average reward real: 0.5360948443412781 Training d_loss: 1.3035 Training g_loss: 0.7391 Training q_loss: 17.4680 Explore P: 0.0378\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 488 Total reward: 150.0 Average reward fake: 0.47944527864456177 Average reward real: 0.4940725266933441 Training d_loss: 1.3632 Training g_loss: 0.7383 Training q_loss: 12.3873 Explore P: 0.0374\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 489 Total reward: 199.0 Average reward fake: 0.5107103586196899 Average reward real: 0.5585045218467712 Training d_loss: 1.3073 Training g_loss: 0.6962 Training q_loss: 13.9393 Explore P: 0.0369\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 490 Total reward: 199.0 Average reward fake: 0.47318100929260254 Average reward real: 0.5126807689666748 Training d_loss: 1.3133 Training g_loss: 0.7700 Training q_loss: 91.8714 Explore P: 0.0363\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 491 Total reward: 192.0 Average reward fake: 0.49132370948791504 Average reward real: 0.522419273853302 Training d_loss: 1.3356 Training g_loss: 0.7205 Training q_loss: 20.0163 Explore P: 0.0358\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 492 Total reward: 199.0 Average reward fake: 0.5115740299224854 Average reward real: 0.5451802015304565 Training d_loss: 1.3269 Training g_loss: 0.6841 Training q_loss: 4.2218 Explore P: 0.0353\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 493 Total reward: 199.0 Average reward fake: 0.5012958645820618 Average reward real: 0.507339596748352 Training d_loss: 1.3765 Training g_loss: 0.6819 Training q_loss: 7.9833 Explore P: 0.0348\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 494 Total reward: 156.0 Average reward fake: 0.48541754484176636 Average reward real: 0.5394729375839233 Training d_loss: 1.3058 Training g_loss: 0.7319 Training q_loss: 7.7602 Explore P: 0.0344\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 495 Total reward: 170.0 Average reward fake: 0.46005529165267944 Average reward real: 0.5610845685005188 Training d_loss: 1.2096 Training g_loss: 0.7769 Training q_loss: 7.3490 Explore P: 0.0340\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 496 Total reward: 199.0 Average reward fake: 0.449146032333374 Average reward real: 0.39499253034591675 Training d_loss: 1.5658 Training g_loss: 0.7967 Training q_loss: 5.2058 Explore P: 0.0335\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 497 Total reward: 194.0 Average reward fake: 0.613271951675415 Average reward real: 0.4542910158634186 Training d_loss: 1.7483 Training g_loss: 0.4846 Training q_loss: 19.3495 Explore P: 0.0331\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 498 Total reward: 198.0 Average reward fake: 0.24487057328224182 Average reward real: 0.7760676145553589 Training d_loss: 0.5352 Training g_loss: 1.5417 Training q_loss: 1.9603 Explore P: 0.0326\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 499 Total reward: 199.0 Average reward fake: 0.45550355315208435 Average reward real: 0.5587984919548035 Training d_loss: 1.2030 Training g_loss: 0.8395 Training q_loss: 6.2585 Explore P: 0.0322\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 500 Total reward: 171.0 Average reward fake: 0.491570383310318 Average reward real: 0.6324454545974731 Training d_loss: 1.1387 Training g_loss: 0.7387 Training q_loss: 6.2783 Explore P: 0.0318\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 501 Total reward: 199.0 Average reward fake: 0.4586207866668701 Average reward real: 0.4572826325893402 Training d_loss: 1.4009 Training g_loss: 0.7774 Training q_loss: 29.1050 Explore P: 0.0314\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 502 Total reward: 199.0 Average reward fake: 0.44528359174728394 Average reward real: 0.5623987913131714 Training d_loss: 1.1720 Training g_loss: 0.8229 Training q_loss: 3.9759 Explore P: 0.0310\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 503 Total reward: 187.0 Average reward fake: 0.4978465139865875 Average reward real: 0.5103195905685425 Training d_loss: 1.3665 Training g_loss: 0.7155 Training q_loss: 4.3392 Explore P: 0.0306\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 504 Total reward: 199.0 Average reward fake: 0.4629914164543152 Average reward real: 0.6241902112960815 Training d_loss: 1.1067 Training g_loss: 0.8254 Training q_loss: 2.1064 Explore P: 0.0302\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 505 Total reward: 199.0 Average reward fake: 0.4579760432243347 Average reward real: 0.4855622351169586 Training d_loss: 1.3421 Training g_loss: 0.7700 Training q_loss: 2.7241 Explore P: 0.0298\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 506 Total reward: 199.0 Average reward fake: 0.5713199973106384 Average reward real: 0.5691081881523132 Training d_loss: 1.4119 Training g_loss: 0.5571 Training q_loss: 115.6393 Explore P: 0.0294\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 507 Total reward: 199.0 Average reward fake: 0.4965072572231293 Average reward real: 0.485198438167572 Training d_loss: 1.4146 Training g_loss: 0.6988 Training q_loss: 4.5530 Explore P: 0.0290\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 508 Total reward: 199.0 Average reward fake: 0.4638268053531647 Average reward real: 0.4563141465187073 Training d_loss: 1.4122 Training g_loss: 0.7529 Training q_loss: 2.2932 Explore P: 0.0286\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 509 Total reward: 199.0 Average reward fake: 0.49548181891441345 Average reward real: 0.5188500285148621 Training d_loss: 1.3424 Training g_loss: 0.7035 Training q_loss: 2.4428 Explore P: 0.0283\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 510 Total reward: 199.0 Average reward fake: 0.45399975776672363 Average reward real: 0.47475457191467285 Training d_loss: 1.3662 Training g_loss: 0.7704 Training q_loss: 3.5841 Explore P: 0.0279\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 511 Total reward: 199.0 Average reward fake: 0.5141198039054871 Average reward real: 0.5787457823753357 Training d_loss: 1.2733 Training g_loss: 0.7199 Training q_loss: 3.0545 Explore P: 0.0276\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 512 Total reward: 199.0 Average reward fake: 0.4567975103855133 Average reward real: 0.49133577942848206 Training d_loss: 1.3295 Training g_loss: 0.7897 Training q_loss: 15.6116 Explore P: 0.0272\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 513 Total reward: 199.0 Average reward fake: 0.5913568139076233 Average reward real: 0.3589779734611511 Training d_loss: 1.9649 Training g_loss: 0.5657 Training q_loss: 7.3580 Explore P: 0.0269\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 514 Total reward: 199.0 Average reward fake: 0.5226519703865051 Average reward real: 0.5652874112129211 Training d_loss: 1.3161 Training g_loss: 0.6688 Training q_loss: 1.6169 Explore P: 0.0265\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 515 Total reward: 199.0 Average reward fake: 0.4626971185207367 Average reward real: 0.5157178640365601 Training d_loss: 1.2945 Training g_loss: 0.8028 Training q_loss: 3.3460 Explore P: 0.0262\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 516 Total reward: 199.0 Average reward fake: 0.46388500928878784 Average reward real: 0.5271340012550354 Training d_loss: 1.2643 Training g_loss: 0.7820 Training q_loss: 2.2039 Explore P: 0.0259\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 517 Total reward: 198.0 Average reward fake: 0.46071749925613403 Average reward real: 0.468421995639801 Training d_loss: 1.3831 Training g_loss: 0.7698 Training q_loss: 2.9765 Explore P: 0.0256\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 518 Total reward: 199.0 Average reward fake: 0.3026916980743408 Average reward real: 0.7148643136024475 Training d_loss: 0.7118 Training g_loss: 1.2798 Training q_loss: 0.9470 Explore P: 0.0253\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 519 Total reward: 199.0 Average reward fake: 0.3948492407798767 Average reward real: 0.6634718179702759 Training d_loss: 0.9275 Training g_loss: 1.0294 Training q_loss: 1.4067 Explore P: 0.0250\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 520 Total reward: 126.0 Average reward fake: 0.5510360598564148 Average reward real: 0.34875279664993286 Training d_loss: 1.9858 Training g_loss: 0.5910 Training q_loss: 29.8821 Explore P: 0.0248\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 521 Total reward: 199.0 Average reward fake: 0.5142953991889954 Average reward real: 0.4700939655303955 Training d_loss: 1.4868 Training g_loss: 0.6606 Training q_loss: 2.0706 Explore P: 0.0245\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 522 Total reward: 182.0 Average reward fake: 0.48424047231674194 Average reward real: 0.4897984564304352 Training d_loss: 1.3767 Training g_loss: 0.7219 Training q_loss: 1.2409 Explore P: 0.0242\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 523 Total reward: 199.0 Average reward fake: 0.48699432611465454 Average reward real: 0.5411077737808228 Training d_loss: 1.2832 Training g_loss: 0.7214 Training q_loss: 2.6421 Explore P: 0.0240\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 524 Total reward: 185.0 Average reward fake: 0.45564889907836914 Average reward real: 0.6207626461982727 Training d_loss: 1.1018 Training g_loss: 0.8240 Training q_loss: 2.2853 Explore P: 0.0237\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 525 Total reward: 199.0 Average reward fake: 0.48119527101516724 Average reward real: 0.5060867667198181 Training d_loss: 1.3454 Training g_loss: 0.7337 Training q_loss: 6.9770 Explore P: 0.0234\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 526 Total reward: 199.0 Average reward fake: 0.4913955628871918 Average reward real: 0.5152401328086853 Training d_loss: 1.3491 Training g_loss: 0.7305 Training q_loss: 4.9025 Explore P: 0.0232\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 527 Total reward: 186.0 Average reward fake: 0.520989716053009 Average reward real: 0.5094859004020691 Training d_loss: 1.4111 Training g_loss: 0.6488 Training q_loss: 1.6294 Explore P: 0.0229\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards and losses list for plotting\n",
    "rewards_list, rewards_fake_list, rewards_real_list = [], [], []\n",
    "d_loss_list, g_loss_list, q_loss_list = [], [], [] \n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training episodes/epochs\n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        \n",
    "        # Env/agent steps/batches/minibatches\n",
    "        total_reward, rewards_fake_mean, rewards_real_mean = 0, 0, 0\n",
    "        d_loss, g_loss, q_loss = 0, 0, 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from model\n",
    "                feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "                actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "                action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Episode/epoch training is done/failed!\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Average reward fake: {}'.format(rewards_fake_mean),\n",
    "                      'Average reward real: {}'.format(rewards_real_mean),\n",
    "                      'Training d_loss: {:.4f}'.format(d_loss),\n",
    "                      'Training g_loss: {:.4f}'.format(g_loss),\n",
    "                      'Training q_loss: {:.4f}'.format(q_loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                \n",
    "                # total rewards and losses for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                rewards_fake_list.append((ep, rewards_fake_mean))\n",
    "                d_loss_list.append((ep, d_loss))\n",
    "                g_loss_list.append((ep, g_loss))\n",
    "                q_loss_list.append((ep, q_loss))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            #rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train the model\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions}\n",
    "            rewards_fake, rewards_real = sess.run([model.rewards_fake, model.rewards_real], feed_dict)\n",
    "            feed_dict={model.states: next_states}\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "\n",
    "            # Mean/average fake and real rewards or rewarded generated/given actions\n",
    "            rewards_fake_mean = np.mean(rewards_fake.reshape(-1))\n",
    "            rewards_real_mean = np.mean(rewards_real.reshape(-1))\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            next_actions_logits[episode_ends] = (0, 0)\n",
    "\n",
    "            # Bellman equation: Qt = Rt + max(Qt+1)\n",
    "            targetQs = rewards_fake.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "\n",
    "            # Updating the model\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions, model.targetQs: targetQs}\n",
    "            d_loss, _ = sess.run([model.d_loss, model.d_opt], feed_dict)\n",
    "            g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict)\n",
    "            q_loss, _ = sess.run([model.q_loss, model.q_opt], feed_dict)\n",
    "            \n",
    "    # Save the trained model \n",
    "    saver.save(sess, 'checkpoints/DQAN-cartpole.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(q_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Q losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_episodes = 5\n",
    "test_max_steps = 2000\n",
    "env.reset()\n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    # Save the trained model \n",
    "    saver.restore(sess, 'checkpoints/DQAN-cartpole.ckpt')\n",
    "    \n",
    "    # iterations\n",
    "    for ep in range(test_episodes):\n",
    "        \n",
    "        # number of env/rob steps\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            env.render()\n",
    "            \n",
    "            # Get action from DQAN\n",
    "            feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "            actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # The task is done or not;\n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1\n",
    "\n",
    "# Closing the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this to Deep Convolutional QAN\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

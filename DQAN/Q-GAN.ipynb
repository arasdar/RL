{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-GAN: (Q-Net) + GAN (G-Net and D-Net)\n",
    "\n",
    "More specifically, we'll use Q-GAN to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# In this one we should define and detect GPUs for tensorflow\n",
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info\n",
      "[-0.00464455 -0.17928359 -0.04387961  0.32460289] 0 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00823023  0.01643479 -0.03738756  0.01841144] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00790153  0.21207242 -0.03701933 -0.28582931] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00366008  0.01749745 -0.04273591 -0.00504801] 0 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[-0.00331013  0.21320541 -0.04283687 -0.31090246] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.00095398  0.40891066 -0.04905492 -0.61678122] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.00913219  0.60468236 -0.06139055 -0.92450188] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.02122584  0.80057741 -0.07988059 -1.23582841] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.03723738  0.99662986 -0.10459715 -1.55242926] 1 1.0 False {}\n",
      "state, action, reward, done, info\n",
      "[ 0.05716998  1.19283899 -0.13564574 -1.87582996] 1 1.0 False {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "rewards, states, actions, dones = [], [], [], []\n",
    "for _ in range(10):\n",
    "    # env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    states.append(state)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    dones.append(done)\n",
    "    print('state, action, reward, done, info')\n",
    "    print(state, action, reward, done, info)\n",
    "    if done:\n",
    "        print('state, action, reward, done, info')\n",
    "        print(state, action, reward, done, info)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        dones.append(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(10,) (10, 4) (10,) (10,)\n",
      "float64 float64 int64 bool\n",
      "1 0\n",
      "2\n",
      "1.0 1.0\n",
      "1.1928389892596862 -1.875829956314631\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])\n",
    "print(np.array(rewards).shape, np.array(states).shape, np.array(actions).shape, np.array(dones).shape)\n",
    "print(np.array(rewards).dtype, np.array(states).dtype, np.array(actions).dtype, np.array(dones).dtype)\n",
    "print(np.max(np.array(actions)), np.min(np.array(actions)))\n",
    "print((np.max(np.array(actions)) - np.min(np.array(actions)))+1)\n",
    "print(np.max(np.array(rewards)), np.min(np.array(rewards)))\n",
    "print(np.max(np.array(states)), np.min(np.array(states)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the model\n",
    "def model_input(state_size):\n",
    "    # Current states given\n",
    "    states = tf.placeholder(tf.float32, [None, state_size], name='states')\n",
    "    \n",
    "    # Next states given\n",
    "    next_states = tf.placeholder(tf.float32, [None, state_size], name='next_states')\n",
    "    \n",
    "    # Current actions given\n",
    "    actions = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # TargetQs/values\n",
    "    targetQs = tf.placeholder(tf.float32, [None], name='targetQs')\n",
    "    \n",
    "    # returning the given data to the model\n",
    "    return states, next_states, actions, targetQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Qfunction/Encoder\n",
    "def qfunction(states, action_size, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('qfunction', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=action_size)        \n",
    "        #predictions = tf.nn.softmax(logits)\n",
    "\n",
    "        # return actions logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: Generator/Decoder: actions can be given actions, generated actions\n",
    "def generator(actions, state_size, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=actions, units=hidden_size)\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=state_size)        \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return next_states_logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D: Descriminator/Reward function\n",
    "def discriminator(states, hidden_size, reuse=False, alpha=0.1):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=states, units=hidden_size)\n",
    "        nl1 = tf.maximum(alpha * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(inputs=nl1, units=hidden_size)\n",
    "        nl2 = tf.maximum(alpha * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(inputs=nl2, units=1)   \n",
    "        #predictions = tf.sigmoid(logits)\n",
    "\n",
    "        # return reward logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(states, action_size, hidden_size, actions, targetQs, state_size, next_states, alpha=0.1):\n",
    "    # DQN: Q-learning - Bellman equations: loss (targetQ - Q)^2\n",
    "    actions_logits = qfunction(states=states, hidden_size=hidden_size, action_size=action_size)\n",
    "    actions_real = tf.one_hot(actions, action_size)\n",
    "    Qs = tf.reduce_sum(tf.multiply(actions_logits, actions_real), axis=1)\n",
    "    q_loss = tf.reduce_mean(tf.square(targetQs - Qs))\n",
    "\n",
    "    # GAN: Generate next states\n",
    "    actions_fake = tf.nn.softmax(actions_logits)\n",
    "    next_states_logits = generator(actions=actions_fake, state_size=state_size, hidden_size=hidden_size)\n",
    "    \n",
    "    # GAN: Discriminate between fake and real\n",
    "    next_states_fake = tf.sigmoid(x=next_states_logits)\n",
    "    d_logits_fake = discriminator(states=next_states_fake, hidden_size=hidden_size, reuse=False)\n",
    "    next_states_real = tf.sigmoid(x=next_states) \n",
    "    d_logits_real = discriminator(states=next_states_real, hidden_size=hidden_size, reuse=True)\n",
    "\n",
    "    # GAN: Adverserial training - D-learning\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # GAN: Adverserial training - G-learning\n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "\n",
    "    # Rewards fake/real\n",
    "    rewards_fake = tf.sigmoid(d_logits_fake)\n",
    "    rewards_real = tf.sigmoid(d_logits_real)\n",
    "\n",
    "    return actions_logits, q_loss, d_loss, g_loss, rewards_fake, rewards_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, q_loss, learning_rate):\n",
    "    \"\"\"\n",
    "    Get optimization operations in order\n",
    "    :param q_loss: Qfunction/Value loss Tensor for next action prediction\n",
    "    :param g_loss: Generator/Decoder loss Tensor for next state prediction\n",
    "    :param d_loss: Discriminator/Reward loss Tensor for current reward function\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :return: A tuple of (qfunction training, generator training, discriminator training)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    q_vars = [var for var in t_vars if var.name.startswith('qfunction')] # Q: action At/at\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')] # G: next state St/st\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')] # D: reward Rt/rt\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        q_opt = tf.train.AdamOptimizer(learning_rate).minimize(q_loss, var_list=q_vars)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "    return q_opt, g_opt, d_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQAN:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate):\n",
    "\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.states, self.next_states, self.actions, self.targetQs = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.actions_logits, self.q_loss, self.d_loss, self.g_loss, self.rewards_fake, self.rewards_real = model_loss(\n",
    "            state_size=state_size, action_size=action_size, hidden_size=hidden_size, \n",
    "            states=self.states, next_states=self.next_states, actions=self.actions, targetQs=self.targetQs)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.q_opt, self.g_opt, self.d_opt = model_opt(d_loss=self.d_loss, g_loss=self.g_loss, q_loss=self.q_loss, \n",
    "                                                       learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():    \n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 500          # max number of episodes to learn from\n",
    "max_steps = 2000              # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64              # number of units in each Q-network hidden layer -- simulation\n",
    "state_size = 4                # number of units for the input state/observation -- simulation\n",
    "action_size = 2               # number of units for the output actions -- simulation\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 100000            # memory capacity\n",
    "batch_size = 10                # experience mini-batch size\n",
    "learning_rate = 0.001          # learning rate for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = DQAN(action_size=action_size, hidden_size=hidden_size, state_size=state_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/Q-GAN-cartpole.ckpt\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 0 Total reward: 6.0 Average reward fake: 0.5262561440467834 Average reward real: 0.6110993027687073 Training q_loss: 1305991.0000 Training g_loss: 0.6420 Training d_loss: 1.2431 Explore P: 0.9994\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 1 Total reward: 16.0 Average reward fake: 0.45489436388015747 Average reward real: 0.5582472085952759 Training q_loss: 4395075.5000 Training g_loss: 0.7877 Training d_loss: 1.2161 Explore P: 0.9978\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 2 Total reward: 9.0 Average reward fake: 0.4416735768318176 Average reward real: 0.5409927368164062 Training q_loss: 3825372.7500 Training g_loss: 0.8172 Training d_loss: 1.2368 Explore P: 0.9969\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 3 Total reward: 28.0 Average reward fake: 0.4705374836921692 Average reward real: 0.5330754518508911 Training q_loss: 3223244.5000 Training g_loss: 0.7539 Training d_loss: 1.3083 Explore P: 0.9942\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 4 Total reward: 9.0 Average reward fake: 0.4954429268836975 Average reward real: 0.5253230929374695 Training q_loss: 457340992.0000 Training g_loss: 0.7023 Training d_loss: 1.4013 Explore P: 0.9933\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 5 Total reward: 17.0 Average reward fake: 0.46443066000938416 Average reward real: 0.49589458107948303 Training q_loss: 732433536.0000 Training g_loss: 0.7669 Training d_loss: 1.3565 Explore P: 0.9916\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 6 Total reward: 8.0 Average reward fake: 0.516241192817688 Average reward real: 0.5216699242591858 Training q_loss: 2999656.0000 Training g_loss: 0.6612 Training d_loss: 1.4273 Explore P: 0.9908\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 7 Total reward: 9.0 Average reward fake: 0.508783221244812 Average reward real: 0.4335055947303772 Training q_loss: 237245872.0000 Training g_loss: 0.6757 Training d_loss: 1.5736 Explore P: 0.9900\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 8 Total reward: 25.0 Average reward fake: 0.25959911942481995 Average reward real: 0.6989132165908813 Training q_loss: 557030016.0000 Training g_loss: 1.3486 Training d_loss: 0.7583 Explore P: 0.9875\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 9 Total reward: 40.0 Average reward fake: 0.5704470872879028 Average reward real: 0.4777810573577881 Training q_loss: 720824.6875 Training g_loss: 0.5613 Training d_loss: 1.6291 Explore P: 0.9836\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 10 Total reward: 20.0 Average reward fake: 0.2593569755554199 Average reward real: 0.8137475848197937 Training q_loss: 411949888.0000 Training g_loss: 1.3495 Training d_loss: 0.5549 Explore P: 0.9817\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 11 Total reward: 23.0 Average reward fake: 0.0786210298538208 Average reward real: 0.943355917930603 Training q_loss: 356370944.0000 Training g_loss: 2.5431 Training d_loss: 0.1399 Explore P: 0.9794\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 12 Total reward: 16.0 Average reward fake: 0.061015862971544266 Average reward real: 0.9539583921432495 Training q_loss: 185090688.0000 Training g_loss: 2.7966 Training d_loss: 0.1185 Explore P: 0.9779\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 13 Total reward: 39.0 Average reward fake: 0.7231653928756714 Average reward real: 0.3415815532207489 Training q_loss: 1153507.7500 Training g_loss: 0.3241 Training d_loss: 3.2621 Explore P: 0.9741\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 14 Total reward: 18.0 Average reward fake: 0.40185031294822693 Average reward real: 0.4353314936161041 Training q_loss: 653612.1250 Training g_loss: 0.9117 Training d_loss: 1.5153 Explore P: 0.9724\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 15 Total reward: 7.0 Average reward fake: 0.4526638090610504 Average reward real: 0.6249849796295166 Training q_loss: 468933.3125 Training g_loss: 0.7926 Training d_loss: 1.1117 Explore P: 0.9717\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 16 Total reward: 17.0 Average reward fake: 0.39661988615989685 Average reward real: 0.5596848726272583 Training q_loss: 453378656.0000 Training g_loss: 0.9248 Training d_loss: 1.1826 Explore P: 0.9701\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 17 Total reward: 20.0 Average reward fake: 0.5291880369186401 Average reward real: 0.4239288866519928 Training q_loss: 2240604.5000 Training g_loss: 0.6364 Training d_loss: 1.6981 Explore P: 0.9682\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 18 Total reward: 47.0 Average reward fake: 0.49034637212753296 Average reward real: 0.3554476797580719 Training q_loss: 327691584.0000 Training g_loss: 0.7126 Training d_loss: 1.7547 Explore P: 0.9637\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 19 Total reward: 14.0 Average reward fake: 0.4662547707557678 Average reward real: 0.43452468514442444 Training q_loss: 2196407.2500 Training g_loss: 0.7630 Training d_loss: 1.4693 Explore P: 0.9623\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 20 Total reward: 10.0 Average reward fake: 0.44653671979904175 Average reward real: 0.4695850908756256 Training q_loss: 2339243.2500 Training g_loss: 0.8062 Training d_loss: 1.3578 Explore P: 0.9614\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 21 Total reward: 65.0 Average reward fake: 0.44449418783187866 Average reward real: 0.545038640499115 Training q_loss: 1955656.0000 Training g_loss: 0.8108 Training d_loss: 1.2074 Explore P: 0.9552\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 22 Total reward: 79.0 Average reward fake: 0.5544271469116211 Average reward real: 0.5437315106391907 Training q_loss: 299809184.0000 Training g_loss: 0.5898 Training d_loss: 1.4290 Explore P: 0.9478\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 23 Total reward: 38.0 Average reward fake: 0.5044890642166138 Average reward real: 0.5606293678283691 Training q_loss: 4556363.5000 Training g_loss: 0.6842 Training d_loss: 1.2892 Explore P: 0.9442\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 24 Total reward: 19.0 Average reward fake: 0.48241668939590454 Average reward real: 0.5059512853622437 Training q_loss: 1168862.7500 Training g_loss: 0.7289 Training d_loss: 1.3450 Explore P: 0.9424\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 25 Total reward: 16.0 Average reward fake: 0.4876479506492615 Average reward real: 0.5032670497894287 Training q_loss: 137469856.0000 Training g_loss: 0.7182 Training d_loss: 1.3651 Explore P: 0.9409\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 26 Total reward: 14.0 Average reward fake: 0.5072512626647949 Average reward real: 0.49395856261253357 Training q_loss: 2459494.0000 Training g_loss: 0.6787 Training d_loss: 1.4201 Explore P: 0.9396\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 27 Total reward: 14.0 Average reward fake: 0.48114269971847534 Average reward real: 0.45672330260276794 Training q_loss: 4353282.5000 Training g_loss: 0.7316 Training d_loss: 1.4548 Explore P: 0.9383\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 28 Total reward: 12.0 Average reward fake: 0.49957799911499023 Average reward real: 0.47274327278137207 Training q_loss: 2965052.7500 Training g_loss: 0.6940 Training d_loss: 1.4473 Explore P: 0.9372\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 29 Total reward: 29.0 Average reward fake: 0.4707655906677246 Average reward real: 0.4758281111717224 Training q_loss: 103851952.0000 Training g_loss: 0.7534 Training d_loss: 1.3861 Explore P: 0.9345\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 30 Total reward: 21.0 Average reward fake: 0.4582887589931488 Average reward real: 0.48147302865982056 Training q_loss: 4616269.0000 Training g_loss: 0.7803 Training d_loss: 1.3483 Explore P: 0.9326\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 31 Total reward: 10.0 Average reward fake: 0.44038209319114685 Average reward real: 0.4755489230155945 Training q_loss: 108090256.0000 Training g_loss: 0.8201 Training d_loss: 1.3281 Explore P: 0.9317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 32 Total reward: 22.0 Average reward fake: 0.42958980798721313 Average reward real: 0.5133348703384399 Training q_loss: 3422710.7500 Training g_loss: 0.8449 Training d_loss: 1.2356 Explore P: 0.9297\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 33 Total reward: 23.0 Average reward fake: 0.41289815306663513 Average reward real: 0.5057380199432373 Training q_loss: 105888240.0000 Training g_loss: 0.8846 Training d_loss: 1.2188 Explore P: 0.9275\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 34 Total reward: 14.0 Average reward fake: 0.42505306005477905 Average reward real: 0.5191644430160522 Training q_loss: 3129283.2500 Training g_loss: 0.8558 Training d_loss: 1.2128 Explore P: 0.9263\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 35 Total reward: 22.0 Average reward fake: 0.43294772505760193 Average reward real: 0.5395950078964233 Training q_loss: 3791658.7500 Training g_loss: 0.8395 Training d_loss: 1.1922 Explore P: 0.9243\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 36 Total reward: 14.0 Average reward fake: 0.45769667625427246 Average reward real: 0.511720597743988 Training q_loss: 58673844.0000 Training g_loss: 0.7904 Training d_loss: 1.2938 Explore P: 0.9230\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 37 Total reward: 13.0 Average reward fake: 0.4846034049987793 Average reward real: 0.5365963578224182 Training q_loss: 3520462.5000 Training g_loss: 0.7302 Training d_loss: 1.2966 Explore P: 0.9218\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 38 Total reward: 24.0 Average reward fake: 0.5328975915908813 Average reward real: 0.5085474252700806 Training q_loss: 66865512.0000 Training g_loss: 0.6296 Training d_loss: 1.4528 Explore P: 0.9196\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 39 Total reward: 20.0 Average reward fake: 0.5826818346977234 Average reward real: 0.578579843044281 Training q_loss: 6738281.5000 Training g_loss: 0.5405 Training d_loss: 1.4509 Explore P: 0.9178\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 40 Total reward: 61.0 Average reward fake: 0.463412344455719 Average reward real: 0.6218207478523254 Training q_loss: 4554208.0000 Training g_loss: 0.7702 Training d_loss: 1.1735 Explore P: 0.9123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 41 Total reward: 17.0 Average reward fake: 0.5144137144088745 Average reward real: 0.47335338592529297 Training q_loss: 3761474.0000 Training g_loss: 0.6675 Training d_loss: 1.5523 Explore P: 0.9107\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 42 Total reward: 11.0 Average reward fake: 0.5078787207603455 Average reward real: 0.46403414011001587 Training q_loss: 2967526.2500 Training g_loss: 0.6795 Training d_loss: 1.5077 Explore P: 0.9097\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 43 Total reward: 30.0 Average reward fake: 0.5012999176979065 Average reward real: 0.3777064383029938 Training q_loss: 78170584.0000 Training g_loss: 0.6920 Training d_loss: 1.6929 Explore P: 0.9070\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 44 Total reward: 17.0 Average reward fake: 0.42423906922340393 Average reward real: 0.44510793685913086 Training q_loss: 3175845.5000 Training g_loss: 0.8598 Training d_loss: 1.3673 Explore P: 0.9055\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 45 Total reward: 32.0 Average reward fake: 0.36488065123558044 Average reward real: 0.5190788507461548 Training q_loss: 2383056.5000 Training g_loss: 1.0106 Training d_loss: 1.1646 Explore P: 0.9027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 46 Total reward: 14.0 Average reward fake: 0.48741212487220764 Average reward real: 0.6044095158576965 Training q_loss: 4832677.0000 Training g_loss: 0.7188 Training d_loss: 1.2233 Explore P: 0.9014\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 47 Total reward: 13.0 Average reward fake: 0.5282212495803833 Average reward real: 0.5143269300460815 Training q_loss: 4657642.0000 Training g_loss: 0.6398 Training d_loss: 1.4777 Explore P: 0.9003\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 48 Total reward: 18.0 Average reward fake: 0.6084115505218506 Average reward real: 0.5217997431755066 Training q_loss: 4833886.0000 Training g_loss: 0.4986 Training d_loss: 1.6161 Explore P: 0.8987\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 49 Total reward: 50.0 Average reward fake: 0.5109856128692627 Average reward real: 0.687839150428772 Training q_loss: 4558663.0000 Training g_loss: 0.6746 Training d_loss: 1.1070 Explore P: 0.8942\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 50 Total reward: 18.0 Average reward fake: 0.4640410840511322 Average reward real: 0.663488507270813 Training q_loss: 5389176.0000 Training g_loss: 0.7910 Training d_loss: 1.0855 Explore P: 0.8926\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 51 Total reward: 15.0 Average reward fake: 0.4594925045967102 Average reward real: 0.42256346344947815 Training q_loss: 3729923.2500 Training g_loss: 0.7776 Training d_loss: 1.5923 Explore P: 0.8913\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 52 Total reward: 15.0 Average reward fake: 0.48668724298477173 Average reward real: 0.2730300724506378 Training q_loss: 2038463.0000 Training g_loss: 0.7201 Training d_loss: 2.0469 Explore P: 0.8900\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 53 Total reward: 13.0 Average reward fake: 0.4485381245613098 Average reward real: 0.34726086258888245 Training q_loss: 26566146.0000 Training g_loss: 0.8018 Training d_loss: 1.7386 Explore P: 0.8888\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 54 Total reward: 12.0 Average reward fake: 0.4093640446662903 Average reward real: 0.49483808875083923 Training q_loss: 75297936.0000 Training g_loss: 0.8958 Training d_loss: 1.2429 Explore P: 0.8878\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 55 Total reward: 25.0 Average reward fake: 0.4638681411743164 Average reward real: 0.512117862701416 Training q_loss: 158849248.0000 Training g_loss: 0.7683 Training d_loss: 1.3529 Explore P: 0.8856\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 56 Total reward: 15.0 Average reward fake: 0.560334324836731 Average reward real: 0.4528709948062897 Training q_loss: 61945752.0000 Training g_loss: 0.5812 Training d_loss: 1.7265 Explore P: 0.8843\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 57 Total reward: 15.0 Average reward fake: 0.6045535802841187 Average reward real: 0.4790631830692291 Training q_loss: 4825689.0000 Training g_loss: 0.5033 Training d_loss: 1.7232 Explore P: 0.8830\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 58 Total reward: 15.0 Average reward fake: 0.5544973015785217 Average reward real: 0.5962095856666565 Training q_loss: 3998057.2500 Training g_loss: 0.5902 Training d_loss: 1.3620 Explore P: 0.8817\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 59 Total reward: 22.0 Average reward fake: 0.5288068652153015 Average reward real: 0.4961868226528168 Training q_loss: 1984906.7500 Training g_loss: 0.6371 Training d_loss: 1.4680 Explore P: 0.8797\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 60 Total reward: 16.0 Average reward fake: 0.524549663066864 Average reward real: 0.5055376887321472 Training q_loss: 3090993.0000 Training g_loss: 0.6452 Training d_loss: 1.4451 Explore P: 0.8784\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 61 Total reward: 30.0 Average reward fake: 0.4949379563331604 Average reward real: 0.492453008890152 Training q_loss: 5257015.0000 Training g_loss: 0.7033 Training d_loss: 1.4024 Explore P: 0.8758\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 62 Total reward: 58.0 Average reward fake: 0.4844897389411926 Average reward real: 0.5171510577201843 Training q_loss: 3310584.5000 Training g_loss: 0.7247 Training d_loss: 1.3290 Explore P: 0.8708\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 63 Total reward: 11.0 Average reward fake: 0.4860244691371918 Average reward real: 0.5237212777137756 Training q_loss: 16096685.0000 Training g_loss: 0.7215 Training d_loss: 1.3296 Explore P: 0.8698\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 64 Total reward: 17.0 Average reward fake: 0.5170947909355164 Average reward real: 0.4520275592803955 Training q_loss: 3349547.5000 Training g_loss: 0.6595 Training d_loss: 1.5499 Explore P: 0.8683\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 65 Total reward: 11.0 Average reward fake: 0.4810088276863098 Average reward real: 0.44397249817848206 Training q_loss: 4536734.0000 Training g_loss: 0.7327 Training d_loss: 1.5071 Explore P: 0.8674\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 66 Total reward: 10.0 Average reward fake: 0.48150983452796936 Average reward real: 0.4400767683982849 Training q_loss: 4116115.5000 Training g_loss: 0.7308 Training d_loss: 1.4924 Explore P: 0.8665\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 67 Total reward: 21.0 Average reward fake: 0.41341057419776917 Average reward real: 0.5040359497070312 Training q_loss: 4313607.0000 Training g_loss: 0.8833 Training d_loss: 1.2226 Explore P: 0.8647\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 68 Total reward: 19.0 Average reward fake: 0.39579057693481445 Average reward real: 0.5566888451576233 Training q_loss: 31840630.0000 Training g_loss: 0.9310 Training d_loss: 1.1115 Explore P: 0.8631\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 69 Total reward: 17.0 Average reward fake: 0.48446911573410034 Average reward real: 0.5384585857391357 Training q_loss: 2357405.5000 Training g_loss: 0.7247 Training d_loss: 1.3073 Explore P: 0.8617\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 70 Total reward: 15.0 Average reward fake: 0.5059080719947815 Average reward real: 0.4365765154361725 Training q_loss: 3112047.5000 Training g_loss: 0.6814 Training d_loss: 1.5509 Explore P: 0.8604\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 71 Total reward: 28.0 Average reward fake: 0.5430368185043335 Average reward real: 0.498473584651947 Training q_loss: 28078336.0000 Training g_loss: 0.6107 Training d_loss: 1.4819 Explore P: 0.8580\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 72 Total reward: 21.0 Average reward fake: 0.5214719176292419 Average reward real: 0.5506240129470825 Training q_loss: 18199840.0000 Training g_loss: 0.6511 Training d_loss: 1.3367 Explore P: 0.8562\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 73 Total reward: 15.0 Average reward fake: 0.5043258666992188 Average reward real: 0.5316277742385864 Training q_loss: 25975926.0000 Training g_loss: 0.6846 Training d_loss: 1.3349 Explore P: 0.8550\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 74 Total reward: 12.0 Average reward fake: 0.4686027467250824 Average reward real: 0.526298463344574 Training q_loss: 21890228.0000 Training g_loss: 0.7580 Training d_loss: 1.2803 Explore P: 0.8540\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 75 Total reward: 9.0 Average reward fake: 0.504111647605896 Average reward real: 0.6028109192848206 Training q_loss: 2324451.5000 Training g_loss: 0.6851 Training d_loss: 1.2167 Explore P: 0.8532\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 76 Total reward: 13.0 Average reward fake: 0.47812357544898987 Average reward real: 0.5643991231918335 Training q_loss: 15959608.0000 Training g_loss: 0.7381 Training d_loss: 1.2314 Explore P: 0.8521\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 77 Total reward: 32.0 Average reward fake: 0.44194668531417847 Average reward real: 0.5369446277618408 Training q_loss: 1958302.7500 Training g_loss: 0.8166 Training d_loss: 1.2129 Explore P: 0.8494\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 78 Total reward: 37.0 Average reward fake: 0.46449628472328186 Average reward real: 0.5658570528030396 Training q_loss: 4467223.0000 Training g_loss: 0.7668 Training d_loss: 1.2055 Explore P: 0.8463\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 79 Total reward: 21.0 Average reward fake: 0.4772622585296631 Average reward real: 0.6058284044265747 Training q_loss: 2514273.5000 Training g_loss: 0.7398 Training d_loss: 1.1698 Explore P: 0.8446\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 80 Total reward: 12.0 Average reward fake: 0.47479432821273804 Average reward real: 0.5174048542976379 Training q_loss: 3025771.2500 Training g_loss: 0.7449 Training d_loss: 1.3171 Explore P: 0.8436\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 81 Total reward: 54.0 Average reward fake: 0.3972250521183014 Average reward real: 0.4950265884399414 Training q_loss: 95277344.0000 Training g_loss: 0.9233 Training d_loss: 1.2269 Explore P: 0.8391\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 82 Total reward: 20.0 Average reward fake: 0.36625006794929504 Average reward real: 0.5264321565628052 Training q_loss: 2979580.5000 Training g_loss: 1.0044 Training d_loss: 1.1316 Explore P: 0.8374\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 83 Total reward: 22.0 Average reward fake: 0.4229432940483093 Average reward real: 0.6643047332763672 Training q_loss: 2464702.5000 Training g_loss: 0.8621 Training d_loss: 0.9963 Explore P: 0.8356\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 84 Total reward: 15.0 Average reward fake: 0.4042033553123474 Average reward real: 0.6304182410240173 Training q_loss: 4475097.0000 Training g_loss: 0.9061 Training d_loss: 1.0105 Explore P: 0.8344\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 85 Total reward: 9.0 Average reward fake: 0.3766927719116211 Average reward real: 0.5385354161262512 Training q_loss: 3261069.2500 Training g_loss: 0.9763 Training d_loss: 1.1172 Explore P: 0.8336\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 86 Total reward: 11.0 Average reward fake: 0.38324448466300964 Average reward real: 0.5485929250717163 Training q_loss: 1997420.0000 Training g_loss: 0.9610 Training d_loss: 1.1402 Explore P: 0.8327\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 87 Total reward: 14.0 Average reward fake: 0.34454911947250366 Average reward real: 0.5800800919532776 Training q_loss: 4688182.5000 Training g_loss: 1.0655 Training d_loss: 1.0139 Explore P: 0.8316\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 88 Total reward: 23.0 Average reward fake: 0.37558263540267944 Average reward real: 0.5041449069976807 Training q_loss: 2011274.0000 Training g_loss: 0.9793 Training d_loss: 1.2055 Explore P: 0.8297\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 89 Total reward: 37.0 Average reward fake: 0.3465891480445862 Average reward real: 0.6910800337791443 Training q_loss: 2983726.7500 Training g_loss: 1.0739 Training d_loss: 0.8323 Explore P: 0.8266\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 90 Total reward: 16.0 Average reward fake: 0.36382266879081726 Average reward real: 0.6302962899208069 Training q_loss: 22374188.0000 Training g_loss: 1.0151 Training d_loss: 0.9703 Explore P: 0.8253\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 91 Total reward: 11.0 Average reward fake: 0.39967861771583557 Average reward real: 0.6310275793075562 Training q_loss: 28854276.0000 Training g_loss: 0.9207 Training d_loss: 1.0277 Explore P: 0.8244\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 92 Total reward: 53.0 Average reward fake: 0.3557547926902771 Average reward real: 0.6465786695480347 Training q_loss: 3663857.2500 Training g_loss: 1.0493 Training d_loss: 0.9397 Explore P: 0.8201\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 93 Total reward: 21.0 Average reward fake: 0.3345896601676941 Average reward real: 0.8080335855484009 Training q_loss: 2664895.0000 Training g_loss: 1.1426 Training d_loss: 0.7539 Explore P: 0.8184\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 94 Total reward: 24.0 Average reward fake: 0.34168127179145813 Average reward real: 0.8901525735855103 Training q_loss: 1581107.8750 Training g_loss: 1.8241 Training d_loss: 1.1896 Explore P: 0.8165\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 95 Total reward: 35.0 Average reward fake: 0.3793720304965973 Average reward real: 0.8647801280021667 Training q_loss: 3282742.5000 Training g_loss: 2.3678 Training d_loss: 1.2134 Explore P: 0.8137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 96 Total reward: 15.0 Average reward fake: 0.12976734340190887 Average reward real: 0.7757471203804016 Training q_loss: 4504803.0000 Training g_loss: 2.9483 Training d_loss: 0.6812 Explore P: 0.8125\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 97 Total reward: 34.0 Average reward fake: 0.36814162135124207 Average reward real: 0.7928657531738281 Training q_loss: 3749057.2500 Training g_loss: 2.2530 Training d_loss: 1.1376 Explore P: 0.8098\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 98 Total reward: 19.0 Average reward fake: 0.2697400748729706 Average reward real: 0.7692720293998718 Training q_loss: 3172891.5000 Training g_loss: 2.6486 Training d_loss: 0.9068 Explore P: 0.8082\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 99 Total reward: 14.0 Average reward fake: 0.17936569452285767 Average reward real: 0.7140825986862183 Training q_loss: 3829653.5000 Training g_loss: 3.0056 Training d_loss: 0.7293 Explore P: 0.8071\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 100 Total reward: 12.0 Average reward fake: 0.21149876713752747 Average reward real: 0.8591915369033813 Training q_loss: 2551931.2500 Training g_loss: 2.5921 Training d_loss: 0.6449 Explore P: 0.8062\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 101 Total reward: 25.0 Average reward fake: 0.29611095786094666 Average reward real: 0.8615260124206543 Training q_loss: 13017323.0000 Training g_loss: 2.2640 Training d_loss: 0.8530 Explore P: 0.8042\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 102 Total reward: 18.0 Average reward fake: 0.08273095637559891 Average reward real: 0.6159177422523499 Training q_loss: 2164016.0000 Training g_loss: 3.5762 Training d_loss: 0.6259 Explore P: 0.8027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 103 Total reward: 11.0 Average reward fake: 0.3634614944458008 Average reward real: 0.8404234647750854 Training q_loss: 4368459.0000 Training g_loss: 2.0017 Training d_loss: 0.9609 Explore P: 0.8019\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 104 Total reward: 16.0 Average reward fake: 0.26750636100769043 Average reward real: 0.7797088027000427 Training q_loss: 3283190.5000 Training g_loss: 1.9683 Training d_loss: 0.7092 Explore P: 0.8006\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 105 Total reward: 12.0 Average reward fake: 0.2636001706123352 Average reward real: 0.6952143907546997 Training q_loss: 5535393.0000 Training g_loss: 1.4374 Training d_loss: 0.7466 Explore P: 0.7997\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 106 Total reward: 28.0 Average reward fake: 0.3693056106567383 Average reward real: 0.5915461182594299 Training q_loss: 3968674.7500 Training g_loss: 1.1159 Training d_loss: 1.1618 Explore P: 0.7975\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 107 Total reward: 14.0 Average reward fake: 0.51155686378479 Average reward real: 0.6987110376358032 Training q_loss: 4656227.0000 Training g_loss: 0.6999 Training d_loss: 1.1863 Explore P: 0.7964\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 108 Total reward: 35.0 Average reward fake: 0.5267802476882935 Average reward real: 0.3231576085090637 Training q_loss: 2189982.2500 Training g_loss: 0.6410 Training d_loss: 1.9708 Explore P: 0.7936\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 109 Total reward: 21.0 Average reward fake: 0.4882034361362457 Average reward real: 0.4329410493373871 Training q_loss: 3400824.0000 Training g_loss: 0.7173 Training d_loss: 1.5196 Explore P: 0.7920\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 110 Total reward: 24.0 Average reward fake: 0.4097643792629242 Average reward real: 0.48026347160339355 Training q_loss: 3566538.5000 Training g_loss: 0.8949 Training d_loss: 1.2755 Explore P: 0.7901\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 111 Total reward: 22.0 Average reward fake: 0.4202955365180969 Average reward real: 0.5948084592819214 Training q_loss: 5031401.0000 Training g_loss: 0.8842 Training d_loss: 1.1139 Explore P: 0.7884\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 112 Total reward: 19.0 Average reward fake: 0.39635175466537476 Average reward real: 0.5950175523757935 Training q_loss: 3468191.2500 Training g_loss: 0.9476 Training d_loss: 1.0896 Explore P: 0.7869\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 113 Total reward: 49.0 Average reward fake: 0.588483452796936 Average reward real: 0.47132986783981323 Training q_loss: 1760371.2500 Training g_loss: 0.5621 Training d_loss: 1.7213 Explore P: 0.7831\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 114 Total reward: 29.0 Average reward fake: 0.501460075378418 Average reward real: 0.5101341009140015 Training q_loss: 3925777.5000 Training g_loss: 0.6903 Training d_loss: 1.3727 Explore P: 0.7809\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 115 Total reward: 28.0 Average reward fake: 0.5043702125549316 Average reward real: 0.5622335076332092 Training q_loss: 4058994.7500 Training g_loss: 0.6903 Training d_loss: 1.2981 Explore P: 0.7787\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 116 Total reward: 25.0 Average reward fake: 0.5040512084960938 Average reward real: 0.5001716613769531 Training q_loss: 2185212.0000 Training g_loss: 0.6892 Training d_loss: 1.4287 Explore P: 0.7768\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 117 Total reward: 11.0 Average reward fake: 0.4987707734107971 Average reward real: 0.5154866576194763 Training q_loss: 2704016.5000 Training g_loss: 0.6983 Training d_loss: 1.3655 Explore P: 0.7759\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 118 Total reward: 9.0 Average reward fake: 0.48774319887161255 Average reward real: 0.5323259234428406 Training q_loss: 2577270.5000 Training g_loss: 0.7181 Training d_loss: 1.3023 Explore P: 0.7753\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 119 Total reward: 34.0 Average reward fake: 0.4737168252468109 Average reward real: 0.46920737624168396 Training q_loss: 7085256.0000 Training g_loss: 0.7583 Training d_loss: 1.4172 Explore P: 0.7727\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 120 Total reward: 18.0 Average reward fake: 0.48026347160339355 Average reward real: 0.4685691297054291 Training q_loss: 2914012.0000 Training g_loss: 0.7356 Training d_loss: 1.4227 Explore P: 0.7713\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 121 Total reward: 30.0 Average reward fake: 0.47613340616226196 Average reward real: 0.5093998908996582 Training q_loss: 2580007.5000 Training g_loss: 0.7427 Training d_loss: 1.3268 Explore P: 0.7690\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 122 Total reward: 38.0 Average reward fake: 0.48864465951919556 Average reward real: 0.510252833366394 Training q_loss: 1709684.3750 Training g_loss: 0.7170 Training d_loss: 1.3522 Explore P: 0.7661\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 123 Total reward: 55.0 Average reward fake: 0.47848907113075256 Average reward real: 0.5022315979003906 Training q_loss: 18267514.0000 Training g_loss: 0.7426 Training d_loss: 1.3570 Explore P: 0.7620\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 124 Total reward: 33.0 Average reward fake: 0.48654741048812866 Average reward real: 0.4957464635372162 Training q_loss: 10728599.0000 Training g_loss: 0.7215 Training d_loss: 1.3733 Explore P: 0.7595\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 125 Total reward: 14.0 Average reward fake: 0.5086663961410522 Average reward real: 0.5082839131355286 Training q_loss: 2962110.5000 Training g_loss: 0.6774 Training d_loss: 1.3926 Explore P: 0.7585\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 126 Total reward: 32.0 Average reward fake: 0.5053292512893677 Average reward real: 0.5400079488754272 Training q_loss: 10880570.0000 Training g_loss: 0.6852 Training d_loss: 1.3303 Explore P: 0.7561\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 127 Total reward: 24.0 Average reward fake: 0.49798232316970825 Average reward real: 0.5425024628639221 Training q_loss: 1326837.5000 Training g_loss: 0.6972 Training d_loss: 1.3081 Explore P: 0.7543\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 128 Total reward: 16.0 Average reward fake: 0.4903329014778137 Average reward real: 0.5068495869636536 Training q_loss: 4291672.0000 Training g_loss: 0.7183 Training d_loss: 1.3658 Explore P: 0.7531\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 129 Total reward: 61.0 Average reward fake: 0.47589951753616333 Average reward real: 0.5049576163291931 Training q_loss: 1441409.2500 Training g_loss: 0.7428 Training d_loss: 1.3334 Explore P: 0.7486\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 130 Total reward: 40.0 Average reward fake: 0.5001288652420044 Average reward real: 0.5113186836242676 Training q_loss: 2259814.5000 Training g_loss: 0.6947 Training d_loss: 1.3700 Explore P: 0.7456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 131 Total reward: 40.0 Average reward fake: 0.5196232795715332 Average reward real: 0.5099211931228638 Training q_loss: 2149444.7500 Training g_loss: 0.6666 Training d_loss: 1.4267 Explore P: 0.7427\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 132 Total reward: 43.0 Average reward fake: 0.47800859808921814 Average reward real: 0.5273393988609314 Training q_loss: 1544116.2500 Training g_loss: 0.7386 Training d_loss: 1.2961 Explore P: 0.7395\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 133 Total reward: 51.0 Average reward fake: 0.49436134099960327 Average reward real: 0.5135723948478699 Training q_loss: 3187542.7500 Training g_loss: 0.7079 Training d_loss: 1.3533 Explore P: 0.7358\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 134 Total reward: 43.0 Average reward fake: 0.4568637013435364 Average reward real: 0.5629000067710876 Training q_loss: 6182150.5000 Training g_loss: 0.8001 Training d_loss: 1.2125 Explore P: 0.7327\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 135 Total reward: 20.0 Average reward fake: 0.5171279311180115 Average reward real: 0.5342438220977783 Training q_loss: 1769228.2500 Training g_loss: 0.6691 Training d_loss: 1.3727 Explore P: 0.7313\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 136 Total reward: 104.0 Average reward fake: 0.4725217819213867 Average reward real: 0.5707218647003174 Training q_loss: 1881996.3750 Training g_loss: 0.7781 Training d_loss: 1.2512 Explore P: 0.7238\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 137 Total reward: 12.0 Average reward fake: 0.5153475403785706 Average reward real: 0.4916214346885681 Training q_loss: 18600868.0000 Training g_loss: 0.6933 Training d_loss: 1.5118 Explore P: 0.7229\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 138 Total reward: 56.0 Average reward fake: 0.4452667236328125 Average reward real: 0.5099351406097412 Training q_loss: 2539717.5000 Training g_loss: 0.8442 Training d_loss: 1.3426 Explore P: 0.7190\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 139 Total reward: 58.0 Average reward fake: 0.45033225417137146 Average reward real: 0.5680059194564819 Training q_loss: 1300271.5000 Training g_loss: 0.8306 Training d_loss: 1.2168 Explore P: 0.7149\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 140 Total reward: 10.0 Average reward fake: 0.42819246649742126 Average reward real: 0.5903957486152649 Training q_loss: 2059861.7500 Training g_loss: 0.8964 Training d_loss: 1.1698 Explore P: 0.7142\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 141 Total reward: 27.0 Average reward fake: 0.4760950207710266 Average reward real: 0.5193063020706177 Training q_loss: 1306259.6250 Training g_loss: 0.7942 Training d_loss: 1.4061 Explore P: 0.7123\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 142 Total reward: 69.0 Average reward fake: 0.5127770900726318 Average reward real: 0.4512568414211273 Training q_loss: 2541165.2500 Training g_loss: 0.6692 Training d_loss: 1.5438 Explore P: 0.7074\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 143 Total reward: 29.0 Average reward fake: 0.47791439294815063 Average reward real: 0.5419687628746033 Training q_loss: 1729318.3750 Training g_loss: 0.7383 Training d_loss: 1.2722 Explore P: 0.7054\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 144 Total reward: 161.0 Average reward fake: 0.5305007696151733 Average reward real: 0.5446631908416748 Training q_loss: 669992.3125 Training g_loss: 0.6343 Training d_loss: 1.3740 Explore P: 0.6943\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 145 Total reward: 27.0 Average reward fake: 0.5090929865837097 Average reward real: 0.5144997835159302 Training q_loss: 1647781.8750 Training g_loss: 0.6868 Training d_loss: 1.4073 Explore P: 0.6925\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 146 Total reward: 14.0 Average reward fake: 0.5332194566726685 Average reward real: 0.5967639684677124 Training q_loss: 1711317.0000 Training g_loss: 0.6296 Training d_loss: 1.2845 Explore P: 0.6915\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 147 Total reward: 51.0 Average reward fake: 0.4952794909477234 Average reward real: 0.5041829347610474 Training q_loss: 1362184.7500 Training g_loss: 0.7201 Training d_loss: 1.3980 Explore P: 0.6880\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 148 Total reward: 30.0 Average reward fake: 0.48479923605918884 Average reward real: 0.4543762803077698 Training q_loss: 1097147.7500 Training g_loss: 0.7241 Training d_loss: 1.4567 Explore P: 0.6860\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 149 Total reward: 21.0 Average reward fake: 0.4908227324485779 Average reward real: 0.46519988775253296 Training q_loss: 4065397.5000 Training g_loss: 0.7124 Training d_loss: 1.4440 Explore P: 0.6846\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 150 Total reward: 18.0 Average reward fake: 0.468593031167984 Average reward real: 0.4994088113307953 Training q_loss: 1176588.5000 Training g_loss: 0.7598 Training d_loss: 1.3306 Explore P: 0.6834\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 151 Total reward: 25.0 Average reward fake: 0.46580010652542114 Average reward real: 0.45802292227745056 Training q_loss: 741561.6875 Training g_loss: 0.7643 Training d_loss: 1.4201 Explore P: 0.6817\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 152 Total reward: 11.0 Average reward fake: 0.4514792859554291 Average reward real: 0.439196914434433 Training q_loss: 1499085.7500 Training g_loss: 0.7953 Training d_loss: 1.4292 Explore P: 0.6810\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 153 Total reward: 109.0 Average reward fake: 0.48848623037338257 Average reward real: 0.5311070680618286 Training q_loss: 989057.1250 Training g_loss: 0.7204 Training d_loss: 1.3306 Explore P: 0.6737\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 154 Total reward: 52.0 Average reward fake: 0.5454437732696533 Average reward real: 0.4713326394557953 Training q_loss: 812480.8750 Training g_loss: 0.6064 Training d_loss: 1.5562 Explore P: 0.6702\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 155 Total reward: 18.0 Average reward fake: 0.48243555426597595 Average reward real: 0.5439155101776123 Training q_loss: 1326668.2500 Training g_loss: 0.7295 Training d_loss: 1.2832 Explore P: 0.6691\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 156 Total reward: 58.0 Average reward fake: 0.5287150740623474 Average reward real: 0.39926570653915405 Training q_loss: 1271865.2500 Training g_loss: 0.6397 Training d_loss: 1.7238 Explore P: 0.6652\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 157 Total reward: 30.0 Average reward fake: 0.5135952830314636 Average reward real: 0.46387118101119995 Training q_loss: 615892.0625 Training g_loss: 0.6664 Training d_loss: 1.4940 Explore P: 0.6633\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 158 Total reward: 40.0 Average reward fake: 0.45870286226272583 Average reward real: 0.5170117020606995 Training q_loss: 1243204.8750 Training g_loss: 0.7800 Training d_loss: 1.2993 Explore P: 0.6607\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 159 Total reward: 71.0 Average reward fake: 0.45923343300819397 Average reward real: 0.5462791323661804 Training q_loss: 679488.5625 Training g_loss: 0.7783 Training d_loss: 1.2752 Explore P: 0.6561\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 160 Total reward: 45.0 Average reward fake: 0.5031020641326904 Average reward real: 0.5464190244674683 Training q_loss: 532583.3125 Training g_loss: 0.6877 Training d_loss: 1.3124 Explore P: 0.6532\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 161 Total reward: 104.0 Average reward fake: 0.46855688095092773 Average reward real: 0.5038563013076782 Training q_loss: 591541.3750 Training g_loss: 0.7582 Training d_loss: 1.3265 Explore P: 0.6465\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 162 Total reward: 107.0 Average reward fake: 0.5027928948402405 Average reward real: 0.4888199269771576 Training q_loss: 504957.1875 Training g_loss: 0.6877 Training d_loss: 1.4419 Explore P: 0.6397\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 163 Total reward: 138.0 Average reward fake: 0.49423637986183167 Average reward real: 0.4997483789920807 Training q_loss: 606957.2500 Training g_loss: 0.7051 Training d_loss: 1.4036 Explore P: 0.6311\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 164 Total reward: 53.0 Average reward fake: 0.5070425271987915 Average reward real: 0.5201699137687683 Training q_loss: 182628.5938 Training g_loss: 0.6792 Training d_loss: 1.3628 Explore P: 0.6278\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 165 Total reward: 49.0 Average reward fake: 0.4978176951408386 Average reward real: 0.5092164874076843 Training q_loss: 461510.3438 Training g_loss: 0.6978 Training d_loss: 1.3721 Explore P: 0.6248\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 166 Total reward: 122.0 Average reward fake: 0.46594247221946716 Average reward real: 0.5125113725662231 Training q_loss: 712409.1875 Training g_loss: 0.7670 Training d_loss: 1.3127 Explore P: 0.6173\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 167 Total reward: 49.0 Average reward fake: 0.49118319153785706 Average reward real: 0.4529809057712555 Training q_loss: 247769.2031 Training g_loss: 0.7147 Training d_loss: 1.4804 Explore P: 0.6144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 168 Total reward: 9.0 Average reward fake: 0.49372783303260803 Average reward real: 0.5011276006698608 Training q_loss: 966752.3750 Training g_loss: 0.7071 Training d_loss: 1.3795 Explore P: 0.6138\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 169 Total reward: 38.0 Average reward fake: 0.4557797908782959 Average reward real: 0.5219904780387878 Training q_loss: 640953.8125 Training g_loss: 0.7859 Training d_loss: 1.2642 Explore P: 0.6115\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 170 Total reward: 34.0 Average reward fake: 0.45995378494262695 Average reward real: 0.5220548510551453 Training q_loss: 728278.1875 Training g_loss: 0.7790 Training d_loss: 1.2846 Explore P: 0.6095\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 171 Total reward: 90.0 Average reward fake: 0.5087719559669495 Average reward real: 0.4554561972618103 Training q_loss: 62747.5312 Training g_loss: 0.6787 Training d_loss: 1.5037 Explore P: 0.6041\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 172 Total reward: 24.0 Average reward fake: 0.48368149995803833 Average reward real: 0.506637692451477 Training q_loss: 340519.9375 Training g_loss: 0.7269 Training d_loss: 1.3428 Explore P: 0.6027\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 173 Total reward: 25.0 Average reward fake: 0.4885452687740326 Average reward real: 0.5521872639656067 Training q_loss: 12949387.0000 Training g_loss: 0.7163 Training d_loss: 1.2761 Explore P: 0.6012\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 174 Total reward: 14.0 Average reward fake: 0.5015465021133423 Average reward real: 0.5607196092605591 Training q_loss: 207861.4531 Training g_loss: 0.6901 Training d_loss: 1.2972 Explore P: 0.6004\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 175 Total reward: 32.0 Average reward fake: 0.46226364374160767 Average reward real: 0.4805367588996887 Training q_loss: 257442.2812 Training g_loss: 0.7753 Training d_loss: 1.3744 Explore P: 0.5985\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 176 Total reward: 122.0 Average reward fake: 0.42840152978897095 Average reward real: 0.4667472839355469 Training q_loss: 707062.1250 Training g_loss: 0.8541 Training d_loss: 1.3342 Explore P: 0.5914\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 177 Total reward: 13.0 Average reward fake: 0.41069167852401733 Average reward real: 0.4731658101081848 Training q_loss: 1471029.5000 Training g_loss: 0.9009 Training d_loss: 1.2867 Explore P: 0.5906\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 178 Total reward: 41.0 Average reward fake: 0.47019463777542114 Average reward real: 0.503298282623291 Training q_loss: 510168.8125 Training g_loss: 0.7610 Training d_loss: 1.3373 Explore P: 0.5882\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 179 Total reward: 33.0 Average reward fake: 0.5696282386779785 Average reward real: 0.5532469749450684 Training q_loss: 633255.9375 Training g_loss: 0.5640 Training d_loss: 1.4400 Explore P: 0.5863\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 180 Total reward: 43.0 Average reward fake: 0.5039297938346863 Average reward real: 0.5249658226966858 Training q_loss: 245160.5938 Training g_loss: 0.6949 Training d_loss: 1.3644 Explore P: 0.5839\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 181 Total reward: 36.0 Average reward fake: 0.471850723028183 Average reward real: 0.491213321685791 Training q_loss: 342249.5938 Training g_loss: 0.7624 Training d_loss: 1.3801 Explore P: 0.5818\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 182 Total reward: 118.0 Average reward fake: 0.4517316222190857 Average reward real: 0.5497558116912842 Training q_loss: 204867.5938 Training g_loss: 0.7969 Training d_loss: 1.2094 Explore P: 0.5751\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 183 Total reward: 114.0 Average reward fake: 0.598014235496521 Average reward real: 0.514012336730957 Training q_loss: 325536.4375 Training g_loss: 0.5204 Training d_loss: 1.6031 Explore P: 0.5687\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 184 Total reward: 55.0 Average reward fake: 0.4665389955043793 Average reward real: 0.6163111925125122 Training q_loss: 178000.7188 Training g_loss: 0.7801 Training d_loss: 1.1626 Explore P: 0.5656\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 185 Total reward: 19.0 Average reward fake: 0.49615684151649475 Average reward real: 0.5675538182258606 Training q_loss: 189611.2656 Training g_loss: 0.7127 Training d_loss: 1.3192 Explore P: 0.5646\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 186 Total reward: 139.0 Average reward fake: 0.5615941286087036 Average reward real: 0.540309488773346 Training q_loss: 315944.5938 Training g_loss: 0.5791 Training d_loss: 1.4502 Explore P: 0.5569\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 187 Total reward: 77.0 Average reward fake: 0.5071635246276855 Average reward real: 0.5853133201599121 Training q_loss: 575646.5000 Training g_loss: 0.6796 Training d_loss: 1.3055 Explore P: 0.5527\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 188 Total reward: 92.0 Average reward fake: 0.4818490147590637 Average reward real: 0.44831380248069763 Training q_loss: 145824.8438 Training g_loss: 0.7302 Training d_loss: 1.4775 Explore P: 0.5478\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 189 Total reward: 35.0 Average reward fake: 0.4444018006324768 Average reward real: 0.6212700605392456 Training q_loss: 100979.0469 Training g_loss: 0.8132 Training d_loss: 1.1055 Explore P: 0.5459\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 190 Total reward: 22.0 Average reward fake: 0.5060478448867798 Average reward real: 0.5559972524642944 Training q_loss: 318900.5938 Training g_loss: 0.6818 Training d_loss: 1.3527 Explore P: 0.5447\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 191 Total reward: 15.0 Average reward fake: 0.6031402349472046 Average reward real: 0.6062561273574829 Training q_loss: 549277.8750 Training g_loss: 0.5058 Training d_loss: 1.4455 Explore P: 0.5439\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 192 Total reward: 199.0 Average reward fake: 0.48645949363708496 Average reward real: 0.44196152687072754 Training q_loss: 2022242.3750 Training g_loss: 0.7221 Training d_loss: 1.4885 Explore P: 0.5334\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 193 Total reward: 33.0 Average reward fake: 0.45181459188461304 Average reward real: 0.5350688695907593 Training q_loss: 64064.1016 Training g_loss: 0.7960 Training d_loss: 1.2440 Explore P: 0.5317\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 194 Total reward: 28.0 Average reward fake: 0.48351389169692993 Average reward real: 0.5047318935394287 Training q_loss: 123509.1250 Training g_loss: 0.7267 Training d_loss: 1.3591 Explore P: 0.5302\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 195 Total reward: 15.0 Average reward fake: 0.47810250520706177 Average reward real: 0.529161810874939 Training q_loss: 68041.5938 Training g_loss: 0.7391 Training d_loss: 1.3084 Explore P: 0.5294\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 196 Total reward: 22.0 Average reward fake: 0.4803953766822815 Average reward real: 0.5463365316390991 Training q_loss: 328966.2500 Training g_loss: 0.7389 Training d_loss: 1.2708 Explore P: 0.5283\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 197 Total reward: 88.0 Average reward fake: 0.49283409118652344 Average reward real: 0.5879460573196411 Training q_loss: 3474187.5000 Training g_loss: 0.7094 Training d_loss: 1.2320 Explore P: 0.5237\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 198 Total reward: 121.0 Average reward fake: 0.4462684988975525 Average reward real: 0.5151899456977844 Training q_loss: 323973.1250 Training g_loss: 0.8182 Training d_loss: 1.2753 Explore P: 0.5176\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 199 Total reward: 95.0 Average reward fake: 0.48280850052833557 Average reward real: 0.5020818114280701 Training q_loss: 214564.5000 Training g_loss: 0.7374 Training d_loss: 1.3652 Explore P: 0.5128\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 200 Total reward: 66.0 Average reward fake: 0.4126608371734619 Average reward real: 0.5661693811416626 Training q_loss: 189093.2656 Training g_loss: 0.9178 Training d_loss: 1.1321 Explore P: 0.5094\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 201 Total reward: 104.0 Average reward fake: 0.45706987380981445 Average reward real: 0.592605471611023 Training q_loss: 210949.2969 Training g_loss: 0.7856 Training d_loss: 1.1550 Explore P: 0.5043\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 202 Total reward: 199.0 Average reward fake: 0.4408842623233795 Average reward real: 0.5320364236831665 Training q_loss: 272088.3750 Training g_loss: 0.8292 Training d_loss: 1.2470 Explore P: 0.4945\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 203 Total reward: 107.0 Average reward fake: 0.5166668891906738 Average reward real: 0.5951293706893921 Training q_loss: 87372.7656 Training g_loss: 0.6906 Training d_loss: 1.3020 Explore P: 0.4894\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 204 Total reward: 81.0 Average reward fake: 0.4697950482368469 Average reward real: 0.6061686277389526 Training q_loss: 224848.5938 Training g_loss: 0.7612 Training d_loss: 1.1685 Explore P: 0.4855\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 205 Total reward: 94.0 Average reward fake: 0.4469313621520996 Average reward real: 0.6100872755050659 Training q_loss: 1723226.7500 Training g_loss: 0.8573 Training d_loss: 1.1446 Explore P: 0.4811\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 206 Total reward: 125.0 Average reward fake: 0.37936311960220337 Average reward real: 0.6039729118347168 Training q_loss: 9805836.0000 Training g_loss: 1.0075 Training d_loss: 1.0254 Explore P: 0.4752\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 207 Total reward: 96.0 Average reward fake: 0.46887797117233276 Average reward real: 0.5601934790611267 Training q_loss: 223083.2031 Training g_loss: 0.7620 Training d_loss: 1.2424 Explore P: 0.4708\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 208 Total reward: 47.0 Average reward fake: 0.38330894708633423 Average reward real: 0.5044348835945129 Training q_loss: 59326.8320 Training g_loss: 0.9775 Training d_loss: 1.1944 Explore P: 0.4686\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 209 Total reward: 71.0 Average reward fake: 0.41314858198165894 Average reward real: 0.48632001876831055 Training q_loss: 4020848.5000 Training g_loss: 1.0605 Training d_loss: 1.4836 Explore P: 0.4654\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 210 Total reward: 99.0 Average reward fake: 0.27363166213035583 Average reward real: 0.6379634737968445 Training q_loss: 209153.1562 Training g_loss: 2.8541 Training d_loss: 0.9224 Explore P: 0.4609\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 211 Total reward: 100.0 Average reward fake: 0.5333483815193176 Average reward real: 0.5970553755760193 Training q_loss: 3180627.2500 Training g_loss: 0.7688 Training d_loss: 1.3624 Explore P: 0.4564\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 212 Total reward: 135.0 Average reward fake: 0.5124189853668213 Average reward real: 0.6484874486923218 Training q_loss: 254379.3438 Training g_loss: 0.7887 Training d_loss: 1.2627 Explore P: 0.4504\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 213 Total reward: 59.0 Average reward fake: 0.5041924715042114 Average reward real: 0.4780915677547455 Training q_loss: 149421.9219 Training g_loss: 0.7248 Training d_loss: 1.6265 Explore P: 0.4478\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 214 Total reward: 120.0 Average reward fake: 0.4330577254295349 Average reward real: 0.47047919034957886 Training q_loss: 21303372.0000 Training g_loss: 0.8394 Training d_loss: 1.3628 Explore P: 0.4426\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 215 Total reward: 154.0 Average reward fake: 0.4807514548301697 Average reward real: 0.4922524094581604 Training q_loss: 209049.5312 Training g_loss: 0.7324 Training d_loss: 1.3703 Explore P: 0.4360\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 216 Total reward: 88.0 Average reward fake: 0.4779689908027649 Average reward real: 0.4670953154563904 Training q_loss: 225226.2500 Training g_loss: 0.7386 Training d_loss: 1.4179 Explore P: 0.4323\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 217 Total reward: 91.0 Average reward fake: 0.5089448690414429 Average reward real: 0.4940066337585449 Training q_loss: 383236.6250 Training g_loss: 0.6781 Training d_loss: 1.4387 Explore P: 0.4284\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 218 Total reward: 148.0 Average reward fake: 0.5328911542892456 Average reward real: 0.4343951642513275 Training q_loss: 170601.2344 Training g_loss: 0.6305 Training d_loss: 1.6697 Explore P: 0.4223\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 219 Total reward: 175.0 Average reward fake: 0.5683662295341492 Average reward real: 0.5016289949417114 Training q_loss: 177398.8125 Training g_loss: 0.5657 Training d_loss: 1.5378 Explore P: 0.4151\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 220 Total reward: 12.0 Average reward fake: 0.528706967830658 Average reward real: 0.5282647013664246 Training q_loss: 162970.7812 Training g_loss: 0.6373 Training d_loss: 1.3916 Explore P: 0.4146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 221 Total reward: 128.0 Average reward fake: 0.4209541380405426 Average reward real: 0.4597701132297516 Training q_loss: 108818.8125 Training g_loss: 0.8677 Training d_loss: 1.3614 Explore P: 0.4095\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 222 Total reward: 106.0 Average reward fake: 0.47030696272850037 Average reward real: 0.5087553858757019 Training q_loss: 164616.5312 Training g_loss: 0.7544 Training d_loss: 1.3186 Explore P: 0.4053\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 223 Total reward: 199.0 Average reward fake: 0.49121156334877014 Average reward real: 0.5367767214775085 Training q_loss: 71297.4219 Training g_loss: 0.7109 Training d_loss: 1.3014 Explore P: 0.3975\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 224 Total reward: 158.0 Average reward fake: 0.5141595602035522 Average reward real: 0.4892439842224121 Training q_loss: 425889.0625 Training g_loss: 0.6667 Training d_loss: 1.4460 Explore P: 0.3914\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 225 Total reward: 151.0 Average reward fake: 0.5226191878318787 Average reward real: 0.502387523651123 Training q_loss: 173132.2500 Training g_loss: 0.6490 Training d_loss: 1.4329 Explore P: 0.3857\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 226 Total reward: 14.0 Average reward fake: 0.4992286264896393 Average reward real: 0.5046164393424988 Training q_loss: 89306.4219 Training g_loss: 0.6949 Training d_loss: 1.3789 Explore P: 0.3852\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 227 Total reward: 34.0 Average reward fake: 0.4762139320373535 Average reward real: 0.5197247266769409 Training q_loss: 97723.6875 Training g_loss: 0.7431 Training d_loss: 1.3191 Explore P: 0.3839\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 228 Total reward: 90.0 Average reward fake: 0.4505313038825989 Average reward real: 0.49163728952407837 Training q_loss: 122049.6484 Training g_loss: 0.7982 Training d_loss: 1.3183 Explore P: 0.3806\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 229 Total reward: 199.0 Average reward fake: 0.48987507820129395 Average reward real: 0.5338681936264038 Training q_loss: 261818.5469 Training g_loss: 0.7148 Training d_loss: 1.3151 Explore P: 0.3733\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 230 Total reward: 199.0 Average reward fake: 0.4795336127281189 Average reward real: 0.4619026184082031 Training q_loss: 69378.4453 Training g_loss: 0.7420 Training d_loss: 1.4412 Explore P: 0.3661\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 231 Total reward: 199.0 Average reward fake: 0.4515911936759949 Average reward real: 0.5945852398872375 Training q_loss: 81462.0547 Training g_loss: 0.7978 Training d_loss: 1.1496 Explore P: 0.3591\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 232 Total reward: 179.0 Average reward fake: 0.5818535685539246 Average reward real: 0.4494269788265228 Training q_loss: 137997.5938 Training g_loss: 0.5419 Training d_loss: 1.7481 Explore P: 0.3529\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 233 Total reward: 159.0 Average reward fake: 0.5427787899971008 Average reward real: 0.3623526096343994 Training q_loss: 188202.2969 Training g_loss: 0.6120 Training d_loss: 1.8262 Explore P: 0.3475\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 234 Total reward: 130.0 Average reward fake: 0.5297975540161133 Average reward real: 0.42787814140319824 Training q_loss: 144262.7031 Training g_loss: 0.6398 Training d_loss: 1.6463 Explore P: 0.3431\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 235 Total reward: 199.0 Average reward fake: 0.4951060712337494 Average reward real: 0.6077988743782043 Training q_loss: 155564.7188 Training g_loss: 0.7047 Training d_loss: 1.2139 Explore P: 0.3366\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 236 Total reward: 161.0 Average reward fake: 0.44971466064453125 Average reward real: 0.46129876375198364 Training q_loss: 49109.4453 Training g_loss: 0.7992 Training d_loss: 1.3908 Explore P: 0.3313\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 237 Total reward: 112.0 Average reward fake: 0.5322182774543762 Average reward real: 0.5512603521347046 Training q_loss: 206129.7500 Training g_loss: 0.6313 Training d_loss: 1.3967 Explore P: 0.3278\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 238 Total reward: 137.0 Average reward fake: 0.5009762644767761 Average reward real: 0.5124766230583191 Training q_loss: 33069.9727 Training g_loss: 0.6912 Training d_loss: 1.3703 Explore P: 0.3234\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 239 Total reward: 199.0 Average reward fake: 0.5531086921691895 Average reward real: 0.510715126991272 Training q_loss: 33894.7383 Training g_loss: 0.5922 Training d_loss: 1.4875 Explore P: 0.3173\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 240 Total reward: 182.0 Average reward fake: 0.5152585506439209 Average reward real: 0.47252321243286133 Training q_loss: 7254786.5000 Training g_loss: 0.6634 Training d_loss: 1.4809 Explore P: 0.3117\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 241 Total reward: 199.0 Average reward fake: 0.47973552346229553 Average reward real: 0.45906758308410645 Training q_loss: 593290.3750 Training g_loss: 0.7348 Training d_loss: 1.4550 Explore P: 0.3058\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 242 Total reward: 149.0 Average reward fake: 0.46866464614868164 Average reward real: 0.4994128346443176 Training q_loss: 158589.6094 Training g_loss: 0.7580 Training d_loss: 1.3374 Explore P: 0.3014\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 243 Total reward: 199.0 Average reward fake: 0.497805118560791 Average reward real: 0.5481152534484863 Training q_loss: 60544.1758 Training g_loss: 0.6981 Training d_loss: 1.2946 Explore P: 0.2957\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 244 Total reward: 199.0 Average reward fake: 0.45504364371299744 Average reward real: 0.48191460967063904 Training q_loss: 115702.3594 Training g_loss: 0.7880 Training d_loss: 1.3394 Explore P: 0.2900\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 245 Total reward: 199.0 Average reward fake: 0.47932419180870056 Average reward real: 0.5115817189216614 Training q_loss: 186001.3438 Training g_loss: 0.7378 Training d_loss: 1.3406 Explore P: 0.2845\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 246 Total reward: 199.0 Average reward fake: 0.4631234109401703 Average reward real: 0.500946044921875 Training q_loss: 1866331.3750 Training g_loss: 0.7706 Training d_loss: 1.3221 Explore P: 0.2791\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 247 Total reward: 199.0 Average reward fake: 0.466456800699234 Average reward real: 0.560327410697937 Training q_loss: 59906.6484 Training g_loss: 0.7690 Training d_loss: 1.2367 Explore P: 0.2738\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 248 Total reward: 199.0 Average reward fake: 0.45896825194358826 Average reward real: 0.3570347726345062 Training q_loss: 89837.0391 Training g_loss: 0.7854 Training d_loss: 1.6951 Explore P: 0.2686\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 249 Total reward: 175.0 Average reward fake: 0.45552897453308105 Average reward real: 0.5806179642677307 Training q_loss: 79367.8125 Training g_loss: 0.7866 Training d_loss: 1.1615 Explore P: 0.2641\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 250 Total reward: 185.0 Average reward fake: 0.3537066578865051 Average reward real: 0.5173865556716919 Training q_loss: 31395.4473 Training g_loss: 1.0428 Training d_loss: 1.1243 Explore P: 0.2595\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 251 Total reward: 199.0 Average reward fake: 0.5043708086013794 Average reward real: 0.49849367141723633 Training q_loss: 361239.5312 Training g_loss: 0.6845 Training d_loss: 1.4034 Explore P: 0.2545\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 252 Total reward: 160.0 Average reward fake: 0.4726943373680115 Average reward real: 0.47817859053611755 Training q_loss: 5201357.0000 Training g_loss: 0.7494 Training d_loss: 1.3804 Explore P: 0.2507\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 253 Total reward: 199.0 Average reward fake: 0.47003570199012756 Average reward real: 0.4969155192375183 Training q_loss: 122419.7500 Training g_loss: 0.7551 Training d_loss: 1.3440 Explore P: 0.2459\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 254 Total reward: 199.0 Average reward fake: 0.5138804316520691 Average reward real: 0.5903687477111816 Training q_loss: 60498.7266 Training g_loss: 0.6659 Training d_loss: 1.2578 Explore P: 0.2413\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 255 Total reward: 199.0 Average reward fake: 0.5087089538574219 Average reward real: 0.47334736585617065 Training q_loss: 63171.5859 Training g_loss: 0.6759 Training d_loss: 1.4634 Explore P: 0.2367\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 256 Total reward: 199.0 Average reward fake: 0.49060407280921936 Average reward real: 0.4797055721282959 Training q_loss: 40289.8633 Training g_loss: 0.7122 Training d_loss: 1.4116 Explore P: 0.2323\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 257 Total reward: 199.0 Average reward fake: 0.5289864540100098 Average reward real: 0.5229449272155762 Training q_loss: 97324.1797 Training g_loss: 0.6368 Training d_loss: 1.4024 Explore P: 0.2279\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 258 Total reward: 169.0 Average reward fake: 0.5051342248916626 Average reward real: 0.5235673189163208 Training q_loss: 44268.7852 Training g_loss: 0.6869 Training d_loss: 1.3651 Explore P: 0.2242\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 259 Total reward: 199.0 Average reward fake: 0.5731322169303894 Average reward real: 0.537179172039032 Training q_loss: 109242.0234 Training g_loss: 0.5568 Training d_loss: 1.4866 Explore P: 0.2200\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 260 Total reward: 199.0 Average reward fake: 0.48196157813072205 Average reward real: 0.5001532435417175 Training q_loss: 62305.3242 Training g_loss: 0.7307 Training d_loss: 1.3599 Explore P: 0.2159\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 261 Total reward: 199.0 Average reward fake: 0.48460444808006287 Average reward real: 0.6136366724967957 Training q_loss: 49340.5625 Training g_loss: 0.7258 Training d_loss: 1.1803 Explore P: 0.2118\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 262 Total reward: 199.0 Average reward fake: 0.5277706384658813 Average reward real: 0.5389887094497681 Training q_loss: 1359010.7500 Training g_loss: 0.6410 Training d_loss: 1.4022 Explore P: 0.2078\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 263 Total reward: 199.0 Average reward fake: 0.45957159996032715 Average reward real: 0.5066767334938049 Training q_loss: 35963.4844 Training g_loss: 0.7775 Training d_loss: 1.2996 Explore P: 0.2039\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 264 Total reward: 199.0 Average reward fake: 0.4952748715877533 Average reward real: 0.6016802191734314 Training q_loss: 53728.4570 Training g_loss: 0.7027 Training d_loss: 1.2009 Explore P: 0.2001\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 265 Total reward: 199.0 Average reward fake: 0.4524570107460022 Average reward real: 0.5081146359443665 Training q_loss: 35551.7773 Training g_loss: 0.7931 Training d_loss: 1.2840 Explore P: 0.1964\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 266 Total reward: 199.0 Average reward fake: 0.4727707505226135 Average reward real: 0.605562686920166 Training q_loss: 54237.7930 Training g_loss: 0.7599 Training d_loss: 1.1800 Explore P: 0.1927\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 267 Total reward: 199.0 Average reward fake: 0.47517338395118713 Average reward real: 0.5032380819320679 Training q_loss: 51268.7422 Training g_loss: 0.7461 Training d_loss: 1.3509 Explore P: 0.1891\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 268 Total reward: 195.0 Average reward fake: 0.5243651270866394 Average reward real: 0.49644985795021057 Training q_loss: 182532.5156 Training g_loss: 0.6457 Training d_loss: 1.4734 Explore P: 0.1856\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 269 Total reward: 199.0 Average reward fake: 0.5048352479934692 Average reward real: 0.48923397064208984 Training q_loss: 18194.0273 Training g_loss: 0.6836 Training d_loss: 1.4221 Explore P: 0.1822\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 270 Total reward: 199.0 Average reward fake: 0.48261141777038574 Average reward real: 0.5414355397224426 Training q_loss: 63969.7617 Training g_loss: 0.7286 Training d_loss: 1.2825 Explore P: 0.1788\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 271 Total reward: 199.0 Average reward fake: 0.5169879794120789 Average reward real: 0.5311323404312134 Training q_loss: 49884.4609 Training g_loss: 0.6641 Training d_loss: 1.3701 Explore P: 0.1755\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 272 Total reward: 199.0 Average reward fake: 0.48060721158981323 Average reward real: 0.5113149881362915 Training q_loss: 35351.0703 Training g_loss: 0.7346 Training d_loss: 1.3303 Explore P: 0.1722\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 273 Total reward: 199.0 Average reward fake: 0.504515528678894 Average reward real: 0.46504926681518555 Training q_loss: 39985.1953 Training g_loss: 0.6860 Training d_loss: 1.4790 Explore P: 0.1690\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 274 Total reward: 199.0 Average reward fake: 0.4886525571346283 Average reward real: 0.4438369870185852 Training q_loss: 15891.8262 Training g_loss: 0.7161 Training d_loss: 1.4890 Explore P: 0.1659\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 275 Total reward: 199.0 Average reward fake: 0.5200125575065613 Average reward real: 0.5006013512611389 Training q_loss: 53477.3047 Training g_loss: 0.6540 Training d_loss: 1.4450 Explore P: 0.1628\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 276 Total reward: 199.0 Average reward fake: 0.48829594254493713 Average reward real: 0.47699204087257385 Training q_loss: 7291.4116 Training g_loss: 0.7177 Training d_loss: 1.4224 Explore P: 0.1598\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 277 Total reward: 199.0 Average reward fake: 0.585004985332489 Average reward real: 0.6277991533279419 Training q_loss: 17215.5137 Training g_loss: 0.5368 Training d_loss: 1.3958 Explore P: 0.1568\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 278 Total reward: 199.0 Average reward fake: 0.5486668348312378 Average reward real: 0.4086364209651947 Training q_loss: 57581.5117 Training g_loss: 0.6009 Training d_loss: 1.8041 Explore P: 0.1539\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 279 Total reward: 199.0 Average reward fake: 0.40930014848709106 Average reward real: 0.5597687363624573 Training q_loss: 14872.9424 Training g_loss: 0.8939 Training d_loss: 1.1146 Explore P: 0.1511\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 280 Total reward: 199.0 Average reward fake: 0.5054563283920288 Average reward real: 0.5321569442749023 Training q_loss: 14121.5518 Training g_loss: 0.6823 Training d_loss: 1.3389 Explore P: 0.1483\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 281 Total reward: 199.0 Average reward fake: 0.43942227959632874 Average reward real: 0.49828267097473145 Training q_loss: 7580.3057 Training g_loss: 0.8225 Training d_loss: 1.2862 Explore P: 0.1456\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 282 Total reward: 199.0 Average reward fake: 0.49164313077926636 Average reward real: 0.4792170524597168 Training q_loss: 14982.9873 Training g_loss: 0.7100 Training d_loss: 1.4140 Explore P: 0.1429\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 283 Total reward: 199.0 Average reward fake: 0.48958078026771545 Average reward real: 0.4826985001564026 Training q_loss: 21219.1289 Training g_loss: 0.7143 Training d_loss: 1.4109 Explore P: 0.1403\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 284 Total reward: 199.0 Average reward fake: 0.43096789717674255 Average reward real: 0.4967823028564453 Training q_loss: 4467.7021 Training g_loss: 0.8421 Training d_loss: 1.2769 Explore P: 0.1377\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 285 Total reward: 199.0 Average reward fake: 0.4584880471229553 Average reward real: 0.5216683149337769 Training q_loss: 17916.1914 Training g_loss: 0.7801 Training d_loss: 1.2874 Explore P: 0.1352\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 286 Total reward: 199.0 Average reward fake: 0.4683231711387634 Average reward real: 0.49587616324424744 Training q_loss: 2795.0305 Training g_loss: 0.7586 Training d_loss: 1.3445 Explore P: 0.1328\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 287 Total reward: 199.0 Average reward fake: 0.3617269992828369 Average reward real: 0.43777161836624146 Training q_loss: 1789.7181 Training g_loss: 1.0197 Training d_loss: 1.2823 Explore P: 0.1303\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 288 Total reward: 199.0 Average reward fake: 0.5418668985366821 Average reward real: 0.44808536767959595 Training q_loss: 3456.9219 Training g_loss: 0.6175 Training d_loss: 1.6070 Explore P: 0.1280\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 289 Total reward: 199.0 Average reward fake: 0.47045737504959106 Average reward real: 0.4867289960384369 Training q_loss: 4757.9102 Training g_loss: 0.7548 Training d_loss: 1.3761 Explore P: 0.1256\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 290 Total reward: 166.0 Average reward fake: 0.5020464658737183 Average reward real: 0.551505446434021 Training q_loss: 26672.8242 Training g_loss: 0.6892 Training d_loss: 1.2962 Explore P: 0.1237\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 291 Total reward: 184.0 Average reward fake: 0.4808802008628845 Average reward real: 0.47760170698165894 Training q_loss: 3743.6929 Training g_loss: 0.7331 Training d_loss: 1.3975 Explore P: 0.1217\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 292 Total reward: 199.0 Average reward fake: 0.5027331113815308 Average reward real: 0.4976791739463806 Training q_loss: 1445.1355 Training g_loss: 0.6895 Training d_loss: 1.3999 Explore P: 0.1195\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 293 Total reward: 199.0 Average reward fake: 0.512472927570343 Average reward real: 0.5103909969329834 Training q_loss: 1417.0901 Training g_loss: 0.6685 Training d_loss: 1.3997 Explore P: 0.1173\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 294 Total reward: 199.0 Average reward fake: 0.45020025968551636 Average reward real: 0.5073667764663696 Training q_loss: 2420.7119 Training g_loss: 0.7982 Training d_loss: 1.2889 Explore P: 0.1152\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 295 Total reward: 199.0 Average reward fake: 0.4873797297477722 Average reward real: 0.45503878593444824 Training q_loss: 1540.9889 Training g_loss: 0.7188 Training d_loss: 1.4618 Explore P: 0.1131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 296 Total reward: 175.0 Average reward fake: 0.5839613676071167 Average reward real: 0.35278964042663574 Training q_loss: 1132.5769 Training g_loss: 0.5380 Training d_loss: 2.0041 Explore P: 0.1113\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 297 Total reward: 199.0 Average reward fake: 0.4957639276981354 Average reward real: 0.4568449854850769 Training q_loss: 1846.5192 Training g_loss: 0.7020 Training d_loss: 1.4873 Explore P: 0.1093\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 298 Total reward: 199.0 Average reward fake: 0.5084440112113953 Average reward real: 0.5254307985305786 Training q_loss: 4059.4712 Training g_loss: 0.6767 Training d_loss: 1.3589 Explore P: 0.1074\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 299 Total reward: 125.0 Average reward fake: 0.4851086735725403 Average reward real: 0.4743422865867615 Training q_loss: 3159.4475 Training g_loss: 0.7307 Training d_loss: 1.4233 Explore P: 0.1062\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 300 Total reward: 199.0 Average reward fake: 0.5125598311424255 Average reward real: 0.48914116621017456 Training q_loss: 762.8004 Training g_loss: 0.6683 Training d_loss: 1.4362 Explore P: 0.1043\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 301 Total reward: 199.0 Average reward fake: 0.5227876305580139 Average reward real: 0.5084923505783081 Training q_loss: 38246.5703 Training g_loss: 0.6486 Training d_loss: 1.4197 Explore P: 0.1024\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 302 Total reward: 137.0 Average reward fake: 0.5084560513496399 Average reward real: 0.5126768350601196 Training q_loss: 408.9256 Training g_loss: 0.6764 Training d_loss: 1.3870 Explore P: 0.1012\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 303 Total reward: 196.0 Average reward fake: 0.4709390699863434 Average reward real: 0.5274944305419922 Training q_loss: 1129.9135 Training g_loss: 0.7623 Training d_loss: 1.2972 Explore P: 0.0994\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 304 Total reward: 160.0 Average reward fake: 0.5140028595924377 Average reward real: 0.5324109792709351 Training q_loss: 416.3274 Training g_loss: 0.6656 Training d_loss: 1.3529 Explore P: 0.0980\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 305 Total reward: 199.0 Average reward fake: 0.22203734517097473 Average reward real: 0.7324363589286804 Training q_loss: 593.2806 Training g_loss: 1.5190 Training d_loss: 0.5806 Explore P: 0.0962\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 306 Total reward: 199.0 Average reward fake: 0.5543780326843262 Average reward real: 0.5175881385803223 Training q_loss: 682.6568 Training g_loss: 0.5906 Training d_loss: 1.4784 Explore P: 0.0945\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 307 Total reward: 199.0 Average reward fake: 0.4574264585971832 Average reward real: 0.4832600951194763 Training q_loss: 235.4745 Training g_loss: 0.7854 Training d_loss: 1.3533 Explore P: 0.0929\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 308 Total reward: 199.0 Average reward fake: 0.4768713414669037 Average reward real: 0.5148382782936096 Training q_loss: 32808.9062 Training g_loss: 0.7405 Training d_loss: 1.3128 Explore P: 0.0912\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 309 Total reward: 118.0 Average reward fake: 0.50119549036026 Average reward real: 0.5048644542694092 Training q_loss: 237.5402 Training g_loss: 0.6914 Training d_loss: 1.3820 Explore P: 0.0903\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 310 Total reward: 199.0 Average reward fake: 0.4974061846733093 Average reward real: 0.5419581532478333 Training q_loss: 16306.8594 Training g_loss: 0.6982 Training d_loss: 1.3170 Explore P: 0.0887\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 311 Total reward: 199.0 Average reward fake: 0.47906237840652466 Average reward real: 0.46596717834472656 Training q_loss: 186.9172 Training g_loss: 0.7367 Training d_loss: 1.4196 Explore P: 0.0872\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 312 Total reward: 199.0 Average reward fake: 0.558201253414154 Average reward real: 0.4316360354423523 Training q_loss: 312.8121 Training g_loss: 0.5861 Training d_loss: 1.6663 Explore P: 0.0856\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 313 Total reward: 199.0 Average reward fake: 0.5670340061187744 Average reward real: 0.45290058851242065 Training q_loss: 802.2963 Training g_loss: 0.5692 Training d_loss: 1.6590 Explore P: 0.0841\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 314 Total reward: 199.0 Average reward fake: 0.46391090750694275 Average reward real: 0.5560298562049866 Training q_loss: 831.2639 Training g_loss: 0.7851 Training d_loss: 1.2343 Explore P: 0.0827\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 315 Total reward: 199.0 Average reward fake: 0.4004906713962555 Average reward real: 0.3434998691082001 Training q_loss: 2305.7163 Training g_loss: 0.9747 Training d_loss: 2.0095 Explore P: 0.0813\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 316 Total reward: 199.0 Average reward fake: 0.4662416875362396 Average reward real: 0.48531967401504517 Training q_loss: 1041.1526 Training g_loss: 0.7632 Training d_loss: 1.3531 Explore P: 0.0798\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 317 Total reward: 199.0 Average reward fake: 0.5194056630134583 Average reward real: 0.4929206967353821 Training q_loss: 3782.6470 Training g_loss: 0.6552 Training d_loss: 1.4462 Explore P: 0.0785\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 318 Total reward: 199.0 Average reward fake: 0.4543566107749939 Average reward real: 0.4767422080039978 Training q_loss: 21541.1250 Training g_loss: 0.7873 Training d_loss: 1.3533 Explore P: 0.0771\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 319 Total reward: 199.0 Average reward fake: 0.4933333992958069 Average reward real: 0.507712721824646 Training q_loss: 5094.0674 Training g_loss: 0.7077 Training d_loss: 1.3612 Explore P: 0.0758\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 320 Total reward: 199.0 Average reward fake: 0.5092452168464661 Average reward real: 0.5277570486068726 Training q_loss: 2121.7039 Training g_loss: 0.6792 Training d_loss: 1.3630 Explore P: 0.0745\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 321 Total reward: 199.0 Average reward fake: 0.43583646416664124 Average reward real: 0.4382988512516022 Training q_loss: 1047.6310 Training g_loss: 0.8415 Training d_loss: 1.4321 Explore P: 0.0732\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 322 Total reward: 199.0 Average reward fake: 0.5307546854019165 Average reward real: 0.4601603150367737 Training q_loss: 8829.5879 Training g_loss: 0.6335 Training d_loss: 1.5368 Explore P: 0.0720\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 323 Total reward: 199.0 Average reward fake: 0.45099353790283203 Average reward real: 0.48914995789527893 Training q_loss: 5231.6650 Training g_loss: 0.7991 Training d_loss: 1.3258 Explore P: 0.0708\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 324 Total reward: 199.0 Average reward fake: 0.5347397923469543 Average reward real: 0.4464566707611084 Training q_loss: 1781.7115 Training g_loss: 0.6261 Training d_loss: 1.6338 Explore P: 0.0696\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 325 Total reward: 199.0 Average reward fake: 0.49682727456092834 Average reward real: 0.5051576495170593 Training q_loss: 15561.2529 Training g_loss: 0.6996 Training d_loss: 1.3779 Explore P: 0.0684\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 326 Total reward: 199.0 Average reward fake: 0.46945720911026 Average reward real: 0.48706454038619995 Training q_loss: 1478.9213 Training g_loss: 0.7562 Training d_loss: 1.3543 Explore P: 0.0672\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 327 Total reward: 199.0 Average reward fake: 0.5140367746353149 Average reward real: 0.5210767984390259 Training q_loss: 6024.7002 Training g_loss: 0.6655 Training d_loss: 1.3737 Explore P: 0.0661\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 328 Total reward: 199.0 Average reward fake: 0.46822160482406616 Average reward real: 0.4909951090812683 Training q_loss: 3038.2788 Training g_loss: 0.7589 Training d_loss: 1.3445 Explore P: 0.0650\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 329 Total reward: 199.0 Average reward fake: 0.45342081785202026 Average reward real: 0.45497140288352966 Training q_loss: 21929.4941 Training g_loss: 0.8067 Training d_loss: 1.4226 Explore P: 0.0639\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 330 Total reward: 199.0 Average reward fake: 0.5342176556587219 Average reward real: 0.5397757291793823 Training q_loss: 1683.3342 Training g_loss: 0.6275 Training d_loss: 1.3923 Explore P: 0.0629\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 331 Total reward: 199.0 Average reward fake: 0.494273841381073 Average reward real: 0.47953152656555176 Training q_loss: 3790.4368 Training g_loss: 0.7047 Training d_loss: 1.4241 Explore P: 0.0618\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 332 Total reward: 194.0 Average reward fake: 0.4699275493621826 Average reward real: 0.4621620178222656 Training q_loss: 26953.2285 Training g_loss: 0.7565 Training d_loss: 1.4197 Explore P: 0.0608\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 333 Total reward: 199.0 Average reward fake: 0.45712390542030334 Average reward real: 0.532477080821991 Training q_loss: 15833.3955 Training g_loss: 0.7846 Training d_loss: 1.2501 Explore P: 0.0598\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 334 Total reward: 199.0 Average reward fake: 0.34446263313293457 Average reward real: 0.8250309824943542 Training q_loss: 8311.4111 Training g_loss: 1.0733 Training d_loss: 0.6344 Explore P: 0.0588\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 335 Total reward: 199.0 Average reward fake: 0.45344385504722595 Average reward real: 0.49164849519729614 Training q_loss: 5027.4688 Training g_loss: 0.7916 Training d_loss: 1.3488 Explore P: 0.0579\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 336 Total reward: 199.0 Average reward fake: 0.3191106915473938 Average reward real: 0.7428704500198364 Training q_loss: 1734.5713 Training g_loss: 1.1557 Training d_loss: 0.7072 Explore P: 0.0569\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 337 Total reward: 199.0 Average reward fake: 0.4943191111087799 Average reward real: 0.5364636778831482 Training q_loss: 1624.5667 Training g_loss: 0.7045 Training d_loss: 1.3076 Explore P: 0.0560\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 338 Total reward: 199.0 Average reward fake: 0.4981040954589844 Average reward real: 0.5045997500419617 Training q_loss: 6975.8281 Training g_loss: 0.6973 Training d_loss: 1.3777 Explore P: 0.0551\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 339 Total reward: 199.0 Average reward fake: 0.4874235987663269 Average reward real: 0.5138307809829712 Training q_loss: 73299.9062 Training g_loss: 0.7188 Training d_loss: 1.3423 Explore P: 0.0542\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 340 Total reward: 199.0 Average reward fake: 0.4863593578338623 Average reward real: 0.5183174014091492 Training q_loss: 2473.2144 Training g_loss: 0.7211 Training d_loss: 1.3311 Explore P: 0.0533\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 341 Total reward: 199.0 Average reward fake: 0.5166143774986267 Average reward real: 0.5090092420578003 Training q_loss: 18380.0254 Training g_loss: 0.6627 Training d_loss: 1.4066 Explore P: 0.0525\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 342 Total reward: 199.0 Average reward fake: 0.5197896361351013 Average reward real: 0.5090805888175964 Training q_loss: 6516.4634 Training g_loss: 0.6831 Training d_loss: 1.4593 Explore P: 0.0517\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 343 Total reward: 199.0 Average reward fake: 0.47692951560020447 Average reward real: 0.5222846269607544 Training q_loss: 941.9758 Training g_loss: 0.7420 Training d_loss: 1.3010 Explore P: 0.0508\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 344 Total reward: 199.0 Average reward fake: 0.4305400252342224 Average reward real: 0.5307835340499878 Training q_loss: 2517.6582 Training g_loss: 0.8600 Training d_loss: 1.2921 Explore P: 0.0500\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 345 Total reward: 199.0 Average reward fake: 0.5242654085159302 Average reward real: 0.4853530526161194 Training q_loss: 9553.3223 Training g_loss: 0.6459 Training d_loss: 1.4758 Explore P: 0.0492\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 346 Total reward: 199.0 Average reward fake: 0.46787557005882263 Average reward real: 0.38818874955177307 Training q_loss: 13382.6436 Training g_loss: 0.7611 Training d_loss: 1.6073 Explore P: 0.0485\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 347 Total reward: 199.0 Average reward fake: 0.5075169801712036 Average reward real: 0.5543404817581177 Training q_loss: 977.5958 Training g_loss: 0.6798 Training d_loss: 1.3095 Explore P: 0.0477\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 348 Total reward: 197.0 Average reward fake: 0.5359110236167908 Average reward real: 0.5044376850128174 Training q_loss: 397.4476 Training g_loss: 0.6220 Training d_loss: 1.4792 Explore P: 0.0470\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 349 Total reward: 199.0 Average reward fake: 0.4468119740486145 Average reward real: 0.48395103216171265 Training q_loss: 1115.7809 Training g_loss: 0.8057 Training d_loss: 1.3208 Explore P: 0.0462\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 350 Total reward: 199.0 Average reward fake: 0.49195727705955505 Average reward real: 0.4968087077140808 Training q_loss: 6134.9619 Training g_loss: 0.7094 Training d_loss: 1.4056 Explore P: 0.0455\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 351 Total reward: 199.0 Average reward fake: 0.4480728209018707 Average reward real: 0.46467918157577515 Training q_loss: 3959.0300 Training g_loss: 0.8134 Training d_loss: 1.4005 Explore P: 0.0448\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 352 Total reward: 199.0 Average reward fake: 0.4931710362434387 Average reward real: 0.48671427369117737 Training q_loss: 14269.0781 Training g_loss: 0.7069 Training d_loss: 1.4050 Explore P: 0.0441\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 353 Total reward: 199.0 Average reward fake: 0.4963091015815735 Average reward real: 0.4966488480567932 Training q_loss: 4121.3447 Training g_loss: 0.7006 Training d_loss: 1.3923 Explore P: 0.0435\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 354 Total reward: 199.0 Average reward fake: 0.504167377948761 Average reward real: 0.5203746557235718 Training q_loss: 1899.7019 Training g_loss: 0.6849 Training d_loss: 1.3650 Explore P: 0.0428\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 355 Total reward: 199.0 Average reward fake: 0.4367755353450775 Average reward real: 0.4377067983150482 Training q_loss: 3213.9727 Training g_loss: 0.8374 Training d_loss: 1.5488 Explore P: 0.0422\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 356 Total reward: 199.0 Average reward fake: 0.5042639970779419 Average reward real: 0.5011429190635681 Training q_loss: 5911.1309 Training g_loss: 0.6848 Training d_loss: 1.3987 Explore P: 0.0415\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 357 Total reward: 183.0 Average reward fake: 0.4700774550437927 Average reward real: 0.4861453175544739 Training q_loss: 20090.1250 Training g_loss: 0.7549 Training d_loss: 1.3573 Explore P: 0.0410\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 358 Total reward: 199.0 Average reward fake: 0.5098143815994263 Average reward real: 0.5143126249313354 Training q_loss: 7296.9814 Training g_loss: 0.6738 Training d_loss: 1.3810 Explore P: 0.0404\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 359 Total reward: 199.0 Average reward fake: 0.5017932653427124 Average reward real: 0.5053709745407104 Training q_loss: 1521.6514 Training g_loss: 0.6884 Training d_loss: 1.3851 Explore P: 0.0398\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 360 Total reward: 199.0 Average reward fake: 0.48599186539649963 Average reward real: 0.4939705729484558 Training q_loss: 22646.0234 Training g_loss: 0.7216 Training d_loss: 1.3718 Explore P: 0.0392\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 361 Total reward: 199.0 Average reward fake: 0.4729715883731842 Average reward real: 0.5146687626838684 Training q_loss: 2135.3186 Training g_loss: 0.7534 Training d_loss: 1.3160 Explore P: 0.0386\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 362 Total reward: 199.0 Average reward fake: 0.5194573402404785 Average reward real: 0.5125616788864136 Training q_loss: 1755.3795 Training g_loss: 0.6687 Training d_loss: 1.4572 Explore P: 0.0380\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 363 Total reward: 199.0 Average reward fake: 0.43046826124191284 Average reward real: 0.4823596477508545 Training q_loss: 804.4078 Training g_loss: 0.8546 Training d_loss: 1.3617 Explore P: 0.0375\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 364 Total reward: 199.0 Average reward fake: 0.48858270049095154 Average reward real: 0.6138672828674316 Training q_loss: 1419.6592 Training g_loss: 0.7357 Training d_loss: 1.1769 Explore P: 0.0369\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 365 Total reward: 199.0 Average reward fake: 0.42681941390037537 Average reward real: 0.5310165882110596 Training q_loss: 16902.7617 Training g_loss: 0.8545 Training d_loss: 1.1935 Explore P: 0.0364\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 366 Total reward: 199.0 Average reward fake: 0.547306478023529 Average reward real: 0.49384814500808716 Training q_loss: 3993.8203 Training g_loss: 0.6072 Training d_loss: 1.6305 Explore P: 0.0359\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 367 Total reward: 199.0 Average reward fake: 0.48530855774879456 Average reward real: 0.5075966715812683 Training q_loss: 2137.5356 Training g_loss: 0.7232 Training d_loss: 1.3609 Explore P: 0.0354\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 368 Total reward: 199.0 Average reward fake: 0.5219138860702515 Average reward real: 0.49116772413253784 Training q_loss: 1600.2367 Training g_loss: 0.6504 Training d_loss: 1.4541 Explore P: 0.0349\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 369 Total reward: 199.0 Average reward fake: 0.4947262406349182 Average reward real: 0.5091459155082703 Training q_loss: 2329.2788 Training g_loss: 0.7057 Training d_loss: 1.3698 Explore P: 0.0344\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 370 Total reward: 199.0 Average reward fake: 0.4553699493408203 Average reward real: 0.5248810052871704 Training q_loss: 1662.1719 Training g_loss: 0.7886 Training d_loss: 1.2569 Explore P: 0.0339\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 371 Total reward: 199.0 Average reward fake: 0.49902087450027466 Average reward real: 0.510581374168396 Training q_loss: 8773.2012 Training g_loss: 0.6951 Training d_loss: 1.3670 Explore P: 0.0334\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 372 Total reward: 199.0 Average reward fake: 0.4761819839477539 Average reward real: 0.5028318166732788 Training q_loss: 3751.8274 Training g_loss: 0.7443 Training d_loss: 1.3392 Explore P: 0.0330\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 373 Total reward: 199.0 Average reward fake: 0.4501420557498932 Average reward real: 0.5787676572799683 Training q_loss: 1587.8057 Training g_loss: 0.7989 Training d_loss: 1.1976 Explore P: 0.0325\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 374 Total reward: 199.0 Average reward fake: 0.3895912766456604 Average reward real: 0.5976715683937073 Training q_loss: 361.4372 Training g_loss: 0.9427 Training d_loss: 1.0343 Explore P: 0.0321\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 375 Total reward: 199.0 Average reward fake: 0.38995522260665894 Average reward real: 0.5374042391777039 Training q_loss: 2203.7239 Training g_loss: 0.9588 Training d_loss: 1.1528 Explore P: 0.0316\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 376 Total reward: 189.0 Average reward fake: 0.37548941373825073 Average reward real: 0.32011786103248596 Training q_loss: 4608.1714 Training g_loss: 0.9795 Training d_loss: 2.1816 Explore P: 0.0312\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 377 Total reward: 199.0 Average reward fake: 0.3857108950614929 Average reward real: 0.5766059756278992 Training q_loss: 1040.4479 Training g_loss: 0.9527 Training d_loss: 1.1347 Explore P: 0.0308\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 378 Total reward: 199.0 Average reward fake: 0.42454463243484497 Average reward real: 0.5513795018196106 Training q_loss: 1847.1809 Training g_loss: 0.8571 Training d_loss: 1.1776 Explore P: 0.0304\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 379 Total reward: 199.0 Average reward fake: 0.48670801520347595 Average reward real: 0.491130530834198 Training q_loss: 2346.2805 Training g_loss: 0.7203 Training d_loss: 1.3981 Explore P: 0.0300\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 380 Total reward: 199.0 Average reward fake: 0.5761168599128723 Average reward real: 0.42447271943092346 Training q_loss: 6430.3193 Training g_loss: 0.5516 Training d_loss: 1.7348 Explore P: 0.0296\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 381 Total reward: 199.0 Average reward fake: 0.4846498966217041 Average reward real: 0.4451832175254822 Training q_loss: 2502.3091 Training g_loss: 0.7272 Training d_loss: 1.5030 Explore P: 0.0292\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 382 Total reward: 199.0 Average reward fake: 0.4729897379875183 Average reward real: 0.5238314867019653 Training q_loss: 1658.7152 Training g_loss: 0.7487 Training d_loss: 1.2939 Explore P: 0.0288\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 383 Total reward: 199.0 Average reward fake: 0.46471208333969116 Average reward real: 0.5161932706832886 Training q_loss: 1954.4043 Training g_loss: 0.7676 Training d_loss: 1.3225 Explore P: 0.0285\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 384 Total reward: 199.0 Average reward fake: 0.49087604880332947 Average reward real: 0.49287086725234985 Training q_loss: 13127.5186 Training g_loss: 0.7141 Training d_loss: 1.3897 Explore P: 0.0281\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 385 Total reward: 199.0 Average reward fake: 0.47440004348754883 Average reward real: 0.5197033286094666 Training q_loss: 4589.8018 Training g_loss: 0.7515 Training d_loss: 1.3227 Explore P: 0.0278\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 386 Total reward: 199.0 Average reward fake: 0.5207234621047974 Average reward real: 0.47137579321861267 Training q_loss: 4285.5063 Training g_loss: 0.6536 Training d_loss: 1.5832 Explore P: 0.0274\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 387 Total reward: 199.0 Average reward fake: 0.48067212104797363 Average reward real: 0.5828258991241455 Training q_loss: 2498.4023 Training g_loss: 0.7326 Training d_loss: 1.2098 Explore P: 0.0271\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 388 Total reward: 197.0 Average reward fake: 0.4268261790275574 Average reward real: 0.54401695728302 Training q_loss: 2192.7397 Training g_loss: 0.8514 Training d_loss: 1.1907 Explore P: 0.0267\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 389 Total reward: 199.0 Average reward fake: 0.5461229085922241 Average reward real: 0.35824820399284363 Training q_loss: 4963.8140 Training g_loss: 0.6051 Training d_loss: 1.9751 Explore P: 0.0264\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 390 Total reward: 199.0 Average reward fake: 0.6215271949768066 Average reward real: 0.5094844102859497 Training q_loss: 1693.0244 Training g_loss: 0.4756 Training d_loss: 1.7052 Explore P: 0.0261\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 391 Total reward: 199.0 Average reward fake: 0.46246814727783203 Average reward real: 0.47368550300598145 Training q_loss: 7237.4883 Training g_loss: 0.7904 Training d_loss: 1.4111 Explore P: 0.0258\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 392 Total reward: 187.0 Average reward fake: 0.4876576364040375 Average reward real: 0.4867278039455414 Training q_loss: 1880.4098 Training g_loss: 0.7222 Training d_loss: 1.8035 Explore P: 0.0255\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 393 Total reward: 199.0 Average reward fake: 0.5346835255622864 Average reward real: 0.5187641382217407 Training q_loss: 1646.0807 Training g_loss: 0.6300 Training d_loss: 1.4336 Explore P: 0.0252\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 394 Total reward: 199.0 Average reward fake: 0.46145081520080566 Average reward real: 0.5397990345954895 Training q_loss: 145806.1562 Training g_loss: 0.7734 Training d_loss: 1.2434 Explore P: 0.0249\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 395 Total reward: 190.0 Average reward fake: 0.4833149313926697 Average reward real: 0.46781474351882935 Training q_loss: 962.5975 Training g_loss: 0.7276 Training d_loss: 1.4518 Explore P: 0.0246\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 396 Total reward: 183.0 Average reward fake: 0.4403042197227478 Average reward real: 0.46262580156326294 Training q_loss: 1992.0065 Training g_loss: 0.8203 Training d_loss: 1.3611 Explore P: 0.0243\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 397 Total reward: 191.0 Average reward fake: 0.4739626944065094 Average reward real: 0.5231236219406128 Training q_loss: 2536.1248 Training g_loss: 0.7470 Training d_loss: 1.3019 Explore P: 0.0240\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 398 Total reward: 192.0 Average reward fake: 0.5072923898696899 Average reward real: 0.5244898796081543 Training q_loss: 816615.3125 Training g_loss: 0.6796 Training d_loss: 1.3615 Explore P: 0.0238\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 399 Total reward: 199.0 Average reward fake: 0.5127946138381958 Average reward real: 0.32920005917549133 Training q_loss: 1373.0750 Training g_loss: 0.6684 Training d_loss: 1.8494 Explore P: 0.0235\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 400 Total reward: 175.0 Average reward fake: 0.5036798715591431 Average reward real: 0.4568178057670593 Training q_loss: 2942.8892 Training g_loss: 0.6860 Training d_loss: 1.6035 Explore P: 0.0233\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 401 Total reward: 174.0 Average reward fake: 0.4165390431880951 Average reward real: 0.40128979086875916 Training q_loss: 4621.7930 Training g_loss: 0.8760 Training d_loss: 1.4886 Explore P: 0.0230\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 402 Total reward: 195.0 Average reward fake: 0.46689271926879883 Average reward real: 0.48579567670822144 Training q_loss: 543.4652 Training g_loss: 0.7617 Training d_loss: 1.3658 Explore P: 0.0228\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 403 Total reward: 199.0 Average reward fake: 0.5326703786849976 Average reward real: 0.4794324040412903 Training q_loss: 1350.1458 Training g_loss: 0.6299 Training d_loss: 1.5030 Explore P: 0.0225\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 404 Total reward: 174.0 Average reward fake: 0.4518399238586426 Average reward real: 0.5217366218566895 Training q_loss: 20806.2520 Training g_loss: 0.7940 Training d_loss: 1.2594 Explore P: 0.0223\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 405 Total reward: 186.0 Average reward fake: 0.5059781074523926 Average reward real: 0.5306070446968079 Training q_loss: 3016.1724 Training g_loss: 0.6842 Training d_loss: 1.3465 Explore P: 0.0221\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 406 Total reward: 195.0 Average reward fake: 0.4681625962257385 Average reward real: 0.49281802773475647 Training q_loss: 2363.8149 Training g_loss: 0.7600 Training d_loss: 1.3413 Explore P: 0.0219\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 407 Total reward: 173.0 Average reward fake: 0.5016802549362183 Average reward real: 0.5352767705917358 Training q_loss: 11441.8340 Training g_loss: 0.6956 Training d_loss: 1.3319 Explore P: 0.0217\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 408 Total reward: 183.0 Average reward fake: 0.5363624095916748 Average reward real: 0.5540772676467896 Training q_loss: 2178.8284 Training g_loss: 0.6372 Training d_loss: 1.3905 Explore P: 0.0214\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 409 Total reward: 184.0 Average reward fake: 0.4129810929298401 Average reward real: 0.489187628030777 Training q_loss: 22204.5684 Training g_loss: 0.8947 Training d_loss: 1.2661 Explore P: 0.0212\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 410 Total reward: 173.0 Average reward fake: 0.4599763751029968 Average reward real: 0.5438816547393799 Training q_loss: 30552.5312 Training g_loss: 0.7835 Training d_loss: 1.2462 Explore P: 0.0210\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 411 Total reward: 161.0 Average reward fake: 0.4202483594417572 Average reward real: 0.595416247844696 Training q_loss: 2577.2168 Training g_loss: 0.8680 Training d_loss: 1.1245 Explore P: 0.0209\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 412 Total reward: 172.0 Average reward fake: 0.4363105893135071 Average reward real: 0.5769201517105103 Training q_loss: 866.7288 Training g_loss: 0.8409 Training d_loss: 1.1578 Explore P: 0.0207\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 413 Total reward: 190.0 Average reward fake: 0.3289516568183899 Average reward real: 0.7843050360679626 Training q_loss: 4816.9097 Training g_loss: 3.8061 Training d_loss: 0.9358 Explore P: 0.0205\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 414 Total reward: 193.0 Average reward fake: 0.4734117090702057 Average reward real: 0.49310103058815 Training q_loss: 1546.0281 Training g_loss: 0.7477 Training d_loss: 1.3681 Explore P: 0.0203\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 415 Total reward: 194.0 Average reward fake: 0.5372955799102783 Average reward real: 0.38968273997306824 Training q_loss: 9865.8535 Training g_loss: 0.6218 Training d_loss: 1.7614 Explore P: 0.0201\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 416 Total reward: 180.0 Average reward fake: 0.5761961936950684 Average reward real: 0.5349763631820679 Training q_loss: 1715.4824 Training g_loss: 0.5519 Training d_loss: 1.4953 Explore P: 0.0199\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 417 Total reward: 188.0 Average reward fake: 0.4764999747276306 Average reward real: 0.4522925913333893 Training q_loss: 3066.3245 Training g_loss: 0.7414 Training d_loss: 1.4521 Explore P: 0.0197\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 418 Total reward: 191.0 Average reward fake: 0.42338138818740845 Average reward real: 0.518302857875824 Training q_loss: 2378.0359 Training g_loss: 0.8595 Training d_loss: 1.2136 Explore P: 0.0195\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 419 Total reward: 160.0 Average reward fake: 0.4689598083496094 Average reward real: 0.5094906091690063 Training q_loss: 4021.9302 Training g_loss: 0.7709 Training d_loss: 1.3526 Explore P: 0.0194\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 420 Total reward: 180.0 Average reward fake: 0.49457859992980957 Average reward real: 0.5223197937011719 Training q_loss: 2318.9363 Training g_loss: 0.7041 Training d_loss: 1.3371 Explore P: 0.0192\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 421 Total reward: 199.0 Average reward fake: 0.49359065294265747 Average reward real: 0.5107625126838684 Training q_loss: 671.8348 Training g_loss: 0.7124 Training d_loss: 1.3929 Explore P: 0.0190\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 422 Total reward: 174.0 Average reward fake: 0.42252326011657715 Average reward real: 0.6209869384765625 Training q_loss: 880.0496 Training g_loss: 0.9060 Training d_loss: 1.0841 Explore P: 0.0189\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 423 Total reward: 194.0 Average reward fake: 0.5150588154792786 Average reward real: 0.48455294966697693 Training q_loss: 26950.1523 Training g_loss: 0.6637 Training d_loss: 1.4545 Explore P: 0.0187\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 424 Total reward: 161.0 Average reward fake: 0.5085546374320984 Average reward real: 0.44396185874938965 Training q_loss: 8274.9424 Training g_loss: 0.6762 Training d_loss: 1.5290 Explore P: 0.0186\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 425 Total reward: 166.0 Average reward fake: 0.590551495552063 Average reward real: 0.47590941190719604 Training q_loss: 1175.4170 Training g_loss: 0.5266 Training d_loss: 1.7887 Explore P: 0.0184\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 426 Total reward: 148.0 Average reward fake: 0.6646289825439453 Average reward real: 0.2511454224586487 Training q_loss: 3948.8501 Training g_loss: 0.4144 Training d_loss: 2.6664 Explore P: 0.0183\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 427 Total reward: 181.0 Average reward fake: 0.5132559537887573 Average reward real: 0.46630510687828064 Training q_loss: 2899.7161 Training g_loss: 0.6679 Training d_loss: 1.5356 Explore P: 0.0182\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 428 Total reward: 199.0 Average reward fake: 0.3884658217430115 Average reward real: 0.6535091400146484 Training q_loss: 465.3638 Training g_loss: 0.9456 Training d_loss: 0.9427 Explore P: 0.0180\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 429 Total reward: 156.0 Average reward fake: 0.5305725932121277 Average reward real: 0.3783011734485626 Training q_loss: 8853.5508 Training g_loss: 0.6361 Training d_loss: 2.3552 Explore P: 0.0179\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 430 Total reward: 168.0 Average reward fake: 0.4905265271663666 Average reward real: 0.610805332660675 Training q_loss: 1672.8701 Training g_loss: 0.7125 Training d_loss: 1.1906 Explore P: 0.0177\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 431 Total reward: 162.0 Average reward fake: 0.4863017201423645 Average reward real: 0.516754686832428 Training q_loss: 2848.8601 Training g_loss: 0.7211 Training d_loss: 1.3315 Explore P: 0.0176\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 432 Total reward: 199.0 Average reward fake: 0.4627169668674469 Average reward real: 0.6080710887908936 Training q_loss: 1179.5989 Training g_loss: 0.8002 Training d_loss: 1.1826 Explore P: 0.0175\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 433 Total reward: 181.0 Average reward fake: 0.348740816116333 Average reward real: 0.5156556367874146 Training q_loss: 3337.7812 Training g_loss: 1.0571 Training d_loss: 1.1190 Explore P: 0.0173\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 434 Total reward: 183.0 Average reward fake: 0.4031746983528137 Average reward real: 0.6447582840919495 Training q_loss: 2032.2975 Training g_loss: 0.9091 Training d_loss: 1.0152 Explore P: 0.0172\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 435 Total reward: 174.0 Average reward fake: 0.503993034362793 Average reward real: 0.5195684432983398 Training q_loss: 1276.6664 Training g_loss: 0.6876 Training d_loss: 1.3743 Explore P: 0.0171\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 436 Total reward: 189.0 Average reward fake: 0.4139160215854645 Average reward real: 0.4906340539455414 Training q_loss: 14824.2812 Training g_loss: 0.8978 Training d_loss: 1.2675 Explore P: 0.0169\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 437 Total reward: 199.0 Average reward fake: 0.5291903018951416 Average reward real: 0.5137242078781128 Training q_loss: 1037.0508 Training g_loss: 0.6365 Training d_loss: 1.4257 Explore P: 0.0168\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 438 Total reward: 199.0 Average reward fake: 0.4993310868740082 Average reward real: 0.5522290468215942 Training q_loss: 242.6037 Training g_loss: 0.6949 Training d_loss: 1.3064 Explore P: 0.0167\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 439 Total reward: 199.0 Average reward fake: 0.4544784426689148 Average reward real: 0.5522936582565308 Training q_loss: 821.3441 Training g_loss: 0.7902 Training d_loss: 1.2247 Explore P: 0.0165\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 440 Total reward: 199.0 Average reward fake: 0.502521812915802 Average reward real: 0.4809119701385498 Training q_loss: 1894.8832 Training g_loss: 0.6900 Training d_loss: 1.4612 Explore P: 0.0164\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 441 Total reward: 158.0 Average reward fake: 0.45617809891700745 Average reward real: 0.4849788248538971 Training q_loss: 902.5229 Training g_loss: 0.7897 Training d_loss: 1.4788 Explore P: 0.0163\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 442 Total reward: 199.0 Average reward fake: 0.49897152185440063 Average reward real: 0.4182390570640564 Training q_loss: 2102.2327 Training g_loss: 0.6956 Training d_loss: 1.6370 Explore P: 0.0162\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 443 Total reward: 199.0 Average reward fake: 0.5077952742576599 Average reward real: 0.5485134720802307 Training q_loss: 307.9616 Training g_loss: 0.6777 Training d_loss: 1.3161 Explore P: 0.0161\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 444 Total reward: 199.0 Average reward fake: 0.43050557374954224 Average reward real: 0.4148589074611664 Training q_loss: 5070.2905 Training g_loss: 0.8562 Training d_loss: 1.4661 Explore P: 0.0159\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 445 Total reward: 178.0 Average reward fake: 0.5136556625366211 Average reward real: 0.5133684277534485 Training q_loss: 2551.8296 Training g_loss: 0.6662 Training d_loss: 1.3912 Explore P: 0.0158\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 446 Total reward: 169.0 Average reward fake: 0.5334842801094055 Average reward real: 0.5513619184494019 Training q_loss: 1640.0554 Training g_loss: 0.6321 Training d_loss: 1.4356 Explore P: 0.0157\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 447 Total reward: 199.0 Average reward fake: 0.48969346284866333 Average reward real: 0.649370551109314 Training q_loss: 428.3313 Training g_loss: 0.7153 Training d_loss: 1.1229 Explore P: 0.0156\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 448 Total reward: 196.0 Average reward fake: 0.0171642042696476 Average reward real: 0.9978076815605164 Training q_loss: 4342.9399 Training g_loss: 4.0657 Training d_loss: 0.0207 Explore P: 0.0155\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 449 Total reward: 198.0 Average reward fake: 0.5644274950027466 Average reward real: 0.5152142643928528 Training q_loss: 2121.0090 Training g_loss: 0.5741 Training d_loss: 1.5685 Explore P: 0.0154\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 450 Total reward: 189.0 Average reward fake: 0.5635169744491577 Average reward real: 0.46058231592178345 Training q_loss: 1391.6118 Training g_loss: 0.5736 Training d_loss: 1.6211 Explore P: 0.0153\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 451 Total reward: 199.0 Average reward fake: 0.5390424728393555 Average reward real: 0.4876216948032379 Training q_loss: 188.7026 Training g_loss: 0.6194 Training d_loss: 1.5387 Explore P: 0.0152\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 452 Total reward: 199.0 Average reward fake: 0.5195621252059937 Average reward real: 0.3847581744194031 Training q_loss: 13453.7471 Training g_loss: 0.6548 Training d_loss: 1.7200 Explore P: 0.0151\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 453 Total reward: 199.0 Average reward fake: 0.509408175945282 Average reward real: 0.5566961765289307 Training q_loss: 2399.2280 Training g_loss: 0.6771 Training d_loss: 1.3377 Explore P: 0.0150\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 454 Total reward: 199.0 Average reward fake: 0.5199543833732605 Average reward real: 0.4647601544857025 Training q_loss: 220.1400 Training g_loss: 0.6530 Training d_loss: 1.5067 Explore P: 0.0149\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 455 Total reward: 199.0 Average reward fake: 0.5412245392799377 Average reward real: 0.4315880835056305 Training q_loss: 13882.8750 Training g_loss: 0.6145 Training d_loss: 1.6790 Explore P: 0.0148\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 456 Total reward: 155.0 Average reward fake: 0.26653072237968445 Average reward real: 0.6943989396095276 Training q_loss: 320.0264 Training g_loss: 1.3278 Training d_loss: 0.7110 Explore P: 0.0147\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 457 Total reward: 149.0 Average reward fake: 0.42622384428977966 Average reward real: 0.5329999923706055 Training q_loss: 160.9159 Training g_loss: 0.8639 Training d_loss: 1.2457 Explore P: 0.0147\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 458 Total reward: 146.0 Average reward fake: 0.5252991914749146 Average reward real: 0.4270418584346771 Training q_loss: 768.7918 Training g_loss: 0.6495 Training d_loss: 1.6641 Explore P: 0.0146\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 459 Total reward: 186.0 Average reward fake: 0.46959224343299866 Average reward real: 0.5132001638412476 Training q_loss: 347.1895 Training g_loss: 0.7561 Training d_loss: 1.3166 Explore P: 0.0145\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 460 Total reward: 199.0 Average reward fake: 0.514326274394989 Average reward real: 0.4352591633796692 Training q_loss: 519.7978 Training g_loss: 0.6668 Training d_loss: 1.5769 Explore P: 0.0144\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 461 Total reward: 106.0 Average reward fake: 0.4843223989009857 Average reward real: 0.4456663131713867 Training q_loss: 1389.7559 Training g_loss: 0.7254 Training d_loss: 1.5042 Explore P: 0.0144\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 462 Total reward: 123.0 Average reward fake: 0.4922129213809967 Average reward real: 0.5201836824417114 Training q_loss: 139.5284 Training g_loss: 0.7086 Training d_loss: 1.3527 Explore P: 0.0143\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 463 Total reward: 180.0 Average reward fake: 0.47298726439476013 Average reward real: 0.48117274045944214 Training q_loss: 8565.1924 Training g_loss: 0.7493 Training d_loss: 1.3956 Explore P: 0.0142\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 464 Total reward: 199.0 Average reward fake: 0.512130618095398 Average reward real: 0.5690885782241821 Training q_loss: 1463.5250 Training g_loss: 0.6740 Training d_loss: 1.2955 Explore P: 0.0142\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 465 Total reward: 132.0 Average reward fake: 0.601848304271698 Average reward real: 0.46369051933288574 Training q_loss: 3740.4817 Training g_loss: 0.5943 Training d_loss: 2.0095 Explore P: 0.0141\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 466 Total reward: 106.0 Average reward fake: 0.4438106119632721 Average reward real: 0.5189962387084961 Training q_loss: 16445.3574 Training g_loss: 0.8124 Training d_loss: 1.4981 Explore P: 0.0141\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 467 Total reward: 41.0 Average reward fake: 0.5574837923049927 Average reward real: 0.38861340284347534 Training q_loss: 17787.5918 Training g_loss: 0.5843 Training d_loss: 1.8342 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 468 Total reward: 9.0 Average reward fake: 0.5501691102981567 Average reward real: 0.37654760479927063 Training q_loss: 24275.8145 Training g_loss: 0.5975 Training d_loss: 1.9276 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 469 Total reward: 14.0 Average reward fake: 0.49964770674705505 Average reward real: 0.4224957525730133 Training q_loss: 19977.6016 Training g_loss: 0.6939 Training d_loss: 1.5708 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 470 Total reward: 17.0 Average reward fake: 0.47119227051734924 Average reward real: 0.5165334939956665 Training q_loss: 17071.9902 Training g_loss: 0.7525 Training d_loss: 1.3054 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 471 Total reward: 91.0 Average reward fake: 0.4781579375267029 Average reward real: 0.540136456489563 Training q_loss: 27060.0566 Training g_loss: 0.7378 Training d_loss: 1.3264 Explore P: 0.0140\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 472 Total reward: 114.0 Average reward fake: 0.49087920784950256 Average reward real: 0.48933443427085876 Training q_loss: 16924.4238 Training g_loss: 0.7116 Training d_loss: 1.4024 Explore P: 0.0139\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 473 Total reward: 127.0 Average reward fake: 0.4274009168148041 Average reward real: 0.4760705530643463 Training q_loss: 8046.2095 Training g_loss: 0.8500 Training d_loss: 1.3399 Explore P: 0.0139\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 474 Total reward: 119.0 Average reward fake: 0.4987610876560211 Average reward real: 0.5170086622238159 Training q_loss: 4980.7290 Training g_loss: 0.6956 Training d_loss: 1.3669 Explore P: 0.0139\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 475 Total reward: 121.0 Average reward fake: 0.523879885673523 Average reward real: 0.4589312672615051 Training q_loss: 6321.1494 Training g_loss: 0.6465 Training d_loss: 1.6711 Explore P: 0.0138\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 476 Total reward: 115.0 Average reward fake: 0.47258853912353516 Average reward real: 0.46214455366134644 Training q_loss: 6237.0928 Training g_loss: 0.7496 Training d_loss: 1.4228 Explore P: 0.0138\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 477 Total reward: 130.0 Average reward fake: 0.5093212723731995 Average reward real: 0.49460163712501526 Training q_loss: 6608.5923 Training g_loss: 0.6781 Training d_loss: 1.4285 Explore P: 0.0137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 478 Total reward: 135.0 Average reward fake: 0.4980778694152832 Average reward real: 0.5079648494720459 Training q_loss: 5588.1821 Training g_loss: 0.6970 Training d_loss: 1.3730 Explore P: 0.0137\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 479 Total reward: 140.0 Average reward fake: 0.48988303542137146 Average reward real: 0.49304327368736267 Training q_loss: 302898.1562 Training g_loss: 0.7145 Training d_loss: 1.3832 Explore P: 0.0136\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 480 Total reward: 157.0 Average reward fake: 0.5425056219100952 Average reward real: 0.5036591291427612 Training q_loss: 11799.1113 Training g_loss: 0.6116 Training d_loss: 1.4696 Explore P: 0.0136\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 481 Total reward: 135.0 Average reward fake: 0.49243465065956116 Average reward real: 0.47958189249038696 Training q_loss: 2967.5911 Training g_loss: 0.7084 Training d_loss: 1.4139 Explore P: 0.0135\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 482 Total reward: 144.0 Average reward fake: 0.5047774910926819 Average reward real: 0.4892800748348236 Training q_loss: 4640.8774 Training g_loss: 0.6837 Training d_loss: 1.4285 Explore P: 0.0135\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 483 Total reward: 161.0 Average reward fake: 0.49370232224464417 Average reward real: 0.5817239284515381 Training q_loss: 22889.9902 Training g_loss: 0.7058 Training d_loss: 1.2348 Explore P: 0.0134\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Episode: 484 Total reward: 153.0 Average reward fake: 0.5465416312217712 Average reward real: 0.5558545589447021 Training q_loss: 2891.2300 Training g_loss: 0.6414 Training d_loss: 1.4606 Explore P: 0.0134\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 485 Total reward: 161.0 Average reward fake: 0.5182978510856628 Average reward real: 0.48949456214904785 Training q_loss: 3937.9062 Training g_loss: 0.6572 Training d_loss: 1.4963 Explore P: 0.0133\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 486 Total reward: 169.0 Average reward fake: 0.4814396798610687 Average reward real: 0.40814629197120667 Training q_loss: 3630.9116 Training g_loss: 0.7325 Training d_loss: 1.6107 Explore P: 0.0132\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 487 Total reward: 199.0 Average reward fake: 0.5713914036750793 Average reward real: 0.5022509694099426 Training q_loss: 5029.3579 Training g_loss: 0.5607 Training d_loss: 1.5579 Explore P: 0.0132\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 488 Total reward: 180.0 Average reward fake: 0.4737953543663025 Average reward real: 0.4752127230167389 Training q_loss: 9087.3799 Training g_loss: 0.7475 Training d_loss: 1.3927 Explore P: 0.0131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 489 Total reward: 199.0 Average reward fake: 0.4979422986507416 Average reward real: 0.46207815408706665 Training q_loss: 2081.0522 Training g_loss: 0.6981 Training d_loss: 1.4814 Explore P: 0.0131\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 490 Total reward: 174.0 Average reward fake: 0.5284017324447632 Average reward real: 0.3259391784667969 Training q_loss: 4815.9771 Training g_loss: 0.6443 Training d_loss: 1.9753 Explore P: 0.0130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 491 Total reward: 199.0 Average reward fake: 0.4703463017940521 Average reward real: 0.5682376027107239 Training q_loss: 1807.8141 Training g_loss: 0.7543 Training d_loss: 1.2086 Explore P: 0.0130\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 492 Total reward: 188.0 Average reward fake: 0.5685049891471863 Average reward real: 0.5731673240661621 Training q_loss: 3144.2297 Training g_loss: 0.5668 Training d_loss: 1.4153 Explore P: 0.0129\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 493 Total reward: 190.0 Average reward fake: 0.5490562319755554 Average reward real: 0.5427969694137573 Training q_loss: 3030.8840 Training g_loss: 0.6046 Training d_loss: 1.4680 Explore P: 0.0128\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 494 Total reward: 179.0 Average reward fake: 0.5069561004638672 Average reward real: 0.5550211668014526 Training q_loss: 2104.4663 Training g_loss: 0.6804 Training d_loss: 1.3063 Explore P: 0.0128\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 495 Total reward: 199.0 Average reward fake: 0.4974590837955475 Average reward real: 0.5835819244384766 Training q_loss: 1589.6047 Training g_loss: 0.6984 Training d_loss: 1.2387 Explore P: 0.0127\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 496 Total reward: 156.0 Average reward fake: 0.5214542746543884 Average reward real: 0.5115600824356079 Training q_loss: 5323.6392 Training g_loss: 0.6632 Training d_loss: 1.4363 Explore P: 0.0127\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 497 Total reward: 182.0 Average reward fake: 0.493346631526947 Average reward real: 0.5393956303596497 Training q_loss: 4154.1357 Training g_loss: 0.7116 Training d_loss: 1.3120 Explore P: 0.0126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 498 Total reward: 182.0 Average reward fake: 0.4773500859737396 Average reward real: 0.5083982348442078 Training q_loss: 3781.3918 Training g_loss: 0.7597 Training d_loss: 1.3521 Explore P: 0.0126\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "Episode: 499 Total reward: 158.0 Average reward fake: 0.4598754346370697 Average reward real: 0.56103515625 Training q_loss: 2278.5684 Training g_loss: 0.7975 Training d_loss: 1.2368 Explore P: 0.0126\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards and losses list for plotting\n",
    "rewards_list, rewards_fake_list, rewards_real_list = [], [], []\n",
    "d_loss_list, g_loss_list, q_loss_list = [], [], [] \n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Restore/load the trained model \n",
    "    saver.restore(sess, 'checkpoints/Q-GAN-cartpole.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # Training episodes/epochs\n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        \n",
    "        # Env/agent steps/batches/minibatches\n",
    "        total_reward, rewards_fake_mean, rewards_real_mean = 0, 0, 0\n",
    "        d_loss, g_loss, q_loss = 0, 0, 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from model\n",
    "                feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "                actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "                action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # Episode/epoch training is done/failed!\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Average reward fake: {}'.format(rewards_fake_mean),\n",
    "                      'Average reward real: {}'.format(rewards_real_mean),\n",
    "                      'Training q_loss: {:.4f}'.format(q_loss),\n",
    "                      'Training g_loss: {:.4f}'.format(g_loss),\n",
    "                      'Training d_loss: {:.4f}'.format(d_loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                print('-------------------------------------------------------------------------------')\n",
    "                \n",
    "                # total rewards and losses for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                rewards_fake_list.append((ep, rewards_fake_mean))\n",
    "                d_loss_list.append((ep, d_loss))\n",
    "                g_loss_list.append((ep, g_loss))\n",
    "                q_loss_list.append((ep, q_loss))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            #rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train the model\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions}\n",
    "            rewards_fake, rewards_real = sess.run([model.rewards_fake, model.rewards_real], feed_dict)\n",
    "            feed_dict={model.states: next_states}\n",
    "            next_actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "\n",
    "            # Mean/average fake and real rewards or rewarded generated/given actions\n",
    "            rewards_fake_mean = np.mean(rewards_fake.reshape(-1))\n",
    "            rewards_real_mean = np.mean(rewards_real.reshape(-1))\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            next_actions_logits[episode_ends] = (0, 0)\n",
    "\n",
    "            # Bellman equation: Qt = Rt + max(Qt+1)\n",
    "            targetQs = rewards_fake.reshape(-1) + (gamma * np.max(next_actions_logits, axis=1))\n",
    "\n",
    "            # Updating the model\n",
    "            feed_dict = {model.states: states, model.next_states: next_states, model.actions: actions, \n",
    "                         model.targetQs: targetQs}\n",
    "            q_loss, _ = sess.run([model.q_loss, model.q_opt], feed_dict)\n",
    "            g_loss, _ = sess.run([model.g_loss, model.g_opt], feed_dict)\n",
    "            d_loss, _ = sess.run([model.d_loss, model.d_opt], feed_dict)\n",
    "            \n",
    "    # Save the trained model \n",
    "    saver.save(sess, 'checkpoints/Q-GAN-cartpole.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(rewards_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps, arr = np.array(q_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Q losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'G losses')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(g_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('G losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'D losses')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, arr = np.array(d_loss_list).T\n",
    "smoothed_arr = running_mean(arr, 10)\n",
    "plt.plot(eps[-len(smoothed_arr):], smoothed_arr)\n",
    "plt.plot(eps, arr, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('D losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/Q-GAN-cartpole.ckpt\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 5\n",
    "test_max_steps = 200\n",
    "env.reset()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Restore/load the trained model \n",
    "    saver.restore(sess, 'checkpoints/Q-GAN-cartpole.ckpt')    \n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    # iterations\n",
    "    for ep in range(test_episodes):\n",
    "        \n",
    "        # number of env/rob steps\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            #env.render()\n",
    "            \n",
    "            # Get action from DQAN\n",
    "            feed_dict = {model.states: state.reshape((1, *state.shape))}\n",
    "            actions_logits = sess.run(model.actions_logits, feed_dict)\n",
    "            action = np.argmax(actions_logits)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            # The task is done or not;\n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1\n",
    "\n",
    "# Closing the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this to Deep Convolutional QAN\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
